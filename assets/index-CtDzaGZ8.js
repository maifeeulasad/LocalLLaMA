const e=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[I have the same opinion](https://preview.redd.it/f3kbm3p73zue1.png?width=1198&amp;format=png&amp;auto=webp&amp;s=626a7ab843545471bcd88509c4daaebaa4d44d79)\\n\\nAnd in Meta's recent Llama 4 release [blog post](https://ai.meta.com/blog/llama-4-multimodal-intelligence/), in the \\"Explore the Llama ecosystem\\" section, Meta thanks and acknowledges various companies and partners:\\n\\n[Meta's blog](https://preview.redd.it/85yqglbi4zue1.png?width=1476&amp;format=png&amp;auto=webp&amp;s=b1292382820cafc658d65bb71ca5bcf15ef0bf1b)\\n\\nNotice how **Ollama** is mentioned, but there's no acknowledgment of **llama.cpp** or its creator **ggerganov**, whose foundational work made much of this ecosystem possible.\\n\\nIsn't this situation incredibly ironic? The original project creators and ecosystem founders get forgotten by big companies, while YouTube and social media are flooded with clickbait titles like \\"Deploy LLM with one click using Ollama.\\"\\n\\nContent creators even deliberately blur the lines between the complete and distilled versions of models like DeepSeek R1, using the R1 name indiscriminately for marketing purposes.\\n\\nMeanwhile, the foundational projects and their creators are forgotten by the public, never receiving the gratitude or compensation they deserve. The people doing the real technical heavy lifting get overshadowed while wrapper projects take all the glory.\\n\\nWhat do you think about this situation? Is this fair?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Finally someone noticed this unfair situation","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":78,"top_awarded_type":null,"hide_score":false,"media_metadata":{"85yqglbi4zue1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":26,"x":108,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bba65c197fbcaa1596917361e860c2577860fe0"},{"y":53,"x":216,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9068007eaa8f4fbfb043e96c1a89abb0ab9b030d"},{"y":78,"x":320,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38da5e7848f72facd32a70a14cd19905a88946c7"},{"y":157,"x":640,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4467f424e645c39ea8b69c2366514c8031250683"},{"y":236,"x":960,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dda18f632eb0846604a8140329f5675236baf66b"},{"y":266,"x":1080,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e732091f7a148d3ecd783b843869aa4604c3ad8c"}],"s":{"y":364,"x":1476,"u":"https://preview.redd.it/85yqglbi4zue1.png?width=1476&amp;format=png&amp;auto=webp&amp;s=b1292382820cafc658d65bb71ca5bcf15ef0bf1b"},"id":"85yqglbi4zue1"},"f3kbm3p73zue1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":59,"x":108,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fdf4ec1351849df7dcb1a4fcfe3fd9055d5e2dc1"},{"y":118,"x":216,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=207c0a2cedd1525ebe0c3ae951dacb52a6b5dbca"},{"y":175,"x":320,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fde5b6bda8c62eb3fe716c58a8a3f3380de68bd5"},{"y":350,"x":640,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb3cc6756edef3ba1c7f959d1b8768ce4ea05e95"},{"y":525,"x":960,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a7ff5e7a543dcbe9ecef38470739184789efb537"},{"y":591,"x":1080,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2ed81b6fd3f17e648893e6f90e5c3afa6e68368a"}],"s":{"y":656,"x":1198,"u":"https://preview.redd.it/f3kbm3p73zue1.png?width=1198&amp;format=png&amp;auto=webp&amp;s=626a7ab843545471bcd88509c4daaebaa4d44d79"},"id":"f3kbm3p73zue1"}},"name":"t3_1jzocoo","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":1704,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_sqi8xxun","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":1704,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/HJCUCArmZhIVCwAB_kUxXfXainLHG1U6mdiv6MF4jaY.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1744712476,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/f3kbm3p73zue1.png?width=1198&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=626a7ab843545471bcd88509c4daaebaa4d44d79\\"&gt;I have the same opinion&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;And in Meta&amp;#39;s recent Llama 4 release &lt;a href=\\"https://ai.meta.com/blog/llama-4-multimodal-intelligence/\\"&gt;blog post&lt;/a&gt;, in the &amp;quot;Explore the Llama ecosystem&amp;quot; section, Meta thanks and acknowledges various companies and partners:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/85yqglbi4zue1.png?width=1476&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b1292382820cafc658d65bb71ca5bcf15ef0bf1b\\"&gt;Meta&amp;#39;s blog&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Notice how &lt;strong&gt;Ollama&lt;/strong&gt; is mentioned, but there&amp;#39;s no acknowledgment of &lt;strong&gt;llama.cpp&lt;/strong&gt; or its creator &lt;strong&gt;ggerganov&lt;/strong&gt;, whose foundational work made much of this ecosystem possible.&lt;/p&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t this situation incredibly ironic? The original project creators and ecosystem founders get forgotten by big companies, while YouTube and social media are flooded with clickbait titles like &amp;quot;Deploy LLM with one click using Ollama.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Content creators even deliberately blur the lines between the complete and distilled versions of models like DeepSeek R1, using the R1 name indiscriminately for marketing purposes.&lt;/p&gt;\\n\\n&lt;p&gt;Meanwhile, the foundational projects and their creators are forgotten by the public, never receiving the gratitude or compensation they deserve. The people doing the real technical heavy lifting get overshadowed while wrapper projects take all the glory.&lt;/p&gt;\\n\\n&lt;p&gt;What do you think about this situation? Is this fair?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?auto=webp&amp;s=73680bd62bdee9144dac3420d3a452f721cd0fd7","width":1920,"height":1080},"resolutions":[{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a3e8d84d84c0771f9170d342e3cad55dd24d2d2","width":108,"height":60},{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e71769f12f8394ade22df3988eb60eb81c4555a0","width":216,"height":121},{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e17ae71bea57a2bacbc6bf76c10a368028e3dfea","width":320,"height":180},{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=65f85ee3e9068eb521d7e3ef4dce3cee7c471c03","width":640,"height":360},{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=33c1ad00be223253a8c1070dabe6caec52316a73","width":960,"height":540},{"url":"https://external-preview.redd.it/5GYklgQz-p1iWSTGvDsKHeD_QUDxP-9vHZQeXTsgRz4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49c2be41512b4174a6b26078fa0963cde736cf09","width":1080,"height":607}],"variants":{},"id":"HkX9BjC2McU-NLZUojMlPZrEAbLHFQpiKt0PlRcihSE"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1jzocoo","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"nekofneko","discussion_type":null,"num_comments":242,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/","subreddit_subscribers":492248,"created_utc":1744712476,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnywsep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Inner-End7733","can_mod_post":false,"send_replies":true,"parent_id":"t1_mnc72d9","score":3,"author_fullname":"t2_1jyxf8j6s6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Honestly Phi4 is dope.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnywsep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly Phi4 is dope.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnywsep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745088467,"author_flair_text":null,"treatment_tags":[],"created_utc":1745088467,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mnc72d9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn870nf","score":53,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Microsoft being an open source advocate still makes me feel all weird but hey, kudos to them for giving credit where credit is due. Unlike llama.cpp wrappers who slap a fancy GUI and flowery VC-baiting language on to work that isn't theirs.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mnc72d9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Microsoft being an open source advocate still makes me feel all weird but hey, kudos to them for giving credit where credit is due. Unlike llama.cpp wrappers who slap a fancy GUI and flowery VC-baiting language on to work that isn&amp;#39;t theirs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnc72d9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744767885,"author_flair_text":null,"treatment_tags":[],"created_utc":1744767885,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8hm71","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn870nf","score":38,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, this is what we wanna see!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8hm71","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, this is what we wanna see!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8hm71/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744725975,"author_flair_text":null,"treatment_tags":[],"created_utc":1744725975,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":38}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8q0vf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThiccStorms","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn870nf","score":21,"author_fullname":"t2_ei5y65wk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"bitnet! im excited!!!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8q0vf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;bitnet! im excited!!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8q0vf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728568,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728568,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbtyq9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"buildmine10","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn870nf","score":0,"author_fullname":"t2_9zuu2802","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That does surprisingly well","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mnbtyq9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That does surprisingly well&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbtyq9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744763199,"author_flair_text":null,"treatment_tags":[],"created_utc":1744763199,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mn870nf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Educational_Rent1059","can_mod_post":false,"created_utc":1744722375,"send_replies":true,"parent_id":"t1_mn7oih5","score":333,"author_fullname":"t2_ac1d5rhvu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hijacking this top comment to update this , Microsoft just released Bitnet 1.58, and look how it should be done:\\n\\n[https://github.com/microsoft/BitNet](https://github.com/microsoft/BitNet)\\n\\nhttps://preview.redd.it/5dnl6todzzue1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=c602fb9df04b295b06f0e1dbce61412cb41629fc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn870nf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hijacking this top comment to update this , Microsoft just released Bitnet 1.58, and look how it should be done:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/microsoft/BitNet\\"&gt;https://github.com/microsoft/BitNet&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5dnl6todzzue1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c602fb9df04b295b06f0e1dbce61412cb41629fc\\"&gt;https://preview.redd.it/5dnl6todzzue1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c602fb9df04b295b06f0e1dbce61412cb41629fc&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn870nf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744722375,"media_metadata":{"5dnl6todzzue1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":20,"x":108,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d591ee38cca20feb735662215fc22edf76ce340"},{"y":40,"x":216,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=162b9f7b0f658cb0ada132fbe016e5ef8a751e02"},{"y":59,"x":320,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e59e85016fa4f583e346991924a61f8bc4ff06c"},{"y":118,"x":640,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fdc497faa37c9cceadfee25db4be3cf054b564f"},{"y":178,"x":960,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=70728f8de7a8b9c0c8c81a175c5a1ecd2de2cf9f"},{"y":200,"x":1080,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=75c9af8ec8873d429414282acbed7838ade7e3e3"}],"s":{"y":247,"x":1329,"u":"https://preview.redd.it/5dnl6todzzue1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=c602fb9df04b295b06f0e1dbce61412cb41629fc"},"id":"5dnl6todzzue1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":333}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn89hem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"siegevjorn","can_mod_post":false,"created_utc":1744723252,"send_replies":true,"parent_id":"t1_mn7oih5","score":137,"author_fullname":"t2_vdj76m1r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hail **llama.cpp**. Long live **ggerganov**, the true **King** of local LLM.","edited":1744754286,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn89hem","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hail &lt;strong&gt;llama.cpp&lt;/strong&gt;. Long live &lt;strong&gt;ggerganov&lt;/strong&gt;, the true &lt;strong&gt;King&lt;/strong&gt; of local LLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn89hem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723252,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":137}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8gvi8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn89w25","score":16,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/i7akpb4d90ve1.png?width=500&amp;format=png&amp;auto=webp&amp;s=8589fb8e01b3fe534bd1fc2de2e12da4feffa197","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8gvi8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/i7akpb4d90ve1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8589fb8e01b3fe534bd1fc2de2e12da4feffa197\\"&gt;https://preview.redd.it/i7akpb4d90ve1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8589fb8e01b3fe534bd1fc2de2e12da4feffa197&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8gvi8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744725732,"media_metadata":{"i7akpb4d90ve1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":133,"x":108,"u":"https://preview.redd.it/i7akpb4d90ve1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3f5c2c1cc1fb2025790c4ea7ef88b354a4deaf8"},{"y":266,"x":216,"u":"https://preview.redd.it/i7akpb4d90ve1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5831dd12d594e07b20fbeed0ff7564ef71bddc0"},{"y":395,"x":320,"u":"https://preview.redd.it/i7akpb4d90ve1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=acdc647729f13ba2c7bbc780992de9a7302ece2c"}],"s":{"y":618,"x":500,"u":"https://preview.redd.it/i7akpb4d90ve1.png?width=500&amp;format=png&amp;auto=webp&amp;s=8589fb8e01b3fe534bd1fc2de2e12da4feffa197"},"id":"i7akpb4d90ve1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1744725732,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"mn89w25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mission_tiefsee","can_mod_post":false,"created_utc":1744723395,"send_replies":true,"parent_id":"t1_mn7oih5","score":17,"author_fullname":"t2_1l0xi85fdm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hail to the king!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn89w25","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hail to the king!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn89w25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723395,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn82kqy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn80cqy","score":86,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/7ol89jxutzue1.png?width=2159&amp;format=png&amp;auto=webp&amp;s=fbf2ba63e5e7e85b3a4ec6e4b1d16b073d294de7\\n\\nFair point =)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn82kqy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/7ol89jxutzue1.png?width=2159&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbf2ba63e5e7e85b3a4ec6e4b1d16b073d294de7\\"&gt;https://preview.redd.it/7ol89jxutzue1.png?width=2159&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbf2ba63e5e7e85b3a4ec6e4b1d16b073d294de7&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Fair point =)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn82kqy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744720732,"media_metadata":{"7ol89jxutzue1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":43,"x":108,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d547bc271ef9f09ffd117511705eb0e489423b72"},{"y":86,"x":216,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=749083ac5eb85ba1a54be54ac38fbd8bd305d162"},{"y":128,"x":320,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=46889434f292b5e1761f02146a057e6dcf24773b"},{"y":257,"x":640,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=082adf3e5a58a2b154de8c3910e3f66122dec37a"},{"y":385,"x":960,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6346c694babd47d92a9e969f846407731f6bc867"},{"y":434,"x":1080,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d502f86580576dab2b86a556a859ee1ededc2e5e"}],"s":{"y":868,"x":2159,"u":"https://preview.redd.it/7ol89jxutzue1.png?width=2159&amp;format=png&amp;auto=webp&amp;s=fbf2ba63e5e7e85b3a4ec6e4b1d16b073d294de7"},"id":"7ol89jxutzue1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1744720732,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":86}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mncqmk9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8o6ks","score":6,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llava and bakllava (best name btw) based models were always supported. As for webui: you can always point to an alternative frontend with the llama-server —path flag (for example the version before the current one, which was also built in; disclaimer: I was the author of that frontend)","edited":false,"author_flair_css_class":null,"name":"t1_mncqmk9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llava and bakllava (best name btw) based models were always supported. As for webui: you can always point to an alternative frontend with the llama-server —path flag (for example the version before the current one, which was also built in; disclaimer: I was the author of that frontend)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mncqmk9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744775495,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1744775495,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"a8acc9bc-4792-11ee-b77d-c61a47557e59","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9bxe2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"henk717","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8o6ks","score":9,"author_fullname":"t2_bx8b9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are downstream projects that allow it over the API. KoboldCpp is one of them and I'd be surprised if we are the only ones.","edited":false,"author_flair_css_class":null,"name":"t1_mn9bxe2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"KoboldAI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are downstream projects that allow it over the API. KoboldCpp is one of them and I&amp;#39;d be surprised if we are the only ones.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9bxe2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744735133,"author_flair_text":"KoboldAI","collapsed":false,"created_utc":1744735133,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#5a74cc","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8o6ks","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shroddy","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8j0bq","score":1,"author_fullname":"t2_10idu2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes but not with the cool web interface, only a very bare-bones cli tool.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8o6ks","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes but not with the cool web interface, only a very bare-bones cli tool.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8o6ks/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728012,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728012,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8j0bq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boringcynicism","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn80cqy","score":14,"author_fullname":"t2_1hz0lz0k5i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It works with Gemma :P","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8j0bq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It works with Gemma :P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8j0bq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726424,"author_flair_text":null,"treatment_tags":[],"created_utc":1744726424,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn813ex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Equivalent-Stuff-347","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn80cqy","score":10,"author_fullname":"t2_m5u9f1xs1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Or a VLA model","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn813ex","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Or a VLA model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn813ex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744720155,"author_flair_text":null,"treatment_tags":[],"created_utc":1744720155,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mn80cqy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shroddy","can_mod_post":false,"created_utc":1744719866,"send_replies":true,"parent_id":"t1_mn7oih5","score":61,"author_fullname":"t2_10idu2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Except you want to use a vision model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn80cqy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Except you want to use a vision model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn80cqy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719866,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":61}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9royx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thrumpwart","can_mod_post":false,"created_utc":1744739700,"send_replies":true,"parent_id":"t1_mn7oih5","score":15,"author_fullname":"t2_iol3buybk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Naming my next child Llama CPP Gerganov the 1st in his honour.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9royx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Naming my next child Llama CPP Gerganov the 1st in his honour.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9royx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744739700,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9czoi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"softwareweaver","can_mod_post":false,"created_utc":1744735450,"send_replies":true,"parent_id":"t1_mn7oih5","score":4,"author_fullname":"t2_k7r9yrxx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A good solution is to use llama.cpp and llama swap.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9czoi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A good solution is to use llama.cpp and llama swap.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9czoi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744735450,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7oih5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"created_utc":1744714625,"send_replies":true,"parent_id":"t3_1jzocoo","score":950,"author_fullname":"t2_s4zzntp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Glory to **llama.cpp** and **ggerganov**!  \\nWe, local users will never forget our main man!  \\nIf you call something local, it is **llama.cpp!**","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7oih5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Glory to &lt;strong&gt;llama.cpp&lt;/strong&gt; and &lt;strong&gt;ggerganov&lt;/strong&gt;!&lt;br/&gt;\\nWe, local users will never forget our main man!&lt;br/&gt;\\nIf you call something local, it is &lt;strong&gt;llama.cpp!&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7oih5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714625,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":950}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndnodh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LinkSea8324","can_mod_post":false,"created_utc":1744794133,"send_replies":true,"parent_id":"t1_mn817in","score":16,"author_fullname":"t2_152zyn72n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ggerganov is aware of it, not sure how he feels but he seems to be ironic about it\\n\\nhttps://github.com/ggml-org/llama.cpp/pull/12896\\n\\n&gt;In VSCode -&gt; Chat -&gt; Manage models -&gt; select \\"Ollama\\" (**not sure why it is called like this**):","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndnodh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ggerganov is aware of it, not sure how he feels but he seems to be ironic about it&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/12896\\"&gt;https://github.com/ggml-org/llama.cpp/pull/12896&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;In VSCode -&amp;gt; Chat -&amp;gt; Manage models -&amp;gt; select &amp;quot;Ollama&amp;quot; (&lt;strong&gt;not sure why it is called like this&lt;/strong&gt;):&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndnodh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744794133,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"mn817in","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1744720200,"send_replies":true,"parent_id":"t3_1jzocoo","score":45,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The recent GitHub Copilot support for local models also only [mentions Ollama](https://www.reddit.com/r/LocalLLaMA/comments/1jxbba9/you_can_now_use_github_copilot_with_native/) (in a very prominent way), but not llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn817in","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The recent GitHub Copilot support for local models also only &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1jxbba9/you_can_now_use_github_copilot_with_native/\\"&gt;mentions Ollama&lt;/a&gt; (in a very prominent way), but not llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn817in/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744720200,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":45}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8j97v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vibjelo","can_mod_post":false,"created_utc":1744726502,"send_replies":true,"parent_id":"t1_mn7z3za","score":46,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Doesn't this contradict their stated goal?\\n\\nI'm not sure why anyone would be surprised at Meta AI being contradictory. Since day one they've called Llama \\"open source\\" in all their marketing materials, but if you read the legal documents, they insist on calling Llama \\"proprietary\\" and even in a few places they call the license a \\"proprietary license\\".\\n\\nIf someone been doing contradictive statements for so long, I don't think we should be surprised when they continue to do that...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8j97v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Doesn&amp;#39;t this contradict their stated goal?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m not sure why anyone would be surprised at Meta AI being contradictory. Since day one they&amp;#39;ve called Llama &amp;quot;open source&amp;quot; in all their marketing materials, but if you read the legal documents, they insist on calling Llama &amp;quot;proprietary&amp;quot; and even in a few places they call the license a &amp;quot;proprietary license&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;If someone been doing contradictive statements for so long, I don&amp;#39;t think we should be surprised when they continue to do that...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8j97v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726502,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnao90r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"milanove","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn9zgwn","score":9,"author_fullname":"t2_ajkmr","approved_by":null,"mod_note":null,"all_awardings":[],"body":"In this vein, doesn't the EU provide grants for open-source projects and organizations? Would it be possible for ggerganov to get an EU grant for the [GGML](https://ggml.ai/) organization he setup for llama.cpp, since he's Bulgarian?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mnao90r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In this vein, doesn&amp;#39;t the EU provide grants for open-source projects and organizations? Would it be possible for ggerganov to get an EU grant for the &lt;a href=\\"https://ggml.ai/\\"&gt;GGML&lt;/a&gt; organization he setup for llama.cpp, since he&amp;#39;s Bulgarian?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnao90r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744749464,"author_flair_text":null,"treatment_tags":[],"created_utc":1744749464,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnmovao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"One-Employment3759","can_mod_post":false,"send_replies":true,"parent_id":"t1_mnknru0","score":2,"author_fullname":"t2_1f6wnmakwr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"I don't always train on test, but when I do, I do it repeatedly.\\"","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mnmovao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;I don&amp;#39;t always train on test, but when I do, I do it repeatedly.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnmovao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744914961,"author_flair_text":null,"treatment_tags":[],"created_utc":1744914961,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mnknru0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"georgejrjrjr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn9zgwn","score":2,"author_fullname":"t2_ei8i09kjx","approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, the original LLaMA team at FAIR played a bunch of dirty tricks to win out over Zetta, Meta’s other LLM project. Including training on test.\\n\\nThen Guillaume went to Mistral and trained on test there —we know because of the huge eval discrepancies when you mixed up the ordering of the answers.\\n\\nAlso, Llama 3 was pretty decent, actually, aside from the garbage license and weak post-training.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mnknru0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, the original LLaMA team at FAIR played a bunch of dirty tricks to win out over Zetta, Meta’s other LLM project. Including training on test.&lt;/p&gt;\\n\\n&lt;p&gt;Then Guillaume went to Mistral and trained on test there —we know because of the huge eval discrepancies when you mixed up the ordering of the answers.&lt;/p&gt;\\n\\n&lt;p&gt;Also, Llama 3 was pretty decent, actually, aside from the garbage license and weak post-training.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnknru0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744892798,"author_flair_text":null,"treatment_tags":[],"created_utc":1744892798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mn9zgwn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"One-Employment3759","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn97dna","score":20,"author_fullname":"t2_1f6wnmakwr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That explains a lot about how things are going. The French are the OG","edited":false,"author_flair_css_class":null,"name":"t1_mn9zgwn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That explains a lot about how things are going. The French are the OG&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9zgwn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744742043,"author_flair_text":null,"collapsed":false,"created_utc":1744742043,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"mn97dna","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"georgejrjrjr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8pyx9","score":12,"author_fullname":"t2_ei8i09kjx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nope! Not anymore. GenAI team (which makes Llama and has since v3 at least) is CA based.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn97dna","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope! Not anymore. GenAI team (which makes Llama and has since v3 at least) is CA based.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn97dna/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744733791,"author_flair_text":null,"treatment_tags":[],"created_utc":1744733791,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8pyx9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lcsq","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8b08j","score":17,"author_fullname":"t2_e43bqeq9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama is built at FAIR's Paris facility. Many of the author names on the llama papers are French.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8pyx9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama is built at FAIR&amp;#39;s Paris facility. Many of the author names on the llama papers are French.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8pyx9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728552,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728552,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8b08j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Remove_Ayys","can_mod_post":false,"created_utc":1744723783,"send_replies":true,"parent_id":"t1_mn7z3za","score":19,"author_fullname":"t2_948o6eyi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you go by the number of commits, 4/5 of the top llama.cpp contributors are located in the EU so this could be a consequence of the conflict between Meta and the European Commission.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8b08j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you go by the number of commits, 4/5 of the top llama.cpp contributors are located in the EU so this could be a consequence of the conflict between Meta and the European Commission.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8b08j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723783,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnd3bpv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustOneAvailableName","can_mod_post":false,"created_utc":1744781547,"send_replies":true,"parent_id":"t1_mn7z3za","score":0,"author_fullname":"t2_jycu8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; To me it's a big mystery why Meta is not actively supporting llama.cpp.\\n\\nI know I was pissed about llama.cpp, so I can imagine the maintainers of PyTorch also wouldn't be happy about that. Llama.cpp just ignored all existing tooling and roadmaps to completely reinvent the wheel.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnd3bpv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;To me it&amp;#39;s a big mystery why Meta is not actively supporting llama.cpp.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I know I was pissed about llama.cpp, so I can imagine the maintainers of PyTorch also wouldn&amp;#39;t be happy about that. Llama.cpp just ignored all existing tooling and roadmaps to completely reinvent the wheel.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnd3bpv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744781547,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"more","data":{"count":3,"name":"t1_mn89q8s","id":"mn89q8s","parent_id":"t1_mn7z3za","depth":1,"children":["mn89q8s","mn8phq7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7z3za","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1744719374,"send_replies":true,"parent_id":"t3_1jzocoo","score":155,"author_fullname":"t2_qhlcbiy3k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To me it's a big mystery why Meta is not actively supporting llama.cpp. Official comment on Llama 4:\\n\\n&gt;**The most accessible** and scalable generation of Llama is here. Native multimodality, mixture-of-experts models, super long context windows, step changes in performance, and unparalleled efficiency. All in easy-to-deploy sizes custom fit for how you want to use it.\\n\\nI'm puzzled by Meta's approach to \\"accessibility\\". If they advocate for \\"accessible AI\\", why aren't they collaborating with the llama.cpp project to make their models compatible? Right now, Llama 4's multimodality is **inaccessible** to consumers because no one has added support to the most popular local LLM engine. Doesn't this contradict their stated goal?\\n\\nKudos to Google for collaborating with llama.cpp and adding support for their models, making them actually accessible to everyone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7z3za","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To me it&amp;#39;s a big mystery why Meta is not actively supporting llama.cpp. Official comment on Llama 4:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;&lt;strong&gt;The most accessible&lt;/strong&gt; and scalable generation of Llama is here. Native multimodality, mixture-of-experts models, super long context windows, step changes in performance, and unparalleled efficiency. All in easy-to-deploy sizes custom fit for how you want to use it.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m puzzled by Meta&amp;#39;s approach to &amp;quot;accessibility&amp;quot;. If they advocate for &amp;quot;accessible AI&amp;quot;, why aren&amp;#39;t they collaborating with the llama.cpp project to make their models compatible? Right now, Llama 4&amp;#39;s multimodality is &lt;strong&gt;inaccessible&lt;/strong&gt; to consumers because no one has added support to the most popular local LLM engine. Doesn&amp;#39;t this contradict their stated goal?&lt;/p&gt;\\n\\n&lt;p&gt;Kudos to Google for collaborating with llama.cpp and adding support for their models, making them actually accessible to everyone.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7z3za/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719374,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":155}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7o0mu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"created_utc":1744714372,"send_replies":true,"parent_id":"t1_mn7m5el","score":30,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agree.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7o0mu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7o0mu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714372,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":9,"name":"t1_mn8xvwl","id":"mn8xvwl","parent_id":"t1_mn8jr3p","depth":5,"children":["mn8xvwl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8jr3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boringcynicism","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8is4d","score":54,"author_fullname":"t2_1hz0lz0k5i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This stuff? [https://github.com/ollama/ollama/pull/7913](https://github.com/ollama/ollama/pull/7913)\\n\\nIt's completely unoptimized so I assure you no-one is actually using this LOL. It pulls in and builds llama.cpp: [https://github.com/ollama/ollama/blob/main/Makefile.sync#L25](https://github.com/ollama/ollama/blob/main/Makefile.sync#L25)","edited":false,"author_flair_css_class":null,"name":"t1_mn8jr3p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This stuff? &lt;a href=\\"https://github.com/ollama/ollama/pull/7913\\"&gt;https://github.com/ollama/ollama/pull/7913&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s completely unoptimized so I assure you no-one is actually using this LOL. It pulls in and builds llama.cpp: &lt;a href=\\"https://github.com/ollama/ollama/blob/main/Makefile.sync#L25\\"&gt;https://github.com/ollama/ollama/blob/main/Makefile.sync#L25&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8jr3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726658,"author_flair_text":null,"collapsed":false,"created_utc":1744726658,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnaasv2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AD7GD","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8is4d","score":6,"author_fullname":"t2_gm98s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As far as I can tell, they use GGML (the building blocks) but not stuff above it (e.g. they do not use llama-serve).","edited":false,"author_flair_css_class":null,"name":"t1_mnaasv2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As far as I can tell, they use GGML (the building blocks) but not stuff above it (e.g. they do not use llama-serve).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnaasv2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744745471,"author_flair_text":null,"collapsed":false,"created_utc":1744745471,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8is4d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vibjelo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7xn3w","score":2,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; ollama is a thin wrapper over llama.cpp\\n\\nI think *used to* would be more correct. If I remember correctly, they've migrated to their own runner (made in Golang), and are no longer using llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8is4d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;ollama is a thin wrapper over llama.cpp&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I think &lt;em&gt;used to&lt;/em&gt; would be more correct. If I remember correctly, they&amp;#39;ve migrated to their own runner (made in Golang), and are no longer using llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8is4d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726352,"author_flair_text":null,"treatment_tags":[],"created_utc":1744726352,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":6,"name":"t1_mn8stri","id":"mn8stri","parent_id":"t1_mn7xn3w","depth":3,"children":["mn8stri"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7xn3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harrro","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7xd1p","score":114,"author_fullname":"t2_4axt7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes ollama is a thin wrapper over llama.cpp. Same with LMStudio and many other GUIs.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn7xn3w","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes ollama is a thin wrapper over llama.cpp. Same with LMStudio and many other GUIs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7xn3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718777,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1744718777,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":114}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mneo53d","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mneo53d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mnec54h","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mneo53d/","num_reports":null,"locked":false,"name":"t1_mneo53d","created":1744810729,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744810729,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mnec54h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1744806561,"send_replies":true,"parent_id":"t1_mne7r9i","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnec54h/","num_reports":null,"locked":false,"name":"t1_mnec54h","created":1744806561,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mne7r9i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mne6ohk","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mne7r9i/","num_reports":null,"locked":false,"name":"t1_mne7r9i","created":1744804799,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744804799,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mne6ohk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mne5qy1","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mne6ohk/","num_reports":null,"locked":false,"name":"t1_mne6ohk","created":1744804351,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744804351,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mne5qy1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1744803952,"send_replies":true,"parent_id":"t1_mndjkz6","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mne5qy1/","num_reports":null,"locked":false,"name":"t1_mne5qy1","created":1744803952,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mndjkz6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mndgd7n","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndjkz6/","num_reports":null,"locked":false,"name":"t1_mndjkz6","created":1744791447,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744791447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mndgd7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"qnixsynapse","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8ygpb","score":3,"author_fullname":"t2_x16oj02mp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What custom backend? I run gemma 3 vision with llama.cpp... it is not \\"production ready\\" atm but usable.\\n\\nThe text only gemma3 is perfectly usable with llama.cpp.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndgd7n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What custom backend? I run gemma 3 vision with llama.cpp... it is not &amp;quot;production ready&amp;quot; atm but usable.&lt;/p&gt;\\n\\n&lt;p&gt;The text only gemma3 is perfectly usable with llama.cpp.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndgd7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744789375,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744789375,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8ygpb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1744731103,"send_replies":true,"parent_id":"t1_mn7xd1p","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":1744791975,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8ygpb/","num_reports":null,"locked":false,"name":"t1_mn8ygpb","created":1744731103,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8mit1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Karyo_Ten","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8lbsj","score":31,"author_fullname":"t2_tbdqg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well posturing Twitter-driven development. It very relies on llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8mit1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well posturing Twitter-driven development. It very relies on llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8mit1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727508,"author_flair_text":null,"treatment_tags":[],"created_utc":1744727508,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8lbsj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"drodev","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7xd1p","score":-1,"author_fullname":"t2_i98zs5bf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"According to their last meetup, ollama no longer use llama.cpp\\n\\nhttps://preview.redd.it/1yalxifkd0ve1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=0096084a3387886fad53be7030d9df6be87412ff\\n\\n[https://x.com/pdev110/status/1863987159289737597?s=19](https://x.com/pdev110/status/1863987159289737597?s=19)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8lbsj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;According to their last meetup, ollama no longer use llama.cpp&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/1yalxifkd0ve1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0096084a3387886fad53be7030d9df6be87412ff\\"&gt;https://preview.redd.it/1yalxifkd0ve1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0096084a3387886fad53be7030d9df6be87412ff&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://x.com/pdev110/status/1863987159289737597?s=19\\"&gt;https://x.com/pdev110/status/1863987159289737597?s=19&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8lbsj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727144,"media_metadata":{"1yalxifkd0ve1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":211,"x":108,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03ec0bd2c083dfe361589b95c8f61ea3ebc2229a"},{"y":423,"x":216,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4339de7bcdd524c75018fec63a5b8e6644589c68"},{"y":626,"x":320,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=db461e6f41d21e8030fce417e968051be324960b"},{"y":1253,"x":640,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4c06374dead388840557b75cc0f0729f8b1dcc2b"},{"y":1880,"x":960,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a0c97811f84f4d0d39ee1c2997ffd725e803bcc"},{"y":2115,"x":1080,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9272306c9d133450c9b446a44fb9d24c884ca6ad"}],"s":{"y":2115,"x":1080,"u":"https://preview.redd.it/1yalxifkd0ve1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=0096084a3387886fad53be7030d9df6be87412ff"},"id":"1yalxifkd0ve1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1744727144,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7xd1p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"night0x63","can_mod_post":false,"created_utc":1744718661,"send_replies":true,"parent_id":"t1_mn7m5el","score":33,"author_fullname":"t2_3h2irqtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does Ollama use llama.cpp under the hood?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7xd1p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does Ollama use llama.cpp under the hood?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7xd1p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718661,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mncpzk1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"visarga","can_mod_post":false,"created_utc":1744775213,"send_replies":true,"parent_id":"t1_mn7m5el","score":0,"author_fullname":"t2_vxvm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; ollama = corporate \\"open source\\"\\n\\nDoes ollama get corporate usage? It doesn't implement dynamic batching","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mncpzk1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;ollama = corporate &amp;quot;open source&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Does ollama get corporate usage? It doesn&amp;#39;t implement dynamic batching&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mncpzk1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744775213,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndztkf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-lq_pl-","can_mod_post":false,"created_utc":1744801211,"send_replies":true,"parent_id":"t1_mn7m5el","score":1,"author_fullname":"t2_16rvbe","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not only that, it is also the typical divide between tech- and marketing-oriented people. Ollama, being free from providing actual technical solutions, can spend all their energy on fluff and marketing, and schmoozing up to corpos.\\n\\nI bet ggerganov and his core team are introverted nerds that only care about solving engineering problems and hate spending time on marketing.\\n\\nWhat I hate most about ollama is that they made up their own incompatible way of storing gguf models for no good reason, so that you cannot easily switch between ollama and anyone else without re-downloading the models. That's an attempt at vendor lock-in.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndztkf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not only that, it is also the typical divide between tech- and marketing-oriented people. Ollama, being free from providing actual technical solutions, can spend all their energy on fluff and marketing, and schmoozing up to corpos.&lt;/p&gt;\\n\\n&lt;p&gt;I bet ggerganov and his core team are introverted nerds that only care about solving engineering problems and hate spending time on marketing.&lt;/p&gt;\\n\\n&lt;p&gt;What I hate most about ollama is that they made up their own incompatible way of storing gguf models for no good reason, so that you cannot easily switch between ollama and anyone else without re-downloading the models. That&amp;#39;s an attempt at vendor lock-in.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndztkf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744801211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":3,"name":"t1_mna0krc","id":"mna0krc","parent_id":"t1_mn7m5el","depth":1,"children":["mna0krc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7m5el","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoffKalast","can_mod_post":false,"created_utc":1744713370,"send_replies":true,"parent_id":"t3_1jzocoo","score":353,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama.cpp = open source community effort\\n\\nollama = corporate \\"open source\\" that's mostly open to tap into additional free labour and get positive marketing\\n\\nCorpos recognize other corpos, everything else is dead to them. It's always been this way.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7m5el","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama.cpp = open source community effort&lt;/p&gt;\\n\\n&lt;p&gt;ollama = corporate &amp;quot;open source&amp;quot; that&amp;#39;s mostly open to tap into additional free labour and get positive marketing&lt;/p&gt;\\n\\n&lt;p&gt;Corpos recognize other corpos, everything else is dead to them. It&amp;#39;s always been this way.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7m5el/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744713370,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":353}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9r96v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"henfiber","can_mod_post":false,"created_utc":1744739571,"send_replies":true,"parent_id":"t3_1jzocoo","score":32,"author_fullname":"t2_lw9me25","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The thing about ollama that annoys me the most is that they do not provide attribution:\\n\\nhttps://github.com/ollama/ollama/issues/3185 \\n\\nThat's why no one knows they use llama.cpp under the hood. \\n\\nThey even use llama-server (at least the last time I looked at the code), not only the main engine.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9r96v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The thing about ollama that annoys me the most is that they do not provide attribution:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ollama/ollama/issues/3185\\"&gt;https://github.com/ollama/ollama/issues/3185&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;p&gt;That&amp;#39;s why no one knows they use llama.cpp under the hood. &lt;/p&gt;\\n\\n&lt;p&gt;They even use llama-server (at least the last time I looked at the code), not only the main engine.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9r96v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744739571,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8ogqp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vibjelo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8o8um","score":3,"author_fullname":"t2_hr2hgnsk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, that sounds likely too :) That's why I started my first message with \\"who is willing to volunteer their time\\" as that's the biggest factor.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mn8ogqp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, that sounds likely too :) That&amp;#39;s why I started my first message with &amp;quot;who is willing to volunteer their time&amp;quot; as that&amp;#39;s the biggest factor.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8ogqp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728098,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728098,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8o8um","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8mxdu","score":4,"author_fullname":"t2_fxk6v95z","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It seems more plausible to me that ollama is packaged simply because it is more popular.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mn8o8um","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems more plausible to me that ollama is packaged simply because it is more popular.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8o8um/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728031,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728031,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8mxdu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vibjelo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8m6s8","score":4,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, since we cannot say for sure if those people were paid or not by Ollama, you post is as much speculation as mine :)\\n\\nI think people who never worked professionally in FOSS would be surprised how many companies are paying developers as \\"freelancers\\" to make contributions to their projects, without mentioning that they're financed by said projects.","edited":false,"author_flair_css_class":null,"name":"t1_mn8mxdu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, since we cannot say for sure if those people were paid or not by Ollama, you post is as much speculation as mine :)&lt;/p&gt;\\n\\n&lt;p&gt;I think people who never worked professionally in FOSS would be surprised how many companies are paying developers as &amp;quot;freelancers&amp;quot; to make contributions to their projects, without mentioning that they&amp;#39;re financed by said projects.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8mxdu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727631,"author_flair_text":null,"collapsed":false,"created_utc":1744727631,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8m6s8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8jq29","score":11,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is a weird thing to speculate about. [You know the package maintainers are public right?](https://archlinux.org/packages/extra/x86_64/ollama/) I don't think either of those guys work for ollama, unless you know something about them I don't. It's probably not packaged because most people using it are building it from source.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8m6s8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a weird thing to speculate about. &lt;a href=\\"https://archlinux.org/packages/extra/x86_64/ollama/\\"&gt;You know the package maintainers are public right?&lt;/a&gt; I don&amp;#39;t think either of those guys work for ollama, unless you know something about them I don&amp;#39;t. It&amp;#39;s probably not packaged because most people using it are building it from source.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8m6s8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727407,"author_flair_text":null,"treatment_tags":[],"created_utc":1744727407,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn93lgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"finah1995","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8jq29","score":1,"author_fullname":"t2_85iwkad9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean even on windows, cloning git repo of llama.cpp and setting up cuda and compiling with Visual studio 2022 is like a breeze, it's lot easier to get it running, even easier deployment from source to build, than some python packages lol, which have lot of dependency. So people who are using Arch and building the full Linux tooling from scratch it will be a walk in the park for them to do it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn93lgv","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean even on windows, cloning git repo of llama.cpp and setting up cuda and compiling with Visual studio 2022 is like a breeze, it&amp;#39;s lot easier to get it running, even easier deployment from source to build, than some python packages lol, which have lot of dependency. So people who are using Arch and building the full Linux tooling from scratch it will be a walk in the park for them to do it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn93lgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744732621,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744732621,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8jq29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vibjelo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7p1if","score":3,"author_fullname":"t2_hr2hgnsk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Usually packaging things like that come down to who is willing to volunteer their time. For Ollama, since they're a business who want to do marketing, probably have a easy time justifying one person spending some hours for each release, to maintain the package for Arch.\\n\\nBut for llama.cpp which doesn't have a for-profit business behind it, it entirely relies on volunteers with knowledge to contribute their time and expertise. Even without a \\"stable release process\\" (which I'd argue is something else than \\"release frequency\\", it could be available in the Arch repositories, granted someone takes the time to create and maintain the package.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8jq29","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Usually packaging things like that come down to who is willing to volunteer their time. For Ollama, since they&amp;#39;re a business who want to do marketing, probably have a easy time justifying one person spending some hours for each release, to maintain the package for Arch.&lt;/p&gt;\\n\\n&lt;p&gt;But for llama.cpp which doesn&amp;#39;t have a for-profit business behind it, it entirely relies on volunteers with knowledge to contribute their time and expertise. Even without a &amp;quot;stable release process&amp;quot; (which I&amp;#39;d argue is something else than &amp;quot;release frequency&amp;quot;, it could be available in the Arch repositories, granted someone takes the time to create and maintain the package.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8jq29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726649,"author_flair_text":null,"treatment_tags":[],"created_utc":1744726649,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7p1if","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"smahs9","can_mod_post":false,"created_utc":1744714893,"send_replies":true,"parent_id":"t1_mn7mq9x","score":41,"author_fullname":"t2_neyagc1uz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its worse actually in some regards. llama.cpp is not even there in most linux distro repos. Even arch doesn't ship it in extra, but it does ship ollama. I guess it partly has to be do with llama.cpp not having a stable release process (building multiple times a day just increases the cost for distro maintainers). Otoh the whitepaper from intel on using vnni on CPUs for inference featured llama.cpp and gguf optimizations. So I guess who's your audience matters.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7p1if","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its worse actually in some regards. llama.cpp is not even there in most linux distro repos. Even arch doesn&amp;#39;t ship it in extra, but it does ship ollama. I guess it partly has to be do with llama.cpp not having a stable release process (building multiple times a day just increases the cost for distro maintainers). Otoh the whitepaper from intel on using vnni on CPUs for inference featured llama.cpp and gguf optimizations. So I guess who&amp;#39;s your audience matters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7p1if/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714893,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn85em5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"alberto_467","can_mod_post":false,"created_utc":1744721786,"send_replies":true,"parent_id":"t1_mn7mq9x","score":22,"author_fullname":"t2_twthd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;it is unfair that ollama got more popular due to being beginner friendly\\n\\nWell you can't blame beginners for choosing and hyping the beginner friendly project. And there are a lot of beginners.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn85em5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;it is unfair that ollama got more popular due to being beginner friendly&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Well you can&amp;#39;t blame beginners for choosing and hyping the beginner friendly project. And there are a lot of beginners.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn85em5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744721786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mo95i8r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"regression-io","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8pfgy","score":1,"author_fullname":"t2_v83ico5c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a virus.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mo95i8r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a virus.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mo95i8r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745242336,"author_flair_text":null,"treatment_tags":[],"created_utc":1745242336,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8pfgy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fullouterjoin","can_mod_post":false,"created_utc":1744728386,"send_replies":true,"parent_id":"t1_mn7mq9x","score":20,"author_fullname":"t2_406sj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ollama is wget in a trench coat.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8pfgy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama is wget in a trench coat.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8pfgy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728386,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbm52p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sidran","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8c721","score":4,"author_fullname":"t2_3t79h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LOLlama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnbm52p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LOLlama?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbm52p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744760480,"author_flair_text":null,"treatment_tags":[],"created_utc":1744760480,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mncvb55","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8c721","score":1,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nollama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mncvb55","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nollama&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mncvb55/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744777604,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744777604,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8c721","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JoMa4","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7tea8","score":23,"author_fullname":"t2_73gx0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They should create a wrapper over Ollama and continue the circle of life. Just call it Oollama.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8c721","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They should create a wrapper over Ollama and continue the circle of life. Just call it Oollama.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8c721/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744724194,"author_flair_text":null,"treatment_tags":[],"created_utc":1744724194,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5c2a2958-309b-11ee-9109-22869f0a11dc","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mna78gj","id":"mna78gj","parent_id":"t1_mn9vvkh","depth":3,"children":["mna78gj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn9vvkh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"candre23","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7tea8","score":9,"author_fullname":"t2_4wc8s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[It already exists.](https://github.com/LostRuins/koboldcpp)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn9vvkh","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/LostRuins/koboldcpp\\"&gt;It already exists.&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9vvkh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744740956,"author_flair_text":"koboldcpp","treatment_tags":[],"created_utc":1744740956,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8v3an","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"The_frozen_one","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8r7z1","score":8,"author_fullname":"t2_5rvpo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Vision support was released in ollama for gemma 3 before llama.cpp. With ollama it was part of their standard binary, with llama.cpp it is a separate test binary (\`llama-gemma3-cli\`).","edited":false,"author_flair_css_class":null,"name":"t1_mn8v3an","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Vision support was released in ollama for gemma 3 before llama.cpp. With ollama it was part of their standard binary, with llama.cpp it is a separate test binary (&lt;code&gt;llama-gemma3-cli&lt;/code&gt;).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8v3an/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744730090,"author_flair_text":null,"collapsed":false,"created_utc":1744730090,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8wbw2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8r7z1","score":4,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Even if this were true (which it arguably isn't; ollama's fork has features llama.cpp upstream does not) I don't think ggerganov has time to develop the kind of ecosystem of tooling that downstream users like ollama provide. It's a question of specialization. I'd rather have llama.cpp focus on doing what it does best: being a llm runtime. Other projects can handle making it easy to use, providing more refined APIs and administration tools for web, etc.","edited":false,"author_flair_css_class":null,"name":"t1_mn8wbw2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Even if this were true (which it arguably isn&amp;#39;t; ollama&amp;#39;s fork has features llama.cpp upstream does not) I don&amp;#39;t think ggerganov has time to develop the kind of ecosystem of tooling that downstream users like ollama provide. It&amp;#39;s a question of specialization. I&amp;#39;d rather have llama.cpp focus on doing what it does best: being a llm runtime. Other projects can handle making it easy to use, providing more refined APIs and administration tools for web, etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8wbw2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744730464,"author_flair_text":null,"collapsed":false,"created_utc":1744730464,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8r7z1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8eupi","score":10,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I disagree. Ollama lags behind llama.cpp. If llama.cpp built a framework in to make it more accessible, ollama could go the way of the dodo because you get the latest model support and it is easy to use.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8r7z1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I disagree. Ollama lags behind llama.cpp. If llama.cpp built a framework in to make it more accessible, ollama could go the way of the dodo because you get the latest model support and it is easy to use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8r7z1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728927,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728927,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8mn5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8lgwd","score":1,"author_fullname":"t2_fxk6v95z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, sorry I guess I don't get it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mn8mn5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, sorry I guess I don&amp;#39;t get it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8mn5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727545,"author_flair_text":null,"treatment_tags":[],"created_utc":1744727545,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8lgwd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8kpl4","score":1,"author_fullname":"t2_fzqff6k3","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It was a joke, a bad one apparently.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mn8lgwd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It was a joke, a bad one apparently.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8lgwd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727189,"author_flair_text":null,"treatment_tags":[],"created_utc":1744727189,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8kpl4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8fb45","score":5,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a bit childish. It's MIT licensed software. Using it as part of a larger package doesn't intrinsically give it more \\"credit\\" than using it directly, or as part of an alternative larger package.","edited":false,"author_flair_css_class":null,"name":"t1_mn8kpl4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a bit childish. It&amp;#39;s MIT licensed software. Using it as part of a larger package doesn&amp;#39;t intrinsically give it more &amp;quot;credit&amp;quot; than using it directly, or as part of an alternative larger package.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8kpl4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744726955,"author_flair_text":null,"collapsed":false,"created_utc":1744726955,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8fb45","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8eupi","score":1,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To give enough credit to llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8fb45","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To give enough credit to llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8fb45/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744725225,"author_flair_text":null,"treatment_tags":[],"created_utc":1744725225,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8eupi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7tea8","score":2,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why would you? Making llama.cpp user friendly just means reinventing ollama.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8eupi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would you? Making llama.cpp user friendly just means reinventing ollama.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8eupi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744725078,"author_flair_text":null,"treatment_tags":[],"created_utc":1744725078,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mo95m93","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"regression-io","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7tea8","score":1,"author_fullname":"t2_v83ico5c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LM Studio","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mo95m93","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LM Studio&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mo95m93/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745242376,"author_flair_text":null,"treatment_tags":[],"created_utc":1745242376,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7tea8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__Maximum__","can_mod_post":false,"created_utc":1744716961,"send_replies":true,"parent_id":"t1_mn7mq9x","score":11,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How hard is it to make llama.cpp user friendly? Or make alternative to ollama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7tea8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How hard is it to make llama.cpp user friendly? Or make alternative to ollama?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7tea8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744716961,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9y84r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zyansheep","can_mod_post":false,"created_utc":1744741664,"send_replies":true,"parent_id":"t1_mn7mq9x","score":1,"author_fullname":"t2_e757sg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't forget the corejs fiasco a couple of years ago...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9y84r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t forget the corejs fiasco a couple of years ago...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9y84r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744741664,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":2,"name":"t1_mn9afnx","id":"mn9afnx","parent_id":"t1_mn7mq9x","depth":1,"children":["mn9afnx"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7mq9x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nrkishere","can_mod_post":false,"created_utc":1744713689,"send_replies":true,"parent_id":"t3_1jzocoo","score":153,"author_fullname":"t2_o66k4w0to","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've read the codebase of ollama. It is not a very complex application. llama.cpp, like any other runtimes is significantly more complex, also the fact that it is C++. So it is unfair that ollama got more popular due to being beginner friendly\\n\\nBut unfortunately, this is true for most other open source projects. Like how many you or companies acknowledged OpenSSL, which powers close to 100% of web servers? or how about Eigen, XNNPACK etc? Softwares are abstraction over abstraction over abstraction, and attention is mostly gained only by the popular ones. It is unfair, but harsh truth :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7mq9x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve read the codebase of ollama. It is not a very complex application. llama.cpp, like any other runtimes is significantly more complex, also the fact that it is C++. So it is unfair that ollama got more popular due to being beginner friendly&lt;/p&gt;\\n\\n&lt;p&gt;But unfortunately, this is true for most other open source projects. Like how many you or companies acknowledged OpenSSL, which powers close to 100% of web servers? or how about Eigen, XNNPACK etc? Softwares are abstraction over abstraction over abstraction, and attention is mostly gained only by the popular ones. It is unfair, but harsh truth :(&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7mq9x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744713689,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":153}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn97e0r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dampflokfreund","can_mod_post":false,"created_utc":1744733794,"send_replies":true,"parent_id":"t3_1jzocoo","score":10,"author_fullname":"t2_lis7z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, it's not fair at all. We must remember GGerganov, Johannes and Slaren, and all the others who made this posssible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn97e0r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, it&amp;#39;s not fair at all. We must remember GGerganov, Johannes and Slaren, and all the others who made this posssible.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn97e0r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744733794,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mna42om","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1744743428,"send_replies":true,"parent_id":"t1_mn7pngo","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"It uses indexed db nowadays, I assume they were afraid of running out of storage for power users...","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It uses indexed db nowadays, I assume they were afraid of running out of storage for power users...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mna42om/","num_reports":null,"locked":false,"name":"t1_mna42om","created":1744743428,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7pngo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"smahs9","can_mod_post":false,"created_utc":1744715198,"send_replies":true,"parent_id":"t1_mn7n96m","score":35,"author_fullname":"t2_neyagc1uz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And it even has a very decent frontend with local storage. You can even test extended features beyond the standard openai API like ebnf grammar.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7pngo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And it even has a very decent frontend with local storage. You can even test extended features beyond the standard openai API like ebnf grammar.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7pngo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715198,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7w8bh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Qual_","can_mod_post":false,"created_utc":1744718188,"send_replies":true,"parent_id":"t1_mn7n96m","score":53,"author_fullname":"t2_c3ca7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"llama.cpp shoot themselves in the feet when they stopped supporting multimodal models tho'","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7w8bh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama.cpp shoot themselves in the feet when they stopped supporting multimodal models tho&amp;#39;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7w8bh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718188,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn87ku6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kingduj","can_mod_post":false,"created_utc":1744722577,"send_replies":true,"parent_id":"t1_mn7n96m","score":8,"author_fullname":"t2_2d1qrdk0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And it's faster! ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn87ku6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And it&amp;#39;s faster! &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn87ku6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744722577,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn96cal","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MINIMAN10001","can_mod_post":false,"created_utc":1744733463,"send_replies":true,"parent_id":"t1_mn7n96m","score":13,"author_fullname":"t2_15mrcb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wanted to try Ollama because it was all the rage.\\n\\n\\nWell the experience kinda sucked. I couldn't just load up any gguf file it wanted to covert them.\\n\\n\\nI couldn't just run any old mmproj file, I could only get it to work if I used their quants in their library which meant no imatrix to reduce RAM. \\n\\n\\nThe heck is the point of Ollama with such a limited list of what sizes and no matrix quants and their proprietary formats.\\n\\n\\nI just ended up using kobold.cpp for gemma3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn96cal","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wanted to try Ollama because it was all the rage.&lt;/p&gt;\\n\\n&lt;p&gt;Well the experience kinda sucked. I couldn&amp;#39;t just load up any gguf file it wanted to covert them.&lt;/p&gt;\\n\\n&lt;p&gt;I couldn&amp;#39;t just run any old mmproj file, I could only get it to work if I used their quants in their library which meant no imatrix to reduce RAM. &lt;/p&gt;\\n\\n&lt;p&gt;The heck is the point of Ollama with such a limited list of what sizes and no matrix quants and their proprietary formats.&lt;/p&gt;\\n\\n&lt;p&gt;I just ended up using kobold.cpp for gemma3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn96cal/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744733463,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbixbp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robberviet","can_mod_post":false,"send_replies":true,"parent_id":"t1_mnbbgha","score":1,"author_fullname":"t2_jxc5a","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's on k8s so I don't want to do all that. No helm, have to build image, open pod shell... On local it's fine, used to do that too, but now I use lmstudio, easier to use &amp; have mlx.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mnbixbp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s on k8s so I don&amp;#39;t want to do all that. No helm, have to build image, open pod shell... On local it&amp;#39;s fine, used to do that too, but now I use lmstudio, easier to use &amp;amp; have mlx.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbixbp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744759384,"author_flair_text":null,"treatment_tags":[],"created_utc":1744759384,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbl5a9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_mnbbgha","score":1,"author_fullname":"t2_559a1","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; All through python scripts...\\n\\nYep, you found the problem. You have a whole lot more of the wheel to reinvent to catch up to where Ollama is on this front or at least llama-swap. It's a silly situation but this small thing you can sort of create by hand in a day or a few is an insurmountable hill for most that divides Ollama from llama.cpp. It unfortunately makes a lot of sense the situation is what it is.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mnbl5a9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;All through python scripts...&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yep, you found the problem. You have a whole lot more of the wheel to reinvent to catch up to where Ollama is on this front or at least llama-swap. It&amp;#39;s a silly situation but this small thing you can sort of create by hand in a day or a few is an insurmountable hill for most that divides Ollama from llama.cpp. It unfortunately makes a lot of sense the situation is what it is.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbl5a9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744760135,"author_flair_text":null,"treatment_tags":[],"created_utc":1744760135,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mnbbgha","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Escroto_de_morsa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8dthd","score":3,"author_fullname":"t2_vk630bo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can say that I am quite new to this and I use llama.cpp and openwebui without any problems with several models. All through python scripts... a folder for the models I download and a CLI command and in a few seconds I have everything ready.","edited":false,"author_flair_css_class":null,"name":"t1_mnbbgha","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can say that I am quite new to this and I use llama.cpp and openwebui without any problems with several models. All through python scripts... a folder for the models I download and a CLI command and in a few seconds I have everything ready.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbbgha/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744756858,"author_flair_text":null,"collapsed":false,"created_utc":1744756858,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8dthd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robberviet","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn89ixe","score":10,"author_fullname":"t2_jxc5a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Packaging, serving multiple models, downloading models. \\nGetting done with single model is ok. But doing that for multi to test is quite troublesome.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8dthd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Packaging, serving multiple models, downloading models. \\nGetting done with single model is ok. But doing that for multi to test is quite troublesome.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8dthd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744724739,"author_flair_text":null,"treatment_tags":[],"created_utc":1744724739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mn89ixe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Far_Buyer_7281","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn80mnw","score":2,"author_fullname":"t2_vyvxdjqyp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what was the exact problem with llama? finding the right ngl?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn89ixe","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what was the exact problem with llama? finding the right ngl?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn89ixe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723268,"author_flair_text":null,"treatment_tags":[],"created_utc":1744723268,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mn80mnw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robberviet","can_mod_post":false,"created_utc":1744719973,"send_replies":true,"parent_id":"t1_mn7n96m","score":21,"author_fullname":"t2_jxc5a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hate it sometime, but using ollama in some situation is still much easier and more widely supported. I am deploying OpenWebUI on k8s, tried llama.cpp but quite a problem, so I used ollama out of the box.\\n\\nMultimodality is yeah, just bad.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn80mnw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hate it sometime, but using ollama in some situation is still much easier and more widely supported. I am deploying OpenWebUI on k8s, tried llama.cpp but quite a problem, so I used ollama out of the box.&lt;/p&gt;\\n\\n&lt;p&gt;Multimodality is yeah, just bad.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn80mnw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719973,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7vxly","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hoodfu","can_mod_post":false,"created_utc":1744718063,"send_replies":true,"parent_id":"t1_mn7n96m","score":10,"author_fullname":"t2_dnq0h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Does it support vision models like Ollama does?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7vxly","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does it support vision models like Ollama does?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7vxly/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718063,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnd9xgs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sudden-Lingonberry-8","can_mod_post":false,"created_utc":1744785349,"send_replies":true,"parent_id":"t1_mn7n96m","score":1,"author_fullname":"t2_7j2k5hlp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can You connect to ollama repository to pull weights and use llama.cpp?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnd9xgs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can You connect to ollama repository to pull weights and use llama.cpp?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnd9xgs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744785349,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndmndn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"trololololo2137","can_mod_post":false,"created_utc":1744793464,"send_replies":true,"parent_id":"t1_mn7n96m","score":0,"author_fullname":"t2_129mr2pstm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"why would i stop using ollama if it's easier and works just fine?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndmndn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;why would i stop using ollama if it&amp;#39;s easier and works just fine?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndmndn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744793464,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"more","data":{"count":1,"name":"t1_mn7yysb","id":"mn7yysb","parent_id":"t1_mn7n96m","depth":1,"children":["mn7yysb"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7n96m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffeine_Monster","can_mod_post":false,"created_utc":1744713970,"send_replies":true,"parent_id":"t3_1jzocoo","score":129,"author_fullname":"t2_hg9yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hot take: stop using ollama\\n\\nllama.cpp has a web server with a standardised interface.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7n96m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hot take: stop using ollama&lt;/p&gt;\\n\\n&lt;p&gt;llama.cpp has a web server with a standardised interface.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7n96m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744713970,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":129}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7q73g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7pm6p","score":5,"author_fullname":"t2_4gc7hf3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think your explanation is more likely to be accurate. I didn't know the leading llama.cpp dev is from EU.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7q73g","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think your explanation is more likely to be accurate. I didn&amp;#39;t know the leading llama.cpp dev is from EU.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7q73g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715465,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744715465,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7pm6p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brown2green","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7p0tj","score":21,"author_fullname":"t2_f010l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As a side note (although I'm not claiming this is the reason or whether it actually had any impact), Meta doesn't allow European users to use Vision-enabled models, and the leading llama.cpp developer is from Bulgaria. He couldn't personally develop and test Llama Vision capabilities without breaking Meta's TOS.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn7pm6p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As a side note (although I&amp;#39;m not claiming this is the reason or whether it actually had any impact), Meta doesn&amp;#39;t allow European users to use Vision-enabled models, and the leading llama.cpp developer is from Bulgaria. He couldn&amp;#39;t personally develop and test Llama Vision capabilities without breaking Meta&amp;#39;s TOS.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7pm6p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715180,"author_flair_text":null,"treatment_tags":[],"created_utc":1744715180,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7p0tj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1744714883,"send_replies":true,"parent_id":"t1_mn7ltg7","score":23,"author_fullname":"t2_4gc7hf3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are right, Meta AI decides to partner with ollama after llama3.2, at the time llama.cpp team don't want to work on new vision models. Therefore, Ollama is the first local inference engine to implement their own support for llama3.2 vision, most likely with the help of meta ai.\\n\\n\\nBut I do agree they should mention llama.cpp, they are basically the foundation of local LLM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7p0tj","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are right, Meta AI decides to partner with ollama after llama3.2, at the time llama.cpp team don&amp;#39;t want to work on new vision models. Therefore, Ollama is the first local inference engine to implement their own support for llama3.2 vision, most likely with the help of meta ai.&lt;/p&gt;\\n\\n&lt;p&gt;But I do agree they should mention llama.cpp, they are basically the foundation of local LLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7p0tj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714883,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7ltg7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1744713183,"send_replies":true,"parent_id":"t3_1jzocoo","score":48,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It mentions \\"partners\\", that's a bit more specific than if they meant to list every platform their models work on. Perhaps Ollama guys are their official partners and llamacpp guys are not? Just a guess. 🤷‍♂️","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7ltg7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It mentions &amp;quot;partners&amp;quot;, that&amp;#39;s a bit more specific than if they meant to list every platform their models work on. Perhaps Ollama guys are their official partners and llamacpp guys are not? Just a guess. 🤷‍♂️&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7ltg7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744713183,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":48}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7yxl0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Everlier","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7v5p3","score":5,"author_fullname":"t2_o7p5m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mostly at the LLM/AI integration level - experience with relevant frameworks/libs, APIs. Sometimes a little bit of traditional ML experience. I can't say that I have a very large sample pool: 12 interviews thus far for this specific position - only one person runned Ollama locally and heard abour vllm, two more heard about Ollama, others only ever used LLMs via platform providers (Bedrock/GenAI Studio/Azure).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn7yxl0","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mostly at the LLM/AI integration level - experience with relevant frameworks/libs, APIs. Sometimes a little bit of traditional ML experience. I can&amp;#39;t say that I have a very large sample pool: 12 interviews thus far for this specific position - only one person runned Ollama locally and heard abour vllm, two more heard about Ollama, others only ever used LLMs via platform providers (Bedrock/GenAI Studio/Azure).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7yxl0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719302,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1744719302,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7v5p3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"5jane","can_mod_post":false,"created_utc":1744717734,"send_replies":true,"parent_id":"t1_mn7p263","score":15,"author_fullname":"t2_4c01etji","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; interviewing people for GenAI positions - they often didn't ever run LLMs on their own\\n\\nwhat is this i dont even \\n\\nsrsly, what's their qualification then? are you interviewing right now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7v5p3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;interviewing people for GenAI positions - they often didn&amp;#39;t ever run LLMs on their own&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;what is this i dont even &lt;/p&gt;\\n\\n&lt;p&gt;srsly, what&amp;#39;s their qualification then? are you interviewing right now?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7v5p3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744717734,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7p263","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Everlier","can_mod_post":false,"created_utc":1744714902,"send_replies":true,"parent_id":"t3_1jzocoo","score":45,"author_fullname":"t2_o7p5m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'd say we live in a bit of a bubble. \\n\\nFor us - llama.cpp is the undeniable legendary-level project that kicked off the whole \\"We have LLM at home\\" adventure. It's very personal. However, interviewing people for GenAI positions - they often didn't ever run LLMs on their own, at best heard about a few inference engines. Ollama made it pretty much effortless to run LLMs on consumer-level hardware. So, while llama.cpp makes things possible - Ollama makes them accessible. \\n\\nThis pattern is also very common in software in general:\\n\\n* v8 vs Node.js\\n* Blink vs Chrome (and all Chromium-based browsers)\\n* Linux Kernel vs Ubuntu/Fedora\\n* OpenGL vs Unity\\n\\nThat said, Meta not acknowledging llama.cpp - the core reason there's a community of enthusiasts around their LLMs - is weird.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7p263","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d say we live in a bit of a bubble. &lt;/p&gt;\\n\\n&lt;p&gt;For us - llama.cpp is the undeniable legendary-level project that kicked off the whole &amp;quot;We have LLM at home&amp;quot; adventure. It&amp;#39;s very personal. However, interviewing people for GenAI positions - they often didn&amp;#39;t ever run LLMs on their own, at best heard about a few inference engines. Ollama made it pretty much effortless to run LLMs on consumer-level hardware. So, while llama.cpp makes things possible - Ollama makes them accessible. &lt;/p&gt;\\n\\n&lt;p&gt;This pattern is also very common in software in general:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;v8 vs Node.js&lt;/li&gt;\\n&lt;li&gt;Blink vs Chrome (and all Chromium-based browsers)&lt;/li&gt;\\n&lt;li&gt;Linux Kernel vs Ubuntu/Fedora&lt;/li&gt;\\n&lt;li&gt;OpenGL vs Unity&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;That said, Meta not acknowledging llama.cpp - the core reason there&amp;#39;s a community of enthusiasts around their LLMs - is weird.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7p263/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714902,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":45}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5e607f92-4428-11ee-be78-faa6ca8ae2cf","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnceq6q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"qnixsynapse","can_mod_post":false,"created_utc":1744770706,"send_replies":true,"parent_id":"t1_mn8748n","score":4,"author_fullname":"t2_x16oj02mp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"haha! It has to wait for llama.cpp to support it. /s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnceq6q","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;haha! It has to wait for llama.cpp to support it. /s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnceq6q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744770706,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8748n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vaibhavs10","can_mod_post":false,"created_utc":1744722412,"send_replies":true,"parent_id":"t3_1jzocoo","score":11,"author_fullname":"t2_yg4dl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wait, but does ollama even support llama 4? [https://github.com/ollama/ollama/issues/10143](https://github.com/ollama/ollama/issues/10143)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8748n","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Hugging Face Staff"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wait, but does ollama even support llama 4? &lt;a href=\\"https://github.com/ollama/ollama/issues/10143\\"&gt;https://github.com/ollama/ollama/issues/10143&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8748n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744722412,"author_flair_text":"Hugging Face Staff","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#5a74cc","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8sieh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vertigo235","can_mod_post":false,"created_utc":1744729310,"send_replies":true,"parent_id":"t3_1jzocoo","score":10,"author_fullname":"t2_812in","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Life is full of unfair situations\\n\\nCheers to ggerganov!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8sieh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Life is full of unfair situations&lt;/p&gt;\\n\\n&lt;p&gt;Cheers to ggerganov!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8sieh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744729310,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9lwqr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StewedAngelSkins","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn9bcty","score":2,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama.cpp is open, but this is kind of a category error. Gguf is not a registry/distribution spec, it's a file format. And ollama's package spec uses this file format.\\n\\n\\n&gt;You could host GGUFs on a plain \\"directory index\\" Apache server and use those on llama.cpp easily.\\n\\n\\n\\nSort of. I mean, you could roll a bunch of your own scripting that does what ollama's package/distribution tooling does... or you could use ollama's package format.\\n\\n\\n&gt;I'm actually not sure what you mean by Ollama being particularly \\"rugpull-resistant.\\"\\n\\n\\nI probably didn't explain it well. To be clear, I'm talking specifically about ollama's package management. I don't have strong opinions either way on the rest of the project.\\n\\n\\nThe typical open source enshittification pipeline involves developing a tool or service, releasing it (and/or ecosystem tooling) as open source software to build a community, then rugging that community by spinning off a proprietary version of the software that has some key premium features your users need. \\"Ollama the corporation\\" could certainly do this with \\"ollama the application\\". No question there. What I'm saying is that *if* they did this, everyone could still keep using their package format like nothing happened, because their package format is a trivial extension of an otherwise open and widely supported spec. (More on this below.)\\n\\n\\n\\n&gt;It feels like Ollama unnecessarily complicates things and obfuscates what is going on. Model folder names being hashes...\\n\\n\\nI can see why you would have this impression, but perhaps you aren't familiar with the technical details of the OCI image/distribution specs? To be fair, most people aren't, and maybe that's some kind of point against it, but the fact of the matter is none of what you're seeing is proprietary and there are in fact completely unaffiliated tools you can pull off the shelf right now that can make sense of those hashes.\\n\\n\\nLet me explain what an ollama package actually is. Apologies if you already know, I just want to make sure we're on the same page. The OCI image spec defines a json \\"manifest\\" schema, which is what actually gets downloaded first when you run \`ollama pull\` (or, in fact, \`docker pull\`). For our purposes, all you need to know is it contains two key elements: a list of hashes corresponding to binary \\"blobs\\" (gguf models, docker image layers... it's arbitrary) and a config object which is meant to be used by client tools to store data that isn't part of the generic spec. Docker clients use this config object to define stuff like what user id the container should be run as, how the layers should be put together at runtime, the entrypoint script, what ports to expose, etc.\\n\\n\\nOllama uses the manifest config object to define model parameters. **This is the only ollama-specific part of the package format: a 10 line json object.** Everything else... the rest of the package format, the registry API, how things are stored in local directories... is bone stock OCI. What this means is if you needed to reinvent a client for retrieving ollama's packages completely from scratch, all you would have to do is pick any off the shelf OCI client library (there are dozens of them, in most languages you'd care about) and write a function to parse 10 lines of json after it retrieves the manifest for you.\\n\\n\\nThe story only gets better when you consider the server side. An ollama model registry is *literally* just a standard OCI registry. Your path from literally nothing to replacing ollama (as far as model distribution is concerned) is \`docker run registry\`.\\n\\n\\nMaybe you can tell me what it would take to replace all of this functionality, were you to standardize on the huggingface client instead. I don't actually know, but my assumption was that it would at the very least involve hand writing a bunch of methods that know how to talk to their REST API.\\n\\n\\n\\nI'm actually of the strong opinion that ollama's package spec is the best way to store and distribute models *even if you are not using ollama* because it is such a simple extension of an existing well-established standard. You get so much useful functionality for free... versioning via OCI tags, metadata/annotations, off the shelf server and client software...\\n\\n\\n&gt;With llama.cpp I know that I'm running a build that can do CUDA, or Vulkan, or ROCm etc, and I can just pass the damn GGUF file with n context and n offloaded layers.\\n\\n\\nI don't really mean this to be an ollama vs llama.cpp thing. In my view they aren't particularly in the same category. There's some overlap, but it's generally pretty obvious which one you should use in a serious project. We tinkerers just happen to be in that small sliver of overlap where you could justifiably use either. It sounds like in your use case ollama's main feature (the excellent package format) is irrelevant to you, so it's not surprising you wouldn't use it. I don't actually use it much either, because I'm developing software that builds directly on llama.cpp. That said, if I end up needing some way to allow my software to retrieve remote models, I'd much rather standardize on ollama packages than rely on huggingface.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9lwqr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama.cpp is open, but this is kind of a category error. Gguf is not a registry/distribution spec, it&amp;#39;s a file format. And ollama&amp;#39;s package spec uses this file format.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;You could host GGUFs on a plain &amp;quot;directory index&amp;quot; Apache server and use those on llama.cpp easily.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Sort of. I mean, you could roll a bunch of your own scripting that does what ollama&amp;#39;s package/distribution tooling does... or you could use ollama&amp;#39;s package format.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;I&amp;#39;m actually not sure what you mean by Ollama being particularly &amp;quot;rugpull-resistant.&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I probably didn&amp;#39;t explain it well. To be clear, I&amp;#39;m talking specifically about ollama&amp;#39;s package management. I don&amp;#39;t have strong opinions either way on the rest of the project.&lt;/p&gt;\\n\\n&lt;p&gt;The typical open source enshittification pipeline involves developing a tool or service, releasing it (and/or ecosystem tooling) as open source software to build a community, then rugging that community by spinning off a proprietary version of the software that has some key premium features your users need. &amp;quot;Ollama the corporation&amp;quot; could certainly do this with &amp;quot;ollama the application&amp;quot;. No question there. What I&amp;#39;m saying is that &lt;em&gt;if&lt;/em&gt; they did this, everyone could still keep using their package format like nothing happened, because their package format is a trivial extension of an otherwise open and widely supported spec. (More on this below.)&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;It feels like Ollama unnecessarily complicates things and obfuscates what is going on. Model folder names being hashes...&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I can see why you would have this impression, but perhaps you aren&amp;#39;t familiar with the technical details of the OCI image/distribution specs? To be fair, most people aren&amp;#39;t, and maybe that&amp;#39;s some kind of point against it, but the fact of the matter is none of what you&amp;#39;re seeing is proprietary and there are in fact completely unaffiliated tools you can pull off the shelf right now that can make sense of those hashes.&lt;/p&gt;\\n\\n&lt;p&gt;Let me explain what an ollama package actually is. Apologies if you already know, I just want to make sure we&amp;#39;re on the same page. The OCI image spec defines a json &amp;quot;manifest&amp;quot; schema, which is what actually gets downloaded first when you run &lt;code&gt;ollama pull&lt;/code&gt; (or, in fact, &lt;code&gt;docker pull&lt;/code&gt;). For our purposes, all you need to know is it contains two key elements: a list of hashes corresponding to binary &amp;quot;blobs&amp;quot; (gguf models, docker image layers... it&amp;#39;s arbitrary) and a config object which is meant to be used by client tools to store data that isn&amp;#39;t part of the generic spec. Docker clients use this config object to define stuff like what user id the container should be run as, how the layers should be put together at runtime, the entrypoint script, what ports to expose, etc.&lt;/p&gt;\\n\\n&lt;p&gt;Ollama uses the manifest config object to define model parameters. &lt;strong&gt;This is the only ollama-specific part of the package format: a 10 line json object.&lt;/strong&gt; Everything else... the rest of the package format, the registry API, how things are stored in local directories... is bone stock OCI. What this means is if you needed to reinvent a client for retrieving ollama&amp;#39;s packages completely from scratch, all you would have to do is pick any off the shelf OCI client library (there are dozens of them, in most languages you&amp;#39;d care about) and write a function to parse 10 lines of json after it retrieves the manifest for you.&lt;/p&gt;\\n\\n&lt;p&gt;The story only gets better when you consider the server side. An ollama model registry is &lt;em&gt;literally&lt;/em&gt; just a standard OCI registry. Your path from literally nothing to replacing ollama (as far as model distribution is concerned) is &lt;code&gt;docker run registry&lt;/code&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe you can tell me what it would take to replace all of this functionality, were you to standardize on the huggingface client instead. I don&amp;#39;t actually know, but my assumption was that it would at the very least involve hand writing a bunch of methods that know how to talk to their REST API.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m actually of the strong opinion that ollama&amp;#39;s package spec is the best way to store and distribute models &lt;em&gt;even if you are not using ollama&lt;/em&gt; because it is such a simple extension of an existing well-established standard. You get so much useful functionality for free... versioning via OCI tags, metadata/annotations, off the shelf server and client software...&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;With llama.cpp I know that I&amp;#39;m running a build that can do CUDA, or Vulkan, or ROCm etc, and I can just pass the damn GGUF file with n context and n offloaded layers.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I don&amp;#39;t really mean this to be an ollama vs llama.cpp thing. In my view they aren&amp;#39;t particularly in the same category. There&amp;#39;s some overlap, but it&amp;#39;s generally pretty obvious which one you should use in a serious project. We tinkerers just happen to be in that small sliver of overlap where you could justifiably use either. It sounds like in your use case ollama&amp;#39;s main feature (the excellent package format) is irrelevant to you, so it&amp;#39;s not surprising you wouldn&amp;#39;t use it. I don&amp;#39;t actually use it much either, because I&amp;#39;m developing software that builds directly on llama.cpp. That said, if I end up needing some way to allow my software to retrieve remote models, I&amp;#39;d much rather standardize on ollama packages than rely on huggingface.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9lwqr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744738022,"author_flair_text":null,"treatment_tags":[],"created_utc":1744738022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mn9bcty","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Firepal64","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn9062h","score":5,"author_fullname":"t2_11i4bd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean, llama.cpp is also very open. Ollama is not revolutionary in this regard.  \\nHuggingface is just a bunch of git repositories (read: folders). You could host GGUFs on a plain \\"directory index\\" Apache server and use those on llama.cpp easily.  \\nI'm actually not sure what you mean by Ollama being particularly \\"rugpull-resistant.\\"\\n\\nIt feels like Ollama unnecessarily complicates things and obfuscates what is going on. Model folder names being hashes... Installing a custom model/finetune of any kind is tedious...  \\nWith llama.cpp I know that I'm running a build that can do CUDA, or Vulkan, or ROCm etc, and I can just pass the damn GGUF file with n context and n offloaded layers.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn9bcty","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, llama.cpp is also very open. Ollama is not revolutionary in this regard.&lt;br/&gt;\\nHuggingface is just a bunch of git repositories (read: folders). You could host GGUFs on a plain &amp;quot;directory index&amp;quot; Apache server and use those on llama.cpp easily.&lt;br/&gt;\\nI&amp;#39;m actually not sure what you mean by Ollama being particularly &amp;quot;rugpull-resistant.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;It feels like Ollama unnecessarily complicates things and obfuscates what is going on. Model folder names being hashes... Installing a custom model/finetune of any kind is tedious...&lt;br/&gt;\\nWith llama.cpp I know that I&amp;#39;m running a build that can do CUDA, or Vulkan, or ROCm etc, and I can just pass the damn GGUF file with n context and n offloaded layers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9bcty/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744734960,"author_flair_text":null,"treatment_tags":[],"created_utc":1744734960,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mn9062h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"StewedAngelSkins","can_mod_post":false,"created_utc":1744731610,"send_replies":true,"parent_id":"t1_mn7xf3o","score":6,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I could take or leave the service itself, but ollama's approach to distributing models is honestly the best thing about it by far. Not just the convenience, the actual package format and protocol are exactly what I would do if I were designing a model distribution scheme that's structurally and technologically resistant to rugpulling.\\n\\n\\n\\nOllama models are fully standards-compliant OCI artifacts (i.e. they're like docker containers).This means that the whole distribution stack is intrinsically open in a way you wouldn't get if they used some proprietary API (or \\"open\\" API where they control the only implementation). You can easily retrieve and produce them using tools like [oras](https://oras.land/) that have nothing to do with the ollama project. It disrupts the whole EEE playbook, because there's no lock-in. Ollama can't make their model server proprietary, because their \\"model server\\" is literally any off the shelf OCI registry. That people shit on this but are tolerant of huggingface blows my mind.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9062h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I could take or leave the service itself, but ollama&amp;#39;s approach to distributing models is honestly the best thing about it by far. Not just the convenience, the actual package format and protocol are exactly what I would do if I were designing a model distribution scheme that&amp;#39;s structurally and technologically resistant to rugpulling.&lt;/p&gt;\\n\\n&lt;p&gt;Ollama models are fully standards-compliant OCI artifacts (i.e. they&amp;#39;re like docker containers).This means that the whole distribution stack is intrinsically open in a way you wouldn&amp;#39;t get if they used some proprietary API (or &amp;quot;open&amp;quot; API where they control the only implementation). You can easily retrieve and produce them using tools like &lt;a href=\\"https://oras.land/\\"&gt;oras&lt;/a&gt; that have nothing to do with the ollama project. It disrupts the whole EEE playbook, because there&amp;#39;s no lock-in. Ollama can&amp;#39;t make their model server proprietary, because their &amp;quot;model server&amp;quot; is literally any off the shelf OCI registry. That people shit on this but are tolerant of huggingface blows my mind.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9062h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744731610,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7xf3o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Firepal64","can_mod_post":false,"created_utc":1744718684,"send_replies":true,"parent_id":"t3_1jzocoo","score":20,"author_fullname":"t2_11i4bd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I love llama-cli and llama-server from llama.cpp. You can just throw ggufs at it and it just runs them... Ollama's approach to distributing models feels weird. IDK.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7xf3o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love llama-cli and llama-server from llama.cpp. You can just throw ggufs at it and it just runs them... Ollama&amp;#39;s approach to distributing models feels weird. IDK.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7xf3o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7l127","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Educational_Rent1059","can_mod_post":false,"created_utc":1744712730,"send_replies":true,"parent_id":"t3_1jzocoo","score":27,"author_fullname":"t2_ac1d5rhvu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Agree","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7l127","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7l127/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744712730,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9pkcr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MrAlienOverLord","can_mod_post":false,"created_utc":1744739082,"send_replies":true,"parent_id":"t3_1jzocoo","score":10,"author_fullname":"t2_bqh7pj6s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"im so glad im not the only one that says ollama are oss bottom feeders ..  - docker guys wrapping shit around other peoples work no real value added . and everyone puts them high up .. i dont understand why","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9pkcr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;im so glad im not the only one that says ollama are oss bottom feeders ..  - docker guys wrapping shit around other peoples work no real value added . and everyone puts them high up .. i dont understand why&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9pkcr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744739082,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mna0d26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yur_mom","can_mod_post":false,"created_utc":1744742316,"send_replies":true,"parent_id":"t3_1jzocoo","score":4,"author_fullname":"t2_5v92f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The lower down the stack you go the less likely you are to be thanked...I rarely see the people writing compilers like gcc thanked for any work they do, but without them we would not be able to run most programs.\\n\\n\\ni always compare low level developing to being a lineman in the NFL...the only time someone noticed them is when they get a penalty and the same goes for low level programming..the only time you are noticed is if there is a bug.  As a low level programmer I always assumed the less people who notice me the better I am doing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mna0d26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The lower down the stack you go the less likely you are to be thanked...I rarely see the people writing compilers like gcc thanked for any work they do, but without them we would not be able to run most programs.&lt;/p&gt;\\n\\n&lt;p&gt;i always compare low level developing to being a lineman in the NFL...the only time someone noticed them is when they get a penalty and the same goes for low level programming..the only time you are noticed is if there is a bug.  As a low level programmer I always assumed the less people who notice me the better I am doing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mna0d26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744742316,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7rzim","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hunting-Succcubus","can_mod_post":false,"created_utc":1744716313,"send_replies":true,"parent_id":"t1_mn7pefi","score":9,"author_fullname":"t2_3wxyen0t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Boiling blood to 1 million kelvin.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7rzim","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Boiling blood to 1 million kelvin.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7rzim/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744716313,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7pefi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Barry_22","can_mod_post":false,"created_utc":1744715073,"send_replies":true,"parent_id":"t3_1jzocoo","score":13,"author_fullname":"t2_pctbl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also no mention of exllamav2? Outrageous!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7pefi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also no mention of exllamav2? Outrageous!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7pefi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715073,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn89cwa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Far_Buyer_7281","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7yifd","score":7,"author_fullname":"t2_vyvxdjqyp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"pretty usual, its consulting, right? holding a wet finger in the air to guess the direction of the wind for millions of dollars","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn89cwa","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;pretty usual, its consulting, right? holding a wet finger in the air to guess the direction of the wind for millions of dollars&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn89cwa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723208,"author_flair_text":null,"treatment_tags":[],"created_utc":1744723208,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7yifd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"molbal","can_mod_post":false,"created_utc":1744719134,"send_replies":true,"parent_id":"t1_mn7ydex","score":3,"author_fullname":"t2_g1srl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My brother in christ, *Deloitte* is on the list and you highlight ollama instead","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7yifd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My brother in christ, &lt;em&gt;Deloitte&lt;/em&gt; is on the list and you highlight ollama instead&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7yifd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719134,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8e6j8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StewedAngelSkins","can_mod_post":false,"created_utc":1744724859,"send_replies":true,"parent_id":"t1_mn7ydex","score":-1,"author_fullname":"t2_fxk6v95z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"People need to get over it. Ollama's fine for what it is. If it didn't exist everyone would be writing something like it, because it just makes sense to give llama.cpp a wrapper for web deployment. (Just having a rudimentary REST API isn't enough.) I don't agree with every design decision they've made, but overall it's competent software.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8e6j8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People need to get over it. Ollama&amp;#39;s fine for what it is. If it didn&amp;#39;t exist everyone would be writing something like it, because it just makes sense to give llama.cpp a wrapper for web deployment. (Just having a rudimentary REST API isn&amp;#39;t enough.) I don&amp;#39;t agree with every design decision they&amp;#39;ve made, but overall it&amp;#39;s competent software.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8e6j8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744724859,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7ydex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"molbal","can_mod_post":false,"created_utc":1744719077,"send_replies":true,"parent_id":"t3_1jzocoo","score":35,"author_fullname":"t2_g1srl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this the daily we-hate-ollama post?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7ydex","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this the daily we-hate-ollama post?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7ydex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719077,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn805ch","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Leflakk","can_mod_post":false,"created_utc":1744719785,"send_replies":true,"parent_id":"t3_1jzocoo","score":9,"author_fullname":"t2_udr659irv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think, no matter what tool people use, llamacpp is the heart of the local llms world and then of locallama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn805ch","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think, no matter what tool people use, llamacpp is the heart of the local llms world and then of locallama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn805ch/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719785,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndpk6z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"relmny","can_mod_post":false,"created_utc":1744795360,"send_replies":true,"parent_id":"t1_mn7qhcf","score":2,"author_fullname":"t2_joxwuyje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You missed the point, without llama.cpp there's no ollama.\\n\\nllama.cpp is the base for most of the local llms.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndpk6z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You missed the point, without llama.cpp there&amp;#39;s no ollama.&lt;/p&gt;\\n\\n&lt;p&gt;llama.cpp is the base for most of the local llms.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndpk6z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744795360,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7qhcf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kitanokikori","can_mod_post":false,"created_utc":1744715603,"send_replies":true,"parent_id":"t3_1jzocoo","score":29,"author_fullname":"t2_13bsp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why does this have to be a zero-sum game? Ollama provides value in making it easy to set up and correctly install models, llama.cpp provides value in abstracting away GPU hardware differences in order to get LLMs running. Projects are valuable based on the problems they solve for their users, not on their technical difficulty\\n\\nBoth projects are Good!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7qhcf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why does this have to be a zero-sum game? Ollama provides value in making it easy to set up and correctly install models, llama.cpp provides value in abstracting away GPU hardware differences in order to get LLMs running. Projects are valuable based on the problems they solve for their users, not on their technical difficulty&lt;/p&gt;\\n\\n&lt;p&gt;Both projects are Good!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7qhcf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715603,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn80ie3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IJOY94","can_mod_post":false,"created_utc":1744719927,"send_replies":true,"parent_id":"t3_1jzocoo","score":7,"author_fullname":"t2_cq3rs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean, that's what the MIT license gets you. It's as open as possible, but leaves the door open to being co-opted.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn80ie3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, that&amp;#39;s what the MIT license gets you. It&amp;#39;s as open as possible, but leaves the door open to being co-opted.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn80ie3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719927,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnaw69p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreatBigJerk","can_mod_post":false,"created_utc":1744751853,"send_replies":true,"parent_id":"t3_1jzocoo","score":8,"author_fullname":"t2_650y4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama.cpp deserves credit, but why do people hate Ollama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnaw69p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama.cpp deserves credit, but why do people hate Ollama?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnaw69p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744751853,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7ml32","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hero_Of_Shadows","can_mod_post":false,"created_utc":1744713610,"send_replies":true,"parent_id":"t3_1jzocoo","score":16,"author_fullname":"t2_13fjr0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Disgraceful","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7ml32","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Disgraceful&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7ml32/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744713610,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7r1sp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hefty_Development813","can_mod_post":false,"created_utc":1744715874,"send_replies":true,"parent_id":"t3_1jzocoo","score":9,"author_fullname":"t2_mqzpi5wj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unfortunately I think it often goes this way, ollama made the effort to get out to the somewhat less technical masses. Whether it was marketing or just simplicity of the setup and operation, idk, probably both. \\n\\n\\nAnyone really involved in this space beyond the surface does know all this, but that's actually a small fraction of ppl. LLMs have a lot of mass attention now, and tons of the ppl interested don't know what git even is. Ppl like that are just never going to be interested in learning to compile llama.cpp. \\n\\n\\nIt is definitely a shame, in this case specifically, bc even all use gguf model format, he should definitely be on that meta acknowledgement page","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7r1sp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately I think it often goes this way, ollama made the effort to get out to the somewhat less technical masses. Whether it was marketing or just simplicity of the setup and operation, idk, probably both. &lt;/p&gt;\\n\\n&lt;p&gt;Anyone really involved in this space beyond the surface does know all this, but that&amp;#39;s actually a small fraction of ppl. LLMs have a lot of mass attention now, and tons of the ppl interested don&amp;#39;t know what git even is. Ppl like that are just never going to be interested in learning to compile llama.cpp. &lt;/p&gt;\\n\\n&lt;p&gt;It is definitely a shame, in this case specifically, bc even all use gguf model format, he should definitely be on that meta acknowledgement page&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7r1sp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715874,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_mn7vrv4","id":"mn7vrv4","parent_id":"t1_mn7pusn","depth":1,"children":["mn7vrv4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7pusn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NobleKale","can_mod_post":false,"created_utc":1744715298,"send_replies":true,"parent_id":"t3_1jzocoo","score":8,"author_fullname":"t2_3ta35","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wait until you hear about [left-pad](https://en.wikipedia.org/wiki/Npm_left-pad_incident)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7pusn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait until you hear about &lt;a href=\\"https://en.wikipedia.org/wiki/Npm_left-pad_incident\\"&gt;left-pad&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7pusn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715298,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9jywv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aesky","can_mod_post":false,"created_utc":1744737469,"send_replies":true,"parent_id":"t3_1jzocoo","score":3,"author_fullname":"t2_kowr9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i say big companies get 'shaft' like this all the the time too\\n\\nlook at Cursor. The hottest start up right now and its a fork of vscode. I imagine microsoft would love Cursor's current MRR every month hitting their bank accounts.  But that's the nature of open source software. People can grab it market/make it better and get more money than you thought it was possible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9jywv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i say big companies get &amp;#39;shaft&amp;#39; like this all the the time too&lt;/p&gt;\\n\\n&lt;p&gt;look at Cursor. The hottest start up right now and its a fork of vscode. I imagine microsoft would love Cursor&amp;#39;s current MRR every month hitting their bank accounts.  But that&amp;#39;s the nature of open source software. People can grab it market/make it better and get more money than you thought it was possible.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9jywv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744737469,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9onrc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"merousername","can_mod_post":false,"created_utc":1744738820,"send_replies":true,"parent_id":"t3_1jzocoo","score":3,"author_fullname":"t2_1lsz1hb30o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The Tittwer user should tag the authors and mention this, trust me name calling authors is the best way to handle these.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9onrc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The Tittwer user should tag the authors and mention this, trust me name calling authors is the best way to handle these.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9onrc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744738820,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7smhx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"featherless_fiend","can_mod_post":false,"created_utc":1744716611,"send_replies":true,"parent_id":"t3_1jzocoo","score":9,"author_fullname":"t2_5kjq1v0e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't that just what you get for choosing MIT License? That's the \\"free shit up for grabs\\" license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7smhx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t that just what you get for choosing MIT License? That&amp;#39;s the &amp;quot;free shit up for grabs&amp;quot; license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7smhx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744716611,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7pd70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hugganao","can_mod_post":false,"created_utc":1744715057,"send_replies":true,"parent_id":"t3_1jzocoo","score":14,"author_fullname":"t2_jc5ns","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yeesh, yeah there was always something off about how ollama worked. people who have no idea what theyre doing makes it look like its a great tool while people who do, it's one of the most restrictive and useless tool.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7pd70","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeesh, yeah there was always something off about how ollama worked. people who have no idea what theyre doing makes it look like its a great tool while people who do, it&amp;#39;s one of the most restrictive and useless tool.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7pd70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715057,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8army","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"created_utc":1744723700,"send_replies":true,"parent_id":"t3_1jzocoo","score":8,"author_fullname":"t2_eerln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s outright toxic behavior.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8army","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s outright toxic behavior.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8army/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723700,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7ngzd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WolpertingerRumo","can_mod_post":false,"created_utc":1744714084,"send_replies":true,"parent_id":"t3_1jzocoo","score":13,"author_fullname":"t2_eju17wbbf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I like ollama. It’s easy to use. But cite your sources, it’s basic decency.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7ngzd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like ollama. It’s easy to use. But cite your sources, it’s basic decency.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7ngzd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744714084,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8n2qu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8c5x0","score":8,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"KoboldCPP usually cutting edge too… it adopts llama.cpp changes far faster.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn8n2qu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;KoboldCPP usually cutting edge too… it adopts llama.cpp changes far faster.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8n2qu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727677,"author_flair_text":null,"treatment_tags":[],"created_utc":1744727677,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":5,"name":"t1_mn8kk4v","id":"mn8kk4v","parent_id":"t1_mn8c5x0","depth":2,"children":["mn8kk4v"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8c5x0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Awwtifishal","can_mod_post":false,"created_utc":1744724184,"send_replies":true,"parent_id":"t1_mn83x4t","score":20,"author_fullname":"t2_1d96a8k10t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Koboldcpp has arguably a better UX because it is just a single executable, with a launcher that lets you select a GGUF with a file selector, while ollama is CLI only. And yet koboldcpp is rarely acknowledged at all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8c5x0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Koboldcpp has arguably a better UX because it is just a single executable, with a launcher that lets you select a GGUF with a file selector, while ollama is CLI only. And yet koboldcpp is rarely acknowledged at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8c5x0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744724184,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"mn83x4t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Poromenos","can_mod_post":false,"created_utc":1744721240,"send_replies":true,"parent_id":"t3_1jzocoo","score":11,"author_fullname":"t2_1pd6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Every single comment here is missing the fact that UX matters, and llama.cpp doesn't have easy enough UX for 99% of the people who want to play with LLMs.\\n\\nllama.cpp is the most amazing tech ever, and it's usable by N people. ollama makes LLMs accessible for 1000N, and of course those tens of thousands of people are going to hold it in high regard and talk about it, because it does something for them that llama.cpp never did.\\n\\nIf you're wondering how tens of thousands of people can be so misguided, you need to adjust your view on things, because either they're all wrong, or you're missing something.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn83x4t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Every single comment here is missing the fact that UX matters, and llama.cpp doesn&amp;#39;t have easy enough UX for 99% of the people who want to play with LLMs.&lt;/p&gt;\\n\\n&lt;p&gt;llama.cpp is the most amazing tech ever, and it&amp;#39;s usable by N people. ollama makes LLMs accessible for 1000N, and of course those tens of thousands of people are going to hold it in high regard and talk about it, because it does something for them that llama.cpp never did.&lt;/p&gt;\\n\\n&lt;p&gt;If you&amp;#39;re wondering how tens of thousands of people can be so misguided, you need to adjust your view on things, because either they&amp;#39;re all wrong, or you&amp;#39;re missing something.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn83x4t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744721240,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mna5gog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1744743840,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i'm team gerganov","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mna5gog","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m team gerganov&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mna5gog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744743840,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnally8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kzgrey","can_mod_post":false,"created_utc":1744748684,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_m4qen","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can anyone think of a time when a corporation has ever acknowledged the contributions of any one individual?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnally8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can anyone think of a time when a corporation has ever acknowledged the contributions of any one individual?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnally8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744748684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnb0s38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"idle2much","can_mod_post":false,"created_utc":1744753310,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_3g6q9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is crazy that the dev whose base code is used everywhere is getting no credit. I have wanted to try llama.cpp but the level of knowledge it takes to setup and use properly is intimidating. If you are new to all of this the level of entry with llama.cpp is high compared to ollama and Openwebui.\\n\\nI have read how much better performance you can get especially out of low end systems with llama.cpp and maybe one day I will try.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnb0s38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is crazy that the dev whose base code is used everywhere is getting no credit. I have wanted to try llama.cpp but the level of knowledge it takes to setup and use properly is intimidating. If you are new to all of this the level of entry with llama.cpp is high compared to ollama and Openwebui.&lt;/p&gt;\\n\\n&lt;p&gt;I have read how much better performance you can get especially out of low end systems with llama.cpp and maybe one day I will try.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnb0s38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744753310,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnb9qni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ventilador_liliana","can_mod_post":false,"created_utc":1744756271,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_ujesezwao","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama.cpp forever 💖","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnb9qni","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama.cpp forever 💖&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnb9qni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744756271,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7uxp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kweglinski","can_mod_post":false,"created_utc":1744717639,"send_replies":true,"parent_id":"t1_mn7qf3z","score":3,"author_fullname":"t2_7gw03ro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nothing surprising here. Usually job offers list tech stack as \\"skillset\\". They don't want you to setup different environment for local development because you will potentially deal with different issues than the team. This ends in either you wasting time on resolving things no-one else has or not being able to help the team to resolve theirs (based on prior experiences, you of course still can just investigate but that is time and money). \\n\\nNote: I'm not saying their stack choice is good in any way.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7uxp3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nothing surprising here. Usually job offers list tech stack as &amp;quot;skillset&amp;quot;. They don&amp;#39;t want you to setup different environment for local development because you will potentially deal with different issues than the team. This ends in either you wasting time on resolving things no-one else has or not being able to help the team to resolve theirs (based on prior experiences, you of course still can just investigate but that is time and money). &lt;/p&gt;\\n\\n&lt;p&gt;Note: I&amp;#39;m not saying their stack choice is good in any way.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7uxp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744717639,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7qf3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Paint-9490","can_mod_post":false,"created_utc":1744715573,"send_replies":true,"parent_id":"t3_1jzocoo","score":4,"author_fullname":"t2_rpm5owysg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To me the most egregious thing is that I have read several job ads which specifically asked for Ollama and LangChain knowledge. Every time I am like WTF am I reading?\\n\\nNever seen mentions of llama.cpp or exllama. You wonder what the hiring manager is thinking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7qf3z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To me the most egregious thing is that I have read several job ads which specifically asked for Ollama and LangChain knowledge. Every time I am like WTF am I reading?&lt;/p&gt;\\n\\n&lt;p&gt;Never seen mentions of llama.cpp or exllama. You wonder what the hiring manager is thinking.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7qf3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715573,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn8xhl1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AryanEmbered","can_mod_post":false,"created_utc":1744730811,"send_replies":true,"parent_id":"t3_1jzocoo","score":6,"author_fullname":"t2_7msa2g0k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ollama is horrible. The product and the whole group who does this as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8xhl1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ollama is horrible. The product and the whole group who does this as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8xhl1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744730811,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7zy13","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KaleidoscopeFuzzy422","can_mod_post":false,"created_utc":1744719704,"send_replies":true,"parent_id":"t3_1jzocoo","score":3,"author_fullname":"t2_41p2vjgo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Never forget that it was these heroes that FORCED the companies to adopt an 'open ai' stance. If they could ban us all from having our own LLMs 'for safety' they 100% would.   \\n\\n\\nShoutout to the heroes who churned out those GPTQs like an inflation printer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7zy13","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Never forget that it was these heroes that FORCED the companies to adopt an &amp;#39;open ai&amp;#39; stance. If they could ban us all from having our own LLMs &amp;#39;for safety&amp;#39; they 100% would.   &lt;/p&gt;\\n\\n&lt;p&gt;Shoutout to the heroes who churned out those GPTQs like an inflation printer.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7zy13/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719704,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn98ewz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mgr2019x","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8mt6b","score":3,"author_fullname":"t2_3j19xoxz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes. For exllama you should use tabbyAPI. It is from the same dev (turboderp). All those support structured  outputs and most of the fun you get with openai lib standards.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn98ewz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes. For exllama you should use tabbyAPI. It is from the same dev (turboderp). All those support structured  outputs and most of the fun you get with openai lib standards.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn98ewz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744734099,"author_flair_text":null,"treatment_tags":[],"created_utc":1744734099,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8mt6b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1744727596,"send_replies":true,"parent_id":"t1_mn8b9p6","score":1,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do those all support open AI apis?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8mt6b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do those all support open AI apis?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8mt6b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744727596,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8b9p6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mgr2019x","can_mod_post":false,"created_utc":1744723874,"send_replies":true,"parent_id":"t3_1jzocoo","score":5,"author_fullname":"t2_3j19xoxz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Never got it. Maybe the apple and windows users need something easy as ollama has to offer. Never used it. I prefere llama.cpp / exllamav2/3 and vllm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8b9p6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Never got it. Maybe the apple and windows users need something easy as ollama has to offer. Never used it. I prefere llama.cpp / exllamav2/3 and vllm.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8b9p6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744723874,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7yb8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Arkonias","can_mod_post":false,"created_utc":1744719053,"send_replies":true,"parent_id":"t3_1jzocoo","score":7,"author_fullname":"t2_6jyyd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fuck Ollama.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7yb8k","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuck Ollama.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7yb8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744719053,"author_flair_text":"Llama 3","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5c2a2958-309b-11ee-9109-22869f0a11dc","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9voul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"candre23","can_mod_post":false,"created_utc":1744740900,"send_replies":true,"parent_id":"t3_1jzocoo","score":5,"author_fullname":"t2_4wc8s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ollama is trash.  Always has been.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9voul","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama is trash.  Always has been.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9voul/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744740900,"author_flair_text":"koboldcpp","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9b3n7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_Erilaz","can_mod_post":false,"created_utc":1744734882,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_plftg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Agreed with Kalomaze. I personally use KoboldCPP for a few extra features, but it really is a mere good llamacpp fork, and anyone knows the OG GG behind GGUF and GGML.\\n\\nOllama can't even figure out the naming. Can't wait for Meta to get on the receiving end of CoolThiccZuccModel-1B-Distilled","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9b3n7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agreed with Kalomaze. I personally use KoboldCPP for a few extra features, but it really is a mere good llamacpp fork, and anyone knows the OG GG behind GGUF and GGML.&lt;/p&gt;\\n\\n&lt;p&gt;Ollama can&amp;#39;t even figure out the naming. Can&amp;#39;t wait for Meta to get on the receiving end of CoolThiccZuccModel-1B-Distilled&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9b3n7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744734882,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":9,"removal_reason":null,"link_id":"t3_1jzocoo","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnb8owh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Statement-0001","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn8q2bb","score":1,"author_fullname":"t2_11gh93nhos","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"model swapping for llama-server. But if really want to get into it, it works for anything that supports an openAI compatible API.\\n\\nI made it cause i wanted both model swapping, the latest llama.cpp features, and support for my older GPUs.","edited":false,"author_flair_css_class":null,"name":"t1_mnb8owh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;model swapping for llama-server. But if really want to get into it, it works for anything that supports an openAI compatible API.&lt;/p&gt;\\n\\n&lt;p&gt;I made it cause i wanted both model swapping, the latest llama.cpp features, and support for my older GPUs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jzocoo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnb8owh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744755911,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1744755911,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8q2bb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn824p6","score":2,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Okay a brief search didn’t make it clear… why would I want llama-swap. How do you use it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8q2bb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay a brief search didn’t make it clear… why would I want llama-swap. How do you use it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8q2bb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728580,"author_flair_text":null,"treatment_tags":[],"created_utc":1744728580,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mn824p6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7z404","score":5,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’ve switch to Koboldcpp. That app truly has it all. I couple it with Llama-Swap and that’s all I need for now.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mn824p6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve switch to Koboldcpp. That app truly has it all. I couple it with Llama-Swap and that’s all I need for now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn824p6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744720559,"author_flair_text":null,"treatment_tags":[],"created_utc":1744720559,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":4,"name":"t1_mn81oq0","id":"mn81oq0","parent_id":"t1_mn7z404","depth":2,"children":["mn81oq0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7z404","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mn7qhai","score":9,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1745078650,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7z404/","num_reports":null,"locked":false,"name":"t1_mn7z404","created":1744719374,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744719374,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":1,"name":"t1_mn7w314","id":"mn7w314","parent_id":"t1_mn7qhai","depth":1,"children":["mn7w314"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7qhai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zalathustra","can_mod_post":false,"created_utc":1744715602,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_lb93vlwi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fuck ollama, all my homies hate ollama.\\n\\nMemes aside, there's literally zero reason to use ollama unless you're completely tech-illiterate, and if you are, what the hell are you doing self-hosting an LLM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7qhai","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fuck ollama, all my homies hate ollama.&lt;/p&gt;\\n\\n&lt;p&gt;Memes aside, there&amp;#39;s literally zero reason to use ollama unless you&amp;#39;re completely tech-illiterate, and if you are, what the hell are you doing self-hosting an LLM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7qhai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744715602,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnb54x7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ECrispy","can_mod_post":false,"created_utc":1744754721,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_8z7kt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I never understood why 99% of youtube videos, posts etc talk about Ollama, when its the worst tool - koboldcpp is far better and much more optimized with new features, and there's llama.cpp of course.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnb54x7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I never understood why 99% of youtube videos, posts etc talk about Ollama, when its the worst tool - koboldcpp is far better and much more optimized with new features, and there&amp;#39;s llama.cpp of course.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnb54x7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744754721,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbg4pc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Artistic_Okra7288","can_mod_post":false,"created_utc":1744758448,"send_replies":true,"parent_id":"t1_mn8ohu4","score":1,"author_fullname":"t2_t35b2uw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I stumbled upon llama-swap on github that is supposed to help with that. It reminds me of ollama but can sit on top of llama.cpp (or other backends).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnbg4pc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I stumbled upon llama-swap on github that is supposed to help with that. It reminds me of ollama but can sit on top of llama.cpp (or other backends).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbg4pc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744758448,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn8ohu4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DigitalDreamRealms","can_mod_post":false,"created_utc":1744728107,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_tauyw6nfl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The one reason I learned how to run llama.cpp. It comes loaded with a basic web gui. Tedious part is loading and unloading, I tied it into OpenWebUI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn8ohu4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The one reason I learned how to run llama.cpp. It comes loaded with a basic web gui. Tedious part is loading and unloading, I tied it into OpenWebUI&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn8ohu4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744728107,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnd9a62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greenyashiro","can_mod_post":false,"created_utc":1744784960,"send_replies":true,"parent_id":"t1_mn9mu1w","score":1,"author_fullname":"t2_jyy83","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When you go eat at a restaurant, do you care about the cow that produced the milk or the farm that grew the vegetables?\\n\\nIt's very common these days to only care about the finished product, unless perhaps the creator is very famous (eg a celebrity chef)\\n\\nTo return to your music analogy, perhaps complexity is one factor, but also that people don't care so much about who did the sound mixing on that album or who played the flute for 20 seconds in a song.\\n\\nThose people are still generally credited on the album, in the CD booklet, online, etc... This information isn't even obscured or hidden. It's right there and people just don't care","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnd9a62","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When you go eat at a restaurant, do you care about the cow that produced the milk or the farm that grew the vegetables?&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s very common these days to only care about the finished product, unless perhaps the creator is very famous (eg a celebrity chef)&lt;/p&gt;\\n\\n&lt;p&gt;To return to your music analogy, perhaps complexity is one factor, but also that people don&amp;#39;t care so much about who did the sound mixing on that album or who played the flute for 20 seconds in a song.&lt;/p&gt;\\n\\n&lt;p&gt;Those people are still generally credited on the album, in the CD booklet, online, etc... This information isn&amp;#39;t even obscured or hidden. It&amp;#39;s right there and people just don&amp;#39;t care&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnd9a62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744784960,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mn9mu1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tylox_","can_mod_post":false,"created_utc":1744738289,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_povxz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's everywhere the same. Highly technical stuff gets neglected because it's difficult to understand. Look at the music industry. A new pop song gets released that has millions of views and has 4 chords on repeat, 5 notes and half of it is not even singing (called rapping). It's \\"good\\" because it's easy to understand. Don't give the average person a Bach or Beethoven.\\n\\nIt's easier to learn to live with it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9mu1w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s everywhere the same. Highly technical stuff gets neglected because it&amp;#39;s difficult to understand. Look at the music industry. A new pop song gets released that has millions of views and has 4 chords on repeat, 5 notes and half of it is not even singing (called rapping). It&amp;#39;s &amp;quot;good&amp;quot; because it&amp;#39;s easy to understand. Don&amp;#39;t give the average person a Bach or Beethoven.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s easier to learn to live with it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9mu1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744738289,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnaiqzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GoofAckYoorsElf","can_mod_post":false,"created_utc":1744747831,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_225efam3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, ask Johann Bernoulli about it...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnaiqzm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, ask Johann Bernoulli about it...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnaiqzm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744747831,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbnp26","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"XtremeHammond","can_mod_post":false,"created_utc":1744761017,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_30bgm29x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama.cpp showed me how LLMs can run on CPU with decent speed. \\nOllama is really easy to use but I know what beats in its heart - Gerganov’s creation.\\nSo no-one can take this from him.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnbnp26","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama.cpp showed me how LLMs can run on CPU with decent speed. \\nOllama is really easy to use but I know what beats in its heart - Gerganov’s creation.\\nSo no-one can take this from him.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbnp26/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744761017,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbnspm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sidran","can_mod_post":false,"created_utc":1744761052,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_3t79h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It would be interesting to know for sure if ggerganov and his team would even want something like this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnbnspm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It would be interesting to know for sure if ggerganov and his team would even want something like this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbnspm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744761052,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnbxi7y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1744764443,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_s6sfw4yy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"To be fair, nowadays ollama only uses the ggml code. So both ollama and llama.cpp are derivatives of ggml. But ollama is more user friendly and it supports vision and gemma 3 iSWA, so it is no wonder it gets more attention. \\n\\nOf course, it would be nice if it acknowledge more on ggml which is mostly written by ggergoanov.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnbxi7y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be fair, nowadays ollama only uses the ggml code. So both ollama and llama.cpp are derivatives of ggml. But ollama is more user friendly and it supports vision and gemma 3 iSWA, so it is no wonder it gets more attention. &lt;/p&gt;\\n\\n&lt;p&gt;Of course, it would be nice if it acknowledge more on ggml which is mostly written by ggergoanov.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnbxi7y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744764443,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnd46jj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"created_utc":1744782018,"send_replies":true,"parent_id":"t3_1jzocoo","score":2,"author_fullname":"t2_32el727b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; Content creators even deliberately blur the lines between the complete and distilled versions of models like DeepSeek R1, using the R1 name indiscriminately for marketing purposes.\\n\\nOf course they do. The only goal of these content creators is to get you sitting through their ads / sponsors messages.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnd46jj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Content creators even deliberately blur the lines between the complete and distilled versions of models like DeepSeek R1, using the R1 name indiscriminately for marketing purposes.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Of course they do. The only goal of these content creators is to get you sitting through their ads / sponsors messages.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnd46jj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744782018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mndcz8o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tabspaces","can_mod_post":false,"created_utc":1744787210,"send_replies":true,"parent_id":"t3_1jzocoo","score":-1,"author_fullname":"t2_h4h2az0s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"TBH Ollama jumped in and solved a problem. The docker-like interface of ollama is killer.\\n\\nIf llama.cpp gets one internally and have the binary in releases with all needed dependencies that ll make ollama useless.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndcz8o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;TBH Ollama jumped in and solved a problem. The docker-like interface of ollama is killer.&lt;/p&gt;\\n\\n&lt;p&gt;If llama.cpp gets one internally and have the binary in releases with all needed dependencies that ll make ollama useless.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndcz8o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744787210,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnfxh6k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celeski","can_mod_post":false,"created_utc":1744824289,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_1j3nttzx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is truly unfair! ggerganov truly deserves all of the recognition for his brilliant work!\\n\\nMuch of everything else would not be possible without his contributions so it is very unfair to see how llama.cpp is being excluded... 😡😤","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnfxh6k","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is truly unfair! ggerganov truly deserves all of the recognition for his brilliant work!&lt;/p&gt;\\n\\n&lt;p&gt;Much of everything else would not be possible without his contributions so it is very unfair to see how llama.cpp is being excluded... 😡😤&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnfxh6k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744824289,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mngaebj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"codeyman2","can_mod_post":false,"created_utc":1744828012,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_vx1w3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Same reason Steve Jobs is more popular than Dennis Ritchie and Brian Kernighan.. that’s how the world works.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mngaebj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same reason Steve Jobs is more popular than Dennis Ritchie and Brian Kernighan.. that’s how the world works.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mngaebj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744828012,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnh5xv2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TakuyaTeng","can_mod_post":false,"created_utc":1744837501,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_y4zp8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really don't think the R1 part is intentional. The number of people that didn't understand anything but commented on how \\"lol the average gaming PC can run DeepSeek offline\\" really made me lose all faith.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnh5xv2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really don&amp;#39;t think the R1 part is intentional. The number of people that didn&amp;#39;t understand anything but commented on how &amp;quot;lol the average gaming PC can run DeepSeek offline&amp;quot; really made me lose all faith.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnh5xv2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744837501,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnipnrx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vegetable_Sun_9225","can_mod_post":false,"created_utc":1744856915,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_dsowj79s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This has always how it's been. Focus is always on interface, and a tiny minority looks under the covers and correctly identifies what it took to make it happen. \\n\\nIn fairness, Ollama has forked llama.cpp so as casual user reviewing the dependencies aren't going to see a link to GGs work. \\n\\nAnd it wasn't out of spite. Meta worked with Ollama and they called out who they worked with","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnipnrx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This has always how it&amp;#39;s been. Focus is always on interface, and a tiny minority looks under the covers and correctly identifies what it took to make it happen. &lt;/p&gt;\\n\\n&lt;p&gt;In fairness, Ollama has forked llama.cpp so as casual user reviewing the dependencies aren&amp;#39;t going to see a link to GGs work. &lt;/p&gt;\\n\\n&lt;p&gt;And it wasn&amp;#39;t out of spite. Meta worked with Ollama and they called out who they worked with&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnipnrx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744856915,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnlddi3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Playfulpetfox","can_mod_post":false,"created_utc":1744901220,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_6gnzp8dz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This post is an onion of irony. It's not that many layers, but enough that apparently not everyone can even see them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnlddi3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This post is an onion of irony. It&amp;#39;s not that many layers, but enough that apparently not everyone can even see them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnlddi3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744901220,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnvfkid","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"baton_camero","can_mod_post":false,"created_utc":1745033684,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_9f4tl9zo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cuck license got cucked? What a surprise!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnvfkid","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cuck license got cucked? What a surprise!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnvfkid/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745033684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn7y1qv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1744718946,"send_replies":true,"parent_id":"t1_mn7vhyu","score":6,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't let the Arch users know about Slackware!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7y1qv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t let the Arch users know about Slackware!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7y1qv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744718946,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mn7vhyu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ElectronSpiderwort","can_mod_post":false,"created_utc":1744717879,"send_replies":true,"parent_id":"t3_1jzocoo","score":-2,"author_fullname":"t2_mxbu5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Counterpoint: llama.cpp is unstable. Remember when all of your GGML models no longer worked? And time and time again that your carefully crafted command line tests failed because the program option changed? I get why that all happened, but backwards compatibility and stability are explicitly not in the project manifesto. It's like saying Slackware doesn't get enough credit now that all the clouds run Debian or Red Hat derivatives. I love and use llama.cpp. It made the magic possible, and it's still amazing (particularly on a Mac), but the product with an easy installer and stable progression between releases is going to get the attention of the masses. Same as it ever was. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn7vhyu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Counterpoint: llama.cpp is unstable. Remember when all of your GGML models no longer worked? And time and time again that your carefully crafted command line tests failed because the program option changed? I get why that all happened, but backwards compatibility and stability are explicitly not in the project manifesto. It&amp;#39;s like saying Slackware doesn&amp;#39;t get enough credit now that all the clouds run Debian or Red Hat derivatives. I love and use llama.cpp. It made the magic possible, and it&amp;#39;s still amazing (particularly on a Mac), but the product with an easy installer and stable progression between releases is going to get the attention of the masses. Same as it ever was. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn7vhyu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744717879,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9rlou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henfiber","can_mod_post":false,"created_utc":1744739673,"send_replies":true,"parent_id":"t1_mn95uwq","score":3,"author_fullname":"t2_lw9me25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The force attribution, though, with the MIT license, no?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9rlou","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The force attribution, though, with the MIT license, no?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn9rlou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744739673,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mn95uwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UsualResult","can_mod_post":false,"created_utc":1744733308,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_10iarzku","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean, if you don't want this, don't make your work open source OR force attribution. It's well known that a decent amount of open source users are \\"freeloaders\\" and since they aren't legally forced to give credit they do NOT.\\n\\nAs someone who has occasionally released open source software, I take my own needs and wants into consideration when I choose a license. For some of my software, I don't care if you take it and run. Others, I do, and they are licensed accordingly.\\n\\nIf llama.cpp really cared (and they may not), they can take steps to prevent what ollama is doing.\\n\\nI suspect they do NOT and that's why we have this current situation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn95uwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, if you don&amp;#39;t want this, don&amp;#39;t make your work open source OR force attribution. It&amp;#39;s well known that a decent amount of open source users are &amp;quot;freeloaders&amp;quot; and since they aren&amp;#39;t legally forced to give credit they do NOT.&lt;/p&gt;\\n\\n&lt;p&gt;As someone who has occasionally released open source software, I take my own needs and wants into consideration when I choose a license. For some of my software, I don&amp;#39;t care if you take it and run. Others, I do, and they are licensed accordingly.&lt;/p&gt;\\n\\n&lt;p&gt;If llama.cpp really cared (and they may not), they can take steps to prevent what ollama is doing.&lt;/p&gt;\\n\\n&lt;p&gt;I suspect they do NOT and that&amp;#39;s why we have this current situation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mn95uwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744733308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mo1xn1d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pakobbix","can_mod_post":false,"send_replies":true,"parent_id":"t1_mndb2mw","score":1,"author_fullname":"t2_zwa53","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wrong and true at the same time. For example, Nvidia workstation and Datacenter cards spike up to 50W just when a model is loaded. I can see this behaviour on 3 different machines using p40, a2000 and A4000. While my old 2080 ti, a 2070 super and the 5090 doesn't do this.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mo1xn1d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wrong and true at the same time. For example, Nvidia workstation and Datacenter cards spike up to 50W just when a model is loaded. I can see this behaviour on 3 different machines using p40, a2000 and A4000. While my old 2080 ti, a 2070 super and the 5090 doesn&amp;#39;t do this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mo1xn1d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745131082,"author_flair_text":null,"treatment_tags":[],"created_utc":1745131082,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mndb2mw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emotional_Egg_251","can_mod_post":false,"created_utc":1744786048,"send_replies":true,"parent_id":"t1_mnac80c","score":2,"author_fullname":"t2_tw96aadz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Ollama dynamically loads and unloads models after 5 minutes. For people with usecases where we query a model at different times throughout the day, this puts less stress on the computer and saves a bit of electricity. No other software seems to have this feature.\\n\\nLlama-swap does this as well, but FYI, no electricity is being used by having the model sit in vram between uses. Check your GPU's power use - it's idle.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mndb2mw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Ollama dynamically loads and unloads models after 5 minutes. For people with usecases where we query a model at different times throughout the day, this puts less stress on the computer and saves a bit of electricity. No other software seems to have this feature.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Llama-swap does this as well, but FYI, no electricity is being used by having the model sit in vram between uses. Check your GPU&amp;#39;s power use - it&amp;#39;s idle.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jzocoo","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mndb2mw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744786048,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mnac80c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArsNeph","can_mod_post":false,"created_utc":1744745906,"send_replies":true,"parent_id":"t3_1jzocoo","score":1,"author_fullname":"t2_vt0xkv60d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There are only four real reasons people use Ollama over llama.cpp when it comes to functionality, other than CLI:\\n\\n1. Ollama makes it incredibly easy to swap between models using a frontend, thanks to the way its API works. This is annoying with other software. Yes, Llama-swap exists, but that's just one more thing to maintain. Why not add that functionality natively?\\n2. Ollama dynamically loads and unloads models after 5 minutes. For people with usecases where we query a model at different times throughout the day, this puts less stress on the computer and saves a bit of electricity. No other software seems to have this feature.\\n\\nThe above two are what make it so good for use away from home, like with OpenWebUI.\\n\\n3. Multimodality. Llama.cpp has completely dropped the ball when it comes to multimodal model support, to the point that Ollama are implementing it themselves. In an era where GPT4o has been out for over a year, and many models are starting to ship multimodal as default, llama.cpp simply lags behind. This is a huge problem, considering the eventual new era of omnimodal models, and the fact anything that doesn't have support, including architectures like Mamba2 hybrids, don't pick up traction.\\n\\n4. Ease of use. It allows you to download a model with a single command, telling the difference between quants is very confusing for beginners, though at the detriment of quality. It loads layers automatically dependent on VRAM, this should be standard functionality with all loaders. And you don't have to mess with specific settings, although this is actually a big problem, since Ollama defaults are horrible, including 2048 context length.\\n\\nIf we can solve these, I believe we'd have way better adoption of other inference software.","edited":1744746705,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnac80c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are only four real reasons people use Ollama over llama.cpp when it comes to functionality, other than CLI:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Ollama makes it incredibly easy to swap between models using a frontend, thanks to the way its API works. This is annoying with other software. Yes, Llama-swap exists, but that&amp;#39;s just one more thing to maintain. Why not add that functionality natively?&lt;/li&gt;\\n&lt;li&gt;Ollama dynamically loads and unloads models after 5 minutes. For people with usecases where we query a model at different times throughout the day, this puts less stress on the computer and saves a bit of electricity. No other software seems to have this feature.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;The above two are what make it so good for use away from home, like with OpenWebUI.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;Multimodality. Llama.cpp has completely dropped the ball when it comes to multimodal model support, to the point that Ollama are implementing it themselves. In an era where GPT4o has been out for over a year, and many models are starting to ship multimodal as default, llama.cpp simply lags behind. This is a huge problem, considering the eventual new era of omnimodal models, and the fact anything that doesn&amp;#39;t have support, including architectures like Mamba2 hybrids, don&amp;#39;t pick up traction.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;Ease of use. It allows you to download a model with a single command, telling the difference between quants is very confusing for beginners, though at the detriment of quality. It loads layers automatically dependent on VRAM, this should be standard functionality with all loaders. And you don&amp;#39;t have to mess with specific settings, although this is actually a big problem, since Ollama defaults are horrible, including 2048 context length.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;If we can solve these, I believe we&amp;#39;d have way better adoption of other inference software.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jzocoo/finally_someone_noticed_this_unfair_situation/mnac80c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744745906,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jzocoo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":21,"name":"t1_mn80418","id":"mn80418","parent_id":"t3_1jzocoo","depth":0,"children":["mn80418","mn80dja","mna2utv","mn8d7jy","mnamndj","mn8lubu","mn8yjzh","mn8brm8","mn9rvxb","mnbgxm2","mn7qpav","mn7ntyu","mn9qb6k","mn8mzsg","mn7m3am"]}}],"before":null}}]`);export{e as default};
