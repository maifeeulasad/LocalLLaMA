import{j as e}from"./index-CmSyeZDT.js";import{R as l}from"./RedditPostRenderer-C2Zg39IK.js";import"./index-CiTZuv6Z.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"have been poring over pcpartpicker, newegg etc. and it seems like the cheapest way to get the most usable VRAM from GPUs is the 16GB 5060Ti? am I missing something obvious? (probably.)\\n\\nTIA.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"best bang for your buck in GPUs for VRAM?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lq4bhu","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.93,"author_flair_background_color":null,"subreddit_type":"public","ups":44,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_34g6p","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":44,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751482961,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;have been poring over pcpartpicker, newegg etc. and it seems like the cheapest way to get the most usable VRAM from GPUs is the 16GB 5060Ti? am I missing something obvious? (probably.)&lt;/p&gt;\\n\\n&lt;p&gt;TIA.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lq4bhu","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"starkruzr","discussion_type":null,"num_comments":61,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/","subreddit_subscribers":494198,"created_utc":1751482961,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zvl0l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1751484216,"send_replies":true,"parent_id":"t3_1lq4bhu","score":41,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Depends if you’re ok shopping for used GPUs. I’ve no idea about new GPUs, but on the used marked the 3090 is still untouchable as king of bang for buck.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zvl0l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends if you’re ok shopping for used GPUs. I’ve no idea about new GPUs, but on the used marked the 3090 is still untouchable as king of bang for buck.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n0zvl0l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751484216,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n128i64","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"quetzalcoatlus1453","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11jx0a","score":11,"author_fullname":"t2_7omstcez","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There’s no hard and fast rule. nVidia just sometimes uses that name for mid-life refreshes. In the case of the 5070ti, speculation is that they will replace the 2GB VRAM chips of the regular 5070ti with the new 3GB ones, thus going from 16GB to 24GB.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n128i64","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There’s no hard and fast rule. nVidia just sometimes uses that name for mid-life refreshes. In the case of the 5070ti, speculation is that they will replace the 2GB VRAM chips of the regular 5070ti with the new 3GB ones, thus going from 16GB to 24GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n128i64/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751511388,"author_flair_text":null,"treatment_tags":[],"created_utc":1751511388,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13i93o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HiddenoO","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11pqug","score":4,"author_fullname":"t2_8127x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's just this particular case (according to rumors, anyway). Generally speaking (what they asked for), there are no such rules and Nvidia just makes the Super version whatever they believe will benefit their total sales the most.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13i93o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s just this particular case (according to rumors, anyway). Generally speaking (what they asked for), there are no such rules and Nvidia just makes the Super version whatever they believe will benefit their total sales the most.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n13i93o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751534355,"author_flair_text":null,"treatment_tags":[],"created_utc":1751534355,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n11pqug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Emotional_Pop_7830","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11jx0a","score":9,"author_fullname":"t2_ptc48crwq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"supers use larger vram chips. like 2gb chips vs 3gb chips.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n11pqug","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;supers use larger vram chips. like 2gb chips vs 3gb chips.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11pqug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751504876,"author_flair_text":null,"treatment_tags":[],"created_utc":1751504876,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n11jx0a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"starkruzr","can_mod_post":false,"created_utc":1751502982,"send_replies":true,"parent_id":"t1_n117kpy","score":7,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what distinguishes the \\"Supers\\" from vanilla cards, generally speaking?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11jx0a","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what distinguishes the &amp;quot;Supers&amp;quot; from vanilla cards, generally speaking?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11jx0a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751502982,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n117kpy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1751498963,"send_replies":true,"parent_id":"t3_1lq4bhu","score":17,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"3090 24gb (still strong)\\n\\n4060 Ti 16gb (fairly slow)\\n\\n5060 Ti 16gb (a bit faster)\\n\\nupcoming/rumored 5070 Ti Super 24gb, might finally displace the 3090 24gb as the value king depending on actual street price, or it might just drive used 3090 prices down a bit\\n\\nRyzen 395+ an entire system with 128GB $2k is worth a mention for vram GB/$ but won't be super fast unless using MOE since it is 4060 Ti tier bandwidth. If you're in the market for a whole PC anyway it is worth considering perhaps?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n117kpy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3090 24gb (still strong)&lt;/p&gt;\\n\\n&lt;p&gt;4060 Ti 16gb (fairly slow)&lt;/p&gt;\\n\\n&lt;p&gt;5060 Ti 16gb (a bit faster)&lt;/p&gt;\\n\\n&lt;p&gt;upcoming/rumored 5070 Ti Super 24gb, might finally displace the 3090 24gb as the value king depending on actual street price, or it might just drive used 3090 prices down a bit&lt;/p&gt;\\n\\n&lt;p&gt;Ryzen 395+ an entire system with 128GB $2k is worth a mention for vram GB/$ but won&amp;#39;t be super fast unless using MOE since it is 4060 Ti tier bandwidth. If you&amp;#39;re in the market for a whole PC anyway it is worth considering perhaps?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n117kpy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751498963,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1994wx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n12q492","score":1,"author_fullname":"t2_34g6p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yeah my use case is stuff like Qwen2-VL-7B-Instruct, so really only generating text but definitely having it \\"look\\" at a lot of image data.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n1994wx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah my use case is stuff like Qwen2-VL-7B-Instruct, so really only generating text but definitely having it &amp;quot;look&amp;quot; at a lot of image data.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lq4bhu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n1994wx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751605844,"author_flair_text":null,"treatment_tags":[],"created_utc":1751605844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n12q492","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"panchovix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n120ds0","score":4,"author_fullname":"t2_j1kqr","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Image I think there is none, and video is offloading some parts to a different GPU, quite different vs LLMs where you can get actually better speeds with TP on inference.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n12q492","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Image I think there is none, and video is offloading some parts to a different GPU, quite different vs LLMs where you can get actually better speeds with TP on inference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lq4bhu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12q492/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751518861,"author_flair_text":"Llama 405B","treatment_tags":[],"created_utc":1751518861,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n120ds0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"federico_84","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11lzdk","score":9,"author_fullname":"t2_vo74r4bt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You also get FP8 and FP4 with 5060.\\nBut there are some image/video gen models that don't support multiple GPUs.","edited":false,"author_flair_css_class":null,"name":"t1_n120ds0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You also get FP8 and FP4 with 5060.\\nBut there are some image/video gen models that don&amp;#39;t support multiple GPUs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lq4bhu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n120ds0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751508367,"author_flair_text":null,"collapsed":false,"created_utc":1751508367,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n11lzdk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"townofsalemfangay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10jwie","score":11,"author_fullname":"t2_122dsg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, a 3090 has more raw memory bandwidth, but that doesn’t automatically translate to better performance for inference workloads (training is not inference). In practice, having more total VRAM *across multiple cards* often beats higher bandwidth on a single card. The key is you avoid offloading, which tanks performance far more than a bandwidth tradeoff.\\n\\nWith two 5060 Tis (16GB each), you’ve got 32GB of total VRAM and the ability to parallelise across both cards. That setup will often deliver better tokens-per-second than a single 3090, even with half the bandwidth per card.\\n\\nSo yeah, unless you’re getting 3090s at a deep discount, newer mid-range cards give you better scale, efficiency, and parallel capacity for the price.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11lzdk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, a 3090 has more raw memory bandwidth, but that doesn’t automatically translate to better performance for inference workloads (training is not inference). In practice, having more total VRAM &lt;em&gt;across multiple cards&lt;/em&gt; often beats higher bandwidth on a single card. The key is you avoid offloading, which tanks performance far more than a bandwidth tradeoff.&lt;/p&gt;\\n\\n&lt;p&gt;With two 5060 Tis (16GB each), you’ve got 32GB of total VRAM and the ability to parallelise across both cards. That setup will often deliver better tokens-per-second than a single 3090, even with half the bandwidth per card.&lt;/p&gt;\\n\\n&lt;p&gt;So yeah, unless you’re getting 3090s at a deep discount, newer mid-range cards give you better scale, efficiency, and parallel capacity for the price.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11lzdk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751503657,"author_flair_text":null,"treatment_tags":[],"created_utc":1751503657,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10mltk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"starkruzr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10jwie","score":4,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"true! for me so far the limiting factor has been \\"can I hold the damn thing,\\" heh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10mltk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;true! for me so far the limiting factor has been &amp;quot;can I hold the damn thing,&amp;quot; heh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10mltk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492193,"author_flair_text":null,"treatment_tags":[],"created_utc":1751492193,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10mcuc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10jwie","score":3,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In theory could be  parallelized","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10mcuc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In theory could be  parallelized&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10mcuc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492118,"author_flair_text":null,"treatment_tags":[],"created_utc":1751492118,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n10jwie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Threatening-Silence-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1065tu","score":24,"author_fullname":"t2_15wqsifdjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Half the memory bandwidth of a 3090 though.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n10jwie","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Half the memory bandwidth of a 3090 though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10jwie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751491367,"author_flair_text":null,"treatment_tags":[],"created_utc":1751491367,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13nche","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Threatening-Silence-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n133sa7","score":1,"author_fullname":"t2_15wqsifdjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nah if your board has Thunderbolt you can run up to six cards as eGPUs, via 3-port tb4 hubs. One in the case gives you 7. Can use Oculink to fit more eGPUs into the PCIe bus. I'm up to 9 total now off a mid tier gaming motherboard. I'd probably do a used Xeon server though if I started over.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13nche","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nah if your board has Thunderbolt you can run up to six cards as eGPUs, via 3-port tb4 hubs. One in the case gives you 7. Can use Oculink to fit more eGPUs into the PCIe bus. I&amp;#39;m up to 9 total now off a mid tier gaming motherboard. I&amp;#39;d probably do a used Xeon server though if I started over.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n13nche/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751537253,"author_flair_text":null,"treatment_tags":[],"created_utc":1751537253,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n133sa7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kaisurniwurer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1065tu","score":1,"author_fullname":"t2_qafso","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Then again two cards is maximum you can easily* run, so 2x3090 will give you 48GB instead of 32GB.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n133sa7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Then again two cards is maximum you can easily* run, so 2x3090 will give you 48GB instead of 32GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n133sa7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751525952,"author_flair_text":null,"treatment_tags":[],"created_utc":1751525952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1065tu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"starkruzr","can_mod_post":false,"created_utc":1751487383,"send_replies":true,"parent_id":"t1_n0zzuz5","score":6,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well, a 3090 with 24GB is about $800. two 5060Tis with 16GB each is $900.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1065tu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well, a 3090 with 24GB is about $800. two 5060Tis with 16GB each is $900.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n1065tu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751487383,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zzuz5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Threatening-Silence-","can_mod_post":false,"created_utc":1751485518,"send_replies":true,"parent_id":"t3_1lq4bhu","score":31,"author_fullname":"t2_15wqsifdjf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The answer is 3090s. Ask next year and it will still be the answer. But the year after that, we'll see.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zzuz5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The answer is 3090s. Ask next year and it will still be the answer. But the year after that, we&amp;#39;ll see.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n0zzuz5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751485518,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n11ib78","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751502452,"send_replies":true,"parent_id":"t1_n11hd4g","score":2,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, my use case is stuff like Qwen2.5-VL*. best I can do rn inside 16GB is 7B at INT8; I just have the one 5060Ti. the VLs seem to use significantly more RAM than \\"pure\\" LLMs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11ib78","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, my use case is stuff like Qwen2.5-VL*. best I can do rn inside 16GB is 7B at INT8; I just have the one 5060Ti. the VLs seem to use significantly more RAM than &amp;quot;pure&amp;quot; LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11ib78/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751502452,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13l0no","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HiddenoO","can_mod_post":false,"created_utc":1751535966,"send_replies":true,"parent_id":"t1_n11hd4g","score":1,"author_fullname":"t2_8127x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;24GB is nice but not really enough memory to fully capitalise on Q32b.  \\nSomewhere around that 40GB mark seems to be ideal.\\n\\n24GB is plenty to fit Q4 and at least some Q5s, and those generally perform within 2% of the 16-bit models.\\n\\n40GB is frankly kind of a waste right now because there aren't any models around 60-70B that perform significantly better than the 32B models and would be worth using quantized.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13l0no","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;24GB is nice but not really enough memory to fully capitalise on Q32b.&lt;br/&gt;\\nSomewhere around that 40GB mark seems to be ideal.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;24GB is plenty to fit Q4 and at least some Q5s, and those generally perform within 2% of the 16-bit models.&lt;/p&gt;\\n\\n&lt;p&gt;40GB is frankly kind of a waste right now because there aren&amp;#39;t any models around 60-70B that perform significantly better than the 32B models and would be worth using quantized.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n13l0no/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751535966,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n11hd4g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1751502138,"send_replies":true,"parent_id":"t3_1lq4bhu","score":8,"author_fullname":"t2_by77ogdhr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Almost nobody uses that word but it's burned into my brain, too.\\n\\n\\nBest bang GPU is super tricky.\\n\\n\\nPerformance \\nEfficiency \\nNoise \\nCost\\nSpace\\nHeat\\n\\n\\nI keep wondering if these LLMs somehow produce inherently better quality outputs when run on a single card, too.\\n\\n\\n16GB really is the sweet spot for entry level which is a shame because the 3060 12GB is awesome. If you don't need 32k context, consider one of those.\\n\\n\\n24GB is nice but not really enough memory to fully capitalise on Q32b.\\n\\n\\nSomewhere around that 40GB mark seems to be ideal.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11hd4g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Almost nobody uses that word but it&amp;#39;s burned into my brain, too.&lt;/p&gt;\\n\\n&lt;p&gt;Best bang GPU is super tricky.&lt;/p&gt;\\n\\n&lt;p&gt;Performance \\nEfficiency \\nNoise \\nCost\\nSpace\\nHeat&lt;/p&gt;\\n\\n&lt;p&gt;I keep wondering if these LLMs somehow produce inherently better quality outputs when run on a single card, too.&lt;/p&gt;\\n\\n&lt;p&gt;16GB really is the sweet spot for entry level which is a shame because the 3060 12GB is awesome. If you don&amp;#39;t need 32k context, consider one of those.&lt;/p&gt;\\n\\n&lt;p&gt;24GB is nice but not really enough memory to fully capitalise on Q32b.&lt;/p&gt;\\n\\n&lt;p&gt;Somewhere around that 40GB mark seems to be ideal.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11hd4g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751502138,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n199kwm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n131atz","score":1,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"$450 even!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n199kwm","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;$450 even!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n199kwm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751606056,"author_flair_text":null,"treatment_tags":[],"created_utc":1751606056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n131atz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sufficient_Prune3897","can_mod_post":false,"created_utc":1751524585,"send_replies":true,"parent_id":"t1_n11q5qz","score":4,"author_fullname":"t2_wl169phz5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No reason to get a 400$ 4060ti if you can get a new 500$ 5060ti","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n131atz","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No reason to get a 400$ 4060ti if you can get a new 500$ 5060ti&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n131atz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751524585,"author_flair_text":"Llama 70B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n11q5qz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xoexohexox","can_mod_post":false,"created_utc":1751505010,"send_replies":true,"parent_id":"t3_1lq4bhu","score":3,"author_fullname":"t2_323db","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Used 3090 24gb around 700 USD\\n\\nUsed 4060ti 16gb around 400 USD\\n\\nUsed MOBILE 3080ti 16gb - not sure how much they cost but probably cheap","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11q5qz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Used 3090 24gb around 700 USD&lt;/p&gt;\\n\\n&lt;p&gt;Used 4060ti 16gb around 400 USD&lt;/p&gt;\\n\\n&lt;p&gt;Used MOBILE 3080ti 16gb - not sure how much they cost but probably cheap&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11q5qz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751505010,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1005hq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Background-Ad-5398","can_mod_post":false,"created_utc":1751485607,"send_replies":true,"parent_id":"t3_1lq4bhu","score":3,"author_fullname":"t2_71b6nl31","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"as far as Ive seen its the cheapest card you can find unless you want to dig thru ebay trash, you also wont need a new power supply for it if you had a smaller card before","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1005hq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;as far as Ive seen its the cheapest card you can find unless you want to dig thru ebay trash, you also wont need a new power supply for it if you had a smaller card before&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n1005hq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751485607,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n126q1v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"allenasm","can_mod_post":false,"created_utc":1751510710,"send_replies":true,"parent_id":"t3_1lq4bhu","score":3,"author_fullname":"t2_fouwt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Honestly it’s hard to say because it depends on your use case. Are you looking for accuracy? Speed? Giant context window?  Lots of variables.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n126q1v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly it’s hard to say because it depends on your use case. Are you looking for accuracy? Speed? Giant context window?  Lots of variables.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n126q1v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751510710,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n113mfs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ninja_Weedle","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1094jo","score":4,"author_fullname":"t2_smvqlry","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"P104 is slower than the 3060 though? It's a mining variant of the 1070 with terrible bandwidth that's also a pain in the ass to use","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n113mfs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;P104 is slower than the 3060 though? It&amp;#39;s a mining variant of the 1070 with terrible bandwidth that&amp;#39;s also a pain in the ass to use&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n113mfs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751497670,"author_flair_text":null,"treatment_tags":[],"created_utc":1751497670,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1094jo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n105x4r","score":3,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well for starters it looks like it only has 8GB RAM. also I guess there's a 3060 with 12GB? I guess the p104 is there to give you core horsepower and the 3060 is there for the RAM","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1094jo","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well for starters it looks like it only has 8GB RAM. also I guess there&amp;#39;s a 3060 with 12GB? I guess the p104 is there to give you core horsepower and the 3060 is there for the RAM&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n1094jo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751488239,"author_flair_text":null,"treatment_tags":[],"created_utc":1751488239,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n122czi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Internal9317","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10ml4u","score":1,"author_fullname":"t2_77yd9w74","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"isn't it pcie1.0gen1 or something as I remembered?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n122czi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;isn&amp;#39;t it pcie1.0gen1 or something as I remembered?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n122czi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751509077,"author_flair_text":null,"treatment_tags":[],"created_utc":1751509077,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n10ml4u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n105x4r","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It has no video output and it is pcie3.0x1","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n10ml4u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It has no video output and it is pcie3.0x1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10ml4u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492187,"author_flair_text":null,"treatment_tags":[],"created_utc":1751492187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n105x4r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Unlikely_Track_5154","can_mod_post":false,"created_utc":1751487313,"send_replies":true,"parent_id":"t1_n102y2q","score":4,"author_fullname":"t2_r783n0ey","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is the p104 just bad in general, is it good for inference, what is the reason it is so cheap","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n105x4r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is the p104 just bad in general, is it good for inference, what is the reason it is so cheap&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n105x4r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751487313,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n102y2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751486434,"send_replies":true,"parent_id":"t3_1lq4bhu","score":6,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; the cheapest way to get the most usable VRAM\\n\\nis 3060 + p104-100. $200 + $25.   \\n20 GiB VRAM for $225. Very shitty, pretty (but not terribly) slow 20GiB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n102y2q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; the cheapest way to get the most usable VRAM&lt;/p&gt;\\n\\n&lt;p&gt;is 3060 + p104-100. $200 + $25.&lt;br/&gt;\\n20 GiB VRAM for $225. Very shitty, pretty (but not terribly) slow 20GiB.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n102y2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751486434,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12egha","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n119f6w","score":3,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nvidia is dumping 5000 series stock in Europe so this makes sense","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12egha","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nvidia is dumping 5000 series stock in Europe so this makes sense&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12egha/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751513765,"author_flair_text":null,"treatment_tags":[],"created_utc":1751513765,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n11g3qy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"send_replies":true,"parent_id":"t1_n119f6w","score":2,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fair enough. I'm still waiting for 3090s to come back down to the price I bought my first one for. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11g3qy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fair enough. I&amp;#39;m still waiting for 3090s to come back down to the price I bought my first one for. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11g3qy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751501731,"author_flair_text":null,"treatment_tags":[],"created_utc":1751501731,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n119f6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"durden111111","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10h2nq","score":7,"author_fullname":"t2_edafqr22","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I actually live in europe and ebay prices crashed from 1k eur to ~700 eur, some even lower. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n119f6w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually live in europe and ebay prices crashed from 1k eur to ~700 eur, some even lower. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n119f6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751499576,"author_flair_text":null,"treatment_tags":[],"created_utc":1751499576,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n10h2nq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1751490523,"send_replies":true,"parent_id":"t1_n106auj","score":10,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No it hasn't. Maybe in your location on FB Marketplace, but any populated area they're still at eBay prices in the United States. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10h2nq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No it hasn&amp;#39;t. Maybe in your location on FB Marketplace, but any populated area they&amp;#39;re still at eBay prices in the United States. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10h2nq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751490523,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n106auj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"durden111111","can_mod_post":false,"created_utc":1751487426,"send_replies":true,"parent_id":"t3_1lq4bhu","score":6,"author_fullname":"t2_edafqr22","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"3090 had a big price crash recently. no brainer imo if you want vram","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n106auj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3090 had a big price crash recently. no brainer imo if you want vram&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n106auj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751487426,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n11neph","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751504116,"send_replies":true,"parent_id":"t1_n11mzwq","score":3,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"looks like they're about the same price judging from eBay. so it's $800 for a 24GB 3090 or $450 for a 16GB 5060Ti (x2 if you want 32GB RAM and can deal with a little more fiddliness making vLLM or whatever work across cards).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11neph","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;looks like they&amp;#39;re about the same price judging from eBay. so it&amp;#39;s $800 for a 24GB 3090 or $450 for a 16GB 5060Ti (x2 if you want 32GB RAM and can deal with a little more fiddliness making vLLM or whatever work across cards).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11neph/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751504116,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n11mzwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"1BlueSpork","can_mod_post":false,"created_utc":1751503983,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_g6k4i32a3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I bought used RTX 30940 for $800 a few months ago. It works great. I heard they are a bit cheaper now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11mzwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I bought used RTX 30940 for $800 a few months ago. It works great. I heard they are a bit cheaper now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n11mzwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751503983,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12pfp1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751518539,"send_replies":true,"parent_id":"t1_n12k564","score":1,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"if we can buy them outside of Battlematrix 😞","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12pfp1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if we can buy them outside of Battlematrix 😞&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12pfp1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751518539,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n12k564","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cravingbird","can_mod_post":false,"created_utc":1751516151,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_11t39s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Intel b580 24gb when it comes out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12k564","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Intel b580 24gb when it comes out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12k564/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751516151,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n18w8ng","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n16zulv","score":2,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; I think you are getting confused with v340L. Each is essentially 2 GPUs in one with 8+8gb. I do have a pair that I’ve been meaning to benchmark. \\n\\nOh I'm not confused. I am talking about the V340L. I have it too.\\n\\n8+8 = 16. 3x16 = 48.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n18w8ng","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I think you are getting confused with v340L. Each is essentially 2 GPUs in one with 8+8gb. I do have a pair that I’ve been meaning to benchmark. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Oh I&amp;#39;m not confused. I am talking about the V340L. I have it too.&lt;/p&gt;\\n\\n&lt;p&gt;8+8 = 16. 3x16 = 48.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n18w8ng/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751600119,"author_flair_text":null,"treatment_tags":[],"created_utc":1751600119,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n16zulv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MachineZer0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n16ocqd","score":2,"author_fullname":"t2_55kl2a90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you are getting confused with v340L. Each is essentially 2 GPUs in one with 8+8gb. I do have a pair that I’ve been meaning to benchmark. \\n\\nI only see one v340 (32gb/16+16gb non-“L”) being offered for $1200","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n16zulv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you are getting confused with v340L. Each is essentially 2 GPUs in one with 8+8gb. I do have a pair that I’ve been meaning to benchmark. &lt;/p&gt;\\n\\n&lt;p&gt;I only see one v340 (32gb/16+16gb non-“L”) being offered for $1200&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n16zulv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751575844,"author_flair_text":null,"treatment_tags":[],"created_utc":1751575844,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n16ocqd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1751572434,"send_replies":true,"parent_id":"t1_n146m0j","score":2,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can get 3 V340s for that same $170. That would be 48GB of VRAM. And you can even use them as real GPU if you want. Like they have a mini-dp port. You need to flash it to be a Vega 56 to enable that port, but it can be enabled.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n16ocqd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can get 3 V340s for that same $170. That would be 48GB of VRAM. And you can even use them as real GPU if you want. Like they have a mini-dp port. You need to flash it to be a Vega 56 to enable that port, but it can be enabled.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n16ocqd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751572434,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n146m0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MachineZer0","can_mod_post":false,"created_utc":1751545871,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_55kl2a90","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Best bang for the buck VRAM is Nvidia CMP 100-210 16gb VRAM. Currently at $170. It’s from the Volta series which is in between 2080ti and 3090. Think of it as a stronger 2080ti with 50% more VRAM.\\n\\nSee below for comparison\\n\\nhttps://www.reddit.com/r/LocalLLaMA/s/ri0hE6VKD0","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n146m0j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Best bang for the buck VRAM is Nvidia CMP 100-210 16gb VRAM. Currently at $170. It’s from the Volta series which is in between 2080ti and 3090. Think of it as a stronger 2080ti with 50% more VRAM.&lt;/p&gt;\\n\\n&lt;p&gt;See below for comparison&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/s/ri0hE6VKD0\\"&gt;https://www.reddit.com/r/LocalLLaMA/s/ri0hE6VKD0&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n146m0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751545871,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14itv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tmvr","can_mod_post":false,"created_utc":1751550072,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_11qlhv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There is nothing better right now than the 5060Ti 16GB, Every other options where you get more VRAM is either way more expensive (5090 - 32GB), used and expensive (4090 24GB) or used, several years old now, bigger and more power hungry and unstable pricing where some say you can get one for $600 and some say \\"no way\\" (3090 - 24GB).\\n\\nThe 5060Ti 16GB gives you the newest feature set (FP8 and FP4 support), enough bandwidth (448GB/s) to get over 20 tok/s inference when the VRAM usage is maxed out. If you get two cards the inference speed with maxing out the 32GB VRAM would still be 11-12 tok/s even when not using tensor parallel.\\n\\nThe 50 series Super cards are still far in the future, maybe a 5080 Super 24GB will come out towards the end of the year, but the refresh will be probably only early next year tbh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14itv6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is nothing better right now than the 5060Ti 16GB, Every other options where you get more VRAM is either way more expensive (5090 - 32GB), used and expensive (4090 24GB) or used, several years old now, bigger and more power hungry and unstable pricing where some say you can get one for $600 and some say &amp;quot;no way&amp;quot; (3090 - 24GB).&lt;/p&gt;\\n\\n&lt;p&gt;The 5060Ti 16GB gives you the newest feature set (FP8 and FP4 support), enough bandwidth (448GB/s) to get over 20 tok/s inference when the VRAM usage is maxed out. If you get two cards the inference speed with maxing out the 32GB VRAM would still be 11-12 tok/s even when not using tensor parallel.&lt;/p&gt;\\n\\n&lt;p&gt;The 50 series Super cards are still far in the future, maybe a 5080 Super 24GB will come out towards the end of the year, but the refresh will be probably only early next year tbh.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n14itv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751550072,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17y06q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751587068,"send_replies":true,"parent_id":"t1_n17n91g","score":1,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that's interesting, you can get a 12GB for $129 on eBay, but someone mentioned it's hard to scale past two on the same machine?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17y06q","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that&amp;#39;s interesting, you can get a 12GB for $129 on eBay, but someone mentioned it&amp;#39;s hard to scale past two on the same machine?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n17y06q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751587068,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n17n91g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"External_History3184","can_mod_post":false,"created_utc":1751583363,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_e5h6t9is","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Triple 3060 ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17n91g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Triple 3060 &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n17n91g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751583363,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10n96c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10mv8z","score":2,"author_fullname":"t2_3f9vjjno","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good point","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n10n96c","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good point&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10n96c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492390,"author_flair_text":"Llama 70B","treatment_tags":[],"created_utc":1751492390,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n10mv8z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751492272,"send_replies":true,"parent_id":"t1_n10hg8o","score":6,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"4060ti sucks, 288gb/sec bandwidth. Belongs to 2016, not 2025.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10mv8z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4060ti sucks, 288gb/sec bandwidth. Belongs to 2016, not 2025.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10mv8z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492272,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n10hg8o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PraxisOG","can_mod_post":false,"created_utc":1751490634,"send_replies":true,"parent_id":"t3_1lq4bhu","score":2,"author_fullname":"t2_3f9vjjno","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A year ago I spend just over $600 on two rx 6800 gpus(16gb x2) to run 70b at iq3xxs, but 30b models are much more common(qwen, gemma, glm) and more powerful than older 70b models. Its nice to have long context or be able to run 30b at q6, but a single 3090 would be much faster for the current best in midsize LLMs. Point being, it matters what you're trying to run. If its 30b models, get a 3090 unless you're budget constrained like me.\\n\\n  \\nLooking at new gpus, the 5060ti and 4060ti are strong value, followed by the arc a770. Technically the best value would be a bunch of old mining or server cards but you'd be trading price for a software headache and power consumption and slow speed. For under $1000 I reckon you could throw together a bunch of rx 580 8gb cards in one of those mining boards with like 20 pcie slots for 160gb vram, though its not recommended and at that point you could just get an old epyc server with 8 channel ddr4.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10hg8o","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A year ago I spend just over $600 on two rx 6800 gpus(16gb x2) to run 70b at iq3xxs, but 30b models are much more common(qwen, gemma, glm) and more powerful than older 70b models. Its nice to have long context or be able to run 30b at q6, but a single 3090 would be much faster for the current best in midsize LLMs. Point being, it matters what you&amp;#39;re trying to run. If its 30b models, get a 3090 unless you&amp;#39;re budget constrained like me.&lt;/p&gt;\\n\\n&lt;p&gt;Looking at new gpus, the 5060ti and 4060ti are strong value, followed by the arc a770. Technically the best value would be a bunch of old mining or server cards but you&amp;#39;d be trading price for a software headache and power consumption and slow speed. For under $1000 I reckon you could throw together a bunch of rx 580 8gb cards in one of those mining boards with like 20 pcie slots for 160gb vram, though its not recommended and at that point you could just get an old epyc server with 8 channel ddr4.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10hg8o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751490634,"author_flair_text":"Llama 70B","treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12psby","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n12pk3e","score":4,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nope. Well no more than AMD GPUs normally cause. Which is pretty much none if you use Vulkan.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n12psby","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope. Well no more than AMD GPUs normally cause. Which is pretty much none if you use Vulkan.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12psby/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751518704,"author_flair_text":null,"treatment_tags":[],"created_utc":1751518704,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n12pk3e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751518596,"send_replies":true,"parent_id":"t1_n12ffo2","score":1,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"does AMD cause issues?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12pk3e","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does AMD cause issues?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12pk3e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751518596,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n12ffo2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1751514163,"send_replies":true,"parent_id":"t3_1lq4bhu","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"V340. 16GB for $49.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12ffo2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;V340. 16GB for $49.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12ffo2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751514163,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12ekc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1188v7","score":3,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would buy 2 and have my work buy 4 more at that price","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n12ekc4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would buy 2 and have my work buy 4 more at that price&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n12ekc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751513808,"author_flair_text":null,"treatment_tags":[],"created_utc":1751513808,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1188v7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"created_utc":1751499185,"send_replies":true,"parent_id":"t1_n10majc","score":13,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"$550 3090s???","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1188v7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;$550 3090s???&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n1188v7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751499185,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n132fy4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sufficient_Prune3897","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10mvy1","score":2,"author_fullname":"t2_wl169phz5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Modern AMD mostly works, the old ones tho...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n132fy4","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Modern AMD mostly works, the old ones tho...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n132fy4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751525207,"author_flair_text":"Llama 70B","treatment_tags":[],"created_utc":1751525207,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n10mvy1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"starkruzr","can_mod_post":false,"created_utc":1751492278,"send_replies":true,"parent_id":"t1_n10majc","score":2,"author_fullname":"t2_34g6p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"didn't know this was HBM2. don't know whether or not you can use the same toolsets with AMD though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10mvy1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;didn&amp;#39;t know this was HBM2. don&amp;#39;t know whether or not you can use the same toolsets with AMD though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq4bhu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10mvy1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492278,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n10majc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Rich_Repeat_22","can_mod_post":false,"created_utc":1751492099,"send_replies":true,"parent_id":"t3_1lq4bhu","score":-5,"author_fullname":"t2_viufiki6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"$450 for a 5060Ti is bad money when can spend $100 more on used  3090. \\n\\nAt this point even 2 Radeon VII make more sense than a single 5060Ti given the prices.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10majc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;$450 for a 5060Ti is bad money when can spend $100 more on used  3090. &lt;/p&gt;\\n\\n&lt;p&gt;At this point even 2 Radeon VII make more sense than a single 5060Ti given the prices.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq4bhu/best_bang_for_your_buck_in_gpus_for_vram/n10majc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751492099,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq4bhu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
