import{j as e}from"./index-CmSyeZDT.js";import{R as l}from"./RedditPostRenderer-C2Zg39IK.js";import"./index-CiTZuv6Z.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey everyone, I'm building this CLI coding agent right now. My big goal is to turn it into a fully autonomous bot that runs on a server, handles error reports, crash logs, and random issues, then tracks them down and fixes everything on its own.\\n\\nFor the moment, it's just a basic CLI tool packed with features for dealing with files, GitHub, general docs, and a bunch more.If you could test it out on your projects and hit me with some feedback or suggestions for improvements, that'd be super helpful.\\n\\nIm struggling to find any edge cases that arent UI/Command related in my personal usage currently so i think its time to get a little real world responses.\\n\\nI currently support LMStudio, Requesty and OpenRouter.  \\nSo far our testing of local models (devstral, qwen and alike) are working really well. I'd love to hear your feedback, the worse the better. i want to know every issue, minor details and alike, im not here to get my ass kissed like ive seen from others.\\n\\nCheck it out here: [https://github.com/xyOz-dev/LogiQCLI/](https://github.com/xyOz-dev/LogiQCLI/)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"OpenSource CLI Agent with Local models.","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lojgxl","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.8,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1aw5hbygqz","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"spoiler","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751318067,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m building this CLI coding agent right now. My big goal is to turn it into a fully autonomous bot that runs on a server, handles error reports, crash logs, and random issues, then tracks them down and fixes everything on its own.&lt;/p&gt;\\n\\n&lt;p&gt;For the moment, it&amp;#39;s just a basic CLI tool packed with features for dealing with files, GitHub, general docs, and a bunch more.If you could test it out on your projects and hit me with some feedback or suggestions for improvements, that&amp;#39;d be super helpful.&lt;/p&gt;\\n\\n&lt;p&gt;Im struggling to find any edge cases that arent UI/Command related in my personal usage currently so i think its time to get a little real world responses.&lt;/p&gt;\\n\\n&lt;p&gt;I currently support LMStudio, Requesty and OpenRouter.&lt;br/&gt;\\nSo far our testing of local models (devstral, qwen and alike) are working really well. I&amp;#39;d love to hear your feedback, the worse the better. i want to know every issue, minor details and alike, im not here to get my ass kissed like ive seen from others.&lt;/p&gt;\\n\\n&lt;p&gt;Check it out here: &lt;a href=\\"https://github.com/xyOz-dev/LogiQCLI/\\"&gt;https://github.com/xyOz-dev/LogiQCLI/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?auto=webp&amp;s=fa0409bbe1f8d906b07e690113e82f2c908bd53b","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3dd179acc38acfd732283181a8e51635eaa3437b","width":108,"height":54},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=928695f33b8f8c253b957201d3f90b7edfd1c078","width":216,"height":108},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=201f7c43dd1803b2b2734b7b4a4b6950bd52f412","width":320,"height":160},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0a1c0dc84624138992eaa2d9044bf6678b2b2e5","width":640,"height":320},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=018676c67c7de2ab3a59f769d4ae44915960bbb7","width":960,"height":480},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fcdede6cd0f0f2dc640b9529077a43779e4047d9","width":1080,"height":540}],"variants":{"obfuscated":{"source":{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=5a1b09182cb7abfab6e34d0f522a9cb752df77b6","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=a46fb28bed1186816aef51622a659e6fb189f8d1","width":108,"height":54},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=9839832c39e03676be2ad1694802e61d077b81a3","width":216,"height":108},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=c2dc0f4a24af39a5787625b7eb63bf6ee1971e7c","width":320,"height":160},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=46d71849c910a41486c74543bb6ae51aa116ca23","width":640,"height":320},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=c47b467f6881511af166851b15c834fceda323a3","width":960,"height":480},{"url":"https://external-preview.redd.it/XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc.png?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=7c11f469cefd6b8239cac428235a05d9ddc5d34a","width":1080,"height":540}]}},"id":"XOM6yqQSk8OHCQafjKsMt_it6ey7fyVrTrYARfC2cbc"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":true,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lojgxl","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"x8ko_dev","discussion_type":null,"num_comments":13,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/","subreddit_subscribers":493458,"created_utc":1751318067,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0q1dhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable_Patience47","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0puw0j","score":1,"author_fullname":"t2_8levrzbi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I built mine on top of langgraph which I'm pretty experienced with. They come with pre-built multi agent so I guess it wouldn't be too hard in my case. But I'm never a fan of unleashing LLMs for too long, except for deep research because it doesn't have consequences.\\n\\nI actually prefer my terminal assistance to just do a bunch of simple quick troubleshoots for me in case I encounter commands I don't use often or find arguments when I'm too lazy to search in man. It simply helps me keep my workflow going.","edited":false,"author_flair_css_class":null,"name":"t1_n0q1dhu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I built mine on top of langgraph which I&amp;#39;m pretty experienced with. They come with pre-built multi agent so I guess it wouldn&amp;#39;t be too hard in my case. But I&amp;#39;m never a fan of unleashing LLMs for too long, except for deep research because it doesn&amp;#39;t have consequences.&lt;/p&gt;\\n\\n&lt;p&gt;I actually prefer my terminal assistance to just do a bunch of simple quick troubleshoots for me in case I encounter commands I don&amp;#39;t use often or find arguments when I&amp;#39;m too lazy to search in man. It simply helps me keep my workflow going.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lojgxl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0q1dhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751356618,"author_flair_text":null,"collapsed":false,"created_utc":1751356618,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0puw0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pul8b","score":1,"author_fullname":"t2_3yvyd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ya, it's pretty crazy how productive you can be.\\n\\nNow add subagents and have fun debugging that mess like I have :P","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0puw0j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ya, it&amp;#39;s pretty crazy how productive you can be.&lt;/p&gt;\\n\\n&lt;p&gt;Now add subagents and have fun debugging that mess like I have :P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0puw0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751352754,"author_flair_text":null,"treatment_tags":[],"created_utc":1751352754,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pul8b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable_Patience47","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ptqtd","score":1,"author_fullname":"t2_8levrzbi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"mine only took 2 days, including docs and a reddit post","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pul8b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mine only took 2 days, including docs and a reddit post&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0pul8b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751352583,"author_flair_text":null,"treatment_tags":[],"created_utc":1751352583,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ptqtd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"created_utc":1751352098,"send_replies":true,"parent_id":"t1_n0pfk0y","score":1,"author_fullname":"t2_3yvyd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Everyone is rolling their own these days cause it only takes a solid week of programming to set something up with Claude Code. \\n\\nThere is no moat.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ptqtd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everyone is rolling their own these days cause it only takes a solid week of programming to set something up with Claude Code. &lt;/p&gt;\\n\\n&lt;p&gt;There is no moat.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0ptqtd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751352098,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0sjqsq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"x8ko_dev","can_mod_post":false,"created_utc":1751390470,"send_replies":true,"parent_id":"t1_n0pfk0y","score":1,"author_fullname":"t2_1aw5hbygqz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My goal isnt a claude code clone, Im going for removing the human from the loop. This current stage is for testing the manual usage and figuring out the bugs that i havent found.\\n\\nWe already have a 4 stack of agents autonomously fixing issues on 2-3 github repos + half of my merged PRs to roo code were entirely autonomously fixed, pr created, follow ups to changes etc all during my sleep.\\n\\nNext months stage is having a branch entirely run by the model pipeline for new features, automated issue fixing etc. These are all things we've already completed internally over the past few months but now im doing it publicly for those who requested access to it aswell as it being a portfolio project.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0sjqsq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My goal isnt a claude code clone, Im going for removing the human from the loop. This current stage is for testing the manual usage and figuring out the bugs that i havent found.&lt;/p&gt;\\n\\n&lt;p&gt;We already have a 4 stack of agents autonomously fixing issues on 2-3 github repos + half of my merged PRs to roo code were entirely autonomously fixed, pr created, follow ups to changes etc all during my sleep.&lt;/p&gt;\\n\\n&lt;p&gt;Next months stage is having a branch entirely run by the model pipeline for new features, automated issue fixing etc. These are all things we&amp;#39;ve already completed internally over the past few months but now im doing it publicly for those who requested access to it aswell as it being a portfolio project.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0sjqsq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751390470,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pfk0y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable_Patience47","can_mod_post":false,"created_utc":1751344760,"send_replies":true,"parent_id":"t3_1lojgxl","score":2,"author_fullname":"t2_8levrzbi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What are the pros compared to aider? I also built my own because mine supports intuitive context building which is rarely seen. [https://github.com/Twofyw/hi](https://github.com/Twofyw/hi)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pfk0y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are the pros compared to aider? I also built my own because mine supports intuitive context building which is rarely seen. &lt;a href=\\"https://github.com/Twofyw/hi\\"&gt;https://github.com/Twofyw/hi&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0pfk0y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751344760,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lojgxl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0nplkc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0np680","score":-1,"author_fullname":"t2_3yvyd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'll eventually be adding a template system so one can modify the prompt per model, but for now it's the same for most models.\\n\\nClaude 4 performs identically to Claude Code (minus extended thinking cause I haven't implemented it yet). Most models suck at agentic workflows in general though, nothing I can really do about that. Deepseek v3 for instance needs to be practically strangled to use file write tools.","edited":false,"author_flair_css_class":null,"name":"t1_n0nplkc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll eventually be adding a template system so one can modify the prompt per model, but for now it&amp;#39;s the same for most models.&lt;/p&gt;\\n\\n&lt;p&gt;Claude 4 performs identically to Claude Code (minus extended thinking cause I haven&amp;#39;t implemented it yet). Most models suck at agentic workflows in general though, nothing I can really do about that. Deepseek v3 for instance needs to be practically strangled to use file write tools.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lojgxl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0nplkc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751322232,"author_flair_text":null,"collapsed":false,"created_utc":1751322232,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0np680","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Old_Standard6804","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nobye","score":2,"author_fullname":"t2_iizyolq97","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean these days everyone is racing to the top, and it is a competition by definition as u posted your project in here and multiple threads so u want exposure. Maybe dont steal prompts and learn to write them for your project specifically ðŸ˜‰","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0np680","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean these days everyone is racing to the top, and it is a competition by definition as u posted your project in here and multiple threads so u want exposure. Maybe dont steal prompts and learn to write them for your project specifically ðŸ˜‰&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0np680/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751322095,"author_flair_text":null,"treatment_tags":[],"created_utc":1751322095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nobye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nny5y","score":0,"author_fullname":"t2_3yvyd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not a competition. Also I stole my prompts from Claude Code so idk what to tell you","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0nobye","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not a competition. Also I stole my prompts from Claude Code so idk what to tell you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0nobye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751321823,"author_flair_text":null,"treatment_tags":[],"created_utc":1751321823,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nny5y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Old_Standard6804","can_mod_post":false,"created_utc":1751321701,"send_replies":true,"parent_id":"t1_n0ne7c4","score":2,"author_fullname":"t2_iizyolq97","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This project feels cleaner than yours and I'm also seeing much better results in comparison in terms of agentic use, maybe use it as a learning experience for prompting etc. Others may feel different but in my 30m of testing that's my opinions as of right now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nny5y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This project feels cleaner than yours and I&amp;#39;m also seeing much better results in comparison in terms of agentic use, maybe use it as a learning experience for prompting etc. Others may feel different but in my 30m of testing that&amp;#39;s my opinions as of right now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0nny5y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751321701,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0nlazh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0nekp9","score":-1,"author_fullname":"t2_3yvyd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah I have Qwen3 1.7 doing tool calling too (it's actually the only model I've really tested with my framework on ollama &gt;.&gt;). But it's not good at it. You can't rely on it autonomously is my point.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0nlazh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah I have Qwen3 1.7 doing tool calling too (it&amp;#39;s actually the only model I&amp;#39;ve really tested with my framework on ollama &amp;gt;.&amp;gt;). But it&amp;#39;s not good at it. You can&amp;#39;t rely on it autonomously is my point.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0nlazh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751320850,"author_flair_text":null,"treatment_tags":[],"created_utc":1751320850,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0nekp9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"x8ko_dev","can_mod_post":false,"created_utc":1751318771,"send_replies":true,"parent_id":"t1_n0ne7c4","score":1,"author_fullname":"t2_1aw5hbygqz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"With my integration even models like Qwen 3 1.7B can reliably call tools. Give it a try, the bigger the model you can handle the better, but even the new age baby models can be useful at applying diffs to add comments to functions or other basic tasks like reading and understanding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0nekp9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With my integration even models like Qwen 3 1.7B can reliably call tools. Give it a try, the bigger the model you can handle the better, but even the new age baby models can be useful at applying diffs to add comments to functions or other basic tasks like reading and understanding.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lojgxl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0nekp9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751318771,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ne7c4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"amranu","can_mod_post":false,"created_utc":1751318659,"send_replies":true,"parent_id":"t3_1lojgxl","score":-1,"author_fullname":"t2_3yvyd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's a bit more specific than what I've built. I have a CLI based agent framework already built [here](https://github.com/amranu/cli-agent). It supports openrouter, ollama, and a few other APIs as well as json-streaming ala Claude Code.\\n\\nI don't think local models are really at all good at tool use yet, from what I've seen. But I don't have hardware for running the bigger ones.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ne7c4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a bit more specific than what I&amp;#39;ve built. I have a CLI based agent framework already built &lt;a href=\\"https://github.com/amranu/cli-agent\\"&gt;here&lt;/a&gt;. It supports openrouter, ollama, and a few other APIs as well as json-streaming ala Claude Code.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think local models are really at all good at tool use yet, from what I&amp;#39;ve seen. But I don&amp;#39;t have hardware for running the bigger ones.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lojgxl/opensource_cli_agent_with_local_models/n0ne7c4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751318659,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lojgxl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
