import{j as e}from"./index-CjwP30j7.js";import{R as l}from"./RedditPostRenderer-BbYuEq_V.js";import"./index-C-yxLSPN.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I’ve developed a working memory engine for LLM-based chat applications, designed primarily for long-term roleplay and simulation stability. It’s called CoreWeaver, and it’s built to address issues around persistent memory, decision consistency, and emotional context management.\\n\\nTechnical Summary:\\n\\t•\\tBuilt in JavaScript as a modular plugin\\n\\t•\\tCompatible with SillyTavern and local LLMs\\n\\t•\\tStores long-term memory entries with metadata (type, emotion, impact)\\n\\t•\\tTracks emotional pressure over time and influences AI decisions\\n\\t•\\tSupports timeline branching for parallel scenarios or alternate chats\\n\\t•\\tIncludes token-optimized compression to reduce memory bloat\\n\\t•\\tFully character-specific memory folders with timeline control\\n\\t•\\tReflective decision engine logs choices and emotional drift\\n\\nStatus:\\n\\t•\\tEngine was functional by 06/29/2025\\n\\t•\\tCurrently integrating into a full companion app and testing with OpenAI and free local models via Horde\\n\\t•\\tCodebase is closed-source for now but may offer technical previews later for feedback\\n\\nMy Role:\\nThis is a solo project—I built and tested the full framework myself over the past month. I’m currently validating its use in AI companion systems, but I believe it has strong potential for interactive NPC behavior in games, simulation RP, and emotionally consistent storytelling.\\n\\nLet me know if anyone else is working on similar long-term memory engines. Happy to exchange ideas.\\n\\n– Mike","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"[Proof of Concept] CoreWeaver – AI Memory Engine for Long-Term Context, Emotional State Tracking, and Branching Timelines","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lpproa","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.89,"author_flair_background_color":null,"subreddit_type":"public","ups":7,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_b1usqotg","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":7,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751441836,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve developed a working memory engine for LLM-based chat applications, designed primarily for long-term roleplay and simulation stability. It’s called CoreWeaver, and it’s built to address issues around persistent memory, decision consistency, and emotional context management.&lt;/p&gt;\\n\\n&lt;p&gt;Technical Summary:\\n    • Built in JavaScript as a modular plugin\\n    • Compatible with SillyTavern and local LLMs\\n    • Stores long-term memory entries with metadata (type, emotion, impact)\\n    • Tracks emotional pressure over time and influences AI decisions\\n    • Supports timeline branching for parallel scenarios or alternate chats\\n    • Includes token-optimized compression to reduce memory bloat\\n    • Fully character-specific memory folders with timeline control\\n    • Reflective decision engine logs choices and emotional drift&lt;/p&gt;\\n\\n&lt;p&gt;Status:\\n    • Engine was functional by 06/29/2025\\n    • Currently integrating into a full companion app and testing with OpenAI and free local models via Horde\\n    • Codebase is closed-source for now but may offer technical previews later for feedback&lt;/p&gt;\\n\\n&lt;p&gt;My Role:\\nThis is a solo project—I built and tested the full framework myself over the past month. I’m currently validating its use in AI companion systems, but I believe it has strong potential for interactive NPC behavior in games, simulation RP, and emotionally consistent storytelling.&lt;/p&gt;\\n\\n&lt;p&gt;Let me know if anyone else is working on similar long-term memory engines. Happy to exchange ideas.&lt;/p&gt;\\n\\n&lt;p&gt;– Mike&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lpproa","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Separate-Toe409","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/","subreddit_subscribers":494001,"created_utc":1751441836,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0y25ni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Separate-Toe409","can_mod_post":false,"created_utc":1751465460,"send_replies":true,"parent_id":"t1_n0x6d0d","score":2,"author_fullname":"t2_b1usqotg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, sounds like you’re building something cool too. Definitely agree — a lot of models fall short when it comes to handling emotional nuance, either due to censorship or just lacking the context to behave believably in social/emotional scenarios.\\n\\nRight now I’m testing primarily with GPT-4 (Turbo/o) and some Horde-hosted local models for the companion plugin. Most models need a lot of scaffolding or prep to get emotionally consistent behavior, which is where my engine steps in — it handles emotional memory and pressure separately, then feeds optimized context back to guide the LLM’s response patterns.\\n\\nI’m not ready to release details yet, but once I finish integration I might offer technical previews for feedback. Happy to compare notes later on if that helps us both level up our systems.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y25ni","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, sounds like you’re building something cool too. Definitely agree — a lot of models fall short when it comes to handling emotional nuance, either due to censorship or just lacking the context to behave believably in social/emotional scenarios.&lt;/p&gt;\\n\\n&lt;p&gt;Right now I’m testing primarily with GPT-4 (Turbo/o) and some Horde-hosted local models for the companion plugin. Most models need a lot of scaffolding or prep to get emotionally consistent behavior, which is where my engine steps in — it handles emotional memory and pressure separately, then feeds optimized context back to guide the LLM’s response patterns.&lt;/p&gt;\\n\\n&lt;p&gt;I’m not ready to release details yet, but once I finish integration I might offer technical previews for feedback. Happy to compare notes later on if that helps us both level up our systems.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpproa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/n0y25ni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751465460,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0x6d0d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"terminoid_","can_mod_post":false,"created_utc":1751453790,"send_replies":true,"parent_id":"t3_1lpproa","score":3,"author_fullname":"t2_1iu07dnz2i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i'm doing some stuff along these lines. big5 personality facets, emotional state, behavioural/emotional response to social situations, etc.  i've distilled my own NNs to speed things up.\\n\\nwhich models are you finding work best with it? all of my testing has shown many models by default kinda suck in emotional intelligence. either they're censored and refuse to act in certain ways, or even choose wildly inappropriate responses to certain situations. better prompting can help a bit for some of the models tho...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x6d0d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m doing some stuff along these lines. big5 personality facets, emotional state, behavioural/emotional response to social situations, etc.  i&amp;#39;ve distilled my own NNs to speed things up.&lt;/p&gt;\\n\\n&lt;p&gt;which models are you finding work best with it? all of my testing has shown many models by default kinda suck in emotional intelligence. either they&amp;#39;re censored and refuse to act in certain ways, or even choose wildly inappropriate responses to certain situations. better prompting can help a bit for some of the models tho...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/n0x6d0d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751453790,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpproa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0wlf3j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"casual_penguin_","can_mod_post":false,"created_utc":1751441994,"send_replies":true,"parent_id":"t3_1lpproa","score":1,"author_fullname":"t2_23b20k8x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"interesting stuff","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wlf3j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;interesting stuff&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/n0wlf3j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751441994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpproa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0y5z8d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maxxim69","can_mod_post":false,"created_utc":1751466580,"send_replies":true,"parent_id":"t1_n0xkao7","score":1,"author_fullname":"t2_8pc5059","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That was a royal \\"we\\", I presume?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y5z8d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That was a royal &amp;quot;we&amp;quot;, I presume?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpproa","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/n0y5z8d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751466580,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xkao7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Pipe-5151","can_mod_post":false,"created_utc":1751459549,"send_replies":true,"parent_id":"t3_1lpproa","score":0,"author_fullname":"t2_uxbdufm8b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it open source? If not, then we don't care","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xkao7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it open source? If not, then we don&amp;#39;t care&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpproa/proof_of_concept_coreweaver_ai_memory_engine_for/n0xkao7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751459549,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpproa","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
