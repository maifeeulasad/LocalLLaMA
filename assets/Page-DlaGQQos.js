import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I own a mid size electrical contracting bussiness, about 35 employees. I'm thinking of implementing a local ai server maybe mixtral 8x7B to increase the efficiency of the business. My main reason is for book keeping/receipt processing, finance etc as of now but I'm hoping to train on other areas. any other ideas on how this could help my business. Is it worth implementing?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Local LLM for business","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltcwbx","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.75,"author_flair_background_color":null,"subreddit_type":"public","ups":10,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_8jgmm760e","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":10,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751838082,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I own a mid size electrical contracting bussiness, about 35 employees. I&amp;#39;m thinking of implementing a local ai server maybe mixtral 8x7B to increase the efficiency of the business. My main reason is for book keeping/receipt processing, finance etc as of now but I&amp;#39;m hoping to train on other areas. any other ideas on how this could help my business. Is it worth implementing?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1ltcwbx","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Acceptable_Factor817","discussion_type":null,"num_comments":29,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/","subreddit_subscribers":496034,"created_utc":1751838082,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qpgah","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Guilty_Serve","can_mod_post":false,"created_utc":1751855203,"send_replies":true,"parent_id":"t1_n1pke95","score":4,"author_fullname":"t2_3ybq2hgt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The funny thing is that a lot of people in business say they'll worry about LLMs taking their jobs when they start having LLMs do their financials like OP wants.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qpgah","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The funny thing is that a lot of people in business say they&amp;#39;ll worry about LLMs taking their jobs when they start having LLMs do their financials like OP wants.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qpgah/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n1pke95","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Failiiix","can_mod_post":false,"created_utc":1751840341,"send_replies":true,"parent_id":"t3_1ltcwbx","score":18,"author_fullname":"t2_xbip5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mmh. I would really think hard about the workload you want to accomplish. Using LLMs, even Chatgpt with anything that needs to be 100% correct, like finances and so on, is, if you plan to use a pure LLM no good idea. \\n\\nLetting it write the texts for receipts or something like that is maybe doable. \\n\\nCan you describe the exact workloads and maybe you find advice here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pke95","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mmh. I would really think hard about the workload you want to accomplish. Using LLMs, even Chatgpt with anything that needs to be 100% correct, like finances and so on, is, if you plan to use a pure LLM no good idea. &lt;/p&gt;\\n\\n&lt;p&gt;Letting it write the texts for receipts or something like that is maybe doable. &lt;/p&gt;\\n\\n&lt;p&gt;Can you describe the exact workloads and maybe you find advice here.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pke95/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751840341,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qponw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Guilty_Serve","can_mod_post":false,"created_utc":1751855293,"send_replies":true,"parent_id":"t1_n1ptc0r","score":3,"author_fullname":"t2_3ybq2hgt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How'd you do that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qponw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How&amp;#39;d you do that?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qponw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855293,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1rn2vo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HiddenoO","can_mod_post":false,"created_utc":1751871056,"send_replies":true,"parent_id":"t1_n1ptc0r","score":2,"author_fullname":"t2_8127x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;If you need an LLM to forecast, that might be more useful.\\n\\nFor almost all forecasting, you're better off just training a small ML model yourself. The type of model depends on the actual task.\\n\\nI'm honestly confused why anybody would want to use LLMs for forecasting. That's not what they're trained for and the little research done on using LLMs for forecasting has shown that they perform at best on par with previous ML architectures.","edited":1751871282,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1rn2vo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;If you need an LLM to forecast, that might be more useful.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;For almost all forecasting, you&amp;#39;re better off just training a small ML model yourself. The type of model depends on the actual task.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m honestly confused why anybody would want to use LLMs for forecasting. That&amp;#39;s not what they&amp;#39;re trained for and the little research done on using LLMs for forecasting has shown that they perform at best on par with previous ML architectures.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1rn2vo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751871056,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ptc0r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teleprint-me","can_mod_post":false,"created_utc":1751843460,"send_replies":true,"parent_id":"t3_1ltcwbx","score":13,"author_fullname":"t2_slcrtxpr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can automate book keeping without LLMs. I know because I've done it. It'll be more accurate in the long run.\\n\\n\\nEven if the LLM is correct 95% of the time, that 5% margin of error will come back to bite you.\\n\\n\\nLLMs are autoregressive, so they're just making statistical predictions. There will always be a margin of error.\\n\\n\\nIf you need an LLM to forecast, that might be more useful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ptc0r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can automate book keeping without LLMs. I know because I&amp;#39;ve done it. It&amp;#39;ll be more accurate in the long run.&lt;/p&gt;\\n\\n&lt;p&gt;Even if the LLM is correct 95% of the time, that 5% margin of error will come back to bite you.&lt;/p&gt;\\n\\n&lt;p&gt;LLMs are autoregressive, so they&amp;#39;re just making statistical predictions. There will always be a margin of error.&lt;/p&gt;\\n\\n&lt;p&gt;If you need an LLM to forecast, that might be more useful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1ptc0r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751843460,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qrb7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pitchblackfriday","can_mod_post":false,"created_utc":1751855927,"send_replies":true,"parent_id":"t3_1ltcwbx","score":6,"author_fullname":"t2_1dt829ipgg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; book keeping/receipt processing\\n\\nNope, nope, nope. Try automation tools like n8n + traditional bookkeeping software.\\n\\nCan't trust AI on that.\\n\\n&gt; finance\\n\\nFor analysis, forecast, and summarization, yes.","edited":1751876623,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qrb7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;book keeping/receipt processing&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Nope, nope, nope. Try automation tools like n8n + traditional bookkeeping software.&lt;/p&gt;\\n\\n&lt;p&gt;Can&amp;#39;t trust AI on that.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;finance&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;For analysis, forecast, and summarization, yes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qrb7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855927,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1r6dhg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Background-Summer-56","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1qk4yk","score":1,"author_fullname":"t2_zviwvs2tn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm also an electrical contractor. Your use case isn't what LLM's are suited to. LLM's are suited to things like speeding up the process for electrical standard searching, finding code references when you need, and searching manuals for your equipment in the field. Another potential use case is to have a specific set of cross-references and informational notes for plans specific to each architect and then seeing if any informational notes are present that aren't in your predefined list.\\n\\nI'm actually working on a project like this to help speed up access to manual libraries for industrial technicians.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1r6dhg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m also an electrical contractor. Your use case isn&amp;#39;t what LLM&amp;#39;s are suited to. LLM&amp;#39;s are suited to things like speeding up the process for electrical standard searching, finding code references when you need, and searching manuals for your equipment in the field. Another potential use case is to have a specific set of cross-references and informational notes for plans specific to each architect and then seeing if any informational notes are present that aren&amp;#39;t in your predefined list.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m actually working on a project like this to help speed up access to manual libraries for industrial technicians.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1r6dhg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751862339,"author_flair_text":null,"treatment_tags":[],"created_utc":1751862339,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qk4yk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Acceptable_Factor817","can_mod_post":false,"created_utc":1751853200,"send_replies":true,"parent_id":"t1_n1q2ayl","score":2,"author_fullname":"t2_8jgmm760e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was thinking about bringing on that 36th employee, I do believe AI is the future so I want to be as proactive as I can. That being said I also want to be involved in the process, tech/ai is where my passion lies and unfortunately I’ve lost sight of that due to being preoccupied with building the business the passed couple years. The business is now in a place where I can focus my attention on projects like this. Side note- I have 8 3090’s that I used to mine crypto with that can now be repurposed for this. I don’t mind investing my time into learning this as I see a huge upside. I’m also willing to make the financial investment needed. The “home run” for me is to have a model that can assist in reading drawings, estimating labor and material and streamline the quotation/proposal process. That is the largest bottle neck and an incredibly painstaking process in my industry ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qk4yk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was thinking about bringing on that 36th employee, I do believe AI is the future so I want to be as proactive as I can. That being said I also want to be involved in the process, tech/ai is where my passion lies and unfortunately I’ve lost sight of that due to being preoccupied with building the business the passed couple years. The business is now in a place where I can focus my attention on projects like this. Side note- I have 8 3090’s that I used to mine crypto with that can now be repurposed for this. I don’t mind investing my time into learning this as I see a huge upside. I’m also willing to make the financial investment needed. The “home run” for me is to have a model that can assist in reading drawings, estimating labor and material and streamline the quotation/proposal process. That is the largest bottle neck and an incredibly painstaking process in my industry &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qk4yk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853200,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1thy7y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tempetemplar","can_mod_post":false,"created_utc":1751900881,"send_replies":true,"parent_id":"t1_n1q2ayl","score":1,"author_fullname":"t2_atvw2aj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Great suggestion","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1thy7y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great suggestion&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1thy7y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751900881,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1q2ayl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teachersecret","can_mod_post":false,"created_utc":1751846644,"send_replies":true,"parent_id":"t3_1ltcwbx","score":3,"author_fullname":"t2_ddyte","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'd use something better than mixtral 8x7b, to start. That's a relatively ancient model in modern terms. Stick with one of the 32b or the 30ba3b qwen models or one of the mid-sized mistrals for a typical 24gb vram setup (a rig locally with a 3090 or a 4090 in it is typical for small scale work, or you could grab something for bigger deepseek style models like a maxed out mac studio if you want to go silly). If you want something lighter, there are heavy duty thinking models in the 4b-8b range that can actually do remarkable work if you set them up right, or the afformentioned 30ba3b qwen. Being up to date on the model is important here - the benchmark difference between modern models and that old 8x7b is substantial.\\n\\nThat said, I think your real issue here is the things you want to do are currently on the fringe of what AI can do with an expert who knows exactly how to set up/tune them. If you're already running 35 employees, you're probably already busy, and I suspect you underestimate how much there is to know here. I mean, the knowledge involved just in producing a good dataset to train on and arrive at the kind of input-&gt;output you want (or the prompt engineering/agentic process to do it) is going to be a lot to set up unless you know -exactly- what you're doing.\\n\\nI have no doubt you understand the business you're in and know (more or less) what you want that LLM to output, but as a business owner handling such a large number of employees, if you -really- want to use an LLM to do something, you should probably look for someone skilled in that area to make into employee 36, at least long enough to get things up and running.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1q2ayl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d use something better than mixtral 8x7b, to start. That&amp;#39;s a relatively ancient model in modern terms. Stick with one of the 32b or the 30ba3b qwen models or one of the mid-sized mistrals for a typical 24gb vram setup (a rig locally with a 3090 or a 4090 in it is typical for small scale work, or you could grab something for bigger deepseek style models like a maxed out mac studio if you want to go silly). If you want something lighter, there are heavy duty thinking models in the 4b-8b range that can actually do remarkable work if you set them up right, or the afformentioned 30ba3b qwen. Being up to date on the model is important here - the benchmark difference between modern models and that old 8x7b is substantial.&lt;/p&gt;\\n\\n&lt;p&gt;That said, I think your real issue here is the things you want to do are currently on the fringe of what AI can do with an expert who knows exactly how to set up/tune them. If you&amp;#39;re already running 35 employees, you&amp;#39;re probably already busy, and I suspect you underestimate how much there is to know here. I mean, the knowledge involved just in producing a good dataset to train on and arrive at the kind of input-&amp;gt;output you want (or the prompt engineering/agentic process to do it) is going to be a lot to set up unless you know -exactly- what you&amp;#39;re doing.&lt;/p&gt;\\n\\n&lt;p&gt;I have no doubt you understand the business you&amp;#39;re in and know (more or less) what you want that LLM to output, but as a business owner handling such a large number of employees, if you -really- want to use an LLM to do something, you should probably look for someone skilled in that area to make into employee 36, at least long enough to get things up and running.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1q2ayl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751846644,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1pngw5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MrWeirdoFace","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pkhpv","score":1,"author_fullname":"t2_12e249","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can't say how useful an LLM will be to your business, but if you want to start experiment to get a feel for what's possible, I would simply download and install [LmStudio](https://lmstudio.ai/). It has an llm browser built right in to search for and download local LLM models.  I'd recommend checking out some of the more reliable popular ones, like Gemma 3, Qwen 2.5 instruct, and Qwen 3.  You usually want the highest parameter models your videocard can handle (vram limitations) with the largest quant you can handle.  For example. I was just tinkering with a Qwen3 30B model with a quant of 4, as it fits into my 24 GB of vram easily with some overhead (18.68 GB size model).  I know that lmstudio also recent added the ability to connect to an mcp server, but I haven't tried it yet.  Either way, it's one of the easiest apps to use and try out local LLMs with. For the record you CAN use regular RAM, but it's often ridiculously slow, depending on your setup.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1pngw5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t say how useful an LLM will be to your business, but if you want to start experiment to get a feel for what&amp;#39;s possible, I would simply download and install &lt;a href=\\"https://lmstudio.ai/\\"&gt;LmStudio&lt;/a&gt;. It has an llm browser built right in to search for and download local LLM models.  I&amp;#39;d recommend checking out some of the more reliable popular ones, like Gemma 3, Qwen 2.5 instruct, and Qwen 3.  You usually want the highest parameter models your videocard can handle (vram limitations) with the largest quant you can handle.  For example. I was just tinkering with a Qwen3 30B model with a quant of 4, as it fits into my 24 GB of vram easily with some overhead (18.68 GB size model).  I know that lmstudio also recent added the ability to connect to an mcp server, but I haven&amp;#39;t tried it yet.  Either way, it&amp;#39;s one of the easiest apps to use and try out local LLMs with. For the record you CAN use regular RAM, but it&amp;#39;s often ridiculously slow, depending on your setup.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pngw5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751841422,"author_flair_text":null,"treatment_tags":[],"created_utc":1751841422,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1po5rk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Salty-Garage7777","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pkhpv","score":1,"author_fullname":"t2_14m2ycs468","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Plan the exact steps you and your specialists believe the LLM should accomplish, create some mock data resembling very much the data you're gonna use, test out the best LLMs, if they can't do it, do the tests with the new bunch of newer LLMs. It's very probable that your expectations are too high. 😉","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1po5rk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Plan the exact steps you and your specialists believe the LLM should accomplish, create some mock data resembling very much the data you&amp;#39;re gonna use, test out the best LLMs, if they can&amp;#39;t do it, do the tests with the new bunch of newer LLMs. It&amp;#39;s very probable that your expectations are too high. 😉&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1po5rk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751841667,"author_flair_text":null,"treatment_tags":[],"created_utc":1751841667,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1powlv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"0xFatWhiteMan","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pkhpv","score":1,"author_fullname":"t2_pz2dkuedp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Get a Mac mini or studio. \\n\\nAlso anything less 12b is unusable imo.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1powlv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Get a Mac mini or studio. &lt;/p&gt;\\n\\n&lt;p&gt;Also anything less 12b is unusable imo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1powlv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751841928,"author_flair_text":null,"treatment_tags":[],"created_utc":1751841928,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qqg1l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Guilty_Serve","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pkhpv","score":1,"author_fullname":"t2_3ybq2hgt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think they meant online as use ChatGPT, but more so provisioning cloud based graphics cards and an LLM so your company owns the data. Also I wouldn't fine tune when you could create a good RAG model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qqg1l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think they meant online as use ChatGPT, but more so provisioning cloud based graphics cards and an LLM so your company owns the data. Also I wouldn&amp;#39;t fine tune when you could create a good RAG model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qqg1l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751855590,"author_flair_text":null,"treatment_tags":[],"created_utc":1751855590,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1pkhpv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Acceptable_Factor817","can_mod_post":false,"created_utc":1751840375,"send_replies":true,"parent_id":"t1_n1pix7n","score":8,"author_fullname":"t2_8jgmm760e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don’t feel to comfortable uploading company data ie financial data, bank statements etc into public models. Especially customer data. Also I want to be able to train the model on my data, set guardrails and tailor the model to my industry rather than a very broad data set.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pkhpv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t feel to comfortable uploading company data ie financial data, bank statements etc into public models. Especially customer data. Also I want to be able to train the model on my data, set guardrails and tailor the model to my industry rather than a very broad data set.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pkhpv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751840375,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1pix7n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"0xFatWhiteMan","can_mod_post":false,"created_utc":1751839833,"send_replies":true,"parent_id":"t3_1ltcwbx","score":4,"author_fullname":"t2_pz2dkuedp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just start with an online one first, see if it pays off.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pix7n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just start with an online one first, see if it pays off.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pix7n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751839833,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ptfdb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jingyangjoon","can_mod_post":false,"created_utc":1751843493,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_14bz0d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi, I am doing something similar to the fabrication business. I also understand the importance of data security and privacy in engineering drawings and such. \\nIf you are interested in connecting with me, please DM me. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ptfdb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, I am doing something similar to the fabrication business. I also understand the importance of data security and privacy in engineering drawings and such. \\nIf you are interested in connecting with me, please DM me. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1ptfdb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751843493,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1pyp7x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WaifuEngine","can_mod_post":false,"created_utc":1751845347,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_bhsjkxeq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"These models are no robust enough to do what your thinking second you would need a UI UX","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pyp7x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These models are no robust enough to do what your thinking second you would need a UI UX&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pyp7x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751845347,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1q1bex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HornyGooner4401","can_mod_post":false,"created_utc":1751846280,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_1fetkxu1xm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"After reading your reply,  I think a traditional program would be much better for your use case than AI as it's prone to making mistakes and hallucinating.\\n\\nI recommend you use LLM as some sort of interface between the actual program and user, i.e. use data from the program as context and use function calls rather than have it handle everything","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1q1bex","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;After reading your reply,  I think a traditional program would be much better for your use case than AI as it&amp;#39;s prone to making mistakes and hallucinating.&lt;/p&gt;\\n\\n&lt;p&gt;I recommend you use LLM as some sort of interface between the actual program and user, i.e. use data from the program as context and use function calls rather than have it handle everything&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1q1bex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751846280,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1q6w27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"admajic","can_mod_post":false,"created_utc":1751848340,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_60b9farf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You'd probably need a hybrid approach. I wanted AI to read a csv and it sucked. So I wrote a small python script with regex to extract the data. You'd need to have the exact same format for this program every time. For that exact report bank statement. \\n\\nThen you can get ai to look at it via RAG. You would need at least qwen3 14b or 32b. With a small company you would probably get away with a 5090 rtx server. \\n\\nMight be doable with a 3090 rtx but I haven't tried.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1q6w27","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;d probably need a hybrid approach. I wanted AI to read a csv and it sucked. So I wrote a small python script with regex to extract the data. You&amp;#39;d need to have the exact same format for this program every time. For that exact report bank statement. &lt;/p&gt;\\n\\n&lt;p&gt;Then you can get ai to look at it via RAG. You would need at least qwen3 14b or 32b. With a small company you would probably get away with a 5090 rtx server. &lt;/p&gt;\\n\\n&lt;p&gt;Might be doable with a 3090 rtx but I haven&amp;#39;t tried.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1q6w27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751848340,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qlbpp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Acceptable_Factor817","can_mod_post":false,"created_utc":1751853643,"send_replies":true,"parent_id":"t1_n1qk1gu","score":2,"author_fullname":"t2_8jgmm760e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Were non union, your not gunna be happy with the hourly rate lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qlbpp","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Were non union, your not gunna be happy with the hourly rate lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qlbpp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853643,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1qk1gu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rubntagme","can_mod_post":false,"created_utc":1751853164,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_9u03lebo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ill help you for journeyman pay","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1qk1gu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ill help you for journeyman pay&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qk1gu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751853164,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1s59os","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jain-nivedit","can_mod_post":false,"created_utc":1751881888,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_1nb525ak26","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I could help you with this, have built workflows for this exact use case of understanding financial docs- accuracy is key","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1s59os","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I could help you with this, have built workflows for this exact use case of understanding financial docs- accuracy is key&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1s59os/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751881888,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1w4e03","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SrDevMX","can_mod_post":false,"created_utc":1751930450,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_i7o4raau","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm researching to do similar things:  a Local LLM + MCP servers for SaaS applications so I can improve the flexibility and productivity of business users","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1w4e03","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m researching to do similar things:  a Local LLM + MCP servers for SaaS applications so I can improve the flexibility and productivity of business users&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1w4e03/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751930450,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1pktqi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Failiiix","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pi3dz","score":6,"author_fullname":"t2_xbip5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The workloads you describe are better solved by traditional logic systems.. No need for LLMs. Remember, they are based on probability..","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1pktqi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The workloads you describe are better solved by traditional logic systems.. No need for LLMs. Remember, they are based on probability..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pktqi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751840492,"author_flair_text":null,"treatment_tags":[],"created_utc":1751840492,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1qrsf6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Unlikely_Track_5154","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1pi3dz","score":1,"author_fullname":"t2_r783n0ey","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hire another estimator...\\n\\nExpand your customer base.\\n\\nSource : The estimator hired to expand the customer base.\\n\\nYes ai can do it, but you are better off using deterministic approaches","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1qrsf6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hire another estimator...&lt;/p&gt;\\n\\n&lt;p&gt;Expand your customer base.&lt;/p&gt;\\n\\n&lt;p&gt;Source : The estimator hired to expand the customer base.&lt;/p&gt;\\n\\n&lt;p&gt;Yes ai can do it, but you are better off using deterministic approaches&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1qrsf6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751856114,"author_flair_text":null,"treatment_tags":[],"created_utc":1751856114,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1pi3dz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Acceptable_Factor817","can_mod_post":false,"created_utc":1751839550,"send_replies":true,"parent_id":"t1_n1petpu","score":2,"author_fullname":"t2_8jgmm760e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We provide commercial electrical and communications wiring services. For example we have a hotel project currently underway, we are wiring all the suites with electrical and cat6 cabling. \\n\\nOur customers are large general contractors and usually contact us via email. We usually receive electrical drawings for a project, those drawing will go to our in house estimator who with put together a proposal to be submitted for tender to the client. This is a major choke point, estimating is extremely time consuming and costly. \\n\\nI think Labour scheduling, material estimation, and keeping track of site progress/PNL can all be  done more efficiently using AI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pi3dz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We provide commercial electrical and communications wiring services. For example we have a hotel project currently underway, we are wiring all the suites with electrical and cat6 cabling. &lt;/p&gt;\\n\\n&lt;p&gt;Our customers are large general contractors and usually contact us via email. We usually receive electrical drawings for a project, those drawing will go to our in house estimator who with put together a proposal to be submitted for tender to the client. This is a major choke point, estimating is extremely time consuming and costly. &lt;/p&gt;\\n\\n&lt;p&gt;I think Labour scheduling, material estimation, and keeping track of site progress/PNL can all be  done more efficiently using AI&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltcwbx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pi3dz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751839550,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1petpu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"That_Neighborhood345","can_mod_post":false,"created_utc":1751838463,"send_replies":true,"parent_id":"t3_1ltcwbx","score":1,"author_fullname":"t2_sevbemsb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hi, could you share some more details about your business.\\n\\n1.  What is the service / product your business provides to customers?  Please give some details.\\n\\n2.  What kind of interaction have your customers with your company?  Chat, Phone, email, etc.\\n\\n3.  How do you handle the paperwork?  Any choke point you currently have in your business processes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1petpu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi, could you share some more details about your business.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;What is the service / product your business provides to customers?  Please give some details.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;What kind of interaction have your customers with your company?  Chat, Phone, email, etc.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;How do you handle the paperwork?  Any choke point you currently have in your business processes.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1petpu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751838463,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1pztir","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"searchblox_searchai","can_mod_post":false,"created_utc":1751845743,"send_replies":true,"parent_id":"t3_1ltcwbx","score":0,"author_fullname":"t2_l30sixm4v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, you can enable a local RAG solution with local chatbot and assistant/copilot to enable access to the documents/receipts/invoices/projects/photos etc with a platform like SearchAI. Start with a packaged solution and then you can expand or build on your own if required. You can do it all onprem with no external costs or APIs. [https://www.searchblox.com/downloads](https://www.searchblox.com/downloads)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1pztir","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, you can enable a local RAG solution with local chatbot and assistant/copilot to enable access to the documents/receipts/invoices/projects/photos etc with a platform like SearchAI. Start with a packaged solution and then you can expand or build on your own if required. You can do it all onprem with no external costs or APIs. &lt;a href=\\"https://www.searchblox.com/downloads\\"&gt;https://www.searchblox.com/downloads&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltcwbx/local_llm_for_business/n1pztir/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751845743,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltcwbx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
