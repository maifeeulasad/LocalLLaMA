import{j as e}from"./index-CNyNkRpk.js";import{R as l}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Here is a decent Qwen3 BitNet model I trained with \\\\~1B tokens using SYNTHETIC-1 data. BitNet Hunyuan A13B is training this week.  \\n[model](https://huggingface.co/codys12/Qwen3-8B-BitNet)\\n\\n[notebook](https://colab.research.google.com/drive/1GT0GEyjzOQUiOI0tphvhiFDwUw-F6v7l?usp=sharing) to try out the model","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Qwen3-8B-BitNet","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltxsqh","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":190,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lrh70bzgq","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":190,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751903624,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Here is a decent Qwen3 BitNet model I trained with ~1B tokens using SYNTHETIC-1 data. BitNet Hunyuan A13B is training this week.&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/codys12/Qwen3-8B-BitNet\\"&gt;model&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://colab.research.google.com/drive/1GT0GEyjzOQUiOI0tphvhiFDwUw-F6v7l?usp=sharing\\"&gt;notebook&lt;/a&gt; to try out the model&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?auto=webp&amp;s=4ff8812960404be0d7a2643af59bc1b61600af09","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b40bafe8c0c1dda845ae6bf6b64f9b1ae35cb68f","width":108,"height":58},{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d095a0e360f9e83df9c9ad60f0d862d3fa5d36a5","width":216,"height":116},{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7648fe3ed780c2bc5b92bab6eb5669151e8ca022","width":320,"height":172},{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9f40d740be4b13cf316ebb8f7dd974181613923b","width":640,"height":345},{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=806e92902def8ea539a264c581f4d8d5f0f0bde3","width":960,"height":518},{"url":"https://external-preview.redd.it/vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0811e238b0810d5ae02b1dc37e74b1424293c3b1","width":1080,"height":583}],"variants":{},"id":"vbyPA12XMjHI8oICjJYnHnT2yOs-DPOZ4MUativ1sZM"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1ltxsqh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"codys12","discussion_type":null,"num_comments":29,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/","subreddit_subscribers":496034,"created_utc":1751903624,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1u055n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1txqtq","score":8,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"llama.cpp [supports BitNet](https://www.reddit.com/r/LocalLLaMA/comments/1dmt4v7/llamacpp_now_supports_bitnet/) models and if you manually apply the [high-throughput changes](https://www.reddit.com/r/LocalLLaMA/comments/1lrmxn7/llama_add_highthroughput_mode_by_ggerganov_pull/) (or wait a bit for them to be polished and merged) you can run parallel tests at nicely improved speed.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1u055n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama.cpp &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1dmt4v7/llamacpp_now_supports_bitnet/\\"&gt;supports BitNet&lt;/a&gt; models and if you manually apply the &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lrmxn7/llama_add_highthroughput_mode_by_ggerganov_pull/\\"&gt;high-throughput changes&lt;/a&gt; (or wait a bit for them to be polished and merged) you can run parallel tests at nicely improved speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1u055n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751906142,"author_flair_text":null,"treatment_tags":[],"created_utc":1751906142,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1tyu2i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kryptkpr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1txqtq","score":12,"author_fullname":"t2_30i1a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have been working on a new kind of LLM evaluation based on randomized (uncontaminated) continuous-scale-difficulty tasks that are parametrized in multiple dimensions.  If there is a way to reasonably generate even a few million tokens I can give you an idea of where you stand against the FP16. Full sweeps in capability space need around 5M, full sweeps in difficulty need 100M 😟","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1tyu2i","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been working on a new kind of LLM evaluation based on randomized (uncontaminated) continuous-scale-difficulty tasks that are parametrized in multiple dimensions.  If there is a way to reasonably generate even a few million tokens I can give you an idea of where you stand against the FP16. Full sweeps in capability space need around 5M, full sweeps in difficulty need 100M 😟&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1tyu2i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751905766,"author_flair_text":"Llama 3","treatment_tags":[],"created_utc":1751905766,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1tzpwa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AgeOfAlgorithms","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1txqtq","score":1,"author_fullname":"t2_2wq7s6vr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"rougly the same as what? Qwen 3 4bit? 8bit? or full precision?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1tzpwa","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;rougly the same as what? Qwen 3 4bit? 8bit? or full precision?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1tzpwa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751906019,"author_flair_text":null,"treatment_tags":[],"created_utc":1751906019,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1txqtq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codys12","can_mod_post":false,"created_utc":1751905452,"send_replies":true,"parent_id":"t1_n1tuq1x","score":24,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Benchmarking is a little tricky because I've struggled to get a good vLLM implementation and am very resource constrained. MATH-500 and AIME seemed roughly the same, but I am holding all benchmarks until I am sure I did it right. Really hoping for some community evals to help with this!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1txqtq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Benchmarking is a little tricky because I&amp;#39;ve struggled to get a good vLLM implementation and am very resource constrained. MATH-500 and AIME seemed roughly the same, but I am holding all benchmarks until I am sure I did it right. Really hoping for some community evals to help with this!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1txqtq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751905452,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}}],"before":null}},"user_reports":[],"saved":false,"id":"n1tuq1x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"created_utc":1751904577,"send_replies":true,"parent_id":"t3_1ltxsqh","score":29,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"BitNet Hunyuan A13B as a bitnet would be great! do you have any information on how well the Qwen 3 BitNet transformation works compared to regular quants?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1tuq1x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;BitNet Hunyuan A13B as a bitnet would be great! do you have any information on how well the Qwen 3 BitNet transformation works compared to regular quants?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1tuq1x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751904577,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wc8lq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ugos4","score":3,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It only cost 400 dollars?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1wc8lq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It only cost 400 dollars?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1wc8lq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751933016,"author_flair_text":null,"treatment_tags":[],"created_utc":1751933016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wauyg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheLegendOfKitty123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ugos4","score":1,"author_fullname":"t2_6mby8px1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"do you have code you use for this training?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1wauyg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do you have code you use for this training?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1wauyg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751932556,"author_flair_text":null,"treatment_tags":[],"created_utc":1751932556,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ugos4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codys12","can_mod_post":false,"created_utc":1751910960,"send_replies":true,"parent_id":"t1_n1u7bx5","score":20,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It took \\\\~24 hours on 8xH100, but looking to decrease that with Sparse Logit Sampling training for a richer signal","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ugos4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It took ~24 hours on 8xH100, but looking to decrease that with Sparse Logit Sampling training for a richer signal&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1ugos4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751910960,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"n1u7bx5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1751908193,"send_replies":true,"parent_id":"t3_1ltxsqh","score":13,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you have an estimate on how much this cost? I'm thinking about potentially full finetuning an 8B model on a similar amount of data, but it seems like it gets expensive real fast. I know the cases aren't directly comparable but having an idea of what to expect would be helpful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1u7bx5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have an estimate on how much this cost? I&amp;#39;m thinking about potentially full finetuning an 8B model on a similar amount of data, but it seems like it gets expensive real fast. I know the cases aren&amp;#39;t directly comparable but having an idea of what to expect would be helpful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1u7bx5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751908193,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1uxvbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1ugzcx","score":5,"author_fullname":"t2_3wi6j7vwh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that would be amazing! would fit into my 24gb vram!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1uxvbe","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that would be amazing! would fit into my 24gb vram!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uxvbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751916499,"author_flair_text":null,"treatment_tags":[],"created_utc":1751916499,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ugzcx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codys12","can_mod_post":false,"created_utc":1751911050,"send_replies":true,"parent_id":"t1_n1ucwum","score":17,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"should be about 20GB in all when in BitNet format!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ugzcx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;should be about 20GB in all when in BitNet format!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1ugzcx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751911050,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"n1ucwum","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LagOps91","can_mod_post":false,"created_utc":1751909825,"send_replies":true,"parent_id":"t3_1ltxsqh","score":10,"author_fullname":"t2_3wi6j7vwh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how large is BitNet Hunyuan A13B going to be?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1ucwum","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how large is BitNet Hunyuan A13B going to be?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1ucwum/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751909825,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vveri","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1vas97","score":1,"author_fullname":"t2_qz1qjc86","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the link. I just tried to convert the safetensors model to GGUF using the GGUF my repo space, it still fails with error on this Qwen3-8B-BitNet. 🤷‍♂️","edited":false,"author_flair_css_class":null,"name":"t1_n1vveri","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the link. I just tried to convert the safetensors model to GGUF using the GGUF my repo space, it still fails with error on this Qwen3-8B-BitNet. 🤷‍♂️&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1ltxsqh","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vveri/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751927557,"author_flair_text":null,"collapsed":false,"created_utc":1751927557,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1vas97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"codys12","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1uogqn","score":3,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[https://huggingface.co/spaces/huggingface-projects/repo\\\\_duplicator](https://huggingface.co/spaces/huggingface-projects/repo_duplicator)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vas97","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/spaces/huggingface-projects/repo_duplicator\\"&gt;https://huggingface.co/spaces/huggingface-projects/repo_duplicator&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vas97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751920784,"author_flair_text":null,"treatment_tags":[],"created_utc":1751920784,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1uogqn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1uml8y","score":1,"author_fullname":"t2_qz1qjc86","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tried to find space for cloning repos, but I couldn't find one. Do you have a link for it, please? Also, thanks for adding the safetensors.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1uogqn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried to find space for cloning repos, but I couldn&amp;#39;t find one. Do you have a link for it, please? Also, thanks for adding the safetensors.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uogqn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751913419,"author_flair_text":null,"treatment_tags":[],"created_utc":1751913419,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1uml8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codys12","can_mod_post":false,"created_utc":1751912813,"send_replies":true,"parent_id":"t1_n1uh7xk","score":7,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think there is a good space for cloning the model to your own repository, then you're off to the races. I also just added safetensors to my repo.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uml8y","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think there is a good space for cloning the model to your own repository, then you&amp;#39;re off to the races. I also just added safetensors to my repo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uml8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751912813,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1w9kyb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lans_throwaway","can_mod_post":false,"created_utc":1751932137,"send_replies":true,"parent_id":"t1_n1uh7xk","score":3,"author_fullname":"t2_4wk26vny","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; pytorch (.bin) format only which cannot be converted to GGUF format directly. First it must be converted into safetensors format and then converted into GGUF format.\\n\\nThat's incorrect. Whether the file is pytorch or safetensors generally doesn't matter (if you're using llama.cpp's \`convert_hf_to_gguf.py\` script (gguf-my-repo for example). It's just that llama.cpp doesn't really know how to convert/run bitnet models (outside of few suppored ones). Someone would have to add handling for this specific model (add support for rms layers to existing qwen3 and so on).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1w9kyb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;pytorch (.bin) format only which cannot be converted to GGUF format directly. First it must be converted into safetensors format and then converted into GGUF format.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s incorrect. Whether the file is pytorch or safetensors generally doesn&amp;#39;t matter (if you&amp;#39;re using llama.cpp&amp;#39;s &lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; script (gguf-my-repo for example). It&amp;#39;s just that llama.cpp doesn&amp;#39;t really know how to convert/run bitnet models (outside of few suppored ones). Someone would have to add handling for this specific model (add support for rms layers to existing qwen3 and so on).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1w9kyb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751932137,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1uh7xk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1751911122,"send_replies":true,"parent_id":"t3_1ltxsqh","score":7,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So if I understand this right llamacpp supports bitnet, but most of the models available so far are in pytorch (.bin) format only which cannot be converted to GGUF format directly. First it must be converted into safetensors format and then converted into GGUF format. There is no convenient way of doing this on HF directly. There is a HF space for converting pytorch format into safetensors format, but it creates PR request in the original model repository which afaik requires manual merge by the repository owner. Needless to say, due to these circumstances most bitnet models won't ever make it to llamacpp... 😞","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uh7xk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So if I understand this right llamacpp supports bitnet, but most of the models available so far are in pytorch (.bin) format only which cannot be converted to GGUF format directly. First it must be converted into safetensors format and then converted into GGUF format. There is no convenient way of doing this on HF directly. There is a HF space for converting pytorch format into safetensors format, but it creates PR request in the original model repository which afaik requires manual merge by the repository owner. Needless to say, due to these circumstances most bitnet models won&amp;#39;t ever make it to llamacpp... 😞&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uh7xk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751911122,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1uhh1i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Daemontatox","can_mod_post":false,"created_utc":1751911198,"send_replies":true,"parent_id":"t3_1ltxsqh","score":3,"author_fullname":"t2_1rm9syq1nb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How dolid you manage to get Hunyuan running ? \\nI keep running into issues from modeling file and sometimes it says its missing or there is a new version.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uhh1i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How dolid you manage to get Hunyuan running ? \\nI keep running into issues from modeling file and sometimes it says its missing or there is a new version.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uhh1i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751911198,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vdh47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Orolol","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1uwt22","score":3,"author_fullname":"t2_fbzx9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why not DynTanh ?  \\n  \\nhttps://arxiv.org/abs/2503.10622","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1vdh47","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why not DynTanh ?  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2503.10622\\"&gt;https://arxiv.org/abs/2503.10622&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vdh47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751921680,"author_flair_text":null,"treatment_tags":[],"created_utc":1751921680,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1uwt22","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codys12","can_mod_post":false,"created_utc":1751916146,"send_replies":true,"parent_id":"t1_n1upqbq","score":8,"author_fullname":"t2_lrh70bzgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://arxiv.org/abs/2505.08823](https://arxiv.org/abs/2505.08823)\\n\\nIt only works with the RMS surprisingly!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uwt22","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2505.08823\\"&gt;https://arxiv.org/abs/2505.08823&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It only works with the RMS surprisingly!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uwt22/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751916146,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1uqclr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GreenTreeAndBlueSky","can_mod_post":false,"created_utc":1751914030,"send_replies":true,"parent_id":"t1_n1upqbq","score":0,"author_fullname":"t2_1p50pl73j2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's less compute heavy than LayerNorm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uqclr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s less compute heavy than LayerNorm&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1uqclr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751914030,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n1upqbq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GL-AI","can_mod_post":false,"created_utc":1751913827,"send_replies":true,"parent_id":"t3_1ltxsqh","score":4,"author_fullname":"t2_1sr5yw3yg0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the reasoning behind adding the RMSNorm to each linear layer?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1upqbq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the reasoning behind adding the RMSNorm to each linear layer?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1upqbq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751913827,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vrupc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreenTreeAndBlueSky","can_mod_post":false,"created_utc":1751926428,"send_replies":true,"parent_id":"t1_n1vqoye","score":8,"author_fullname":"t2_1p50pl73j2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My guess is that they converted the linear layers to bitnet layers (fp8 to ternary) and then retrained to make up for some of the (colossal) loss of accuracy.\\n\\nThe advantage of bitnet is due to how convolution is handled and saves A LOT of comuptation on cpu inference. Gpus dont support it (yet) so it's not a difference there. The goal of bitnet models is to make them very computationally efficient and they require very little energy to run compared to their peers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vrupc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My guess is that they converted the linear layers to bitnet layers (fp8 to ternary) and then retrained to make up for some of the (colossal) loss of accuracy.&lt;/p&gt;\\n\\n&lt;p&gt;The advantage of bitnet is due to how convolution is handled and saves A LOT of comuptation on cpu inference. Gpus dont support it (yet) so it&amp;#39;s not a difference there. The goal of bitnet models is to make them very computationally efficient and they require very little energy to run compared to their peers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltxsqh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vrupc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751926428,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n1vqoye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hideo_kuze_","can_mod_post":false,"created_utc":1751926059,"send_replies":true,"parent_id":"t3_1ltxsqh","score":2,"author_fullname":"t2_47x1vr66","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm confused.\\n\\nYou say you _trained_ it. Did you train this from scratch? Or is this a finetune from original Qwen3 model which then you converted the model file to bitnet?\\n\\nAnd in any case what was your motivation? Learning purposes or to have a faster inference?\\n\\nThanks\\n\\nedit: by \\"faster inference\\" I meant it in the sense that's faster but accuracy remains similar. Did you get any numbers for KL divergence?","edited":1751927158,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vqoye","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m confused.&lt;/p&gt;\\n\\n&lt;p&gt;You say you &lt;em&gt;trained&lt;/em&gt; it. Did you train this from scratch? Or is this a finetune from original Qwen3 model which then you converted the model file to bitnet?&lt;/p&gt;\\n\\n&lt;p&gt;And in any case what was your motivation? Learning purposes or to have a faster inference?&lt;/p&gt;\\n\\n&lt;p&gt;Thanks&lt;/p&gt;\\n\\n&lt;p&gt;edit: by &amp;quot;faster inference&amp;quot; I meant it in the sense that&amp;#39;s faster but accuracy remains similar. Did you get any numbers for KL divergence?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vqoye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751926059,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xwtky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Hot_Landscape_1063","can_mod_post":false,"created_utc":1751955372,"send_replies":true,"parent_id":"t3_1ltxsqh","score":1,"author_fullname":"t2_brfsq4v2k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"But how did you train it??? I've been trying for weeks to replicate your RMSNorm idea. So far I'm getting nowhere near the performance of the original model even after training on 500B tokens","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xwtky","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But how did you train it??? I&amp;#39;ve been trying for weeks to replicate your RMSNorm idea. So far I&amp;#39;m getting nowhere near the performance of the original model even after training on 500B tokens&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1xwtky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751955372,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vgkyu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"created_utc":1751922749,"send_replies":true,"parent_id":"t3_1ltxsqh","score":1,"author_fullname":"t2_c2f558x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vgkyu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltxsqh/qwen38bbitnet/n1vgkyu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751922749,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltxsqh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
