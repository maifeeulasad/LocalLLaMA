import{j as e}from"./index-BTIgvohq.js";import{R as t}from"./RedditPostRenderer-almq7it9.js";import"./index-tYRBzv7e.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm well aware my hardware is... not ideal.. for running LLMs, but I thought I'd at least be able to run small 2B to 4B models at a decent clip. But even the E2B version of Gemma 3n seems fairly slow. The TK/s aren't so bad (\\\\~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.\\n\\nIs this more or less expected for my hardware, or should I be seeing modestly better speeds?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"i5-8500 (6 cores), 24GB DDR4 2666 dual channel, realistic expectations for 3b/4b models?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lmt3kt","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.9,"author_flair_background_color":null,"subreddit_type":"public","ups":8,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_kehp8nb59","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":8,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751133510,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m well aware my hardware is... not ideal.. for running LLMs, but I thought I&amp;#39;d at least be able to run small 2B to 4B models at a decent clip. But even the E2B version of Gemma 3n seems fairly slow. The TK/s aren&amp;#39;t so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.&lt;/p&gt;\\n\\n&lt;p&gt;Is this more or less expected for my hardware, or should I be seeing modestly better speeds?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lmt3kt","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"redoubt515","discussion_type":null,"num_comments":37,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/","subreddit_subscribers":492840,"created_utc":1751133510,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0azyth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ElectronSpiderwort","can_mod_post":false,"created_utc":1751145236,"send_replies":true,"parent_id":"t1_n0aaa0t","score":3,"author_fullname":"t2_mxbu5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My i5-7500 has only 4 cores and Qwen3-30B-A3B-Q8\\\\_0.gguf runs at 25.7 tok/s prompt and 6.34 tok/s generation, for a 1165 token prompt and 1821 token output. Memory use by llama.cpp was \\\\~35GB so OP would need to run a quant.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0azyth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My i5-7500 has only 4 cores and Qwen3-30B-A3B-Q8_0.gguf runs at 25.7 tok/s prompt and 6.34 tok/s generation, for a 1165 token prompt and 1821 token output. Memory use by llama.cpp was ~35GB so OP would need to run a quant.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0azyth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751145236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f95x6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751211842,"send_replies":true,"parent_id":"t1_n0aaa0t","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm going to give Qwen3 30B a try. I thought it was out of reach for me, but from what you and a couple other people are saying, it sounds like it might be the best choice. I'm also going to upgrade to 32GB (2 x 16GB) so that should give me a little more breathing room.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f95x6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m going to give Qwen3 30B a try. I thought it was out of reach for me, but from what you and a couple other people are saying, it sounds like it might be the best choice. I&amp;#39;m also going to upgrade to 32GB (2 x 16GB) so that should give me a little more breathing room.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0f95x6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751211842,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0aaa0t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoffKalast","can_mod_post":false,"created_utc":1751136893,"send_replies":true,"parent_id":"t3_1lmt3kt","score":12,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That actually sounds like a pretty decent speed for your setup, I would be expecting less. And yes all cores you allocate will be used to 100% for the duration since practically any CPU will be compute bound by performance regardless.\\n\\nI think a sparse model like Qwen-30B-A3B could be the best option for your setup, it's 3B active so the speed should be similar, and the 30B total should just about fit into 24 GB, total performance of about a 10B dense.","edited":1751137324,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0aaa0t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That actually sounds like a pretty decent speed for your setup, I would be expecting less. And yes all cores you allocate will be used to 100% for the duration since practically any CPU will be compute bound by performance regardless.&lt;/p&gt;\\n\\n&lt;p&gt;I think a sparse model like Qwen-30B-A3B could be the best option for your setup, it&amp;#39;s 3B active so the speed should be similar, and the 30B total should just about fit into 24 GB, total performance of about a 10B dense.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0aaa0t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751136893,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ivaj6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0fe9cq","score":1,"author_fullname":"t2_kehp8nb59","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It isn't a standard off the shelf GPU, its a custom [non-standard form factor](https://www.ebay.com/itm/236084630886?_skw=rx560+elitedesk&amp;epid=13066999150&amp;itmmeta=01JYY8BE75GAYDDPA2N7RAYVRE&amp;hash=item36f7bd9566:g:l~kAAOSwCFtoG7Nw&amp;itmprp=enc%3AAQAKAAAA8FkggFvd1GGDu0w3yXCmi1cZYFoS5g8%2FMdZEpXnkwXRCU1wXAgGLvY8djrMN%2BVN0Sc9kgZ%2FXKTS7MyVh1yBdRCYfS9Q4OLpYKhIY2zRYSf90OmA1GuHMLFTKjDtm8a94ghrpu6e%2FGrqrgvyQjWw2yuhfK0iPYnKhXppWUl55dTgTLP4SAUI2YRtS4PZ%2Fanh6ebZf6SvP1jf0DGCLOiR0HMq%2FH44GT%2FIrUVz%2FumnNYtsSG0r%2BalPiWTFpY%2FlZvBdRjUdfewiD%2FsCglwm3L70SsgaWqHX3c6rqhQzKPjdSiVMk1F9F%2FX5CjouSrLhquhzYdg%3D%3D%7Ctkp%3ABFBM2OOtyPdl) made for the specific hardware and proprietary connector.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0ivaj6","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It isn&amp;#39;t a standard off the shelf GPU, its a custom &lt;a href=\\"https://www.ebay.com/itm/236084630886?_skw=rx560+elitedesk&amp;amp;epid=13066999150&amp;amp;itmmeta=01JYY8BE75GAYDDPA2N7RAYVRE&amp;amp;hash=item36f7bd9566:g:l%7EkAAOSwCFtoG7Nw&amp;amp;itmprp=enc%3AAQAKAAAA8FkggFvd1GGDu0w3yXCmi1cZYFoS5g8%2FMdZEpXnkwXRCU1wXAgGLvY8djrMN%2BVN0Sc9kgZ%2FXKTS7MyVh1yBdRCYfS9Q4OLpYKhIY2zRYSf90OmA1GuHMLFTKjDtm8a94ghrpu6e%2FGrqrgvyQjWw2yuhfK0iPYnKhXppWUl55dTgTLP4SAUI2YRtS4PZ%2Fanh6ebZf6SvP1jf0DGCLOiR0HMq%2FH44GT%2FIrUVz%2FumnNYtsSG0r%2BalPiWTFpY%2FlZvBdRjUdfewiD%2FsCglwm3L70SsgaWqHX3c6rqhQzKPjdSiVMk1F9F%2FX5CjouSrLhquhzYdg%3D%3D%7Ctkp%3ABFBM2OOtyPdl\\"&gt;non-standard form factor&lt;/a&gt; made for the specific hardware and proprietary connector.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ivaj6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751256993,"author_flair_text":null,"treatment_tags":[],"created_utc":1751256993,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fe9cq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0fbqju","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" &gt; I have neither available\\n\\nand  RX560 4GB does not compute.","edited":false,"author_flair_css_class":null,"name":"t1_n0fe9cq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I have neither available&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;and  RX560 4GB does not compute.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fe9cq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751213462,"author_flair_text":null,"collapsed":false,"created_utc":1751213462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fbqju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0df4ry","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not an option unfortunately. (riser cable still needs a pcie slot and space in the case (or outside of it) I have neither available)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fbqju","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not an option unfortunately. (riser cable still needs a pcie slot and space in the case (or outside of it) I have neither available)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fbqju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212658,"author_flair_text":null,"treatment_tags":[],"created_utc":1751212658,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0df4ry","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0crapt","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A riser cable + p104-100 = $30. This will give yo massive, 10x speed up.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0df4ry","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A riser cable + p104-100 = $30. This will give yo massive, 10x speed up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0df4ry/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181798,"author_flair_text":null,"treatment_tags":[],"created_utc":1751181798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0crapt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169447,"send_replies":true,"parent_id":"t1_n0aaaam","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately for me, this system *is* already maxed out. 2666 is the max supported memory speeed, and you are correct that dual channel is the best I can do.\\n\\nI have no pcie slots available so the *only \\"\\"*upgrade\\"\\" I have available to me, without full hardware replacement is an RX560 4GB (my server is a non-standard form factor, so this is the only GPU available to me. And that upgrade doesn't really feel worth it just to be able to run a 3B model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0crapt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately for me, this system &lt;em&gt;is&lt;/em&gt; already maxed out. 2666 is the max supported memory speeed, and you are correct that dual channel is the best I can do.&lt;/p&gt;\\n\\n&lt;p&gt;I have no pcie slots available so the &lt;em&gt;only &amp;quot;&amp;quot;&lt;/em&gt;upgrade&amp;quot;&amp;quot; I have available to me, without full hardware replacement is an RX560 4GB (my server is a non-standard form factor, so this is the only GPU available to me. And that upgrade doesn&amp;#39;t really feel worth it just to be able to run a 3B model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0crapt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169447,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dr76z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dpzh2","score":-1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Best of luck with your pointless crusade.","edited":1751189388,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0dr76z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Best of luck with your pointless crusade.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dr76z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751189183,"author_flair_text":null,"treatment_tags":[],"created_utc":1751189183,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dpzh2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dletq","score":4,"author_fullname":"t2_4di8yifm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is very strange attitude.   \\nSo, since the info is limited, i had to assume some of the things (which relevant/important ones are confirmed by OP), while you get in to irrevelant points like RAM slot limit is not caused by CPU its caused by motherboard. And somehow you think that, while i can do calculations about tps i do know nothing about ram slot limit caused by what?  \\n  \\nAlso for some reason, you seem to believe that I'm obligated to explain things you've cherry-picked from my comment, even while your own comments are a cascade of errors and useless advice. Like deliberately twisting OP's \\"the TK/s **aren't so bad** (\\\\~6-7 tk/s)\\" into \\"not caring\\" just to give perfect examples about 4060ti with Ryzen 7 which has definelty relevant or suggesting OP to get **\\"riser cable + GPU\\"** while explicitly stated, **\\"I have no pcie slots available.\\"** is totally relevant and definetly not \\"silly\\".  \\nFrankly, the only thing that matters here is that the OP understood my advice and its rationale. There's no point in continuing with this meaningless argument with someone who has contributed nothing while \\"beeing a nice person\\".   \\nI have work to do. Best of luck with your pointless crusade.","edited":false,"author_flair_css_class":null,"name":"t1_n0dpzh2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is very strange attitude.&lt;br/&gt;\\nSo, since the info is limited, i had to assume some of the things (which relevant/important ones are confirmed by OP), while you get in to irrevelant points like RAM slot limit is not caused by CPU its caused by motherboard. And somehow you think that, while i can do calculations about tps i do know nothing about ram slot limit caused by what?  &lt;/p&gt;\\n\\n&lt;p&gt;Also for some reason, you seem to believe that I&amp;#39;m obligated to explain things you&amp;#39;ve cherry-picked from my comment, even while your own comments are a cascade of errors and useless advice. Like deliberately twisting OP&amp;#39;s &amp;quot;the TK/s &lt;strong&gt;aren&amp;#39;t so bad&lt;/strong&gt; (~6-7 tk/s)&amp;quot; into &amp;quot;not caring&amp;quot; just to give perfect examples about 4060ti with Ryzen 7 which has definelty relevant or suggesting OP to get &lt;strong&gt;&amp;quot;riser cable + GPU&amp;quot;&lt;/strong&gt; while explicitly stated, &lt;strong&gt;&amp;quot;I have no pcie slots available.&amp;quot;&lt;/strong&gt; is totally relevant and definetly not &amp;quot;silly&amp;quot;.&lt;br/&gt;\\nFrankly, the only thing that matters here is that the OP understood my advice and its rationale. There&amp;#39;s no point in continuing with this meaningless argument with someone who has contributed nothing while &amp;quot;beeing a nice person&amp;quot;.&lt;br/&gt;\\nI have work to do. Best of luck with your pointless crusade.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dpzh2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751188423,"author_flair_text":null,"collapsed":false,"created_utc":1751188423,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dletq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0djz17","score":0,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; My advice was grounded in the practical reality of the user's specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.\\n\\nYour advice has incorrect silly info such as \\"i5-8500 only have two slots, therefore u cannot add more ram\\", as this is not a contraint of CPU but motherboard, and that installing 3600 ddr4 will do any improvement to the prompt processing, one of the concern op voiced.\\n\\n\\n&gt; My focus was on inference, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.\\n\\nYou tone is turgid, but I being a nice person will ignore that.\\n\\nThe OP explicitly mentioned concern about PP speeds: \\n\\n&gt; The TK/s aren't so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.\\n\\nIn the other words, **they mentioned they do not care much about inference speed**, but PP speed is concerning.\\n\\nOn their hardware, the only way to improve prompt processing is to install i7-8700, not worth it. No amount of improving memory bandwith will have any influence on PP.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dletq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;My advice was grounded in the practical reality of the user&amp;#39;s specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Your advice has incorrect silly info such as &amp;quot;i5-8500 only have two slots, therefore u cannot add more ram&amp;quot;, as this is not a contraint of CPU but motherboard, and that installing 3600 ddr4 will do any improvement to the prompt processing, one of the concern op voiced.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;My focus was on inference, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;You tone is turgid, but I being a nice person will ignore that.&lt;/p&gt;\\n\\n&lt;p&gt;The OP explicitly mentioned concern about PP speeds: &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The TK/s aren&amp;#39;t so bad (~6-7 tk/s) but the prompt processing is pretty slow and CPU is pinned at 100% all cores for the entirety of each response.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;In the other words, &lt;strong&gt;they mentioned they do not care much about inference speed&lt;/strong&gt;, but PP speed is concerning.&lt;/p&gt;\\n\\n&lt;p&gt;On their hardware, the only way to improve prompt processing is to install i7-8700, not worth it. No amount of improving memory bandwith will have any influence on PP.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0dletq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751185594,"author_flair_text":null,"treatment_tags":[],"created_utc":1751185594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0djz17","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0delyr","score":3,"author_fullname":"t2_4di8yifm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You seem to have missed the entire context of my original comment. I'm not debating the theoretical nature of prompt processing. My advice was grounded in the practical reality of the user's specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.\\n\\nI assumed the user isn't looking to build a new system, but to make incremental improvements. Within that specific context:  \\n\\\\- My focus was on **inference**, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.  \\n\\\\- Your point, while generally true, is impractical here. Suggesting \\"get a GPU\\" is the obvious but trivial answer. If we were ignoring the user's constraints, I could just as easily recommend an RTX 5090 for a 40x increase in inference speed and probably a 1000x increase in prompt processing. There are a billion options, but that wasn't the user's question.\\n\\nIn short, while you are correct that prompt processing is compute-bound, your entire point is irrelevant within the scope of providing actionable advice for the user's existing hardware. My recommendations were about optimizing that system and providing general guidance on how things works in simple terms. Yours are about replacing it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0djz17","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You seem to have missed the entire context of my original comment. I&amp;#39;m not debating the theoretical nature of prompt processing. My advice was grounded in the practical reality of the user&amp;#39;s specific hardware (i5-8500, DDR4) and their direct question about realistic expectations for modestly better speeds.&lt;/p&gt;\\n\\n&lt;p&gt;I assumed the user isn&amp;#39;t looking to build a new system, but to make incremental improvements. Within that specific context:&lt;br/&gt;\\n- My focus was on &lt;strong&gt;inference&lt;/strong&gt;, as that was the tangible metric the user provided. For that task on a CPU, the bottleneck is unequivocally memory bandwidth. Upgrading from 2666MHz to 3600MHz RAM is a system-specific suggestion that yields a measurable improvement in that area.&lt;br/&gt;\\n- Your point, while generally true, is impractical here. Suggesting &amp;quot;get a GPU&amp;quot; is the obvious but trivial answer. If we were ignoring the user&amp;#39;s constraints, I could just as easily recommend an RTX 5090 for a 40x increase in inference speed and probably a 1000x increase in prompt processing. There are a billion options, but that wasn&amp;#39;t the user&amp;#39;s question.&lt;/p&gt;\\n\\n&lt;p&gt;In short, while you are correct that prompt processing is compute-bound, your entire point is irrelevant within the scope of providing actionable advice for the user&amp;#39;s existing hardware. My recommendations were about optimizing that system and providing general guidance on how things works in simple terms. Yours are about replacing it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0djz17/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184717,"author_flair_text":null,"treatment_tags":[],"created_utc":1751184717,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0delyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181488,"send_replies":true,"parent_id":"t1_n0aaaam","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I used to think like that too, but prompt processing is compute intensive, and cpu matters too.\\n\\n&gt; Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it's constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are\\n\\nNo, it is not hat simple. CPU can be pinned at 100% both if waiting for data to arrive and also if it is simply saturated at compute - this caqn easily be verified by checking the power consumption, if cpu is like 100% at 20W than it is stuck by memory, if at full 60-80W than it is too weak. Prompt processing is exactly the case of dumb, compute intensive tasks that no cpu will bw good at. Memory bandwith of a conumer GPU (say 4060ti) is not that  much bigger than of DDR4 (5 times) yet prompt processing on 4060ti is 120x of prompt prrocessing on Ryzen 7.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0delyr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I used to think like that too, but prompt processing is compute intensive, and cpu matters too.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it&amp;#39;s constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;No, it is not hat simple. CPU can be pinned at 100% both if waiting for data to arrive and also if it is simply saturated at compute - this caqn easily be verified by checking the power consumption, if cpu is like 100% at 20W than it is stuck by memory, if at full 60-80W than it is too weak. Prompt processing is exactly the case of dumb, compute intensive tasks that no cpu will bw good at. Memory bandwith of a conumer GPU (say 4060ti) is not that  much bigger than of DDR4 (5 times) yet prompt processing on 4060ti is 120x of prompt prrocessing on Ryzen 7.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0delyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181488,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0aaaam","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mir4can","can_mod_post":false,"created_utc":1751136895,"send_replies":true,"parent_id":"t3_1lmt3kt","score":5,"author_fullname":"t2_4di8yifm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In your case, when running an LLM on the CPU, the primary bottleneck is almost always **memory bandwidth**, not the CPU's raw processing power.  \\nIf you are not using any GPU, your dual-channel DDR4-2666 RAM gives you a approx. maximum bandwidth of 41-42 GB/s.For dense models (not MOE) if you divide this number to your model's total memory usage(eg. model size, kv cache etc.) you will get your approx tps.\\n\\nMoreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it's constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are   \\n1- run on gpu,  \\n2- Upgrade your ddr4 ram to 3600+ mhz. (afaik i5-8500 only have two slots, therefore u cannot add more ram)  \\nfor 6 gb model (with model size, kv cache etc. included)   \\n\\\\- on first scenario u probbly x10 to x20 tps increase **(this is purely based on the GPU's bandwight)**  \\n\\\\- you probbly get (lets say if you upgraded to 4000 mhz) like 1.5x of your current tps.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0aaaam","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In your case, when running an LLM on the CPU, the primary bottleneck is almost always &lt;strong&gt;memory bandwidth&lt;/strong&gt;, not the CPU&amp;#39;s raw processing power.&lt;br/&gt;\\nIf you are not using any GPU, your dual-channel DDR4-2666 RAM gives you a approx. maximum bandwidth of 41-42 GB/s.For dense models (not MOE) if you divide this number to your model&amp;#39;s total memory usage(eg. model size, kv cache etc.) you will get your approx tps.&lt;/p&gt;\\n\\n&lt;p&gt;Moreover, the slow prompt processing and 100% CPU usage are also classic symptoms of a memory-bound workload—the CPU is working as fast as it can, but it&amp;#39;s constantly waiting for data from the slower RAM. So in terms of tps etc. your best options are&lt;br/&gt;\\n1- run on gpu,&lt;br/&gt;\\n2- Upgrade your ddr4 ram to 3600+ mhz. (afaik i5-8500 only have two slots, therefore u cannot add more ram)&lt;br/&gt;\\nfor 6 gb model (with model size, kv cache etc. included)&lt;br/&gt;\\n- on first scenario u probbly x10 to x20 tps increase &lt;strong&gt;(this is purely based on the GPU&amp;#39;s bandwight)&lt;/strong&gt;&lt;br/&gt;\\n- you probbly get (lets say if you upgraded to 4000 mhz) like 1.5x of your current tps.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0aaaam/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751136895,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b7p6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1751147872,"send_replies":true,"parent_id":"t1_n0ajcq1","score":3,"author_fullname":"t2_8fu8sqhz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could also be 8+4+8+4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b7p6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could also be 8+4+8+4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b7p6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751147872,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0jbgpj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ixgz3","score":1,"author_fullname":"t2_11qlhv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"These are my play machines, not using them for LLMs specifically. I was just trying things which coincided with your post. It was just ollama under Ubuntu 24.04 pulling the unsloth quants from Huggingface directly:\\n\\n\`ollama run\` [\`hf.co/unsloth/Qwen3-30B-A3B-GGUF:Q6_K_XL\`](http://hf.co/unsloth/Qwen3-30B-A3B-GGUF:Q6_K_XL)\\n\\nThis was to max out memory and quality, realistically you can probably get away with lower quants like Q4\\\\_K\\\\_XL and make sure to use the recommended settings temperature etc. from here:\\n\\n[https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n0jbgpj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;These are my play machines, not using them for LLMs specifically. I was just trying things which coincided with your post. It was just ollama under Ubuntu 24.04 pulling the unsloth quants from Huggingface directly:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;ollama run&lt;/code&gt; &lt;a href=\\"http://hf.co/unsloth/Qwen3-30B-A3B-GGUF:Q6_K_XL\\"&gt;&lt;code&gt;hf.co/unsloth/Qwen3-30B-A3B-GGUF:Q6_K_XL&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This was to max out memory and quality, realistically you can probably get away with lower quants like Q4_K_XL and make sure to use the recommended settings temperature etc. from here:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune\\"&gt;https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0jbgpj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751265394,"author_flair_text":null,"treatment_tags":[],"created_utc":1751265394,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ixgz3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0fxl8i","score":1,"author_fullname":"t2_kehp8nb59","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, this is really useful perspective.\\n\\nWe have similar systems (Mine is a 1 liter, HP Elitedesk). I decided last night after to upgrade to 32GB of RAM (2x16) since DDR4 is so cheap these days. I have the \\"non-T\\" version CPU, but similar thermal limitations. \\n\\nWhen the new stick of memory shows up, I think I'll try Qwen3 30B A3B and see how it goes. I'd be happy if I got similar speeds to your experience.\\n\\nWhat OS and what software are you using to run the LLM?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0ixgz3","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, this is really useful perspective.&lt;/p&gt;\\n\\n&lt;p&gt;We have similar systems (Mine is a 1 liter, HP Elitedesk). I decided last night after to upgrade to 32GB of RAM (2x16) since DDR4 is so cheap these days. I have the &amp;quot;non-T&amp;quot; version CPU, but similar thermal limitations. &lt;/p&gt;\\n\\n&lt;p&gt;When the new stick of memory shows up, I think I&amp;#39;ll try Qwen3 30B A3B and see how it goes. I&amp;#39;d be happy if I got similar speeds to your experience.&lt;/p&gt;\\n\\n&lt;p&gt;What OS and what software are you using to run the LLM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ixgz3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751258022,"author_flair_text":null,"treatment_tags":[],"created_utc":1751258022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fxl8i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0fbub6","score":1,"author_fullname":"t2_11qlhv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have a couple of machines with a similar configuration, but full 32GB DDR4-2666 RAM (2x16GB). The CPU is i5-8500T so either the same as yours or slightly slower. I've tried to use as much RAM as possible and still have decent generation speed so I loaded the 26.3GB Q6\\\\_K\\\\_XL version of Qwen3 30BA3B from here:  \\n  \\n[https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF](https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF)  \\n  \\nFor an input prompt of 319 tokens it did 210-220 tok/s prompt processing speed and slightly over 8 tok/s token generation. Saying that I also saw up to 280 tok/s prompt processing speed for some queries (around 1000 input tokens).\\n\\nMonolithic models of this size won't be this fast of course, even Llama3.1 8B at Q4\\\\_K\\\\_M (5GB) does only 6 tok/s. The 16.3GB Qwen3 Q3\\\\_K\\\\_XL doesn't even hit 2 tok/s, it does 1.5-1.6 only. That's unusable for thinking models so I'd either stick to that MoE Q3 30BA3B or non-thinking models like Gemma3, Qwen2.5 or Llama3.2 etc. at lower quants. \\n\\nThe machine is an USFF Dell Optiplex 7060, but it does pretty well for such a thermally constrained chassis, the CPU stays at around 72-73C for a couple of minutes under full load so stays at 3.0-3.1GHz and even after that when it hit 75-76C on some core it drops down to 2.8Ghz then goes back up to 3Ghz quickly because the temps go down. On average it stays at 3Ghz which determines your prompt processing speed.","edited":false,"author_flair_css_class":null,"name":"t1_n0fxl8i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a couple of machines with a similar configuration, but full 32GB DDR4-2666 RAM (2x16GB). The CPU is i5-8500T so either the same as yours or slightly slower. I&amp;#39;ve tried to use as much RAM as possible and still have decent generation speed so I loaded the 26.3GB Q6_K_XL version of Qwen3 30BA3B from here:  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF\\"&gt;https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF&lt;/a&gt;  &lt;/p&gt;\\n\\n&lt;p&gt;For an input prompt of 319 tokens it did 210-220 tok/s prompt processing speed and slightly over 8 tok/s token generation. Saying that I also saw up to 280 tok/s prompt processing speed for some queries (around 1000 input tokens).&lt;/p&gt;\\n\\n&lt;p&gt;Monolithic models of this size won&amp;#39;t be this fast of course, even Llama3.1 8B at Q4_K_M (5GB) does only 6 tok/s. The 16.3GB Qwen3 Q3_K_XL doesn&amp;#39;t even hit 2 tok/s, it does 1.5-1.6 only. That&amp;#39;s unusable for thinking models so I&amp;#39;d either stick to that MoE Q3 30BA3B or non-thinking models like Gemma3, Qwen2.5 or Llama3.2 etc. at lower quants. &lt;/p&gt;\\n\\n&lt;p&gt;The machine is an USFF Dell Optiplex 7060, but it does pretty well for such a thermally constrained chassis, the CPU stays at around 72-73C for a couple of minutes under full load so stays at 3.0-3.1GHz and even after that when it hit 75-76C on some core it drops down to 2.8Ghz then goes back up to 3Ghz quickly because the temps go down. On average it stays at 3Ghz which determines your prompt processing speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fxl8i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751219482,"author_flair_text":null,"collapsed":false,"created_utc":1751219482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fbub6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0d6gdg","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks, I appreciate the confirmation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fbub6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I appreciate the confirmation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fbub6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212691,"author_flair_text":null,"treatment_tags":[],"created_utc":1751212691,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0d6gdg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0cqeq4","score":3,"author_fullname":"t2_11qlhv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Then it works in flex mode. The first 16GB of the addressable space are accessed in dual channel mode and the last 8 single channel.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0d6gdg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Then it works in flex mode. The first 16GB of the addressable space are accessed in dual channel mode and the last 8 single channel.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0d6gdg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751176872,"author_flair_text":null,"treatment_tags":[],"created_utc":1751176872,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cqeq4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169059,"send_replies":true,"parent_id":"t1_n0ajcq1","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm certain that:\\n\\n1. my system *supports* dual channel (and has only two RAM slots so no chance of using wrong slots)\\n2. I'm using 2 dimms (1 x 16gb + 1 x 8 gb)\\n\\nI'm not *certain* that it is actually *working* as dual channel. I assumed so, I guess this is something I need to confirm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cqeq4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m certain that:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;my system &lt;em&gt;supports&lt;/em&gt; dual channel (and has only two RAM slots so no chance of using wrong slots)&lt;/li&gt;\\n&lt;li&gt;I&amp;#39;m using 2 dimms (1 x 16gb + 1 x 8 gb)&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I&amp;#39;m not &lt;em&gt;certain&lt;/em&gt; that it is actually &lt;em&gt;working&lt;/em&gt; as dual channel. I assumed so, I guess this is something I need to confirm.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cqeq4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169059,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ajcq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wild_Requirement8902","can_mod_post":false,"created_utc":1751139841,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_98yqzbqx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"are you sure you are in dual channel ? or do you have 3 8gb stick ? I am pretty sure you need 2 or 4 stick of the same size for dual channel. maybe getting anoter ram stick and messing with your bios a bit could help what qwant are you running ? q4 km imatrix one ? you should try q4\\\\_0 or even q8\\\\_0 since they are more cpu friendly. and try other model especialy if you are running them trough llama.cpp or ollama","edited":1751140365,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ajcq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are you sure you are in dual channel ? or do you have 3 8gb stick ? I am pretty sure you need 2 or 4 stick of the same size for dual channel. maybe getting anoter ram stick and messing with your bios a bit could help what qwant are you running ? q4 km imatrix one ? you should try q4_0 or even q8_0 since they are more cpu friendly. and try other model especialy if you are running them trough llama.cpp or ollama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ajcq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751139841,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b8hou","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1751148146,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_8fu8sqhz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is what Zen 3 + DDR4-3200 inference looks like:\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/\\n\\n\\nIf I had to guess, Skylake + DDR4-2666 should be around 50-60% of this speed. So at the first glance, your results seem fair","edited":1751148388,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b8hou","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is what Zen 3 + DDR4-3200 inference looks like:\\n&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1d9m0z3/comment/l7fged8/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If I had to guess, Skylake + DDR4-2666 should be around 50-60% of this speed. So at the first glance, your results seem fair&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b8hou/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751148146,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1lmt3kt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1lmt3kt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ivrju","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0i09v6","score":1,"author_fullname":"t2_kehp8nb59","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much. This insight is really helpful.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0ivrju","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much. This insight is really helpful.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lmt3kt","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ivrju/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751257213,"author_flair_text":null,"treatment_tags":[],"created_utc":1751257213,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0i09v6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0fdmev","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Use llama.cpp to fully optimise for your setup. \\n\\n\\nMMAP keeps weights in storage freeing ram for context (great for MoE's where only a faction of the weights get used per token). You can 2x your tps with a 2GB GPU for qwen 30b a3b after overriding half those activated 3b (shared experts) to stay in GPU. You can expect 5-10 tps with an SSD (no GPU) for a3b and 2 tps for MoE's no larger than 17b active. \\n\\n\\nWith MMAP, giant models can be run on common computers and with MoE's, at surprising speeds.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Use llama.cpp to fully optimise for your setup. &lt;/p&gt;\\n\\n&lt;p&gt;MMAP keeps weights in storage freeing ram for context (great for MoE&amp;#39;s where only a faction of the weights get used per token). You can 2x your tps with a 2GB GPU for qwen 30b a3b after overriding half those activated 3b (shared experts) to stay in GPU. You can expect 5-10 tps with an SSD (no GPU) for a3b and 2 tps for MoE&amp;#39;s no larger than 17b active. &lt;/p&gt;\\n\\n&lt;p&gt;With MMAP, giant models can be run on common computers and with MoE&amp;#39;s, at surprising speeds.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0i09v6/","num_reports":null,"locked":false,"name":"t1_n0i09v6","created":1751244542,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751244542,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fdmev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ddayf","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\&gt; Just don't use --no-mmap if you have an SSD\\n\\nThis is not a terminal command I've ever used, so unless it is an ollama default I think I'm safe there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fdmev","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Just don&amp;#39;t use --no-mmap if you have an SSD&lt;/p&gt;\\n\\n&lt;p&gt;This is not a terminal command I&amp;#39;ve ever used, so unless it is an ollama default I think I&amp;#39;m safe there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0fdmev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751213259,"author_flair_text":null,"treatment_tags":[],"created_utc":1751213259,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ddayf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1751180727,"send_replies":true,"parent_id":"t1_n0cr37n","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Just don't use --no-mmap if you have an SSD. That 4GB GPU would also help cache shared weights.","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just don&amp;#39;t use --no-mmap if you have an SSD. That 4GB GPU would also help cache shared weights.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddayf/","num_reports":null,"locked":false,"name":"t1_n0ddayf","created":1751180727,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"n0cr37n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169354,"send_replies":true,"parent_id":"t1_n0c3yj2","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'll give it a try. See how that goes. Thanks for the pointer. I'd be really happy if I could run Qwen 3 30B","edited":1751178499,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cr37n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll give it a try. See how that goes. Thanks for the pointer. I&amp;#39;d be really happy if I could run Qwen 3 30B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cr37n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169354,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0c3yj2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1751159752,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Run Qwen 3 30B A3B @ UD Q2K_XL. This is going to be the best setup for you. You can also use IQ4XS if you want a little more precision at the cost of speed. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0c3yj2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Run Qwen 3 30B A3B @ UD Q2K_XL. This is going to be the best setup for you. You can also use IQ4XS if you want a little more precision at the cost of speed. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0c3yj2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751159752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1lmt3kt","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0cqr5k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"created_utc":1751169205,"send_replies":true,"parent_id":"t1_n0asbid","score":1,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately it is an ultra small form factor system (non-standard form factor) so *the only* GPU I have available is a custom *RX560 4GB* for \\\\~$80.\\n\\nI'm always up for a good heist though....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0cqr5k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately it is an ultra small form factor system (non-standard form factor) so &lt;em&gt;the only&lt;/em&gt; GPU I have available is a custom &lt;em&gt;RX560 4GB&lt;/em&gt; for ~$80.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m always up for a good heist though....&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmt3kt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0cqr5k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751169205,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0asbid","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1lmt3kt","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0asbid/","num_reports":null,"locked":false,"name":"t1_n0asbid","created":1751142736,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751142736,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ab9ld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1751137205,"send_replies":true,"parent_id":"t3_1lmt3kt","score":1,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"why not add 3060?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ab9ld","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;why not add 3060?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ab9ld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751137205,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0b2nmv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ElectronSpiderwort","can_mod_post":false,"created_utc":1751146140,"send_replies":true,"parent_id":"t3_1lmt3kt","score":1,"author_fullname":"t2_mxbu5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"On an i5-7500 (4 cores) and llama.cpp, Llama-3.2-3B-Instruct-Q8\\\\_0.gguf gives me 36.67 prompt tok/sec and 7.06 generation tok/sec, for a small request of 1163 prompt tokens and 887 generation tokens. Set --threads to the number of cores you have, not the number of \\"threads\\" your CPU thinks it has","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0b2nmv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On an i5-7500 (4 cores) and llama.cpp, Llama-3.2-3B-Instruct-Q8_0.gguf gives me 36.67 prompt tok/sec and 7.06 generation tok/sec, for a small request of 1163 prompt tokens and 887 generation tokens. Set --threads to the number of cores you have, not the number of &amp;quot;threads&amp;quot; your CPU thinks it has&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0b2nmv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751146140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ddz9m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181119,"send_replies":true,"parent_id":"t3_1lmt3kt","score":-1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ddz9m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddz9m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181119,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ddzv7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751181129,"send_replies":true,"parent_id":"t3_1lmt3kt","score":-1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ddzv7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;connect an external gpu through a riser. $25 gpu, $10-$20 used 500W psu, you are good to go.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmt3kt/i58500_6_cores_24gb_ddr4_2666_dual_channel/n0ddzv7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751181129,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmt3kt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
