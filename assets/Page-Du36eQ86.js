import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"1. [Qwen 30b](https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF) \\\\[main model\\\\]\\n2. [Mistral Small 24b](https://huggingface.co/llmware/mistral-3.2-24b-gguf) \\\\[alternative\\\\]\\n3. [Gemmasutra 9b](https://huggingface.co/TheDrummer/Gemmasutra-9B-v1-GGUF) \\\\[descriptor/storywritter model\\\\]\\n4. [Gemmasutra 27b](https://huggingface.co/mradermacher/Gemmasutra-Pro-27B-v1.1-i1-GGUF) \\\\[main/descriptor/storywritter alternative\\\\]\\n5. [Mistral Nemo Instruct](https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF) \\\\[main/alternative\\\\]\\n6. [Qwen 32b](https://huggingface.co/unsloth/Qwen3-32B-GGUF) \\\\[not sure if necessary\\\\]\\n\\n  \\nI use Qwen Q3 mainly because of speed and context window, Q4 is not working for me. The others are alternatives, Gemmasutra is my descriptor since it has perfect sense of poses and distance of objects in a area, helps a lot with learning to describe stuff. But I don't think they can see uploaded images or even hear audios. Is there a way of adding vision to a model or a side model for describing images perfectly like Gemini does or understanding what is in a audio file?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Do these models have vision?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2e8vc","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.36,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_eljq22kg","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752774525,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF\\"&gt;Qwen 30b&lt;/a&gt; [main model]&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/llmware/mistral-3.2-24b-gguf\\"&gt;Mistral Small 24b&lt;/a&gt; [alternative]&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/TheDrummer/Gemmasutra-9B-v1-GGUF\\"&gt;Gemmasutra 9b&lt;/a&gt; [descriptor/storywritter model]&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/mradermacher/Gemmasutra-Pro-27B-v1.1-i1-GGUF\\"&gt;Gemmasutra 27b&lt;/a&gt; [main/descriptor/storywritter alternative]&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF\\"&gt;Mistral Nemo Instruct&lt;/a&gt; [main/alternative]&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\\"https://huggingface.co/unsloth/Qwen3-32B-GGUF\\"&gt;Qwen 32b&lt;/a&gt; [not sure if necessary]&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I use Qwen Q3 mainly because of speed and context window, Q4 is not working for me. The others are alternatives, Gemmasutra is my descriptor since it has perfect sense of poses and distance of objects in a area, helps a lot with learning to describe stuff. But I don&amp;#39;t think they can see uploaded images or even hear audios. Is there a way of adding vision to a model or a side model for describing images perfectly like Gemini does or understanding what is in a audio file?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?auto=webp&amp;s=aefad16ea2864eef99dcadf93df8444144fa67ed","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2c938c4ae12a4d27c8de4261ccf88356f37bc51","width":108,"height":58},{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c1a147d37410e2f1f72d34fabe85210dc38c33c","width":216,"height":116},{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=485e6b07fa7f377c43ceb6f9a4637a81b7818f89","width":320,"height":172},{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c2a635e5e9f6e95e116a2d7bc876a810ff12ae6a","width":640,"height":345},{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d6da9eeeb180f0538e9fc663954d4112ff522535","width":960,"height":518},{"url":"https://external-preview.redd.it/cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6fce397c967c8b239fd10cbcf83fa68dbb93d565","width":1080,"height":583}],"variants":{},"id":"cjzPEUuOBR2g8gk6tVmSifQ7qZZk1mITfDwM5z6fu9g"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m2e8vc","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"WEREWOLF_BX13","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/","subreddit_subscribers":500897,"created_utc":1752774525,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3od0j2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752776589,"send_replies":true,"parent_id":"t1_n3o9c6i","score":4,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The latest Mistral Small actually has native vision support, Magistral (Mistral's reasoning model) does not though. The model you linked to is a version of Magistral with the vision feature from Mistral Small implanted into it. \\n\\nWhich is neat for users of Magistral, but not needed if you are using the regular Mistral Small model which already supports vision.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3od0j2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The latest Mistral Small actually has native vision support, Magistral (Mistral&amp;#39;s reasoning model) does not though. The model you linked to is a version of Magistral with the vision feature from Mistral Small implanted into it. &lt;/p&gt;\\n\\n&lt;p&gt;Which is neat for users of Magistral, but not needed if you are using the regular Mistral Small model which already supports vision.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2e8vc","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/n3od0j2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752776589,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3o9c6i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zipperlein","can_mod_post":false,"created_utc":1752775537,"send_replies":true,"parent_id":"t3_1m2e8vc","score":3,"author_fullname":"t2_x3duw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There is a mistral small variant with vision. Did not test yet though.\\n\\n[https://huggingface.co/OptimusePrime/Magistral-Small-2506-Vision](https://huggingface.co/OptimusePrime/Magistral-Small-2506-Vision)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3o9c6i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is a mistral small variant with vision. Did not test yet though.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/OptimusePrime/Magistral-Small-2506-Vision\\"&gt;https://huggingface.co/OptimusePrime/Magistral-Small-2506-Vision&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/n3o9c6i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752775537,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2e8vc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3od3s2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752776615,"send_replies":true,"parent_id":"t3_1m2e8vc","score":4,"author_fullname":"t2_4amlo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mistral Small is the only one of those models with vision support.\\n\\nThe Gemma models you reference is based on Gemma 2, which does not support vision. For vision support in Gemma you have to use Gemma 3 models.\\n\\nFor Qwen, only the Qwen-VL family and the QVQ models have vision support. With Qwen2.5-VL being the best one currently.\\n\\nAs far as native audio support goes, that's still quite rare in the local LLM space. Though this seems to be changing as a number of audio models have come out quite recently. Including one from Mistral called Voxtral.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3od3s2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mistral Small is the only one of those models with vision support.&lt;/p&gt;\\n\\n&lt;p&gt;The Gemma models you reference is based on Gemma 2, which does not support vision. For vision support in Gemma you have to use Gemma 3 models.&lt;/p&gt;\\n\\n&lt;p&gt;For Qwen, only the Qwen-VL family and the QVQ models have vision support. With Qwen2.5-VL being the best one currently.&lt;/p&gt;\\n\\n&lt;p&gt;As far as native audio support goes, that&amp;#39;s still quite rare in the local LLM space. Though this seems to be changing as a number of audio models have come out quite recently. Including one from Mistral called Voxtral.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/n3od3s2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752776615,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2e8vc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3o7q29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tengo_harambe","can_mod_post":false,"created_utc":1752775080,"send_replies":true,"parent_id":"t3_1m2e8vc","score":2,"author_fullname":"t2_sgx7w7mb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'd recommend Qwen2.5-VL for vision. They have model sizes ranging from 3B to 72B. I've only used the 72B variant and it's very solid.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3o7q29","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d recommend Qwen2.5-VL for vision. They have model sizes ranging from 3B to 72B. I&amp;#39;ve only used the 72B variant and it&amp;#39;s very solid.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2e8vc/do_these_models_have_vision/n3o7q29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752775080,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2e8vc","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),i=()=>e.jsx(t,{data:a});export{i as default};
