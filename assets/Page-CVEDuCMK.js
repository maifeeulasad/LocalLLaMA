import{j as e}from"./index-CeRg6Q3f.js";import{R as a}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I would like something like a writing assistant, or summarizer using an LLM, but most of these extensions are tied to services like gpt or gemini, with no option to use your own openai compatible api or local model. ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Any good browser extensions that with any OpenAI compatible API or local model?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lps7c3","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.66,"author_flair_background_color":"#bbbdbf","subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_i697e","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751451618,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I would like something like a writing assistant, or summarizer using an LLM, but most of these extensions are tied to services like gpt or gemini, with no option to use your own openai compatible api or local model. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lps7c3","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"lemon07r","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/","subreddit_subscribers":494001,"created_utc":1751451618,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xpvsa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"created_utc":1751461527,"send_replies":true,"parent_id":"t1_n0x8na8","score":0,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s what I use; issues are usually model specific","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xpvsa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s what I use; issues are usually model specific&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lps7c3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/n0xpvsa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751461527,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n0x8na8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jamaalwakamaal","can_mod_post":false,"created_utc":1751454837,"send_replies":true,"parent_id":"t3_1lps7c3","score":5,"author_fullname":"t2_alyeos2m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try PageAssist","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x8na8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try PageAssist&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/n0x8na8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751454837,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lps7c3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n142avl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KonradFreeman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11eqpy","score":1,"author_fullname":"t2_hlftmupu5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, thanks for asking, in fact it would be easier for some parts.\\n\\nI stopped using OpenAI so I don't know what their current set up is but when I did use them it was fairly easy to swap out Ollama for OpenAI or the other way around.\\n\\nhttps://preview.redd.it/jqsyxs06gnaf1.jpeg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=ce86b5f45406e8e1693c708e28bea678f7c0be16","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n142avl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, thanks for asking, in fact it would be easier for some parts.&lt;/p&gt;\\n\\n&lt;p&gt;I stopped using OpenAI so I don&amp;#39;t know what their current set up is but when I did use them it was fairly easy to swap out Ollama for OpenAI or the other way around.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ce86b5f45406e8e1693c708e28bea678f7c0be16\\"&gt;https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=4032&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ce86b5f45406e8e1693c708e28bea678f7c0be16&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lps7c3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/n142avl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751544210,"media_metadata":{"jqsyxs06gnaf1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":81,"x":108,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed7b1218ad8227725f3d17bf2f6dd18241f32d5c"},{"y":162,"x":216,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=705dd7b9bc9904a61ae502e029c990c9bd0634fa"},{"y":240,"x":320,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=51c6e80b4bb40c94ab93d3b614d2580d8184889c"},{"y":480,"x":640,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2033a69ce486c1ced4dce4a2e84fbebb011f5774"},{"y":720,"x":960,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=00279af4652d70e28af20bfeb700eeb277eada43"},{"y":810,"x":1080,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=005dbb9b91e273e9f7ee6cfe84b9d68c6d51b870"}],"s":{"y":3024,"x":4032,"u":"https://preview.redd.it/jqsyxs06gnaf1.jpeg?width=4032&amp;format=pjpg&amp;auto=webp&amp;s=ce86b5f45406e8e1693c708e28bea678f7c0be16"},"id":"jqsyxs06gnaf1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1751544210,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n11eqpy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lemon07r","can_mod_post":false,"created_utc":1751501296,"send_replies":true,"parent_id":"t1_n0zyh0f","score":1,"author_fullname":"t2_i697e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Would it be much harder to use an openai compatible api instead of ollama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11eqpy","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would it be much harder to use an openai compatible api instead of ollama?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lps7c3","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/n11eqpy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751501296,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0zyh0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KonradFreeman","can_mod_post":false,"created_utc":1751485097,"send_replies":true,"parent_id":"t3_1lps7c3","score":2,"author_fullname":"t2_hlftmupu5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They are not hard to code, ask chatGPT to help you write an extension that uses Ollama, that is what I did for this extension:\\n\\n[https://chromewebstore.google.com/detail/ai-filename-generator/eocbkbnabbmclgneeakdbglicbhbimbj](https://chromewebstore.google.com/detail/ai-filename-generator/eocbkbnabbmclgneeakdbglicbhbimbj)\\n\\n  \\nThat is the beauty of vibe coding, all you have to do is give it enough structure and context and you can construct software which will pass the chrome store verifications and such.\\n\\nI have also made other extensions in the past as well, so I don't know if a non coder would know what to do but that is how I built that one.\\n\\nThat extension I linked just lets you right click an image in chrome and save it with an ai generated filename which uses an LLM with vision that quickly creates the name of the file because I got tired of having to keep coming up with names in order for it all to not be numbers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zyh0f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are not hard to code, ask chatGPT to help you write an extension that uses Ollama, that is what I did for this extension:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://chromewebstore.google.com/detail/ai-filename-generator/eocbkbnabbmclgneeakdbglicbhbimbj\\"&gt;https://chromewebstore.google.com/detail/ai-filename-generator/eocbkbnabbmclgneeakdbglicbhbimbj&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;That is the beauty of vibe coding, all you have to do is give it enough structure and context and you can construct software which will pass the chrome store verifications and such.&lt;/p&gt;\\n\\n&lt;p&gt;I have also made other extensions in the past as well, so I don&amp;#39;t know if a non coder would know what to do but that is how I built that one.&lt;/p&gt;\\n\\n&lt;p&gt;That extension I linked just lets you right click an image in chrome and save it with an ai generated filename which uses an LLM with vision that quickly creates the name of the file because I got tired of having to keep coming up with names in order for it all to not be numbers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lps7c3/any_good_browser_extensions_that_with_any_openai/n0zyh0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751485097,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lps7c3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),r=()=>e.jsx(a,{data:t});export{r as default};
