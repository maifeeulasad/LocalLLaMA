import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Fixed title: Asking LLMs for data visualized as plots\\n\\nHi, I'm looking for an app (e.g. LM Studio) + LLM solution that allows me to visualize LLM-generated data.\\n\\nI often ask LLM questions that returns some form of numerical data. For example, I might ask \\"what's the world's population over time\\" or \\"what's the population by country in 2000\\", which might return me a table with some data. This data is better visualized as a plot (e.g. bar graph).\\n\\nAre there models that might return plots (which I guess is a form of image)? I am aware of [https://github.com/nyanp/chat2plot](chat2plot), but are there others? Are there ones which can simply plug into a generalist app like LM Studio (afaik, LM Studio doesn't output graphics. Is that true?)?\\n\\nI'm pretty new to self-hosted local LLMs so pardon me if I'm missing something obvious!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Asking LLMs data visualized as plots","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ls663p","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.64,"author_flair_background_color":null,"subreddit_type":"public","ups":3,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_6czvm5cr","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":3,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751711905,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751708626,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Fixed title: Asking LLMs for data visualized as plots&lt;/p&gt;\\n\\n&lt;p&gt;Hi, I&amp;#39;m looking for an app (e.g. LM Studio) + LLM solution that allows me to visualize LLM-generated data.&lt;/p&gt;\\n\\n&lt;p&gt;I often ask LLM questions that returns some form of numerical data. For example, I might ask &amp;quot;what&amp;#39;s the world&amp;#39;s population over time&amp;quot; or &amp;quot;what&amp;#39;s the population by country in 2000&amp;quot;, which might return me a table with some data. This data is better visualized as a plot (e.g. bar graph).&lt;/p&gt;\\n\\n&lt;p&gt;Are there models that might return plots (which I guess is a form of image)? I am aware of [&lt;a href=\\"https://github.com/nyanp/chat2plot%5D(chat2plot)\\"&gt;https://github.com/nyanp/chat2plot](chat2plot)&lt;/a&gt;, but are there others? Are there ones which can simply plug into a generalist app like LM Studio (afaik, LM Studio doesn&amp;#39;t output graphics. Is that true?)?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m pretty new to self-hosted local LLMs so pardon me if I&amp;#39;m missing something obvious!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?auto=webp&amp;s=7723e569af1e8ff257ee3db7f222bb80e3ae7678","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=83f44c8691982ad244b150d65aff459fb5af56ed","width":108,"height":54},{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ba32ca7ee6ca6f824a135a3c17fdb257ffbfb32","width":216,"height":108},{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a8f6c4e384662e5c474a588b61568eafdfe0fc4","width":320,"height":160},{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e7223e9ff4aeb45d9d61a3c8499d357e4157c31","width":640,"height":320},{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c34d17676d9faf29f0b5eed5020de03d3f79c45d","width":960,"height":480},{"url":"https://external-preview.redd.it/EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=082296ef5dab26f9655e3f6205d204df6ae67499","width":1080,"height":540}],"variants":{},"id":"EmPlmkUgK-psVbhlsUSnHxl3YPY4gyS7RTnvxPH48b4"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1ls663p","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"injeolmi-bingsoo","discussion_type":null,"num_comments":3,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ls663p/asking_llms_data_visualized_as_plots/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ls663p/asking_llms_data_visualized_as_plots/","subreddit_subscribers":494986,"created_utc":1751708626,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1gd0k5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1751714638,"send_replies":true,"parent_id":"t3_1ls663p","score":1,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ask any devstral or coder whatever. To do the plot using matplotlib for exemple\\n\\nDo that in an agentic workflow. Have fun","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1gd0k5","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ask any devstral or coder whatever. To do the plot using matplotlib for exemple&lt;/p&gt;\\n\\n&lt;p&gt;Do that in an agentic workflow. Have fun&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ls663p/asking_llms_data_visualized_as_plots/n1gd0k5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751714638,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1ls663p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1g48rg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rich_Repeat_22","can_mod_post":false,"created_utc":1751709643,"send_replies":true,"parent_id":"t3_1ls663p","score":1,"author_fullname":"t2_viufiki6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's what AI agents are for which you will hook to the LLM. Something like A0 will even go and install everything needs to do the job, assuming the local LLM is has the knowledge how to do things. (can use hosted LLM with it too)\\n\\nNow if you want number crunching you need to use Python and hook the model that way and get charts out.\\n\\nAlso somewhere my eye caught a Stable Diffusion model generating charts with prompts, search for it.\\n\\nAs for pure number crunching, you need things like TimeGPT (remote), NeuralProphet (local), even META Prophet  (local) does good job even if is pure statistical (aka not \\"AI model\\"), IBM TTMs (local).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1g48rg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s what AI agents are for which you will hook to the LLM. Something like A0 will even go and install everything needs to do the job, assuming the local LLM is has the knowledge how to do things. (can use hosted LLM with it too)&lt;/p&gt;\\n\\n&lt;p&gt;Now if you want number crunching you need to use Python and hook the model that way and get charts out.&lt;/p&gt;\\n\\n&lt;p&gt;Also somewhere my eye caught a Stable Diffusion model generating charts with prompts, search for it.&lt;/p&gt;\\n\\n&lt;p&gt;As for pure number crunching, you need things like TimeGPT (remote), NeuralProphet (local), even META Prophet  (local) does good job even if is pure statistical (aka not &amp;quot;AI model&amp;quot;), IBM TTMs (local).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ls663p/asking_llms_data_visualized_as_plots/n1g48rg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751709643,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ls663p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1i9baz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AutomataManifold","can_mod_post":false,"created_utc":1751738846,"send_replies":true,"parent_id":"t3_1ls663p","score":2,"author_fullname":"t2_bfs5bk7y8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Easy way with no extra infrastructure is to tell it to generate the code to visualize a plot. Javascript and Python have good libraries for it, it's easier than trying to get the LLM to produce an accurate SVG.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1i9baz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Easy way with no extra infrastructure is to tell it to generate the code to visualize a plot. Javascript and Python have good libraries for it, it&amp;#39;s easier than trying to get the LLM to produce an accurate SVG.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ls663p/asking_llms_data_visualized_as_plots/n1i9baz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751738846,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ls663p","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),r=()=>e.jsx(t,{data:a});export{r as default};
