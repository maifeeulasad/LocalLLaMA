import{j as e}from"./index-CqAPCjw5.js";import{R as l}from"./RedditPostRenderer-4oBDAtGr.js";import"./index-D3Sdy_Op.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey all,\\n\\nWhat would be the most energy efficient (tokens per seconds does not matter, only tokens per watthours) to run Gemma 3 27b?\\n\\nA 3090 capped at 210watts gives 25 t/s - this is what I'm using now. I'm wondering if there is a more efficient alternative. Idle power is \\\\~30 watts, not a huge factor but it does matter.\\n\\nRyzen 395+ AI desktop version seems to be \\\\~120 watts, and 10/s  - so that would worse, actually?\\n\\na 4090 might be a bit more efficient? Like 20%?\\n\\nMacs seems to be on the same scale, less power but also less T/s.\\n\\nMy impression is that it's all a bit the same in terms of power, macs have a bit less idle power than a PC, but for the rest there isn't huge differences?\\n\\nMy main question if there are significant improvements (&gt;50%) in tokens per watt-hour in changing from  a 3090 to a mac or a ryzen ai (or something else?). My impression is that there isn't really much difference.\\n\\nEDIT: [https://www.reddit.com/r/LocalLLaMA/comments/1k9e5p0/gemma3\\\\_performance\\\\_on\\\\_ryzen\\\\_ai\\\\_max/](https://www.reddit.com/r/LocalLLaMA/comments/1k9e5p0/gemma3_performance_on_ryzen_ai_max/)\\n\\nThis is (I think?) 55 watts and 10 tokens per second. This would be kind of great result from ryzen 395 ai. Did anyone test this? Does anyone own a \\\\*mobile\\\\* ryzen ai pc?\\n\\nEDIT 2: Best contender so far (from the answers below) would be a mac mini M4 pro with 20 gpu cores (top spec mac mini) that could run at 15 t/s using 70 watts.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Most energy efficient way to run Gemma 3 27b?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lxhjjn","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":21,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_6j5c6oz9","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":21,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1752303119,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752265862,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\\n\\n&lt;p&gt;What would be the most energy efficient (tokens per seconds does not matter, only tokens per watthours) to run Gemma 3 27b?&lt;/p&gt;\\n\\n&lt;p&gt;A 3090 capped at 210watts gives 25 t/s - this is what I&amp;#39;m using now. I&amp;#39;m wondering if there is a more efficient alternative. Idle power is ~30 watts, not a huge factor but it does matter.&lt;/p&gt;\\n\\n&lt;p&gt;Ryzen 395+ AI desktop version seems to be ~120 watts, and 10/s  - so that would worse, actually?&lt;/p&gt;\\n\\n&lt;p&gt;a 4090 might be a bit more efficient? Like 20%?&lt;/p&gt;\\n\\n&lt;p&gt;Macs seems to be on the same scale, less power but also less T/s.&lt;/p&gt;\\n\\n&lt;p&gt;My impression is that it&amp;#39;s all a bit the same in terms of power, macs have a bit less idle power than a PC, but for the rest there isn&amp;#39;t huge differences?&lt;/p&gt;\\n\\n&lt;p&gt;My main question if there are significant improvements (&amp;gt;50%) in tokens per watt-hour in changing from  a 3090 to a mac or a ryzen ai (or something else?). My impression is that there isn&amp;#39;t really much difference.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1k9e5p0/gemma3_performance_on_ryzen_ai_max/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1k9e5p0/gemma3_performance_on_ryzen_ai_max/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This is (I think?) 55 watts and 10 tokens per second. This would be kind of great result from ryzen 395 ai. Did anyone test this? Does anyone own a *mobile* ryzen ai pc?&lt;/p&gt;\\n\\n&lt;p&gt;EDIT 2: Best contender so far (from the answers below) would be a mac mini M4 pro with 20 gpu cores (top spec mac mini) that could run at 15 t/s using 70 watts.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lxhjjn","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Extremely_Engaged","discussion_type":null,"num_comments":61,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/","subreddit_subscribers":498115,"created_utc":1752265862,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mfrxh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752269302,"send_replies":true,"parent_id":"t1_n2mfl3r","score":2,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"do you have any numbers in terms of watt vs tokens/s?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mfrxh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do you have any numbers in terms of watt vs tokens/s?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mfrxh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752269302,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mix83","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752270293,"send_replies":true,"parent_id":"t1_n2mfl3r","score":2,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"cool thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mix83","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;cool thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mix83/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270293,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mfl3r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MKU64","can_mod_post":false,"created_utc":1752269243,"send_replies":true,"parent_id":"t3_1lxhjjn","score":15,"author_fullname":"t2_wn7it","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably a Mac Mini M4 or M4 Pro in Low Power Consumption (don’t expect any decent speed in M4 as it gets less than 4 tokens per second after 12-14B).\\n\\nM4 goes to 10Wh in Low Power Consumption mode, my guess is that the M4 Pro has to be somewhere there too but it has double the memory bandwidth so I guess it should run at 3-5 tokens per second at int8.\\n\\nEdit: If you are talking plainly of tokens per watts then definitely an undervolt 5090. Even with how much energy it requires it’s still insanely efficient and the amount of memory bandwidth is insane. If you don’t take time to first token into account I think you should look at the Power Consumption vs Memory Bandwidth of all devices you’re interested in.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mfl3r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably a Mac Mini M4 or M4 Pro in Low Power Consumption (don’t expect any decent speed in M4 as it gets less than 4 tokens per second after 12-14B).&lt;/p&gt;\\n\\n&lt;p&gt;M4 goes to 10Wh in Low Power Consumption mode, my guess is that the M4 Pro has to be somewhere there too but it has double the memory bandwidth so I guess it should run at 3-5 tokens per second at int8.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: If you are talking plainly of tokens per watts then definitely an undervolt 5090. Even with how much energy it requires it’s still insanely efficient and the amount of memory bandwidth is insane. If you don’t take time to first token into account I think you should look at the Power Consumption vs Memory Bandwidth of all devices you’re interested in.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mfl3r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752269243,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mk0y4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752270640,"send_replies":true,"parent_id":"t1_n2mjdy7","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey interesting thank you!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mk0y4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey interesting thank you!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mk0y4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270640,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mjdy7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chregu","can_mod_post":false,"created_utc":1752270439,"send_replies":true,"parent_id":"t3_1lxhjjn","score":12,"author_fullname":"t2_2rzgu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My MacBook Pro M4 Max with 128 GB RAM uses about 12W when idle (internal screen off). And around 70-90W when running gemma-3-27b-it-qat@4bit MLX on LM Studio at 20-25 tokens/sec\\n\\nMakes it around 4w per token/sec. Way less than the 3090 with 310/25 = 12w per token/sec\\n\\nMeasured with iStat Menus, not on the wall, but resonates about with what a MacBook Pro draws.\\n\\nGemma 3 27b with 8bit makes about 15 tokens/sec.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mjdy7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My MacBook Pro M4 Max with 128 GB RAM uses about 12W when idle (internal screen off). And around 70-90W when running gemma-3-27b-it-qat@4bit MLX on LM Studio at 20-25 tokens/sec&lt;/p&gt;\\n\\n&lt;p&gt;Makes it around 4w per token/sec. Way less than the 3090 with 310/25 = 12w per token/sec&lt;/p&gt;\\n\\n&lt;p&gt;Measured with iStat Menus, not on the wall, but resonates about with what a MacBook Pro draws.&lt;/p&gt;\\n\\n&lt;p&gt;Gemma 3 27b with 8bit makes about 15 tokens/sec.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mjdy7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270439,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mlfaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752271084,"send_replies":true,"parent_id":"t1_n2mkrmu","score":2,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"THIS is an interesting answer, thank you!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mlfaz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;THIS is an interesting answer, thank you!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mlfaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752271084,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mkrmu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cergorach","can_mod_post":false,"created_utc":1752270875,"send_replies":true,"parent_id":"t3_1lxhjjn","score":7,"author_fullname":"t2_cs4w88d2l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mac Mini M4 Pro (20c GPU) 64GB unified RAM; Gemma 3 27b with MLX 14.5t/s power usage almost 70W (including connected keyboard and mouse). So more efficient then even the Ryzen 395 AI (if those results are accurate).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mkrmu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mac Mini M4 Pro (20c GPU) 64GB unified RAM; Gemma 3 27b with MLX 14.5t/s power usage almost 70W (including connected keyboard and mouse). So more efficient then even the Ryzen 395 AI (if those results are accurate).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mkrmu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270875,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2p80n5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"c3real2k","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ost2w","score":2,"author_fullname":"t2_h7qvk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, those are base M4s (10CPU, 10GPU, 120GBps). I'm sure RPC, even over TB, doesn't help either.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2p80n5","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, those are base M4s (10CPU, 10GPU, 120GBps). I&amp;#39;m sure RPC, even over TB, doesn&amp;#39;t help either.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2p80n5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752311621,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752311621,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ost2w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752302679,"send_replies":true,"parent_id":"t1_n2mswa6","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"fantastic! thank you!. Someone else here got 15 t/s on their mac mini (pro?) with 20gpu cores. Seems like I should avoid the base model of the m4?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ost2w","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;fantastic! thank you!. Someone else here got 15 t/s on their mac mini (pro?) with 20gpu cores. Seems like I should avoid the base model of the m4?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2ost2w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752302679,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mswa6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"c3real2k","can_mod_post":false,"created_utc":1752273573,"send_replies":true,"parent_id":"t3_1lxhjjn","score":4,"author_fullname":"t2_h7qvk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just ran some tests with Tiger Gemma 27B @ Q6K (was the only Gemma model I had laying around) on a RTX 3090 (unlimited and power limited to 220W), a dual 4060Ti 16GB config and a MacMini setup. Maybe it helps. Tests are of course incredibly unscientific...\\n\\nCommands:\\n\\n    # 3090\\n    llama.cpp/build-cuda/bin/llama-cli \\\\\\n    --model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n    -ngl 999 --tensor-split 0,24,0,0 \\\\\\n    -fa -ctk f16 -ctv f16 \\\\\\n    -p \\"Paper boat\\"\\n    \\n    # 4060Ti\\n    llama.cpp/build-cuda/bin/llama-cli \\\\\\n    --model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n    -ngl 999 --tensor-split 0,0,16,16 \\\\\\n    -fa -ctk f16 -ctv f16 \\\\\\n    -p \\"Paper boat\\"\\n    \\n    # Mac mini\\n    llamacpp/llama-cli \\\\\\n    --model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n    --no-mmap -ngl 999 --rpc 172.16.1.201:50050 --tensor-split 12,20 \\\\\\n    -fa -ctk f16 -ctv f16 \\\\\\n    -p \\"Paper boat\\"\\n\\nRTX 3090 @ 370W\\n\\n    llama_perf_context_print: prompt eval time =      60,27 ms /    11 tokens (    5,48 ms per token,   182,51 tokens per second)\\n    llama_perf_context_print:        eval time =   28887,86 ms /   848 runs   (   34,07 ms per token,    29,35 tokens per second)\\n    llama_perf_context_print:       total time =   31541,68 ms /   859 tokens\\n    \\n    TPS: 29,4\\n    AVG W: 347 (nvtop)\\n    idle: ~70W\\n    Ws/T: 11,8\\n\\nRTX 3090 @ 220W\\n\\n    llama_perf_context_print: prompt eval time =      98,27 ms /    11 tokens (    8,93 ms per token,   111,94 tokens per second)\\n    llama_perf_context_print:        eval time =   73864,77 ms /   990 runs   (   74,61 ms per token,    13,40 tokens per second)\\n    llama_perf_context_print:       total time =   76139,29 ms /  1001 tokens\\n    \\n    TPS: 13,4\\n    AVG W: 219 (nvtop)\\n    idle: ~70W\\n    Ws/T: 16,3\\n\\n2x RTX 4060Ti 16GB\\n\\n    llama_perf_context_print: prompt eval time =     120,84 ms /    11 tokens (   10,99 ms per token,    91,03 tokens per second)\\n    llama_perf_context_print:        eval time =   79815,68 ms /   906 runs   (   88,10 ms per token,    11,35 tokens per second)\\n    llama_perf_context_print:       total time =   84298,20 ms /   917 tokens\\n    \\n    TPS: 11,4\\n    AVG W: 164 (nvtop)\\n    idle: ~70W\\n    Ws/T: 14,5\\n\\nMac mini M4 16GB + Mac mini M4 24GB + Thunderbolt Network\\n\\n    llama_perf_context_print: prompt eval time =     751.59 ms /    11 tokens (   68.33 ms per token,    14.64 tokens per second)\\n    llama_perf_context_print:        eval time =  281518.85 ms /  1210 runs   (  232.66 ms per token,     4.30 tokens per second)\\n    llama_perf_context_print:       total time =  435641.65 ms /  1221 tokens\\n    \\n    TPS: 4,3\\n    AVG W: 35 (outlet)\\n    idle: 5W\\n    Ws/T: 8,1\\n\\nAccording to those values, the Mac mini setup should be the most efficient. Although you'd have to be REALLY patient at 4 tokens per second...\\n\\n(Though I'm curious while you're getting 25TPS @ 210W. What quantization are you using?)","edited":1752274118,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mswa6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just ran some tests with Tiger Gemma 27B @ Q6K (was the only Gemma model I had laying around) on a RTX 3090 (unlimited and power limited to 220W), a dual 4060Ti 16GB config and a MacMini setup. Maybe it helps. Tests are of course incredibly unscientific...&lt;/p&gt;\\n\\n&lt;p&gt;Commands:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;# 3090\\nllama.cpp/build-cuda/bin/llama-cli \\\\\\n--model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n-ngl 999 --tensor-split 0,24,0,0 \\\\\\n-fa -ctk f16 -ctv f16 \\\\\\n-p &amp;quot;Paper boat&amp;quot;\\n\\n# 4060Ti\\nllama.cpp/build-cuda/bin/llama-cli \\\\\\n--model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n-ngl 999 --tensor-split 0,0,16,16 \\\\\\n-fa -ctk f16 -ctv f16 \\\\\\n-p &amp;quot;Paper boat&amp;quot;\\n\\n# Mac mini\\nllamacpp/llama-cli \\\\\\n--model gguf/Tiger-Gemma-27B-v3a-Q6_K.gguf \\\\\\n--no-mmap -ngl 999 --rpc 172.16.1.201:50050 --tensor-split 12,20 \\\\\\n-fa -ctk f16 -ctv f16 \\\\\\n-p &amp;quot;Paper boat&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;RTX 3090 @ 370W&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;llama_perf_context_print: prompt eval time =      60,27 ms /    11 tokens (    5,48 ms per token,   182,51 tokens per second)\\nllama_perf_context_print:        eval time =   28887,86 ms /   848 runs   (   34,07 ms per token,    29,35 tokens per second)\\nllama_perf_context_print:       total time =   31541,68 ms /   859 tokens\\n\\nTPS: 29,4\\nAVG W: 347 (nvtop)\\nidle: ~70W\\nWs/T: 11,8\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;RTX 3090 @ 220W&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;llama_perf_context_print: prompt eval time =      98,27 ms /    11 tokens (    8,93 ms per token,   111,94 tokens per second)\\nllama_perf_context_print:        eval time =   73864,77 ms /   990 runs   (   74,61 ms per token,    13,40 tokens per second)\\nllama_perf_context_print:       total time =   76139,29 ms /  1001 tokens\\n\\nTPS: 13,4\\nAVG W: 219 (nvtop)\\nidle: ~70W\\nWs/T: 16,3\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;2x RTX 4060Ti 16GB&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;llama_perf_context_print: prompt eval time =     120,84 ms /    11 tokens (   10,99 ms per token,    91,03 tokens per second)\\nllama_perf_context_print:        eval time =   79815,68 ms /   906 runs   (   88,10 ms per token,    11,35 tokens per second)\\nllama_perf_context_print:       total time =   84298,20 ms /   917 tokens\\n\\nTPS: 11,4\\nAVG W: 164 (nvtop)\\nidle: ~70W\\nWs/T: 14,5\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Mac mini M4 16GB + Mac mini M4 24GB + Thunderbolt Network&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;llama_perf_context_print: prompt eval time =     751.59 ms /    11 tokens (   68.33 ms per token,    14.64 tokens per second)\\nllama_perf_context_print:        eval time =  281518.85 ms /  1210 runs   (  232.66 ms per token,     4.30 tokens per second)\\nllama_perf_context_print:       total time =  435641.65 ms /  1221 tokens\\n\\nTPS: 4,3\\nAVG W: 35 (outlet)\\nidle: 5W\\nWs/T: 8,1\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;According to those values, the Mac mini setup should be the most efficient. Although you&amp;#39;d have to be REALLY patient at 4 tokens per second...&lt;/p&gt;\\n\\n&lt;p&gt;(Though I&amp;#39;m curious while you&amp;#39;re getting 25TPS @ 210W. What quantization are you using?)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mswa6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752273573,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2o7wd8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ProtUA","can_mod_post":false,"created_utc":1752292375,"send_replies":true,"parent_id":"t3_1lxhjjn","score":2,"author_fullname":"t2_1woxr8u6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AMD MI50 has good power efficiency at 125W power limit. Gemma 3 27b Q4 = 20 tok/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2o7wd8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AMD MI50 has good power efficiency at 125W power limit. Gemma 3 27b Q4 = 20 tok/s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2o7wd8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752292375,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ngbfc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Square-Onion-1825","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mmsnr","score":1,"author_fullname":"t2_1mkh7x2yxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"perhaps the new nvidia spark might fit the bill.","edited":false,"author_flair_css_class":null,"name":"t1_n2ngbfc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;perhaps the new nvidia spark might fit the bill.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2ngbfc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752281825,"author_flair_text":null,"collapsed":false,"created_utc":1752281825,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mmsnr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mjcqj","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"of course, yes, but i'm interested if there is a significant difference. Lets say &gt;50%","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mmsnr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;of course, yes, but i&amp;#39;m interested if there is a significant difference. Lets say &amp;gt;50%&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mmsnr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752271531,"author_flair_text":null,"treatment_tags":[],"created_utc":1752271531,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mjcqj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Square-Onion-1825","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m7jxc","score":3,"author_fullname":"t2_1mkh7x2yxn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's relevant because the 'watt-hour' in your efficiency metric is calculated from the total power your entire system pulls from the wall, not just the 210 watts your GPU uses.\\n\\nYour Ryzen CPU, motherboard, and RAM all add to that total power consumption. This is why other hardware like an Apple Silicon Mac or a Ryzen AI laptop can be significantly more efficient—their entire system is a single, low-power package.\\n\\nThe true comparison is your whole PC's power draw against their whole system's power draw.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2mjcqj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s relevant because the &amp;#39;watt-hour&amp;#39; in your efficiency metric is calculated from the total power your entire system pulls from the wall, not just the 210 watts your GPU uses.&lt;/p&gt;\\n\\n&lt;p&gt;Your Ryzen CPU, motherboard, and RAM all add to that total power consumption. This is why other hardware like an Apple Silicon Mac or a Ryzen AI laptop can be significantly more efficient—their entire system is a single, low-power package.&lt;/p&gt;\\n\\n&lt;p&gt;The true comparison is your whole PC&amp;#39;s power draw against their whole system&amp;#39;s power draw.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mjcqj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270428,"author_flair_text":null,"treatment_tags":[],"created_utc":1752270428,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m7jxc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752266808,"send_replies":true,"parent_id":"t1_n2m5282","score":0,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ryzen 5700G, 32gb ddr4. Pretty regular last-gen PC. Why is that relevant? My question is more if there any other hardware that is significantly more efficient (tokens per watthour) than a PC.","edited":1752267378,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m7jxc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ryzen 5700G, 32gb ddr4. Pretty regular last-gen PC. Why is that relevant? My question is more if there any other hardware that is significantly more efficient (tokens per watthour) than a PC.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m7jxc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752266808,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m5282","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Square-Onion-1825","can_mod_post":false,"created_utc":1752266075,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_1mkh7x2yxn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you tell us what your full computer configuration is, hardware and software?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m5282","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you tell us what your full computer configuration is, hardware and software?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m5282/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752266075,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ojwx5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2n5wv2","score":1,"author_fullname":"t2_zebuyjw9s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh nice I hadn’t found this while researching! Cheers 😁","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2ojwx5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh nice I hadn’t found this while researching! Cheers 😁&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2ojwx5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752297901,"author_flair_text":null,"treatment_tags":[],"created_utc":1752297901,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2n5wv2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeltaSqueezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mz22v","score":2,"author_fullname":"t2_8jqx3m14","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Test along the curve. I did:\\n\\nhttps://jankyai.droidgram.com/power-limiting-rtx-3090-gpu-to-increase-power-efficiency/\\n\\nThis is for single inferencing. OP didn't specify whether he wanted efficiency for single inference or batch, which can change the answer on the optimal hardware.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2n5wv2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Test along the curve. I did:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://jankyai.droidgram.com/power-limiting-rtx-3090-gpu-to-increase-power-efficiency/\\"&gt;https://jankyai.droidgram.com/power-limiting-rtx-3090-gpu-to-increase-power-efficiency/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This is for single inferencing. OP didn&amp;#39;t specify whether he wanted efficiency for single inference or batch, which can change the answer on the optimal hardware.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2n5wv2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752278047,"author_flair_text":null,"treatment_tags":[],"created_utc":1752278047,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mz22v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m94vf","score":1,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean the performance axis for finding the sweet spot. I’ve been blindly following the power limit advice that supposedly is 20% less power for 5% drop in performance. I’m trying to find a way to get a bit more scientific.","edited":false,"author_flair_css_class":null,"name":"t1_n2mz22v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean the performance axis for finding the sweet spot. I’ve been blindly following the power limit advice that supposedly is 20% less power for 5% drop in performance. I’m trying to find a way to get a bit more scientific.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mz22v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752275678,"author_flair_text":null,"collapsed":false,"created_utc":1752275678,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m94vf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m8nzf","score":2,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i dont understand your question, i do the same thing. I also verified the usage with an external watt-meter","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m94vf","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i dont understand your question, i do the same thing. I also verified the usage with an external watt-meter&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m94vf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267275,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267275,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m8nzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DorphinPack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m6k42","score":1,"author_fullname":"t2_zebuyjw9s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How did you measure and are you using Linux? I slapped a simple power limit on mine on each boot but I’d like to explore more elegant options.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2m8nzf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you measure and are you using Linux? I slapped a simple power limit on mine on each boot but I’d like to explore more elegant options.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m8nzf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267138,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267138,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mbd4o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m6k42","score":1,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"40xx series cards will be more efficient because they're on a new lithography node.  I'm not sure if the 50xx series is, it's not on a truly new lithography tech, so at best minor gains in joules/token.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2mbd4o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;40xx series cards will be more efficient because they&amp;#39;re on a new lithography node.  I&amp;#39;m not sure if the 50xx series is, it&amp;#39;s not on a truly new lithography tech, so at best minor gains in joules/token.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mbd4o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267941,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267941,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m6k42","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752266513,"send_replies":true,"parent_id":"t1_n2m5l21","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes, as stated above. Sweetspot seems to be 210 watts. My question is if there is more efficient hardware out there.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m6k42","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, as stated above. Sweetspot seems to be 210 watts. My question is if there is more efficient hardware out there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m6k42/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752266513,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m5l21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Red_Redditor_Reddit","can_mod_post":false,"created_utc":1752266227,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_8eelmfjg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have you tried throttling your 3090?\\n\\nnvidia-smi -pl 100","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m5l21","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you tried throttling your 3090?&lt;/p&gt;\\n\\n&lt;p&gt;nvidia-smi -pl 100&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m5l21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752266227,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mboeu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m9nzw","score":3,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A4500 is Ampere architecture, same as 3090, so I wouldn't expect its energy efficiency to be any better.","edited":false,"author_flair_css_class":null,"name":"t1_n2mboeu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A4500 is Ampere architecture, same as 3090, so I wouldn&amp;#39;t expect its energy efficiency to be any better.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mboeu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268037,"author_flair_text":null,"collapsed":false,"created_utc":1752268037,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mawzl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mamgo","score":-1,"author_fullname":"t2_6j5c6oz9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"in terms of tokens per watthour its a bit the same probably?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2mawzl","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;in terms of tokens per watthour its a bit the same probably?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mawzl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267803,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267803,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mamgo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ciprianveg","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m9nzw","score":1,"author_fullname":"t2_j8fit2p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also a4500 can be power limited. I know I tried 150w and it worked similar to 200w, I assume it can get even lower","edited":false,"author_flair_css_class":null,"name":"t1_n2mamgo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also a4500 can be power limited. I know I tried 150w and it worked similar to 200w, I assume it can get even lower&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mamgo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267715,"author_flair_text":null,"collapsed":false,"created_utc":1752267715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m9nzw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m9es5","score":-1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"as mentioned above, i'm running my 3090 at 210 watts at 80% speed, so that would be a wash?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m9nzw","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;as mentioned above, i&amp;#39;m running my 3090 at 210 watts at 80% speed, so that would be a wash?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m9nzw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267432,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267432,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m9es5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ciprianveg","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2m8tle","score":1,"author_fullname":"t2_j8fit2p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A4500 is 25% slower than 3090 but 200W max power vs 350W","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2m9es5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A4500 is 25% slower than 3090 but 200W max power vs 350W&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m9es5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267356,"author_flair_text":null,"treatment_tags":[],"created_utc":1752267356,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m8tle","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752267184,"send_replies":true,"parent_id":"t1_n2m7o3r","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"care to elaborate?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m8tle","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;care to elaborate?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m8tle/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267184,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m7o3r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ciprianveg","can_mod_post":false,"created_utc":1752266843,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_j8fit2p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A4500?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m7o3r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A4500?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m7o3r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752266843,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mc3fx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2man0h","score":1,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you measuring power draw at the wall for the entire system?  If not, you should be.  Get a Kil-a-watt and plug your entire computer into it.  I'd expect joules/token to be better for the Ryzen chip.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2mc3fx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you measuring power draw at the wall for the entire system?  If not, you should be.  Get a Kil-a-watt and plug your entire computer into it.  I&amp;#39;d expect joules/token to be better for the Ryzen chip.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mc3fx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268164,"author_flair_text":null,"treatment_tags":[],"created_utc":1752268164,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2meqwd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mcwij","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting info thanks. i dont have a ryzen AI, only a last gen PC with a 3090 in it. \\n\\nI don't mind having to run windows.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2meqwd","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting info thanks. i dont have a ryzen AI, only a last gen PC with a 3090 in it. &lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t mind having to run windows.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2meqwd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268981,"author_flair_text":null,"treatment_tags":[],"created_utc":1752268981,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mcwij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MDT-49","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2man0h","score":1,"author_fullname":"t2_h8yrica5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not sure how you're running it with the Ryzen AI, but you might want to look at [Lemonade](https://github.com/lemonade-sdk/lemonade) to run it in the hardware optimized way. Although there is no support for the NPU on Linux yet. \\n\\nAlso, the Ryzen can't compete with dedicated GPUs on dense LLMs like Gemma 3, but it can probably be competitive on \\"performance/watt\\" when you use a MoE model, e.g. Qwen3-30B-A3, Qwen3-235B-A22B or Hunyuan-A13B depending on how much RAM you have.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2mcwij","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not sure how you&amp;#39;re running it with the Ryzen AI, but you might want to look at &lt;a href=\\"https://github.com/lemonade-sdk/lemonade\\"&gt;Lemonade&lt;/a&gt; to run it in the hardware optimized way. Although there is no support for the NPU on Linux yet. &lt;/p&gt;\\n\\n&lt;p&gt;Also, the Ryzen can&amp;#39;t compete with dedicated GPUs on dense LLMs like Gemma 3, but it can probably be competitive on &amp;quot;performance/watt&amp;quot; when you use a MoE model, e.g. Qwen3-30B-A3, Qwen3-235B-A22B or Hunyuan-A13B depending on how much RAM you have.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mcwij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268413,"author_flair_text":null,"treatment_tags":[],"created_utc":1752268413,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2man0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752267720,"send_replies":true,"parent_id":"t1_n2m9kgi","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you. Yes, this is my feeling as well. I was a bit disappointed in the results coming out from the Ryzen AI tests I've seen, for some reason I expected it to use less power per token.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2man0h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. Yes, this is my feeling as well. I was a bit disappointed in the results coming out from the Ryzen AI tests I&amp;#39;ve seen, for some reason I expected it to use less power per token.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2man0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267720,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2m9kgi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MDT-49","can_mod_post":false,"created_utc":1752267403,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_h8yrica5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm not an expert, but I'd say that the most energy efficient way (tokens/watthour) would probably be using a GPU and use the (lowest) precision that is natively supported by that GPU/Tensor Cores. \\n\\nThen, use batching to fully utilize the GPU and maximize the tokens/second throughput. \\n\\nBut if you're using it at home for personal use (only) in an \\"on demand\\" way, then idle time &amp; wattage is probably more important. If it's sitting mostly idle and you only need AI inference occasionally, then the Ryzen NPU is probably more energy-efficient overall, even though it's t/s is less efficient.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2m9kgi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not an expert, but I&amp;#39;d say that the most energy efficient way (tokens/watthour) would probably be using a GPU and use the (lowest) precision that is natively supported by that GPU/Tensor Cores. &lt;/p&gt;\\n\\n&lt;p&gt;Then, use batching to fully utilize the GPU and maximize the tokens/second throughput. &lt;/p&gt;\\n\\n&lt;p&gt;But if you&amp;#39;re using it at home for personal use (only) in an &amp;quot;on demand&amp;quot; way, then idle time &amp;amp; wattage is probably more important. If it&amp;#39;s sitting mostly idle and you only need AI inference occasionally, then the Ryzen NPU is probably more energy-efficient overall, even though it&amp;#39;s t/s is less efficient.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2m9kgi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267403,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mf96g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2megsf","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no, of course. But that's not super relevant to my question. I wonder if I would gain a lot (&gt;50%?) of power efficiency by changing to a mac or ryzen ai, for example. It seems that's not the case.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mf96g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, of course. But that&amp;#39;s not super relevant to my question. I wonder if I would gain a lot (&amp;gt;50%?) of power efficiency by changing to a mac or ryzen ai, for example. It seems that&amp;#39;s not the case.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mf96g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752269139,"author_flair_text":null,"treatment_tags":[],"created_utc":1752269139,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2megsf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mdyyv","score":1,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Something is wrong if the number is identical.  The rest of your system takes more than zero watts.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2megsf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Something is wrong if the number is identical.  The rest of your system takes more than zero watts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2megsf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268894,"author_flair_text":null,"treatment_tags":[],"created_utc":1752268894,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mdyyv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752268741,"send_replies":true,"parent_id":"t1_n2md0ka","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i do measure from the wall, it corresponds perfectly with nvidia-smi cap settings. I dont have a ryzen 395 to compare with","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mdyyv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i do measure from the wall, it corresponds perfectly with nvidia-smi cap settings. I dont have a ryzen 395 to compare with&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mdyyv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268741,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2md0ka","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1752268448,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you're not measuring power draw at the wall and instead trying to compare what some software tool says the GPU only is using and comparing that to the total max system power of a Ryzen 395 desktop you're probably off by a fair margin. \\n\\nGo buy a Kil-a-watt and plug it into the wall and look at the real total power draw of both systems during generation.  Then use the real total system power draw to calculate your joules/token.\\n\\nI'd also bet the Ryzen 395 total system idle power draw is lower than most desktops people have with 3090s in them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2md0ka","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re not measuring power draw at the wall and instead trying to compare what some software tool says the GPU only is using and comparing that to the total max system power of a Ryzen 395 desktop you&amp;#39;re probably off by a fair margin. &lt;/p&gt;\\n\\n&lt;p&gt;Go buy a Kil-a-watt and plug it into the wall and look at the real total power draw of both systems during generation.  Then use the real total system power draw to calculate your joules/token.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d also bet the Ryzen 395 total system idle power draw is lower than most desktops people have with 3090s in them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2md0ka/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268448,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mfe57","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752269182,"send_replies":true,"parent_id":"t1_n2mejo4","score":2,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you for the first real concrete answer :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mfe57","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you for the first real concrete answer :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mfe57/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752269182,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mejo4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752268919,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"3090 capped at 200-250W is indeed most efficient per joule way to run LLMs these days. You may also try to use speculative decoding, this bring extra 20% efficiency.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mejo4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3090 capped at 200-250W is indeed most efficient per joule way to run LLMs these days. You may also try to use speculative decoding, this bring extra 20% efficiency.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mejo4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268919,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2pz60h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2pu8l1","score":1,"author_fullname":"t2_6j5c6oz9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"i'm not sure, is it very low? maybe its 50? I've got more things connected so maybe I made a mistake.\\n\\nIn either case it's not the most important factor. What I care about the most is powerdraw during inference","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2pz60h","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i&amp;#39;m not sure, is it very low? maybe its 50? I&amp;#39;ve got more things connected so maybe I made a mistake.&lt;/p&gt;\\n\\n&lt;p&gt;In either case it&amp;#39;s not the most important factor. What I care about the most is powerdraw during inference&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2pz60h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752325166,"author_flair_text":null,"treatment_tags":[],"created_utc":1752325166,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2pu8l1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2opna3","score":1,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol. When you can prove that with a short video, the internet will believe you 😄","edited":false,"author_flair_css_class":null,"name":"t1_n2pu8l1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol. When you can prove that with a short video, the internet will believe you 😄&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lxhjjn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2pu8l1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752323210,"author_flair_text":null,"collapsed":false,"created_utc":1752323210,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2opna3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ndux4","score":-1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No, idle power is 30 watts","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2opna3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, idle power is 30 watts&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2opna3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752300926,"author_flair_text":null,"treatment_tags":[],"created_utc":1752300926,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ndux4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mi8zt","score":1,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don’t want to discredit you, but your post falls in the “I don’t believe it until I see it”.\\n\\nMaybe I misunderstood. You’re telling me your 3090 Desktop tower pulls 30 watts from the wall?? Again, I need everything not just the GPU. That said,  I was referring to the max load, not idle. Do yourself a favor and grab a real meter like this, and while under full load, measure how much your entire PC pulls from the wall.\\n\\nhttps://www.amazon.com/Connect-P4498-Electricity-Monitor-Consumption/dp/B0CVS4WXM9/ref=mp_s_a_1_1?dib=eyJ2IjoiMSJ9.KHO6Kv3btghMDageBiJfxzETGKrt9XBJ6YOUS2w-CDE.aXM3XU-jNcqleIZDqDZYpXHoTBYpwfx0zHmpPoP2olo&amp;dib_tag=se&amp;qid=1752280902&amp;refinements=p_89%3AKILL+A+WATT&amp;sr=8-1&amp;srs=8331248011","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ndux4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don’t want to discredit you, but your post falls in the “I don’t believe it until I see it”.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe I misunderstood. You’re telling me your 3090 Desktop tower pulls 30 watts from the wall?? Again, I need everything not just the GPU. That said,  I was referring to the max load, not idle. Do yourself a favor and grab a real meter like this, and while under full load, measure how much your entire PC pulls from the wall.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.amazon.com/Connect-P4498-Electricity-Monitor-Consumption/dp/B0CVS4WXM9/ref=mp_s_a_1_1?dib=eyJ2IjoiMSJ9.KHO6Kv3btghMDageBiJfxzETGKrt9XBJ6YOUS2w-CDE.aXM3XU-jNcqleIZDqDZYpXHoTBYpwfx0zHmpPoP2olo&amp;amp;dib_tag=se&amp;amp;qid=1752280902&amp;amp;refinements=p_89%3AKILL+A+WATT&amp;amp;sr=8-1&amp;amp;srs=8331248011\\"&gt;https://www.amazon.com/Connect-P4498-Electricity-Monitor-Consumption/dp/B0CVS4WXM9/ref=mp_s_a_1_1?dib=eyJ2IjoiMSJ9.KHO6Kv3btghMDageBiJfxzETGKrt9XBJ6YOUS2w-CDE.aXM3XU-jNcqleIZDqDZYpXHoTBYpwfx0zHmpPoP2olo&amp;amp;dib_tag=se&amp;amp;qid=1752280902&amp;amp;refinements=p_89%3AKILL+A+WATT&amp;amp;sr=8-1&amp;amp;srs=8331248011&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2ndux4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752280930,"author_flair_text":null,"treatment_tags":[],"created_utc":1752280930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mi8zt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752270081,"send_replies":true,"parent_id":"t1_n2mgstz","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i measure from the socket. Yes idle power is a factor (in total 30 watts), but it's not the main factor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mi8zt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i measure from the socket. Yes idle power is a factor (in total 30 watts), but it&amp;#39;s not the main factor.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mi8zt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270081,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mikly","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752270183,"send_replies":true,"parent_id":"t1_n2mgstz","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thanks, this is what i had in mind as well. Although, ryzen ai mobile version looks interesting (55watts)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mikly","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks, this is what i had in mind as well. Although, ryzen ai mobile version looks interesting (55watts)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mikly/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270183,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mgstz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simracerman","can_mod_post":false,"created_utc":1752269623,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_vbzgnic","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are missing a lot of watts not mentioned in the 3090 Desktop setup. If you want this to be more than just a fun exercise, let's get accurate and get a Kill-A-Watt meter that you plug into the wall and measure the TOTAL System pull for your 3090, not just the card.\\n\\nAt max load,  the CPU+MB+Memory+Drives+Any peripherals plugged into the PC and the inefficient power supply loss pull more power, and you end up wasting another 120-180 W. Your total can be 330-390 based on 210 W max cap you put on the 3090.\\n\\n  \\nThe 395+ has a[ total system pull of 170-180W.](https://www.servethehome.com/gmktec-evo-x2-review-an-amd-ryzen-ai-max-395-powerhouse/4/) Macs are even more power efficient, but for the price to performance, the 395+ is a better deal if you don't mind the 10 t/s (Macs are marginally faster).\\n\\n  \\nIf you are migrating away from a 3090 for the power save only, its not worth it. In my case, other factors come in with a 3090 Desktop. The gigantic Desktop tower days are over for me, as space is limited. The fan noise in unbearable is too loud for even short inference sessions. The heat from a 300+ W tower is a space heater in the 100+ degree summer where I live, which pushes me to cool the house for longer periods.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mgstz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are missing a lot of watts not mentioned in the 3090 Desktop setup. If you want this to be more than just a fun exercise, let&amp;#39;s get accurate and get a Kill-A-Watt meter that you plug into the wall and measure the TOTAL System pull for your 3090, not just the card.&lt;/p&gt;\\n\\n&lt;p&gt;At max load,  the CPU+MB+Memory+Drives+Any peripherals plugged into the PC and the inefficient power supply loss pull more power, and you end up wasting another 120-180 W. Your total can be 330-390 based on 210 W max cap you put on the 3090.&lt;/p&gt;\\n\\n&lt;p&gt;The 395+ has a&lt;a href=\\"https://www.servethehome.com/gmktec-evo-x2-review-an-amd-ryzen-ai-max-395-powerhouse/4/\\"&gt; total system pull of 170-180W.&lt;/a&gt; Macs are even more power efficient, but for the price to performance, the 395+ is a better deal if you don&amp;#39;t mind the 10 t/s (Macs are marginally faster).&lt;/p&gt;\\n\\n&lt;p&gt;If you are migrating away from a 3090 for the power save only, its not worth it. In my case, other factors come in with a 3090 Desktop. The gigantic Desktop tower days are over for me, as space is limited. The fan noise in unbearable is too loud for even short inference sessions. The heat from a 300+ W tower is a space heater in the 100+ degree summer where I live, which pushes me to cool the house for longer periods.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mgstz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752269623,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2mk88e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ambitious-Most4485","can_mod_post":false,"created_utc":1752270703,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_y8jr8mmod","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What quant are u running (if any)?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mk88e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What quant are u running (if any)?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mk88e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752270703,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2moynp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Munkie50","can_mod_post":false,"created_utc":1752272237,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_dwbph","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Running it on one of those gaming phones with a Snapdragon 8 Elite and 24GB RAM maybe.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2moynp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Running it on one of those gaming phones with a Snapdragon 8 Elite and 24GB RAM maybe.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2moynp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752272237,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2n7571","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DeltaSqueezer","can_mod_post":false,"created_utc":1752278487,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_8jqx3m14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are you looking at idle power, or fully utilized or something in between?\\nSingle inferencing or batched?\\nI don't have cards later than 30 series, but I would expect these to increase in efficiency when inferencing (assuming you power limit to the optimal efficiency).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2n7571","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you looking at idle power, or fully utilized or something in between?\\nSingle inferencing or batched?\\nI don&amp;#39;t have cards later than 30 series, but I would expect these to increase in efficiency when inferencing (assuming you power limit to the optimal efficiency).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2n7571/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752278487,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2nixrz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1752282783,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Snapdragon X Elite laptop, llama.cpp, Adreno OpenCL backend, Gemma 3 27B q4_0: I'm getting about 4 t/s at 20 W. Low or high performance mode doesn't affect the t/s or power usage.\\n\\nThe CPU backend gets 6 t/s at 40-60 W in high performance mode.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nixrz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Snapdragon X Elite laptop, llama.cpp, Adreno OpenCL backend, Gemma 3 27B q4_0: I&amp;#39;m getting about 4 t/s at 20 W. Low or high performance mode doesn&amp;#39;t affect the t/s or power usage.&lt;/p&gt;\\n\\n&lt;p&gt;The CPU backend gets 6 t/s at 40-60 W in high performance mode.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2nixrz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752282783,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ot4sg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752302860,"send_replies":true,"parent_id":"t1_n2nladw","score":1,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"interesting! thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ot4sg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;interesting! thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2ot4sg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752302860,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2nladw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"My_Unbiased_Opinion","can_mod_post":false,"created_utc":1752283636,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_esiyl0yb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Key point: the UD Q2KXL quant by unsloth is the most efficient in terms of size to performance ratio (check their documentation). \\n\\n\\nThis means, you can get more tokens per second than for example running Q4 since you need less memory bandwidth. \\n\\n\\nBasically, running Q2KXL UD would give you the most efficiency in terms of token per watt. \\n\\n\\nAlso, run ik_llama.cpp. That fork is also faster than standard llama.cpp. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2nladw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Key point: the UD Q2KXL quant by unsloth is the most efficient in terms of size to performance ratio (check their documentation). &lt;/p&gt;\\n\\n&lt;p&gt;This means, you can get more tokens per second than for example running Q4 since you need less memory bandwidth. &lt;/p&gt;\\n\\n&lt;p&gt;Basically, running Q2KXL UD would give you the most efficiency in terms of token per watt. &lt;/p&gt;\\n\\n&lt;p&gt;Also, run ik_llama.cpp. That fork is also faster than standard llama.cpp. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2nladw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752283636,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2o5z5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1752291574,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; A 3090 capped at 210watts gives 25 t/s - this is what I'm using now.\\n\\nHow are you running a 3090 without a computer? ;) You need to factor that in too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2o5z5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;A 3090 capped at 210watts gives 25 t/s - this is what I&amp;#39;m using now.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;How are you running a 3090 without a computer? ;) You need to factor that in too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2o5z5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752291574,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oa3dd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Equivalent-Bet-8771","can_mod_post":false,"created_utc":1752293306,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_l16sej0pt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"NVFP4?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2oa3dd","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;NVFP4?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2oa3dd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752293306,"author_flair_text":"textgen web UI","treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2oocul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2mbty5","score":2,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the math would be a bit more complicated than that. Your approach isn't accounting for idle power usage.\\n\\nAssuming that the break-even point during inference between the RPI and the 3090 is 1.4tps on the Pi, The Pi would win out, because it'd be idling at a considerably lower power level (probably an order of magnitude lower or more) and presumably (if this is for a personal project, the system woudl be idle most of the time)..","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2oocul","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the math would be a bit more complicated than that. Your approach isn&amp;#39;t accounting for idle power usage.&lt;/p&gt;\\n\\n&lt;p&gt;Assuming that the break-even point during inference between the RPI and the 3090 is 1.4tps on the Pi, The Pi would win out, because it&amp;#39;d be idling at a considerably lower power level (probably an order of magnitude lower or more) and presumably (if this is for a personal project, the system woudl be idle most of the time)..&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2oocul/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752300229,"author_flair_text":null,"treatment_tags":[],"created_utc":1752300229,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2mbty5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Extremely_Engaged","can_mod_post":false,"created_utc":1752268083,"send_replies":true,"parent_id":"t1_n2matd3","score":5,"author_fullname":"t2_6j5c6oz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That really depends how many tokens per second you get for those 12 watts. It would have to be &gt; 1.4 tokens per second to beat the 3090.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2mbty5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That really depends how many tokens per second you get for those 12 watts. It would have to be &amp;gt; 1.4 tokens per second to beat the 3090.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lxhjjn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2mbty5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752268083,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2matd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"remghoost7","can_mod_post":false,"created_utc":1752267773,"send_replies":true,"parent_id":"t3_1lxhjjn","score":2,"author_fullname":"t2_sejql","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean, if you're going *full min/max*, running it on something like a [Raspberry Pi 5 (16gb of RAM)](https://www.raspberrypi.com/products/raspberry-pi-5/) in q3 or below would probably be the \\"most energy efficient\\" method...  \\nA pi 5 allegedly pulls around 12w under load.\\n\\nI don't know how efficient it would be per watthour though.  \\nIt's got a quad core ARM processor clocked at 2.4GHz (non-hyperthreaded), but I'm not sure what sort of t/s you'd be getting.\\n\\nI only have a Pi 4 on me, so I'm not able to test it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2matd3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, if you&amp;#39;re going &lt;em&gt;full min/max&lt;/em&gt;, running it on something like a &lt;a href=\\"https://www.raspberrypi.com/products/raspberry-pi-5/\\"&gt;Raspberry Pi 5 (16gb of RAM)&lt;/a&gt; in q3 or below would probably be the &amp;quot;most energy efficient&amp;quot; method...&lt;br/&gt;\\nA pi 5 allegedly pulls around 12w under load.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t know how efficient it would be per watthour though.&lt;br/&gt;\\nIt&amp;#39;s got a quad core ARM processor clocked at 2.4GHz (non-hyperthreaded), but I&amp;#39;m not sure what sort of t/s you&amp;#39;d be getting.&lt;/p&gt;\\n\\n&lt;p&gt;I only have a Pi 4 on me, so I&amp;#39;m not able to test it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2matd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752267773,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2q30xp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tcpjack","can_mod_post":false,"created_utc":1752326620,"send_replies":true,"parent_id":"t3_1lxhjjn","score":1,"author_fullname":"t2_3mm65","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try putting your 3090 into suspend and back out. I have a script that checks per hour and does it auto if it's not being used. \\n\\nOn mobile now so can't say to certain, but I believe idle power went from 30-&gt;19w","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2q30xp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try putting your 3090 into suspend and back out. I have a script that checks per hour and does it auto if it&amp;#39;s not being used. &lt;/p&gt;\\n\\n&lt;p&gt;On mobile now so can&amp;#39;t say to certain, but I believe idle power went from 30-&amp;gt;19w&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lxhjjn/most_energy_efficient_way_to_run_gemma_3_27b/n2q30xp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752326620,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lxhjjn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(l,{data:t});export{o as default};
