import{j as e}from"./index-BgwOAK4-.js";import{R as l}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I believe this is the first NPU specifically designed for LLM inference. They specifically mention 2.5 or 5GB of \\"ultra high bandwidth memory\\", but not the actual speed. 50TPS for a 7B model at Q4 implies around 200GB/s. The high prompt processing speed is the best part IMO, it's going to let an on device assistant use a lot more context.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Rockchip unveils RK182X LLM co-processor: Runs Qwen 2.5 7B at 50TPS decode, 800TPS prompt processing","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":102,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5fmlp","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":null,"ups":130,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lkljr","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":130,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=140&amp;height=102&amp;crop=140:102,smart&amp;auto=webp&amp;s=f46b99f9160b02acaab35b0793c2419a717f902a","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753094763,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"cnx-software.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I believe this is the first NPU specifically designed for LLM inference. They specifically mention 2.5 or 5GB of &amp;quot;ultra high bandwidth memory&amp;quot;, but not the actual speed. 50TPS for a 7B model at Q4 implies around 200GB/s. The high prompt processing speed is the best part IMO, it&amp;#39;s going to let an on device assistant use a lot more context.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.cnx-software.com/2025/07/18/rockchip-unveils-rk3668-10-core-arm-cortex-a730-cortex-a530-soc-with-16-tops-npu-rk182x-llm-vlm-co-processor/#rockchip-rk182x-llm-vlm-accelerator","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?auto=webp&amp;s=a3357893385aa57e61c85776502b465fe73661a4","width":1184,"height":868},"resolutions":[{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=19d2a2efbd9333bbc8e7495d96c37dc9a67f94f7","width":108,"height":79},{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4320f14e39faee0bd0ec022e73a0260326f90d4","width":216,"height":158},{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36df6ea44afc6e837f534a02a66625d799b64a88","width":320,"height":234},{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ec21866ca44554bfe2c9ada5521c937f241afc3","width":640,"height":469},{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f3f1fc5136f191685dd65bd8cc69f5a732d025a2","width":960,"height":703},{"url":"https://external-preview.redd.it/p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=24e96efb97efa4c62ad46fa709863ab37c9c8266","width":1080,"height":791}],"variants":{},"id":"p-XdyFJrlRnofvAjkk2RhNaWbyuM0y_S5JEPvTprq-8"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m5fmlp","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"PmMeForPCBuilds","discussion_type":null,"num_comments":44,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/","stickied":false,"url":"https://www.cnx-software.com/2025/07/18/rockchip-unveils-rk3668-10-core-arm-cortex-a730-cortex-a530-soc-with-16-tops-npu-rk182x-llm-vlm-co-processor/#rockchip-rk182x-llm-vlm-accelerator","subreddit_subscribers":502516,"created_utc":1753094763,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bwsj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PmMeForPCBuilds","can_mod_post":false,"created_utc":1753101256,"send_replies":true,"parent_id":"t1_n4bjcnb","score":29,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Prompt processing is compute limited as it runs across all tokens in parallel and only needs to load the model from memory once. So it can load the first layer and process all context tokens with those weights, then the second, etc. Whereas token generation needs to load every layer to generate a single token, so it's memory bandwidth bound.\\n\\nNPUs have a lot more compute than a CPU or GPU, as they can fill it with optimized low precision tensor cores instead of general purpose compute. If you look at Apple's NPUs for example, they have a higher TOPS rating than the GPU despite using less silicon. However, most other NPU designs use the systems main memory which is slow, so they aren't very useful for token generation. This one has its own fast memory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bwsj7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Prompt processing is compute limited as it runs across all tokens in parallel and only needs to load the model from memory once. So it can load the first layer and process all context tokens with those weights, then the second, etc. Whereas token generation needs to load every layer to generate a single token, so it&amp;#39;s memory bandwidth bound.&lt;/p&gt;\\n\\n&lt;p&gt;NPUs have a lot more compute than a CPU or GPU, as they can fill it with optimized low precision tensor cores instead of general purpose compute. If you look at Apple&amp;#39;s NPUs for example, they have a higher TOPS rating than the GPU despite using less silicon. However, most other NPU designs use the systems main memory which is slow, so they aren&amp;#39;t very useful for token generation. This one has its own fast memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bwsj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101256,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cw9fe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PmMeForPCBuilds","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bn4xc","score":5,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is basically true, the hardwired part is the matrix multiplication unit, usually a [systolic array](https://en.wikipedia.org/wiki/Systolic_array). It’s the same thing that Nvidia tensor cores use.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4cw9fe","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is basically true, the hardwired part is the matrix multiplication unit, usually a &lt;a href=\\"https://en.wikipedia.org/wiki/Systolic_array\\"&gt;systolic array&lt;/a&gt;. It’s the same thing that Nvidia tensor cores use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4cw9fe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753112398,"author_flair_text":null,"treatment_tags":[],"created_utc":1753112398,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bnqog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnomalyNexus","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bn4xc","score":3,"author_fullname":"t2_3q8dd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah they must have done something special there. The discrepancy seems way higher than on other hardware &amp; I thought both are roughly under the same hardware constraints - GPU compute and memory.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4bnqog","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah they must have done something special there. The discrepancy seems way higher than on other hardware &amp;amp; I thought both are roughly under the same hardware constraints - GPU compute and memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bnqog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753097638,"author_flair_text":null,"treatment_tags":[],"created_utc":1753097638,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bn4xc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"National_Meeting_749","can_mod_post":false,"created_utc":1753097369,"send_replies":true,"parent_id":"t1_n4bjcnb","score":29,"author_fullname":"t2_drm5tg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is pure guessing from my part,\\nBut there is probably some bit of the math for prompt processing that they were able to 'hardwire' and make an ASIC component for the chip that is much faster than multi-purpose cores would be able to process them.\\n\\nThat generally what happens when some process gets accelerated quite a bit by a piece of hardware. \\n\\nMining Bitcoin on GPU's became obsolete when the ASIC miners came out, which is what I'm hoping happens with LLM's. These AI accelerator cards become the best thing to run LLMs on, and the GPU market will have pressure taken off of it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bn4xc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is pure guessing from my part,\\nBut there is probably some bit of the math for prompt processing that they were able to &amp;#39;hardwire&amp;#39; and make an ASIC component for the chip that is much faster than multi-purpose cores would be able to process them.&lt;/p&gt;\\n\\n&lt;p&gt;That generally what happens when some process gets accelerated quite a bit by a piece of hardware. &lt;/p&gt;\\n\\n&lt;p&gt;Mining Bitcoin on GPU&amp;#39;s became obsolete when the ASIC miners came out, which is what I&amp;#39;m hoping happens with LLM&amp;#39;s. These AI accelerator cards become the best thing to run LLMs on, and the GPU market will have pressure taken off of it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bn4xc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753097369,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bnsqu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Amazing_Athlete_2265","can_mod_post":false,"created_utc":1753097664,"send_replies":true,"parent_id":"t1_n4bjcnb","score":7,"author_fullname":"t2_1nw9fzb7dt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Almost all of my benchmarks show this is the case for most local models. For example, for falcon-h1-7b-instruct I am showing prompt processing rate of 104 t/s and inference rate of 7 t/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bnsqu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Almost all of my benchmarks show this is the case for most local models. For example, for falcon-h1-7b-instruct I am showing prompt processing rate of 104 t/s and inference rate of 7 t/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bnsqu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753097664,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bqnfq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1753098867,"send_replies":true,"parent_id":"t1_n4bjcnb","score":12,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is an odd statement for someone who run models locally, as it is well known fact that PP is faster than TG on any accelerated platform, but not on cpus. Token generation is bottlenecked by memory bandwidth, which difficult to scale. PP is limited by compute, which is easier to scale by dropping more computation units on the chip, without need to reengineer bus interface.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqnfq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is an odd statement for someone who run models locally, as it is well known fact that PP is faster than TG on any accelerated platform, but not on cpus. Token generation is bottlenecked by memory bandwidth, which difficult to scale. PP is limited by compute, which is easier to scale by dropping more computation units on the chip, without need to reengineer bus interface.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bqnfq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098867,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bjp2x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Vas1le","can_mod_post":false,"created_utc":1753095792,"send_replies":true,"parent_id":"t1_n4bjcnb","score":-8,"author_fullname":"t2_9mhfdr5f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It connects to China servers for processing \\n\\n\\n^/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bjp2x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It connects to China servers for processing &lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;/s&lt;/sup&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bjp2x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095792,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4blrdt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jack-of-the-Shadows","can_mod_post":false,"created_utc":1753096751,"send_replies":true,"parent_id":"t1_n4bjcnb","score":0,"author_fullname":"t2_2pykl6xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Memory bandwith?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4blrdt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Memory bandwith?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4blrdt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753096751,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bpc5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1753098330,"send_replies":true,"parent_id":"t1_n4bjcnb","score":-1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[flash attention ](https://arxiv.org/abs/2205.14135)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bpc5h","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2205.14135\\"&gt;flash attention &lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bpc5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098330,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bjcnb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AnomalyNexus","can_mod_post":false,"created_utc":1753095629,"send_replies":true,"parent_id":"t3_1m5fmlp","score":26,"author_fullname":"t2_3q8dd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wonder why it’s so much faster on prompt processing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bjcnb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wonder why it’s so much faster on prompt processing&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bjcnb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095629,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bldtl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thellton","can_mod_post":false,"created_utc":1753096580,"send_replies":true,"parent_id":"t3_1m5fmlp","score":18,"author_fullname":"t2_gzzli","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"that link also makes mention of an announcement for an RK3668 SoC. \\n\\n&gt;CPU – 4x Cortex-A730 + 6x Cortex-A530 Armv9.3 cores delivering around 200K DMIPS; note: neither core has been announced by Arm yet\\n\\n&gt;GPU – Arm Magni GPU delivering up to 1-1.5 TFLOPS of performance\\n\\n&gt;***AI accelerator – 16 TOPS RKNN-P3 NPU***\\n\\n&gt;VPU – 8K 60 FPS video decoder\\n\\n&gt;ISP – AI-enhanced ISP supporting up to 8K @ 30 FPS\\n\\n&gt;Memory – LPDDR5/5x/6 up to 100 GB/s\\n\\n&gt;Storage – UFS 4.0\\n\\n&gt;Video Output – HDMI 2.1 up to 8K 60 FPS, MIPI DSI\\n\\n&gt;Peripherals interfaces – PCIe, UCIe\\n\\n&gt;Manufacturing Process- 5~6nm         \\n\\nwhich is much more interesting as that'll likely support up to 48GB of RAM going by its predecessor (the RK3588), which supports 32GB of RAM. would definitely make for a way better base for a mobile inferencing device.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bldtl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that link also makes mention of an announcement for an RK3668 SoC. &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;CPU – 4x Cortex-A730 + 6x Cortex-A530 Armv9.3 cores delivering around 200K DMIPS; note: neither core has been announced by Arm yet&lt;/p&gt;\\n\\n&lt;p&gt;GPU – Arm Magni GPU delivering up to 1-1.5 TFLOPS of performance&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;AI accelerator – 16 TOPS RKNN-P3 NPU&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;VPU – 8K 60 FPS video decoder&lt;/p&gt;\\n\\n&lt;p&gt;ISP – AI-enhanced ISP supporting up to 8K @ 30 FPS&lt;/p&gt;\\n\\n&lt;p&gt;Memory – LPDDR5/5x/6 up to 100 GB/s&lt;/p&gt;\\n\\n&lt;p&gt;Storage – UFS 4.0&lt;/p&gt;\\n\\n&lt;p&gt;Video Output – HDMI 2.1 up to 8K 60 FPS, MIPI DSI&lt;/p&gt;\\n\\n&lt;p&gt;Peripherals interfaces – PCIe, UCIe&lt;/p&gt;\\n\\n&lt;p&gt;Manufacturing Process- 5~6nm         &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;which is much more interesting as that&amp;#39;ll likely support up to 48GB of RAM going by its predecessor (the RK3588), which supports 32GB of RAM. would definitely make for a way better base for a mobile inferencing device.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bldtl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753096580,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bq6wz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1753098684,"send_replies":true,"parent_id":"t3_1m5fmlp","score":13,"author_fullname":"t2_1hgbaqgbnq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope this is a wakeup call for Qualcomm. The problem is that Qualcomm's developer tooling is a pain to deal with and the Hexagon Tensor Processor (the internal name for the NPU) can't be used with GGUF models, not without Qualcomm developers coming in. They actually did that with the Adreno GPU OpenCL backend and it's a nice low-power option for users running Snapdragon X laptops.\\n\\nAI at the edge doesn't need kilowatt GPUs, it needs NPUs running at 5W or 10W on smaller models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bq6wz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope this is a wakeup call for Qualcomm. The problem is that Qualcomm&amp;#39;s developer tooling is a pain to deal with and the Hexagon Tensor Processor (the internal name for the NPU) can&amp;#39;t be used with GGUF models, not without Qualcomm developers coming in. They actually did that with the Adreno GPU OpenCL backend and it&amp;#39;s a nice low-power option for users running Snapdragon X laptops.&lt;/p&gt;\\n\\n&lt;p&gt;AI at the edge doesn&amp;#39;t need kilowatt GPUs, it needs NPUs running at 5W or 10W on smaller models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bq6wz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4blqgs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HiddenoO","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bi4po","score":11,"author_fullname":"t2_8127x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sequence length is the actual length of the input (context), not the maximum length. Obviously, this also means that the numbers presented will get worse if your input is longer than 1024, assuming longer input fits in the memory.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4blqgs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sequence length is the actual length of the input (context), not the maximum length. Obviously, this also means that the numbers presented will get worse if your input is longer than 1024, assuming longer input fits in the memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4blqgs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753096740,"author_flair_text":null,"treatment_tags":[],"created_utc":1753096740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4by3ey","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fast-Satisfaction482","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bvby6","score":1,"author_fullname":"t2_9ceux4xp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it dedicated memory like in a GPU or would the OS also need to be in that memory? All in all, the chip sounds really nice if there is no big caveat hidden somewhere. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4by3ey","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it dedicated memory like in a GPU or would the OS also need to be in that memory? All in all, the chip sounds really nice if there is no big caveat hidden somewhere. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4by3ey/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101730,"author_flair_text":null,"treatment_tags":[],"created_utc":1753101730,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4elgtn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PmMeForPCBuilds","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4eemcc","score":1,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[Here](https://www.cnx-software.com/2025/07/18/rockchip-unveils-rk3668-10-core-arm-cortex-a730-cortex-a530-soc-with-16-tops-npu-rk182x-llm-vlm-co-processor/#:~:text=The%20company%20indicates%20that%20INT4/FP4%207B%20parameter%20models%20can%20fit%20into%203.5GB%20of%20RAM)","edited":false,"author_flair_css_class":null,"name":"t1_n4elgtn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.cnx-software.com/2025/07/18/rockchip-unveils-rk3668-10-core-arm-cortex-a730-cortex-a530-soc-with-16-tops-npu-rk182x-llm-vlm-co-processor/#:%7E:text=The%20company%20indicates%20that%20INT4/FP4%207B%20parameter%20models%20can%20fit%20into%203.5GB%20of%20RAM\\"&gt;Here&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5fmlp","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4elgtn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753129564,"author_flair_text":null,"collapsed":false,"created_utc":1753129564,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eemcc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MMAgeezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bvby6","score":1,"author_fullname":"t2_34hhuqbx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Where did you get 3.5GB from? It says the Qwen 7B scores are estimated, and 4-bit Qwen 2.5 7B is more like 4.5GB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eemcc","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where did you get 3.5GB from? It says the Qwen 7B scores are estimated, and 4-bit Qwen 2.5 7B is more like 4.5GB.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4eemcc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127607,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753127607,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bvby6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PmMeForPCBuilds","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bi4po","score":4,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It has 5GB of memory and 3.5GB are taken by the model (for Qwen 7B), so you'd have 1.5GB left over for context. That should be able to fit more than 2048 tokens, but I'm not sure what the limit is.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4bvby6","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It has 5GB of memory and 3.5GB are taken by the model (for Qwen 7B), so you&amp;#39;d have 1.5GB left over for context. That should be able to fit more than 2048 tokens, but I&amp;#39;m not sure what the limit is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bvby6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100707,"author_flair_text":null,"treatment_tags":[],"created_utc":1753100707,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bi4po","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fast-Satisfaction482","can_mod_post":false,"created_utc":1753095052,"send_replies":true,"parent_id":"t1_n4bhluo","score":2,"author_fullname":"t2_9ceux4xp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I hope the given Seq len number does not mean how big the context can be, because 1024 is a bit low.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bi4po","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope the given Seq len number does not mean how big the context can be, because 1024 is a bit low.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bi4po/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095052,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bhluo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PmMeForPCBuilds","can_mod_post":false,"created_utc":1753094800,"send_replies":true,"parent_id":"t3_1m5fmlp","score":8,"author_fullname":"t2_lkljr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/zygp6nfvi7ef1.png?width=1536&amp;format=png&amp;auto=webp&amp;s=541621dcd1c91b62ac181228183adeb15a035351","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bhluo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/zygp6nfvi7ef1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=541621dcd1c91b62ac181228183adeb15a035351\\"&gt;https://preview.redd.it/zygp6nfvi7ef1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=541621dcd1c91b62ac181228183adeb15a035351&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bhluo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753094800,"media_metadata":{"zygp6nfvi7ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":60,"x":108,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf3df163f99ba738c77913a2ea98eb71546083f5"},{"y":121,"x":216,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=604cc4d81fd79d2a368de88151ca63b8d8a4cfa8"},{"y":180,"x":320,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=96e932260543797a7e9287e33e60606ca1ce20a1"},{"y":360,"x":640,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1781a83910ec7cad78f7780afe57677a8e32ed50"},{"y":540,"x":960,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7bbfcc0b3d7549e83daec1d5fcc1c569829eaeb1"},{"y":607,"x":1080,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a00791863ecd708df5c2d8f0aa3eddb26025135a"}],"s":{"y":864,"x":1536,"u":"https://preview.redd.it/zygp6nfvi7ef1.png?width=1536&amp;format=png&amp;auto=webp&amp;s=541621dcd1c91b62ac181228183adeb15a035351"},"id":"zygp6nfvi7ef1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ckdcv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Roubbes","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cjfkc","score":1,"author_fullname":"t2_aoir7erh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Multitude or plethora?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ckdcv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Multitude or plethora?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4ckdcv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753108966,"author_flair_text":null,"treatment_tags":[],"created_utc":1753108966,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4cjfkc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"created_utc":1753108708,"send_replies":true,"parent_id":"t1_n4bnq5a","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A multitude of watts","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cjfkc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A multitude of watts&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4cjfkc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753108708,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bnq5a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Roubbes","can_mod_post":false,"created_utc":1753097631,"send_replies":true,"parent_id":"t3_1m5fmlp","score":8,"author_fullname":"t2_aoir7erh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Power consumption?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bnq5a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Power consumption?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bnq5a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753097631,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c6wur","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shing3232","can_mod_post":false,"created_utc":1753104762,"send_replies":true,"parent_id":"t1_n4bvy1m","score":6,"author_fullname":"t2_ze4mg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A newer variant with bigger bandwidth and powerful NPU","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c6wur","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A newer variant with bigger bandwidth and powerful NPU&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4c6wur/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104762,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4co56b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"created_utc":1753110072,"send_replies":true,"parent_id":"t1_n4bvy1m","score":2,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just like the apple that made newton","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4co56b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just like the apple that made newton&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4co56b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753110072,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dbf7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d9y7d","score":1,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've installed lots of newer packages on them and didn't have any issues. In real world experience these bespoke products are often relegated to a single task, and my normal computer boots off anewer kernel because I'm looking for features.","edited":false,"author_flair_css_class":null,"name":"t1_n4dbf7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve installed lots of newer packages on them and didn&amp;#39;t have any issues. In real world experience these bespoke products are often relegated to a single task, and my normal computer boots off anewer kernel because I&amp;#39;m looking for features.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5fmlp","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4dbf7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753116676,"author_flair_text":null,"collapsed":false,"created_utc":1753116676,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d9y7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GreenPastures2845","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d8j6q","score":1,"author_fullname":"t2_1eec9087px","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"security, security, security, compatibility, ease of use, usability over time, etc.\\n\\nAfter 5 years, it's likely that modern OS versions will depend on kernel features that your old weirdball kernel lacks, so you're stuck on the old OS altogether with older everything.\\n\\nIn the long term, the ONLY sane user experience for hardware support is mainline kernel support.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4d9y7d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;security, security, security, compatibility, ease of use, usability over time, etc.&lt;/p&gt;\\n\\n&lt;p&gt;After 5 years, it&amp;#39;s likely that modern OS versions will depend on kernel features that your old weirdball kernel lacks, so you&amp;#39;re stuck on the old OS altogether with older everything.&lt;/p&gt;\\n\\n&lt;p&gt;In the long term, the ONLY sane user experience for hardware support is mainline kernel support.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4d9y7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753116269,"author_flair_text":null,"treatment_tags":[],"created_utc":1753116269,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d8j6q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d5cov","score":1,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just wondering, whats wrong with that? I know its not ideal for security reasons, but whats the real problem if its local? I had android phones with no problems, still use some old ones on weird kernels before project treble.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4d8j6q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just wondering, whats wrong with that? I know its not ideal for security reasons, but whats the real problem if its local? I had android phones with no problems, still use some old ones on weird kernels before project treble.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4d8j6q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753115875,"author_flair_text":null,"treatment_tags":[],"created_utc":1753115875,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d5cov","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GreenPastures2845","can_mod_post":false,"created_utc":1753114980,"send_replies":true,"parent_id":"t1_n4bvy1m","score":1,"author_fullname":"t2_1eec9087px","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, and like your tv box, this new thing will require a bespoke kernel which will be maintained for 3 months until the company loses interest and then you will be forever stuck with an old weirdball kernel.\\n\\nI would not go near this company's products.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4d5cov","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, and like your tv box, this new thing will require a bespoke kernel which will be maintained for 3 months until the company loses interest and then you will be forever stuck with an old weirdball kernel.&lt;/p&gt;\\n\\n&lt;p&gt;I would not go near this company&amp;#39;s products.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4d5cov/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753114980,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bvy1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bene_42069","can_mod_post":false,"created_utc":1753100940,"send_replies":true,"parent_id":"t3_1m5fmlp","score":7,"author_fullname":"t2_9yo3ah1u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The same Rockchip that powers my dollar store android tv box?\\n\\nhttps://preview.redd.it/yjcprts418ef1.png?width=764&amp;format=png&amp;auto=webp&amp;s=410601eb65032ef34c222116433ace0e4cfc985c","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bvy1m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The same Rockchip that powers my dollar store android tv box?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/yjcprts418ef1.png?width=764&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=410601eb65032ef34c222116433ace0e4cfc985c\\"&gt;https://preview.redd.it/yjcprts418ef1.png?width=764&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=410601eb65032ef34c222116433ace0e4cfc985c&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bvy1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100940,"media_metadata":{"yjcprts418ef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":33,"x":108,"u":"https://preview.redd.it/yjcprts418ef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=274f7eadd66862adb5301138aa45e74d2b9cbd7a"},{"y":67,"x":216,"u":"https://preview.redd.it/yjcprts418ef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5eba47a92aeea128070c3b38e9ff52b05a77165"},{"y":99,"x":320,"u":"https://preview.redd.it/yjcprts418ef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd2c28fdcfdd4787f8338fb67dbdf7dc591c5e1e"},{"y":198,"x":640,"u":"https://preview.redd.it/yjcprts418ef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8edd42ef0ebbfcc5d1794b6929978c220fb099e8"}],"s":{"y":237,"x":764,"u":"https://preview.redd.it/yjcprts418ef1.png?width=764&amp;format=png&amp;auto=webp&amp;s=410601eb65032ef34c222116433ace0e4cfc985c"},"id":"yjcprts418ef1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cxrnz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"evil0sheep","can_mod_post":false,"created_utc":1753112826,"send_replies":true,"parent_id":"t3_1m5fmlp","score":3,"author_fullname":"t2_4ty73","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So I’ve fucked around quite a bit with llms on rk3588 which is their last gen flagship (working on the 16gb orangepi 5 which runs about $130). The two biggest limits with that hardware for llm inference is that it only has 2 lpddr5 interfaces which max out at a combined 52GB/s and the Mali gpu has no local memory which means that 1) you can’t do flash attention so the attention matrices eat up your lpddr bandwidth and 2) it’s basically impossible to read quantized gguf weights in a way that coalesces the memory transactions and be able to dequantize those weights on the chip without writing intermediaries back and forth over the lpddr bus (which blows cause quantization is the easiest way to improve performance when you’re memory bound which these things always are).\\n\\nSo this thing has twice as many lpddr controllers and if they designed that npu specifically for llms that means it absolutely will have enough sram to do flash attention and to dequant gguf weights, and that means if you only do 4gb of lpddr5 per channel instead of 8 (so 16gb per chip) you might be able to get like 10-15 tok/s with speculative decoding on a q4 model with 12-14 GB of weights, which means that a Turing pi 2 with 4 of those might be able to run inference on a 60GB model at acceptable throughput for under $1000 (or close to it, depending on exact pricing and performance)\\n\\nExcited to get my hands on one, I hope someone cuts a board with 4x lpddr5x chips that can do the full 104GB/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cxrnz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I’ve fucked around quite a bit with llms on rk3588 which is their last gen flagship (working on the 16gb orangepi 5 which runs about $130). The two biggest limits with that hardware for llm inference is that it only has 2 lpddr5 interfaces which max out at a combined 52GB/s and the Mali gpu has no local memory which means that 1) you can’t do flash attention so the attention matrices eat up your lpddr bandwidth and 2) it’s basically impossible to read quantized gguf weights in a way that coalesces the memory transactions and be able to dequantize those weights on the chip without writing intermediaries back and forth over the lpddr bus (which blows cause quantization is the easiest way to improve performance when you’re memory bound which these things always are).&lt;/p&gt;\\n\\n&lt;p&gt;So this thing has twice as many lpddr controllers and if they designed that npu specifically for llms that means it absolutely will have enough sram to do flash attention and to dequant gguf weights, and that means if you only do 4gb of lpddr5 per channel instead of 8 (so 16gb per chip) you might be able to get like 10-15 tok/s with speculative decoding on a q4 model with 12-14 GB of weights, which means that a Turing pi 2 with 4 of those might be able to run inference on a 60GB model at acceptable throughput for under $1000 (or close to it, depending on exact pricing and performance)&lt;/p&gt;\\n\\n&lt;p&gt;Excited to get my hands on one, I hope someone cuts a board with 4x lpddr5x chips that can do the full 104GB/s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4cxrnz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753112826,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"body":"This is nifty, but unless they also opensource the software they are using or show how using it with their system. I don't see this being a hit.\\n\\nAlso DD5 4 channels 100GBps ... big oofs if that is accurate ... because DDR5 channel is about 38.4 GB/s per channel and at 4 channels that would be 153.6 GB/s. Keep in mind DDR5 can be much faster I am using the base rate of 4800MT for my math... So at their rate it is either more like 5200 MT dual channel or they are running slower than 4800mt in quad channel.\\n\\nAll that is to say IDK about their number as most of what they are saying can't be done with 16 tops NPU when you integrate NPUs in to LLM workloads. Sure they help and it makes things faster but they are scaled and 16 Unit NPU just isn't that much power.\\n\\nThis is either hype of BS... we will find out when this product is released and their is now software to test the one you can buy against, and magically they say they will release their NPU compatible Llama,cpp later. Then every time someone uses this for LLM and it falls way short they will site it isn't using their 16 TOPS NPU cores. \\n\\nEDIT: To clarify I was referring to desktop usage as that is what I thought one of the target points would be for a small desktop LLM device.\\n\\nNow about LPDDR5 here is the information I was going off of \\n\\n[https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram](https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram)\\n\\n[https://www.micron.com/products/memory/dram-components/lpddr5](https://www.micron.com/products/memory/dram-components/lpddr5)\\n\\n[https://semiconductor.samsung.com/dram/lpddr/lpddr5/](https://semiconductor.samsung.com/dram/lpddr/lpddr5/)\\n\\nAll of which state at 6400MT at low power should be 51.2GB/s per channel I figured they would run it lower at say the base for LPDDR5 of 4800MT which is 38.4GB/s and having 4 channels that gives you 153.6 GB/s. This isn't complicated","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Now about LPDDR5 here is the information I was going off of\\n\\n[https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram](https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram)\\n\\n[https://www.micron.com/products/memory/dram-components/lpddr5](https://www.micron.com/products/memory/dram-components/lpddr5)\\n\\n[https://semiconductor.samsung.com/dram/lpddr/lpddr5/](https://semiconductor.samsung.com/dram/lpddr/lpddr5/)\\n\\nAll of which state at 6400MT at low power should be 51.2GB/s per channel I figured they would run it lower at say the base for LPDDR5 of 4800MT which is 38.4GB/s and having 4 channels that gives you 153.6 GB/s. This isn't complicated.\\n\\nEDIT: Note these sources are reputable tech news sources, and the manufactures of LPDDR5.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dhcnz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ctt2k","score":1,"author_fullname":"t2_zq180","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":1753118619,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dhcnz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now about LPDDR5 here is the information I was going off of&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram\\"&gt;https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.micron.com/products/memory/dram-components/lpddr5\\"&gt;https://www.micron.com/products/memory/dram-components/lpddr5&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://semiconductor.samsung.com/dram/lpddr/lpddr5/\\"&gt;https://semiconductor.samsung.com/dram/lpddr/lpddr5/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;All of which state at 6400MT at low power should be 51.2GB/s per channel I figured they would run it lower at say the base for LPDDR5 of 4800MT which is 38.4GB/s and having 4 channels that gives you 153.6 GB/s. This isn&amp;#39;t complicated.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Note these sources are reputable tech news sources, and the manufactures of LPDDR5.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4dhcnz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118294,"author_flair_text":null,"treatment_tags":[],"created_utc":1753118294,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ctt2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"evil0sheep","can_mod_post":false,"created_utc":1753111706,"send_replies":true,"parent_id":"t1_n4c60fz","score":3,"author_fullname":"t2_4ty73","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you’re conflating DDR and LPDDR. Chips like this typically use LPDDR and by my calcs 100GB/s is correct for 4 channels of LPDDR5 at max clock","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ctt2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you’re conflating DDR and LPDDR. Chips like this typically use LPDDR and by my calcs 100GB/s is correct for 4 channels of LPDDR5 at max clock&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4ctt2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753111706,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"That makes since, but at that point LPDDR4 would make more since as it is more mature and can run faster at lower TDP, but it is what it is.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dg38i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c9mfy","score":1,"author_fullname":"t2_zq180","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dg38i","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That makes since, but at that point LPDDR4 would make more since as it is more mature and can run faster at lower TDP, but it is what it is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4dg38i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753117947,"author_flair_text":null,"treatment_tags":[],"created_utc":1753117947,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c9mfy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uti24","can_mod_post":false,"created_utc":1753105647,"send_replies":true,"parent_id":"t1_n4c60fz","score":1,"author_fullname":"t2_13hbro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;because DDR5 channel is about 38.4 GB/s per channel and at 4 channels that would be 153.6 GB/s. Keep in mind DDR5 can be much faster I am using the base rate of 4800MT for my math...\\n\\nI think it is about mobile chip for smartphones and tablets. They can have like 2000MT/s for power consumption reasons.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c9mfy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;because DDR5 channel is about 38.4 GB/s per channel and at 4 channels that would be 153.6 GB/s. Keep in mind DDR5 can be much faster I am using the base rate of 4800MT for my math...&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I think it is about mobile chip for smartphones and tablets. They can have like 2000MT/s for power consumption reasons.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4c9mfy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753105647,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Okay I was going off of the slides, So The slide before the Performance they showed specs so if that is for something completely different my mistake.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dhm5t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GeekyBit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cu9u6","score":1,"author_fullname":"t2_zq180","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dhm5t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay I was going off of the slides, So The slide before the Performance they showed specs so if that is for something completely different my mistake.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4dhm5t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118364,"author_flair_text":null,"treatment_tags":[],"created_utc":1753118364,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4cu9u6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PmMeForPCBuilds","can_mod_post":false,"created_utc":1753111837,"send_replies":true,"parent_id":"t1_n4c60fz","score":1,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think you’re mixing up the SoC they announced which uses DDR5 and this LLM coprocessor, they’re separate products. The TOPS and memory architecture haven’t been announced for this product (RK182X).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cu9u6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think you’re mixing up the SoC they announced which uses DDR5 and this LLM coprocessor, they’re separate products. The TOPS and memory architecture haven’t been announced for this product (RK182X).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4cu9u6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753111837,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c60fz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GeekyBit","can_mod_post":false,"created_utc":1753104461,"send_replies":true,"parent_id":"t3_1m5fmlp","score":5,"author_fullname":"t2_zq180","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":1753118282,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c60fz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is nifty, but unless they also opensource the software they are using or show how using it with their system. I don&amp;#39;t see this being a hit.&lt;/p&gt;\\n\\n&lt;p&gt;Also DD5 4 channels 100GBps ... big oofs if that is accurate ... because DDR5 channel is about 38.4 GB/s per channel and at 4 channels that would be 153.6 GB/s. Keep in mind DDR5 can be much faster I am using the base rate of 4800MT for my math... So at their rate it is either more like 5200 MT dual channel or they are running slower than 4800mt in quad channel.&lt;/p&gt;\\n\\n&lt;p&gt;All that is to say IDK about their number as most of what they are saying can&amp;#39;t be done with 16 tops NPU when you integrate NPUs in to LLM workloads. Sure they help and it makes things faster but they are scaled and 16 Unit NPU just isn&amp;#39;t that much power.&lt;/p&gt;\\n\\n&lt;p&gt;This is either hype of BS... we will find out when this product is released and their is now software to test the one you can buy against, and magically they say they will release their NPU compatible Llama,cpp later. Then every time someone uses this for LLM and it falls way short they will site it isn&amp;#39;t using their 16 TOPS NPU cores. &lt;/p&gt;\\n\\n&lt;p&gt;EDIT: To clarify I was referring to desktop usage as that is what I thought one of the target points would be for a small desktop LLM device.&lt;/p&gt;\\n\\n&lt;p&gt;Now about LPDDR5 here is the information I was going off of &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram\\"&gt;https://acemagic.com/blogs/accessories-peripherals/lpddr5-vs-ddr5-ram&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.micron.com/products/memory/dram-components/lpddr5\\"&gt;https://www.micron.com/products/memory/dram-components/lpddr5&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://semiconductor.samsung.com/dram/lpddr/lpddr5/\\"&gt;https://semiconductor.samsung.com/dram/lpddr/lpddr5/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;All of which state at 6400MT at low power should be 51.2GB/s per channel I figured they would run it lower at say the base for LPDDR5 of 4800MT which is 38.4GB/s and having 4 channels that gives you 153.6 GB/s. This isn&amp;#39;t complicated&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4c60fz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104461,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cv4dm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PmMeForPCBuilds","can_mod_post":false,"created_utc":1753112078,"send_replies":true,"parent_id":"t1_n4bjscn","score":3,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A lot of NPUs are basically useless because they were designed for CNNs which was the most practical type of neural net a few years back. Or if they can run LLMs they are slower than the CPU and GPU because they share a bus with them. This has its own high speed memory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cv4dm","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A lot of NPUs are basically useless because they were designed for CNNs which was the most practical type of neural net a few years back. Or if they can run LLMs they are slower than the CPU and GPU because they share a bus with them. This has its own high speed memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4cv4dm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753112078,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dbri8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InsideYork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4bqgeg","score":1,"author_fullname":"t2_12s3hn4y0b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They can run Q3, or another quant. Wonder why they used qwen2.5 over 3.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dbri8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They can run Q3, or another quant. Wonder why they used qwen2.5 over 3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4dbri8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753116767,"author_flair_text":null,"treatment_tags":[],"created_utc":1753116767,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bqgeg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"oxygen_addiction","can_mod_post":false,"created_utc":1753098789,"send_replies":true,"parent_id":"t1_n4bjscn","score":2,"author_fullname":"t2_66k6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably doesn't have enough memory for it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqgeg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably doesn&amp;#39;t have enough memory for it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5fmlp","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bqgeg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098789,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bjscn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Vas1le","can_mod_post":false,"created_utc":1753095836,"send_replies":true,"parent_id":"t3_1m5fmlp","score":2,"author_fullname":"t2_9mhfdr5f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wonder why qwen 3 wasn't in the benchmark. \\n\\nDoesn't rock already have a NPU for LLM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bjscn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wonder why qwen 3 wasn&amp;#39;t in the benchmark. &lt;/p&gt;\\n\\n&lt;p&gt;Doesn&amp;#39;t rock already have a NPU for LLM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bjscn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753095836,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bqt4w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1753098934,"send_replies":true,"parent_id":"t3_1m5fmlp","score":2,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"4060 but more energy efficient. Great.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bqt4w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4060 but more energy efficient. Great.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4bqt4w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753098934,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4d1ieo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rog-uk","can_mod_post":false,"created_utc":1753113885,"send_replies":true,"parent_id":"t3_1m5fmlp","score":1,"author_fullname":"t2_x4r6o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I suppose the cost will be a big factor, I mean if they're substantially cheaper than GPU for equivalent performance that would be mighty interesting. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4d1ieo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I suppose the cost will be a big factor, I mean if they&amp;#39;re substantially cheaper than GPU for equivalent performance that would be mighty interesting. &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5fmlp/rockchip_unveils_rk182x_llm_coprocessor_runs_qwen/n4d1ieo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753113885,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5fmlp","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
