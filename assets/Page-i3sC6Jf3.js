import{j as e}from"./index-Bu7qcPAU.js";import{R as t}from"./RedditPostRenderer-CbHA7O5q.js";import"./index-BKgbfxhf.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I am trying to do voice dubbing but since I have started I am not being to achieve audible output... The videos are in English I transcrbe then in English then I translate the text in french, then when I try to get the traduced text to be read with the text to speech it gives me a bunch of gibberish, I am asking myself if it's an issue with the M1 processor or the script I don't get it... The videos are short, between 1 min to 3 min... Below is the script I use:\\n\\n\\n#!/usr/bin/env python3\\nimport torch\\nimport gradio as gr\\nimport librosa\\nimport numpy as np\\nfrom chatterbox.tts import ChatterboxTTS\\nimport tempfile\\nimport os\\nimport importlib.util  # For dependency checking\\n\\n# Define sampling rate (Chatterbox uses 22.05kHz)\\nSAMPLING_RATE = 22050\\n\\n# Check if soundfile is available\\nif importlib.util.find_spec(\\"soundfile\\"):\\n    import soundfile as sf\\n    has_soundfile = True\\nelse:\\n    print(\\"Warning: soundfile not installed. Using scipy.io.wavfile instead.\\")\\n    from scipy.io import wavfile\\n    has_soundfile = False\\n\\n# Initialize TTS model\\ndevice = \\"mps\\" if torch.backends.mps.is_available() else \\"cpu\\"\\ntts_model = ChatterboxTTS.from_pretrained(device=device)\\n\\ndef preprocess_french_text(text):\\n    \\"\\"\\"Preprocess French text for better TTS pronunciation\\"\\"\\"\\n    # Simple normalization - expand common abbreviations\\n    replacements = {\\n        \\"M.\\": \\"Monsieur\\",\\n        \\"Mme\\": \\"Madame\\",\\n        \\"Mlle\\": \\"Mademoiselle\\",\\n        \\"Dr.\\": \\"Docteur\\",\\n        \\"St.\\": \\"Saint\\",\\n        \\"nÂ°\\": \\"numÃ©ro\\",\\n        \\"&amp;\\": \\"et\\"\\n    }\\n    \\n    for abbr, full in replacements.items():\\n        text = text.replace(abbr, full)\\n    \\n    return text\\n\\ndef preprocess_voice_sample(voice_path):\\n    \\"\\"\\"Preprocess voice sample to meet Chatterbox requirements\\"\\"\\"\\n    if not voice_path or not os.path.exists(voice_path):\\n        return None\\n    \\n    try:\\n        # Load audio and convert to mono\\n        y, sr = librosa.load(voice_path, sr=SAMPLING_RATE, mono=True)\\n        \\n        # Trim to 5 seconds (Chatterbox's optimal length)\\n        max_samples = 5 * SAMPLING_RATE\\n        if len(y) &gt; max_samples:\\n            y = y[:max_samples]\\n        \\n        # Save processed sample to temporary file\\n        with tempfile.NamedTemporaryFile(suffix=\\".wav\\", delete=False) as tmpfile:\\n            if has_soundfile:\\n                sf.write(tmpfile.name, y, SAMPLING_RATE)\\n            else:\\n                wavfile.write(tmpfile.name, SAMPLING_RATE, (y * 32767).astype(np.int16))\\n            return tmpfile.name\\n    except Exception as e:\\n        print(f\\"Voice preprocessing error: {e}\\")\\n        return voice_path  # Fallback to original\\n\\ndef ensure_mono(audio):\\n    \\"\\"\\"Convert audio to mono (1D array) if it's stereo\\"\\"\\"\\n    if audio.ndim &gt; 1:\\n        return np.mean(audio, axis=1)\\n    return audio\\n\\ndef generate_tts_segment(text, voice_sample_path=None, exaggeration=0.5, cfg_weight=0.7, pace=1.0):\\n    \\"\\"\\"Generate French TTS audio for text segment\\"\\"\\"\\n    # Preprocess French text\\n    text = preprocess_french_text(text)\\n    \\n    params = {\\n        \\"text\\": text,\\n        \\"exaggeration\\": exaggeration,\\n        \\"cfg_weight\\": cfg_weight\\n    }\\n    \\n    if voice_sample_path and os.path.exists(voice_sample_path):\\n        params[\\"audio_prompt_path\\"] = voice_sample_path\\n    \\n    # Generate audio (returns a PyTorch tensor)\\n    audio_tensor = tts_model.generate(**params)\\n    \\n    # Convert tensor to numpy array\\n    audio = audio_tensor.cpu().numpy().astype(np.float32)\\n    \\n    # Ensure mono audio\\n    audio = ensure_mono(audio)\\n    \\n    # Normalize audio to avoid clipping\\n    max_val = np.max(np.abs(audio))\\n    if max_val &gt; 0:\\n        audio = audio / max_val\\n    \\n    # Apply pace adjustment\\n    if pace != 1.0:\\n        audio = librosa.effects.time_stretch(audio, rate=pace)\\n    \\n    return audio\\n\\ndef process_text_file(text_file, voice_sample=None, exaggeration=0.5, cfg_weight=0.7, pause_duration=0.5, pace=1.0):\\n    \\"\\"\\"Process text file and generate concatenated audio\\"\\"\\"\\n    # Get actual file path\\n    txt_path = text_file.name\\n    \\n    # Preprocess voice sample if provided\\n    preprocessed_voice_path = None\\n    if voice_sample:\\n        preprocessed_voice_path = preprocess_voice_sample(voice_sample)\\n    \\n    try:\\n        with open(txt_path, 'r', encoding='utf-8') as f:\\n            text = f.read()\\n    except Exception as e:\\n        yield f\\"Error opening text file: {str(e)}\\", None\\n        return\\n    \\n    # Split text into paragraphs\\n    paragraphs = [p.strip() for p in text.split('\\\\n\\\\n') if p.strip()]\\n    \\n    full_audio = np.array([], dtype=np.float32)\\n    pause_samples = int(pause_duration * SAMPLING_RATE)\\n    \\n    for i, paragraph in enumerate(paragraphs):\\n        try:\\n            # Generate audio for paragraph\\n            segment = generate_tts_segment(\\n                text=paragraph,\\n                voice_sample_path=preprocessed_voice_path,\\n                exaggeration=exaggeration,\\n                cfg_weight=cfg_weight,\\n                pace=pace\\n            )\\n            full_audio = np.concatenate([full_audio, segment])\\n            \\n            # Add pause between paragraphs (except after last one)\\n            if i &lt; len(paragraphs) - 1:\\n                full_audio = np.concatenate([full_audio, np.zeros(pause_samples)])\\n        except Exception as e:\\n            yield f\\"Error processing paragraph {i+1}: {str(e)}\\", None\\n            return\\n        \\n        yield f\\"Processing paragraph {i+1}/{len(paragraphs)}\\", None\\n        \\n    # Clean up temporary voice file\\n    if preprocessed_voice_path and os.path.exists(preprocessed_voice_path):\\n        try:\\n            os.remove(preprocessed_voice_path)\\n        except Exception:\\n            pass  # Ignore cleanup errors\\n        \\n    # Save to temporary file\\n    try:\\n        with tempfile.NamedTemporaryFile(suffix=\\".wav\\", delete=False) as tmpfile:\\n            output_path = tmpfile.name\\n            if has_soundfile:\\n                sf.write(output_path, full_audio, SAMPLING_RATE)\\n            else:\\n                wavfile.write(output_path, SAMPLING_RATE, (full_audio * 32767).astype(np.int16))\\n        yield \\"Audio generated successfully!\\", output_path\\n    except Exception as e:\\n        yield f\\"Audio save error: {str(e)}\\", None\\n\\n# Gradio UI\\nwith gr.Blocks(title=\\"French Text Audio Synthesizer\\") as ui:\\n    gr.Markdown(\\"# ðŸŽ§ French Text-to-Speech Generator\\")\\n    gr.Markdown(\\"Generate French audio from .txt files with natural pauses\\")\\n    \\n    with gr.Row():\\n        with gr.Column():\\n            text_input = gr.File(label=\\"Text File\\", file_types=[\\".txt\\"])\\n            voice_input = gr.Audio(\\n                label=\\"Voice Sample (Optional)\\",\\n                type=\\"filepath\\",\\n                sources=[\\"upload\\"],\\n                format=\\"wav\\"\\n            )\\n            emotion_slider = gr.Slider(0.0, 1.0, 0.5, label=\\"Emotion Intensity\\")\\n            pause_slider = gr.Slider(0.0, 2.0, 0.5, label=\\"Pause Duration (seconds)\\")\\n            pace_slider = gr.Slider(0.5, 1.5, 1.0, label=\\"Speech Pace\\")\\n            generate_btn = gr.Button(\\"Generate Audio\\")\\n        \\n        with gr.Column():\\n            status = gr.Textbox(label=\\"Status\\", interactive=False)\\n            audio_output = gr.Audio(label=\\"Generated Audio\\", type=\\"filepath\\")\\n    \\n    generate_btn.click(\\n        fn=process_text_file,\\n        inputs=[text_input, voice_input, emotion_slider, pause_slider, pace_slider],\\n        outputs=[status, audio_output]\\n    )\\n\\nif __name__ == \\"__main__\\":\\n    ui.launch(server_port=7860)\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Xttsv2 model, Chatterbox on MacBook air 8 gb","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzf6zi","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.67,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_77qlzs20","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752474601,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I am trying to do voice dubbing but since I have started I am not being to achieve audible output... The videos are in English I transcrbe then in English then I translate the text in french, then when I try to get the traduced text to be read with the text to speech it gives me a bunch of gibberish, I am asking myself if it&amp;#39;s an issue with the M1 processor or the script I don&amp;#39;t get it... The videos are short, between 1 min to 3 min... Below is the script I use:&lt;/p&gt;\\n\\n&lt;h1&gt;!/usr/bin/env python3&lt;/h1&gt;\\n\\n&lt;p&gt;import torch\\nimport gradio as gr\\nimport librosa\\nimport numpy as np\\nfrom chatterbox.tts import ChatterboxTTS\\nimport tempfile\\nimport os\\nimport importlib.util  # For dependency checking&lt;/p&gt;\\n\\n&lt;h1&gt;Define sampling rate (Chatterbox uses 22.05kHz)&lt;/h1&gt;\\n\\n&lt;p&gt;SAMPLING_RATE = 22050&lt;/p&gt;\\n\\n&lt;h1&gt;Check if soundfile is available&lt;/h1&gt;\\n\\n&lt;p&gt;if importlib.util.find_spec(&amp;quot;soundfile&amp;quot;):\\n    import soundfile as sf\\n    has_soundfile = True\\nelse:\\n    print(&amp;quot;Warning: soundfile not installed. Using scipy.io.wavfile instead.&amp;quot;)\\n    from scipy.io import wavfile\\n    has_soundfile = False&lt;/p&gt;\\n\\n&lt;h1&gt;Initialize TTS model&lt;/h1&gt;\\n\\n&lt;p&gt;device = &amp;quot;mps&amp;quot; if torch.backends.mps.is_available() else &amp;quot;cpu&amp;quot;\\ntts_model = ChatterboxTTS.from_pretrained(device=device)&lt;/p&gt;\\n\\n&lt;p&gt;def preprocess_french_text(text):\\n    &amp;quot;&amp;quot;&amp;quot;Preprocess French text for better TTS pronunciation&amp;quot;&amp;quot;&amp;quot;\\n    # Simple normalization - expand common abbreviations\\n    replacements = {\\n        &amp;quot;M.&amp;quot;: &amp;quot;Monsieur&amp;quot;,\\n        &amp;quot;Mme&amp;quot;: &amp;quot;Madame&amp;quot;,\\n        &amp;quot;Mlle&amp;quot;: &amp;quot;Mademoiselle&amp;quot;,\\n        &amp;quot;Dr.&amp;quot;: &amp;quot;Docteur&amp;quot;,\\n        &amp;quot;St.&amp;quot;: &amp;quot;Saint&amp;quot;,\\n        &amp;quot;nÂ°&amp;quot;: &amp;quot;numÃ©ro&amp;quot;,\\n        &amp;quot;&amp;amp;&amp;quot;: &amp;quot;et&amp;quot;\\n    }&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;for abbr, full in replacements.items():\\n    text = text.replace(abbr, full)\\n\\nreturn text\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;def preprocess_voice_sample(voice_path):\\n    &amp;quot;&amp;quot;&amp;quot;Preprocess voice sample to meet Chatterbox requirements&amp;quot;&amp;quot;&amp;quot;\\n    if not voice_path or not os.path.exists(voice_path):\\n        return None&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;try:\\n    # Load audio and convert to mono\\n    y, sr = librosa.load(voice_path, sr=SAMPLING_RATE, mono=True)\\n\\n    # Trim to 5 seconds (Chatterbox&amp;#39;s optimal length)\\n    max_samples = 5 * SAMPLING_RATE\\n    if len(y) &amp;gt; max_samples:\\n        y = y[:max_samples]\\n\\n    # Save processed sample to temporary file\\n    with tempfile.NamedTemporaryFile(suffix=&amp;quot;.wav&amp;quot;, delete=False) as tmpfile:\\n        if has_soundfile:\\n            sf.write(tmpfile.name, y, SAMPLING_RATE)\\n        else:\\n            wavfile.write(tmpfile.name, SAMPLING_RATE, (y * 32767).astype(np.int16))\\n        return tmpfile.name\\nexcept Exception as e:\\n    print(f&amp;quot;Voice preprocessing error: {e}&amp;quot;)\\n    return voice_path  # Fallback to original\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;def ensure_mono(audio):\\n    &amp;quot;&amp;quot;&amp;quot;Convert audio to mono (1D array) if it&amp;#39;s stereo&amp;quot;&amp;quot;&amp;quot;\\n    if audio.ndim &amp;gt; 1:\\n        return np.mean(audio, axis=1)\\n    return audio&lt;/p&gt;\\n\\n&lt;p&gt;def generate_tts_segment(text, voice_sample_path=None, exaggeration=0.5, cfg_weight=0.7, pace=1.0):\\n    &amp;quot;&amp;quot;&amp;quot;Generate French TTS audio for text segment&amp;quot;&amp;quot;&amp;quot;\\n    # Preprocess French text\\n    text = preprocess_french_text(text)&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;params = {\\n    &amp;quot;text&amp;quot;: text,\\n    &amp;quot;exaggeration&amp;quot;: exaggeration,\\n    &amp;quot;cfg_weight&amp;quot;: cfg_weight\\n}\\n\\nif voice_sample_path and os.path.exists(voice_sample_path):\\n    params[&amp;quot;audio_prompt_path&amp;quot;] = voice_sample_path\\n\\n# Generate audio (returns a PyTorch tensor)\\naudio_tensor = tts_model.generate(**params)\\n\\n# Convert tensor to numpy array\\naudio = audio_tensor.cpu().numpy().astype(np.float32)\\n\\n# Ensure mono audio\\naudio = ensure_mono(audio)\\n\\n# Normalize audio to avoid clipping\\nmax_val = np.max(np.abs(audio))\\nif max_val &amp;gt; 0:\\n    audio = audio / max_val\\n\\n# Apply pace adjustment\\nif pace != 1.0:\\n    audio = librosa.effects.time_stretch(audio, rate=pace)\\n\\nreturn audio\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;def process_text_file(text_file, voice_sample=None, exaggeration=0.5, cfg_weight=0.7, pause_duration=0.5, pace=1.0):\\n    &amp;quot;&amp;quot;&amp;quot;Process text file and generate concatenated audio&amp;quot;&amp;quot;&amp;quot;\\n    # Get actual file path\\n    txt_path = text_file.name&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;# Preprocess voice sample if provided\\npreprocessed_voice_path = None\\nif voice_sample:\\n    preprocessed_voice_path = preprocess_voice_sample(voice_sample)\\n\\ntry:\\n    with open(txt_path, &amp;#39;r&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;) as f:\\n        text = f.read()\\nexcept Exception as e:\\n    yield f&amp;quot;Error opening text file: {str(e)}&amp;quot;, None\\n    return\\n\\n# Split text into paragraphs\\nparagraphs = [p.strip() for p in text.split(&amp;#39;\\\\n\\\\n&amp;#39;) if p.strip()]\\n\\nfull_audio = np.array([], dtype=np.float32)\\npause_samples = int(pause_duration * SAMPLING_RATE)\\n\\nfor i, paragraph in enumerate(paragraphs):\\n    try:\\n        # Generate audio for paragraph\\n        segment = generate_tts_segment(\\n            text=paragraph,\\n            voice_sample_path=preprocessed_voice_path,\\n            exaggeration=exaggeration,\\n            cfg_weight=cfg_weight,\\n            pace=pace\\n        )\\n        full_audio = np.concatenate([full_audio, segment])\\n\\n        # Add pause between paragraphs (except after last one)\\n        if i &amp;lt; len(paragraphs) - 1:\\n            full_audio = np.concatenate([full_audio, np.zeros(pause_samples)])\\n    except Exception as e:\\n        yield f&amp;quot;Error processing paragraph {i+1}: {str(e)}&amp;quot;, None\\n        return\\n\\n    yield f&amp;quot;Processing paragraph {i+1}/{len(paragraphs)}&amp;quot;, None\\n\\n# Clean up temporary voice file\\nif preprocessed_voice_path and os.path.exists(preprocessed_voice_path):\\n    try:\\n        os.remove(preprocessed_voice_path)\\n    except Exception:\\n        pass  # Ignore cleanup errors\\n\\n# Save to temporary file\\ntry:\\n    with tempfile.NamedTemporaryFile(suffix=&amp;quot;.wav&amp;quot;, delete=False) as tmpfile:\\n        output_path = tmpfile.name\\n        if has_soundfile:\\n            sf.write(output_path, full_audio, SAMPLING_RATE)\\n        else:\\n            wavfile.write(output_path, SAMPLING_RATE, (full_audio * 32767).astype(np.int16))\\n    yield &amp;quot;Audio generated successfully!&amp;quot;, output_path\\nexcept Exception as e:\\n    yield f&amp;quot;Audio save error: {str(e)}&amp;quot;, None\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;Gradio UI&lt;/h1&gt;\\n\\n&lt;p&gt;with gr.Blocks(title=&amp;quot;French Text Audio Synthesizer&amp;quot;) as ui:\\n    gr.Markdown(&amp;quot;# ðŸŽ§ French Text-to-Speech Generator&amp;quot;)\\n    gr.Markdown(&amp;quot;Generate French audio from .txt files with natural pauses&amp;quot;)&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;with gr.Row():\\n    with gr.Column():\\n        text_input = gr.File(label=&amp;quot;Text File&amp;quot;, file_types=[&amp;quot;.txt&amp;quot;])\\n        voice_input = gr.Audio(\\n            label=&amp;quot;Voice Sample (Optional)&amp;quot;,\\n            type=&amp;quot;filepath&amp;quot;,\\n            sources=[&amp;quot;upload&amp;quot;],\\n            format=&amp;quot;wav&amp;quot;\\n        )\\n        emotion_slider = gr.Slider(0.0, 1.0, 0.5, label=&amp;quot;Emotion Intensity&amp;quot;)\\n        pause_slider = gr.Slider(0.0, 2.0, 0.5, label=&amp;quot;Pause Duration (seconds)&amp;quot;)\\n        pace_slider = gr.Slider(0.5, 1.5, 1.0, label=&amp;quot;Speech Pace&amp;quot;)\\n        generate_btn = gr.Button(&amp;quot;Generate Audio&amp;quot;)\\n\\n    with gr.Column():\\n        status = gr.Textbox(label=&amp;quot;Status&amp;quot;, interactive=False)\\n        audio_output = gr.Audio(label=&amp;quot;Generated Audio&amp;quot;, type=&amp;quot;filepath&amp;quot;)\\n\\ngenerate_btn.click(\\n    fn=process_text_file,\\n    inputs=[text_input, voice_input, emotion_slider, pause_slider, pace_slider],\\n    outputs=[status, audio_output]\\n)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;quot;&lt;strong&gt;main&lt;/strong&gt;&amp;quot;:\\n    ui.launch(server_port=7860)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lzf6zi","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Layonkizungu","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/","subreddit_subscribers":499297,"created_utc":1752474601,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31eb7y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Layonkizungu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n31a4eq","score":1,"author_fullname":"t2_77qlzs20","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31eb7y","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzf6zi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/n31eb7y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752478660,"author_flair_text":null,"treatment_tags":[],"created_utc":1752478660,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n31a4eq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3191lx","score":1,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hah, no worries, and again, best of luck.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n31a4eq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hah, no worries, and again, best of luck.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzf6zi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/n31a4eq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752476261,"author_flair_text":null,"treatment_tags":[],"created_utc":1752476261,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3191lx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Layonkizungu","can_mod_post":false,"created_utc":1752475667,"send_replies":true,"parent_id":"t1_n318s54","score":2,"author_fullname":"t2_77qlzs20","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sorry it looks like I pasted the wrong script... I am using coqui xttsv2 my bad","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3191lx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry it looks like I pasted the wrong script... I am using coqui xttsv2 my bad&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lzf6zi","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/n3191lx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475667,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n318s54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"created_utc":1752475521,"send_replies":true,"parent_id":"t3_1lzf6zi","score":1,"author_fullname":"t2_1opxde6hyq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Per [https://github.com/resemble-ai/chatterbox](https://github.com/resemble-ai/chatterbox)  \\nSupported Language:  Currently only English.\\n\\nEven if you get everything working perfectly, expect odd output.\\n\\nPast that, best of luck.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n318s54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Per &lt;a href=\\"https://github.com/resemble-ai/chatterbox\\"&gt;https://github.com/resemble-ai/chatterbox&lt;/a&gt;&lt;br/&gt;\\nSupported Language:  Currently only English.&lt;/p&gt;\\n\\n&lt;p&gt;Even if you get everything working perfectly, expect odd output.&lt;/p&gt;\\n\\n&lt;p&gt;Past that, best of luck.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzf6zi/xttsv2_model_chatterbox_on_macbook_air_8_gb/n318s54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752475521,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzf6zi","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(t,{data:a});export{r as default};
