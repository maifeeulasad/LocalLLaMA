import{j as e}from"./index-BxgxThME.js";import{R as l}from"./RedditPostRenderer-BL_SOtuv.js";import"./index--Az3yIKM.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"So, I want to finetune any model good or bad, into a youtuber persona\\nMy idea is i will download youtube videos of that youtuber and generate transcript and POFF! I have the youtuber data, now i just need train the model on that data\\n\\nMy idea is Gemini have gems, can that be useful? If not, can i achieve my goal for free? Btw, i have gemini advanced subscription \\n\\nP.S, I am not a technical person, i can write python code, but thats it, so think of me as dumb, and then read the question again","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Finetuning a youtuber persona without expensive hardware or buying expensive cloud computing","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lsevb1","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.36,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_3hpgagyv","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751735592,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;So, I want to finetune any model good or bad, into a youtuber persona\\nMy idea is i will download youtube videos of that youtuber and generate transcript and POFF! I have the youtuber data, now i just need train the model on that data&lt;/p&gt;\\n\\n&lt;p&gt;My idea is Gemini have gems, can that be useful? If not, can i achieve my goal for free? Btw, i have gemini advanced subscription &lt;/p&gt;\\n\\n&lt;p&gt;P.S, I am not a technical person, i can write python code, but thats it, so think of me as dumb, and then read the question again&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lsevb1","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Khushalgogia","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/","subreddit_subscribers":494986,"created_utc":1751735592,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1ib4e2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AltruisticList6000","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1hzs2s","score":5,"author_fullname":"t2_hnjq9xn4a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3 0.6b, maybe 1.7b...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1ib4e2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 0.6b, maybe 1.7b...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsevb1","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1ib4e2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751739421,"author_flair_text":null,"treatment_tags":[],"created_utc":1751739421,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1jl68e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LogicalAnimation","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1hzs2s","score":1,"author_fullname":"t2_625i4zoy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also try qwen3 30b a3b at iq2 quants or iq3\\\\_xxs if you can have fit everything in your ram. It's up to you to decide: small llm at higher quant vs larger llm at lower quant. For finetuning, maybe try to use google colab, they offer T4 with 16gb vram for free, or you can rent a gpu/vm from companies like runpod or vast ai.  That's the best use of your gpu/ram I can think of.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1jl68e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also try qwen3 30b a3b at iq2 quants or iq3_xxs if you can have fit everything in your ram. It&amp;#39;s up to you to decide: small llm at higher quant vs larger llm at lower quant. For finetuning, maybe try to use google colab, they offer T4 with 16gb vram for free, or you can rent a gpu/vm from companies like runpod or vast ai.  That&amp;#39;s the best use of your gpu/ram I can think of.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsevb1","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1jl68e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751754891,"author_flair_text":null,"treatment_tags":[],"created_utc":1751754891,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1hzs2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Khushalgogia","can_mod_post":false,"created_utc":1751735920,"send_replies":true,"parent_id":"t1_n1hzeg2","score":-3,"author_fullname":"t2_3hpgagyv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have old nvidia gtx 1050, 4gb vram\\nAnd 16gb ram\\nSo basically, i have nothing which could run a good model\\n Can you suggest some alternative, if you can think of anything?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1hzs2s","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have old nvidia gtx 1050, 4gb vram\\nAnd 16gb ram\\nSo basically, i have nothing which could run a good model\\n Can you suggest some alternative, if you can think of anything?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lsevb1","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1hzs2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751735920,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"n1hzeg2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ninja_Weedle","can_mod_post":false,"created_utc":1751735805,"send_replies":true,"parent_id":"t3_1lsevb1","score":4,"author_fullname":"t2_smvqlry","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is LocalLLaMA, so it's about running stuff locally... what kind of hardware do you have? that changes what kind of models you can (or should) run","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1hzeg2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is LocalLLaMA, so it&amp;#39;s about running stuff locally... what kind of hardware do you have? that changes what kind of models you can (or should) run&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1hzeg2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751735805,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsevb1","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1i29m2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Environmental-Metal9","can_mod_post":false,"created_utc":1751736680,"send_replies":true,"parent_id":"t3_1lsevb1","score":1,"author_fullname":"t2_6x9o42az","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Smollm2 family is one of my favorite small models. You can likely fit a training script in your vram with all the calculations on top of it.\\n\\nHere are some resources on finetuning it:\\n\\nhttps://github.com/huggingface/smol-course/tree/main\\n\\nhttps://huggingface.co/blog/prithivMLmods/smollm2-ft\\n\\nhttps://mikulskibartosz.name/fine-tune-small-language-model\\n\\nhttps://colab.research.google.com/github/huggingface/smol-course/blob/main/2_preference_alignment/notebooks/dpo_finetuning_example.ipynb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1i29m2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Smollm2 family is one of my favorite small models. You can likely fit a training script in your vram with all the calculations on top of it.&lt;/p&gt;\\n\\n&lt;p&gt;Here are some resources on finetuning it:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/huggingface/smol-course/tree/main\\"&gt;https://github.com/huggingface/smol-course/tree/main&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/blog/prithivMLmods/smollm2-ft\\"&gt;https://huggingface.co/blog/prithivMLmods/smollm2-ft&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://mikulskibartosz.name/fine-tune-small-language-model\\"&gt;https://mikulskibartosz.name/fine-tune-small-language-model&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://colab.research.google.com/github/huggingface/smol-course/blob/main/2_preference_alignment/notebooks/dpo_finetuning_example.ipynb\\"&gt;https://colab.research.google.com/github/huggingface/smol-course/blob/main/2_preference_alignment/notebooks/dpo_finetuning_example.ipynb&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1i29m2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751736680,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsevb1","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1is7h1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArsNeph","can_mod_post":false,"created_utc":1751745075,"send_replies":true,"parent_id":"t3_1lsevb1","score":1,"author_fullname":"t2_vt0xkv60d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You can create transcripts of a YouTuber's streams, but you have to actually clean and organize the data before doing any fine tuning. If there isn't some back and forth in the chat, and it's just the YouTuber talking one-sidedly, you're going to end up with a terrible, terrible result.\\n\\nYour GPU is not capable of fine-tuning, and while you could theoretically try to fine tune in a Google colab notebook, that's not going to be enough to fine-tune a model large enough to accurately convey some of the nuances of a YouTuber's persona. I would suggest renting cloud compute from Runpod, it's only about $2 an hour for enterprise-grade GPUs. \\n\\nTo learn about fine-tuning, I would recommend looking at Unsloth and Axolotl. Unsloth in particular has great documentation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1is7h1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can create transcripts of a YouTuber&amp;#39;s streams, but you have to actually clean and organize the data before doing any fine tuning. If there isn&amp;#39;t some back and forth in the chat, and it&amp;#39;s just the YouTuber talking one-sidedly, you&amp;#39;re going to end up with a terrible, terrible result.&lt;/p&gt;\\n\\n&lt;p&gt;Your GPU is not capable of fine-tuning, and while you could theoretically try to fine tune in a Google colab notebook, that&amp;#39;s not going to be enough to fine-tune a model large enough to accurately convey some of the nuances of a YouTuber&amp;#39;s persona. I would suggest renting cloud compute from Runpod, it&amp;#39;s only about $2 an hour for enterprise-grade GPUs. &lt;/p&gt;\\n\\n&lt;p&gt;To learn about fine-tuning, I would recommend looking at Unsloth and Axolotl. Unsloth in particular has great documentation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lsevb1/finetuning_a_youtuber_persona_without_expensive/n1is7h1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751745075,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lsevb1","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
