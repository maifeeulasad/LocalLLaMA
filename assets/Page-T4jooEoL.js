import{j as t}from"./index-DQXiEb7D.js";import{R as e}from"./RedditPostRenderer-BjndLgq8.js";import"./index-B-ILyjT1.js";const n=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm trying to get MistralThinker to... think. According to discussion on the model page (https://huggingface.co/Undi95/MistralThinker-v1.1/discussions/1) it is necessary to encourage the model to use reasoning with some structured output or otherwise prefixes. But I'm not using SillyTavern so the suggestions in the thread don't seem applicable for me. Instead I'm using LM studio for out of the box ROCm support. \\n\\nI've never made a json schema before so I tried generating a structured output, but I'm not entirely sure what the structure is supposed to look like, as I found the LM Studio documentation unclear with poor examples. Here's where I'm at:\\n\\n    {\\n      \\"type\\": \\"object\\",\\n      \\"properties\\": {\\n        \\"reasoning_prefix\\": {\\n          \\"type\\": \\"string\\",\\n          \\"enum\\": [\\"&lt;think&gt;\\"],\\n          \\"description\\": \\"Prefix indicating the model is thinking\\"\\n        },\\n        \\"reasoning\\": {\\n          \\"type\\": \\"string\\",\\n          \\"description\\": \\"The model's internal reasoning and thought process\\"\\n        },\\n        \\"reasoning_suffix\\": {\\n          \\"type\\": \\"string\\",\\n          \\"enum\\": [\\"&lt;/think&gt;\\"],\\n          \\"description\\": \\"Suffix marking the end of the thinking phase\\"\\n        },\\n        \\"reply\\": {\\n          \\"type\\": \\"string\\",\\n          \\"description\\": \\"Final response to the user after reasoning\\"\\n        }\\n      },\\n      \\"required\\": [\\n        \\"reasoning_prefix\\",\\n        \\"reasoning\\",\\n        \\"reasoning_suffix\\",\\n        \\"reply\\"\\n      ]\\n    }\\n\\nThis *sort of works* in that it does in fact cause the model to perform reasoning, but some bits of undesired json are being included in the output. Such as:\\n\\n&gt; { \\"thinking_prefix\\": \\"\\n&gt; \\n&gt; &lt;think&gt;\\",\\n&gt; \\"thoughts\\": \\"The user is asking for a simple test. I need to respond positively and confirm functionality. Maybe add a playful emoji.\\"\\n&gt; , \\"thinking_suffix\\": \\"&lt;/think&gt;\\n&gt; \\n&gt; \\",\\n&gt; \\"reply\\": \\"Testing successful! ðŸ˜Š Everything seems to be working smoothly. How can I assist you today?\\" } \\n\\nI assume I've done something wrong. Can anyone help me understand how to format the schema correctly for this purpose?\\n\\nOn an unrelated note, if anyone can tell me where to find or modify more llama.cpp sampler settings I'd love to know about it. Otherwise it seems like I can only change Temperature, TopK, Rep. Pen., MinP, and TopP...","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Structured output help (LM Studio)","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m3s01i","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_gebwv","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1752917148,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m trying to get MistralThinker to... think. According to discussion on the model page (&lt;a href=\\"https://huggingface.co/Undi95/MistralThinker-v1.1/discussions/1\\"&gt;https://huggingface.co/Undi95/MistralThinker-v1.1/discussions/1&lt;/a&gt;) it is necessary to encourage the model to use reasoning with some structured output or otherwise prefixes. But I&amp;#39;m not using SillyTavern so the suggestions in the thread don&amp;#39;t seem applicable for me. Instead I&amp;#39;m using LM studio for out of the box ROCm support. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve never made a json schema before so I tried generating a structured output, but I&amp;#39;m not entirely sure what the structure is supposed to look like, as I found the LM Studio documentation unclear with poor examples. Here&amp;#39;s where I&amp;#39;m at:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;{\\n  &amp;quot;type&amp;quot;: &amp;quot;object&amp;quot;,\\n  &amp;quot;properties&amp;quot;: {\\n    &amp;quot;reasoning_prefix&amp;quot;: {\\n      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,\\n      &amp;quot;enum&amp;quot;: [&amp;quot;&amp;lt;think&amp;gt;&amp;quot;],\\n      &amp;quot;description&amp;quot;: &amp;quot;Prefix indicating the model is thinking&amp;quot;\\n    },\\n    &amp;quot;reasoning&amp;quot;: {\\n      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,\\n      &amp;quot;description&amp;quot;: &amp;quot;The model&amp;#39;s internal reasoning and thought process&amp;quot;\\n    },\\n    &amp;quot;reasoning_suffix&amp;quot;: {\\n      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,\\n      &amp;quot;enum&amp;quot;: [&amp;quot;&amp;lt;/think&amp;gt;&amp;quot;],\\n      &amp;quot;description&amp;quot;: &amp;quot;Suffix marking the end of the thinking phase&amp;quot;\\n    },\\n    &amp;quot;reply&amp;quot;: {\\n      &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;,\\n      &amp;quot;description&amp;quot;: &amp;quot;Final response to the user after reasoning&amp;quot;\\n    }\\n  },\\n  &amp;quot;required&amp;quot;: [\\n    &amp;quot;reasoning_prefix&amp;quot;,\\n    &amp;quot;reasoning&amp;quot;,\\n    &amp;quot;reasoning_suffix&amp;quot;,\\n    &amp;quot;reply&amp;quot;\\n  ]\\n}\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;This &lt;em&gt;sort of works&lt;/em&gt; in that it does in fact cause the model to perform reasoning, but some bits of undesired json are being included in the output. Such as:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;{ &amp;quot;thinking_prefix&amp;quot;: &amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;&amp;lt;think&amp;gt;&amp;quot;,\\n&amp;quot;thoughts&amp;quot;: &amp;quot;The user is asking for a simple test. I need to respond positively and confirm functionality. Maybe add a playful emoji.&amp;quot;\\n, &amp;quot;thinking_suffix&amp;quot;: &amp;quot;&amp;lt;/think&amp;gt;&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;,\\n&amp;quot;reply&amp;quot;: &amp;quot;Testing successful! ðŸ˜Š Everything seems to be working smoothly. How can I assist you today?&amp;quot; } &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I assume I&amp;#39;ve done something wrong. Can anyone help me understand how to format the schema correctly for this purpose?&lt;/p&gt;\\n\\n&lt;p&gt;On an unrelated note, if anyone can tell me where to find or modify more llama.cpp sampler settings I&amp;#39;d love to know about it. Otherwise it seems like I can only change Temperature, TopK, Rep. Pen., MinP, and TopP...&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?auto=webp&amp;s=4f9186aabac5847d8bb8cba8a974ad27cd3964d3","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=965bf8099f34d87a454fb8dd1f546be43d598fb7","width":108,"height":58},{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=03851a7f7e0086b37a428817e7f3ddf5dd74354e","width":216,"height":116},{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4aaa81559ba0c45f7b6fe03da92d3652c0837843","width":320,"height":172},{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=69d5a1db9f762af62c26cda7748ec1a3b24b1d37","width":640,"height":345},{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=db6631de9e38e7205dc68f64e424d22140dc4387","width":960,"height":518},{"url":"https://external-preview.redd.it/ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b01269a9d5f541a8510da2f205dd43b2628558ef","width":1080,"height":583}],"variants":{},"id":"ytmT6spTi9ZIVCmBZ4Xdi8PdPPKQAGuJJuT6HnMnshk"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m3s01i","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Jawzper","discussion_type":null,"num_comments":0,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m3s01i/structured_output_help_lm_studio/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m3s01i/structured_output_help_lm_studio/","subreddit_subscribers":501232,"created_utc":1752917148,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[],"before":null}}]`),s=()=>t.jsx(e,{data:n});export{s as default};
