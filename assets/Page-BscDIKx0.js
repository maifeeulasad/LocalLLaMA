import{j as e}from"./index-BgwOAK4-.js";import{R as l}from"./RedditPostRenderer-BOBjDTFu.js";import"./index-BL22wVg5.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[https://modelscope.cn/organization/Qwen](https://modelscope.cn/organization/Qwen)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Qwen3 Published 30 seconds ago (Model Weights Available)","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":69,"top_awarded_type":null,"hide_score":false,"name":"t3_1k9qxbl","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.97,"author_flair_background_color":"#bbbdbf","ups":1408,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_fmd6oq5v6","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":1408,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/FtozaQu3557OebIFl1BVvOE8Db0Y-Et5AwAJxVnZgEg.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1745830479,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://modelscope.cn/organization/Qwen\\"&gt;https://modelscope.cn/organization/Qwen&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/472i9pxaijxe1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/472i9pxaijxe1.png?auto=webp&amp;s=166e254eaf9c851c7e7623b096356b68123912d8","width":1898,"height":944},"resolutions":[{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d9a50bab7f0fc0c14256292a6f614ce08e7a5dc","width":108,"height":53},{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=118251b42355290fbe8b5da80531a16365850bb2","width":216,"height":107},{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac9c4fe9e91a8c0a31e9d2284602269a5ebc1b60","width":320,"height":159},{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7159a0fbacf3b156659f562487286b785c7f6484","width":640,"height":318},{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b00d8ee572f4d556f435380dbf27904ea0629b63","width":960,"height":477},{"url":"https://preview.redd.it/472i9pxaijxe1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98c00cd40b5ac398a180ef46a4b1094496b87715","width":1080,"height":537}],"variants":{},"id":"WqT2jSt1_aXgCJHx4ePlc5HWRswZuY_05-Vi6iERDRo"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1k9qxbl","is_robot_indexable":true,"num_duplicates":4,"report_reasons":null,"author":"random-tomato","discussion_type":null,"num_comments":208,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/","stickied":false,"url":"https://i.redd.it/472i9pxaijxe1.png","subreddit_subscribers":492315,"created_utc":1745830479,"num_crossposts":5,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgdcdt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xXWarMachineRoXx","can_mod_post":false,"created_utc":1745831345,"send_replies":true,"parent_id":"t1_mpgcf2s","score":32,"author_fullname":"t2_6zhl6n94","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ahhaha \\n\\nSame","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdcdt","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ahhaha &lt;/p&gt;\\n\\n&lt;p&gt;Same&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdcdt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831345,"author_flair_text":"Llama 3","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgo9qk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sibilischtic","can_mod_post":false,"created_utc":1745837847,"send_replies":true,"parent_id":"t1_mpgcf2s","score":14,"author_fullname":"t2_2m38a4a7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pay dirt. Now just let me finish scrolling and I'll get to downloading those weights","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgo9qk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pay dirt. Now just let me finish scrolling and I&amp;#39;ll get to downloading those weights&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgo9qk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837847,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgdtmk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"daavyzhu","can_mod_post":false,"created_utc":1745831661,"send_replies":true,"parent_id":"t1_mpgcf2s","score":5,"author_fullname":"t2_pnhfc40mp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ðŸ˜‚","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdtmk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ðŸ˜‚&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdtmk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831661,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgk4na","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1745835595,"send_replies":true,"parent_id":"t1_mpgcf2s","score":3,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep ..me too :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgk4na","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep ..me too :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgk4na/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745835595,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpghtr7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tamal4444","can_mod_post":false,"created_utc":1745834210,"send_replies":true,"parent_id":"t1_mpgcf2s","score":0,"author_fullname":"t2_14p01g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpghtr7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpghtr7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745834210,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgcf2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Bakedsoda","can_mod_post":false,"created_utc":1745830723,"send_replies":true,"parent_id":"t3_1k9qxbl","score":362,"author_fullname":"t2_70osb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ok i knew staying up on monday work week scrolling was gonna pay off!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcf2s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ok i knew staying up on monday work week scrolling was gonna pay off!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcf2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745830723,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":362}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpk2v0n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"henfiber","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpibr27","score":4,"author_fullname":"t2_lw9me25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The new o3 also: [https://fiction.live/stories/Fiction-liveBench-April-6-2025/oQdzQvKHw8JyXbN87](https://fiction.live/stories/Fiction-liveBench-April-6-2025/oQdzQvKHw8JyXbN87)","edited":false,"author_flair_css_class":null,"name":"t1_mpk2v0n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The new o3 also: &lt;a href=\\"https://fiction.live/stories/Fiction-liveBench-April-6-2025/oQdzQvKHw8JyXbN87\\"&gt;https://fiction.live/stories/Fiction-liveBench-April-6-2025/oQdzQvKHw8JyXbN87&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpk2v0n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745877665,"author_flair_text":null,"collapsed":false,"created_utc":1745877665,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mpibr27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EducatorDear9685","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpi4ome","score":21,"author_fullname":"t2_16aep2zpze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's really only Gemini 2.5 that can manage the truly long contexts from the last Fiction.LiveBench testing I've seen. \\n\\nI'd not even be mad about 32k context, if it manages to exceed o1, Gemini 2.5 and qwq in comprehension at that context length. It doesn't really matter if it can handle 120k, if it can't do it at a proper comprehension level anyway.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpibr27","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s really only Gemini 2.5 that can manage the truly long contexts from the last Fiction.LiveBench testing I&amp;#39;ve seen. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d not even be mad about 32k context, if it manages to exceed o1, Gemini 2.5 and qwq in comprehension at that context length. It doesn&amp;#39;t really matter if it can handle 120k, if it can&amp;#39;t do it at a proper comprehension level anyway.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpibr27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745858587,"author_flair_text":null,"treatment_tags":[],"created_utc":1745858587,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}}],"before":null}},"user_reports":[],"saved":false,"id":"mpi4ome","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boxingdog","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":36,"author_fullname":"t2_914ev","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"most models fake it anyway, they go off the rails after 16k","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpi4ome","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;most models fake it anyway, they go off the rails after 16k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpi4ome/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745856483,"author_flair_text":null,"treatment_tags":[],"created_utc":1745856483,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph62qp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok-Satisfaction-3949","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph2y18","score":17,"author_fullname":"t2_bfb6yqxe","approved_by":null,"mod_note":null,"all_awardings":[],"body":"True Dude","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mph62qp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;True Dude&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph62qp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845499,"author_flair_text":null,"treatment_tags":[],"created_utc":1745845499,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpkwn5l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Finanzamt_Endgegner","can_mod_post":false,"created_utc":1745887913,"send_replies":true,"parent_id":"t1_mpkiemt","score":1,"author_fullname":"t2_yxfnlbfi8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"at least with the current methods and arch yeah","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpkwn5l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;at least with the current methods and arch yeah&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpkwn5l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745887913,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpkiemt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"floofysox","can_mod_post":false,"created_utc":1745882968,"send_replies":true,"parent_id":"t1_mphxf0s","score":1,"author_fullname":"t2_3gnke5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Itâ€™s not possible for current architectures to retain understanding of such large context lengths with just 8 billion params. thereâ€™s only so much information that can be encoded","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpkiemt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Itâ€™s not possible for current architectures to retain understanding of such large context lengths with just 8 billion params. thereâ€™s only so much information that can be encoded&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpkiemt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745882968,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mphxf0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Finanzamt_Endgegner","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphpks3","score":8,"author_fullname":"t2_yxfnlbfi8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think gemini 2.5 pro exp is probably one of the best with long context, but its paid/free to some degree and not open weights. For local idk tbh","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mphxf0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think gemini 2.5 pro exp is probably one of the best with long context, but its paid/free to some degree and not open weights. For local idk tbh&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphxf0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745854328,"author_flair_text":null,"treatment_tags":[],"created_utc":1745854328,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpieo6a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WitAndWonder","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphpks3","score":6,"author_fullname":"t2_58u1t2z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemini tests have indicated that most of its stated context is actually well referenced during processing. Compared to, say, Claude, where even with its massive context its retention really falls off past something like 32k. Unless you're explicitly using the newest Gemini, you're best off incorporating a RAG or limiting context in some other way for optimal results, regardless of model.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpieo6a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemini tests have indicated that most of its stated context is actually well referenced during processing. Compared to, say, Claude, where even with its massive context its retention really falls off past something like 32k. Unless you&amp;#39;re explicitly using the newest Gemini, you&amp;#39;re best off incorporating a RAG or limiting context in some other way for optimal results, regardless of model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpieo6a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745859434,"author_flair_text":null,"treatment_tags":[],"created_utc":1745859434,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpih7m1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Biggest_Cans","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphpks3","score":2,"author_fullname":"t2_avkl9k31","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Local it's QWQ, non-local it's the latest Gemini.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpih7m1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Local it&amp;#39;s QWQ, non-local it&amp;#39;s the latest Gemini.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpih7m1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860175,"author_flair_text":null,"treatment_tags":[],"created_utc":1745860175,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpivl77","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphpks3","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;do you know what models have the most usable context?\\n\\nmaybe MiniMax-01 (pretrained on 1M context, extended to 4 post training... really usable \\"only\\" for 1M from my experience)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpivl77","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;do you know what models have the most usable context?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;maybe MiniMax-01 (pretrained on 1M context, extended to 4 post training... really usable &amp;quot;only&amp;quot; for 1M from my experience)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpivl77/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745864351,"author_flair_text":null,"treatment_tags":[],"created_utc":1745864351,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mphpks3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iiiba","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph2y18","score":6,"author_fullname":"t2_fszcpxsmi","approved_by":null,"mod_note":null,"all_awardings":[],"body":"do you know what models have the most usable context? i think gemini claims 2M and Llama4 claims 10M but i dont believe either of them. NVIDIA's RULER is a bit outdated, has there been a more recent study?","edited":1745858492,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mphpks3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;do you know what models have the most usable context? i think gemini claims 2M and Llama4 claims 10M but i dont believe either of them. NVIDIA&amp;#39;s RULER is a bit outdated, has there been a more recent study?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphpks3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745851950,"author_flair_text":null,"treatment_tags":[],"created_utc":1745851950,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mph2y18","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Finanzamt_Endgegner","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgqpcr","score":94,"author_fullname":"t2_yxfnlbfi8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If only 16k of those 128k are useable it doesnt matter how long it is...","edited":false,"author_flair_css_class":null,"name":"t1_mph2y18","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If only 16k of those 128k are useable it doesnt matter how long it is...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph2y18/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844328,"author_flair_text":null,"collapsed":false,"created_utc":1745844328,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":94}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph74bk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgqpcr","score":7,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes... but if Gemma3 can only tell you that Beetlejuice shouldn't be in the middle of chapter 3 of Harry Potter... but 30B-A3B can go in extensive detail on how a single sentence change in  chapter 3 could have setup the series for Hermione to end up with Harry or for Harry to side with Lord Voldemort ... then I'll take 32k context. At present Llama 4 Scout has a 10 million context that isn't very effective. It's all in how well you use it...","edited":false,"author_flair_css_class":null,"name":"t1_mph74bk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes... but if Gemma3 can only tell you that Beetlejuice shouldn&amp;#39;t be in the middle of chapter 3 of Harry Potter... but 30B-A3B can go in extensive detail on how a single sentence change in  chapter 3 could have setup the series for Hermione to end up with Harry or for Harry to side with Lord Voldemort ... then I&amp;#39;ll take 32k context. At present Llama 4 Scout has a 10 million context that isn&amp;#39;t very effective. It&amp;#39;s all in how well you use it...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph74bk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845883,"author_flair_text":null,"collapsed":false,"created_utc":1745845883,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgt5r0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Different_Fix_2217","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgqpcr","score":4,"author_fullname":"t2_4dhrrvi6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the power of TPUs","edited":false,"author_flair_css_class":null,"name":"t1_mpgt5r0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the power of TPUs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgt5r0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745840239,"author_flair_text":null,"collapsed":false,"created_utc":1745840239,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgqpcr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tjuene","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgmp0k","score":28,"author_fullname":"t2_j61e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The 30B-A3B also only has 32k context (according to the leak from u/sunshinecheung). gemma3 4b has 128k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgqpcr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The 30B-A3B also only has 32k context (according to the leak from &lt;a href=\\"/u/sunshinecheung\\"&gt;u/sunshinecheung&lt;/a&gt;). gemma3 4b has 128k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgqpcr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839066,"author_flair_text":null,"treatment_tags":[],"created_utc":1745839066,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpll0ly","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpjnvk2","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, although honestly I cant run it, best I can do is 8b at \\\\~28k (for llama3.1). it just uses too much vram, and when context is near full, it uses waaay too much compute.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpll0ly","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, although honestly I cant run it, best I can do is 8b at ~28k (for llama3.1). it just uses too much vram, and when context is near full, it uses waaay too much compute.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpll0ly/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745896645,"author_flair_text":null,"treatment_tags":[],"created_utc":1745896645,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpjnvk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph3t4f","score":4,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would like to see an 8b model that can make good use of long context.  If it's for needle in haystack tests then you can just use ctrl+f.","edited":false,"author_flair_css_class":null,"name":"t1_mpjnvk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would like to see an 8b model that can make good use of long context.  If it&amp;#39;s for needle in haystack tests then you can just use ctrl+f.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjnvk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745872856,"author_flair_text":null,"collapsed":false,"created_utc":1745872856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mph3t4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgmp0k","score":2,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A lot of 8b models also have 128k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph3t4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A lot of 8b models also have 128k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph3t4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844656,"author_flair_text":null,"treatment_tags":[],"created_utc":1745844656,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgmp0k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OkActive3404","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":69,"author_fullname":"t2_1i6g5eg2gd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thats only the 8b small model tho","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgmp0k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thats only the 8b small model tho&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgmp0k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837027,"author_flair_text":null,"treatment_tags":[],"created_utc":1745837027,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":69}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphirqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kep0a","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":31,"author_fullname":"t2_iid99","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Guys we had like 4096/t context length a year ago. Most models context length is way inflated too.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mphirqk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Guys we had like 4096/t context length a year ago. Most models context length is way inflated too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphirqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745849835,"author_flair_text":null,"treatment_tags":[],"created_utc":1745849835,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpjnogl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":3,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes and no.  There has yet to be a local LLM that can make good use of context beyond 8-16k - needle in haystack aside.  Long context tends to severely degrade the quality of the output as well.  Even top tier models like claude 3.7 fall apart after 20-30k.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpjnogl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes and no.  There has yet to be a local LLM that can make good use of context beyond 8-16k - needle in haystack aside.  Long context tends to severely degrade the quality of the output as well.  Even top tier models like claude 3.7 fall apart after 20-30k.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjnogl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745872798,"author_flair_text":null,"treatment_tags":[],"created_utc":1745872798,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpimlkt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Happy_Intention3873","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":2,"author_fullname":"t2_xm0g1ffai","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"could this be the base model by which the 256k context length instruct model will be post trained on?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpimlkt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;could this be the base model by which the 256k context length instruct model will be post trained on?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpimlkt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745861729,"author_flair_text":null,"treatment_tags":[],"created_utc":1745861729,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mplq7r5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"5dtriangles201376","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgki8x","score":1,"author_fullname":"t2_7kqsnjio","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm happy with anything over 12-16k honestly, but I haven't done much with reasoning in fairness","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mplq7r5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m happy with anything over 12-16k honestly, but I haven&amp;#39;t done much with reasoning in fairness&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mplq7r5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745898731,"author_flair_text":null,"treatment_tags":[],"created_utc":1745898731,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgki8x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tjuene","can_mod_post":false,"created_utc":1745835814,"send_replies":true,"parent_id":"t1_mpgfxul","score":34,"author_fullname":"t2_j61e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The context length is a bit disappointing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgki8x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The context length is a bit disappointing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgki8x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745835814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfxul","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Different_Fix_2217","can_mod_post":false,"created_utc":1745833040,"send_replies":true,"parent_id":"t3_1k9qxbl","score":151,"author_fullname":"t2_4dhrrvi6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"# Qwen3-8B\\n\\n# Qwen3 Highlights\\n\\nQwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Building upon extensive advancements in training data, model architecture, and optimization techniques, Qwen3 delivers the following key improvements over the previously released Qwen2.5:\\n\\n* **Expanded Higher-Quality Pre-training Corpus:**Â Qwen3 is pre-trained on 36 trillion tokens across 119 languages â€” tripling the language coverage of Qwen2.5 â€” with a much richer mix of high-quality data, including coding, STEM, reasoning, book, multilingual, and synthetic data.\\n* **Training Techniques and Model Architecture:**Â Qwen3 incorporates a series of training techiques and architectural refinements, including global-batch load balancing loss for MoE models and qk layernorm for all models, leading to improved stability and overall performance.\\n* **Three-stage Pre-training:**Â Stage 1 focuses on broad language modeling and general knowledge acquisition, Stage 2 improves reasoning skills like STEM, coding, and logical reasoning, and Stage 3 enhances long-context comprehension by extending training sequence lengths up to 32k tokens.\\n* **Scaling Law Guided Hyperparameter Tuning:**Â Through comprehensive scaling law studies across the three-stage pre-training pipeline, Qwen3 systematically tunes critical hyperparameters â€” such as learning rate scheduler and batch size â€” separately for dense and MoE models, resulting in better training dynamics and final performance across different model scales.\\n\\n# Model Overview\\n\\n**Qwen3-8B**Â has the following features:\\n\\n* Type: Causal Language Models\\n* Training Stage: Pretraining &amp; Post-training\\n* Number of Parameters: 8.2B\\n* Number of Paramaters (Non-Embedding): 6.95B\\n* Number of Layers: 36\\n* Number of Attention Heads (GQA): 32 for Q and 8 for KV\\n* Context Length: 32,768","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgfxul","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;h1&gt;Qwen3-8B&lt;/h1&gt;\\n\\n&lt;h1&gt;Qwen3 Highlights&lt;/h1&gt;\\n\\n&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Building upon extensive advancements in training data, model architecture, and optimization techniques, Qwen3 delivers the following key improvements over the previously released Qwen2.5:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Expanded Higher-Quality Pre-training Corpus:&lt;/strong&gt;Â Qwen3 is pre-trained on 36 trillion tokens across 119 languages â€” tripling the language coverage of Qwen2.5 â€” with a much richer mix of high-quality data, including coding, STEM, reasoning, book, multilingual, and synthetic data.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Training Techniques and Model Architecture:&lt;/strong&gt;Â Qwen3 incorporates a series of training techiques and architectural refinements, including global-batch load balancing loss for MoE models and qk layernorm for all models, leading to improved stability and overall performance.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Three-stage Pre-training:&lt;/strong&gt;Â Stage 1 focuses on broad language modeling and general knowledge acquisition, Stage 2 improves reasoning skills like STEM, coding, and logical reasoning, and Stage 3 enhances long-context comprehension by extending training sequence lengths up to 32k tokens.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Scaling Law Guided Hyperparameter Tuning:&lt;/strong&gt;Â Through comprehensive scaling law studies across the three-stage pre-training pipeline, Qwen3 systematically tunes critical hyperparameters â€” such as learning rate scheduler and batch size â€” separately for dense and MoE models, resulting in better training dynamics and final performance across different model scales.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;Model Overview&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Qwen3-8B&lt;/strong&gt;Â has the following features:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Type: Causal Language Models&lt;/li&gt;\\n&lt;li&gt;Training Stage: Pretraining &amp;amp; Post-training&lt;/li&gt;\\n&lt;li&gt;Number of Parameters: 8.2B&lt;/li&gt;\\n&lt;li&gt;Number of Paramaters (Non-Embedding): 6.95B&lt;/li&gt;\\n&lt;li&gt;Number of Layers: 36&lt;/li&gt;\\n&lt;li&gt;Number of Attention Heads (GQA): 32 for Q and 8 for KV&lt;/li&gt;\\n&lt;li&gt;Context Length: 32,768&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfxul/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833040,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":151}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpiih6l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Artistic_Okra7288","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgsgih","score":4,"author_fullname":"t2_t35b2uw5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwoon?","edited":false,"author_flair_css_class":null,"name":"t1_mpiih6l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwoon?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiih6l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860542,"author_flair_text":null,"collapsed":false,"created_utc":1745860542,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpi9cbm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgsgih","score":3,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"...soon.","edited":false,"author_flair_css_class":null,"name":"t1_mpi9cbm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...soon.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpi9cbm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745857873,"author_flair_text":null,"collapsed":false,"created_utc":1745857873,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgsgih","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"some_user_2021","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpge37g","score":13,"author_fullname":"t2_cmfeo4yq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen will then be now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgsgih","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen will then be now?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgsgih/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839912,"author_flair_text":null,"treatment_tags":[],"created_utc":1745839912,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"mpge37g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EugenePopcorn","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdwbl","score":85,"author_fullname":"t2_g6hpxxgss","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen they get around to it, I guess.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpge37g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen they get around to it, I guess.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpge37g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831836,"author_flair_text":null,"treatment_tags":[],"created_utc":1745831836,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":85}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgmtf7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tabspaces","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdwbl","score":26,"author_fullname":"t2_h4h2az0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good Qwention","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgmtf7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good Qwention&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgmtf7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837091,"author_flair_text":null,"treatment_tags":[],"created_utc":1745837091,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphfzhw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BoneDaddyMan","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdwbl","score":2,"author_fullname":"t2_9hgwo6uk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tell me qwendo qwendo qwennnndoooooooo!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mphfzhw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tell me qwendo qwendo qwennnndoooooooo!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphfzhw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745848940,"author_flair_text":null,"treatment_tags":[],"created_utc":1745848940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdwbl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dampflokfreund","can_mod_post":false,"created_utc":1745831709,"send_replies":true,"parent_id":"t1_mpgcqsp","score":99,"author_fullname":"t2_lis7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen then, now no qwen so Qwen when?Â ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdwbl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen then, now no qwen so Qwen when?Â &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdwbl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831709,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":99}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphdriq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1745848212,"send_replies":true,"parent_id":"t1_mphai34","score":2,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's my concern... elsewhere it doesn't have that. Hopefully that isn't a default they took it down to change. I'm excited for Apache 2.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mphdriq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s my concern... elsewhere it doesn&amp;#39;t have that. Hopefully that isn&amp;#39;t a default they took it down to change. I&amp;#39;m excited for Apache 2.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphdriq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745848212,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mphai34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kouteiheika","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph61px","score":5,"author_fullname":"t2_4blhr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"OP didn't grab the license file, but [it says Apache 2 here](https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fvf4pzi9mgjxe1.png).","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mphai34","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP didn&amp;#39;t grab the license file, but &lt;a href=\\"https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fvf4pzi9mgjxe1.png\\"&gt;it says Apache 2 here&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphai34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745847097,"author_flair_text":null,"treatment_tags":[],"created_utc":1745847097,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mph61px","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgux4n","score":3,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is there a model license listed? Did they release all as Apache or are some under Qwen special license?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mph61px","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there a model license listed? Did they release all as Apache or are some under Qwen special license?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph61px/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845488,"author_flair_text":null,"treatment_tags":[],"created_utc":1745845488,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgux4n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kouteiheika","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdltj","score":22,"author_fullname":"t2_4blhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You got enough files to get it running. Copy \`tokenizer.json\`, \`tokenizer_config.json\` and \`generation_config.json\` from Qwen2.5, and then copy-paste this as a \`config.json\` (you downloaded the wrong config, but it's easy enough to guess the correct one):\\n\\n    {\\n      \\"architectures\\": [\\n        \\"Qwen3ForCausalLM\\"\\n      ],\\n      \\"attention_bias\\": false,\\n      \\"attention_dropout\\": 0.0,\\n      \\"bos_token_id\\": 151643,\\n      \\"eos_token_id\\": 151643,\\n      \\"head_dim\\": 128,\\n      \\"hidden_act\\": \\"silu\\",\\n      \\"hidden_size\\": 1024,\\n      \\"initializer_range\\": 0.02,\\n      \\"intermediate_size\\": 3072,\\n      \\"max_position_embeddings\\": 32768,\\n      \\"max_window_layers\\": 36,\\n      \\"model_type\\": \\"qwen3\\",\\n      \\"num_attention_heads\\": 16,\\n      \\"num_hidden_layers\\": 28,\\n      \\"num_key_value_heads\\": 8,\\n      \\"rms_norm_eps\\": 1e-06,\\n      \\"rope_scaling\\": null,\\n      \\"rope_theta\\": 1000000,\\n      \\"sliding_window\\": null,\\n      \\"tie_word_embeddings\\": true,\\n      \\"torch_dtype\\": \\"bfloat16\\",\\n      \\"transformers_version\\": \\"4.51.0\\",\\n      \\"use_cache\\": true,\\n      \\"use_sliding_window\\": false,\\n      \\"vocab_size\\": 151936\\n    }\\n\\nI can confirm that it works with this.","edited":false,"author_flair_css_class":null,"name":"t1_mpgux4n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You got enough files to get it running. Copy &lt;code&gt;tokenizer.json&lt;/code&gt;, &lt;code&gt;tokenizer_config.json&lt;/code&gt; and &lt;code&gt;generation_config.json&lt;/code&gt; from Qwen2.5, and then copy-paste this as a &lt;code&gt;config.json&lt;/code&gt; (you downloaded the wrong config, but it&amp;#39;s easy enough to guess the correct one):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;{\\n  &amp;quot;architectures&amp;quot;: [\\n    &amp;quot;Qwen3ForCausalLM&amp;quot;\\n  ],\\n  &amp;quot;attention_bias&amp;quot;: false,\\n  &amp;quot;attention_dropout&amp;quot;: 0.0,\\n  &amp;quot;bos_token_id&amp;quot;: 151643,\\n  &amp;quot;eos_token_id&amp;quot;: 151643,\\n  &amp;quot;head_dim&amp;quot;: 128,\\n  &amp;quot;hidden_act&amp;quot;: &amp;quot;silu&amp;quot;,\\n  &amp;quot;hidden_size&amp;quot;: 1024,\\n  &amp;quot;initializer_range&amp;quot;: 0.02,\\n  &amp;quot;intermediate_size&amp;quot;: 3072,\\n  &amp;quot;max_position_embeddings&amp;quot;: 32768,\\n  &amp;quot;max_window_layers&amp;quot;: 36,\\n  &amp;quot;model_type&amp;quot;: &amp;quot;qwen3&amp;quot;,\\n  &amp;quot;num_attention_heads&amp;quot;: 16,\\n  &amp;quot;num_hidden_layers&amp;quot;: 28,\\n  &amp;quot;num_key_value_heads&amp;quot;: 8,\\n  &amp;quot;rms_norm_eps&amp;quot;: 1e-06,\\n  &amp;quot;rope_scaling&amp;quot;: null,\\n  &amp;quot;rope_theta&amp;quot;: 1000000,\\n  &amp;quot;sliding_window&amp;quot;: null,\\n  &amp;quot;tie_word_embeddings&amp;quot;: true,\\n  &amp;quot;torch_dtype&amp;quot;: &amp;quot;bfloat16&amp;quot;,\\n  &amp;quot;transformers_version&amp;quot;: &amp;quot;4.51.0&amp;quot;,\\n  &amp;quot;use_cache&amp;quot;: true,\\n  &amp;quot;use_sliding_window&amp;quot;: false,\\n  &amp;quot;vocab_size&amp;quot;: 151936\\n}\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;I can confirm that it works with this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgux4n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841029,"author_flair_text":null,"collapsed":false,"created_utc":1745841029,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgmaxe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shing3232","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdq85","score":15,"author_fullname":"t2_ze4mg","approved_by":null,"mod_note":null,"all_awardings":[],"body":"enable_thinking=TrueBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting enable_thinking=True or leaving it as the default value in tokenizer.apply_chat_template, the model will engage its thinking mode.\\ntext = tokenizer.apply_chat_template(\\n    messages,\\n    tokenize=False,\\n    add_generation_prompt=True,\\n    enable_thinking=True  # True is the default value for enable_thinking\\n)\\n\\nIn this mode, the model will generate think content wrapped in a &lt;think&gt;...&lt;/think&gt; block, followed by the final response.\\nNote\\nFor thinking mode, use Temperature=0.6, TopP=0.95, TopK=20, and MinP=0 (the default setting in generation_config.json). DO NOT use greedy decoding, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the Best Practices section.\\nenable_thinking=False","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpgmaxe","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;enable_thinking=TrueBy default, Qwen3 has thinking capabilities enabled, similar to QwQ-32B. This means the model will use its reasoning abilities to enhance the quality of generated responses. For example, when explicitly setting enable_thinking=True or leaving it as the default value in tokenizer.apply_chat_template, the model will engage its thinking mode.\\ntext = tokenizer.apply_chat_template(\\n    messages,\\n    tokenize=False,\\n    add_generation_prompt=True,\\n    enable_thinking=True  # True is the default value for enable_thinking\\n)&lt;/p&gt;\\n\\n&lt;p&gt;In this mode, the model will generate think content wrapped in a &amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt; block, followed by the final response.\\nNote\\nFor thinking mode, use Temperature=0.6, TopP=0.95, TopK=20, and MinP=0 (the default setting in generation_config.json). DO NOT use greedy decoding, as it can lead to performance degradation and endless repetitions. For more detailed guidance, please refer to the Best Practices section.\\nenable_thinking=False&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgmaxe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836819,"author_flair_text":null,"treatment_tags":[],"created_utc":1745836819,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgjifz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inteblio","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdq85","score":5,"author_fullname":"t2_bzdh4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cool! \\n\\nI like a pre-order....","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpgjifz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool! &lt;/p&gt;\\n\\n&lt;p&gt;I like a pre-order....&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgjifz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745835232,"author_flair_text":null,"treatment_tags":[],"created_utc":1745835232,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdq85","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shing3232","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdltj","score":26,"author_fullname":"t2_ze4mg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Building upon extensive advancements in training data, model architecture, and optimization techniques, Qwen3 delivers the following key improvements over the previously released Qwen2.5:\\nExpanded Higher-Quality Pre-training Corpus: Qwen3 is pre-trained on 36 trillion tokens across 119 languages â€” tripling the language coverage of Qwen2.5 â€” with a much richer mix of high-quality data, including coding, STEM, reasoning, book, multilingual, and synthetic data.\\nTraining Techniques and Model Architecture: Qwen3 incorporates a series of training techiques and architectural refinements, including global-batch load balancing loss for MoE models and qk layernorm for all models, leading to improved stability and overall performance.\\nThree-stage Pre-training: Stage 1 focuses on broad language modeling and general knowledge acquisition, Stage 2 improves reasoning skills like STEM, coding, and logical reasoning, and Stage 3 enhances long-context comprehension by extending training sequence lengths up to 32k tokens.\\nScaling Law Guided Hyperparameter Tuning: Through comprehensive scaling law studies across the three-stage pre-training pipeline, Qwen3 systematically tunes critical hyperparameters â€” such as learning rate scheduler and batch size â€” separately for dense and MoE models, resulting in better training dynamics and final performance across different model scales.","edited":false,"author_flair_css_class":null,"name":"t1_mpgdq85","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Building upon extensive advancements in training data, model architecture, and optimization techniques, Qwen3 delivers the following key improvements over the previously released Qwen2.5:\\nExpanded Higher-Quality Pre-training Corpus: Qwen3 is pre-trained on 36 trillion tokens across 119 languages â€” tripling the language coverage of Qwen2.5 â€” with a much richer mix of high-quality data, including coding, STEM, reasoning, book, multilingual, and synthetic data.\\nTraining Techniques and Model Architecture: Qwen3 incorporates a series of training techiques and architectural refinements, including global-batch load balancing loss for MoE models and qk layernorm for all models, leading to improved stability and overall performance.\\nThree-stage Pre-training: Stage 1 focuses on broad language modeling and general knowledge acquisition, Stage 2 improves reasoning skills like STEM, coding, and logical reasoning, and Stage 3 enhances long-context comprehension by extending training sequence lengths up to 32k tokens.\\nScaling Law Guided Hyperparameter Tuning: Through comprehensive scaling law studies across the three-stage pre-training pipeline, Qwen3 systematically tunes critical hyperparameters â€” such as learning rate scheduler and batch size â€” separately for dense and MoE models, resulting in better training dynamics and final performance across different model scales.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdq85/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831598,"author_flair_text":null,"collapsed":false,"created_utc":1745831598,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgnxr5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"terminoid_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdltj","score":3,"author_fullname":"t2_1iu07dnz2i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i hope somebody turns that 0.6B into an embedding model","edited":false,"author_flair_css_class":null,"name":"t1_mpgnxr5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i hope somebody turns that 0.6B into an embedding model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgnxr5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837676,"author_flair_text":null,"collapsed":false,"created_utc":1745837676,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpj4iff","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphjz0s","score":2,"author_fullname":"t2_fmd6oq5v6","approved_by":null,"mod_note":null,"all_awardings":[],"body":"my internet speed sucks, I just choose the small boi because at least I would have a chance of downloading the whole weights quickly","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpj4iff","is_submitter":true,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;my internet speed sucks, I just choose the small boi because at least I would have a chance of downloading the whole weights quickly&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpj4iff/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745867018,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1745867018,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mphjz0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mnt_brain","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdltj","score":1,"author_fullname":"t2_1mtt9dytfn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"0.6b, nice, at least you picked the worst model of all","edited":false,"author_flair_css_class":null,"name":"t1_mphjz0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;0.6b, nice, at least you picked the worst model of all&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphjz0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745850218,"author_flair_text":null,"collapsed":false,"created_utc":1745850218,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdltj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdh6d","score":45,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm downloading the Qwen3 0.6B safetensors. I have the vocab.json and the model.safetensors but nothing else.\\n\\nEdit 1 - Uploaded: [https://huggingface.co/qingy2024/Qwen3-0.6B/tree/main](https://huggingface.co/qingy2024/Qwen3-0.6B/tree/main)\\n\\nEdit 2 - Probably not useful considering a lot of important files are missing, but it's better than nothing :)\\n\\nEdit 3 - I'm stupid, I should have downloaded them faster...","edited":1745832809,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdltj","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m downloading the Qwen3 0.6B safetensors. I have the vocab.json and the model.safetensors but nothing else.&lt;/p&gt;\\n\\n&lt;p&gt;Edit 1 - Uploaded: &lt;a href=\\"https://huggingface.co/qingy2024/Qwen3-0.6B/tree/main\\"&gt;https://huggingface.co/qingy2024/Qwen3-0.6B/tree/main&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Edit 2 - Probably not useful considering a lot of important files are missing, but it&amp;#39;s better than nothing :)&lt;/p&gt;\\n\\n&lt;p&gt;Edit 3 - I&amp;#39;m stupid, I should have downloaded them faster...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdltj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831516,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1745831516,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":45}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdh6d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RazzmatazzReal4129","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgcvht","score":64,"author_fullname":"t2_flbicsbbj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OP, think of all the time you wasted with this post when you could have gotten us the files first!Â  Last time we put you on Qwen watch...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgdh6d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OP, think of all the time you wasted with this post when you could have gotten us the files first!Â  Last time we put you on Qwen watch...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdh6d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831433,"author_flair_text":null,"treatment_tags":[],"created_utc":1745831433,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":64}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph6kln","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph2n3b","score":7,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=ed09266d48bab8ffe11fce35b00de755238e3f8f\\n\\nAlmost said it correctly, but this time, emphasize the Eetlejuice part for me.","edited":false,"author_flair_css_class":null,"name":"t1_mph6kln","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ed09266d48bab8ffe11fce35b00de755238e3f8f\\"&gt;https://preview.redd.it/0sttjf9crkxe1.jpeg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ed09266d48bab8ffe11fce35b00de755238e3f8f&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Almost said it correctly, but this time, emphasize the Eetlejuice part for me.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph6kln/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845682,"media_metadata":{"0sttjf9crkxe1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":60,"x":108,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2ab8a679c7f4453817c5c31e7d9ba899c3ce457"},{"y":121,"x":216,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86ae036a6037efdf4d124031dc2fd1c0f2335677"},{"y":180,"x":320,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b82ce66e0721367b8da68ac17dbf127026891b8"},{"y":360,"x":640,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c5c5d1cff940ce08f9d98e55f750633bee3f80d"},{"y":540,"x":960,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0846b889736bc509a6984af9e28cf31182f3cca6"},{"y":607,"x":1080,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f086b220fb9e169091fa6c3c1f4a84c75a63851"}],"s":{"y":1080,"x":1920,"u":"https://preview.redd.it/0sttjf9crkxe1.jpeg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=ed09266d48bab8ffe11fce35b00de755238e3f8f"},"id":"0sttjf9crkxe1"}},"author_flair_text":null,"collapsed":false,"created_utc":1745845682,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mph2n3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdhal","score":20,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Bartowski Bartowski Bartowski!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph2n3b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bartowski Bartowski Bartowski!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph2n3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844211,"author_flair_text":null,"treatment_tags":[],"created_utc":1745844211,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdhal","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlanCarrOnline","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgcvht","score":23,"author_fullname":"t2_ry6xs35o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Where GGUF?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgdhal","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where GGUF?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdhal/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831435,"author_flair_text":null,"treatment_tags":[],"created_utc":1745831435,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgcvht","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"created_utc":1745831031,"send_replies":true,"parent_id":"t1_mpgcqsp","score":31,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"... yep\\n\\nwe were so close :')","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcvht","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;... yep&lt;/p&gt;\\n\\n&lt;p&gt;we were so close :&amp;#39;)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcvht/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831031,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphbr5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MrWeirdoFace","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgv2kk","score":7,"author_fullname":"t2_12e249","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen it's ready.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mphbr5x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen it&amp;#39;s ready.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphbr5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745847536,"author_flair_text":null,"treatment_tags":[],"created_utc":1745847536,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgv2kk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"2shanigans","can_mod_post":false,"created_utc":1745841095,"send_replies":true,"parent_id":"t1_mpgcqsp","score":10,"author_fullname":"t2_116dje","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's only a matter of Qwen it will be back.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgv2kk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s only a matter of Qwen it will be back.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgv2kk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841095,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgdhbk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_stream_line_","can_mod_post":false,"created_utc":1745831435,"send_replies":true,"parent_id":"t1_mpgcqsp","score":4,"author_fullname":"t2_13t6yz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Context?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdhbk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Context?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdhbk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831435,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph1kea","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"diroussel","can_mod_post":false,"created_utc":1745843794,"send_replies":true,"parent_id":"t1_mpgcqsp","score":4,"author_fullname":"t2_1s6sx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If not now, then Qwen?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph1kea","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If not now, then Qwen?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph1kea/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843794,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph5lsm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnomalyNexus","can_mod_post":false,"created_utc":1745845325,"send_replies":true,"parent_id":"t1_mpgcqsp","score":1,"author_fullname":"t2_3q8dd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Guessing someone accidentally a token","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph5lsm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Guessing someone accidentally a token&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph5lsm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845325,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgcqsp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shing3232","can_mod_post":false,"created_utc":1745830942,"send_replies":true,"parent_id":"t3_1k9qxbl","score":176,"author_fullname":"t2_ze4mg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"then it's gone","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcqsp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;then it&amp;#39;s gone&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcqsp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745830942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":176}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgdkf0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"created_utc":1745831491,"send_replies":true,"parent_id":"t3_1k9qxbl","score":53,"author_fullname":"t2_8jqx3m14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Aaaaand it's gone.\\n\\nI just downloaded Qwen 2.5 VL, so maybe this will trigger the Qwen 3 drop...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdkf0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Aaaaand it&amp;#39;s gone.&lt;/p&gt;\\n\\n&lt;p&gt;I just downloaded Qwen 2.5 VL, so maybe this will trigger the Qwen 3 drop...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdkf0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831491,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgqy3k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Loose_Race908","can_mod_post":false,"created_utc":1745839184,"send_replies":true,"parent_id":"t1_mpgojy2","score":4,"author_fullname":"t2_bnej4s5r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very interesting!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgqy3k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very interesting!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgqy3k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839184,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphg8zv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"created_utc":1745849026,"send_replies":true,"parent_id":"t1_mpgojy2","score":8,"author_fullname":"t2_eerln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"40k context length? You must be kidding? I hope 1bit quant works","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mphg8zv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;40k context length? You must be kidding? I hope 1bit quant works&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphg8zv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745849026,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgojy2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Different_Fix_2217","can_mod_post":false,"created_utc":1745837992,"send_replies":true,"parent_id":"t3_1k9qxbl","score":42,"author_fullname":"t2_4dhrrvi6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/sc0amo4o4kxe1.png?width=1402&amp;format=png&amp;auto=webp&amp;s=3ff9ef57aa51bd40480a94c47a25bb3c9a85d145","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgojy2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/sc0amo4o4kxe1.png?width=1402&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ff9ef57aa51bd40480a94c47a25bb3c9a85d145\\"&gt;https://preview.redd.it/sc0amo4o4kxe1.png?width=1402&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ff9ef57aa51bd40480a94c47a25bb3c9a85d145&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgojy2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837992,"media_metadata":{"sc0amo4o4kxe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":119,"x":108,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa647798efd713e7b35d0ddffe2fc289fd599019"},{"y":238,"x":216,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e1f32a08aaa1b672f9e14adefc6b6bbc8d2e8e0"},{"y":353,"x":320,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4aaec98cbae48ad44d4627cc95a97216271013ed"},{"y":706,"x":640,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=25d115713dc79249d0a28349d98fa6fdc2ff9741"},{"y":1059,"x":960,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5c7951f529a9b11d627b1e2a01128d84b8af7a34"},{"y":1192,"x":1080,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a803396beb070184d27160a3edcbcf251ab8bfc7"}],"s":{"y":1548,"x":1402,"u":"https://preview.redd.it/sc0amo4o4kxe1.png?width=1402&amp;format=png&amp;auto=webp&amp;s=3ff9ef57aa51bd40480a94c47a25bb3c9a85d145"},"id":"sc0amo4o4kxe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph3vnj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dp3471","can_mod_post":false,"created_utc":1745844683,"send_replies":true,"parent_id":"t1_mpgfhet","score":6,"author_fullname":"t2_nosjvxse","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the flashbacks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph3vnj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the flashbacks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph3vnj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844683,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfhet","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"seeKAYx","can_mod_post":false,"created_utc":1745832745,"send_replies":true,"parent_id":"t3_1k9qxbl","score":97,"author_fullname":"t2_48w2cx4p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=720&amp;format=png&amp;auto=webp&amp;s=d95e9436d651dac85fa360d0eda980092375b930","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgfhet","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/jm2bsrt2pjxe1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d95e9436d651dac85fa360d0eda980092375b930\\"&gt;https://preview.redd.it/jm2bsrt2pjxe1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d95e9436d651dac85fa360d0eda980092375b930&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfhet/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745832745,"media_metadata":{"jm2bsrt2pjxe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":72,"x":108,"u":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=60e71fda623f0782281a43dc60933b74f04b91bc"},{"y":144,"x":216,"u":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2041d7538d1c07639bc868e2bce3298d3c01ae47"},{"y":213,"x":320,"u":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b5898715e3185dc2564b112f69a55dd7b85dbd5"},{"y":426,"x":640,"u":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c59bdaa872d32cbb106695e1a77c8847590ff7bc"}],"s":{"y":480,"x":720,"u":"https://preview.redd.it/jm2bsrt2pjxe1.png?width=720&amp;format=png&amp;auto=webp&amp;s=d95e9436d651dac85fa360d0eda980092375b930"},"id":"jm2bsrt2pjxe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":97}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":24,"removal_reason":null,"link_id":"t3_1k9qxbl","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":12,"removal_reason":null,"link_id":"t3_1k9qxbl","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpmgqll","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"created_utc":1745912590,"send_replies":true,"parent_id":"t1_mph3rzf","score":2,"author_fullname":"t2_o5fyioqm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks a lot. People seem to be using this sqrt(active X all\\\\_params) extremely liberally, without any reference to support such use.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpmgqll","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks a lot. People seem to be using this sqrt(active X all_params) extremely liberally, without any reference to support such use.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmgqll/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745912590,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":3,"name":"t1_mph75kc","id":"mph75kc","parent_id":"t1_mph3rzf","depth":7,"children":["mph75kc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mph3rzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgop62","score":12,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1745850155,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph3rzf/","num_reports":null,"locked":false,"name":"t1_mph3rzf","created":1745844643,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1745844643,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgop62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgi7lr","score":15,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a dense model equivalence formula. Basically the 30b is supposed to compare to a 10b dense in terms of actual performance on AI things. Think it's kind of a useful metric. Fast means nothing if the tokens aren't good.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpgop62","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a dense model equivalence formula. Basically the 30b is supposed to compare to a 10b dense in terms of actual performance on AI things. Think it&amp;#39;s kind of a useful metric. Fast means nothing if the tokens aren&amp;#39;t good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgop62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745838066,"author_flair_text":null,"treatment_tags":[],"created_utc":1745838066,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgi7lr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgfmrm","score":24,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1745834923,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgi7lr/","num_reports":null,"locked":false,"name":"t1_mpgi7lr","created":1745834443,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1745834443,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgva4c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgglc1","score":3,"author_fullname":"t2_5hobp6m4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, it s only an estimation. Modern MoE use a lot of tiny experts (I think this one will use 128 of them, 8 active), the number of active parameters is a sum of all that are activated.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpgva4c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, it s only an estimation. Modern MoE use a lot of tiny experts (I think this one will use 128 of them, 8 active), the number of active parameters is a sum of all that are activated.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgva4c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841186,"author_flair_text":null,"treatment_tags":[],"created_utc":1745841186,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgglc1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"moncallikta","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgfmrm","score":7,"author_fullname":"t2_15ju4l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Depends on how many experts are activated per token too, right? Some models do 1 expert only, others 2-3 experts.","edited":false,"author_flair_css_class":null,"name":"t1_mpgglc1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends on how many experts are activated per token too, right? Some models do 1 expert only, others 2-3 experts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgglc1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833451,"author_flair_text":null,"collapsed":false,"created_utc":1745833451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mpn2xoq","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mpn2xoq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kweglinski","can_mod_post":false,"created_utc":1745925689,"send_replies":true,"parent_id":"t1_mpmwz98","score":1,"author_fullname":"t2_7gw03ro","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"congrats, you've just learned that benchmarks are useless. Spending 10 mins with both is dead giveaway that we're not looking at just 2%.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpn2xoq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;congrats, you&amp;#39;ve just learned that benchmarks are useless. Spending 10 mins with both is dead giveaway that we&amp;#39;re not looking at just 2%.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpn2xoq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745925689,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmwz98","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"created_utc":1745922766,"send_replies":true,"parent_id":"t1_mpmuep8","score":2,"author_fullname":"t2_o5fyioqm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Because 30a3 is still significantly worse than 32b.\\n\\n\\n\\n||Qwen-3-32B|Qwen-3-30B-A3B|A3B expressed in percent of 32B|Difference (%)|\\n|:-|:-|:-|:-|:-|\\n|ArenaHard|93,80|91,00|97,01|2,99|\\n|AIME24|81,40|80,40|98,77|1,23|\\n|AIME25|72,90|70,90|97,26|2,74|\\n|LiveCodeBench|65,70|62,60|95,28|4,72|\\n|CodeForces|1977,00|1974,00|99,85|0,15|\\n|LiveBench|74,90|74,30|99,20|0,80|\\n|BFCL|70,30|69,10|98,29|1,71|\\n|MultilF|73,00|72,20|98,90|1,10|\\n\\n\\n\\nI cannot agree with your assessment. It is on average 1.93 percent worse, while being 6.25 percent smaller in terms of the complete parameter count. It doesn't \\"stand nowhere near 32B\\", especially with the LiveCodeBench, where despite the lower *total* parameter count it is almost identical.","edited":1745924725,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpmwz98","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Because 30a3 is still significantly worse than 32b.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Qwen-3-32B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Qwen-3-30B-A3B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;A3B expressed in percent of 32B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Difference (%)&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;ArenaHard&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;93,80&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;91,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;97,01&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2,99&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;AIME24&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;81,40&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;80,40&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,77&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,23&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;AIME25&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;72,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;70,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;97,26&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2,74&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;LiveCodeBench&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;65,70&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;62,60&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;95,28&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4,72&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;CodeForces&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1977,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1974,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;99,85&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0,15&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;LiveBench&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;74,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;74,30&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;99,20&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0,80&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;BFCL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;70,30&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;69,10&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,29&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,71&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;MultilF&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;73,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;72,20&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,10&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;I cannot agree with your assessment. It is on average 1.93 percent worse, while being 6.25 percent smaller in terms of the complete parameter count. It doesn&amp;#39;t &amp;quot;stand nowhere near 32B&amp;quot;, especially with the LiveCodeBench, where despite the lower &lt;em&gt;total&lt;/em&gt; parameter count it is almost identical.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmwz98/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745922766,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmuep8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kweglinski","can_mod_post":false,"created_utc":1745921317,"send_replies":true,"parent_id":"t1_mpmsov2","score":1,"author_fullname":"t2_7gw03ro","approved_by":null,"mod_note":null,"all_awardings":[],"body":"they didn't provide a paper and there won't be one for sure. To have a paper that you can rely on you'd first need a reliable measurement of model \\"smartness\\" which sadly is missing. Also meaning of rule of thumb says there's no paper. Even LLM asked about what a rule of thumb is says: \\"practical, approximate method for making decisions or solving problems without requiring precise calculations. Itâ€™s often based on experience, tradition, or simplified logic rather than strict scientific analysis. While not always exact, it serves as a helpful shortcut for quick judgment or action.\\"\\n\\nOn the other hand I find it interesting that you find it contrary where many people actually experience exactly that. Including model teams running benchmarks agaist models fitting into this rule of thumb. This rule seems (because it just dropped) to fit even the latest release of qwen. 30a3 stands nowhere near 32b. Scout sligltly beats gemma, not command-a and so on. It also comes with assortment of other issues like where occasionally it punches above the thumb based weight and occasionally it hits below the active params weight if router gets misled.\\n\\nBtw. qwen3 is good explanation. So if 32b hits above qwen2.5 32b (or gemma3 or any other \\"hot\\" model) it is likely that 30a3 will do that as well. But that doesn't break the rule of thumb. Because 30a3 is still significantly worse than 32b. Think of this as a generation change and then apply the thumb on generation.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpmuep8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they didn&amp;#39;t provide a paper and there won&amp;#39;t be one for sure. To have a paper that you can rely on you&amp;#39;d first need a reliable measurement of model &amp;quot;smartness&amp;quot; which sadly is missing. Also meaning of rule of thumb says there&amp;#39;s no paper. Even LLM asked about what a rule of thumb is says: &amp;quot;practical, approximate method for making decisions or solving problems without requiring precise calculations. Itâ€™s often based on experience, tradition, or simplified logic rather than strict scientific analysis. While not always exact, it serves as a helpful shortcut for quick judgment or action.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;On the other hand I find it interesting that you find it contrary where many people actually experience exactly that. Including model teams running benchmarks agaist models fitting into this rule of thumb. This rule seems (because it just dropped) to fit even the latest release of qwen. 30a3 stands nowhere near 32b. Scout sligltly beats gemma, not command-a and so on. It also comes with assortment of other issues like where occasionally it punches above the thumb based weight and occasionally it hits below the active params weight if router gets misled.&lt;/p&gt;\\n\\n&lt;p&gt;Btw. qwen3 is good explanation. So if 32b hits above qwen2.5 32b (or gemma3 or any other &amp;quot;hot&amp;quot; model) it is likely that 30a3 will do that as well. But that doesn&amp;#39;t break the rule of thumb. Because 30a3 is still significantly worse than 32b. Think of this as a generation change and then apply the thumb on generation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmuep8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745921317,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmsov2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpmlugy","score":1,"author_fullname":"t2_o5fyioqm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you point to the paper where they gave this rule of thumb? This rule of thumb currently goes contrary to all of my observations, so I'd rather like to see definitive proof of this. \\"Trust\\" does not cut it for me. (nor should it for anyone, to be perfectly frank)","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpmsov2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you point to the paper where they gave this rule of thumb? This rule of thumb currently goes contrary to all of my observations, so I&amp;#39;d rather like to see definitive proof of this. &amp;quot;Trust&amp;quot; does not cut it for me. (nor should it for anyone, to be perfectly frank)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmsov2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745920293,"author_flair_text":null,"treatment_tags":[],"created_utc":1745920293,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmlugy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kweglinski","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpmgdlw","score":2,"author_fullname":"t2_7gw03ro","approved_by":null,"mod_note":null,"all_awardings":[],"body":"rule of thumb is one thing, then you have standard model capabilities. So llama3 is better than llama2. There's also a case where all stars allign and moe speaks more as if it was all dense.\\n\\nRule of thumb was given by mistral team so I trust them. Also it has proven itself over time.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpmlugy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;rule of thumb is one thing, then you have standard model capabilities. So llama3 is better than llama2. There&amp;#39;s also a case where all stars allign and moe speaks more as if it was all dense.&lt;/p&gt;\\n\\n&lt;p&gt;Rule of thumb was given by mistral team so I trust them. Also it has proven itself over time.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmlugy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745915891,"author_flair_text":null,"treatment_tags":[],"created_utc":1745915891,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmgdlw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgfmrm","score":1,"author_fullname":"t2_o5fyioqm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Everybody keeps using this \\"rule of thumb\\", but I haven't seen one person reference the paper proving this is acceptable. I think it is not, since according to this Deepseek V3 would be a Llama3.3-70B equivalent, which is nonsense.","edited":false,"author_flair_css_class":null,"name":"t1_mpmgdlw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Everybody keeps using this &amp;quot;rule of thumb&amp;quot;, but I haven&amp;#39;t seen one person reference the paper proving this is acceptable. I think it is not, since according to this Deepseek V3 would be a Llama3.3-70B equivalent, which is nonsense.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmgdlw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745912363,"author_flair_text":null,"collapsed":false,"created_utc":1745912363,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfmrm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kweglinski","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgfhsc","score":7,"author_fullname":"t2_7gw03ro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"that's not how MoE works. Rule of thumb is sqrt(params*active). So a 30b 3 active means a bit less than 10b dense model but with blazing speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgfmrm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that&amp;#39;s not how MoE works. Rule of thumb is sqrt(params*active). So a 30b 3 active means a bit less than 10b dense model but with blazing speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfmrm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745832840,"author_flair_text":null,"treatment_tags":[],"created_utc":1745832840,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":1,"name":"t1_mpi9kvm","id":"mpi9kvm","parent_id":"t1_mpgfhsc","depth":3,"children":["mpi9kvm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfhsc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ijwfly","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgf6q9","score":33,"author_fullname":"t2_4orcz67","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It seems to be 3B active params, i think A3B means exactly that.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgfhsc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems to be 3B active params, i think A3B means exactly that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfhsc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745832751,"author_flair_text":null,"treatment_tags":[],"created_utc":1745832751,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpiwbc1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpihtl3","score":3,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"well, if you want to run it strictly on CPU, sure. but for a consumer GPU like a 3060, Your going to get more \\"intelligence\\" by completely filling your VRAM with a dense model rather than a MOE. and on consumer GPU's even with the dense model, you will still get good speeds, so dense is better for consumer GPU's\\n\\nWhen you scale however, the compute becomes a bigger issue than the memory, that's where MOE is more useful. If you are a company that has access to slightly better than your average PC, then MOE is the way to go.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpiwbc1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well, if you want to run it strictly on CPU, sure. but for a consumer GPU like a 3060, Your going to get more &amp;quot;intelligence&amp;quot; by completely filling your VRAM with a dense model rather than a MOE. and on consumer GPU&amp;#39;s even with the dense model, you will still get good speeds, so dense is better for consumer GPU&amp;#39;s&lt;/p&gt;\\n\\n&lt;p&gt;When you scale however, the compute becomes a bigger issue than the memory, that&amp;#39;s where MOE is more useful. If you are a company that has access to slightly better than your average PC, then MOE is the way to go.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiwbc1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745864568,"author_flair_text":null,"treatment_tags":[],"created_utc":1745864568,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpihtl3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noiserr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpib27n","score":6,"author_fullname":"t2_2khn0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"We have Framework Desktop, and Mac Studios. MoE is really the only way to run large models on consumer hardware. Consumer GPUs just don't have enough VRAM.","edited":1745860556,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpihtl3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We have Framework Desktop, and Mac Studios. MoE is really the only way to run large models on consumer hardware. Consumer GPUs just don&amp;#39;t have enough VRAM.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpihtl3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860351,"author_flair_text":null,"treatment_tags":[],"created_utc":1745860351,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mplltm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"asssuber","can_mod_post":false,"created_utc":1745896946,"send_replies":true,"parent_id":"t1_mplkl2c","score":1,"author_fullname":"t2_17eswh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The architecture you are describing is the old one used by Mixtral, not the new one used since DeepSeek V2 where MOE models have a \\"dense core\\" in parallel with traditional routed experts that change for each layer for each token. Maverick even intersperses layers with and w/o MOE.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mplltm0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The architecture you are describing is the old one used by Mixtral, not the new one used since DeepSeek V2 where MOE models have a &amp;quot;dense core&amp;quot; in parallel with traditional routed experts that change for each layer for each token. Maverick even intersperses layers with and w/o MOE.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mplltm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745896946,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mplkl2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1745896488,"send_replies":true,"parent_id":"t1_mpljtvo","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"but the experts used for each token changes for each token, you might be able to get away with not swapping 1 expert for a few tokens assuming you have the most common ones in vram, but if you want to use any other expert, you need to swap.\\n\\nI am not familiar with the paper and I dont have time to read. so sorry abt that, but it does sound interesting","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mplkl2c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;but the experts used for each token changes for each token, you might be able to get away with not swapping 1 expert for a few tokens assuming you have the most common ones in vram, but if you want to use any other expert, you need to swap.&lt;/p&gt;\\n\\n&lt;p&gt;I am not familiar with the paper and I dont have time to read. so sorry abt that, but it does sound interesting&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mplkl2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745896488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpljtvo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"asssuber","can_mod_post":false,"created_utc":1745896206,"send_replies":true,"parent_id":"t1_mpliy01","score":1,"author_fullname":"t2_17eswh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Parameters aren't moving in and out the GPU memory during inference. The GPU has the shared experts + attention/context, the CPU has the rest of sparse experts. It's a variation on DeepkSeek shared experts architecture: https://arxiv.org/abs/2401.06066","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpljtvo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Parameters aren&amp;#39;t moving in and out the GPU memory during inference. The GPU has the shared experts + attention/context, the CPU has the rest of sparse experts. It&amp;#39;s a variation on DeepkSeek shared experts architecture: &lt;a href=\\"https://arxiv.org/abs/2401.06066\\"&gt;https://arxiv.org/abs/2401.06066&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpljtvo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745896206,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpliy01","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpjx9q4","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"huh, how does that even work? you simply can't swap gpu memory that fast.\\n\\nAnyways, the conversation was on gpu inference, still interesting tho","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpliy01","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;huh, how does that even work? you simply can&amp;#39;t swap gpu memory that fast.&lt;/p&gt;\\n\\n&lt;p&gt;Anyways, the conversation was on gpu inference, still interesting tho&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpliy01/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745895872,"author_flair_text":null,"treatment_tags":[],"created_utc":1745895872,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpjx9q4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"asssuber","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpib27n","score":3,"author_fullname":"t2_17eswh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; There's no way to make a personal server to host these models without spending 10-100k, the consumer hardware just doesn't exist\\n\\nThat is a huge hyperbole. Here for example how fast you can run Llama 4 Maverick for under 2k dollars:\\n&gt; Ktransformers on 1x 3090 + 16 core DDR4 Epyc - Q4.5 29 T/s at 3k context Prompt 129 T/s\\n\\n[Source.](https://old.reddit.com/r/LocalLLaMA/comments/1k2li9f/speed_testing_llama_4_maverick_with_various/)\\n\\nIt can also run at not so terrible speeds out of SSDs in a regular gaming computer, as you have less than 3B parameters to fetch from it for each token.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpjx9q4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;There&amp;#39;s no way to make a personal server to host these models without spending 10-100k, the consumer hardware just doesn&amp;#39;t exist&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That is a huge hyperbole. Here for example how fast you can run Llama 4 Maverick for under 2k dollars:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Ktransformers on 1x 3090 + 16 core DDR4 Epyc - Q4.5 29 T/s at 3k context Prompt 129 T/s&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://old.reddit.com/r/LocalLLaMA/comments/1k2li9f/speed_testing_llama_4_maverick_with_various/\\"&gt;Source.&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It can also run at not so terrible speeds out of SSDs in a regular gaming computer, as you have less than 3B parameters to fetch from it for each token.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjx9q4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745875767,"author_flair_text":null,"treatment_tags":[],"created_utc":1745875767,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpib27n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpiaavb","score":2,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, but the kind of hardware needed for shared memory isnt wide spread yet, only really on power optimized laptops or expensive macs.\\n\\nThere's no way to make a personal server to host these models without spending 10-100k, the consumer hardware just doesn't exist","edited":false,"author_flair_css_class":null,"name":"t1_mpib27n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, but the kind of hardware needed for shared memory isnt wide spread yet, only really on power optimized laptops or expensive macs.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s no way to make a personal server to host these models without spending 10-100k, the consumer hardware just doesn&amp;#39;t exist&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpib27n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745858382,"author_flair_text":null,"collapsed":false,"created_utc":1745858382,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpmgyin","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpiaavb","score":2,"author_fullname":"t2_o5fyioqm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not just macs. Any desktop, as well as many laptops where the VRAM is only 8GB or so. For them specifically the 30GB MoE becomes very feasible.","edited":false,"author_flair_css_class":null,"name":"t1_mpmgyin","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not just macs. Any desktop, as well as many laptops where the VRAM is only 8GB or so. For them specifically the 30GB MoE becomes very feasible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmgyin/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745912727,"author_flair_text":null,"collapsed":false,"created_utc":1745912727,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpiaavb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noiserr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph41xw","score":5,"author_fullname":"t2_2khn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Depends. MoE is really good for folks who have Macs or Strix Halo.","edited":1745863101,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpiaavb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends. MoE is really good for folks who have Macs or Strix Halo.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiaavb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745858159,"author_flair_text":null,"treatment_tags":[],"created_utc":1745858159,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpo7cwk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpnhmcd","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"yeah, dense models give more bang for buck with low memory.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpo7cwk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, dense models give more bang for buck with low memory.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpo7cwk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745939628,"author_flair_text":null,"treatment_tags":[],"created_utc":1745939628,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpnhmcd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mplks6t","score":2,"author_fullname":"t2_ehhvb","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's probably a good option if you're in the 8gb VRAM club or below because it's likely better than 7-8B models.   If you have 12-16gb of VRAM then it's competing with the 12b-14b models...and it'd be the best Moe to date if it manages to do much better than a 10b model.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpnhmcd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s probably a good option if you&amp;#39;re in the 8gb VRAM club or below because it&amp;#39;s likely better than 7-8B models.   If you have 12-16gb of VRAM then it&amp;#39;s competing with the 12b-14b models...and it&amp;#39;d be the best Moe to date if it manages to do much better than a 10b model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpnhmcd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745931554,"author_flair_text":null,"treatment_tags":[],"created_utc":1745931554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mplks6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpjolk2","score":2,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i agree, mostly not worth it for GPU.\\n\\nI have herd of some ppl having success with a mix of gpu and cpu, I think they keep the most common experts in gpu, and only swap the less common experts, not entirely sure tho.","edited":false,"author_flair_css_class":null,"name":"t1_mplks6t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i agree, mostly not worth it for GPU.&lt;/p&gt;\\n\\n&lt;p&gt;I have herd of some ppl having success with a mix of gpu and cpu, I think they keep the most common experts in gpu, and only swap the less common experts, not entirely sure tho.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mplks6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745896560,"author_flair_text":null,"collapsed":false,"created_utc":1745896560,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpjolk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph41xw","score":3,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's a great option for CPU, especially at the 3b active size.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpjolk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a great option for CPU, especially at the 3b active size.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjolk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745873073,"author_flair_text":null,"treatment_tags":[],"created_utc":1745873073,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mph41xw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgf6q9","score":4,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think MOE is only really worth it at industrial scale where your not limited by compute rather than vram.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mph41xw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think MOE is only really worth it at industrial scale where your not limited by compute rather than vram.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph41xw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844748,"author_flair_text":null,"treatment_tags":[],"created_utc":1745844748,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgf6q9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1745832552,"send_replies":true,"parent_id":"t1_mpgdv3w","score":35,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nothing to be happy about unless you run cpu-only, 30B MoE is about 10b dense.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgf6q9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nothing to be happy about unless you run cpu-only, 30B MoE is about 10b dense.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgf6q9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745832552,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph7cjb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1745845966,"send_replies":true,"parent_id":"t1_mpgdv3w","score":3,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And they're releasing a Base for us to pretrain? And if there is no 72b... does that mean that they think the MOE is just as good? And ... I'm going to stop speculating and just wait in agony over here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph7cjb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And they&amp;#39;re releasing a Base for us to pretrain? And if there is no 72b... does that mean that they think the MOE is just as good? And ... I&amp;#39;m going to stop speculating and just wait in agony over here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph7cjb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745845966,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdv3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ijwfly","can_mod_post":false,"created_utc":1745831687,"send_replies":true,"parent_id":"t3_1k9qxbl","score":50,"author_fullname":"t2_4orcz67","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3-30B is MoE? Wow!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdv3w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3-30B is MoE? Wow!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdv3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831687,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgw402","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NamelessNobody888","can_mod_post":false,"created_utc":1745841542,"send_replies":true,"parent_id":"t1_mpgh54h","score":2,"author_fullname":"t2_4njd0lnh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That'll work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgw402","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;ll work!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgw402/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841542,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgh54h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1745833795,"send_replies":true,"parent_id":"t3_1k9qxbl","score":25,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\*Checks Bindu's Twitter for details...\\\\* ðŸ¤ª","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgh54h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;*Checks Bindu&amp;#39;s Twitter for details...* ðŸ¤ª&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgh54h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833795,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgprnh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FlyingCC","can_mod_post":false,"created_utc":1745838608,"send_replies":true,"parent_id":"t1_mpgoa0x","score":3,"author_fullname":"t2_f10kj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm waiting, looks close to a well coordinated release if multiple folks are involved!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgprnh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m waiting, looks close to a well coordinated release if multiple folks are involved!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgprnh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745838608,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgoa0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1745837851,"send_replies":true,"parent_id":"t3_1k9qxbl","score":24,"author_fullname":"t2_5wukhd4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can't wait to get Qwen3 Dynamic 2.0 GGUFs running! :)\\n\\nSuper hyped about this release!","edited":1745838808,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgoa0x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can&amp;#39;t wait to get Qwen3 Dynamic 2.0 GGUFs running! :)&lt;/p&gt;\\n\\n&lt;p&gt;Super hyped about this release!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgoa0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837851,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5e607f92-4428-11ee-be78-faa6ca8ae2cf","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgigfp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1745834593,"send_replies":true,"parent_id":"t1_mpgfz0w","score":5,"author_fullname":"t2_qz1qjc86","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://i.redd.it/wz0vzxckujxe1.gif","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgigfp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://i.redd.it/wz0vzxckujxe1.gif\\"&gt;https://i.redd.it/wz0vzxckujxe1.gif&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgigfp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745834593,"media_metadata":{"wz0vzxckujxe1":{"status":"valid","e":"AnimatedImage","m":"image/gif","p":[{"y":97,"x":108,"u":"https://preview.redd.it/wz0vzxckujxe1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=27eb80db0c80d129f0cf1f22957131163b63f6b7"},{"y":195,"x":216,"u":"https://preview.redd.it/wz0vzxckujxe1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=f4d83d4152b9fb476bb0aa8e48abee876e0fd794"},{"y":290,"x":320,"u":"https://preview.redd.it/wz0vzxckujxe1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=1e28733b31985a789fc65e5bb6531923a1918b6c"},{"y":580,"x":640,"u":"https://preview.redd.it/wz0vzxckujxe1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=129beb21fbe2d300b958b9235a8c4211d181fcbd"}],"s":{"y":580,"gif":"https://i.redd.it/wz0vzxckujxe1.gif","mp4":"https://preview.redd.it/wz0vzxckujxe1.gif?format=mp4&amp;s=ebccd9b46b57402700e1c619a7e8dbd00386f42f","x":640},"id":"wz0vzxckujxe1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgusch","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"phenotype001","can_mod_post":false,"created_utc":1745840970,"send_replies":true,"parent_id":"t1_mpgfz0w","score":2,"author_fullname":"t2_agql1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://x.com/JustinLin610/status/1916805525171494965](https://x.com/JustinLin610/status/1916805525171494965)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgusch","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://x.com/JustinLin610/status/1916805525171494965\\"&gt;https://x.com/JustinLin610/status/1916805525171494965&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgusch/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745840970,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfz0w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vaibhavs10","can_mod_post":false,"created_utc":1745833062,"send_replies":true,"parent_id":"t3_1k9qxbl","score":35,"author_fullname":"t2_yg4dl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"All eyes on [hf.co/qwen](http://hf.co/qwen) today! ðŸ”¥","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgfz0w","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Hugging Face Staff"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All eyes on &lt;a href=\\"http://hf.co/qwen\\"&gt;hf.co/qwen&lt;/a&gt; today! ðŸ”¥&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfz0w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833062,"author_flair_text":"Hugging Face Staff","treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#5a74cc","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpge3ly","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1745831843,"send_replies":true,"parent_id":"t3_1k9qxbl","score":11,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this week started strong!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpge3ly","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this week started strong!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpge3ly/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831843,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpj1aix","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahstanin","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgln8p","score":3,"author_fullname":"t2_im30t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is savage, they just spoiled the ðŸ¦™","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpj1aix","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is savage, they just spoiled the ðŸ¦™&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpj1aix/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745866055,"author_flair_text":null,"treatment_tags":[],"created_utc":1745866055,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgln8p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chikengunya","can_mod_post":false,"created_utc":1745836457,"send_replies":true,"parent_id":"t1_mpgct1t","score":18,"author_fullname":"t2_gduow","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"waiting to release it tomorrow right before llamacon","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgln8p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;waiting to release it tomorrow right before llamacon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgln8p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836457,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgct1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1745830985,"send_replies":true,"parent_id":"t3_1k9qxbl","score":17,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems they hid them. Can't see them now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgct1t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems they hid them. Can&amp;#39;t see them now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgct1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745830985,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgs28n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1745839725,"send_replies":true,"parent_id":"t1_mpgl8kx","score":9,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This the one I'm most interested in. It has to be better than maverick and more worth the download. Yea, I'll have to offload some of it, but it's going to be faster than deepseek.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgs28n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This the one I&amp;#39;m most interested in. It has to be better than maverick and more worth the download. Yea, I&amp;#39;ll have to offload some of it, but it&amp;#39;s going to be faster than deepseek.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgs28n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839725,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgs3ya","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpglpx4","score":10,"author_fullname":"t2_2m3au2xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Waiting for them unsloth dynamic quants. ðŸ¤¤","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgs3ya","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Waiting for them unsloth dynamic quants. ðŸ¤¤&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgs3ya/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839747,"author_flair_text":null,"treatment_tags":[],"created_utc":1745839747,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpjoyb9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph2e9c","score":1,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You left out the Epyc Gen2 CPU price....  \\nEdit: I just checked out the used prices and that's not bad","edited":1745873429,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpjoyb9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You left out the Epyc Gen2 CPU price....&lt;br/&gt;\\nEdit: I just checked out the used prices and that&amp;#39;s not bad&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjoyb9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745873178,"author_flair_text":null,"treatment_tags":[],"created_utc":1745873178,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mph2e9c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"un_passant","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpglpx4","score":5,"author_fullname":"t2_7rqtc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ECC DDR4 at 3200 is $100 for a 64GB so it's not crazy to treat your &lt;$500 Epyc Gen2 CPU with enough RAM to run this.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mph2e9c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ECC DDR4 at 3200 is $100 for a 64GB so it&amp;#39;s not crazy to treat your &amp;lt;$500 Epyc Gen2 CPU with enough RAM to run this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph2e9c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844116,"author_flair_text":null,"treatment_tags":[],"created_utc":1745844116,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mph2h14","id":"mph2h14","parent_id":"t1_mpgq2fj","depth":3,"children":["mph2h14"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgq2fj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shing3232","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpglpx4","score":2,"author_fullname":"t2_ze4mg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It should work with ktransformer","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgq2fj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It should work with ktransformer&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgq2fj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745838756,"author_flair_text":null,"treatment_tags":[],"created_utc":1745838756,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpglpx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"created_utc":1745836499,"send_replies":true,"parent_id":"t1_mpgl8kx","score":8,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That would be pretty cool, but probably too big for any of us to run :sigh:","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpglpx4","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would be pretty cool, but probably too big for any of us to run :sigh:&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpglpx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836499,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpih0bc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1745860117,"send_replies":true,"parent_id":"t1_mpgl8kx","score":1,"author_fullname":"t2_guxix","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"two MoEs, one bar","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpih0bc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;two MoEs, one bar&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpih0bc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860117,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgl8kx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mixivivo","can_mod_post":false,"created_utc":1745836227,"send_replies":true,"parent_id":"t3_1k9qxbl","score":23,"author_fullname":"t2_6eqzhefqi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It seems there's a Qwen3-235B-A22B model. I wonder if it's the largest one.\\n\\nhttps://preview.redd.it/sq7rnnsezjxe1.jpeg?width=2966&amp;format=pjpg&amp;auto=webp&amp;s=9520c6a537df5d81d76717d814b20d6f55bd5b2e","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgl8kx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems there&amp;#39;s a Qwen3-235B-A22B model. I wonder if it&amp;#39;s the largest one.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=2966&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9520c6a537df5d81d76717d814b20d6f55bd5b2e\\"&gt;https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=2966&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9520c6a537df5d81d76717d814b20d6f55bd5b2e&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgl8kx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836227,"media_metadata":{"sq7rnnsezjxe1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":44,"x":108,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dace9ee6977110671d35c2c77ae8292b8124b05"},{"y":89,"x":216,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8dce3950c5a0181badd12abd85eeba6526241c42"},{"y":133,"x":320,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec492a0b60462fff07c08521baf679a44c893361"},{"y":266,"x":640,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f55297bf998590d52d57469fbbec3ac6aefaafe4"},{"y":399,"x":960,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7751f5c2041017077a7ae6944539093e05fc9c01"},{"y":449,"x":1080,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05929d91887f1002d640f62722d5f566711a11c4"}],"s":{"y":1234,"x":2966,"u":"https://preview.redd.it/sq7rnnsezjxe1.jpeg?width=2966&amp;format=pjpg&amp;auto=webp&amp;s=9520c6a537df5d81d76717d814b20d6f55bd5b2e"},"id":"sq7rnnsezjxe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgcr2m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Special_System_6627","can_mod_post":false,"created_utc":1745830947,"send_replies":true,"parent_id":"t3_1k9qxbl","score":6,"author_fullname":"t2_w1mitrw3x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Finally yayyyy!Â ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcr2m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Finally yayyyy!Â &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcr2m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745830947,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpggpbf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LamentableLily","can_mod_post":false,"created_utc":1745833522,"send_replies":true,"parent_id":"t3_1k9qxbl","score":6,"author_fullname":"t2_1alm63l5wg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Come back to us, Qwen3! It might as well be Tuesday! ðŸ˜­ Monday's good for a release, too!","edited":1745834119,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpggpbf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Come back to us, Qwen3! It might as well be Tuesday! ðŸ˜­ Monday&amp;#39;s good for a release, too!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpggpbf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833522,"author_flair_text":"Llama 3","treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph3b9s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph1g13","score":1,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Woah, this is weird. Huggingface and Modelscope uploads go up and then vanish.\\n\\nDid someone at Qwen screw up the release?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mph3b9s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Woah, this is weird. Huggingface and Modelscope uploads go up and then vanish.&lt;/p&gt;\\n\\n&lt;p&gt;Did someone at Qwen screw up the release?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph3b9s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844468,"author_flair_text":null,"treatment_tags":[],"created_utc":1745844468,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mph1g13","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Frettam","can_mod_post":false,"created_utc":1745843747,"send_replies":true,"parent_id":"t1_mph0ntw","score":1,"author_fullname":"t2_1jq8hy2uta","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not available now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph1g13","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not available now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph1g13/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843747,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mph0ntw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sammcj","can_mod_post":false,"created_utc":1745843437,"send_replies":true,"parent_id":"t3_1k9qxbl","score":7,"author_fullname":"t2_3mf7o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like they're in the process of uploading the modelsÂ \\n- https://huggingface.co/Qwen/Qwen3-0.6B-FP8/tree/main\\n-Â https://huggingface.co/Qwen/Qwen3-1.7B-FP8/tree/main","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph0ntw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like they&amp;#39;re in the process of uploading the modelsÂ \\n- &lt;a href=\\"https://huggingface.co/Qwen/Qwen3-0.6B-FP8/tree/main\\"&gt;https://huggingface.co/Qwen/Qwen3-0.6B-FP8/tree/main&lt;/a&gt;\\n-Â &lt;a href=\\"https://huggingface.co/Qwen/Qwen3-1.7B-FP8/tree/main\\"&gt;https://huggingface.co/Qwen/Qwen3-1.7B-FP8/tree/main&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph0ntw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843437,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgd9np","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1745831295,"send_replies":true,"parent_id":"t3_1k9qxbl","score":10,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yaaay the return of the 30B model!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgd9np","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yaaay the return of the 30B model!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgd9np/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831295,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":39,"removal_reason":null,"link_id":"t3_1k9qxbl","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphc5dd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgfhyp","score":2,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Haha hope this is real. If so don't worry, it happens to everyone in their career.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mphc5dd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haha hope this is real. If so don&amp;#39;t worry, it happens to everyone in their career.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphc5dd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745847671,"author_flair_text":null,"treatment_tags":[],"created_utc":1745847671,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgfhyp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgdjc7","score":39,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Yeh, my bad. æˆ‘é‡åˆ°å¤§éº»çƒ¦äº† ðŸ˜­","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeh, my bad. æˆ‘é‡åˆ°å¤§éº»çƒ¦äº† ðŸ˜­&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfhyp/","num_reports":null,"locked":false,"name":"t1_mpgfhyp","created":1745832754,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1745832754,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgdjc7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mrleibniz","can_mod_post":false,"created_utc":1745831472,"send_replies":true,"parent_id":"t3_1k9qxbl","score":12,"author_fullname":"t2_43eod","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't know why they hid them? Did an intern mistakenly made them public or something?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgdjc7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t know why they hid them? Did an intern mistakenly made them public or something?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgdjc7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831472,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgkq55","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"usernameplshere","can_mod_post":false,"created_utc":1745835937,"send_replies":true,"parent_id":"t3_1k9qxbl","score":4,"author_fullname":"t2_1zes6cdw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder when or if they release 2.5 Max and QwQ weights. They said something like this months ago.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgkq55","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder when or if they release 2.5 Max and QwQ weights. They said something like this months ago.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgkq55/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745835937,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgcus0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RealKingNish","can_mod_post":false,"created_utc":1745831017,"send_replies":true,"parent_id":"t3_1k9qxbl","score":6,"author_fullname":"t2_u8qbowfxm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not showing now, i guess they hide it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcus0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not showing now, i guess they hide it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcus0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831017,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgfn2g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"reabiter","can_mod_post":false,"created_utc":1745832846,"send_replies":true,"parent_id":"t3_1k9qxbl","score":3,"author_fullname":"t2_1mx8vxa6x1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It must be tonight!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgfn2g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It must be tonight!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgfn2g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745832846,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphsbth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1745852794,"send_replies":true,"parent_id":"t1_mphjt9y","score":11,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think this is what a lot of us are waiting on. A lightspeed 2.5 32B equivalent would be a game changer for us GPU middle class","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mphsbth","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this is what a lot of us are waiting on. A lightspeed 2.5 32B equivalent would be a game changer for us GPU middle class&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphsbth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745852794,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mphjt9y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kep0a","can_mod_post":false,"created_utc":1745850168,"send_replies":true,"parent_id":"t3_1k9qxbl","score":3,"author_fullname":"t2_iid99","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean if the 30b MoE can outperform 2.5 32b at twice the speed I'm happy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mphjt9y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean if the 30b MoE can outperform 2.5 32b at twice the speed I&amp;#39;m happy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphjt9y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745850168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpggd3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sunshinecheung","can_mod_post":false,"created_utc":1745833308,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_u398xzta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wow!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpggd3z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wow!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpggd3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgop1h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emport1","can_mod_post":false,"created_utc":1745838064,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_ubae0chn0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Holy shit it's here, no spoilers plz\\n\\nnvm","edited":1745838343,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgop1h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Holy shit it&amp;#39;s here, no spoilers plz&lt;/p&gt;\\n\\n&lt;p&gt;nvm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgop1h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745838064,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphkwv4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_mph1m7v","score":14,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Easiest explanation - they want to release it all at once but someone at Alibaba doesn't know that you can upload privately, so they're uploading one by one and then quickly clicking over to their other browser tab to set it to private.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mphkwv4","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Easiest explanation - they want to release it all at once but someone at Alibaba doesn&amp;#39;t know that you can upload privately, so they&amp;#39;re uploading one by one and then quickly clicking over to their other browser tab to set it to private.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphkwv4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745850513,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1745850513,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"mph1m7v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"WashWarm8360","can_mod_post":false,"created_utc":1745843814,"send_replies":true,"parent_id":"t1_mph0cip","score":4,"author_fullname":"t2_p2gnozjh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's gone too, what is happening?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph1m7v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s gone too, what is happening?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph1m7v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mph0cip","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WashWarm8360","can_mod_post":false,"created_utc":1745843311,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_p2gnozjh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/lii4aazekkxe1.png?width=1125&amp;format=png&amp;auto=webp&amp;s=44b590b5e0a497f621aae6a94ac3cf4d7b01af73\\n\\nThe first model is available now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph0cip","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/lii4aazekkxe1.png?width=1125&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44b590b5e0a497f621aae6a94ac3cf4d7b01af73\\"&gt;https://preview.redd.it/lii4aazekkxe1.png?width=1125&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=44b590b5e0a497f621aae6a94ac3cf4d7b01af73&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The first model is available now.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph0cip/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843311,"media_metadata":{"lii4aazekkxe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":14,"x":108,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b90236560576f44e1bfc2b3efd232747ccc2fb0f"},{"y":28,"x":216,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2dd7bfb6df2f3e662577b20e38663feccccabc5"},{"y":41,"x":320,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=612b097093d9381e5aebad327d491ae6139983cb"},{"y":83,"x":640,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1199ba51f84528f94c7a75f061e9a25e07c964ef"},{"y":124,"x":960,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aed6e1d4be5e678dbb666cc1efe97c1b35bef62f"},{"y":140,"x":1080,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=002915e68c75ca4a0dfe543213b7965fe9834791"}],"s":{"y":146,"x":1125,"u":"https://preview.redd.it/lii4aazekkxe1.png?width=1125&amp;format=png&amp;auto=webp&amp;s=44b590b5e0a497f621aae6a94ac3cf4d7b01af73"},"id":"lii4aazekkxe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mphrx7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1745852670,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The summoning ritual worked!! Keep at it fellow llama cultists","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mphrx7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The summoning ritual worked!! Keep at it fellow llama cultists&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphrx7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745852670,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mppu7vn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Shronx_","can_mod_post":false,"created_utc":1745956558,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_uxozb0ns","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please wake me up when it's uncensored","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mppu7vn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please wake me up when it&amp;#39;s uncensored&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mppu7vn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745956558,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgcuy5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullstackSensei","can_mod_post":false,"created_utc":1745831020,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_17n3nqtj56","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems they hid them. Can't see them now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgcuy5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems they hid them. Can&amp;#39;t see them now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgcuy5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745831020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mppz02b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Peach-555","can_mod_post":false,"created_utc":1745957918,"send_replies":true,"parent_id":"t1_mpo5abq","score":1,"author_fullname":"t2_dkco6eatd","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I appreciate you putting out all the numbers.\\n\\nThe differences between relative parameter sizes increase the smaller a model is, because of the information constraint.\\n\\nThe general ranking is  \\n235B-22B  \\n32B  \\n30B-3B  \\n4B\\n\\nAs expected from the MoE/dense comparison heuristic.\\n\\nI don't know if I expressed this clearly, but the geometric mean heuristic should be about the ceiling/potential. A 8B model can know more than a 70B model, but the 70B model has a higher potential of knowing than a 8B model.\\n\\nMoE is cheaper to train and run for the same quality of output, meaning a 32B8B model can on average outperforming a 32B dense model in the same family - thought 32B technically have a slightly higher ceiling. I'd expect 32B8B to outperform 32B dense it to if both where constrained on training compute and had the same training budget as the MoE can make more efficient use of same training. Smaller models can outperform bigger models with post-training, even within the same family. 3.3 70B outperforming 3.1 405B as an example.\\n\\nDense models optimize for VRAM amount, MoE optimize for speed/efficiency at the cost of VRAM amount.\\n\\nThe reason why dense models exist at all, despite them being costlier to train on average for the same quality, and being significantly faster/cheaper to run, is because the performance potential per total parameter is lower than the dense model. At least the current architecture.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mppz02b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I appreciate you putting out all the numbers.&lt;/p&gt;\\n\\n&lt;p&gt;The differences between relative parameter sizes increase the smaller a model is, because of the information constraint.&lt;/p&gt;\\n\\n&lt;p&gt;The general ranking is&lt;br/&gt;\\n235B-22B&lt;br/&gt;\\n32B&lt;br/&gt;\\n30B-3B&lt;br/&gt;\\n4B&lt;/p&gt;\\n\\n&lt;p&gt;As expected from the MoE/dense comparison heuristic.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t know if I expressed this clearly, but the geometric mean heuristic should be about the ceiling/potential. A 8B model can know more than a 70B model, but the 70B model has a higher potential of knowing than a 8B model.&lt;/p&gt;\\n\\n&lt;p&gt;MoE is cheaper to train and run for the same quality of output, meaning a 32B8B model can on average outperforming a 32B dense model in the same family - thought 32B technically have a slightly higher ceiling. I&amp;#39;d expect 32B8B to outperform 32B dense it to if both where constrained on training compute and had the same training budget as the MoE can make more efficient use of same training. Smaller models can outperform bigger models with post-training, even within the same family. 3.3 70B outperforming 3.1 405B as an example.&lt;/p&gt;\\n\\n&lt;p&gt;Dense models optimize for VRAM amount, MoE optimize for speed/efficiency at the cost of VRAM amount.&lt;/p&gt;\\n\\n&lt;p&gt;The reason why dense models exist at all, despite them being costlier to train on average for the same quality, and being significantly faster/cheaper to run, is because the performance potential per total parameter is lower than the dense model. At least the current architecture.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mppz02b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745957918,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpo5abq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"created_utc":1745939023,"send_replies":true,"parent_id":"t1_mpntz31","score":1,"author_fullname":"t2_o5fyioqm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"So, let's assume the \\"real\\" model sizes are 9.5, 32 and 72B for the 30, 32 and 235 models respectively.\\n\\nI did two extra tables:\\n\\nhttps://preview.redd.it/umsqk6hlgsxe1.png?width=897&amp;format=png&amp;auto=webp&amp;s=5a42d85ee250464a511d94ddf36d537238ad4f68\\n\\nAverage difference being 5.46% and 11,39% between the 235 and the 32B respectively.\\n\\nSo we have a progression of\\n\\n11.39 : 1.93 : 5.46 (Scores, relative to the previous one)\\n\\n  \\n2.375 : 3.368 : 2.25 (Effective model sizes, assuming the thumb rule holds)\\n\\nÂ \\n\\n7.5 : 1.06 : 7.34 (Model sizes, assuming dense and sparse models are equivalent)\\n\\nÂ \\n\\nAs it seems to me, the effective increase of 3.368 netting by far the lowest result would seem very questionable when doubling the model size just before and after netted 11.39 and 5.46 percent. Sparse models will be less effective, but not equivalent to a model 3 times smaller. Maybe a model 85% of the size.\\n\\nWe need the benchmarks for 14B. If it really is better than the 30B, well, I guess I'm wrong then, but I do not expect to be wrong. Data is still being approximated by a greater number of parameters, and the model *will know* *more*, however instead of making conclusions on all of said data, it is forced to use only what is most relevant within its \\"memory\\".","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpo5abq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So, let&amp;#39;s assume the &amp;quot;real&amp;quot; model sizes are 9.5, 32 and 72B for the 30, 32 and 235 models respectively.&lt;/p&gt;\\n\\n&lt;p&gt;I did two extra tables:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/umsqk6hlgsxe1.png?width=897&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a42d85ee250464a511d94ddf36d537238ad4f68\\"&gt;https://preview.redd.it/umsqk6hlgsxe1.png?width=897&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a42d85ee250464a511d94ddf36d537238ad4f68&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Average difference being 5.46% and 11,39% between the 235 and the 32B respectively.&lt;/p&gt;\\n\\n&lt;p&gt;So we have a progression of&lt;/p&gt;\\n\\n&lt;p&gt;11.39 : 1.93 : 5.46 (Scores, relative to the previous one)&lt;/p&gt;\\n\\n&lt;p&gt;2.375 : 3.368 : 2.25 (Effective model sizes, assuming the thumb rule holds)&lt;/p&gt;\\n\\n&lt;p&gt;Â &lt;/p&gt;\\n\\n&lt;p&gt;7.5 : 1.06 : 7.34 (Model sizes, assuming dense and sparse models are equivalent)&lt;/p&gt;\\n\\n&lt;p&gt;Â &lt;/p&gt;\\n\\n&lt;p&gt;As it seems to me, the effective increase of 3.368 netting by far the lowest result would seem very questionable when doubling the model size just before and after netted 11.39 and 5.46 percent. Sparse models will be less effective, but not equivalent to a model 3 times smaller. Maybe a model 85% of the size.&lt;/p&gt;\\n\\n&lt;p&gt;We need the benchmarks for 14B. If it really is better than the 30B, well, I guess I&amp;#39;m wrong then, but I do not expect to be wrong. Data is still being approximated by a greater number of parameters, and the model &lt;em&gt;will know&lt;/em&gt; &lt;em&gt;more&lt;/em&gt;, however instead of making conclusions on all of said data, it is forced to use only what is most relevant within its &amp;quot;memory&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpo5abq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745939023,"media_metadata":{"umsqk6hlgsxe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":70,"x":108,"u":"https://preview.redd.it/umsqk6hlgsxe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=38739bc4a8ec31bd52ae6219904cf082fd75202b"},{"y":141,"x":216,"u":"https://preview.redd.it/umsqk6hlgsxe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=908fae4d91686d5990caea5bf6cbff859b346b7f"},{"y":209,"x":320,"u":"https://preview.redd.it/umsqk6hlgsxe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3065b41a5d532634af08101e7df3f8f6a3663462"},{"y":418,"x":640,"u":"https://preview.redd.it/umsqk6hlgsxe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c19a758307a1fd6b6173296e3cb2892dd2ab62d7"}],"s":{"y":587,"x":897,"u":"https://preview.redd.it/umsqk6hlgsxe1.png?width=897&amp;format=png&amp;auto=webp&amp;s=5a42d85ee250464a511d94ddf36d537238ad4f68"},"id":"umsqk6hlgsxe1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpntz31","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Peach-555","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpmy8dv","score":1,"author_fullname":"t2_dkco6eatd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Summary: The rule of thumb that the MoE in the same model family is weaker per total perimeter, but stronger per active perimeter, holds true fro the Qwen family.  \\n  \\nPerfect timing. Lets look into it. I think it almost perfectly fits the rule.\\n\\n235B-22B (\\\\~70B dens) compared to 32B dense.  \\nThe MoE generally outperforms the 32B dense model by the type of margin you would expect from a 70B model compared to the same model 32B model. The MoE is stronger per active parameter, but weaker per total parameter, as expected.  \\nThe 30B3B \\\\~9.5B dens is weaker than 32GB but significantly stronger than 4B dense, also fitting with the general pattern.\\n\\nAs you probably already know, a model in the same family that is twice the size in parameter, generally only differ by a small, in terms of percentages, margin. Look at 3.1 LLAMA for comparison, 70B compared to 405B. That is a model with 5.8 times more parameters having slightly being within a couple percentages of the smaller model in many of the benchmarks.\\n\\nThe difference should be more pronounced at lower model sizes where the information stored starts to get more constrained. 32B is large enough to where a model that is 70B should not be in a different class, some percentage difference is what you'd expect, especially towards the top end of percentages, a 97% model is significantly stronger than a 94% model, it has half the errors, and the remaining 3% it gets right is likely harder.\\n\\nhttps://preview.redd.it/4u8ff24w5sxe1.jpeg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=e7fe952cbc74b7245a9983b5c64ae50fdbb86e56","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpntz31","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Summary: The rule of thumb that the MoE in the same model family is weaker per total perimeter, but stronger per active perimeter, holds true fro the Qwen family.  &lt;/p&gt;\\n\\n&lt;p&gt;Perfect timing. Lets look into it. I think it almost perfectly fits the rule.&lt;/p&gt;\\n\\n&lt;p&gt;235B-22B (~70B dens) compared to 32B dense.&lt;br/&gt;\\nThe MoE generally outperforms the 32B dense model by the type of margin you would expect from a 70B model compared to the same model 32B model. The MoE is stronger per active parameter, but weaker per total parameter, as expected.&lt;br/&gt;\\nThe 30B3B ~9.5B dens is weaker than 32GB but significantly stronger than 4B dense, also fitting with the general pattern.&lt;/p&gt;\\n\\n&lt;p&gt;As you probably already know, a model in the same family that is twice the size in parameter, generally only differ by a small, in terms of percentages, margin. Look at 3.1 LLAMA for comparison, 70B compared to 405B. That is a model with 5.8 times more parameters having slightly being within a couple percentages of the smaller model in many of the benchmarks.&lt;/p&gt;\\n\\n&lt;p&gt;The difference should be more pronounced at lower model sizes where the information stored starts to get more constrained. 32B is large enough to where a model that is 70B should not be in a different class, some percentage difference is what you&amp;#39;d expect, especially towards the top end of percentages, a 97% model is significantly stronger than a 94% model, it has half the errors, and the remaining 3% it gets right is likely harder.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7fe952cbc74b7245a9983b5c64ae50fdbb86e56\\"&gt;https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7fe952cbc74b7245a9983b5c64ae50fdbb86e56&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpntz31/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745935648,"media_metadata":{"4u8ff24w5sxe1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":83,"x":108,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e6d1a4846952edfa08666a6dfeeeec962d76532"},{"y":167,"x":216,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae33488848ac934f14aad80a1e6be9e945de3419"},{"y":248,"x":320,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2fac3224bc56b45de3503d9c67f86502fb1ce5c9"},{"y":496,"x":640,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77baddae2cc64feb149cdc59a77e1ef0a1c6cbe4"},{"y":744,"x":960,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f30e6928882d7401674e7815e7abe831a6612209"},{"y":838,"x":1080,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dae0e69a8ea99eaeed6faa8bda96aec17d6fd544"}],"s":{"y":838,"x":1080,"u":"https://preview.redd.it/4u8ff24w5sxe1.jpeg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=e7fe952cbc74b7245a9983b5c64ae50fdbb86e56"},"id":"4u8ff24w5sxe1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1745935648,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmy8dv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpmmkgb","score":1,"author_fullname":"t2_o5fyioqm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, the recent Qwen-3 release seems to suggest otherwise. I did a table for another guy on the benchmarks that can be compared:\\n\\n||Qwen-3-32B|Qwen-3-30B-A3B|A3B expressed in percent of 32B|Difference (%)|\\n|:-|:-|:-|:-|:-|\\n|ArenaHard|93,80|91,00|97,01|2,99|\\n|AIME24|81,40|80,40|98,77|1,23|\\n|AIME25|72,90|70,90|97,26|2,74|\\n|LiveCodeBench|65,70|62,60|95,28|4,72|\\n|CodeForces|1977,00|1974,00|99,85|0,15|\\n|LiveBench|74,90|74,30|99,20|0,80|\\n|BFCL|70,30|69,10|98,29|1,71|\\n|MultilF|73,00|72,20|98,90|1,10|\\n\\nThe 30B MoE is 1.93% worse on average, despite having 6.25% fewer parameters. It *does not* appear to function like a 9.5B model. Of course, the proper test to falsify the rule of thumb would be against the 14B, which unfortunately is not mentioned, but would allow to verify or contradict it, as by said \\"rule of thumb\\" it should be better.\\n\\n&gt;Its not like a law, its an estimation, a heuristic, a rule of thumb.Â \\n\\nSure, whatever, but if people are citing it left and right, we should verify that it indeed is accurate to at least +-10% or so, instead of blindly using it.","edited":1745924611,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpmy8dv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, the recent Qwen-3 release seems to suggest otherwise. I did a table for another guy on the benchmarks that can be compared:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Qwen-3-32B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Qwen-3-30B-A3B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;A3B expressed in percent of 32B&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Difference (%)&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;ArenaHard&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;93,80&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;91,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;97,01&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2,99&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;AIME24&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;81,40&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;80,40&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,77&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,23&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;AIME25&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;72,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;70,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;97,26&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2,74&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;LiveCodeBench&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;65,70&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;62,60&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;95,28&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4,72&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;CodeForces&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1977,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1974,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;99,85&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0,15&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;LiveBench&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;74,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;74,30&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;99,20&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;0,80&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;BFCL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;70,30&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;69,10&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,29&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,71&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;MultilF&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;73,00&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;72,20&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;98,90&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;1,10&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;The 30B MoE is 1.93% worse on average, despite having 6.25% fewer parameters. It &lt;em&gt;does not&lt;/em&gt; appear to function like a 9.5B model. Of course, the proper test to falsify the rule of thumb would be against the 14B, which unfortunately is not mentioned, but would allow to verify or contradict it, as by said &amp;quot;rule of thumb&amp;quot; it should be better.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Its not like a law, its an estimation, a heuristic, a rule of thumb.Â &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Sure, whatever, but if people are citing it left and right, we should verify that it indeed is accurate to at least +-10% or so, instead of blindly using it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmy8dv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745923427,"author_flair_text":null,"treatment_tags":[],"created_utc":1745923427,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmmkgb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Peach-555","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpmhb8y","score":1,"author_fullname":"t2_dkco6eatd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"DeepseekV3 MoE is not a Llama70B equivalent  \\nDeepseekV3 Moe is a DeekseekV3 dense equivalent\\n\\nI know I seen the research before, but I don't have it on hand, where the approximation of the ceiling of performance between the dense and mixture of expert model is the geometric mean between the total and active parameters.\\n\\nAt at purely intuitive level, this makes sense, the potential performance per total parameter is lower for a mixture of expert model, but it is higher per active parameter, this is the trade-off. A MoE model with 100B total and 50B active parameters, would probably fall in the 70B range. While a 100B total and 1B active parameters model would be closer to 10B.\\n\\nIts not like a law, its an estimation, a heuristic, a rule of thumb. The trade-off is that MoE has lower training costs for the same level of performance, lower active parameters for the same level of performance, and total parameters for the same level of performance.\\n\\nIn other words, MoE is optimizing for compute efficiency, dense models are optimizing for memory efficiency, and the trade-off between compute and memory, for the same level of performance, is somewhere between the passive and active parameter count.","edited":1745916555,"author_flair_css_class":null,"name":"t1_mpmmkgb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DeepseekV3 MoE is not a Llama70B equivalent&lt;br/&gt;\\nDeepseekV3 Moe is a DeekseekV3 dense equivalent&lt;/p&gt;\\n\\n&lt;p&gt;I know I seen the research before, but I don&amp;#39;t have it on hand, where the approximation of the ceiling of performance between the dense and mixture of expert model is the geometric mean between the total and active parameters.&lt;/p&gt;\\n\\n&lt;p&gt;At at purely intuitive level, this makes sense, the potential performance per total parameter is lower for a mixture of expert model, but it is higher per active parameter, this is the trade-off. A MoE model with 100B total and 50B active parameters, would probably fall in the 70B range. While a 100B total and 1B active parameters model would be closer to 10B.&lt;/p&gt;\\n\\n&lt;p&gt;Its not like a law, its an estimation, a heuristic, a rule of thumb. The trade-off is that MoE has lower training costs for the same level of performance, lower active parameters for the same level of performance, and total parameters for the same level of performance.&lt;/p&gt;\\n\\n&lt;p&gt;In other words, MoE is optimizing for compute efficiency, dense models are optimizing for memory efficiency, and the trade-off between compute and memory, for the same level of performance, is somewhere between the passive and active parameter count.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmmkgb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745916363,"author_flair_text":null,"collapsed":false,"created_utc":1745916363,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpmhb8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alamacra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpglbj1","score":1,"author_fullname":"t2_o5fyioqm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"According to this DeepseekV3 is basically a Llama70B equivalent, and Mistral Large should be measurably worse than it. This is not the case.\\n\\nWhere does this \\"rule of thumb\\" come from? Any papers you can reference?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpmhb8y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;According to this DeepseekV3 is basically a Llama70B equivalent, and Mistral Large should be measurably worse than it. This is not the case.&lt;/p&gt;\\n\\n&lt;p&gt;Where does this &amp;quot;rule of thumb&amp;quot; come from? Any papers you can reference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpmhb8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745912955,"author_flair_text":null,"treatment_tags":[],"created_utc":1745912955,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpglbj1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Peach-555","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpggxle","score":8,"author_fullname":"t2_dkco6eatd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the spirit of the statement that MoE being weaker than dense models for a given parameter size is true, however, its not that much weaker depending on the active parameter size. Its also much more expensive/slow to train and/or use the model.\\n\\nDeepseek-R1 685B-37B would theoretically be comparable to a dense Deepseek 159B, sqrt(685x37).  \\nMaverick 400B-17B would theoretically be sqrt(400x17) 82B, which roughly matches the llama 3.3 70B.  \\nQwen3 30B-3B squrt(30\\\\*3) \\\\~9B","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpglbj1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the spirit of the statement that MoE being weaker than dense models for a given parameter size is true, however, its not that much weaker depending on the active parameter size. Its also much more expensive/slow to train and/or use the model.&lt;/p&gt;\\n\\n&lt;p&gt;Deepseek-R1 685B-37B would theoretically be comparable to a dense Deepseek 159B, sqrt(685x37).&lt;br/&gt;\\nMaverick 400B-17B would theoretically be sqrt(400x17) 82B, which roughly matches the llama 3.3 70B.&lt;br/&gt;\\nQwen3 30B-3B squrt(30*3) ~9B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpglbj1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836272,"author_flair_text":null,"treatment_tags":[],"created_utc":1745836272,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpj8u09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpiw9oz","score":1,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma does surprisingly well. Benchmarks posted showing similar or even better results from not thinking are kind of telling though. COT has always been hit or miss, just the hype train took off.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mpj8u09","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma does surprisingly well. Benchmarks posted showing similar or even better results from not thinking are kind of telling though. COT has always been hit or miss, just the hype train took off.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpj8u09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745868329,"author_flair_text":null,"treatment_tags":[],"created_utc":1745868329,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpiw9oz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpij2iu","score":2,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well yeah they'll try to follow any pattern, but none below 30B seem to actually figure anything out and mostly just gaslight themselves into oblivion, especially without RL training.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mpiw9oz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well yeah they&amp;#39;ll try to follow any pattern, but none below 30B seem to actually figure anything out and mostly just gaslight themselves into oblivion, especially without RL training.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiw9oz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745864554,"author_flair_text":null,"treatment_tags":[],"created_utc":1745864554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpij2iu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpiai8a","score":1,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"AFAIK, they all can think if you prefill, if not on their own.","edited":false,"author_flair_css_class":null,"name":"t1_mpij2iu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AFAIK, they all can think if you prefill, if not on their own.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1k9qxbl","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpij2iu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860715,"author_flair_text":null,"collapsed":false,"created_utc":1745860715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpiai8a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgrcaz","score":2,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What would be really interesting would be a QwQ based on it, since the speed of a 3B would really help with the long think and it could make up for some of its sparsity, especially as 30B seems to be the current minimum for models that can do decent reasoning.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpiai8a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What would be really interesting would be a QwQ based on it, since the speed of a 3B would really help with the long think and it could make up for some of its sparsity, especially as 30B seems to be the current minimum for models that can do decent reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiai8a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745858219,"author_flair_text":null,"treatment_tags":[],"created_utc":1745858219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgrcaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpggxle","score":5,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The \\"ton more to it\\" is literally how well they trained it.\\n\\nIf models were plastic surgery, around 30b is where they start to \\"pass\\". Deepseek has a high enough active param count, a ~160b dense equivalent and great training data. The formula for success.\\n\\nllama-405b and nvidia's model are not *bad* either. They aren't being dragged by architecture. Comes down to how they cooked based on what's in them.\\n\\nNow this 3b active... I think even meme-marks will show where it lands, and open ended conversation surely will. Neither the equivalence metric nor the active count reach the level which makes the nose job look \\"real\\". Super interested to *look* and confirm or deny my numerical suspicions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpgrcaz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The &amp;quot;ton more to it&amp;quot; is literally how well they trained it.&lt;/p&gt;\\n\\n&lt;p&gt;If models were plastic surgery, around 30b is where they start to &amp;quot;pass&amp;quot;. Deepseek has a high enough active param count, a ~160b dense equivalent and great training data. The formula for success.&lt;/p&gt;\\n\\n&lt;p&gt;llama-405b and nvidia&amp;#39;s model are not &lt;em&gt;bad&lt;/em&gt; either. They aren&amp;#39;t being dragged by architecture. Comes down to how they cooked based on what&amp;#39;s in them.&lt;/p&gt;\\n\\n&lt;p&gt;Now this 3b active... I think even meme-marks will show where it lands, and open ended conversation surely will. Neither the equivalence metric nor the active count reach the level which makes the nose job look &amp;quot;real&amp;quot;. Super interested to &lt;em&gt;look&lt;/em&gt; and confirm or deny my numerical suspicions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgrcaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839377,"author_flair_text":null,"treatment_tags":[],"created_utc":1745839377,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":5,"name":"t1_mpghqda","id":"mpghqda","parent_id":"t1_mpggxle","depth":2,"children":["mpghqda"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mpggxle","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Different_Fix_2217","can_mod_post":false,"created_utc":1745833666,"send_replies":true,"parent_id":"t1_mpggnco","score":20,"author_fullname":"t2_4dhrrvi6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt;always weaker than dense models\\n\\nThere's a ton more to it than that. Deepseek performs far better than llama 405B (and nvidia's further trained and distilled 253B version of it) for instance and its 37B active 685B total. And you can find 30B models trading blows in more specialized domains with cloud models. Getting that level of performance plus the raw extra general knowledge to generalize from that more params gives you can be big. More params = less 'lossy' model. Number of active parms is surely a diminishing returns thing.","edited":1745834613,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpggxle","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt;always weaker than dense models&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s a ton more to it than that. Deepseek performs far better than llama 405B (and nvidia&amp;#39;s further trained and distilled 253B version of it) for instance and its 37B active 685B total. And you can find 30B models trading blows in more specialized domains with cloud models. Getting that level of performance plus the raw extra general knowledge to generalize from that more params gives you can be big. More params = less &amp;#39;lossy&amp;#39; model. Number of active parms is surely a diminishing returns thing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpggxle/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833666,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgil47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gpupoor","can_mod_post":false,"created_utc":1745834673,"send_replies":true,"parent_id":"t1_mpggnco","score":1,"author_fullname":"t2_1hcyral852","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":".....your rule makes no sense.Â Rule of thumb is sqrt(params*active). So a 30b 3 active means a bit less than 10b dense but with blazing speed.\\n\\n\\ndeepseek v3's dense equivalent for example is like 160-180B.\\n\\n\\nand even this isnt fully accurate IIRC.\\n\\n\\nso yeah, you've written this comment with the assumption that it could beat 32B but unless qwen3 is magic, it will at most come somewhat close to them.\\n\\n\\nif you dont like the MoE model, don't use it. it's not the replacement for dense 32B, so you don't need to worry about it.\\n\\n\\nfor many with enough vram to use it, it could easily replace all 10-8B or less dense models.","edited":1745850729,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgil47","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;.....your rule makes no sense.Â Rule of thumb is sqrt(params*active). So a 30b 3 active means a bit less than 10b dense but with blazing speed.&lt;/p&gt;\\n\\n&lt;p&gt;deepseek v3&amp;#39;s dense equivalent for example is like 160-180B.&lt;/p&gt;\\n\\n&lt;p&gt;and even this isnt fully accurate IIRC.&lt;/p&gt;\\n\\n&lt;p&gt;so yeah, you&amp;#39;ve written this comment with the assumption that it could beat 32B but unless qwen3 is magic, it will at most come somewhat close to them.&lt;/p&gt;\\n\\n&lt;p&gt;if you dont like the MoE model, don&amp;#39;t use it. it&amp;#39;s not the replacement for dense 32B, so you don&amp;#39;t need to worry about it.&lt;/p&gt;\\n\\n&lt;p&gt;for many with enough vram to use it, it could easily replace all 10-8B or less dense models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgil47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745834673,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpggnco","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1745833488,"send_replies":true,"parent_id":"t3_1k9qxbl","score":7,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have mixed feelings about this Qwen3-30B-A3B. So, it's a 30B model. Great. However, it's a MoE, which is always weaker than dense models, right? Because while it's a relatively big model, its active parameters are actually what determines quality of its output overall and in this case there are just 3B active parameters. That's not too much, is it? I believe that MoEs deliver about a half of the quality of a dense model of the same size, so this 30B with 3B active parameters is probably like a 15B dense model in quality.\\n\\nSure its inference speed will most likely be faster than regular dense 32B model which is great, but what about the quality of the output? Each new generation should outperform the last one and I'm just not sure if this model can outperform models like Qwen-2.5-32B or QwQ-32B.\\n\\nDon't get me wrong, if they somehow managed to make it match the QwQ-32B (but faster due to it being MoE model), I think that would be still a win for everyone, because it would allow models of QwQ-32B quality to run on weaker hardware. I guess we will just have to wait and see. ðŸ¤·â€â™‚ï¸","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpggnco","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have mixed feelings about this Qwen3-30B-A3B. So, it&amp;#39;s a 30B model. Great. However, it&amp;#39;s a MoE, which is always weaker than dense models, right? Because while it&amp;#39;s a relatively big model, its active parameters are actually what determines quality of its output overall and in this case there are just 3B active parameters. That&amp;#39;s not too much, is it? I believe that MoEs deliver about a half of the quality of a dense model of the same size, so this 30B with 3B active parameters is probably like a 15B dense model in quality.&lt;/p&gt;\\n\\n&lt;p&gt;Sure its inference speed will most likely be faster than regular dense 32B model which is great, but what about the quality of the output? Each new generation should outperform the last one and I&amp;#39;m just not sure if this model can outperform models like Qwen-2.5-32B or QwQ-32B.&lt;/p&gt;\\n\\n&lt;p&gt;Don&amp;#39;t get me wrong, if they somehow managed to make it match the QwQ-32B (but faster due to it being MoE model), I think that would be still a win for everyone, because it would allow models of QwQ-32B quality to run on weaker hardware. I guess we will just have to wait and see. ðŸ¤·â€â™‚ï¸&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpggnco/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpglsun","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"truth_offmychest","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgl82n","score":4,"author_fullname":"t2_1e8945t8da","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"they will probably release it this week though\\n\\nI can wait....","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpglsun","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they will probably release it this week though&lt;/p&gt;\\n\\n&lt;p&gt;I can wait....&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpglsun/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836546,"author_flair_text":null,"treatment_tags":[],"created_utc":1745836546,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgl82n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yami_no_ko","can_mod_post":false,"created_utc":1745836219,"send_replies":true,"parent_id":"t1_mpgkkm6","score":2,"author_fullname":"t2_30y9lbr0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Already disappeared again.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgl82n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Already disappeared again.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgl82n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836219,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgkkm6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"truth_offmychest","can_mod_post":false,"created_utc":1745835851,"send_replies":true,"parent_id":"t3_1k9qxbl","score":3,"author_fullname":"t2_1e8945t8da","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Holy shit, dude. We eating good tonight.\\n\\nLet's Gooooooooo","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgkkm6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Holy shit, dude. We eating good tonight.&lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s Gooooooooo&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgkkm6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745835851,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgmhut","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OkActive3404","can_mod_post":false,"created_utc":1745836922,"send_replies":true,"parent_id":"t3_1k9qxbl","score":2,"author_fullname":"t2_1i6g5eg2gd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"YESSS FINALLY NEW QWEN MODELS","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgmhut","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;YESSS FINALLY NEW QWEN MODELS&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgmhut/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745836922,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgx7qx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"geoffwolf98","can_mod_post":false,"created_utc":1745842018,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_mjln2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen will it be famous?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgx7qx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen will it be famous?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgx7qx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745842018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph0e4w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"avatarOfIndifference","can_mod_post":false,"created_utc":1745843329,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_2w2e9q6p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fave gspro course","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph0e4w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fave gspro course&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph0e4w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745843329,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mph2rlz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheLieAndTruth","can_mod_post":false,"created_utc":1745844260,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_17atz7rs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen when? ðŸ˜…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mph2rlz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen when? ðŸ˜…&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mph2rlz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745844260,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpi3vvp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Firm-Development1953","can_mod_post":false,"created_utc":1745856242,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_168r0fft40","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not available now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpi3vvp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not available now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpi3vvp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745856242,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpidgoh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IngwiePhoenix","can_mod_post":false,"created_utc":1745859085,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_2c8xodlx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Neat! So now I just wait for it to pop up somewhere, where ollama can pull it from. o.o\\n\\nI do hope to see some higher ctx models though; Cline really destroys context windows... x.x","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpidgoh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Neat! So now I just wait for it to pop up somewhere, where ollama can pull it from. o.o&lt;/p&gt;\\n\\n&lt;p&gt;I do hope to see some higher ctx models though; Cline really destroys context windows... x.x&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpidgoh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745859085,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpihqgb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bguberfain","can_mod_post":false,"created_utc":1745860326,"send_replies":true,"parent_id":"t1_mpigmy4","score":2,"author_fullname":"t2_urnu0n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It points to a \\"qwen-research\\" license. Seems to be a non-commercial model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpihqgb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It points to a &amp;quot;qwen-research&amp;quot; license. Seems to be a non-commercial model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpihqgb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860326,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mpigmy4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bguberfain","can_mod_post":false,"created_utc":1745860004,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_urnu0n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Real or fake? [https://huggingface.co/second-state/Qwen3-32B-GGUF](https://huggingface.co/second-state/Qwen3-32B-GGUF)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpigmy4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Real or fake? &lt;a href=\\"https://huggingface.co/second-state/Qwen3-32B-GGUF\\"&gt;https://huggingface.co/second-state/Qwen3-32B-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpigmy4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745860004,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpiowb8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"letsgeditmedia","can_mod_post":false,"created_utc":1745862389,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_7cjlpcpk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"36 trillion tokens Jesus f","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpiowb8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;36 trillion tokens Jesus f&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiowb8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745862389,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1k9qxbl","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpiszhr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"My man!!!","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My man!!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpiszhr/","num_reports":null,"locked":false,"name":"t1_mpiszhr","created":1745863574,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1745863574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpjsu38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thrumpwart","can_mod_post":false,"created_utc":1745874360,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_iol3buybk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[Woohoo!](https://i.imgur.com/c5Z1CsP.png)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpjsu38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://i.imgur.com/c5Z1CsP.png\\"&gt;Woohoo!&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjsu38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745874360,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mq3syj8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FunJumpy9129","can_mod_post":false,"created_utc":1746141305,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_1edfrbmpbu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you think we have further space to improve model in the next coming 3-5 years?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mq3syj8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you think we have further space to improve model in the next coming 3-5 years?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mq3syj8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1746141305,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpgqwm7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xignaceh","can_mod_post":false,"created_utc":1745839163,"send_replies":true,"parent_id":"t1_mpggxhu","score":12,"author_fullname":"t2_7ec9wuz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's what she said","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgqwm7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s what she said&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgqwm7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745839163,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1k9qxbl","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpi6wrb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stoppableDissolution","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphoznd","score":3,"author_fullname":"t2_1n0su21k4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its not about knowledge, its about long context patterns. I want my models to stay coherent past 15k. And while you can RAG knowledge, you cant RAG complex behaviors, the size is still important here. I really hoped for some 40-50b dense, but alas. \\n\\nAlso, that \\"30b\\" is not, in fact, 30b, its, best case, 12b in a trenchcoat (because MoE), and probably closer to 10b. Which is, imo, kinda pointless, because at that point you might as well just use 14b dense they are also rolling out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpi6wrb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its not about knowledge, its about long context patterns. I want my models to stay coherent past 15k. And while you can RAG knowledge, you cant RAG complex behaviors, the size is still important here. I really hoped for some 40-50b dense, but alas. &lt;/p&gt;\\n\\n&lt;p&gt;Also, that &amp;quot;30b&amp;quot; is not, in fact, 30b, its, best case, 12b in a trenchcoat (because MoE), and probably closer to 10b. Which is, imo, kinda pointless, because at that point you might as well just use 14b dense they are also rolling out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpi6wrb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745857153,"author_flair_text":null,"treatment_tags":[],"created_utc":1745857153,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_mpi14ac","id":"mpi14ac","parent_id":"t1_mphytfl","depth":4,"children":["mpi14ac"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mphytfl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphoznd","score":2,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;and the only requirement now is that the model in question should be good at instruction following and smart enough to do exactly what it's RAG-ed to do, including tool use.\\n\\nNo, 90%+ context recall is priority #1 for RAG.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mphytfl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;and the only requirement now is that the model in question should be good at instruction following and smart enough to do exactly what it&amp;#39;s RAG-ed to do, including tool use.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;No, 90%+ context recall is priority #1 for RAG.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphytfl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745854743,"author_flair_text":null,"treatment_tags":[],"created_utc":1745854743,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpj9sx9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bakoro","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphoznd","score":2,"author_fullname":"t2_7fz62","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;As much as big home GPU bros want model sizes to go up to justify their purchase, the future of language models is local, open-source, and &lt;32b params. \\n    \\nThe future is in cheaper, more specialized hardware.  \\nASICs for inference are going to be the way to go. They'll be expensive at first, and get cheaper with scale. There are already several companies with tangible products in this area. A company like Cerebras will go after the top end of the market, and several other companies will compete for the mid and lower tiers.  \\n     \\nGPUs were an effective way to do proof of concept and bridge the gap to the future ways of doing things, but they can't be the end point.  \\n \\n&gt;This is because 1) the companies are getting better at training so less is becoming more, and 2) the publishers and users of these models are slowly figuring out that nobody needs \\"all human knowledge\\" in one model because nobody ever works with or really needs all human knowledge when they work or do something. \\n   \\nI'd agree that there is likely a lot more we can be doing at the training stage to improve models, but I don't think we can just ignore the power of scaling. All the evidence and all the theory supports that when using the same techniques, bigger ends up being better, substantially better at first and eventually hitting a point diminishing returns.  \\n    \\nI don't think that stops with parameter size, a broader and deeper training set improves the model's cognitive abilities. Data which is seemingly unrelated to the thing you're doing, may very well be a benefit because it helps generalization.  \\n    \\nEven if a smaller model can muddle along through arbitrary tasks with the help of external tools, it's not going to be as good or fast as a larger model.  \\nA model not trained in a field and only using RAG is not going to be as good as a model trained trained in a field which is also using RAG.   \\nRAG also assumes that you have a sufficient set of quality resources to cite. \\nA business might have that, most people won't. \\n    \\nI'd much rather have a larger model which is excessive for my needs than a smaller model which kinda-sorta works good enough.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpj9sx9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;As much as big home GPU bros want model sizes to go up to justify their purchase, the future of language models is local, open-source, and &amp;lt;32b params. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The future is in cheaper, more specialized hardware.&lt;br/&gt;\\nASICs for inference are going to be the way to go. They&amp;#39;ll be expensive at first, and get cheaper with scale. There are already several companies with tangible products in this area. A company like Cerebras will go after the top end of the market, and several other companies will compete for the mid and lower tiers.  &lt;/p&gt;\\n\\n&lt;p&gt;GPUs were an effective way to do proof of concept and bridge the gap to the future ways of doing things, but they can&amp;#39;t be the end point.  &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;This is because 1) the companies are getting better at training so less is becoming more, and 2) the publishers and users of these models are slowly figuring out that nobody needs &amp;quot;all human knowledge&amp;quot; in one model because nobody ever works with or really needs all human knowledge when they work or do something. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;d agree that there is likely a lot more we can be doing at the training stage to improve models, but I don&amp;#39;t think we can just ignore the power of scaling. All the evidence and all the theory supports that when using the same techniques, bigger ends up being better, substantially better at first and eventually hitting a point diminishing returns.  &lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think that stops with parameter size, a broader and deeper training set improves the model&amp;#39;s cognitive abilities. Data which is seemingly unrelated to the thing you&amp;#39;re doing, may very well be a benefit because it helps generalization.  &lt;/p&gt;\\n\\n&lt;p&gt;Even if a smaller model can muddle along through arbitrary tasks with the help of external tools, it&amp;#39;s not going to be as good or fast as a larger model.&lt;br/&gt;\\nA model not trained in a field and only using RAG is not going to be as good as a model trained trained in a field which is also using RAG.&lt;br/&gt;\\nRAG also assumes that you have a sufficient set of quality resources to cite. \\nA business might have that, most people won&amp;#39;t. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d much rather have a larger model which is excessive for my needs than a smaller model which kinda-sorta works good enough.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpj9sx9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745868626,"author_flair_text":null,"treatment_tags":[],"created_utc":1745868626,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpk0dmg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"send_replies":true,"parent_id":"t1_mphoznd","score":1,"author_fullname":"t2_a2uzegb8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;As much as big home GPU bros want model sizes to go up to justify their purchase\\n\\nI don't think it's bias, I think it's just realism about the limitations of RAG. I only have 24 GB VRAM and every reason to 'really' want that to be enough. \\n\\nI'm using a custom RAG system I wrote, with allowances for more RAG queries within the reasoning blocks, combined with additional fine tuning. I think that it's the best that's possible at this time with any given model. And it's still just very noticeable as a band-aid solution. A very smart pattern matching system that's been given crib notes. I think it's fantastic for what it is. But at the same time I'm not going to pretend that I wouldn't switch to a specialty model that'd been trained on those particular areas in a heartbeat if it were possible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpk0dmg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;As much as big home GPU bros want model sizes to go up to justify their purchase&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I don&amp;#39;t think it&amp;#39;s bias, I think it&amp;#39;s just realism about the limitations of RAG. I only have 24 GB VRAM and every reason to &amp;#39;really&amp;#39; want that to be enough. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m using a custom RAG system I wrote, with allowances for more RAG queries within the reasoning blocks, combined with additional fine tuning. I think that it&amp;#39;s the best that&amp;#39;s possible at this time with any given model. And it&amp;#39;s still just very noticeable as a band-aid solution. A very smart pattern matching system that&amp;#39;s been given crib notes. I think it&amp;#39;s fantastic for what it is. But at the same time I&amp;#39;m not going to pretend that I wouldn&amp;#39;t switch to a specialty model that&amp;#39;d been trained on those particular areas in a heartbeat if it were possible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpk0dmg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745876787,"author_flair_text":null,"treatment_tags":[],"created_utc":1745876787,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mphoznd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1745851771,"send_replies":true,"parent_id":"t1_mpgvotc","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mphoznd/","num_reports":null,"locked":false,"name":"t1_mphoznd","created":1745851771,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgvotc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FinalsMVPZachZarba","can_mod_post":false,"created_utc":1745841361,"send_replies":true,"parent_id":"t1_mpggxhu","score":5,"author_fullname":"t2_p36owpxz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My M4 Max 128GB is looking more and more useless with every new release","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgvotc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My M4 Max 128GB is looking more and more useless with every new release&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgvotc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841361,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mpggxhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stoppableDissolution","can_mod_post":false,"created_utc":1745833664,"send_replies":true,"parent_id":"t3_1k9qxbl","score":0,"author_fullname":"t2_1n0su21k4z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The sizes are quite disappointing, ngl.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpggxhu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The sizes are quite disappointing, ngl.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpggxhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745833664,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpjjfm6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpjhp3q","score":3,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Offload some layers to CPU\\" does not come together with \\"very fast\\" as soon you offload more than 2 Gb. (20 t/s max on DDR4)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpjjfm6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Offload some layers to CPU&amp;quot; does not come together with &amp;quot;very fast&amp;quot; as soon you offload more than 2 Gb. (20 t/s max on DDR4)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjjfm6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745871539,"author_flair_text":null,"treatment_tags":[],"created_utc":1745871539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpjhp3q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgvrgc","score":1,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can offload some layers to CPU and it will still be very fast.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpjhp3q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can offload some layers to CPU and it will still be very fast.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpjhp3q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745871021,"author_flair_text":null,"treatment_tags":[],"created_utc":1745871021,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpk0gqx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"asssuber","can_mod_post":false,"send_replies":true,"parent_id":"t1_mpgvrgc","score":1,"author_fullname":"t2_17eswh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it's anything like like DeepSeek or specially Llama 4 Maverick, you can offload the non-shared experts to CPU and it will still be very fast. \\n\\nIf the ratio of shared/non-shared parameters among the active 3B is similar to Maverick, it would mean you only need 0.5B parameters for each token from the CPU/RAM side. It means a user with a 6GB GPU and 32GB DDR4 dual-channel would be able to run this hypothetical model at over 100 t/s.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mpk0gqx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s anything like like DeepSeek or specially Llama 4 Maverick, you can offload the non-shared experts to CPU and it will still be very fast. &lt;/p&gt;\\n\\n&lt;p&gt;If the ratio of shared/non-shared parameters among the active 3B is similar to Maverick, it would mean you only need 0.5B parameters for each token from the CPU/RAM side. It means a user with a 6GB GPU and 32GB DDR4 dual-channel would be able to run this hypothetical model at over 100 t/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpk0gqx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745876822,"author_flair_text":null,"treatment_tags":[],"created_utc":1745876822,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgvrgc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1745841394,"send_replies":true,"parent_id":"t1_mpgnskc","score":3,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it will be _very hungry_ in terms of VRAM 15b min for IQ4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgvrgc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it will be &lt;em&gt;very hungry&lt;/em&gt; in terms of VRAM 15b min for IQ4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1k9qxbl","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgvrgc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745841394,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mpgnskc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anshulsingh8326","can_mod_post":false,"created_utc":1745837602,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_4sqglud7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"30b model, a3b ?\\nSo i can run it on 12gb vram?\\nI csn run 8b models, and this is a3b so will be only take 3b worth resources or more?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpgnskc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;30b model, a3b ?\\nSo i can run it on 12gb vram?\\nI csn run 8b models, and this is a3b so will be only take 3b worth resources or more?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpgnskc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745837602,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mpipust","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mark__27","can_mod_post":false,"created_utc":1745862663,"send_replies":true,"parent_id":"t3_1k9qxbl","score":1,"author_fullname":"t2_1gxy2k6l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Multimodal/omni when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mpipust","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Multimodal/omni when?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1k9qxbl/qwen3_published_30_seconds_ago_model_weights/mpipust/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745862663,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1k9qxbl","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":6,"name":"t1_mpgpa5o","id":"mpgpa5o","parent_id":"t3_1k9qxbl","depth":0,"children":["mpgpa5o","mpggi85","mpgp6y3","mqcb0pn"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
