import{j as e}from"./index-Bqs-ekb2.js";import{R as l}from"./RedditPostRenderer-DUVdf0-i.js";import"./index-D52ORTDm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"This morning, I got an E-Mail from the team behind the Mercury Coder LLM, Inception (https://www.inceptionlabs.ai/) that basically announced a chat-focused model. Pretty neat, sent along an API example with cURL also. Simple and nice.\\n\\nBut this reminded me of dLLMs in general - they haven't really been talked a lot about lately. So I wanted to ask into the broad space: What's up? I like the idea of dLLMs being a different approach and perhaps easier to run compared to transformers. But I also understand the tech is relatively new - that is, diffusers for text rather than images.\\n\\nThanks!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"So whatever happened to d(iffuser)LLMs?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lnzj5e","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.89,"author_flair_background_color":null,"subreddit_type":"public","ups":48,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_2c8xodlx","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":48,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751261349,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;This morning, I got an E-Mail from the team behind the Mercury Coder LLM, Inception (&lt;a href=\\"https://www.inceptionlabs.ai/\\"&gt;https://www.inceptionlabs.ai/&lt;/a&gt;) that basically announced a chat-focused model. Pretty neat, sent along an API example with cURL also. Simple and nice.&lt;/p&gt;\\n\\n&lt;p&gt;But this reminded me of dLLMs in general - they haven&amp;#39;t really been talked a lot about lately. So I wanted to ask into the broad space: What&amp;#39;s up? I like the idea of dLLMs being a different approach and perhaps easier to run compared to transformers. But I also understand the tech is relatively new - that is, diffusers for text rather than images.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lnzj5e","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"IngwiePhoenix","discussion_type":null,"num_comments":11,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/","subreddit_subscribers":493242,"created_utc":1751261349,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0jbkn3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Salty-Garage7777","can_mod_post":false,"created_utc":1751265458,"send_replies":true,"parent_id":"t1_n0j4svw","score":15,"author_fullname":"t2_14m2ycs468","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's extremely fast, only useful for one shotting, and low quality ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0jbkn3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s extremely fast, only useful for one shotting, and low quality &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0jbkn3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751265458,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kmuev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ColorlessCrowfeet","can_mod_post":false,"created_utc":1751289602,"send_replies":true,"parent_id":"t1_n0j4svw","score":12,"author_fullname":"t2_9g89e30o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gone nowhere for 40 days since [the announcement](https://blog.google/technology/google-deepmind/gemini-diffusion/)!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kmuev","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gone nowhere for 40 days since &lt;a href=\\"https://blog.google/technology/google-deepmind/gemini-diffusion/\\"&gt;the announcement&lt;/a&gt;!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0kmuev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751289602,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n0j4svw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Only_Situation_4713","can_mod_post":false,"created_utc":1751261716,"send_replies":true,"parent_id":"t3_1lnzj5e","score":47,"author_fullname":"t2_aafjsulg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[Gemini Diffusion - Google DeepMind](https://deepmind.google/models/gemini-diffusion/) doesn't seem like it went anywhere","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0j4svw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://deepmind.google/models/gemini-diffusion/\\"&gt;Gemini Diffusion - Google DeepMind&lt;/a&gt; doesn&amp;#39;t seem like it went anywhere&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0j4svw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751261716,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnzj5e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0jpx2f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IngwiePhoenix","can_mod_post":false,"created_utc":1751274148,"send_replies":true,"parent_id":"t1_n0jfnoy","score":6,"author_fullname":"t2_2c8xodlx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Good one. :)\\n\\nYeah...good point. Big corpo doesn't need _that_ much optimization and scales for a whole lot more than a single user. Oh well!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0jpx2f","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Good one. :)&lt;/p&gt;\\n\\n&lt;p&gt;Yeah...good point. Big corpo doesn&amp;#39;t need &lt;em&gt;that&lt;/em&gt; much optimization and scales for a whole lot more than a single user. Oh well!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0jpx2f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751274148,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qkb6m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Karyo_Ten","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0l2sb2","score":1,"author_fullname":"t2_tbdqg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which are?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qkb6m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which are?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0qkb6m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751367496,"author_flair_text":null,"treatment_tags":[],"created_utc":1751367496,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0l2sb2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PermanentLiminality","can_mod_post":false,"created_utc":1751294657,"send_replies":true,"parent_id":"t1_n0jfnoy","score":1,"author_fullname":"t2_19zqycaf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are a lot of use cases that can benefit greatly from the reduced latency and greater speeds.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0l2sb2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are a lot of use cases that can benefit greatly from the reduced latency and greater speeds.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0l2sb2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751294657,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0jfnoy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751267831,"send_replies":true,"parent_id":"t3_1lnzj5e","score":29,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They diffused away. \\n\\nTo be serious, I think there is a much less of performance gain at cloud level as batching will probably produce same results in toytal throughput. And who cares about edge single-user inference?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0jfnoy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They diffused away. &lt;/p&gt;\\n\\n&lt;p&gt;To be serious, I think there is a much less of performance gain at cloud level as batching will probably produce same results in toytal throughput. And who cares about edge single-user inference?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0jfnoy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751267831,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnzj5e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0jv7jv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"martinerous","can_mod_post":false,"created_utc":1751277345,"send_replies":true,"parent_id":"t3_1lnzj5e","score":8,"author_fullname":"t2_5tp54ey","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems that their benefits could not (yet) compete with autoregressive models. However, the future might be some kind of a hybrid, especially when combined with something even more decoupled from tokens. Just speculating here with ideas: using diffusion for scaffolding a draft of the response with core concepts and their associations, ignoring small grammar details (e.g. Request: What color is the sky? Draft response: sky blue) and then using autoregressive models to form grammatically correct sentences in a specific language. That seems more similar to how we think - first, the core concepts pop up in our mind and then we use our inner dialogue to form a response.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0jv7jv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems that their benefits could not (yet) compete with autoregressive models. However, the future might be some kind of a hybrid, especially when combined with something even more decoupled from tokens. Just speculating here with ideas: using diffusion for scaffolding a draft of the response with core concepts and their associations, ignoring small grammar details (e.g. Request: What color is the sky? Draft response: sky blue) and then using autoregressive models to form grammatically correct sentences in a specific language. That seems more similar to how we think - first, the core concepts pop up in our mind and then we use our inner dialogue to form a response.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0jv7jv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751277345,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnzj5e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0lkyh9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Terminator857","can_mod_post":false,"created_utc":1751299942,"send_replies":true,"parent_id":"t3_1lnzj5e","score":3,"author_fullname":"t2_m40tjcn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Other reddit discussion on same topic: [https://www.reddit.com/r/LocalLLM/comments/1ljbajp/diffusion\\\\_language\\\\_models\\\\_will\\\\_cut\\\\_the\\\\_cost\\\\_of/](https://www.reddit.com/r/LocalLLM/comments/1ljbajp/diffusion_language_models_will_cut_the_cost_of/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0lkyh9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Other reddit discussion on same topic: &lt;a href=\\"https://www.reddit.com/r/LocalLLM/comments/1ljbajp/diffusion_language_models_will_cut_the_cost_of/\\"&gt;https://www.reddit.com/r/LocalLLM/comments/1ljbajp/diffusion_language_models_will_cut_the_cost_of/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0lkyh9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751299942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnzj5e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pserq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IngwiePhoenix","can_mod_post":false,"created_utc":1751351344,"send_replies":true,"parent_id":"t1_n0owrn1","score":1,"author_fullname":"t2_2c8xodlx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ohh that's interesting; I am not too deep into the inner workings of the various models (I am glad I know the utter basic difference between a diffuser and autoregressive xD) so this was super insightful. Thanks for that! =)\\n\\nIf scaling is such an issue, then I am hardly surprised that imagegen has kind of, seemingly \\"stalled\\". Sure, stuff still happens - Flux Kontext, for instance - but at a much different pace than typical LLMs.\\n\\nWeren't there some distributed training things going on a while back? Wonder how they'd fare with diffuser training...would certainly donate some compute towards that out of sheer curiosity. I have some spare compute most of the time. :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pserq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ohh that&amp;#39;s interesting; I am not too deep into the inner workings of the various models (I am glad I know the utter basic difference between a diffuser and autoregressive xD) so this was super insightful. Thanks for that! =)&lt;/p&gt;\\n\\n&lt;p&gt;If scaling is such an issue, then I am hardly surprised that imagegen has kind of, seemingly &amp;quot;stalled&amp;quot;. Sure, stuff still happens - Flux Kontext, for instance - but at a much different pace than typical LLMs.&lt;/p&gt;\\n\\n&lt;p&gt;Weren&amp;#39;t there some distributed training things going on a while back? Wonder how they&amp;#39;d fare with diffuser training...would certainly donate some compute towards that out of sheer curiosity. I have some spare compute most of the time. :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnzj5e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0pserq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751351344,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0owrn1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1751337117,"send_replies":true,"parent_id":"t3_1lnzj5e","score":3,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The nature of Diffusion models (do keep in mind that they're not really structurally different; they just have a different objective), favors local single-user inference more than auto regressive models.\\n\\nBasically, a Diffusion workload looks more like batched LLM inference (to the hardware), so you're seeing a pretty even balance of memory bandwidth and compute used to generate tokens.\\n\\nThe problem with this is when you scale it up in the cloud, you don't really get as many benefit from the Diffusion model, whereas the autoregressive models scale in total throughput quite elegantly.\\n\\nSo...If you're an enterprise with the funds to train a Diffusion LLM, is it really worth spending 16x on training compute to get the same performance, and then to have inference costs that are the same (or possibly even worse) than your super optimized cloud infra?\\n\\nThey probably make a lot of sense for distributed open source training, though.\\n\\nIt's a very similar tradeoff to Bitnet, actually.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0owrn1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The nature of Diffusion models (do keep in mind that they&amp;#39;re not really structurally different; they just have a different objective), favors local single-user inference more than auto regressive models.&lt;/p&gt;\\n\\n&lt;p&gt;Basically, a Diffusion workload looks more like batched LLM inference (to the hardware), so you&amp;#39;re seeing a pretty even balance of memory bandwidth and compute used to generate tokens.&lt;/p&gt;\\n\\n&lt;p&gt;The problem with this is when you scale it up in the cloud, you don&amp;#39;t really get as many benefit from the Diffusion model, whereas the autoregressive models scale in total throughput quite elegantly.&lt;/p&gt;\\n\\n&lt;p&gt;So...If you&amp;#39;re an enterprise with the funds to train a Diffusion LLM, is it really worth spending 16x on training compute to get the same performance, and then to have inference costs that are the same (or possibly even worse) than your super optimized cloud infra?&lt;/p&gt;\\n\\n&lt;p&gt;They probably make a lot of sense for distributed open source training, though.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a very similar tradeoff to Bitnet, actually.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnzj5e/so_whatever_happened_to_diffuserllms/n0owrn1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751337117,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnzj5e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
