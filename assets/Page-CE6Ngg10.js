import{j as e}from"./index-cvG704yx.js";import{R as l}from"./RedditPostRenderer-CBthLTAH.js";import"./index-D-GavSZU.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Maybe there is an interesting research project, which is not effective yet, but after further improvements, can open new doors in AI development?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Is there any promising alternative to Transformers?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m3amtu","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.94,"author_flair_background_color":null,"subreddit_type":"public","ups":81,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_xvwcc","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":81,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752864640,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe there is an interesting research project, which is not effective yet, but after further improvements, can open new doors in AI development?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m3amtu","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"VR-Person","discussion_type":null,"num_comments":53,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/","subreddit_subscribers":501076,"created_utc":1752864640,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vkxsn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OfficialHashPanda","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vjakg","score":7,"author_fullname":"t2_8w6mm4hmo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; But it doesn't necessarily not either.\\n\\n\\nIf it did, they probably would've mentioned it in their post. It's one of the first things one would consider in this case.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vkxsn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;But it doesn&amp;#39;t necessarily not either.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;If it did, they probably would&amp;#39;ve mentioned it in their post. It&amp;#39;s one of the first things one would consider in this case.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vkxsn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752869051,"author_flair_text":null,"treatment_tags":[],"created_utc":1752869051,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vjakg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"National_Meeting_749","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vcxhc","score":3,"author_fullname":"t2_drm5tg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But it doesn't necessarily not either.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vjakg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But it doesn&amp;#39;t necessarily not either.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vjakg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868563,"author_flair_text":null,"treatment_tags":[],"created_utc":1752868563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xplnh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"I-am_Sleepy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xh523","score":2,"author_fullname":"t2_8r6wb3jy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Isn’t that what foundation model does, trying to cover all the bases?","edited":false,"author_flair_css_class":null,"name":"t1_n3xplnh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn’t that what foundation model does, trying to cover all the bases?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m3amtu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xplnh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752895834,"author_flair_text":null,"collapsed":false,"created_utc":1752895834,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xh523","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bigfatstinkypoo","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3x7tt7","score":5,"author_fullname":"t2_3zy0bzv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it's easy, just overfit a general problem","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xh523","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s easy, just overfit a general problem&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xh523/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752892350,"author_flair_text":null,"treatment_tags":[],"created_utc":1752892350,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3x7tt7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yaosio","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vcxhc","score":2,"author_fullname":"t2_3z3zm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Overfit a model into producing general purpose architecture.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3x7tt7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Overfit a model into producing general purpose architecture.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3x7tt7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752888769,"author_flair_text":null,"treatment_tags":[],"created_utc":1752888769,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vcxhc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OfficialHashPanda","can_mod_post":false,"created_utc":1752866670,"send_replies":true,"parent_id":"t1_n3v7tkb","score":21,"author_fullname":"t2_8w6mm4hmo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LiquidAI's evolutionary approach overfits an architecture to a specific scale / dataset. Such an architecture doesn't necessarily generalize to larger scales and/or different datasets.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vcxhc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LiquidAI&amp;#39;s evolutionary approach overfits an architecture to a specific scale / dataset. Such an architecture doesn&amp;#39;t necessarily generalize to larger scales and/or different datasets.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vcxhc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866670,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3w8ky3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"log_2","can_mod_post":false,"created_utc":1752876282,"send_replies":true,"parent_id":"t1_n3v7tkb","score":3,"author_fullname":"t2_dbimn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looking at liquid ai GitHub code since the website is frustratingly lacking in detail, while transformer attention does all-token vs all-token (L x L) mixing the liquid version does all-token vs average-token (L x 1) mixing. Not too impressive.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w8ky3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking at liquid ai GitHub code since the website is frustratingly lacking in detail, while transformer attention does all-token vs all-token (L x L) mixing the liquid version does all-token vs average-token (L x 1) mixing. Not too impressive.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3w8ky3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752876282,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wcipi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Accomplished_Mode170","can_mod_post":false,"created_utc":1752877606,"send_replies":true,"parent_id":"t1_n3v7tkb","score":4,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My bet is on [memory layers as scaled up KV machines](https://ai.meta.com/research/publications/memory-layers-at-scale/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wcipi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My bet is on &lt;a href=\\"https://ai.meta.com/research/publications/memory-layers-at-scale/\\"&gt;memory layers as scaled up KV machines&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wcipi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752877606,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v7tkb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Background_Put_4978","can_mod_post":false,"created_utc":1752865148,"send_replies":true,"parent_id":"t3_1m3amtu","score":83,"author_fullname":"t2_ap0qx6cm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes, many. You can use Liquid Foundation Models right now on HuggingFace or LiquidAI’s own playground. They are mostly fantastic. Mamba is not a household name but SSMs in general have a ton to offer. In the future, Oscillator Neural Nets are promising, and dynamic neural fields may yield surprises. Some folks are hot on reservoir computing. My bet is on LiquidAI as a source of stable alternative architectures. They have a whole evolutionary system that basically spits out novel architectures.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v7tkb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, many. You can use Liquid Foundation Models right now on HuggingFace or LiquidAI’s own playground. They are mostly fantastic. Mamba is not a household name but SSMs in general have a ton to offer. In the future, Oscillator Neural Nets are promising, and dynamic neural fields may yield surprises. Some folks are hot on reservoir computing. My bet is on LiquidAI as a source of stable alternative architectures. They have a whole evolutionary system that basically spits out novel architectures.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3v7tkb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865148,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":83}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xpyvo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kaldnite","can_mod_post":false,"created_utc":1752895995,"send_replies":true,"parent_id":"t1_n3wjctn","score":1,"author_fullname":"t2_sclf58","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Great explanation... Thank you","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xpyvo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great explanation... Thank you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xpyvo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752895995,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wjctn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"stikves","can_mod_post":false,"created_utc":1752879962,"send_replies":true,"parent_id":"t3_1m3amtu","score":18,"author_fullname":"t2_17g3q9fd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Transformers (or the actual name \\"attention layers\\") are a natural progression of Natural Language Processing pipelines.\\n\\nWe had **LSTM** (Long Short-Term Memory) which contained \\"cells\\" each remembering parts of previously seen text.\\n\\nThen it expanded to bi-directional LSTM and other hooks to have correspondence between different parts of the text pieces.\\n\\nAnd finally, Google built the **attention layers**, or the attention mechanism, which basically gave an NxN matrix of connections between LSTM cells.\\n\\n(Say you have 100 LSTM cells. Initially they would be forward only recurrent networks, basically you'd process one word (token) at a time, and it would slowly understand context, and remember up to 100 pieces of information from past (it also has a concept of **forget**, so it will not be overflown by useless stuff).\\n\\nIt would help understand something like \\"cell\\" being a biological cell, a cell phone, prison cell, LSTM cell, and so on. It evolved from there)\\n\\nWhy is attention important? Because Google basically proved \\"**attention is all you need\\"**. Kept the attention layers, and erased everything else from LSTM. It became much better.\\n\\nWhy? LSTMs are **sequential,** attention is **parallel.** Much better suited for both training an inference on modern tensor based machines.\\n\\n(Read that paper, it is a good one. If you cannot, have an LLM summarize it for you)\\n\\nNow, there are attempts to revive LSTM, like xLSTM, or enhance attention layers (basically for larger context sizes, and obviously an NxN network will have quadratic memory requirements).\\n\\nBut we have not moved *too far* from there, yet.\\n\\nWhatever new that will come might probably be not too dissimilar either. (LSTM and attention basically are two extremes and are pretty much as bare as you can get).","edited":1752880172,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wjctn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Transformers (or the actual name &amp;quot;attention layers&amp;quot;) are a natural progression of Natural Language Processing pipelines.&lt;/p&gt;\\n\\n&lt;p&gt;We had &lt;strong&gt;LSTM&lt;/strong&gt; (Long Short-Term Memory) which contained &amp;quot;cells&amp;quot; each remembering parts of previously seen text.&lt;/p&gt;\\n\\n&lt;p&gt;Then it expanded to bi-directional LSTM and other hooks to have correspondence between different parts of the text pieces.&lt;/p&gt;\\n\\n&lt;p&gt;And finally, Google built the &lt;strong&gt;attention layers&lt;/strong&gt;, or the attention mechanism, which basically gave an NxN matrix of connections between LSTM cells.&lt;/p&gt;\\n\\n&lt;p&gt;(Say you have 100 LSTM cells. Initially they would be forward only recurrent networks, basically you&amp;#39;d process one word (token) at a time, and it would slowly understand context, and remember up to 100 pieces of information from past (it also has a concept of &lt;strong&gt;forget&lt;/strong&gt;, so it will not be overflown by useless stuff).&lt;/p&gt;\\n\\n&lt;p&gt;It would help understand something like &amp;quot;cell&amp;quot; being a biological cell, a cell phone, prison cell, LSTM cell, and so on. It evolved from there)&lt;/p&gt;\\n\\n&lt;p&gt;Why is attention important? Because Google basically proved &amp;quot;&lt;strong&gt;attention is all you need&amp;quot;&lt;/strong&gt;. Kept the attention layers, and erased everything else from LSTM. It became much better.&lt;/p&gt;\\n\\n&lt;p&gt;Why? LSTMs are &lt;strong&gt;sequential,&lt;/strong&gt; attention is &lt;strong&gt;parallel.&lt;/strong&gt; Much better suited for both training an inference on modern tensor based machines.&lt;/p&gt;\\n\\n&lt;p&gt;(Read that paper, it is a good one. If you cannot, have an LLM summarize it for you)&lt;/p&gt;\\n\\n&lt;p&gt;Now, there are attempts to revive LSTM, like xLSTM, or enhance attention layers (basically for larger context sizes, and obviously an NxN network will have quadratic memory requirements).&lt;/p&gt;\\n\\n&lt;p&gt;But we have not moved &lt;em&gt;too far&lt;/em&gt; from there, yet.&lt;/p&gt;\\n\\n&lt;p&gt;Whatever new that will come might probably be not too dissimilar either. (LSTM and attention basically are two extremes and are pretty much as bare as you can get).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wjctn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752879962,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3y3vp6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1752902335,"send_replies":true,"parent_id":"t1_n3wc6gs","score":1,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Much better than LG. LG is just advancing new ways to limit their models with custom nonsensical licenses","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y3vp6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Much better than LG. LG is just advancing new ways to limit their models with custom nonsensical licenses&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3y3vp6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752902335,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wc6gs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bratao","can_mod_post":false,"created_utc":1752877490,"send_replies":true,"parent_id":"t3_1m3amtu","score":14,"author_fullname":"t2_376nl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The IBM granite 4 looks impressive. It is a mixed model with Mamba2 and Transformers but they really look like did a solid job.\\nwww.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wc6gs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The IBM granite 4 looks impressive. It is a mixed model with Mamba2 and Transformers but they really look like did a solid job.\\n&lt;a href=\\"http://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek\\"&gt;www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wc6gs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752877490,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vwqsu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Striking-Warning9533","can_mod_post":false,"created_utc":1752872534,"send_replies":true,"parent_id":"t1_n3v8kyx","score":23,"author_fullname":"t2_70mnmect","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Diffusers also use transformer, just not auto regressive","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vwqsu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Diffusers also use transformer, just not auto regressive&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vwqsu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752872534,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vvp9a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JoMaster68","can_mod_post":false,"created_utc":1752872219,"send_replies":true,"parent_id":"t1_n3v8kyx","score":9,"author_fullname":"t2_5trqznsz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"but don‘t diffusion LLMs also use transformers?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vvp9a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;but don‘t diffusion LLMs also use transformers?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vvp9a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752872219,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v8kyx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dany0","can_mod_post":false,"created_utc":1752865370,"send_replies":true,"parent_id":"t3_1m3amtu","score":13,"author_fullname":"t2_bc7wl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As for now, not really. Diffusers are fast but that's about it. In benchmarks they can almost match previous SOTAs from 1-2 years ago\\n\\n  \\nAs for the future, short answer, yes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v8kyx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As for now, not really. Diffusers are fast but that&amp;#39;s about it. In benchmarks they can almost match previous SOTAs from 1-2 years ago&lt;/p&gt;\\n\\n&lt;p&gt;As for the future, short answer, yes&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3v8kyx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865370,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x2s1w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vrpna","score":0,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"More than meets the need","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x2s1w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More than meets the need&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3x2s1w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752886871,"author_flair_text":null,"treatment_tags":[],"created_utc":1752886871,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vrpna","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"digitaljohn","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3vdtbr","score":2,"author_fullname":"t2_8k2gj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"More than meets the eye","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3vrpna","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;More than meets the eye&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vrpna/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752871041,"author_flair_text":null,"treatment_tags":[],"created_utc":1752871041,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vdtbr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bobby-chan","can_mod_post":false,"created_utc":1752866934,"send_replies":true,"parent_id":"t1_n3v7dy9","score":13,"author_fullname":"t2_frmtv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But they aren't alternatives, they ARE transformers. \\n\\nMore than meets all you need.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vdtbr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But they aren&amp;#39;t alternatives, they ARE transformers. &lt;/p&gt;\\n\\n&lt;p&gt;More than meets all you need.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vdtbr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752866934,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xkshg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"delicious_fanta","can_mod_post":false,"created_utc":1752893821,"send_replies":true,"parent_id":"t1_n3v7dy9","score":1,"author_fullname":"t2_afmq1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was thinking go-bots would make a resurgence.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xkshg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was thinking go-bots would make a resurgence.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xkshg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752893821,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v7dy9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GreenTreeAndBlueSky","can_mod_post":false,"created_utc":1752865022,"send_replies":true,"parent_id":"t3_1m3amtu","score":46,"author_fullname":"t2_1p50pl73j2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Decepticons will rise at some point and dominate trust me","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v7dy9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Decepticons will rise at some point and dominate trust me&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3v7dy9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752865022,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wsq71","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wshii","score":3,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To me it works but here is the paper [page](https://arxiv.org/abs/2501.00663v1)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3wsq71","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To me it works but here is the paper &lt;a href=\\"https://arxiv.org/abs/2501.00663v1\\"&gt;page&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wsq71/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752883176,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752883176,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wshii","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Antsint","can_mod_post":false,"created_utc":1752883089,"send_replies":true,"parent_id":"t1_n3vqp7m","score":2,"author_fullname":"t2_5z0j4pel","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Your link doesn’t work","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wshii","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your link doesn’t work&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wshii/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752883089,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xe9z0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3x9z3t","score":3,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[this kind?](https://arxiv.org/abs/2411.06414)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3xe9z0","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2411.06414\\"&gt;this kind?&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xe9z0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752891227,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752891227,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n3x9z3t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752889587,"send_replies":true,"parent_id":"t1_n3vqp7m","score":1,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We need Gundam architecture next.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x9z3t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need Gundam architecture next.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3x9z3t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752889587,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3vqp7m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1752870744,"send_replies":true,"parent_id":"t3_1m3amtu","score":7,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[titans](https://arxiv.org/html/2501.00663v1)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vqp7m","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/html/2501.00663v1\\"&gt;titans&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vqp7m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752870744,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vqy75","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Apprehensive_Bar6609","can_mod_post":false,"created_utc":1752870818,"send_replies":true,"parent_id":"t3_1m3amtu","score":5,"author_fullname":"t2_5bie8k5s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mamba, XLstm, theres a few but nothing revolutionary.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vqy75","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mamba, XLstm, theres a few but nothing revolutionary.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vqy75/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752870818,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vy280","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Feztopia","can_mod_post":false,"created_utc":1752872939,"send_replies":true,"parent_id":"t3_1m3amtu","score":5,"author_fullname":"t2_34dar1xn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think rwkv would be nice with enough training budget. Someone from openai also did say in the past that the architecture doesn't matter and in the end they all converge to what ever the trainingset has. Which speaks even more for efficient architectures like rwkv because if the max quality is the same, why not use the architecture which is most efficient to run. The next 7b model is going to be released in a few days I think, I'm curious if it will reach lands 3 8b (which I prefer over qwen).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vy280","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think rwkv would be nice with enough training budget. Someone from openai also did say in the past that the architecture doesn&amp;#39;t matter and in the end they all converge to what ever the trainingset has. Which speaks even more for efficient architectures like rwkv because if the max quality is the same, why not use the architecture which is most efficient to run. The next 7b model is going to be released in a few days I think, I&amp;#39;m curious if it will reach lands 3 8b (which I prefer over qwen).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vy280/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752872939,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vixaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffdy","can_mod_post":false,"created_utc":1752868453,"send_replies":true,"parent_id":"t3_1m3amtu","score":5,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, you can always watch Mobile Suit Gundam","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vixaq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, you can always watch Mobile Suit Gundam&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vixaq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868453,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vgiz2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"disillusioned_okapi","can_mod_post":false,"created_utc":1752867748,"send_replies":true,"parent_id":"t3_1m3amtu","score":2,"author_fullname":"t2_wy3w8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From last week, in case you want to try it out\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1lxmldq/liquidai_lfm2_model_released/","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vgiz2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From last week, in case you want to try it out\\n&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lxmldq/liquidai_lfm2_model_released/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1lxmldq/liquidai_lfm2_model_released/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vgiz2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752867748,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xl9pg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoneyPowerNexis","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xi01l","score":1,"author_fullname":"t2_635g2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They are posting somewhat regularly on the [\\nThousand Brains Project channel](https://www.youtube.com/@thousandbrainsproject/videos) but yeah I get the feeling that they pivoted to open source because they don't have anything of commercial value because its slow going. That might be great for people wanting to have their tech as open models so long as they dont do an open AI and make everything hidden if they do make a breakthrough.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3xl9pg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are posting somewhat regularly on the &lt;a href=\\"https://www.youtube.com/@thousandbrainsproject/videos\\"&gt;\\nThousand Brains Project channel&lt;/a&gt; but yeah I get the feeling that they pivoted to open source because they don&amp;#39;t have anything of commercial value because its slow going. That might be great for people wanting to have their tech as open models so long as they dont do an open AI and make everything hidden if they do make a breakthrough.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xl9pg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752894016,"author_flair_text":null,"treatment_tags":[],"created_utc":1752894016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xi01l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tronathan","can_mod_post":false,"created_utc":1752892689,"send_replies":true,"parent_id":"t1_n3wh1ie","score":1,"author_fullname":"t2_3aqn7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Man, I miss numetia and Jeff's videos on cortial columns and such. All I can assume is that Transformers ate their lunch and now their research is either slowed or changing directions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xi01l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Man, I miss numetia and Jeff&amp;#39;s videos on cortial columns and such. All I can assume is that Transformers ate their lunch and now their research is either slowed or changing directions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xi01l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752892689,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wh1ie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoneyPowerNexis","can_mod_post":false,"created_utc":1752879167,"send_replies":true,"parent_id":"t3_1m3amtu","score":2,"author_fullname":"t2_635g2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Every so often I look up numenta / the 1000 brains project to see if they are making progress at cracking the algorithmic architecture of the human brain. I dont give them a high probability of being the ones to do it (I think it will probably result from the human brain project or a lab that focuses on imaging and predictive modeling of how neurons learn, maybe one of the companies working with human brains on a chip) but I still hold out hope that figuring out how the brain learns will lead to true AGI. A major difference in the architecture would be that brains dont do back propagation or anything that has a global learning rule as far as we know. \\n\\nIt might turn out that gradient decent /  back propagation is superior to how the brain works but how the brain works certainly scales to a high parameter count and uses arguably unimpressive individual hardware components (in terms of latency) to achieve simultaneous training and inference in 20w.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wh1ie","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Every so often I look up numenta / the 1000 brains project to see if they are making progress at cracking the algorithmic architecture of the human brain. I dont give them a high probability of being the ones to do it (I think it will probably result from the human brain project or a lab that focuses on imaging and predictive modeling of how neurons learn, maybe one of the companies working with human brains on a chip) but I still hold out hope that figuring out how the brain learns will lead to true AGI. A major difference in the architecture would be that brains dont do back propagation or anything that has a global learning rule as far as we know. &lt;/p&gt;\\n\\n&lt;p&gt;It might turn out that gradient decent /  back propagation is superior to how the brain works but how the brain works certainly scales to a high parameter count and uses arguably unimpressive individual hardware components (in terms of latency) to achieve simultaneous training and inference in 20w.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wh1ie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752879167,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xk4mm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"simulated-souls","can_mod_post":false,"created_utc":1752893549,"send_replies":true,"parent_id":"t3_1m3amtu","score":2,"author_fullname":"t2_1bvkixdlpc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The answer is Google's [Atlas architecture](https://arxiv.org/abs/2505.23735) which is a follow up to their much publicized [Titans architecture](https://arxiv.org/abs/2501.00663).\\n\\nIt matches or outperforms transformers on pretty much everything they tested, with linear time and constant space complexity. This means that handling a 10x longer context would use 10x more compute and the same amount of memory. In comparison, a transformer would use 100x more compute and 10x more memory. \\n\\nHere's the killer:\\n&gt;  ATLAS further improves the long context performance of Titans, achieving **+80% accuracy in 10M context length of BABILong benchmark**.\\n\\nThat's 10 times longer than the context length offered by any frontier models. None of the standard transformers they tested could even get 80% at 10 *thousand* tokens.","edited":1752893752,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xk4mm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The answer is Google&amp;#39;s &lt;a href=\\"https://arxiv.org/abs/2505.23735\\"&gt;Atlas architecture&lt;/a&gt; which is a follow up to their much publicized &lt;a href=\\"https://arxiv.org/abs/2501.00663\\"&gt;Titans architecture&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;It matches or outperforms transformers on pretty much everything they tested, with linear time and constant space complexity. This means that handling a 10x longer context would use 10x more compute and the same amount of memory. In comparison, a transformer would use 100x more compute and 10x more memory. &lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s the killer:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;ATLAS further improves the long context performance of Titans, achieving &lt;strong&gt;+80% accuracy in 10M context length of BABILong benchmark&lt;/strong&gt;.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s 10 times longer than the context length offered by any frontier models. None of the standard transformers they tested could even get 80% at 10 &lt;em&gt;thousand&lt;/em&gt; tokens.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xk4mm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752893549,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xdewk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3xb5wo","score":0,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No, i am saying that self attention mechanism can be replaced with some other state management mechanism such as rvkv and the result will be more or less same as soon as ffn stays same.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xdewk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, i am saying that self attention mechanism can be replaced with some other state management mechanism such as rvkv and the result will be more or less same as soon as ffn stays same.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xdewk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752890893,"author_flair_text":null,"treatment_tags":[],"created_utc":1752890893,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n3xb5wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jtoma5","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wavin","score":1,"author_fullname":"t2_4dfvlfzp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They are saying that the \\"self-attention\\" in transformers describes one kind of matrix operation that can be done in a feed forward neural network. There are others that can be used to produce chatbots(?) that feel similar (i.e., not way less stupid, all things being equal). Therefore, the key is the network type. \\n\\nIdk how right that is. You have to look at how things scale with compute.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3xb5wo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are saying that the &amp;quot;self-attention&amp;quot; in transformers describes one kind of matrix operation that can be done in a feed forward neural network. There are others that can be used to produce chatbots(?) that feel similar (i.e., not way less stupid, all things being equal). Therefore, the key is the network type. &lt;/p&gt;\\n\\n&lt;p&gt;Idk how right that is. You have to look at how things scale with compute.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xb5wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752890036,"author_flair_text":null,"treatment_tags":[],"created_utc":1752890036,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xe9oj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wavin","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have already answered - there are already some alternatives to transformers (which afaik may still have some self attention) such as jamba and yet the resulting model behavior is not too different compared to transformer based models, as knowledge of the model stored in ffn, which are used irrespective of the architecture.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3xe9oj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have already answered - there are already some alternatives to transformers (which afaik may still have some self attention) such as jamba and yet the resulting model behavior is not too different compared to transformer based models, as knowledge of the model stored in ffn, which are used irrespective of the architecture.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xe9oj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752891224,"author_flair_text":null,"treatment_tags":[],"created_utc":1752891224,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3werer","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Tarekun","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3wavin","score":1,"author_fullname":"t2_1n731ucb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think the point being made is that the attention mechanism is kinda like feature engineering, it doesn't really produce the output in a sense, but computes how relevant tokens are to each other, then gives that attention map as input to FF layers","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3werer","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the point being made is that the attention mechanism is kinda like feature engineering, it doesn&amp;#39;t really produce the output in a sense, but computes how relevant tokens are to each other, then gives that attention map as input to FF layers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3werer/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752878372,"author_flair_text":null,"treatment_tags":[],"created_utc":1752878372,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wavin","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"created_utc":1752877049,"send_replies":true,"parent_id":"t1_n3v79f6","score":2,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you mean by \\"transformer mechanism\\"? If you mean self-attention, then please expand because, and someone correct me if i am wrong, it's the only thing made difference. There were architectures with normal attention or any other attention additional to FFNs, but none of them were that effective? Sure, now with lots of compute and lots of params, you can come a long way, but nothing has reached it yet.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wavin","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you mean by &amp;quot;transformer mechanism&amp;quot;? If you mean self-attention, then please expand because, and someone correct me if i am wrong, it&amp;#39;s the only thing made difference. There were architectures with normal attention or any other attention additional to FFNs, but none of them were that effective? Sure, now with lots of compute and lots of params, you can come a long way, but nothing has reached it yet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wavin/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752877049,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3v79f6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752864986,"send_replies":true,"parent_id":"t3_1m3amtu","score":5,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the intelligence of the model not in transformer mechanism, but in FFN. Jamba models have different context handling profile, but still feel like normal transformer model, more or less.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3v79f6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the intelligence of the model not in transformer mechanism, but in FFN. Jamba models have different context handling profile, but still feel like normal transformer model, more or less.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3v79f6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752864986,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vtn1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Superb-Translator236","can_mod_post":false,"created_utc":1752871604,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_1tsrtg3x6z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"xlstm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vtn1m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;xlstm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vtn1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752871604,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3we154","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Background_Put_4978","can_mod_post":false,"created_utc":1752878122,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_ap0qx6cm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If yall wanna see someone coming up with fantastically cool ideas just search for Andrew Kiruluta’s work on Arxiv. Post transformer ideas galore.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3we154","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If yall wanna see someone coming up with fantastically cool ideas just search for Andrew Kiruluta’s work on Arxiv. Post transformer ideas galore.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3we154/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752878122,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wkftw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"created_utc":1752880329,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"+1 on the Mamba comments but it hasn't taken off at scale the way transformers have.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wkftw","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;+1 on the Mamba comments but it hasn&amp;#39;t taken off at scale the way transformers have.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wkftw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752880329,"author_flair_text":":X:","treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3y3bq6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1752902060,"send_replies":true,"parent_id":"t1_n3wlvrx","score":1,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is more than meets the eye with this response","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3y3bq6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is more than meets the eye with this response&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3y3bq6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752902060,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3wlvrx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sunomonodekani","can_mod_post":false,"created_utc":1752880815,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_1lurun92nv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"DECEPTICONS","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wlvrx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DECEPTICONS&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wlvrx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752880815,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wnyxr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EndStorm","can_mod_post":false,"created_utc":1752881525,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_iz090","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Maybe Voltron.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wnyxr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe Voltron.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wnyxr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752881525,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wtjy3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MarinatedPickachu","can_mod_post":false,"created_utc":1752883472,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_bwdb8qqfj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"GoBots","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wtjy3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GoBots&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wtjy3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752883472,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x3fij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752887115,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"not strictly an alternative but Imo the next step toward efficiency (after MoEs) is hybrid models (a true transformers layer every n layers, and those could be SSM or something else...)\\n\\nalso I think that there is the possibility that \\"we\\" skipped something focusing exclusively on decoder-only architectures (T5Gemma results show interesting insights)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x3fij","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;not strictly an alternative but Imo the next step toward efficiency (after MoEs) is hybrid models (a true transformers layer every n layers, and those could be SSM or something else...)&lt;/p&gt;\\n\\n&lt;p&gt;also I think that there is the possibility that &amp;quot;we&amp;quot; skipped something focusing exclusively on decoder-only architectures (T5Gemma results show interesting insights)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3x3fij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752887115,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3x9j2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iamz_th","can_mod_post":false,"created_utc":1752889417,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_j0p635xl9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There is an objective problem not an architectural one. All architectures are MLPs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3x9j2a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is an objective problem not an architectural one. All architectures are MLPs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3x9j2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752889417,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3xdhmo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"meatycowboy","can_mod_post":false,"created_utc":1752890923,"send_replies":true,"parent_id":"t3_1m3amtu","score":1,"author_fullname":"t2_8j8afrcr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mamba is the only big one I know of","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3xdhmo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mamba is the only big one I know of&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3xdhmo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752890923,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3vjbr3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ILoveMy2Balls","can_mod_post":false,"created_utc":1752868573,"send_replies":true,"parent_id":"t3_1m3amtu","score":0,"author_fullname":"t2_1nisx8ggay","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"mamba and rwkv are popular","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3vjbr3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mamba and rwkv are popular&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3vjbr3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752868573,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3wf301","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"asdrabael1234","can_mod_post":false,"created_utc":1752878484,"send_replies":true,"parent_id":"t1_n3w7inq","score":5,"author_fullname":"t2_9f972xt1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You don't know if something else will work better or not without alternatives to test on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3wf301","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don&amp;#39;t know if something else will work better or not without alternatives to test on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m3amtu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3wf301/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752878484,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n3w7inq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Terminator857","can_mod_post":false,"created_utc":1752875936,"send_replies":true,"parent_id":"t3_1m3amtu","score":-7,"author_fullname":"t2_m40tjcn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Why do you want alternative to transformers?  If it works, then build upon it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3w7inq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why do you want alternative to transformers?  If it works, then build upon it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m3amtu/is_there_any_promising_alternative_to_transformers/n3w7inq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752875936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m3amtu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
