import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I'm running Ollama &amp; OpenWebUI on a headless Linux server, as Docker (with Compose) containers, with an NVIDIA GPU. This setup works great, but I want to add MCP servers to my environment, to improve the results from Ollama invocations.\\n\\nThe [documentation for OpenWebUI](https://docs.openwebui.com/openapi-servers/mcp/) suggests running a single container per MCP server. However, that will get unwieldy quickly.\\n\\nHow are other people exposing multiple MCP servers as a *singular* Docker service, as part of their Docker Compose stack?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Manage multiple MCP servers for Ollama + OpenWebUI as Docker service","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lx0b5w","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.6,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lophktmpt","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752217473,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m running Ollama &amp;amp; OpenWebUI on a headless Linux server, as Docker (with Compose) containers, with an NVIDIA GPU. This setup works great, but I want to add MCP servers to my environment, to improve the results from Ollama invocations.&lt;/p&gt;\\n\\n&lt;p&gt;The &lt;a href=\\"https://docs.openwebui.com/openapi-servers/mcp/\\"&gt;documentation for OpenWebUI&lt;/a&gt; suggests running a single container per MCP server. However, that will get unwieldy quickly.&lt;/p&gt;\\n\\n&lt;p&gt;How are other people exposing multiple MCP servers as a &lt;em&gt;singular&lt;/em&gt; Docker service, as part of their Docker Compose stack?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lx0b5w","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"trevorstr","discussion_type":null,"num_comments":1,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lx0b5w/manage_multiple_mcp_servers_for_ollama_openwebui/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lx0b5w/manage_multiple_mcp_servers_for_ollama_openwebui/","subreddit_subscribers":497503,"created_utc":1752217473,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ipktg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Altruistic_Heat_9531","can_mod_post":false,"created_utc":1752225767,"send_replies":true,"parent_id":"t3_1lx0b5w","score":2,"author_fullname":"t2_9sh0mgya","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gotta be honest with you, you just moving complexity arround, not reducing it. Either you spend all resource managing docker image or managing combine build in a single image.\\n\\nHave 2 or 3 docker-compose.yml\\n\\n1 for your frontend e.g openwebui\\n\\n1 for serving e.g ollama or vLLM\\n\\n1 for multiple mcp's.\\n\\nor you can combine mcp's compose with openwebui compose\\n\\nJust make sure each docker-compose.yml is connected with the same bridged network.\\n\\n    # front/docker-compose.yml\\n    services:\\n      front:\\n        ...\\n        networks:\\n          - some-net\\n    networks:\\n      some-net:\\n        driver: bridge\\n    \\n    # mcp/docker-compose.yml\\n    services:\\n      # ...\\n    networks:\\n      network1:\\n        name: some-net\\n        external: true\\n\\nAdded bonus that you can convert these workflow into kube service.\\n\\nIf you want to reduce storage usage. **USE THE SAME BASE CONTAINER IMAGE**  for all the built.\\n\\n**If you really trully wants single image docker.** \\n\\nuse uv or any venv. since many mcp is written on python.\\n\\non Dockerfile just copy paste build from multiple MCPs dockerfile, and provide neccessary src build file. make sure each mcp got its own venv. \\n\\n  \\nBut trust me, just do 1 mcp / image","edited":1752226163,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ipktg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gotta be honest with you, you just moving complexity arround, not reducing it. Either you spend all resource managing docker image or managing combine build in a single image.&lt;/p&gt;\\n\\n&lt;p&gt;Have 2 or 3 docker-compose.yml&lt;/p&gt;\\n\\n&lt;p&gt;1 for your frontend e.g openwebui&lt;/p&gt;\\n\\n&lt;p&gt;1 for serving e.g ollama or vLLM&lt;/p&gt;\\n\\n&lt;p&gt;1 for multiple mcp&amp;#39;s.&lt;/p&gt;\\n\\n&lt;p&gt;or you can combine mcp&amp;#39;s compose with openwebui compose&lt;/p&gt;\\n\\n&lt;p&gt;Just make sure each docker-compose.yml is connected with the same bridged network.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;# front/docker-compose.yml\\nservices:\\n  front:\\n    ...\\n    networks:\\n      - some-net\\nnetworks:\\n  some-net:\\n    driver: bridge\\n\\n# mcp/docker-compose.yml\\nservices:\\n  # ...\\nnetworks:\\n  network1:\\n    name: some-net\\n    external: true\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Added bonus that you can convert these workflow into kube service.&lt;/p&gt;\\n\\n&lt;p&gt;If you want to reduce storage usage. &lt;strong&gt;USE THE SAME BASE CONTAINER IMAGE&lt;/strong&gt;  for all the built.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;If you really trully wants single image docker.&lt;/strong&gt; &lt;/p&gt;\\n\\n&lt;p&gt;use uv or any venv. since many mcp is written on python.&lt;/p&gt;\\n\\n&lt;p&gt;on Dockerfile just copy paste build from multiple MCPs dockerfile, and provide neccessary src build file. make sure each mcp got its own venv. &lt;/p&gt;\\n\\n&lt;p&gt;But trust me, just do 1 mcp / image&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lx0b5w/manage_multiple_mcp_servers_for_ollama_openwebui/n2ipktg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752225767,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lx0b5w","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),a=()=>e.jsx(t,{data:l});export{a as default};
