import{j as e}from"./index-BVRZ7CYH.js";import{R as l}from"./RedditPostRenderer-CNEPJF1Q.js";import"./index-DEfHl5U1.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey r/LocalLLaMA! I managed to **dynamically quantize** the full DeepSeek R1 671B MoE to 1.58bits in GGUF format. The trick is **not to quantize all layers**, but quantize only the MoE layers to 1.5bit, and leave attention and other layers in 4 or 6bit.\\n\\n|MoE Bits|Type|Disk Size|Accuracy|HF Link|\\n|:-|:-|:-|:-|:-|\\n|1.58bit|IQ1\\\\_S|**131GB**|Fair|[Link](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S)|\\n|1.73bit|IQ1\\\\_M|**158GB**|Good|[Link](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_M)|\\n|2.22bit|IQ2\\\\_XXS|**183GB**|Better|[Link](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ2_XXS)|\\n|2.51bit|Q2\\\\_K\\\\_XL|**212GB**|Best|[Link](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-Q2_K_XL)|\\n\\nYou can get **140 tokens / s** for throughput and 14 tokens /s for single user inference on 2x H100 80GB GPUs with all layers offloaded. A 24GB GPU like RTX 4090 should be able to get at least 1 to 3 tokens / s.\\n\\nIf we naively quantize all layers to 1.5bit (-1, 0, 1), the model will fail dramatically, since it'll produce **gibberish** and **infinite repetitions**. I selectively leave all attention layers in 4/6bit, and leave the first 3 transformer dense layers in 4/6bit. The MoE layers take up 88% of all space, so we can leave them in 1.5bit. We get in total a weighted sum of 1.58bits!\\n\\nI asked it the 1.58bit model to create Flappy Bird with 10 conditions (like random colors, a best score etc), and it did pretty well! Using a generic non dynamically quantized model will fail miserably - there will be no output at all!\\n\\n[Flappy Bird game made by 1.58bit R1](https://i.redd.it/k8nfun2ezjfe1.gif)\\n\\nThere's more details in the blog here: [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic) The link to the 1.58bit GGUF is here: [https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1\\\\_S](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S) You should be able to run it in your favorite inference tool if it supports i matrix quants. No need to re-update llama.cpp.\\n\\nA reminder on DeepSeek's chat template (for distilled versions as well) - it auto adds a BOS - do not add it manually!\\n\\n\`&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;What is 1+1?&lt;｜Assistant｜&gt;It's 2.&lt;｜end▁of▁sentence｜&gt;&lt;｜User｜&gt;Explain more!&lt;｜Assistant｜&gt;\`\\n\\nTo know how many layers to offload to the GPU, I approximately calculated it as below:\\n\\n|Quant|File Size|24GB GPU|80GB GPU|2x80GB GPU|\\n|:-|:-|:-|:-|:-|\\n|1.58bit|131GB|7|33|All layers 61|\\n|1.73bit|158GB|5|26|57|\\n|2.22bit|183GB|4|22|49|\\n|2.51bit|212GB|2|19|32|\\n\\nAll other GGUFs for R1 are here: [https://huggingface.co/unsloth/DeepSeek-R1-GGUF](https://huggingface.co/unsloth/DeepSeek-R1-GGUF) There's also GGUFs and dynamic 4bit bitsandbytes quants and others for all other distilled versions (Qwen, Llama etc) at [https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5](https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"1.58bit DeepSeek R1 - 131GB Dynamic GGUF","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"media_metadata":{"k8nfun2ezjfe1":{"status":"valid","e":"AnimatedImage","m":"image/gif","p":[{"y":108,"x":108,"u":"https://preview.redd.it/k8nfun2ezjfe1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=23d5ebe8eb52b2f05361eb7fd0d9d2ae8d12e8a1"},{"y":216,"x":216,"u":"https://preview.redd.it/k8nfun2ezjfe1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=454b5a7d438559134999f6822fa703258cca1a94"},{"y":320,"x":320,"u":"https://preview.redd.it/k8nfun2ezjfe1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=5ae54ef35387d76c5015363aa97d1cc67e3f57b7"}],"s":{"y":480,"gif":"https://i.redd.it/k8nfun2ezjfe1.gif","mp4":"https://preview.redd.it/k8nfun2ezjfe1.gif?format=mp4&amp;s=03d8cf4aacad9d711799a8376ea4189bc57880ea","x":480},"id":"k8nfun2ezjfe1"}},"name":"t3_1ibbloy","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.99,"author_flair_background_color":null,"ups":1685,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_5wukhd4","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":1685,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/Zcp-HHNhodXZpXJ8zaEFT2wttuYa8CrCOUcS3Hlnn3w.jpg","edited":1738127475,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1737991440,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey &lt;a href=\\"/r/LocalLLaMA\\"&gt;r/LocalLLaMA&lt;/a&gt;! I managed to &lt;strong&gt;dynamically quantize&lt;/strong&gt; the full DeepSeek R1 671B MoE to 1.58bits in GGUF format. The trick is &lt;strong&gt;not to quantize all layers&lt;/strong&gt;, but quantize only the MoE layers to 1.5bit, and leave attention and other layers in 4 or 6bit.&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;MoE Bits&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Type&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Disk Size&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Accuracy&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;HF Link&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1.58bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;IQ1_S&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;131GB&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Fair&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S\\"&gt;Link&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1.73bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;IQ1_M&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;158GB&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Good&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_M\\"&gt;Link&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2.22bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;IQ2_XXS&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;183GB&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Better&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ2_XXS\\"&gt;Link&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2.51bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Q2_K_XL&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;strong&gt;212GB&lt;/strong&gt;&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;Best&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;&lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-Q2_K_XL\\"&gt;Link&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;You can get &lt;strong&gt;140 tokens / s&lt;/strong&gt; for throughput and 14 tokens /s for single user inference on 2x H100 80GB GPUs with all layers offloaded. A 24GB GPU like RTX 4090 should be able to get at least 1 to 3 tokens / s.&lt;/p&gt;\\n\\n&lt;p&gt;If we naively quantize all layers to 1.5bit (-1, 0, 1), the model will fail dramatically, since it&amp;#39;ll produce &lt;strong&gt;gibberish&lt;/strong&gt; and &lt;strong&gt;infinite repetitions&lt;/strong&gt;. I selectively leave all attention layers in 4/6bit, and leave the first 3 transformer dense layers in 4/6bit. The MoE layers take up 88% of all space, so we can leave them in 1.5bit. We get in total a weighted sum of 1.58bits!&lt;/p&gt;\\n\\n&lt;p&gt;I asked it the 1.58bit model to create Flappy Bird with 10 conditions (like random colors, a best score etc), and it did pretty well! Using a generic non dynamically quantized model will fail miserably - there will be no output at all!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://i.redd.it/k8nfun2ezjfe1.gif\\"&gt;Flappy Bird game made by 1.58bit R1&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s more details in the blog here: &lt;a href=\\"https://unsloth.ai/blog/deepseekr1-dynamic\\"&gt;https://unsloth.ai/blog/deepseekr1-dynamic&lt;/a&gt; The link to the 1.58bit GGUF is here: &lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S\\"&gt;https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S&lt;/a&gt; You should be able to run it in your favorite inference tool if it supports i matrix quants. No need to re-update llama.cpp.&lt;/p&gt;\\n\\n&lt;p&gt;A reminder on DeepSeek&amp;#39;s chat template (for distilled versions as well) - it auto adds a BOS - do not add it manually!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;&amp;lt;｜begin▁of▁sentence｜&amp;gt;&amp;lt;｜User｜&amp;gt;What is 1+1?&amp;lt;｜Assistant｜&amp;gt;It&amp;#39;s 2.&amp;lt;｜end▁of▁sentence｜&amp;gt;&amp;lt;｜User｜&amp;gt;Explain more!&amp;lt;｜Assistant｜&amp;gt;&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;To know how many layers to offload to the GPU, I approximately calculated it as below:&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Quant&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;File Size&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;24GB GPU&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;80GB GPU&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;2x80GB GPU&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1.58bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;131GB&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;7&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;33&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;All layers 61&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;1.73bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;158GB&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;5&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;26&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;57&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2.22bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;183GB&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;4&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;22&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;49&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;2.51bit&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;212GB&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;2&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;19&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;32&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;All other GGUFs for R1 are here: &lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-GGUF\\"&gt;https://huggingface.co/unsloth/DeepSeek-R1-GGUF&lt;/a&gt; There&amp;#39;s also GGUFs and dynamic 4bit bitsandbytes quants and others for all other distilled versions (Qwen, Llama etc) at &lt;a href=\\"https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5\\"&gt;https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?auto=webp&amp;s=15786bbf8fa654f9c457319fd2509fc682f49b99","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38be96fe7ba592d724845ec508925c2e2d0437a9","width":108,"height":58},{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=216add24eeddf96721764be15a01323d3289a098","width":216,"height":116},{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=146aafa2effa94c6a92be3a1e52d5d1c5dada77c","width":320,"height":172},{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc7cd6ab7b35a273b107dce1a4113ba2c9dcca51","width":640,"height":345},{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f708695c420ae4c27a7b7b045b263ef095a49773","width":960,"height":518},{"url":"https://external-preview.redd.it/uHOmNdCTHW-Q1CBdw01aifeSpeyvgfhjJI_lcC-SH5c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=674cf56e451c44a0c9ae525a6f1cb1a1dd92eab0","width":1080,"height":583}],"variants":{},"id":"xSdGWArWU6LYyDRL5oP5FnuIAfKsN1Z6N1wc8N_fOQY"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1ibbloy","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"danielhanchen","discussion_type":null,"num_comments":601,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/","subreddit_subscribers":492315,"created_utc":1737991440,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ifvas","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lissanro","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9hmt1r","score":19,"author_fullname":"t2_fpfao9g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They already shared it in their blog article here: [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic) \\\\- see the \\"Prompt and results\\" section.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ifvas","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They already shared it in their blog article here: &lt;a href=\\"https://unsloth.ai/blog/deepseekr1-dynamic\\"&gt;https://unsloth.ai/blog/deepseekr1-dynamic&lt;/a&gt; - see the &amp;quot;Prompt and results&amp;quot; section.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ifvas/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738008782,"author_flair_text":null,"treatment_tags":[],"created_utc":1738008782,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9napiq","id":"m9napiq","parent_id":"t1_m9j7un7","depth":4,"children":["m9napiq","m9kc4ya"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9j7un7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9hmt1r","score":10,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh yes for the prompt used to test the model - u/Lissanro mentioned the blog (scroll all the way down) :) All experiments and outputs are here: [https://docs.unsloth.ai/basics/deepseek-r1-dynamic-1.58-bit](https://docs.unsloth.ai/basics/deepseek-r1-dynamic-1.58-bit)\\n\\nOr did you mean the chat template format?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9j7un7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes for the prompt used to test the model - &lt;a href=\\"/u/Lissanro\\"&gt;u/Lissanro&lt;/a&gt; mentioned the blog (scroll all the way down) :) All experiments and outputs are here: &lt;a href=\\"https://docs.unsloth.ai/basics/deepseek-r1-dynamic-1.58-bit\\"&gt;https://docs.unsloth.ai/basics/deepseek-r1-dynamic-1.58-bit&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Or did you mean the chat template format?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9j7un7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738016658,"author_flair_text":null,"treatment_tags":[],"created_utc":1738016658,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hmt1r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Secure_Reflection409","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gxkye","score":7,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Would you mind sharing the prompt, too?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9hmt1r","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would you mind sharing the prompt, too?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hmt1r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738000680,"author_flair_text":null,"treatment_tags":[],"created_utc":1738000680,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9qgugo","id":"m9qgugo","parent_id":"t1_m9jjkv1","depth":4,"children":["m9qgugo"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jjkv1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9javnf","score":8,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh yes that is doable - 1.58bit might take a bit longer sadly - doing the imatrix will take ages :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jjkv1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes that is doable - 1.58bit might take a bit longer sadly - doing the imatrix will take ages :(&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jjkv1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738020203,"author_flair_text":null,"treatment_tags":[],"created_utc":1738020203,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m9javnf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Bukt","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gxkye","score":6,"author_fullname":"t2_1f72g809","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are incredible. Are you able to make similar dynamic GGUF's for Deepseek-V3 chat as well?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9javnf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are incredible. Are you able to make similar dynamic GGUF&amp;#39;s for Deepseek-V3 chat as well?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9javnf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738017542,"author_flair_text":null,"treatment_tags":[],"created_utc":1738017542,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_ma4m7ki","id":"ma4m7ki","parent_id":"t1_m9gxkye","depth":2,"children":["ma4m7ki"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gxkye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993636,"send_replies":true,"parent_id":"t1_m9gtlyj","score":91,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you a lot! Appreciate it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gxkye","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you a lot! Appreciate it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gxkye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993636,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":91}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9m750u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zeikos","can_mod_post":false,"created_utc":1738061195,"send_replies":true,"parent_id":"t1_m9gtlyj","score":6,"author_fullname":"t2_9asvt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The CoT likely catches a lot of problems before they materialize.  \\n\\nI'd be curious in seeing a size by size zero-temp comparison of the &lt;thinking&gt; output.  \\n\\nThis to me hints that there is a considerable source of inefficiency yet to be understood/conquered.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9m750u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The CoT likely catches a lot of problems before they materialize.  &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d be curious in seeing a size by size zero-temp comparison of the &amp;lt;thinking&amp;gt; output.  &lt;/p&gt;\\n\\n&lt;p&gt;This to me hints that there is a considerable source of inefficiency yet to be understood/conquered.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9m750u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738061195,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":4,"name":"t1_m9jl9q7","id":"m9jl9q7","parent_id":"t1_m9gtlyj","depth":1,"children":["m9jl9q7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gtlyj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SomeOddCodeGuy","can_mod_post":false,"created_utc":1737992494,"send_replies":true,"parent_id":"t3_1ibbloy","score":399,"author_fullname":"t2_kle75fbd6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I cannot express how insane it is to me that a 1bit quantized MoE was able to write that flappy bird without just dumping out tons of bugs in the code. *Especially* with it being an MoE.\\n\\nExcellent work on figuring this out.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gtlyj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I cannot express how insane it is to me that a 1bit quantized MoE was able to write that flappy bird without just dumping out tons of bugs in the code. &lt;em&gt;Especially&lt;/em&gt; with it being an MoE.&lt;/p&gt;\\n\\n&lt;p&gt;Excellent work on figuring this out.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gtlyj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":399}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gtsms","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737992547,"send_replies":true,"parent_id":"t1_m9gsdtq","score":73,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gtsms","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gtsms/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992547,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":73}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9j7ymm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9hge8e","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh yes I think I saw that video as well!! :) Matthew always makes good videos :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9j7ymm","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes I think I saw that video as well!! :) Matthew always makes good videos :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9j7ymm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738016690,"author_flair_text":null,"treatment_tags":[],"created_utc":1738016690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hge8e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"moldyjellybean","can_mod_post":false,"created_utc":1737998914,"send_replies":true,"parent_id":"t1_m9gsdtq","score":28,"author_fullname":"t2_dxkhe2u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks OP this is amazing\\n\\nI saw this last week and was like WOW\\n\\nhttps://www.youtube.com/watch?v=bOsvI3HYHgI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hge8e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks OP this is amazing&lt;/p&gt;\\n\\n&lt;p&gt;I saw this last week and was like WOW&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.youtube.com/watch?v=bOsvI3HYHgI\\"&gt;https://www.youtube.com/watch?v=bOsvI3HYHgI&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hge8e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737998914,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gsdtq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CreepyMan121","can_mod_post":false,"created_utc":1737992137,"send_replies":true,"parent_id":"t3_1ibbloy","score":308,"author_fullname":"t2_17kw8kiwcg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"HES THE GOAT... THE GOOOOAAAT....","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gsdtq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;HES THE GOAT... THE GOOOOAAAT....&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gsdtq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992137,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":308}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":12,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9wtdtd","id":"m9wtdtd","parent_id":"t1_m9jkf9s","depth":4,"children":["m9wtdtd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jkf9s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9i34hx","score":4,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep it's actually pretty cool PTQ randomly works fine for MoEs! Yes there was a paper on that! I think the paper was saying if you saturate the model's tokens on the scaling laws, then doing lower bits will hurt.\\n\\nDeepSeek R1 I think is at max 16 trillion tokens for 671B - Llama 3 8B is 15 trillion and 4bit still functions, but smaller ones like Qwen 3B ish break down (with 15T tokens)\\n\\nSo extrapolating this, we get 8B = 15T, 671B = 1256T tokens ==&gt; so maybe lower bits will not start working anymore once we train a model with maybe 1000T tokens on 671B params","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jkf9s","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep it&amp;#39;s actually pretty cool PTQ randomly works fine for MoEs! Yes there was a paper on that! I think the paper was saying if you saturate the model&amp;#39;s tokens on the scaling laws, then doing lower bits will hurt.&lt;/p&gt;\\n\\n&lt;p&gt;DeepSeek R1 I think is at max 16 trillion tokens for 671B - Llama 3 8B is 15 trillion and 4bit still functions, but smaller ones like Qwen 3B ish break down (with 15T tokens)&lt;/p&gt;\\n\\n&lt;p&gt;So extrapolating this, we get 8B = 15T, 671B = 1256T tokens ==&amp;gt; so maybe lower bits will not start working anymore once we train a model with maybe 1000T tokens on 671B params&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jkf9s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738020470,"author_flair_text":null,"treatment_tags":[],"created_utc":1738020470,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i34hx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1738005208,"send_replies":true,"parent_id":"t1_m9gwtke","score":12,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i34hx/","num_reports":null,"locked":false,"name":"t1_m9i34hx","created":1738005208,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":1,"name":"t1_m9h8g9k","id":"m9h8g9k","parent_id":"t1_m9gwtke","depth":2,"children":["m9h8g9k"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gwtke","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993416,"send_replies":true,"parent_id":"t1_m9guubv","score":77,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh even more fantastic!! :) I'm surprised it actually works :) I expected it to bomb since BitNet needs to train stuff from scratch, whilst post quantization shouldn't randomnly just \\"work\\", but it seems to function OK!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gwtke","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh even more fantastic!! :) I&amp;#39;m surprised it actually works :) I expected it to bomb since BitNet needs to train stuff from scratch, whilst post quantization shouldn&amp;#39;t randomnly just &amp;quot;work&amp;quot;, but it seems to function OK!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gwtke/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993416,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":77}},{"kind":"more","data":{"count":1,"name":"t1_m9lty26","id":"m9lty26","parent_id":"t1_m9guubv","depth":1,"children":["m9lty26"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9guubv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brown2green","can_mod_post":false,"created_utc":1737992849,"send_replies":true,"parent_id":"t3_1ibbloy","score":144,"author_fullname":"t2_f010l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;The trick is not to quantize all layers, but quantize only the MoE layers to 1.5bit, and leave attention and other layers in 4 or 6bit.\\n\\nIncidentally, not even the original BitNet paper suggests to quantize everything to low-precision. The authors keep attention, input/output layers and embeddings in \\"high-precision\\" (8-bit). So this is the right way.\\n\\nEDIT: details were in the 1-bit BitNet paper: https://arxiv.org/pdf/2310.11453\\n\\n&gt; [...] As shown in Figure 2, BitNet uses the same layout as Transformers, stacking blocks of self-attention and feed-forward networks. Compared with vanilla Transformer, BitNet uses BitLinear (Eq. 11) instead of conventional matrix multiplication, which employs binarized (i.e., 1-bit) model weights. We leave the other components high-precision, e.g., 8-bit in our experiments. We summarized the reasons as follows. First, the residual connections and the layer normalization contribute negligible computation costs to large language models. Second, the computation cost of QKV transformation is much smaller than the parametric projection as the model grows larger. Third, we preserve the precision for the input/output embedding because the language models have to use high-precision probabilities to perform sampling.","edited":1737993217,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9guubv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The trick is not to quantize all layers, but quantize only the MoE layers to 1.5bit, and leave attention and other layers in 4 or 6bit.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Incidentally, not even the original BitNet paper suggests to quantize everything to low-precision. The authors keep attention, input/output layers and embeddings in &amp;quot;high-precision&amp;quot; (8-bit). So this is the right way.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: details were in the 1-bit BitNet paper: &lt;a href=\\"https://arxiv.org/pdf/2310.11453\\"&gt;https://arxiv.org/pdf/2310.11453&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;[...] As shown in Figure 2, BitNet uses the same layout as Transformers, stacking blocks of self-attention and feed-forward networks. Compared with vanilla Transformer, BitNet uses BitLinear (Eq. 11) instead of conventional matrix multiplication, which employs binarized (i.e., 1-bit) model weights. We leave the other components high-precision, e.g., 8-bit in our experiments. We summarized the reasons as follows. First, the residual connections and the layer normalization contribute negligible computation costs to large language models. Second, the computation cost of QKV transformation is much smaller than the parametric projection as the model grows larger. Third, we preserve the precision for the input/output embedding because the language models have to use high-precision probabilities to perform sampling.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9guubv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992849,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":144}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jn7rf","id":"m9jn7rf","parent_id":"t1_m9h1m3x","depth":2,"children":["m9jn7rf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h1m3x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737994787,"send_replies":true,"parent_id":"t1_m9h12pu","score":16,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks a lot! :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h1m3x","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks a lot! :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h1m3x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994787,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h12pu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VegaKH","can_mod_post":false,"created_utc":1737994636,"send_replies":true,"parent_id":"t3_1ibbloy","score":58,"author_fullname":"t2_11wjla","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This will still be too big for me to handle, but just wanted to say thank you for all the work you do creating quants of the best models. We appreciate it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h12pu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This will still be too big for me to handle, but just wanted to say thank you for all the work you do creating quants of the best models. We appreciate it!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h12pu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994636,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":58}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":55,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":12,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gummu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gu7at","score":9,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gummu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gummu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992788,"author_flair_text":null,"treatment_tags":[],"created_utc":1737992788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gu7at","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1737992665,"send_replies":true,"parent_id":"t1_m9gu0aq","score":12,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746984226,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gu7at/","num_reports":null,"locked":false,"name":"t1_m9gu7at","created":1737992665,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9jkicr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h4og4","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes! On of my goals was to do more extensive benchmarking!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jkicr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes! On of my goals was to do more extensive benchmarking!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jkicr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738020497,"author_flair_text":null,"treatment_tags":[],"created_utc":1738020497,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h4og4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Equivalent-Bet-8771","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gu0aq","score":6,"author_fullname":"t2_l16sej0pt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes please. I'd like to see how your special sauce compares to the full precision version.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9h4og4","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes please. I&amp;#39;d like to see how your special sauce compares to the full precision version.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h4og4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995648,"author_flair_text":"textgen web UI","treatment_tags":[],"created_utc":1737995648,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_m9jmqxb","id":"m9jmqxb","parent_id":"t1_m9gu0aq","depth":2,"children":["m9jmqxb"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gu0aq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737992608,"send_replies":true,"parent_id":"t1_m9gsf8h","score":74,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh yes more extensive benchmarks would be cool :) I just couldn't wait and just posted it :))\\n\\nQualitatively it looks reasonably good - I was actually shocked it worked lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gu0aq","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes more extensive benchmarks would be cool :) I just couldn&amp;#39;t wait and just posted it :))&lt;/p&gt;\\n\\n&lt;p&gt;Qualitatively it looks reasonably good - I was actually shocked it worked lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gu0aq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992608,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":74}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gsf8h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1ibbloy","score":55,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746982255,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gsf8h/","num_reports":null,"locked":false,"name":"t1_m9gsf8h","created":1737992149,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737992149,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9votsm","id":"m9votsm","parent_id":"t1_m9joddb","depth":2,"children":["m9votsm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9joddb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738021748,"send_replies":true,"parent_id":"t1_m9i1und","score":15,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Actually I had a 127GB version, but it didn't go that good - so I have to increase it by 4GB sorry :(\\n\\nBut anyways offloading 60 layers should work fine!\\n\\nYou need (VRAM + RAM) around 140GB - you don't need it to fit all in GPU!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9joddb","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually I had a 127GB version, but it didn&amp;#39;t go that good - so I have to increase it by 4GB sorry :(&lt;/p&gt;\\n\\n&lt;p&gt;But anyways offloading 60 layers should work fine!&lt;/p&gt;\\n\\n&lt;p&gt;You need (VRAM + RAM) around 140GB - you don&amp;#39;t need it to fit all in GPU!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9joddb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021748,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9k6avz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"samelaaaa","can_mod_post":false,"created_utc":1738027489,"send_replies":true,"parent_id":"t1_m9i1und","score":10,"author_fullname":"t2_gefyf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Jesus, I'm interested to learn more about the power and cooling logistics of a 4x5090 rig lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9k6avz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jesus, I&amp;#39;m interested to learn more about the power and cooling logistics of a 4x5090 rig lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k6avz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738027489,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":9,"name":"t1_m9jt70z","id":"m9jt70z","parent_id":"t1_m9jppk2","depth":2,"children":["m9jt70z","m9p03ee"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jppk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lissanro","can_mod_post":false,"created_utc":1738022181,"send_replies":true,"parent_id":"t1_m9i1und","score":5,"author_fullname":"t2_fpfao9g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Since it is MoE with many small experts, it should still have acceptable performance even with partial offloading to RAM. At least, I hope so - I am still downloading to try on my 4x3090 rig.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jppk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Since it is MoE with many small experts, it should still have acceptable performance even with partial offloading to RAM. At least, I hope so - I am still downloading to try on my 4x3090 rig.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jppk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738022181,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_m9id1mf","id":"m9id1mf","parent_id":"t1_m9i1und","depth":1,"children":["m9id1mf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i1und","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ArtyfacialIntelagent","can_mod_post":false,"created_utc":1738004849,"send_replies":true,"parent_id":"t3_1ibbloy","score":26,"author_fullname":"t2_e2wzka14w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This was a massive disappointment - how could you *just* exceed the 128 GB limit for the 4x5090 rigs all of us are going to build next week? ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i1und","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was a massive disappointment - how could you &lt;em&gt;just&lt;/em&gt; exceed the 128 GB limit for the 4x5090 rigs all of us are going to build next week? ;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i1und/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738004849,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9h5h4l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737995872,"send_replies":true,"parent_id":"t1_m9h43g3","score":17,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":":)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h5h4l","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;:)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h5h4l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995872,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h43g3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Born_Fox6153","can_mod_post":false,"created_utc":1737995484,"send_replies":true,"parent_id":"t3_1ibbloy","score":42,"author_fullname":"t2_i359u2mr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unsloth’s really cooking 🔥","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h43g3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unsloth’s really cooking 🔥&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h43g3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9klmzq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thereisonlythedance","can_mod_post":false,"created_utc":1738032486,"send_replies":true,"parent_id":"t1_m9kgjwh","score":10,"author_fullname":"t2_u4wkj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I’m running the 2.5bit version (on 5x3090 + 256GB RAM) and it’s great. Getting 2 t/s but that’s giving it a 2500 token prompt to start.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9klmzq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I’m running the 2.5bit version (on 5x3090 + 256GB RAM) and it’s great. Getting 2 t/s but that’s giving it a 2500 token prompt to start.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9klmzq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738032486,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9q3px3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ll3tu","score":3,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are the real MVP","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9q3px3","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are the real MVP&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9q3px3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738105530,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1738105530,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ll3tu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738047456,"send_replies":true,"parent_id":"t1_m9kgjwh","score":6,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":":) Glad it works well!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ll3tu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;:) Glad it works well!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ll3tu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738047456,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":2,"name":"t1_m9ubz7m","id":"m9ubz7m","parent_id":"t1_m9kgjwh","depth":1,"children":["m9ubz7m"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kgjwh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1738030801,"send_replies":true,"parent_id":"t3_1ibbloy","score":24,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I thought it was a joke but it actually works. I'm getting 3.5 tok/s using 3x3090 and 128gb of ram in a very old E5-2680 using the 1.58 bit version, and its output are very similar to the R1 deepseek at the web. It's incredible, I guess the 2.51 version should be very good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9kgjwh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought it was a joke but it actually works. I&amp;#39;m getting 3.5 tok/s using 3x3090 and 128gb of ram in a very old E5-2680 using the 1.58 bit version, and its output are very similar to the R1 deepseek at the web. It&amp;#39;s incredible, I guess the 2.51 version should be very good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kgjwh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738030801,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mav0tog","id":"mav0tog","parent_id":"t1_m9lsmfv","depth":4,"children":["mav0tog"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9lsmfv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nmkd","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9hqhva","score":13,"author_fullname":"t2_rg6rx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"At this quant it will be a bit behind ChatGPT, but still pretty incredible","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lsmfv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At this quant it will be a bit behind ChatGPT, but still pretty incredible&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lsmfv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738051932,"author_flair_text":null,"treatment_tags":[],"created_utc":1738051932,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hqhva","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"roshanpr","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gxswj","score":22,"author_fullname":"t2_hw45s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"so ChatGPT at home for $3k in GPU Computaitonal power buying used.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9hqhva","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so ChatGPT at home for $3k in GPU Computaitonal power buying used.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hqhva/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738001705,"author_flair_text":null,"treatment_tags":[],"created_utc":1738001705,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":16,"name":"t1_m9l26g5","id":"m9l26g5","parent_id":"t1_m9jl23i","depth":5,"children":["m9l26g5","m9ubmt9","m9jvpo7","m9shcg8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jl23i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9i35vv","score":6,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes it should work fine!! You just need (VRAM + RAM) around 140GB and it should run smoothly!\\nFor 183GB - it should work fine!","edited":false,"author_flair_css_class":null,"name":"t1_m9jl23i","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes it should work fine!! You just need (VRAM + RAM) around 140GB and it should run smoothly!\\nFor 183GB - it should work fine!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1ibbloy","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jl23i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738020672,"author_flair_text":null,"collapsed":false,"created_utc":1738020672,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":4,"name":"t1_m9jeyky","id":"m9jeyky","parent_id":"t1_m9i35vv","depth":4,"children":["m9jeyky"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i35vv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MLDataScientist","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h9bvh","score":6,"author_fullname":"t2_3zy7pnf1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also interested in this. I have 128GB RAM and 64 GB VRAM. Combined, they are 196GB. Can I run IQ2\\\\_XXS (183GB) model even if I don't have enough CPU RAM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i35vv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also interested in this. I have 128GB RAM and 64 GB VRAM. Combined, they are 196GB. Can I run IQ2_XXS (183GB) model even if I don&amp;#39;t have enough CPU RAM?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i35vv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738005219,"author_flair_text":null,"treatment_tags":[],"created_utc":1738005219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":5,"name":"t1_m9hvxtr","id":"m9hvxtr","parent_id":"t1_m9h9bvh","depth":3,"children":["m9hvxtr","m9jkxdv"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h9bvh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gxswj","score":15,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you need as much ram as the binary size or just enough for the remaining?   So if I have 96gb vram and 128gb system ram.  Can I run the 200B model?   Is there a reason you stopped at 2.51?   Can you do dynamic gguf up to say Q4?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9h9bvh","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you need as much ram as the binary size or just enough for the remaining?   So if I have 96gb vram and 128gb system ram.  Can I run the 200B model?   Is there a reason you stopped at 2.51?   Can you do dynamic gguf up to say Q4?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h9bvh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996936,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1737996936,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"more","data":{"count":7,"name":"t1_m9pzexe","id":"m9pzexe","parent_id":"t1_m9gxswj","depth":2,"children":["m9pzexe","m9gy1xb"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gxswj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993699,"send_replies":true,"parent_id":"t1_m9gv1bv","score":35,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh 96GB of VRAM hmm you can offload around 40 layers - if you have enough RAM, you should be able to get maybe 20 to 40 tokens per second","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gxswj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh 96GB of VRAM hmm you can offload around 40 layers - if you have enough RAM, you should be able to get maybe 20 to 40 tokens per second&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gxswj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993699,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jsue0","id":"m9jsue0","parent_id":"t1_m9jkfqk","depth":3,"children":["m9jsue0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jkfqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"realJoeTrump","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9iqlqa","score":7,"author_fullname":"t2_pi2ewl0zl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"on one. I'm using supermicro server motherboard.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9jkfqk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;on one. I&amp;#39;m using supermicro server motherboard.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jkfqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738020474,"author_flair_text":null,"treatment_tags":[],"created_utc":1738020474,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":4,"name":"t1_m9jmrkm","id":"m9jmrkm","parent_id":"t1_m9iqlqa","depth":2,"children":["m9jmrkm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9iqlqa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cmndr_spanky","can_mod_post":false,"created_utc":1738011809,"send_replies":true,"parent_id":"t1_m9gv1bv","score":5,"author_fullname":"t2_r41b1kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just curious are those 3090s all on one motherboard or is it using a network attached multi-pc thing ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9iqlqa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just curious are those 3090s all on one motherboard or is it using a network attached multi-pc thing ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iqlqa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738011809,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gv1bv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"realJoeTrump","can_mod_post":false,"created_utc":1737992905,"send_replies":true,"parent_id":"t3_1ibbloy","score":19,"author_fullname":"t2_pi2ewl0zl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Cool! what is the inference speed you guess i can get? i have 4x 3090","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gv1bv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool! what is the inference speed you guess i can get? i have 4x 3090&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gv1bv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992905,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gwdkd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737993290,"send_replies":true,"parent_id":"t1_m9gw0c2","score":20,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep this was what happened when we tested it too. Please do test and share any results! :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gwdkd","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep this was what happened when we tested it too. Please do test and share any results! :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gwdkd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993290,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9vv8za","id":"m9vv8za","parent_id":"t1_m9gxw98","depth":2,"children":["m9vv8za","m9lwqad"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gxw98","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993726,"send_replies":true,"parent_id":"t1_m9gw0c2","score":15,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh yes that was a non dynamic quant - hopefully the new one is much better!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gxw98","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes that was a non dynamic quant - hopefully the new one is much better!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gxw98/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993726,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gw0c2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kryptkpr","can_mod_post":false,"created_utc":1737993184,"send_replies":true,"parent_id":"t3_1ibbloy","score":16,"author_fullname":"t2_30i1a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Incredible work! I've been playing with Q2KS but found it unable to complete basic tasks, going to give this one a shot next.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gw0c2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Incredible work! I&amp;#39;ve been playing with Q2KS but found it unable to complete basic tasks, going to give this one a shot next.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gw0c2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993184,"author_flair_text":"Llama 3","treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gqujn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737991687,"send_replies":true,"parent_id":"t1_m9gqorb","score":9,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":":)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gqujn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;:)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gqujn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737991687,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gqorb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thin_Ad7360","can_mod_post":false,"created_utc":1737991640,"send_replies":true,"parent_id":"t3_1ibbloy","score":15,"author_fullname":"t2_2mspehin","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Niubi","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gqorb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Niubi&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gqorb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737991640,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9kk9d3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LycanWolfe","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ino6x","score":7,"author_fullname":"t2_14i3kw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes please!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9kk9d3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes please!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kk9d3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738032028,"author_flair_text":null,"treatment_tags":[],"created_utc":1738032028,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9rs6j5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Moist-Mongoose4467","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9pn9ee","score":4,"author_fullname":"t2_5q5x9ckg","approved_by":null,"mod_note":null,"all_awardings":[],"body":"We need more folks to be very specific about what they have in their rigs. [PCPartPicker.com](http://PCPartPicker.com) does not have an AI build section, so I have to troll Reddit and try to cobble together the parts without any guarantee that they will end up working together. I appreciate when folks like you share the CPU, RAM, and graphics card. I am still in need of which motherboard, power supply, and the winning lotto numbers so that I can pay for all of it.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m9rs6j5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need more folks to be very specific about what they have in their rigs. &lt;a href=\\"http://PCPartPicker.com\\"&gt;PCPartPicker.com&lt;/a&gt; does not have an AI build section, so I have to troll Reddit and try to cobble together the parts without any guarantee that they will end up working together. I appreciate when folks like you share the CPU, RAM, and graphics card. I am still in need of which motherboard, power supply, and the winning lotto numbers so that I can pay for all of it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1ibbloy","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9rs6j5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738125679,"author_flair_text":null,"treatment_tags":[],"created_utc":1738125679,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9pn9ee","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ozzeruk82","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9pmy4h","score":4,"author_fullname":"t2_kt5g5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So I guess that's over 1 token per second, with a lot of fixing of settings to come.\\n\\nThis is on an old Ryzen 3700XT, 128GB ram, 3090 with 24GB VRAM, using a new NVME SSD. Llama.cpp compiled earlier today and the model from unsloth's hf.","edited":false,"author_flair_css_class":null,"name":"t1_m9pn9ee","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I guess that&amp;#39;s over 1 token per second, with a lot of fixing of settings to come.&lt;/p&gt;\\n\\n&lt;p&gt;This is on an old Ryzen 3700XT, 128GB ram, 3090 with 24GB VRAM, using a new NVME SSD. Llama.cpp compiled earlier today and the model from unsloth&amp;#39;s hf.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1ibbloy","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9pn9ee/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738100740,"author_flair_text":null,"collapsed":false,"created_utc":1738100740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9pmy4h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ozzeruk82","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9pmpzd","score":5,"author_fullname":"t2_kt5g5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"llama\\\\_perf\\\\_sampler\\\\_print:    sampling time =      54.40 ms /   617 runs   (    0.09 ms per token, 11342.75 tokens per second)\\n\\nllama\\\\_perf\\\\_context\\\\_print:        load time =  355347.99 ms\\n\\nllama\\\\_perf\\\\_context\\\\_print: prompt eval time =   36626.19 ms /    31 tokens ( 1181.49 ms per token,     0.85 tokens per second)\\n\\nllama\\\\_perf\\\\_context\\\\_print:        eval time =  508790.83 ms /   585 runs   (  869.73 ms per token,     1.15 tokens per second)\\n\\nllama\\\\_perf\\\\_context\\\\_print:       total time =  545787.39 ms /   616 tokens","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9pmy4h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;llama_perf_sampler_print:    sampling time =      54.40 ms /   617 runs   (    0.09 ms per token, 11342.75 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;llama_perf_context_print:        load time =  355347.99 ms&lt;/p&gt;\\n\\n&lt;p&gt;llama_perf_context_print: prompt eval time =   36626.19 ms /    31 tokens ( 1181.49 ms per token,     0.85 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;llama_perf_context_print:        eval time =  508790.83 ms /   585 runs   (  869.73 ms per token,     1.15 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;llama_perf_context_print:       total time =  545787.39 ms /   616 tokens&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9pmy4h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738100653,"author_flair_text":null,"treatment_tags":[],"created_utc":1738100653,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":2,"name":"t1_maqlbry","id":"maqlbry","parent_id":"t1_m9pmpzd","depth":3,"children":["maqlbry"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9pmpzd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ozzeruk82","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ino6x","score":3,"author_fullname":"t2_kt5g5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\[Update\\\\] I have the 158GB version running now. It's going at about the speed I can type, maybe slightly quicker. I have 5 layers on the 3090, which is in 'space heater mode' going nuts. Interestingly, on HTOP I see only 13.2gb memory used out of 128GB, but my 8 gig swap file is maxed out. I was under the impression it should say the 128GB is maxed out?\\n\\nAlso I need to check my memory settings in the bios, so I reckon I can get it to go faster.\\n\\nOne thing to note - starting up the inference took a while, as in there was a couple of minutes of waiting, then it started. Okay it's just done. Here are the stats, that will get better:","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9pmpzd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[Update] I have the 158GB version running now. It&amp;#39;s going at about the speed I can type, maybe slightly quicker. I have 5 layers on the 3090, which is in &amp;#39;space heater mode&amp;#39; going nuts. Interestingly, on HTOP I see only 13.2gb memory used out of 128GB, but my 8 gig swap file is maxed out. I was under the impression it should say the 128GB is maxed out?&lt;/p&gt;\\n\\n&lt;p&gt;Also I need to check my memory settings in the bios, so I reckon I can get it to go faster.&lt;/p&gt;\\n\\n&lt;p&gt;One thing to note - starting up the inference took a while, as in there was a couple of minutes of waiting, then it started. Okay it&amp;#39;s just done. Here are the stats, that will get better:&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9pmpzd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738100590,"author_flair_text":null,"treatment_tags":[],"created_utc":1738100590,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ino6x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Goldkoron","can_mod_post":false,"created_utc":1738010989,"send_replies":true,"parent_id":"t1_m9i7hj7","score":15,"author_fullname":"t2_8fz90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Let me know how the speed is with that setup, I am curious","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ino6x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Let me know how the speed is with that setup, I am curious&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ino6x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738010989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9pni5b","id":"m9pni5b","parent_id":"t1_m9jxfkv","depth":2,"children":["m9pni5b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jxfkv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738024659,"send_replies":true,"parent_id":"t1_m9i7hj7","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hope it works well!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jxfkv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hope it works well!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jxfkv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738024659,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_m9mgh26","id":"m9mgh26","parent_id":"t1_m9i7hj7","depth":1,"children":["m9mgh26"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i7hj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ozzeruk82","can_mod_post":false,"created_utc":1738006426,"send_replies":true,"parent_id":"t3_1ibbloy","score":15,"author_fullname":"t2_kt5g5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very pleased I just upgraded to 128GB ram to go with my 3090 now!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i7hj7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very pleased I just upgraded to 128GB ram to go with my 3090 now!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i7hj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738006426,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":13,"name":"t1_m9nxyul","id":"m9nxyul","parent_id":"t1_m9kf7ly","depth":2,"children":["m9nxyul","m9llioj","m9lgerm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kf7ly","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Kebob-","can_mod_post":false,"created_utc":1738030359,"send_replies":true,"parent_id":"t1_m9itx7h","score":12,"author_fullname":"t2_qycj4py2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tried the IQ1_M quants on an M2 Ultra (192GB), and I'm only able to use a context size of 8192. I could maybe push it a little further, but the small context size is quite limiting for a reasoning model. I wasn't able to get it to fully finish the flappy bird example - it had only just finished with the reasoning and started writing code before i hit the context length limit. I was getting about 15 tok/sec.","edited":1738033024,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9kf7ly","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried the IQ1_M quants on an M2 Ultra (192GB), and I&amp;#39;m only able to use a context size of 8192. I could maybe push it a little further, but the small context size is quite limiting for a reasoning model. I wasn&amp;#39;t able to get it to fully finish the flappy bird example - it had only just finished with the reasoning and started writing code before i hit the context length limit. I was getting about 15 tok/sec.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kf7ly/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738030359,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"more","data":{"count":2,"name":"t1_m9kfwqe","id":"m9kfwqe","parent_id":"t1_m9itx7h","depth":1,"children":["m9kfwqe","m9vyay1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9itx7h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"grmelacz","can_mod_post":false,"created_utc":1738012733,"send_replies":true,"parent_id":"t3_1ibbloy","score":15,"author_fullname":"t2_ru4pwmtp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So…anyone with Apple Silicon and a plenty of RAM to try that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9itx7h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So…anyone with Apple Silicon and a plenty of RAM to try that?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9itx7h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738012733,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9jtshu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738023499,"send_replies":true,"parent_id":"t1_m9iwfhm","score":7,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Loll :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jtshu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Loll :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jtshu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738023499,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9iwfhm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Standard-Anybody","can_mod_post":false,"created_utc":1738013429,"send_replies":true,"parent_id":"t3_1ibbloy","score":15,"author_fullname":"t2_5bxoqu9o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey cut it out with the tanking the American stock market. /s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9iwfhm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey cut it out with the tanking the American stock market. /s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iwfhm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738013429,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_ma76an5","id":"ma76an5","parent_id":"t1_m9l7vzk","depth":3,"children":["ma76an5"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9l7vzk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1738040872,"send_replies":true,"parent_id":"t1_m9h1igv","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9l7vzk/","num_reports":null,"locked":false,"name":"t1_m9l7vzk","created":1738040872,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h1igv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737994759,"send_replies":true,"parent_id":"t1_m9gwk0f","score":19,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would suggest the sum of VRAM + RAM to be at least 140GB for 1bit, but it should be fine.\\n\\nllama.cpp and other engines have disk mmap offloading, so if you have less, it's fine, but it'll be slow","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h1igv","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would suggest the sum of VRAM + RAM to be at least 140GB for 1bit, but it should be fine.&lt;/p&gt;\\n\\n&lt;p&gt;llama.cpp and other engines have disk mmap offloading, so if you have less, it&amp;#39;s fine, but it&amp;#39;ll be slow&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h1igv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994759,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"more","data":{"count":2,"name":"t1_m9gxaxa","id":"m9gxaxa","parent_id":"t1_m9gwk0f","depth":1,"children":["m9gxaxa","m9gx4xd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gwk0f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IrisColt","can_mod_post":false,"created_utc":1737993341,"send_replies":true,"parent_id":"t3_1ibbloy","score":13,"author_fullname":"t2_c2f558x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;A 24GB GPU like RTX 4090 should be able to get at least 1 to 3 tokens / s.\\n\\nHow much RAM would I need?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gwk0f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;A 24GB GPU like RTX 4090 should be able to get at least 1 to 3 tokens / s.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;How much RAM would I need?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gwk0f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993341,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9yjqg1","id":"m9yjqg1","parent_id":"t1_m9gvw8p","depth":2,"children":["m9yjqg1","m9rpmfl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gvw8p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737993151,"send_replies":true,"parent_id":"t1_m9gv8t5","score":17,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes correcto, you'll just need to merge it yourself, we wrote about it in the blog: [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gvw8p","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes correcto, you&amp;#39;ll just need to merge it yourself, we wrote about it in the blog: &lt;a href=\\"https://unsloth.ai/blog/deepseekr1-dynamic\\"&gt;https://unsloth.ai/blog/deepseekr1-dynamic&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gvw8p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993151,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gv8t5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jnk_str","can_mod_post":false,"created_utc":1737992965,"send_replies":true,"parent_id":"t3_1ibbloy","score":12,"author_fullname":"t2_5ct4y4k6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"VLLM should run it, since it’s GGUF, right? Or is it some special kind?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gv8t5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;VLLM should run it, since it’s GGUF, right? Or is it some special kind?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gv8t5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992965,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jtde7","id":"m9jtde7","parent_id":"t1_m9jowgd","depth":3,"children":["m9jtde7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jowgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lissanro","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h5kow","score":4,"author_fullname":"t2_fpfao9g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I imagine collapsing it would be different than 8x22B &gt; 1x22B, since there are so many small experts. One possibility, is to organize experts to 64 groups (4 experts in each group) and collapse each group to a single experts, getting 64 experts. This adds quite a lot of complexity though, and also there is a question on what criteria experts should be put in a single group (I guess could be done randomly as the most simple approach).\\n\\nIf someone manages to do it, the result would be 168B instead of 671B, which may fit on just four 24GB GPUs at 3.5 bit or maybe even 4-bit quant. Not sure if it will be any better than full R1 dynamic quant that is already shared here though. But I thought I share the idea in case someone finds it interesting.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9jowgd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I imagine collapsing it would be different than 8x22B &amp;gt; 1x22B, since there are so many small experts. One possibility, is to organize experts to 64 groups (4 experts in each group) and collapse each group to a single experts, getting 64 experts. This adds quite a lot of complexity though, and also there is a question on what criteria experts should be put in a single group (I guess could be done randomly as the most simple approach).&lt;/p&gt;\\n\\n&lt;p&gt;If someone manages to do it, the result would be 168B instead of 671B, which may fit on just four 24GB GPUs at 3.5 bit or maybe even 4-bit quant. Not sure if it will be any better than full R1 dynamic quant that is already shared here though. But I thought I share the idea in case someone finds it interesting.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jowgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021922,"author_flair_text":null,"treatment_tags":[],"created_utc":1738021922,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h5kow","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737995901,"send_replies":true,"parent_id":"t1_m9h2fru","score":13,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh not a bad idea - I think maybe R1 might be more complex to collapse since it has 256 experts :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h5kow","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh not a bad idea - I think maybe R1 might be more complex to collapse since it has 256 experts :(&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h5kow/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995901,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h2fru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mtasic85","can_mod_post":false,"created_utc":1737995020,"send_replies":true,"parent_id":"t3_1ibbloy","score":12,"author_fullname":"t2_gpgni","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What about collapsing MoE layer to just dense layers? I think same was done for Mixtral 8x22b to just 22b. 🤔","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h2fru","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What about collapsing MoE layer to just dense layers? I think same was done for Mixtral 8x22b to just 22b. 🤔&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h2fru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995020,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gy7j4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993817,"send_replies":true,"parent_id":"t1_m9gxe74","score":7,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gy7j4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gy7j4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993817,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gxe74","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Educational_Rent1059","can_mod_post":false,"created_utc":1737993582,"send_replies":true,"parent_id":"t3_1ibbloy","score":9,"author_fullname":"t2_ac1d5rhvu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"DAMN!!! Niceeeeeeeeeeee work as always","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gxe74","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DAMN!!! Niceeeeeeeeeeee work as always&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gxe74/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993582,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9h7hmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aurath","can_mod_post":false,"created_utc":1737996428,"send_replies":true,"parent_id":"t3_1ibbloy","score":10,"author_fullname":"t2_35vo8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, if my 3090 can pull 1t/s it would probably still be faster than waiting for the DeepSeekV3 API to start responding.\\n\\nI'm usually concerned about fitting a model in my vram, I've never had to make additional space on my SSD before 🤣","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h7hmx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, if my 3090 can pull 1t/s it would probably still be faster than waiting for the DeepSeekV3 API to start responding.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m usually concerned about fitting a model in my vram, I&amp;#39;ve never had to make additional space on my SSD before 🤣&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h7hmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996428,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9jxeaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738024647,"send_replies":true,"parent_id":"t1_m9i6rsn","score":4,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gooo local models!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jxeaa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gooo local models!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jxeaa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738024647,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_m9me2oy","id":"m9me2oy","parent_id":"t1_m9kt1ac","depth":2,"children":["m9me2oy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kt1ac","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"robot_turtle","can_mod_post":false,"created_utc":1738034993,"send_replies":true,"parent_id":"t1_m9i6rsn","score":4,"author_fullname":"t2_b6q5p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This feels like why the markets are freaking out. If we can run something like this locally, what's Google and OpenAI's business model?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9kt1ac","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This feels like why the markets are freaking out. If we can run something like this locally, what&amp;#39;s Google and OpenAI&amp;#39;s business model?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kt1ac/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738034993,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i6rsn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"custodiam99","can_mod_post":false,"created_utc":1738006227,"send_replies":true,"parent_id":"t3_1ibbloy","score":11,"author_fullname":"t2_nqnhgqqf5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does this mean that we will have 160b models in 50GB GGUF files? Jesus. That's the end of non-local LLMs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i6rsn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does this mean that we will have 160b models in 50GB GGUF files? Jesus. That&amp;#39;s the end of non-local LLMs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i6rsn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738006227,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma76azk","id":"ma76azk","parent_id":"t1_m9jolyk","depth":2,"children":["ma76azk"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jolyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738021827,"send_replies":true,"parent_id":"t1_m9h6eyp","score":12,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Currently no extensive benchmarks yet - I was extremely excited to share the model with everyone - I'll update everyone when I get to extensive testing!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jolyk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Currently no extensive benchmarks yet - I was extremely excited to share the model with everyone - I&amp;#39;ll update everyone when I get to extensive testing!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jolyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021827,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h6eyp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sahil1572","can_mod_post":false,"created_utc":1737996133,"send_replies":true,"parent_id":"t3_1ibbloy","score":9,"author_fullname":"t2_d6v17","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"any hint or benchmark of how much intelligence performance we lose with these quantization's compared to the fp8 version?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h6eyp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;any hint or benchmark of how much intelligence performance we lose with these quantization&amp;#39;s compared to the fp8 version?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h6eyp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996133,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":11,"name":"t1_m9qiafp","id":"m9qiafp","parent_id":"t1_m9ln5p0","depth":4,"children":["m9qiafp","m9rq2i0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ln5p0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sigjnf","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9jntys","score":9,"author_fullname":"t2_kdi40iq0d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's here!\\n\\n[https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit](https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit)\\n\\nTell me if I need to edit any of the readme's or anything at all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ln5p0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s here!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit\\"&gt;https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Tell me if I need to edit any of the readme&amp;#39;s or anything at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ln5p0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738048621,"author_flair_text":null,"treatment_tags":[],"created_utc":1738048621,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jntys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ix1ok","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh glad you solved it!!! Looking forward to the upload!! :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9jntys","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh glad you solved it!!! Looking forward to the upload!! :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jntys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021571,"author_flair_text":null,"treatment_tags":[],"created_utc":1738021571,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9sc6oa","id":"m9sc6oa","parent_id":"t1_m9rd76o","depth":3,"children":["m9sc6oa"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9rd76o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"elsung","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ix1ok","score":3,"author_fullname":"t2_94yk8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"awesome stuff! i tried running this on ollama/openwebui but after the first response im unable to get a second response. \\n\\nis there some sort of setting we need to do? like turn on mmap? i’m everything on default right now and it eats up to 170gb (i’ve done the thing to increase memory limit)\\nsudo sysctl iogpu.wired_limit_mb\\n\\ni’m on an m2 ultra 192gb, running the 1.58bit iq1s. \\n\\nwould be lovely to be able to run this consistently~~","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9rd76o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;awesome stuff! i tried running this on ollama/openwebui but after the first response im unable to get a second response. &lt;/p&gt;\\n\\n&lt;p&gt;is there some sort of setting we need to do? like turn on mmap? i’m everything on default right now and it eats up to 170gb (i’ve done the thing to increase memory limit)\\nsudo sysctl iogpu.wired_limit_mb&lt;/p&gt;\\n\\n&lt;p&gt;i’m on an m2 ultra 192gb, running the 1.58bit iq1s. &lt;/p&gt;\\n\\n&lt;p&gt;would be lovely to be able to run this consistently~~&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9rd76o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738120094,"author_flair_text":null,"treatment_tags":[],"created_utc":1738120094,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":7,"name":"t1_m9lq6et","id":"m9lq6et","parent_id":"t1_m9ix1ok","depth":2,"children":["m9lq6et","m9kffne"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ix1ok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sigjnf","can_mod_post":false,"created_utc":1738013602,"send_replies":true,"parent_id":"t1_m9hwqkg","score":11,"author_fullname":"t2_kdi40iq0d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I figured it all out on my own and we're flying away, available in a few hours for every Ollama user!\\n\\nhttps://preview.redd.it/o0n3cm3pulfe1.png?width=608&amp;format=png&amp;auto=webp&amp;s=55c6128e607c52438b593c186d84bf187c37036b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ix1ok","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I figured it all out on my own and we&amp;#39;re flying away, available in a few hours for every Ollama user!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/o0n3cm3pulfe1.png?width=608&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=55c6128e607c52438b593c186d84bf187c37036b\\"&gt;https://preview.redd.it/o0n3cm3pulfe1.png?width=608&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=55c6128e607c52438b593c186d84bf187c37036b&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ix1ok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738013602,"media_metadata":{"o0n3cm3pulfe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":65,"x":108,"u":"https://preview.redd.it/o0n3cm3pulfe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70059c4d72886d88482dfdb9766ba3406c185d90"},{"y":131,"x":216,"u":"https://preview.redd.it/o0n3cm3pulfe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=90526f312ea0d31afe23a65b7e1dbc73730edb2a"},{"y":194,"x":320,"u":"https://preview.redd.it/o0n3cm3pulfe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7bd755d1442e7905c168f900841f74c8196a6a0"}],"s":{"y":369,"x":608,"u":"https://preview.redd.it/o0n3cm3pulfe1.png?width=608&amp;format=png&amp;auto=webp&amp;s=55c6128e607c52438b593c186d84bf187c37036b"},"id":"o0n3cm3pulfe1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hwqkg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sigjnf","can_mod_post":false,"created_utc":1738003425,"send_replies":true,"parent_id":"t3_1ibbloy","score":9,"author_fullname":"t2_kdi40iq0d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey, amazing work! Any chance I'd be able to run it using Ollama? I wanna see how the performance looks on Apple Silicon","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hwqkg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, amazing work! Any chance I&amp;#39;d be able to run it using Ollama? I wanna see how the performance looks on Apple Silicon&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hwqkg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738003425,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9w0p6p","id":"m9w0p6p","parent_id":"t1_m9lj7f0","depth":2,"children":["m9w0p6p"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9lj7f0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1738046416,"send_replies":true,"parent_id":"t1_m9kw4zv","score":8,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We might release the 1.58bit versions for DeepSeek V3 soon as well :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lj7f0","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We might release the 1.58bit versions for DeepSeek V3 soon as well :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lj7f0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738046416,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":2,"name":"t1_m9zveuw","id":"m9zveuw","parent_id":"t1_m9kw4zv","depth":1,"children":["m9zveuw"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kw4zv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Monkey_1505","can_mod_post":false,"created_utc":1738036117,"send_replies":true,"parent_id":"t3_1ibbloy","score":10,"author_fullname":"t2_7qrmh9n9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That probably puts us one AMD hardware gen away from being about to load this on one machine in unified memory. Nice work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9kw4zv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That probably puts us one AMD hardware gen away from being about to load this on one machine in unified memory. Nice work!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kw4zv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738036117,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gzob3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737994240,"send_replies":true,"parent_id":"t1_m9gz88z","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gzob3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gzob3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994240,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gz88z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PizzaCatAm","can_mod_post":false,"created_utc":1737994112,"send_replies":true,"parent_id":"t3_1ibbloy","score":8,"author_fullname":"t2_xr1nq0s3u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow, amazing work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gz88z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow, amazing work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gz88z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994112,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9sd4c0","id":"m9sd4c0","parent_id":"t1_m9jp2lk","depth":2,"children":["m9sd4c0","maztrjy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jp2lk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738021977,"send_replies":true,"parent_id":"t1_m9i5329","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"4bit is extremely close to the original non quantized model of 8bits - the 2.5bit dynamic quant should function reasonably as well - the 1.58bit should be reasonably ok as well - I haven't yet done extensive benchmarks since I wanted to share it with everyone first!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jp2lk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4bit is extremely close to the original non quantized model of 8bits - the 2.5bit dynamic quant should function reasonably as well - the 1.58bit should be reasonably ok as well - I haven&amp;#39;t yet done extensive benchmarks since I wanted to share it with everyone first!!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jp2lk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021977,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_m9z8hz6","id":"m9z8hz6","parent_id":"t1_m9i5329","depth":1,"children":["m9z8hz6"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i5329","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"infstudent","can_mod_post":false,"created_utc":1738005755,"send_replies":true,"parent_id":"t3_1ibbloy","score":7,"author_fullname":"t2_tj765","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does the accuracy compare to the accuracy of the non-quantized distills?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i5329","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does the accuracy compare to the accuracy of the non-quantized distills?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i5329/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738005755,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9hiawj","id":"m9hiawj","parent_id":"t1_m9gvtc1","depth":2,"children":["m9hiawj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gvtc1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737993128,"send_replies":true,"parent_id":"t1_m9gv4g4","score":12,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Definitely possible. We might upload them 'soon' (sorry our estimations for soon are always terrible) 😭","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gvtc1","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely possible. We might upload them &amp;#39;soon&amp;#39; (sorry our estimations for soon are always terrible) 😭&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gvtc1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993128,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gv4g4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jnk_str","can_mod_post":false,"created_utc":1737992930,"send_replies":true,"parent_id":"t3_1ibbloy","score":15,"author_fullname":"t2_5ct4y4k6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh very nice. I‘ve been waiting for some quants that can fit the popular 2x H100 setup. \\n\\nIs this possible for Deepseek V3 too?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gv4g4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh very nice. I‘ve been waiting for some quants that can fit the popular 2x H100 setup. &lt;/p&gt;\\n\\n&lt;p&gt;Is this possible for Deepseek V3 too?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gv4g4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737992930,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":19,"name":"t1_m9h3qz4","id":"m9h3qz4","parent_id":"t1_m9h3h0h","depth":2,"children":["m9h3qz4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h3h0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737995310,"send_replies":true,"parent_id":"t1_m9h2rhq","score":8,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LM Studio didnt support R1 until 5 days ago. Make sure you have the latest version","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h3h0h","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LM Studio didnt support R1 until 5 days ago. Make sure you have the latest version&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h3h0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995310,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":1,"name":"t1_m9h3wfc","id":"m9h3wfc","parent_id":"t1_m9h2rhq","depth":1,"children":["m9h3wfc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h2rhq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Berberis","can_mod_post":false,"created_utc":1737995112,"send_replies":true,"parent_id":"t3_1ibbloy","score":7,"author_fullname":"t2_57oao","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anyone know why this is not compatible with LM studio? Running on a Mac Studio","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h2rhq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anyone know why this is not compatible with LM studio? Running on a Mac Studio&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h2rhq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995112,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9joh9r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738021784,"send_replies":true,"parent_id":"t1_m9ich4h","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh fantastic!! :) Glad it worked well!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9joh9r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh fantastic!! :) Glad it worked well!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9joh9r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021784,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":5,"name":"t1_m9nzlml","id":"m9nzlml","parent_id":"t1_m9ich4h","depth":1,"children":["m9nzlml"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ich4h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thereisonlythedance","can_mod_post":false,"created_utc":1738007819,"send_replies":true,"parent_id":"t3_1ibbloy","score":14,"author_fullname":"t2_u4wkj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’ve just tested the 2.51bit on a long form creative writing task and it was majestic. Thank you. It’s brilliant, very close to the results I’ve gotten over the API.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ich4h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve just tested the 2.51bit on a long form creative writing task and it was majestic. Thank you. It’s brilliant, very close to the results I’ve gotten over the API.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ich4h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738007819,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9h36n8","id":"m9h36n8","parent_id":"t1_m9h1o8j","depth":3,"children":["m9h36n8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h1o8j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wonderful_Alfalfa115","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gy2ks","score":3,"author_fullname":"t2_116fi2cw8w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for the quick responses. Would you be willing to share the code? What I am wondering is if you quantize a 32B distilled model to 1.58 bits in this same method, will it perform equally well, better or worse and faster or slower than a 14B distilled 4bit AWQ? And the same with 7B distilled 4bit awq","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9h1o8j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the quick responses. Would you be willing to share the code? What I am wondering is if you quantize a 32B distilled model to 1.58 bits in this same method, will it perform equally well, better or worse and faster or slower than a 14B distilled 4bit AWQ? And the same with 7B distilled 4bit awq&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h1o8j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994804,"author_flair_text":null,"treatment_tags":[],"created_utc":1737994804,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gy2ks","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737993777,"send_replies":true,"parent_id":"t1_m9gwcbe","score":8,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh distilled is maybe not a good idea - I did upload 2bit, 3bit, 4bit GGUFs for Llama 70B for eg here: https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF/tree/main\\n\\nDense models in low bit generally is not a good idea","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gy2ks","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh distilled is maybe not a good idea - I did upload 2bit, 3bit, 4bit GGUFs for Llama 70B for eg here: &lt;a href=\\"https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF/tree/main\\"&gt;https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF/tree/main&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Dense models in low bit generally is not a good idea&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gy2ks/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993777,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gwcbe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wonderful_Alfalfa115","can_mod_post":false,"created_utc":1737993280,"send_replies":true,"parent_id":"t3_1ibbloy","score":7,"author_fullname":"t2_116fi2cw8w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the process? Can this be done with distilled models? Benchmarks? Is this faster than awq?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gwcbe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the process? Can this be done with distilled models? Benchmarks? Is this faster than awq?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gwcbe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993280,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9jtrqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1738023492,"send_replies":true,"parent_id":"t1_m9idi82","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh on deployment - Georgi (llama.cpp creator) tweeted about hosting it via Hugging Face! https://x.com/ggerganov/status/1883961201371042120 Maybe some cloud services like Runpod or Lambda could be helpful - 2x H100s is best for speed - 1x H100 also works ok!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jtrqo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh on deployment - Georgi (llama.cpp creator) tweeted about hosting it via Hugging Face! &lt;a href=\\"https://x.com/ggerganov/status/1883961201371042120\\"&gt;https://x.com/ggerganov/status/1883961201371042120&lt;/a&gt; Maybe some cloud services like Runpod or Lambda could be helpful - 2x H100s is best for speed - 1x H100 also works ok!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jtrqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738023492,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9idi82","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Still_Map_8572","can_mod_post":false,"created_utc":1738008108,"send_replies":true,"parent_id":"t3_1ibbloy","score":6,"author_fullname":"t2_kl4swv8u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What’s the cheapest cloud we can run this ? I don’t need ultra fast speeds, maybe around 5-10t/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9idi82","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What’s the cheapest cloud we can run this ? I don’t need ultra fast speeds, maybe around 5-10t/s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9idi82/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738008108,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9iej66","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9idcuq","score":5,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's good to hear. There's still a lot of optimization that could be made. Supposedly the full model outputs 2 tokens at a time and there are also 8bit activations like it's done for sage attention in DiT models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9iej66","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s good to hear. There&amp;#39;s still a lot of optimization that could be made. Supposedly the full model outputs 2 tokens at a time and there are also 8bit activations like it&amp;#39;s done for sage attention in DiT models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iej66/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738008401,"author_flair_text":null,"treatment_tags":[],"created_utc":1738008401,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9idcuq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thereisonlythedance","can_mod_post":false,"created_utc":1738008065,"send_replies":true,"parent_id":"t1_m9hh94u","score":9,"author_fullname":"t2_u4wkj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very impressed with the results I got with the 2.5bit. Wasn’t too far off what I was getting with the API. No obvious gremlins.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9idcuq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very impressed with the results I got with the 2.5bit. Wasn’t too far off what I was getting with the API. No obvious gremlins.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9idcuq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738008065,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9jolis","id":"m9jolis","parent_id":"t1_m9jn56o","depth":2,"children":["m9jolis"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jn56o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"created_utc":1738021348,"send_replies":true,"parent_id":"t1_m9hh94u","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh I just saw this as well!! It's pretty cool DeepSeek R1 helped author like the entire PR - now that's something!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jn56o","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh I just saw this as well!! It&amp;#39;s pretty cool DeepSeek R1 helped author like the entire PR - now that&amp;#39;s something!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jn56o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738021348,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hh94u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1737999155,"send_replies":true,"parent_id":"t3_1ibbloy","score":10,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Might combine well with that PR in llama.cpp which gives higher t/s. https://github.com/ggerganov/llama.cpp/pull/11453\\n\\nYea, it's stunted deepseek but it's local :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hh94u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Might combine well with that PR in llama.cpp which gives higher t/s. &lt;a href=\\"https://github.com/ggerganov/llama.cpp/pull/11453\\"&gt;https://github.com/ggerganov/llama.cpp/pull/11453&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Yea, it&amp;#39;s stunted deepseek but it&amp;#39;s local :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hh94u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737999155,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9h3dl9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737995283,"send_replies":true,"parent_id":"t1_m9h1897","score":6,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":":)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h3dl9","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;:)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h3dl9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995283,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h1897","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"celsowm","can_mod_post":false,"created_utc":1737994680,"send_replies":true,"parent_id":"t3_1ibbloy","score":11,"author_fullname":"t2_dyvrh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"God Bless You","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h1897","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;God Bless You&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h1897/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994680,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ic9fa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LetterRip","can_mod_post":false,"created_utc":1738007760,"send_replies":true,"parent_id":"t1_m9i5pur","score":7,"author_fullname":"t2_3zb81","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No that is not correct, he hasn't benchmarked it, but it should be quite close in performance. Yes you are correct about the speed.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ic9fa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No that is not correct, he hasn&amp;#39;t benchmarked it, but it should be quite close in performance. Yes you are correct about the speed.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ic9fa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738007760,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9nka6u","id":"m9nka6u","parent_id":"t1_m9jpe21","depth":2,"children":["m9nka6u"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jpe21","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"created_utc":1738022079,"send_replies":true,"parent_id":"t1_m9i5pur","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh that's an internal benchmark on the Flappy Bird benchmark - I guess qualitatively using 3 trials, it's around 69.2% on our own benchmark, but best to do more benchmarks.\\n\\nYes on speed! (VRAM + RAM) at least 80GB for 1-3tok/s (best 140GB for &gt;20tok/s). Less than 80GB will work, but be very slow","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jpe21","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh that&amp;#39;s an internal benchmark on the Flappy Bird benchmark - I guess qualitatively using 3 trials, it&amp;#39;s around 69.2% on our own benchmark, but best to do more benchmarks.&lt;/p&gt;\\n\\n&lt;p&gt;Yes on speed! (VRAM + RAM) at least 80GB for 1-3tok/s (best 140GB for &amp;gt;20tok/s). Less than 80GB will work, but be very slow&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jpe21/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738022079,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i5pur","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Strong_Masterpiece13","can_mod_post":false,"created_utc":1738005933,"send_replies":true,"parent_id":"t3_1ibbloy","score":6,"author_fullname":"t2_9jry9amp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have no knowledge about the local LLM.\\n\\nBased on the Unsloth blog content, it appears that the 1.58-bit quantization model performs at about 69.2% of the R1 base model's performance. Is this correct?\\n\\nAlso, regarding the minimum recommended specifications for the 1.58-bit quantization model (VRAM+RAM=80G or more), does this mean that with an RTX4090 24G + 64G of system memory, it can run locally at a speed of 1-3 tokens per second?\\n\\nPlease correct me if I'm wrong.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i5pur","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have no knowledge about the local LLM.&lt;/p&gt;\\n\\n&lt;p&gt;Based on the Unsloth blog content, it appears that the 1.58-bit quantization model performs at about 69.2% of the R1 base model&amp;#39;s performance. Is this correct?&lt;/p&gt;\\n\\n&lt;p&gt;Also, regarding the minimum recommended specifications for the 1.58-bit quantization model (VRAM+RAM=80G or more), does this mean that with an RTX4090 24G + 64G of system memory, it can run locally at a speed of 1-3 tokens per second?&lt;/p&gt;\\n\\n&lt;p&gt;Please correct me if I&amp;#39;m wrong.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i5pur/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738005933,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":6,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9llc59","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"created_utc":1738047584,"send_replies":true,"parent_id":"t1_m9kdti7","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much! Oh yes we're working on something like that!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9llc59","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much! Oh yes we&amp;#39;re working on something like that!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9llc59/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738047584,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":3,"name":"t1_m9liuff","id":"m9liuff","parent_id":"t1_m9kdti7","depth":1,"children":["m9liuff"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kdti7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1ibbloy","score":6,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kdti7/","num_reports":null,"locked":false,"name":"t1_m9kdti7","created":1738029908,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738029908,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ljp2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yoracale","can_mod_post":false,"created_utc":1738046684,"send_replies":true,"parent_id":"t1_m9l7apv","score":3,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much!! We really appreciate it! :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ljp2a","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much!! We really appreciate it! :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ljp2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738046684,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9l7apv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ravenpest","can_mod_post":false,"created_utc":1738040609,"send_replies":true,"parent_id":"t3_1ibbloy","score":6,"author_fullname":"t2_21lhc1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I love you unsloth","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9l7apv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I love you unsloth&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9l7apv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738040609,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9lkzyr","id":"m9lkzyr","parent_id":"t1_m9lj95q","depth":1,"children":["m9lkzyr"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9lj95q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tdhffgf","can_mod_post":false,"created_utc":1738046443,"send_replies":true,"parent_id":"t3_1ibbloy","score":6,"author_fullname":"t2_4dtwe7ea","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any chance you could test with https://github.com/ggerganov/llama.cpp/pull/11397 as that PR will allow offloading everything but the experts to the GPU which helps with lower VRAM amounts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lj95q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any chance you could test with &lt;a href=\\"https://github.com/ggerganov/llama.cpp/pull/11397\\"&gt;https://github.com/ggerganov/llama.cpp/pull/11397&lt;/a&gt; as that PR will allow offloading everything but the experts to the GPU which helps with lower VRAM amounts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lj95q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738046443,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s25l6","id":"m9s25l6","parent_id":"t1_m9no3df","depth":1,"children":["m9s25l6"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9no3df","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lord_of_Many_Memes","can_mod_post":false,"created_utc":1738081103,"send_replies":true,"parent_id":"t3_1ibbloy","score":5,"author_fullname":"t2_7r5nulmb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jensen approves this message\\n\\nhttps://preview.redd.it/25mkicrgfrfe1.jpeg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=34c01f1a20c298f9c2c21167dd3b03cf0c96a527","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9no3df","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jensen approves this message&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=34c01f1a20c298f9c2c21167dd3b03cf0c96a527\\"&gt;https://preview.redd.it/25mkicrgfrfe1.jpeg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=34c01f1a20c298f9c2c21167dd3b03cf0c96a527&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9no3df/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738081103,"media_metadata":{"25mkicrgfrfe1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":60,"x":108,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=114dbcb57f1d0a3bf51e7aaf3afd56d74d538d5d"},{"y":121,"x":216,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3824402d3860498ceca1af12b6898f21a148a86a"},{"y":180,"x":320,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02ff37be77c93c62123cecfec0330663952c8c65"},{"y":360,"x":640,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36346b7ea5a4796a4d8863246ec2ac7b0b1970ce"},{"y":540,"x":960,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8516394b120ee746ddafac97c97a818d47954a43"},{"y":607,"x":1080,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da8be672e46ff9b7bf7ddcca9d153981cfa9629f"}],"s":{"y":720,"x":1280,"u":"https://preview.redd.it/25mkicrgfrfe1.jpeg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=34c01f1a20c298f9c2c21167dd3b03cf0c96a527"},"id":"25mkicrgfrfe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gzw92","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737994304,"send_replies":true,"parent_id":"t1_m9gy7um","score":7,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh the llama.cpp GGUF impl is slightly different - but as some people mentioned in the Reddit thread, the ideas I had were similar to those in Bitnet :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gzw92","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh the llama.cpp GGUF impl is slightly different - but as some people mentioned in the Reddit thread, the ideas I had were similar to those in Bitnet :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gzw92/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994304,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gy7um","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Wonderful_Alfalfa115","can_mod_post":false,"created_utc":1737993819,"send_replies":true,"parent_id":"t3_1ibbloy","score":4,"author_fullname":"t2_116fi2cw8w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does this compare to bitnet?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gy7um","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does this compare to bitnet?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gy7um/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993819,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jo3sr","id":"m9jo3sr","parent_id":"t1_m9h704g","depth":3,"children":["m9jo3sr"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h704g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"softwareweaver","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h3unk","score":3,"author_fullname":"t2_k7r9yrxx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks u/danielhanchen","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9h704g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks &lt;a href=\\"/u/danielhanchen\\"&gt;u/danielhanchen&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h704g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996295,"author_flair_text":null,"treatment_tags":[],"created_utc":1737996295,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h3unk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"created_utc":1737995415,"send_replies":true,"parent_id":"t1_m9h2k0c","score":5,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks! Oh it should be automatic since the model has a chat template inside - just don't add a system prompt and use temp = 0.6 and min\\\\_p = 0.1\\n\\nOtherwise, the template looks like this: \`&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;What is 1+1?&lt;｜Assistant｜&gt;It's 2.&lt;｜end▁of▁sentence｜&gt;&lt;｜User｜&gt;Explain more!&lt;｜Assistant｜&gt;\`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h3unk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks! Oh it should be automatic since the model has a chat template inside - just don&amp;#39;t add a system prompt and use temp = 0.6 and min_p = 0.1&lt;/p&gt;\\n\\n&lt;p&gt;Otherwise, the template looks like this: &lt;code&gt;&amp;lt;｜begin▁of▁sentence｜&amp;gt;&amp;lt;｜User｜&amp;gt;What is 1+1?&amp;lt;｜Assistant｜&amp;gt;It&amp;#39;s 2.&amp;lt;｜end▁of▁sentence｜&amp;gt;&amp;lt;｜User｜&amp;gt;Explain more!&amp;lt;｜Assistant｜&amp;gt;&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h3unk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995415,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h2k0c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"softwareweaver","can_mod_post":false,"created_utc":1737995053,"send_replies":true,"parent_id":"t3_1ibbloy","score":5,"author_fullname":"t2_k7r9yrxx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is amazing u/danielhanchen Will try it out today.\\n\\nAny tips on how to set the prompt template in llama.cpp server app? Thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h2k0c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is amazing &lt;a href=\\"/u/danielhanchen\\"&gt;u/danielhanchen&lt;/a&gt; Will try it out today.&lt;/p&gt;\\n\\n&lt;p&gt;Any tips on how to set the prompt template in llama.cpp server app? Thanks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h2k0c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995053,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jorzr","id":"m9jorzr","parent_id":"t1_m9h935j","depth":1,"children":["m9jorzr"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h935j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Everlier","can_mod_post":false,"created_utc":1737996869,"send_replies":true,"parent_id":"t3_1ibbloy","score":4,"author_fullname":"t2_o7p5m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is huge (literally)!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h935j","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is huge (literally)!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h935j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996869,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jow2d","id":"m9jow2d","parent_id":"t1_m9heldh","depth":1,"children":["m9jow2d"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9heldh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"indrasmirror","can_mod_post":false,"created_utc":1737998411,"send_replies":true,"parent_id":"t3_1ibbloy","score":4,"author_fullname":"t2_szcb4dcge","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are a legend! Can't wait to try this!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9heldh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are a legend! Can&amp;#39;t wait to try this!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9heldh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737998411,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jv6bs","id":"m9jv6bs","parent_id":"t1_m9hnd5p","depth":1,"children":["m9jv6bs"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hnd5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Stepfunction","can_mod_post":false,"created_utc":1738000833,"send_replies":true,"parent_id":"t3_1ibbloy","score":4,"author_fullname":"t2_sxigq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gonna need more system RAM!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hnd5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gonna need more system RAM!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hnd5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738000833,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jtw6u","id":"m9jtw6u","parent_id":"t1_m9jh1u7","depth":1,"children":["m9jtw6u"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jh1u7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"andreclaudino","can_mod_post":false,"created_utc":1738019407,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_4x38skfk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://i.redd.it/wr983a60cmfe1.gif","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jh1u7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://i.redd.it/wr983a60cmfe1.gif\\"&gt;https://i.redd.it/wr983a60cmfe1.gif&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jh1u7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738019407,"media_metadata":{"wr983a60cmfe1":{"status":"valid","e":"AnimatedImage","m":"image/gif","p":[{"y":108,"x":108,"u":"https://preview.redd.it/wr983a60cmfe1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=8d20ac42f2d2cd5b9e49b8f1fc31df176de787cf"},{"y":216,"x":216,"u":"https://preview.redd.it/wr983a60cmfe1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=497d6108f9b0e950cbe832bc041620e542a5495f"},{"y":320,"x":320,"u":"https://preview.redd.it/wr983a60cmfe1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=554cf50a36af91f75788cb322c1c06a6e41e573f"},{"y":640,"x":640,"u":"https://preview.redd.it/wr983a60cmfe1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=2a73045588e90e7fa8477895210278ef2435459b"}],"s":{"y":640,"gif":"https://i.redd.it/wr983a60cmfe1.gif","mp4":"https://preview.redd.it/wr983a60cmfe1.gif?format=mp4&amp;s=e42f3166f00a2c746f3137f982fd8326e88b0c66","x":640},"id":"wr983a60cmfe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":13,"name":"t1_m9m78zw","id":"m9m78zw","parent_id":"t1_m9m2q5j","depth":1,"children":["m9m78zw","m9mar36"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9m2q5j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Slaghton","can_mod_post":false,"created_utc":1738058428,"send_replies":true,"parent_id":"t3_1ibbloy","score":4,"author_fullname":"t2_t2nbp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"(Just want to say, with such a reduction in model size, the 1.58bit model I can test is surprisingly decent.)  \\n  \\n\\\\*1.58bit model\\\\*  \\nUsing koboldcpp + 2 P40's and 128 gb of system ram. Set to just 4096 context length for testing.\\n\\nGPU1 23,733mb used  \\nGPU2 23,239mb used\\n\\nCurrent system memory in use is about 118gb. Model and koboldcpp probably take around 110-112gb since this windows build can just have 5gb in use on startup.  \\n16 total layers offloaded to gpu's. \\\\*\\\\*I set the tensor split to 8,8 and checkmarked rowsplit\\\\*\\\\*  \\nCrucial 16GB DDR4 2400T-R Server Memory x8  \\nIntel Xeon E5-2680 v4 (dual cpu system)  \\nSet to 36 threads in this test.  \\nNote: My system gets better performance in oobabooga then koboldcpp I think due to better cpu handling since but koboldcpp doesn't max out my system memory when using this model and reduce speeds to like .01 tk/s when using this particular model.\\n\\n(ooba auto selects all threads while kobold just uses 8 threads. I've played around trying to use more threads for more speed but past a point it slows down so it doesn't match ooba's speed when its partially offloaded to system ram. I prefer koboldcpp though when the model can fit all inside vram as it uses less vram with no performance hit.)\\n\\n\\\\--------------------------------------------------------------------\\n\\nAnyways, the model takes a bit to boot up but with basically no context length for the prompt (basic ai prompt) I get about 2tk/s per second.\\n\\nProcessing a prompt of 3827 tokens for the first time did take like 2-3 minutes but the 2tk/s remained I believe.\\n\\nRaising the context to 8096 increased the memory usage past 128gb limit to around like 135gb which then makes it unusable like ooba.  I may be looking to upgrade to a new AI machine in the future to adapt to big MoE models.","edited":1738060674,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9m2q5j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;(Just want to say, with such a reduction in model size, the 1.58bit model I can test is surprisingly decent.)  &lt;/p&gt;\\n\\n&lt;p&gt;*1.58bit model*&lt;br/&gt;\\nUsing koboldcpp + 2 P40&amp;#39;s and 128 gb of system ram. Set to just 4096 context length for testing.&lt;/p&gt;\\n\\n&lt;p&gt;GPU1 23,733mb used&lt;br/&gt;\\nGPU2 23,239mb used&lt;/p&gt;\\n\\n&lt;p&gt;Current system memory in use is about 118gb. Model and koboldcpp probably take around 110-112gb since this windows build can just have 5gb in use on startup.&lt;br/&gt;\\n16 total layers offloaded to gpu&amp;#39;s. **I set the tensor split to 8,8 and checkmarked rowsplit**&lt;br/&gt;\\nCrucial 16GB DDR4 2400T-R Server Memory x8&lt;br/&gt;\\nIntel Xeon E5-2680 v4 (dual cpu system)&lt;br/&gt;\\nSet to 36 threads in this test.&lt;br/&gt;\\nNote: My system gets better performance in oobabooga then koboldcpp I think due to better cpu handling since but koboldcpp doesn&amp;#39;t max out my system memory when using this model and reduce speeds to like .01 tk/s when using this particular model.&lt;/p&gt;\\n\\n&lt;p&gt;(ooba auto selects all threads while kobold just uses 8 threads. I&amp;#39;ve played around trying to use more threads for more speed but past a point it slows down so it doesn&amp;#39;t match ooba&amp;#39;s speed when its partially offloaded to system ram. I prefer koboldcpp though when the model can fit all inside vram as it uses less vram with no performance hit.)&lt;/p&gt;\\n\\n&lt;p&gt;--------------------------------------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;Anyways, the model takes a bit to boot up but with basically no context length for the prompt (basic ai prompt) I get about 2tk/s per second.&lt;/p&gt;\\n\\n&lt;p&gt;Processing a prompt of 3827 tokens for the first time did take like 2-3 minutes but the 2tk/s remained I believe.&lt;/p&gt;\\n\\n&lt;p&gt;Raising the context to 8096 increased the memory usage past 128gb limit to around like 135gb which then makes it unusable like ooba.  I may be looking to upgrade to a new AI machine in the future to adapt to big MoE models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9m2q5j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738058428,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9gx9rx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737993546,"send_replies":true,"parent_id":"t1_m9gwm4a","score":10,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, the original R1 on the official DeepSeek website.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gx9rx","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, the original R1 on the official DeepSeek website.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gx9rx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993546,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9ldv5a","id":"m9ldv5a","parent_id":"t1_m9gww4a","depth":2,"children":["m9ldv5a"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gww4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zalathustra","can_mod_post":false,"created_utc":1737993437,"send_replies":true,"parent_id":"t1_m9gwm4a","score":17,"author_fullname":"t2_lb93vlwi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"An extremely quantized version of it, but yes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gww4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An extremely quantized version of it, but yes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gww4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993437,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"more","data":{"count":1,"name":"t1_m9hae77","id":"m9hae77","parent_id":"t1_m9gwm4a","depth":1,"children":["m9hae77"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gwm4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bkacademy","can_mod_post":false,"created_utc":1737993358,"send_replies":true,"parent_id":"t3_1ibbloy","score":5,"author_fullname":"t2_s275a8le9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":" i am a absolute newbie. sorry if the question is dumb. so, is this basically the full \\"R1\\" model that they allow access in their website. ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gwm4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i am a absolute newbie. sorry if the question is dumb. so, is this basically the full &amp;quot;R1&amp;quot; model that they allow access in their website. ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gwm4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993358,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":5,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jou6w","id":"m9jou6w","parent_id":"t1_m9h9jw7","depth":1,"children":["m9jou6w"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h9jw7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1ibbloy","score":5,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":1738792119,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h9jw7/","num_reports":null,"locked":false,"name":"t1_m9h9jw7","created":1737996997,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1737996997,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jv1es","id":"m9jv1es","parent_id":"t1_m9hgurt","depth":1,"children":["m9jv1es"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hgurt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jeffwadsworth","can_mod_post":false,"created_utc":1737999043,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_11m4x2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I can't wait to try out the village idiot version of R1.  Not joking.  Great work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hgurt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t wait to try out the village idiot version of R1.  Not joking.  Great work.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hgurt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737999043,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jv2rc","id":"m9jv2rc","parent_id":"t1_m9hkywg","depth":1,"children":["m9jv2rc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hkywg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AlanzhuLy","can_mod_post":false,"created_utc":1738000178,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_186az5xn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Beautiful work!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hkywg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Beautiful work!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hkywg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738000178,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9jvbze","id":"m9jvbze","parent_id":"t1_m9hpd61","depth":1,"children":["m9jvbze"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9hpd61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Foreveradam2018","can_mod_post":false,"created_utc":1738001391,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_ylir8jwob","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"On windows, I used the following command to run 1.58bit version:\\n\\nllama-cli.exe --model DeepSeek-R1-UD-IQ1\\\\_S-00001-of-00003.gguf --cache-type-k q4\\\\_0 --threads 12 -no-cnv --prio 2 --n-gpu-layers 10 --temp 0.6 --ctx-size 8192 --seed 3407 --prompt \\"&lt;｜User｜&gt;Create a Flappy Bird game in Python.&lt;｜Assistant｜&gt;\\"\\n\\nHowever, after it output\\n\\nsystem\\\\_info: n\\\\_threads = 12 (n\\\\_threads\\\\_batch = 12) / 24 | CUDA : ARCHS = 520,610,700,750 | USE\\\\_GRAPHS = 1 | PEER\\\\_MAX\\\\_BATCH\\\\_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64\\\\_REPACK = 1 |\\n\\nIt returns without any error or generated text.\\n\\n  \\nDoes anyone encounter the same issue?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hpd61","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On windows, I used the following command to run 1.58bit version:&lt;/p&gt;\\n\\n&lt;p&gt;llama-cli.exe --model DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf --cache-type-k q4_0 --threads 12 -no-cnv --prio 2 --n-gpu-layers 10 --temp 0.6 --ctx-size 8192 --seed 3407 --prompt &amp;quot;&amp;lt;｜User｜&amp;gt;Create a Flappy Bird game in Python.&amp;lt;｜Assistant｜&amp;gt;&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;However, after it output&lt;/p&gt;\\n\\n&lt;p&gt;system_info: n_threads = 12 (n_threads_batch = 12) / 24 | CUDA : ARCHS = 520,610,700,750 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |&lt;/p&gt;\\n\\n&lt;p&gt;It returns without any error or generated text.&lt;/p&gt;\\n\\n&lt;p&gt;Does anyone encounter the same issue?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hpd61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738001391,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9k01fj","id":"m9k01fj","parent_id":"t1_m9iepf9","depth":1,"children":["m9k01fj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9iepf9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1738008451,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_o65i6kx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you for a Q1. Now this I can run.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9iepf9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for a Q1. Now this I can run.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iepf9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738008451,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9k05t5","id":"m9k05t5","parent_id":"t1_m9ih7nu","depth":1,"children":["m9k05t5"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ih7nu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheDreamWoken","can_mod_post":false,"created_utc":1738009161,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_151ddpzf3g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"can you do the entire magic you did one more time, to make it fit adequetely into a shit-tier gpu?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ih7nu","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;can you do the entire magic you did one more time, to make it fit adequetely into a shit-tier gpu?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ih7nu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738009161,"author_flair_text":"textgen web UI","treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jka1t","id":"m9jka1t","parent_id":"t1_m9jia22","depth":2,"children":["m9jka1t"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jia22","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1738019792,"send_replies":true,"parent_id":"t1_m9ixdjd","score":4,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Will definitely run a single GPU. The minimum requirement is only 20GB of RAM (CPU) with no GPU but it will be slow. More details in the blog: [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jia22","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will definitely run a single GPU. The minimum requirement is only 20GB of RAM (CPU) with no GPU but it will be slow. More details in the blog: &lt;a href=\\"https://unsloth.ai/blog/deepseekr1-dynamic\\"&gt;https://unsloth.ai/blog/deepseekr1-dynamic&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jia22/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738019792,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":2,"name":"t1_m9jtuli","id":"m9jtuli","parent_id":"t1_m9ixdjd","depth":1,"children":["m9jtuli"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ixdjd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Moist-Taro3362","can_mod_post":false,"created_utc":1738013692,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_1gm9t23iie","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This won't run on a single NVIDIA DIGITS, since it will have only 128GB RAM, right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ixdjd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This won&amp;#39;t run on a single NVIDIA DIGITS, since it will have only 128GB RAM, right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ixdjd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738013692,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9k0acy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"created_utc":1738025570,"send_replies":true,"parent_id":"t1_m9jglr3","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh yes that's a good point!! Also maybe increase the RMS Norm EPS a bit","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9k0acy","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yes that&amp;#39;s a good point!! Also maybe increase the RMS Norm EPS a bit&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k0acy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738025570,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jglr3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aaaaaaaaaeeeee","can_mod_post":false,"created_utc":1738019269,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_el5pibmej","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":" When increasing the experts from 8 to 16, with --override-kv deepseek2.expert_used_count=int:16, it does better in terms of perplexity benchmarks. So if you have enough GPUs, you may want to try that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jglr3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When increasing the experts from 8 to 16, with --override-kv deepseek2.expert_used_count=int:16, it does better in terms of perplexity benchmarks. So if you have enough GPUs, you may want to try that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jglr3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738019269,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jhyby","id":"m9jhyby","parent_id":"t1_m9jh66q","depth":1,"children":["m9jhyby"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jh66q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jh66q/","num_reports":null,"locked":false,"name":"t1_m9jh66q","created":1738019445,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738019445,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9lhdbf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yoracale","can_mod_post":false,"created_utc":1738045433,"send_replies":true,"parent_id":"t1_m9jv0ev","score":3,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks so much for the kind words. Daniel and I (Michael) appreciate it!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lhdbf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks so much for the kind words. Daniel and I (Michael) appreciate it!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lhdbf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738045433,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jv0ev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nootropicMan","can_mod_post":false,"created_utc":1738023886,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_7cai71g1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are amazing!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jv0ev","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are amazing!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jv0ev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738023886,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ljbz2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1738046486,"send_replies":true,"parent_id":"t1_m9kxk3k","score":5,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Currently we're just a team of 2 people Daniel and I (Michael). Daniel previously worked at NVIDIA and loved Math and watched tonnes of Jeremy Howard/Andrej videos so you can start from there.\\n\\nIn general all our blogposts explain a lot behind the process and execution of these works in a way any beginner can understand: [unsloth.ai/blog/deepseekr1-dynamic](http://unsloth.ai/blog/deepseekr1-dynamic)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ljbz2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Currently we&amp;#39;re just a team of 2 people Daniel and I (Michael). Daniel previously worked at NVIDIA and loved Math and watched tonnes of Jeremy Howard/Andrej videos so you can start from there.&lt;/p&gt;\\n\\n&lt;p&gt;In general all our blogposts explain a lot behind the process and execution of these works in a way any beginner can understand: &lt;a href=\\"http://unsloth.ai/blog/deepseekr1-dynamic\\"&gt;unsloth.ai/blog/deepseekr1-dynamic&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ljbz2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738046486,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9kxk3k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chipotlemayo_","can_mod_post":false,"created_utc":1738036648,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_yzbls","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How did you learn to do this? What would be a good beginner entry point into understanding the methods you used?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9kxk3k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you learn to do this? What would be a good beginner entry point into understanding the methods you used?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9kxk3k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738036648,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9lxlz4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thetaFAANG","can_mod_post":false,"created_utc":1738055154,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_da5i8ajs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"bro whaaat","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lxlz4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;bro whaaat&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lxlz4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738055154,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s3y2e","id":"m9s3y2e","parent_id":"t1_m9lzepu","depth":1,"children":["m9s3y2e"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9lzepu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pkmxtw","can_mod_post":false,"created_utc":1738056308,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_a2gtk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Running DeepSeek-R1-UD-IQ1_S with 8K context on 2x EPYC 7543 with 16-channel DDR4-3200 (409.6 GB/s bandwidth):\\n\\n    prompt eval time =    7017.07 ms /    74 tokens (   94.83 ms per token,    10.55 tokens per second)\\n           eval time =   82475.78 ms /   321 tokens (  256.93 ms per token,     3.89 tokens per second)\\n          total time =   89492.85 ms /   395 tokens\\n\\nSpeed-wise I don't think it is much faster, since the size of active parameters isn't quantized that much. I probably should have gone with IQ1_M instead.\\n\\nThis should be pretty awesome for those with 192GB Macs, since they can now fit both the IQ1 quants with some spare for context.\\n\\nOTOH, do you happen to know if there are draft models that you can use with R1. I believe the distilled versions won't work due to using completely different tokenizers.","edited":1738056915,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9lzepu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Running DeepSeek-R1-UD-IQ1_S with 8K context on 2x EPYC 7543 with 16-channel DDR4-3200 (409.6 GB/s bandwidth):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;prompt eval time =    7017.07 ms /    74 tokens (   94.83 ms per token,    10.55 tokens per second)\\n       eval time =   82475.78 ms /   321 tokens (  256.93 ms per token,     3.89 tokens per second)\\n      total time =   89492.85 ms /   395 tokens\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Speed-wise I don&amp;#39;t think it is much faster, since the size of active parameters isn&amp;#39;t quantized that much. I probably should have gone with IQ1_M instead.&lt;/p&gt;\\n\\n&lt;p&gt;This should be pretty awesome for those with 192GB Macs, since they can now fit both the IQ1 quants with some spare for context.&lt;/p&gt;\\n\\n&lt;p&gt;OTOH, do you happen to know if there are draft models that you can use with R1. I believe the distilled versions won&amp;#39;t work due to using completely different tokenizers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lzepu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738056308,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9s1tis","id":"m9s1tis","parent_id":"t1_m9o1o61","depth":1,"children":["m9s1tis"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9o1o61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"separatelyrepeatedly","can_mod_post":false,"created_utc":1738084939,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_1amfw1yl2n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"2.22bit on 192GB Ram + 48GB VRAM (4090/3090) only got me 1.35 tok/sec\\n\\nAlso I was able to offload 12 layers on 48GB RAM based on the formula on your blog.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9o1o61","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2.22bit on 192GB Ram + 48GB VRAM (4090/3090) only got me 1.35 tok/sec&lt;/p&gt;\\n\\n&lt;p&gt;Also I was able to offload 12 layers on 48GB RAM based on the formula on your blog.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9o1o61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738084939,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s1mi8","id":"m9s1mi8","parent_id":"t1_m9pt54o","depth":1,"children":["m9s1mi8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9pt54o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anemone_armada","can_mod_post":false,"created_utc":1738102396,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_16slre44zk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have tried the 1.58bit version. It's mindblowingly good for RP. Much better than Mistral Large and Qwen-2.5-72B fine-tunes at 4-bit.\\n\\nKudos to u/danielhanchen for the amazing job and of course to the guys at deepseek.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9pt54o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have tried the 1.58bit version. It&amp;#39;s mindblowingly good for RP. Much better than Mistral Large and Qwen-2.5-72B fine-tunes at 4-bit.&lt;/p&gt;\\n\\n&lt;p&gt;Kudos to &lt;a href=\\"/u/danielhanchen\\"&gt;u/danielhanchen&lt;/a&gt; for the amazing job and of course to the guys at deepseek.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9pt54o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738102396,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9wgjbt","id":"m9wgjbt","parent_id":"t1_m9tu74q","depth":1,"children":["m9wgjbt","m9zqgay"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9tu74q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Paint-9490","can_mod_post":false,"created_utc":1738161829,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_rpm5owysg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have tried the 131 GB version and the output is very good, but I have no use for it. Oddly, on llama.cpp server it has the very same speed of the 4-bit version, which is almost thrice its size.\\n\\nKudos for the effort, yet there is no point in a lower quant which has the same speed of a higher quant.\\n\\nedit: it has the same behaviour on kobold.cpp.","edited":1738163056,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9tu74q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have tried the 131 GB version and the output is very good, but I have no use for it. Oddly, on llama.cpp server it has the very same speed of the 4-bit version, which is almost thrice its size.&lt;/p&gt;\\n\\n&lt;p&gt;Kudos for the effort, yet there is no point in a lower quant which has the same speed of a higher quant.&lt;/p&gt;\\n\\n&lt;p&gt;edit: it has the same behaviour on kobold.cpp.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9tu74q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738161829,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9h6z0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"omarc1492","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h56jo","score":4,"author_fullname":"t2_24p0f19d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thank you, downloading for the last 30 min 1 of 5 files  \\nIn case anyone needs it  \\n[https://github.com/ollama/ollama/issues/5245#issuecomment-2305577747](https://github.com/ollama/ollama/issues/5245#issuecomment-2305577747)","edited":false,"author_flair_css_class":null,"name":"t1_m9h6z0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thank you, downloading for the last 30 min 1 of 5 files&lt;br/&gt;\\nIn case anyone needs it&lt;br/&gt;\\n&lt;a href=\\"https://github.com/ollama/ollama/issues/5245#issuecomment-2305577747\\"&gt;https://github.com/ollama/ollama/issues/5245#issuecomment-2305577747&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1ibbloy","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h6z0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996286,"author_flair_text":null,"collapsed":false,"created_utc":1737996286,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h56jo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h1c1v","score":6,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh it looks like one has to merge it - unfortunately Hugging Face's maximum upload size is 50GB, so I had to shard it.\\n\\nYou'll need to merge it via \`./llama.cpp/llama-gguf-split --merge\`   \\n\`DeepSeek-R1-UD-IQ1_S/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf\`   \\n\`merged_file.gguf\`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h56jo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh it looks like one has to merge it - unfortunately Hugging Face&amp;#39;s maximum upload size is 50GB, so I had to shard it.&lt;/p&gt;\\n\\n&lt;p&gt;You&amp;#39;ll need to merge it via &lt;code&gt;./llama.cpp/llama-gguf-split --merge&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;DeepSeek-R1-UD-IQ1_S/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;merged_file.gguf&lt;/code&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h56jo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995790,"author_flair_text":null,"treatment_tags":[],"created_utc":1737995790,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d40ca12a-0e73-11ee-8563-f216e082168e","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9iugao","id":"m9iugao","parent_id":"t1_m9h4mb4","depth":4,"children":["m9iugao"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h4mb4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yoracale","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9h1c1v","score":3,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh no that means that you will need to merge the GGUFs together which is the function we wrote for VLLM in our blogpost","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h4mb4","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh no that means that you will need to merge the GGUFs together which is the function we wrote for VLLM in our blogpost&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h4mb4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737995631,"author_flair_text":"Llama 2","treatment_tags":[],"created_utc":1737995631,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m9h42ju","id":"m9h42ju","parent_id":"t1_m9h1c1v","depth":3,"children":["m9h42ju"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h1c1v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"omarc1492","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9gw99z","score":5,"author_fullname":"t2_24p0f19d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Error: pull model manifest: 400: The specified repository contains sharded GGUF. Ollama does not support this yet. Follow this issue for more info: [https://github.com/ollama/ollama/issues/5245](https://github.com/ollama/ollama/issues/5245)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9h1c1v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Error: pull model manifest: 400: The specified repository contains sharded GGUF. Ollama does not support this yet. Follow this issue for more info: &lt;a href=\\"https://github.com/ollama/ollama/issues/5245\\"&gt;https://github.com/ollama/ollama/issues/5245&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h1c1v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737994710,"author_flair_text":null,"treatment_tags":[],"created_utc":1737994710,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gw99z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"yoracale","can_mod_post":false,"created_utc":1737993255,"send_replies":true,"parent_id":"t1_m9gvi95","score":7,"author_fullname":"t2_1162lx9rgr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ollama a few months ago allows you to pull any model from hugging face\\n\\nI think the command is something like this: ollama run [hf.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF:Q3\\\\_K\\\\_M](http://hf.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF:Q3_K_M) (change the model name etc to the correct one)\\n\\nEDIT: Nevermind they dont support sharded GGUFs yet meaning you have to manually merge it then run the local merged model via Ollama. Code to merge in llama.cpp\\n\\n    ./llama.cpp/llama-gguf-split --merge \\\\\\\\\\n    \\n    DeepSeek-R1-UD-IQ1\\\\_S/DeepSeek-R1-UD-IQ1\\\\_S-00001-of-00003.gguf \\\\\\\\\\n    \\n        merged\\\\_file.gguf","edited":1737996535,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gw99z","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 2"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ollama a few months ago allows you to pull any model from hugging face&lt;/p&gt;\\n\\n&lt;p&gt;I think the command is something like this: ollama run &lt;a href=\\"http://hf.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF:Q3_K_M\\"&gt;hf.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF:Q3_K_M&lt;/a&gt; (change the model name etc to the correct one)&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Nevermind they dont support sharded GGUFs yet meaning you have to manually merge it then run the local merged model via Ollama. Code to merge in llama.cpp&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;./llama.cpp/llama-gguf-split --merge \\\\\\\\\\n\\nDeepSeek-R1-UD-IQ1\\\\_S/DeepSeek-R1-UD-IQ1\\\\_S-00001-of-00003.gguf \\\\\\\\\\n\\n    merged\\\\_file.gguf\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gw99z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993255,"author_flair_text":"Llama 2","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#ab96c2","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m9gvi95","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"alex_bit_","can_mod_post":false,"created_utc":1737993039,"send_replies":true,"parent_id":"t3_1ibbloy","score":3,"author_fullname":"t2_u6j81q9mz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How to load and run it in Ollama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9gvi95","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How to load and run it in Ollama?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9gvi95/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737993039,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9h8ci8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xXPaTrIcKbUsTXx","can_mod_post":false,"created_utc":1737996663,"send_replies":true,"parent_id":"t1_m9h85cj","score":2,"author_fullname":"t2_siia0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nvm I missed reading that one lol. Thanks for providing it &lt;3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h8ci8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nvm I missed reading that one lol. Thanks for providing it &amp;lt;3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h8ci8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996663,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9jugvx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"created_utc":1738023715,"send_replies":true,"parent_id":"t1_m9h85cj","score":2,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh it's probably not a good idea to quantize the smaller models to 1.58bit - the dense models are probs best left at 4bit!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jugvx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh it&amp;#39;s probably not a good idea to quantize the smaller models to 1.58bit - the dense models are probs best left at 4bit!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jugvx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738023715,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h85cj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xXPaTrIcKbUsTXx","can_mod_post":false,"created_utc":1737996609,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_siia0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great work and observation sir, can you also please also do this on its distilled models, I've tried the recent quantized version of it especially the 7b model with the strawberry question and it hallucinates much, maybe this trick can also help thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h85cj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great work and observation sir, can you also please also do this on its distilled models, I&amp;#39;ve tried the recent quantized version of it especially the 7b model with the strawberry question and it hallucinates much, maybe this trick can also help thanks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h85cj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996609,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9juiz7","id":"m9juiz7","parent_id":"t1_m9h8y4k","depth":1,"children":["m9juiz7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9h8y4k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Muted_Estate890","can_mod_post":false,"created_utc":1737996830,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_4dsvh4x9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is really really cool!!! Every other post I've seen about quantizing models has just been people complaining about how it makes the model really bad haha cheers!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9h8y4k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is really really cool!!! Every other post I&amp;#39;ve seen about quantizing models has just been people complaining about how it makes the model really bad haha cheers!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9h8y4k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1737996830,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9hrhk3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"roshanpr","can_mod_post":false,"created_utc":1738001978,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_hw45s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So this is why people are camping at Microcenter for","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9hrhk3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So this is why people are camping at Microcenter for&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9hrhk3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738001978,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jw4qm","id":"m9jw4qm","parent_id":"t1_m9huhov","depth":1,"children":["m9jw4qm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9huhov","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LostMyOtherAcct69","can_mod_post":false,"created_utc":1738002804,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_ewg9k97p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow this is incredible work! Great job!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9huhov","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow this is incredible work! Great job!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9huhov/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738002804,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9jx60c","id":"m9jx60c","parent_id":"t1_m9i0de4","depth":1,"children":["m9jx60c"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i0de4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Snoo62259","can_mod_post":false,"created_utc":1738004430,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_7adyqld1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Could you write some collab notebook tutorials on how to do quantization of models (or only some parts of models)?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i0de4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you write some collab notebook tutorials on how to do quantization of models (or only some parts of models)?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i0de4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738004430,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9i31v6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShigeruTarantino64_","can_mod_post":false,"created_utc":1738005187,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_172tzlwvfk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I need a simple apk lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i31v6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I need a simple apk lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i31v6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738005187,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9i3to1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WanderingPulsar","can_mod_post":false,"created_utc":1738005402,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_ju83w4x1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Holy hell :d","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i3to1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Holy hell :d&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i3to1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738005402,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9jxj30","id":"m9jxj30","parent_id":"t1_m9i7qp7","depth":1,"children":["m9jxj30"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9i7qp7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aplakka","can_mod_post":false,"created_utc":1738006498,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_pllww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's impressive. How much total memory does this kind of model use? Is it on the scale of around the same as the file size? I've wondered how the \\"sparse\\" models' memory usage goes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9i7qp7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s impressive. How much total memory does this kind of model use? Is it on the scale of around the same as the file size? I&amp;#39;ve wondered how the &amp;quot;sparse&amp;quot; models&amp;#39; memory usage goes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9i7qp7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738006498,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9ix3so","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LetterRip","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9iso75","score":3,"author_fullname":"t2_3zb81","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes it is quite possible only a small percentage of the experts are relevant to many domain specific problems.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ix3so","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes it is quite possible only a small percentage of the experts are relevant to many domain specific problems.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ix3so/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738013617,"author_flair_text":null,"treatment_tags":[],"created_utc":1738013617,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9iso75","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"loadsamuny","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ibta6","score":3,"author_fullname":"t2_10p7p3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah really interesting, so would it be feasible to trace a model with some coding challenges and then prune off the non-coding layers to create a smaller coding focused version?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9iso75","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah really interesting, so would it be feasible to trace a model with some coding challenges and then prune off the non-coding layers to create a smaller coding focused version?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iso75/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738012389,"author_flair_text":null,"treatment_tags":[],"created_utc":1738012389,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9k8x8r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9k8bqt","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh whoops you're right 9*!! One expert is indeed shared - I also left that as 4/6bit!!","edited":false,"author_flair_css_class":null,"name":"t1_m9k8x8r","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh whoops you&amp;#39;re right 9*!! One expert is indeed shared - I also left that as 4/6bit!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1ibbloy","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k8x8r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738028329,"author_flair_text":null,"collapsed":false,"created_utc":1738028329,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9k8bqt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LetterRip","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9jzu1y","score":3,"author_fullname":"t2_3zb81","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great diagram, it is actually 9 (but definitely not 3) - 8 routed + 1 shared (also I vaguely recall the shared expert is significantly wider than the routed experts).  One key aspect of the DeepSeek MoE v3 Secret sauce is they have a 'shared expert' that is always routed to, and then the 'routed experts' that are selected on a per token basis. Also looks like it was 256 possible routed experts not 128.","edited":1738028634,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9k8bqt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great diagram, it is actually 9 (but definitely not 3) - 8 routed + 1 shared (also I vaguely recall the shared expert is significantly wider than the routed experts).  One key aspect of the DeepSeek MoE v3 Secret sauce is they have a &amp;#39;shared expert&amp;#39; that is always routed to, and then the &amp;#39;routed experts&amp;#39; that are selected on a per token basis. Also looks like it was 256 possible routed experts not 128.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k8bqt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738028136,"author_flair_text":null,"treatment_tags":[],"created_utc":1738028136,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jzu1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danielhanchen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m9ibta6","score":3,"author_fullname":"t2_5wukhd4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh 8 experts\\\\* out of 256 per token! :))\\n\\nI made a diagram for a MoE layer - left is Dense and right is MoE with 8 experts and selecting 2.\\n\\nThe trick is the white shaded areas are all 0, so we skip calculating them!\\n\\nhttps://preview.redd.it/trenejattmfe1.png?width=1477&amp;format=png&amp;auto=webp&amp;s=3cabd3d700d599294850f60a5b1e3862f42ac376","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m9jzu1y","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh 8 experts* out of 256 per token! :))&lt;/p&gt;\\n\\n&lt;p&gt;I made a diagram for a MoE layer - left is Dense and right is MoE with 8 experts and selecting 2.&lt;/p&gt;\\n\\n&lt;p&gt;The trick is the white shaded areas are all 0, so we skip calculating them!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/trenejattmfe1.png?width=1477&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cabd3d700d599294850f60a5b1e3862f42ac376\\"&gt;https://preview.redd.it/trenejattmfe1.png?width=1477&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cabd3d700d599294850f60a5b1e3862f42ac376&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jzu1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738025424,"media_metadata":{"trenejattmfe1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":45,"x":108,"u":"https://preview.redd.it/trenejattmfe1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=99def846ae520d330319734d7f6a565404e6cfba"},{"y":90,"x":216,"u":"https://preview.redd.it/trenejattmfe1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=777f78703495f7e0a4e6cc1516d4578b9f0f5d87"},{"y":134,"x":320,"u":"https://preview.redd.it/trenejattmfe1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ca5dbf2257bf474d277d90289b9db77ca68f9c6"},{"y":268,"x":640,"u":"https://preview.redd.it/trenejattmfe1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83f2e28de960bd4ef7041d6fb51d3611fd3c7c07"},{"y":402,"x":960,"u":"https://preview.redd.it/trenejattmfe1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=801afc40a8c355b8d6210acbdd8dfd8ec6b98398"},{"y":452,"x":1080,"u":"https://preview.redd.it/trenejattmfe1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5264e429e663e70eff0cd5790235bae9276d095"}],"s":{"y":619,"x":1477,"u":"https://preview.redd.it/trenejattmfe1.png?width=1477&amp;format=png&amp;auto=webp&amp;s=3cabd3d700d599294850f60a5b1e3862f42ac376"},"id":"trenejattmfe1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1738025424,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ibta6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LetterRip","can_mod_post":false,"created_utc":1738007634,"send_replies":true,"parent_id":"t1_m9iaq6w","score":3,"author_fullname":"t2_3zb81","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"MoE are just a replacement for the FFN layer, the token is routed to both the main (shared) expert (which is essentially the same as a normal FFN - it sees every token) and then additional specialized experts (each expert specializes in specific types of tokens, some specialize in punctation, some in nouns, verbs, math related tokens, code related tokens etc). On average there are 3 (edit 8 routed not 3) context specific experts chosen per layer per token (out of 128 experts I think it was? Edit - 256)\\n\\nYou might be thinking of a different meaning of 'mixture of experts' (where a entirely different full model is an 'expert')","edited":1738032505,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ibta6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MoE are just a replacement for the FFN layer, the token is routed to both the main (shared) expert (which is essentially the same as a normal FFN - it sees every token) and then additional specialized experts (each expert specializes in specific types of tokens, some specialize in punctation, some in nouns, verbs, math related tokens, code related tokens etc). On average there are 3 (edit 8 routed not 3) context specific experts chosen per layer per token (out of 128 experts I think it was? Edit - 256)&lt;/p&gt;\\n\\n&lt;p&gt;You might be thinking of a different meaning of &amp;#39;mixture of experts&amp;#39; (where a entirely different full model is an &amp;#39;expert&amp;#39;)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ibbloy","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ibta6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738007634,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m9iaq6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"loadsamuny","can_mod_post":false,"created_utc":1738007330,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_10p7p3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey Daniel, this is amazing. \\n\\nI have a naive question for you, can the experts be extracted / sliced out into their own models? (un-mixing them) or are the “mixture of experts” not actually distinct entities? \\n(I saw someone made a mixture of experts of mistral models a while ago and assumed it might be possible to reverse)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9iaq6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey Daniel, this is amazing. &lt;/p&gt;\\n\\n&lt;p&gt;I have a naive question for you, can the experts be extracted / sliced out into their own models? (un-mixing them) or are the “mixture of experts” not actually distinct entities? \\n(I saw someone made a mixture of experts of mistral models a while ago and assumed it might be possible to reverse)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9iaq6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738007330,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9ji3tl","id":"m9ji3tl","parent_id":"t1_m9jclxu","depth":1,"children":["m9ji3tl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jclxu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mgr2019x","can_mod_post":false,"created_utc":1738018054,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_3j19xoxz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you very much!! Could you do a V3 as well? :-D","edited":1738018485,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jclxu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you very much!! Could you do a V3 as well? :-D&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jclxu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738018054,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9ji293","id":"m9ji293","parent_id":"t1_m9je3se","depth":1,"children":["m9ji293"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9je3se","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Deredere12","can_mod_post":false,"created_utc":1738018502,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_dh8fn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have been trying to understand all of this and it’s so hard for some reason. Any good YouTube channels on how to learn this all? I have no idea what the bits and quantized MoEs are and would love to learn more.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9je3se","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have been trying to understand all of this and it’s so hard for some reason. Any good YouTube channels on how to learn this all? I have no idea what the bits and quantized MoEs are and would love to learn more.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9je3se/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738018502,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9lk9hq","id":"m9lk9hq","parent_id":"t1_m9jxney","depth":1,"children":["m9lk9hq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9jxney","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rae_1988","can_mod_post":false,"created_utc":1738024728,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_4ql3eu2xa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"giga chad","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9jxney","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;giga chad&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9jxney/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738024728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9lk8t2","id":"m9lk8t2","parent_id":"t1_m9k00vu","depth":1,"children":["m9lk8t2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9k00vu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MarceloTT","can_mod_post":false,"created_utc":1738025485,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_qya4m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have no words to thank you, this will help me a lot, I will try to increase accuracy using GRAG, a paper came out teaching a new technique that streamlines the search for knowledge by creating communities of knowledge agents organized by graphs and increases the accuracy of the model, I think can compensate for some loss. But thank you very much!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9k00vu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have no words to thank you, this will help me a lot, I will try to increase accuracy using GRAG, a paper came out teaching a new technique that streamlines the search for knowledge by creating communities of knowledge agents organized by graphs and increases the accuracy of the model, I think can compensate for some loss. But thank you very much!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k00vu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738025485,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9lhgsi","id":"m9lhgsi","parent_id":"t1_m9k69wu","depth":1,"children":["m9lhgsi"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9k69wu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheKing01","can_mod_post":false,"created_utc":1738027480,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_i0iy4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How fast does it run CPU only?\\n\\nThis comment claims they can get 5 tokens/second on CPU (I think they are talking about the original model?): https://huggingface.co/deepseek-ai/DeepSeek-R1/discussions/19#6793b75967103520df3ebf52","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9k69wu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How fast does it run CPU only?&lt;/p&gt;\\n\\n&lt;p&gt;This comment claims they can get 5 tokens/second on CPU (I think they are talking about the original model?): &lt;a href=\\"https://huggingface.co/deepseek-ai/DeepSeek-R1/discussions/19#6793b75967103520df3ebf52\\"&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1/discussions/19#6793b75967103520df3ebf52&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9k69wu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738027480,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9ll2eg","id":"m9ll2eg","parent_id":"t1_m9l7lm4","depth":1,"children":["m9ll2eg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9l7lm4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EastOriginal1622","can_mod_post":false,"created_utc":1738040744,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_1ac5m8m2x6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you sir!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9l7lm4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you sir!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9l7lm4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738040744,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1ibbloy","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9ljxqp","id":"m9ljxqp","parent_id":"t1_m9lcnr1","depth":1,"children":["m9ljxqp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9lcnr1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9lcnr1/","num_reports":null,"locked":false,"name":"t1_m9lcnr1","created":1738043077,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1738043077,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9lk3xs","id":"m9lk3xs","parent_id":"t1_m9ld2k1","depth":1,"children":["m9lk3xs"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ld2k1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"toothpastespiders","can_mod_post":false,"created_utc":1738043277,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_a2uzegb8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For what it's worth, just adding one more bit of thanks within the avalanche of it. Both for the accomplishment, and for always taking the time to describe how and why you accomplished all the cool LLM things you've done.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ld2k1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For what it&amp;#39;s worth, just adding one more bit of thanks within the avalanche of it. Both for the accomplishment, and for always taking the time to describe how and why you accomplished all the cool LLM things you&amp;#39;ve done.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ld2k1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738043277,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9m6ull","id":"m9m6ull","parent_id":"t1_m9ls6km","depth":1,"children":["m9m6ull"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9ls6km","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VentoraDreamy","can_mod_post":false,"created_utc":1738051656,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_jxu0uiks","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is there quantized version of 70b model?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9ls6km","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there quantized version of 70b model?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9ls6km/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738051656,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s3tfc","id":"m9s3tfc","parent_id":"t1_m9m7vqs","depth":1,"children":["m9s3tfc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9m7vqs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"its1968okwar","can_mod_post":false,"created_utc":1738061630,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_de8ojk2d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hero!!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9m7vqs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hero!!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9m7vqs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738061630,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s3s6f","id":"m9s3s6f","parent_id":"t1_m9mchhw","depth":1,"children":["m9s3s6f"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9mchhw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Revolutionary-Cup400","can_mod_post":false,"created_utc":1738064201,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_8a1wol8t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\\\- i7 10700 + DDR4 3200mhz 32\\\\*2 (64gb ram)\\n\\n\\\\- RTX 3090\\\\*2 (48g vram)\\n\\nI ran a 1.58-bit model with llama.cpp on the system.\\n\\nIn the llama-cli command in the blog post, I modified only the GPU offload layer to 15, and as a result of the execution, almost all of the system memory and VRAM were used, and the rest was offloaded to the SSD. Perhaps because of that, it unfortunately showed a low speed of about 0.1 to 0.2 tokens per second. 😥\\n\\nIf I did not do something wrong, I plan to increase the system memory to 128gb.\\n\\nAlso, if there is a significant effect on the speed improvement, I plan to bring in a 3090 from another computer and install it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9mchhw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;- i7 10700 + DDR4 3200mhz 32*2 (64gb ram)&lt;/p&gt;\\n\\n&lt;p&gt;- RTX 3090*2 (48g vram)&lt;/p&gt;\\n\\n&lt;p&gt;I ran a 1.58-bit model with llama.cpp on the system.&lt;/p&gt;\\n\\n&lt;p&gt;In the llama-cli command in the blog post, I modified only the GPU offload layer to 15, and as a result of the execution, almost all of the system memory and VRAM were used, and the rest was offloaded to the SSD. Perhaps because of that, it unfortunately showed a low speed of about 0.1 to 0.2 tokens per second. 😥&lt;/p&gt;\\n\\n&lt;p&gt;If I did not do something wrong, I plan to increase the system memory to 128gb.&lt;/p&gt;\\n\\n&lt;p&gt;Also, if there is a significant effect on the speed improvement, I plan to bring in a 3090 from another computer and install it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9mchhw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738064201,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9s2bmp","id":"m9s2bmp","parent_id":"t1_m9mtzqc","depth":1,"children":["m9s2bmp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9mtzqc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"separatelyrepeatedly","can_mod_post":false,"created_utc":1738071703,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_1amfw1yl2n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Allright boys 192gb RAM + 1x 3090 + 1x 4090. Wish me luck, going to try 2.51bit. \\n\\nAlso man how is huggingface paying for all this bandwidth.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9mtzqc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Allright boys 192gb RAM + 1x 3090 + 1x 4090. Wish me luck, going to try 2.51bit. &lt;/p&gt;\\n\\n&lt;p&gt;Also man how is huggingface paying for all this bandwidth.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9mtzqc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738071703,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s27on","id":"m9s27on","parent_id":"t1_m9nkoo6","depth":1,"children":["m9s27on"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9nkoo6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pushypro","can_mod_post":false,"created_utc":1738080133,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_c1jdwho1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Excellent list","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9nkoo6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Excellent list&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9nkoo6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738080133,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s26tl","id":"m9s26tl","parent_id":"t1_m9nn5vv","depth":1,"children":["m9s26tl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9nn5vv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AlanCarrOnline","can_mod_post":false,"created_utc":1738080839,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_ry6xs35o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So... my 3090 and 64 RAM could run this, slowly?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9nn5vv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So... my 3090 and 64 RAM could run this, slowly?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9nn5vv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738080839,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9zrsxo","id":"m9zrsxo","parent_id":"t1_m9o80mu","depth":1,"children":["m9zrsxo"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9o80mu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BrilliantArmadillo64","can_mod_post":false,"created_utc":1738086686,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_74bpyw3s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does anybody have a machine powerful enough to test this with https://github.com/ikawrakow/ik_llama.cpp ?\\nIt is a fork of llama.cpp with lots of CPU optimizations, among them a very fast 1.56Bit implementation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9o80mu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does anybody have a machine powerful enough to test this with &lt;a href=\\"https://github.com/ikawrakow/ik_llama.cpp\\"&gt;https://github.com/ikawrakow/ik_llama.cpp&lt;/a&gt; ?\\nIt is a fork of llama.cpp with lots of CPU optimizations, among them a very fast 1.56Bit implementation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9o80mu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738086686,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":6,"name":"t1_m9s1l86","id":"m9s1l86","parent_id":"t1_m9q714t","depth":1,"children":["m9s1l86"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9q714t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dealingwitholddata","can_mod_post":false,"created_utc":1738106550,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_2qatlocm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If I have 64gb of ddr5 ram and a 4080 can I run any of these at all? Any speed is acceptable, I'll treat it like an email conversation.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9q714t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If I have 64gb of ddr5 ram and a 4080 can I run any of these at all? Any speed is acceptable, I&amp;#39;ll treat it like an email conversation.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9q714t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738106550,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9s1bkp","id":"m9s1bkp","parent_id":"t1_m9qmi07","depth":1,"children":["m9s1bkp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9qmi07","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"inteblio","can_mod_post":false,"created_utc":1738111400,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_bzdh4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It fizzles my bonnet what you boffins can do. Cake!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9qmi07","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It fizzles my bonnet what you boffins can do. Cake!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9qmi07/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738111400,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m9skymk","id":"m9skymk","parent_id":"t1_m9saloo","depth":1,"children":["m9skymk","m9wm5s1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9saloo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahtolllka","can_mod_post":false,"created_utc":1738134557,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_brpth","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wasn’t able to start it with vLLM, it says architecture not supported (I merged it to single gguf of course). Tried vllm 0.6.6, 0.7, v1.  Has someone accomplished this task? What have you tuned and what are sampling parameters you’ve used?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9saloo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wasn’t able to start it with vLLM, it says architecture not supported (I merged it to single gguf of course). Tried vllm 0.6.6, 0.7, v1.  Has someone accomplished this task? What have you tuned and what are sampling parameters you’ve used?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9saloo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738134557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9skz5w","id":"m9skz5w","parent_id":"t1_m9sbxf0","depth":1,"children":["m9skz5w"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9sbxf0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"townofsalemfangay","can_mod_post":false,"created_utc":1738135303,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_122dsg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You're doing the lords work, mate. Well done.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9sbxf0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re doing the lords work, mate. Well done.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9sbxf0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738135303,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9sqtvf","id":"m9sqtvf","parent_id":"t1_m9spp6g","depth":1,"children":["m9sqtvf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9spp6g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Deep-Refrigerator362","can_mod_post":false,"created_utc":1738143735,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_w8zns2nnv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Stellar work my brother!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9spp6g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Stellar work my brother!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9spp6g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738143735,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9t00hm","id":"m9t00hm","parent_id":"t1_m9suljj","depth":1,"children":["m9t00hm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9suljj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Spiritual_Option_963","can_mod_post":false,"created_utc":1738146776,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_blbfd8ls","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We need to test it on nvidia's new project digits when it comes out. It's gonna be awesome year.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9suljj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We need to test it on nvidia&amp;#39;s new project digits when it comes out. It&amp;#39;s gonna be awesome year.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9suljj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738146776,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9zqb17","id":"m9zqb17","parent_id":"t1_m9uxh5c","depth":1,"children":["m9zqb17"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9uxh5c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"smflx","can_mod_post":false,"created_utc":1738173016,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_16qe65sqwe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just checked Q2\\\\_K\\\\_XL(2.51bit)  on Epyc Genoa 9534 (64 core) with 12 channel memory.   It's usable.  I will check more about other quants and cpus.   It's cpu only!  Many thanks to MoE deepseek &amp; Unsloth.\\n\\nprompt eval time =   25679.53 ms /    29 tokens (  885.50 ms per token,     1.13 tokens per second)\\n\\neval time =  514394.86 ms /  3536 runs   (  145.47 ms per token,     6.87 tokens per second)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9uxh5c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just checked Q2_K_XL(2.51bit)  on Epyc Genoa 9534 (64 core) with 12 channel memory.   It&amp;#39;s usable.  I will check more about other quants and cpus.   It&amp;#39;s cpu only!  Many thanks to MoE deepseek &amp;amp; Unsloth.&lt;/p&gt;\\n\\n&lt;p&gt;prompt eval time =   25679.53 ms /    29 tokens (  885.50 ms per token,     1.13 tokens per second)&lt;/p&gt;\\n\\n&lt;p&gt;eval time =  514394.86 ms /  3536 runs   (  145.47 ms per token,     6.87 tokens per second)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9uxh5c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738173016,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m9zq9qg","id":"m9zq9qg","parent_id":"t1_m9z7o27","depth":1,"children":["m9zq9qg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9z7o27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JoshS-345","can_mod_post":false,"created_utc":1738224342,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_308kbj9h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have an rtx a6000 (48gb)\\n\\nan MI50 (32 gb version) \\n\\nand a 3060 (12 gb)\\n\\nbut I suspect my system ram of 128 gb is too small for this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9z7o27","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have an rtx a6000 (48gb)&lt;/p&gt;\\n\\n&lt;p&gt;an MI50 (32 gb version) &lt;/p&gt;\\n\\n&lt;p&gt;and a 3060 (12 gb)&lt;/p&gt;\\n\\n&lt;p&gt;but I suspect my system ram of 128 gb is too small for this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9z7o27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738224342,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":3,"name":"t1_m9zq66x","id":"m9zq66x","parent_id":"t1_m9zk2tu","depth":1,"children":["m9zq66x"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m9zk2tu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FroHawk98","can_mod_post":false,"created_utc":1738232112,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_xx984","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have it running nicely on my 4090 with the heaviest model. Well done.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9zk2tu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have it running nicely on my 4090 with the heaviest model. Well done.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/m9zk2tu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738232112,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_ma5t2to","id":"ma5t2to","parent_id":"t1_ma0v9ci","depth":1,"children":["ma5t2to"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma0v9ci","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ybdave","can_mod_post":false,"created_utc":1738251234,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_3gqt4j1k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you very much for your work! Would you happen to have any benchmarks done? I have 8x3090, and I’m very curious to see if I can get a decent level running…","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma0v9ci","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you very much for your work! Would you happen to have any benchmarks done? I have 8x3090, and I’m very curious to see if I can get a decent level running…&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/ma0v9ci/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738251234,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma5t606","id":"ma5t606","parent_id":"t1_ma186ay","depth":1,"children":["ma5t606"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma186ay","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LycanWolfe","can_mod_post":false,"created_utc":1738254920,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_14i3kw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ollama pull SIGJNF/deepseek-r1-671b-1.58bit (https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit)\\n\\nollama pull Huzderu/deepseek-r1-671b-1.73bit (https://ollama.com/Huzderu/deepseek-r1-671b-1.73bit)\\n\\nollama pull Huzderu/deepseek-r1-671b-2.22bit (https://ollama.com/Huzderu/deepseek-r1-671b-2.22bit)","edited":1738256986,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma186ay","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ollama pull SIGJNF/deepseek-r1-671b-1.58bit (&lt;a href=\\"https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit\\"&gt;https://ollama.com/SIGJNF/deepseek-r1-671b-1.58bit&lt;/a&gt;)&lt;/p&gt;\\n\\n&lt;p&gt;ollama pull Huzderu/deepseek-r1-671b-1.73bit (&lt;a href=\\"https://ollama.com/Huzderu/deepseek-r1-671b-1.73bit\\"&gt;https://ollama.com/Huzderu/deepseek-r1-671b-1.73bit&lt;/a&gt;)&lt;/p&gt;\\n\\n&lt;p&gt;ollama pull Huzderu/deepseek-r1-671b-2.22bit (&lt;a href=\\"https://ollama.com/Huzderu/deepseek-r1-671b-2.22bit\\"&gt;https://ollama.com/Huzderu/deepseek-r1-671b-2.22bit&lt;/a&gt;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/ma186ay/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738254920,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma5t0f9","id":"ma5t0f9","parent_id":"t1_ma297p0","depth":1,"children":["ma5t0f9"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma297p0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pffnopee","can_mod_post":false,"created_utc":1738265100,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_x9ghor5ez","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you. Excellent work","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma297p0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. Excellent work&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/ma297p0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738265100,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma5t77q","id":"ma5t77q","parent_id":"t1_ma53y6n","depth":1,"children":["ma5t77q"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma53y6n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BABA_yaaGa","can_mod_post":false,"created_utc":1738297001,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_meae4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Now I just want to get another ssd to try this locally. This is awesome!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma53y6n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now I just want to get another ssd to try this locally. This is awesome!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/ma53y6n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738297001,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_ma5sxee","id":"ma5sxee","parent_id":"t1_ma5eoto","depth":1,"children":["ma5sxee"]}}],"before":null}},"user_reports":[],"saved":false,"id":"ma5eoto","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poop_on_balls","can_mod_post":false,"created_utc":1738301526,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_4folaes6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_ma5eoto","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/ma5eoto/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738301526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mc5xh90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"np-n","can_mod_post":false,"created_utc":1739271831,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_l2yc5jx6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have tried running R1-1.58 bit in my device with RTX 3090 24 GB GPU and 64 GB of RAM. I am loading 7 layers to GPU. Currently 24/24 GB of GPU and 20/64 GB of CPU have been utilized.  I am using llama.cpp and  exactly following unslot blog.\\n\\n./llama.cpp/llama-cli \\\\\\\\  \\n\\\\--model DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1\\\\_S/DeepSeek-R1-UD-IQ1\\\\_S-00001-of-00003.gguf \\\\\\\\  \\n\\\\--cache-type-k q4\\\\_0 \\\\\\\\  \\n\\\\--threads 16 \\\\\\\\  \\n\\\\--prio 2 \\\\\\\\  \\n\\\\--temp 0.6 \\\\\\\\  \\n\\\\--ctx-size 8192 \\\\\\\\  \\n\\\\--seed 3407 \\\\\\\\  \\n\\\\--n-gpu-layers 7 \\\\\\\\  \\n\\\\-no-cnv \\\\\\\\  \\n\\\\--prompt \\"&lt;｜User｜&gt;Create a Flappy Bird game in Python.&lt;｜Assistant｜&gt;\\"\\n\\nBut, I stuck on inference. I waited for more than 30 minutes but couldn't get the response. Why it is taking that much of time, I don't have any idea. Could you please help me on it. What might be the problems. Thank you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc5xh90","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have tried running R1-1.58 bit in my device with RTX 3090 24 GB GPU and 64 GB of RAM. I am loading 7 layers to GPU. Currently 24/24 GB of GPU and 20/64 GB of CPU have been utilized.  I am using llama.cpp and  exactly following unslot blog.&lt;/p&gt;\\n\\n&lt;p&gt;./llama.cpp/llama-cli \\\\&lt;br/&gt;\\n--model DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1_S/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf \\\\&lt;br/&gt;\\n--cache-type-k q4_0 \\\\&lt;br/&gt;\\n--threads 16 \\\\&lt;br/&gt;\\n--prio 2 \\\\&lt;br/&gt;\\n--temp 0.6 \\\\&lt;br/&gt;\\n--ctx-size 8192 \\\\&lt;br/&gt;\\n--seed 3407 \\\\&lt;br/&gt;\\n--n-gpu-layers 7 \\\\&lt;br/&gt;\\n-no-cnv \\\\&lt;br/&gt;\\n--prompt &amp;quot;&amp;lt;｜User｜&amp;gt;Create a Flappy Bird game in Python.&amp;lt;｜Assistant｜&amp;gt;&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;But, I stuck on inference. I waited for more than 30 minutes but couldn&amp;#39;t get the response. Why it is taking that much of time, I don&amp;#39;t have any idea. Could you please help me on it. What might be the problems. Thank you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/mc5xh90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739271831,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mih757c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"akrit8888","can_mod_post":false,"created_utc":1742321273,"send_replies":true,"parent_id":"t3_1ibbloy","score":2,"author_fullname":"t2_cix5bft8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder what is stopping a largest model for dynamic quant at 2.51bit?\\n\\nAnd how well does the dynamic quant model such as 2.51bit compare against a standard quantization method at 3bit or 4bit?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mih757c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder what is stopping a largest model for dynamic quant at 2.51bit?&lt;/p&gt;\\n\\n&lt;p&gt;And how well does the dynamic quant model such as 2.51bit compare against a standard quantization method at 3bit or 4bit?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ibbloy/158bit_deepseek_r1_131gb_dynamic_gguf/mih757c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1742321273,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ibbloy","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":176,"name":"t1_m9hdl7d","id":"m9hdl7d","parent_id":"t3_1ibbloy","depth":0,"children":["m9hdl7d","m9kd5lx","m9kkm7o","m9n3oae","m9hcvyd","m9ozdzl","m9qkma0","m9hdhpt","m9l6ny7","m9iki6b","m9m057h","m9mqyca","m9hcafv","m9m9436","m9n3c10","m9knumn","mklfeek","m9int24","m9oigqh","ma7yarr","m9re3a9","md46iqr","m9i2l3s","m9rlhiz","m9hc1ve","ma5lf9r","mbecsgm","ma3r757","mbuffu5","ma6nn74","m9jkhv2","m9qwqxx","m9kb70z","m9khqna","m9hxebp","m9ml8fl","m9m3d3i","m9mlkdd","m9rpjhw","mafbskd","m9np3it","m9ntpfx","m9t8f21","m9rh76f","m9m6cu9","m9id2ic","m9smv5r","mbdzfr4","ma4ubrt","m9jn7c1","m9lualw","m9kgud3","m9tvz51","m9sqyve","m9jlh1i","m9gyc9v","m9s7h4v","m9pnjlg","maqi2ut","m9olmyc","m9hdmju","m9zw7dw","m9i0ycm","mb9l4rw","mdvf95h","m9hq592","ma7fv8u","m9qg5zl","m9olev9","m9llzxm","m9olbrb","mac1d8s","mc5gyuw","mcct5zb","m9ndca3","mba1fjz","mbf09m0","mgx202q","ma7qn8m"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
