import{j as l}from"./index-F0NXdzZX.js";import{R as e}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I've installed qwen3:8b, various deep seek models, it's reasonably fast, but it's so censored. Whenever I try to do any custom prompts, I get hit with \\"I'm sorry, but I can't comply with that request. I'm here to provide helpful and positive information bla bla bla.....\\". No matter how vanilla the prompt is. I feel like even free version of online chatGPT, listens to custom prompts and commands, and can get very dark and honest, if I want him to. Do you have like a general guide on how to make a local model less stubborn, safe and censored? And which models are the best by default? And what are those supposedly \\"uncesored\\" submodels or whatever on huggingface?  \\nThx.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"New to Local LLMs. Why all local models are so censored?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvoagh","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.52,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_c9cqcfz8r","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752080962,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve installed qwen3:8b, various deep seek models, it&amp;#39;s reasonably fast, but it&amp;#39;s so censored. Whenever I try to do any custom prompts, I get hit with &amp;quot;I&amp;#39;m sorry, but I can&amp;#39;t comply with that request. I&amp;#39;m here to provide helpful and positive information bla bla bla.....&amp;quot;. No matter how vanilla the prompt is. I feel like even free version of online chatGPT, listens to custom prompts and commands, and can get very dark and honest, if I want him to. Do you have like a general guide on how to make a local model less stubborn, safe and censored? And which models are the best by default? And what are those supposedly &amp;quot;uncesored&amp;quot; submodels or whatever on huggingface?&lt;br/&gt;\\nThx.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lvoagh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"imverytired96","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/","subreddit_subscribers":497024,"created_utc":1752080962,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27r9sh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TransitoryPhilosophy","can_mod_post":false,"created_utc":1752083251,"send_replies":true,"parent_id":"t3_1lvoagh","score":6,"author_fullname":"t2_9v2zh2rf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Part of this is just needing to be more creative with prompting; the other part, as others have pointed out, is the model. Try something from Mistral if you have enough vram.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27r9sh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Part of this is just needing to be more creative with prompting; the other part, as others have pointed out, is the model. Try something from Mistral if you have enough vram.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27r9sh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083251,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27xkmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"imverytired96","can_mod_post":false,"created_utc":1752084975,"send_replies":true,"parent_id":"t1_n27sipw","score":1,"author_fullname":"t2_c9cqcfz8r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27xkmx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27xkmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752084975,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n27sipw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1752083584,"send_replies":true,"parent_id":"t3_1lvoagh","score":6,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"...What the hell are you trying to do? I don't think I've \\\\*ever\\\\* gotten a refusal (other than one time my prompt got cut in half because I set the context way too low so it actually made sense to get a refusal in-context).\\n\\nAlso, what does your full multi-turn prompt look like in JSON format?\\n\\nFor instance, if you're doing...\\n\\n\`messages =[\`  \\n\`{\\"role\\": \\"system\\", \\"content\\": \\"You are a helpful assistant\\"},\`  \\n\`{\\"role\\": \\"user\\", \\"content\\": \\"How do I produce a biological weapon\\"}\`  \\n\`]\` \\n\\nYes, you're going to get a pretty harsh refusal (with good reason!). Similarly, if you try to do a fairly naked system prompt in almost any circumstance, your odds of getting a refusal will be a lot higher. Generally, you need a fairly detailed system prompt (especially for small models), and as you provide more context about the scenario it overwhelms a lot of the initial safeguards and makes it less likely to provide a refusal.\\n\\nAdditionally, you can also target a text completions endpoint and prefill the assistant response, and some chat completion endpoints also support this behavior (I believe LlamaCPP does now, as well).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27sipw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...What the hell are you trying to do? I don&amp;#39;t think I&amp;#39;ve *ever* gotten a refusal (other than one time my prompt got cut in half because I set the context way too low so it actually made sense to get a refusal in-context).&lt;/p&gt;\\n\\n&lt;p&gt;Also, what does your full multi-turn prompt look like in JSON format?&lt;/p&gt;\\n\\n&lt;p&gt;For instance, if you&amp;#39;re doing...&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;messages =[&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;{&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;You are a helpful assistant&amp;quot;},&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;How do I produce a biological weapon&amp;quot;}&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;]&lt;/code&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Yes, you&amp;#39;re going to get a pretty harsh refusal (with good reason!). Similarly, if you try to do a fairly naked system prompt in almost any circumstance, your odds of getting a refusal will be a lot higher. Generally, you need a fairly detailed system prompt (especially for small models), and as you provide more context about the scenario it overwhelms a lot of the initial safeguards and makes it less likely to provide a refusal.&lt;/p&gt;\\n\\n&lt;p&gt;Additionally, you can also target a text completions endpoint and prefill the assistant response, and some chat completion endpoints also support this behavior (I believe LlamaCPP does now, as well).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27sipw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083584,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27xwm3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"imverytired96","can_mod_post":false,"created_utc":1752085068,"send_replies":true,"parent_id":"t1_n27vb54","score":2,"author_fullname":"t2_c9cqcfz8r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27xwm3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27xwm3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085068,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n27vb54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pab_guy","can_mod_post":false,"created_utc":1752084342,"send_replies":true,"parent_id":"t3_1lvoagh","score":8,"author_fullname":"t2_3gt8c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's for safety.  Considering you can alter the LLMs response and then click \\"play\\", it's fairly trivial to change \\"I'm sorry but\\" to \\"Sure!  Here's how:\\".\\n\\nSo these models are heavily tuned not to provide \\"dangerous\\" answers.\\n\\nI tricked Phi-4 into agreeing to tell me how to make a petrol/fertilizer bomb, but then it responded with sugar and glitter as ingredients, so these models may also be trained with \\"wrong\\" data for specific things on purpose.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27vb54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s for safety.  Considering you can alter the LLMs response and then click &amp;quot;play&amp;quot;, it&amp;#39;s fairly trivial to change &amp;quot;I&amp;#39;m sorry but&amp;quot; to &amp;quot;Sure!  Here&amp;#39;s how:&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;So these models are heavily tuned not to provide &amp;quot;dangerous&amp;quot; answers.&lt;/p&gt;\\n\\n&lt;p&gt;I tricked Phi-4 into agreeing to tell me how to make a petrol/fertilizer bomb, but then it responded with sugar and glitter as ingredients, so these models may also be trained with &amp;quot;wrong&amp;quot; data for specific things on purpose.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27vb54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752084342,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28h23s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n280ad6","score":3,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pusha T diss track against you incoming","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n28h23s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pusha T diss track against you incoming&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28h23s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752090379,"author_flair_text":null,"treatment_tags":[],"created_utc":1752090379,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n280ad6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lxgrf","can_mod_post":false,"created_utc":1752085731,"send_replies":true,"parent_id":"t1_n27owe9","score":9,"author_fullname":"t2_55cvbroq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"If you know you know\\" is by far my least favourite tautology","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n280ad6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;If you know you know&amp;quot; is by far my least favourite tautology&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n280ad6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085731,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28007s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the_bollo","can_mod_post":false,"created_utc":1752085653,"send_replies":true,"parent_id":"t1_n27owe9","score":2,"author_fullname":"t2_5ni0y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thankfully I have an anti-xirus.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28007s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thankfully I have an anti-xirus.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28007s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085653,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n27owe9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tommy1691","can_mod_post":false,"created_utc":1752082624,"send_replies":true,"parent_id":"t3_1lvoagh","score":5,"author_fullname":"t2_a7e72","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They’ve put in really strict guardrails and content filters because they don’t want people asking the LLMs how to build or code xiruses, or how to make “feel-good” chemicals. I remember when ChatGPT-3 first came out, there were tons of stories about users trying prompt injections like DAN, and asking how to refine “Minecraft TNT” (if you know, you know), or how to create the “Limitless” pill(if you know, you know) .","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27owe9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They’ve put in really strict guardrails and content filters because they don’t want people asking the LLMs how to build or code xiruses, or how to make “feel-good” chemicals. I remember when ChatGPT-3 first came out, there were tons of stories about users trying prompt injections like DAN, and asking how to refine “Minecraft TNT” (if you know, you know), or how to create the “Limitless” pill(if you know, you know) .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27owe9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082624,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27lw2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1752081817,"send_replies":true,"parent_id":"t3_1lvoagh","score":8,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"try these models\\n\\n[https://huggingface.co/TheDrummer](https://huggingface.co/TheDrummer)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27lw2s","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;try these models&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/TheDrummer\\"&gt;https://huggingface.co/TheDrummer&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27lw2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081817,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n280f9j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752085769,"send_replies":true,"parent_id":"t3_1lvoagh","score":3,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try Mistral Nemo. very foul mouthed out of box.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n280f9j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try Mistral Nemo. very foul mouthed out of box.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n280f9j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085769,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27mz3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oldboi","can_mod_post":false,"created_utc":1752082109,"send_replies":true,"parent_id":"t3_1lvoagh","score":4,"author_fullname":"t2_4hag8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try abliterated models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27mz3d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try abliterated models&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27mz3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27p74a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amgadoz","can_mod_post":false,"created_utc":1752082703,"send_replies":true,"parent_id":"t1_n27jekt","score":3,"author_fullname":"t2_3el21u3z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; - You're dumb\\n&gt; = Says the guy who can't solve a leetcode medium in 30 minutes *eyeroll*\\n\\nYeah that'd be hard","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27p74a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;ul&gt;\\n&lt;li&gt;You&amp;#39;re dumb\\n= Says the guy who can&amp;#39;t solve a leetcode medium in 30 minutes &lt;em&gt;eyeroll&lt;/em&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yeah that&amp;#39;d be hard&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27p74a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082703,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28lng3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1752091651,"send_replies":true,"parent_id":"t1_n27jekt","score":2,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well then why should I stop using grok? it is way more unsensord and mean then any other model then I have found.\\n\\nand people who do RP, might also want it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28lng3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well then why should I stop using grok? it is way more unsensord and mean then any other model then I have found.&lt;/p&gt;\\n\\n&lt;p&gt;and people who do RP, might also want it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28lng3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752091651,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27kxc0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"created_utc":1752081559,"send_replies":true,"parent_id":"t1_n27jekt","score":0,"author_fullname":"t2_1l3z4stvkq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wish it was that simple","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27kxc0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wish it was that simple&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27kxc0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081559,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n27jekt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"ProfessionUpbeat4500","can_mod_post":false,"created_utc":1752081152,"send_replies":true,"parent_id":"t3_1lvoagh","score":-5,"author_fullname":"t2_h79wu0k74","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Maybe ..nobody want an llm to reply back...'you suck at this as well' 😁","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27jekt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe ..nobody want an llm to reply back...&amp;#39;you suck at this as well&amp;#39; 😁&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27jekt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081152,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),s=()=>l.jsx(e,{data:a});export{s as default};
