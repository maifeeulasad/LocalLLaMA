import{j as l}from"./index-F0NXdzZX.js";import{R as e}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I've installed qwen3:8b, various deep seek models, it's reasonably fast, but it's so censored. Whenever I try to do any custom prompts, I get hit with \\"I'm sorry, but I can't comply with that request. I'm here to provide helpful and positive information bla bla bla.....\\". No matter how vanilla the prompt is. I feel like even free version of online chatGPT, listens to custom prompts and commands, and can get very dark and honest, if I want him to. Do you have like a general guide on how to make a local model less stubborn, safe and censored? And which models are the best by default? And what are those supposedly \\"uncesored\\" submodels or whatever on huggingface?  \\nThx.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"New to Local LLMs. Why all local models are so censored?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvoagh","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.52,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_c9cqcfz8r","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752080962,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve installed qwen3:8b, various deep seek models, it&amp;#39;s reasonably fast, but it&amp;#39;s so censored. Whenever I try to do any custom prompts, I get hit with &amp;quot;I&amp;#39;m sorry, but I can&amp;#39;t comply with that request. I&amp;#39;m here to provide helpful and positive information bla bla bla.....&amp;quot;. No matter how vanilla the prompt is. I feel like even free version of online chatGPT, listens to custom prompts and commands, and can get very dark and honest, if I want him to. Do you have like a general guide on how to make a local model less stubborn, safe and censored? And which models are the best by default? And what are those supposedly &amp;quot;uncesored&amp;quot; submodels or whatever on huggingface?&lt;br/&gt;\\nThx.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lvoagh","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"imverytired96","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/","subreddit_subscribers":497024,"created_utc":1752080962,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27r9sh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TransitoryPhilosophy","can_mod_post":false,"created_utc":1752083251,"send_replies":true,"parent_id":"t3_1lvoagh","score":6,"author_fullname":"t2_9v2zh2rf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Part of this is just needing to be more creative with prompting; the other part, as others have pointed out, is the model. Try something from Mistral if you have enough vram.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27r9sh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Part of this is just needing to be more creative with prompting; the other part, as others have pointed out, is the model. Try something from Mistral if you have enough vram.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27r9sh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083251,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27xkmx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"imverytired96","can_mod_post":false,"created_utc":1752084975,"send_replies":true,"parent_id":"t1_n27sipw","score":1,"author_fullname":"t2_c9cqcfz8r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27xkmx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27xkmx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752084975,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n27sipw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Double_Cause4609","can_mod_post":false,"created_utc":1752083584,"send_replies":true,"parent_id":"t3_1lvoagh","score":6,"author_fullname":"t2_1kubzxt2ww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"...What the hell are you trying to do? I don't think I've \\\\*ever\\\\* gotten a refusal (other than one time my prompt got cut in half because I set the context way too low so it actually made sense to get a refusal in-context).\\n\\nAlso, what does your full multi-turn prompt look like in JSON format?\\n\\nFor instance, if you're doing...\\n\\n\`messages =[\`  \\n\`{\\"role\\": \\"system\\", \\"content\\": \\"You are a helpful assistant\\"},\`  \\n\`{\\"role\\": \\"user\\", \\"content\\": \\"How do I produce a biological weapon\\"}\`  \\n\`]\` \\n\\nYes, you're going to get a pretty harsh refusal (with good reason!). Similarly, if you try to do a fairly naked system prompt in almost any circumstance, your odds of getting a refusal will be a lot higher. Generally, you need a fairly detailed system prompt (especially for small models), and as you provide more context about the scenario it overwhelms a lot of the initial safeguards and makes it less likely to provide a refusal.\\n\\nAdditionally, you can also target a text completions endpoint and prefill the assistant response, and some chat completion endpoints also support this behavior (I believe LlamaCPP does now, as well).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27sipw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...What the hell are you trying to do? I don&amp;#39;t think I&amp;#39;ve *ever* gotten a refusal (other than one time my prompt got cut in half because I set the context way too low so it actually made sense to get a refusal in-context).&lt;/p&gt;\\n\\n&lt;p&gt;Also, what does your full multi-turn prompt look like in JSON format?&lt;/p&gt;\\n\\n&lt;p&gt;For instance, if you&amp;#39;re doing...&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;messages =[&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;{&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;You are a helpful assistant&amp;quot;},&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;How do I produce a biological weapon&amp;quot;}&lt;/code&gt;&lt;br/&gt;\\n&lt;code&gt;]&lt;/code&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Yes, you&amp;#39;re going to get a pretty harsh refusal (with good reason!). Similarly, if you try to do a fairly naked system prompt in almost any circumstance, your odds of getting a refusal will be a lot higher. Generally, you need a fairly detailed system prompt (especially for small models), and as you provide more context about the scenario it overwhelms a lot of the initial safeguards and makes it less likely to provide a refusal.&lt;/p&gt;\\n\\n&lt;p&gt;Additionally, you can also target a text completions endpoint and prefill the assistant response, and some chat completion endpoints also support this behavior (I believe LlamaCPP does now, as well).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27sipw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752083584,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27xwm3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"imverytired96","can_mod_post":false,"created_utc":1752085068,"send_replies":true,"parent_id":"t1_n27vb54","score":2,"author_fullname":"t2_c9cqcfz8r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thx","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27xwm3","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thx&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27xwm3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085068,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n27vb54","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pab_guy","can_mod_post":false,"created_utc":1752084342,"send_replies":true,"parent_id":"t3_1lvoagh","score":8,"author_fullname":"t2_3gt8c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's for safety.  Considering you can alter the LLMs response and then click \\"play\\", it's fairly trivial to change \\"I'm sorry but\\" to \\"Sure!  Here's how:\\".\\n\\nSo these models are heavily tuned not to provide \\"dangerous\\" answers.\\n\\nI tricked Phi-4 into agreeing to tell me how to make a petrol/fertilizer bomb, but then it responded with sugar and glitter as ingredients, so these models may also be trained with \\"wrong\\" data for specific things on purpose.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27vb54","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s for safety.  Considering you can alter the LLMs response and then click &amp;quot;play&amp;quot;, it&amp;#39;s fairly trivial to change &amp;quot;I&amp;#39;m sorry but&amp;quot; to &amp;quot;Sure!  Here&amp;#39;s how:&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;So these models are heavily tuned not to provide &amp;quot;dangerous&amp;quot; answers.&lt;/p&gt;\\n\\n&lt;p&gt;I tricked Phi-4 into agreeing to tell me how to make a petrol/fertilizer bomb, but then it responded with sugar and glitter as ingredients, so these models may also be trained with &amp;quot;wrong&amp;quot; data for specific things on purpose.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27vb54/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752084342,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28h23s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n280ad6","score":3,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pusha T diss track against you incoming","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n28h23s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pusha T diss track against you incoming&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28h23s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752090379,"author_flair_text":null,"treatment_tags":[],"created_utc":1752090379,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n280ad6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lxgrf","can_mod_post":false,"created_utc":1752085731,"send_replies":true,"parent_id":"t1_n27owe9","score":9,"author_fullname":"t2_55cvbroq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"If you know you know\\" is by far my least favourite tautology","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n280ad6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;If you know you know&amp;quot; is by far my least favourite tautology&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n280ad6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085731,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28007s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the_bollo","can_mod_post":false,"created_utc":1752085653,"send_replies":true,"parent_id":"t1_n27owe9","score":2,"author_fullname":"t2_5ni0y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thankfully I have an anti-xirus.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28007s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thankfully I have an anti-xirus.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28007s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085653,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n27owe9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tommy1691","can_mod_post":false,"created_utc":1752082624,"send_replies":true,"parent_id":"t3_1lvoagh","score":5,"author_fullname":"t2_a7e72","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Theyâ€™ve put in really strict guardrails and content filters because they donâ€™t want people asking the LLMs how to build or code xiruses, or how to make â€œfeel-goodâ€ chemicals. I remember when ChatGPT-3 first came out, there were tons of stories about users trying prompt injections like DAN, and asking how to refine â€œMinecraft TNTâ€ (if you know, you know), or how to create the â€œLimitlessâ€ pill(if you know, you know) .","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27owe9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Theyâ€™ve put in really strict guardrails and content filters because they donâ€™t want people asking the LLMs how to build or code xiruses, or how to make â€œfeel-goodâ€ chemicals. I remember when ChatGPT-3 first came out, there were tons of stories about users trying prompt injections like DAN, and asking how to refine â€œMinecraft TNTâ€ (if you know, you know), or how to create the â€œLimitlessâ€ pill(if you know, you know) .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27owe9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082624,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27lw2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jacek2023","can_mod_post":false,"created_utc":1752081817,"send_replies":true,"parent_id":"t3_1lvoagh","score":8,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"try these models\\n\\n[https://huggingface.co/TheDrummer](https://huggingface.co/TheDrummer)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27lw2s","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;try these models&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/TheDrummer\\"&gt;https://huggingface.co/TheDrummer&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27lw2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081817,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n280f9j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752085769,"send_replies":true,"parent_id":"t3_1lvoagh","score":3,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try Mistral Nemo. very foul mouthed out of box.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n280f9j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try Mistral Nemo. very foul mouthed out of box.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n280f9j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752085769,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27mz3d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oldboi","can_mod_post":false,"created_utc":1752082109,"send_replies":true,"parent_id":"t3_1lvoagh","score":4,"author_fullname":"t2_4hag8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try abliterated models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27mz3d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try abliterated models&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27mz3d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082109,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27p74a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amgadoz","can_mod_post":false,"created_utc":1752082703,"send_replies":true,"parent_id":"t1_n27jekt","score":3,"author_fullname":"t2_3el21u3z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; - You're dumb\\n&gt; = Says the guy who can't solve a leetcode medium in 30 minutes *eyeroll*\\n\\nYeah that'd be hard","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27p74a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;ul&gt;\\n&lt;li&gt;You&amp;#39;re dumb\\n= Says the guy who can&amp;#39;t solve a leetcode medium in 30 minutes &lt;em&gt;eyeroll&lt;/em&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yeah that&amp;#39;d be hard&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27p74a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752082703,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28lng3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1752091651,"send_replies":true,"parent_id":"t1_n27jekt","score":2,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"well then why should I stop using grok? it is way more unsensord and mean then any other model then I have found.\\n\\nand people who do RP, might also want it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n28lng3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well then why should I stop using grok? it is way more unsensord and mean then any other model then I have found.&lt;/p&gt;\\n\\n&lt;p&gt;and people who do RP, might also want it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n28lng3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752091651,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n27kxc0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"created_utc":1752081559,"send_replies":true,"parent_id":"t1_n27jekt","score":0,"author_fullname":"t2_1l3z4stvkq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wish it was that simple","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27kxc0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wish it was that simple&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvoagh","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27kxc0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081559,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n27jekt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"ProfessionUpbeat4500","can_mod_post":false,"created_utc":1752081152,"send_replies":true,"parent_id":"t3_1lvoagh","score":-5,"author_fullname":"t2_h79wu0k74","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Maybe ..nobody want an llm to reply back...'you suck at this as well' ðŸ˜","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n27jekt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe ..nobody want an llm to reply back...&amp;#39;you suck at this as well&amp;#39; ðŸ˜&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvoagh/new_to_local_llms_why_all_local_models_are_so/n27jekt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752081152,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvoagh","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),s=()=>l.jsx(e,{data:a});export{s as default};
