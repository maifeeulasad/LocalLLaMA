import{j as e}from"./index-C9o7w-KS.js";import{R as l}from"./RedditPostRenderer-C4RcPiw4.js";import"./index-CvnyzE1l.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"is_gallery":true,"title":"DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":97,"top_awarded_type":null,"name":"t3_1juni3t","media_metadata":{"krz6zcjf6ote1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":75,"x":108,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea5b35d9b6e38c7cc859447f5f9ab850f4ff74b4"},{"y":150,"x":216,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=48c4db3b24ae46a79ce8264ab31e3bd64d3831ac"},{"y":223,"x":320,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd42af159364fb0731d966395878431988d8d382"},{"y":447,"x":640,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e75e5ff9eaa71a249ea07b65ee50c039e334263"},{"y":671,"x":960,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b11966ca3b2112e6b8af6e2409c7bb8d67ba9b2d"},{"y":754,"x":1080,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87c46cb5d9917b940ca53be79592dceb647cffd1"}],"s":{"y":980,"x":1402,"u":"https://preview.redd.it/krz6zcjf6ote1.png?width=1402&amp;format=png&amp;auto=webp&amp;s=b724a88e92156c3050f2f719da301f7fba7697b3"},"id":"krz6zcjf6ote1"},"tfsoymdg6ote1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":46,"x":108,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9e8719a473aa8602cb6b210a96e1ee93101e7a"},{"y":92,"x":216,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba70ee132fa475649f1337fb597745eb58e9efd5"},{"y":137,"x":320,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=72523eb964b23fb68ea71de4eda8cadfe3416982"},{"y":274,"x":640,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef4380f328d730ca661dabc878dd42c454986007"},{"y":411,"x":960,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dee9402f67c3fe3885586c4ed8f9997a8b20b176"},{"y":463,"x":1080,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c911deb388b6da077719fa9e804a22452de5d6de"}],"s":{"y":670,"x":1562,"u":"https://preview.redd.it/tfsoymdg6ote1.png?width=1562&amp;format=png&amp;auto=webp&amp;s=4ffb07c1d4142ae67a910049b987df0f90eea1ad"},"id":"tfsoymdg6ote1"}},"hide_score":false,"quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":null,"ups":1600,"domain":"reddit.com","media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_14mlbg","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"gallery_data":{"items":[{"media_id":"krz6zcjf6ote1","id":639382097},{"media_id":"tfsoymdg6ote1","id":639382098}]},"link_flair_text":"New Model","can_mod_post":false,"score":1600,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://a.thumbs.redditmedia.com/Y5BwtBnjZby6zmZDlawuWxCvPe3JSO0Wzb73zGMqhW4.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"subreddit_type":"public","created":1744143630,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.reddit.com/gallery/1juni3t","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1juni3t","is_robot_indexable":true,"num_duplicates":4,"report_reasons":null,"author":"TKGaming_11","discussion_type":null,"num_comments":205,"send_replies":false,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/","stickied":false,"url":"https://www.reddit.com/gallery/1juni3t","subreddit_subscribers":492315,"created_utc":1744143630,"num_crossposts":5,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3nju5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1744145783,"send_replies":true,"parent_id":"t3_1juni3t","score":99,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's a slight discrepancy. R1 is listed with 95.4% for Codeforces here. In the [DS benchmark](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) it was 96.3%. In general the numbers seem to be about right though. The 32B distill isn't listed in the table, but it scored 90.6%. A fully open 14B model beating that is indeed a great improvement. During tests I found that the full R1 often \\"gets\\" things that smaller models did not. Let's see if this still holds true despite almost identical benchmark results.\\n\\nThe model is [here](https://huggingface.co/agentica-org/DeepCoder-14B-Preview). No quants yet, but they'll come soon as it's based on a widely supported 14B model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3nju5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a slight discrepancy. R1 is listed with 95.4% for Codeforces here. In the &lt;a href=\\"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\\"&gt;DS benchmark&lt;/a&gt; it was 96.3%. In general the numbers seem to be about right though. The 32B distill isn&amp;#39;t listed in the table, but it scored 90.6%. A fully open 14B model beating that is indeed a great improvement. During tests I found that the full R1 often &amp;quot;gets&amp;quot; things that smaller models did not. Let&amp;#39;s see if this still holds true despite almost identical benchmark results.&lt;/p&gt;\\n\\n&lt;p&gt;The model is &lt;a href=\\"https://huggingface.co/agentica-org/DeepCoder-14B-Preview\\"&gt;here&lt;/a&gt;. No quants yet, but they&amp;#39;ll come soon as it&amp;#39;s based on a widely supported 14B model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3nju5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145783,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":99}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3h4zg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TKGaming_11","can_mod_post":false,"created_utc":1744143986,"send_replies":true,"parent_id":"t1_mm3gzgq","score":30,"author_fullname":"t2_14mlbg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yup its a really interesting read","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3h4zg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yup its a really interesting read&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3h4zg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744143986,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3gzgq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Stepfunction","can_mod_post":false,"created_utc":1744143942,"send_replies":true,"parent_id":"t3_1juni3t","score":177,"author_fullname":"t2_sxigq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is pretty amazing. Not only is it truly open-source, but they also offer a number of enhancements to GRPO as well as additional efficiency added to the sampling pipeline during training.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3gzgq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is pretty amazing. Not only is it truly open-source, but they also offer a number of enhancements to GRPO as well as additional efficiency added to the sampling pipeline during training.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3gzgq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744143942,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":177}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5n7u1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MidAirRunner","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3nr0q","score":33,"author_fullname":"t2_qwhykwm6l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very nice for my potato","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm5n7u1","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very nice for my potato&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5n7u1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744170780,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1744170780,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm46jqv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"random-tomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3nr0q","score":29,"author_fullname":"t2_fmd6oq5v6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"0.5B would have been nic**er** but it's fine, 14B is pretty fast anyway :D","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm46jqv","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;0.5B would have been nic&lt;strong&gt;er&lt;/strong&gt; but it&amp;#39;s fine, 14B is pretty fast anyway :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm46jqv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151818,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744151818,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6ma02","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ComprehensiveBird317","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6m046","score":11,"author_fullname":"t2_iaby02kl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you kind stranger","edited":false,"author_flair_css_class":null,"name":"t1_mm6ma02","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you kind stranger&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6ma02/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744190880,"author_flair_text":null,"collapsed":false,"created_utc":1744190880,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6m046","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6lkxm","score":35,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Speculative decoding can speed up the token generation of a model without losing any quality by using a smaller, faster model to speculate on what the larger model would maybe output. The speed-up you get [depends on](https://www.reddit.com/r/LocalLLaMA/comments/1hesft1/this_is_how_speculative_decoding_speeds_the_model/) how close the output of the smaller model is to that of the larger mode.\\n\\nHere's the [thread ](https://www.reddit.com/r/LocalLLaMA/comments/1gzm93o/speculative_decoding_just_landed_in_llamacpps/)with more discussion for the integration in llama.cpp.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6m046","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Speculative decoding can speed up the token generation of a model without losing any quality by using a smaller, faster model to speculate on what the larger model would maybe output. The speed-up you get &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1hesft1/this_is_how_speculative_decoding_speeds_the_model/\\"&gt;depends on&lt;/a&gt; how close the output of the smaller model is to that of the larger mode.&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s the &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1gzm93o/speculative_decoding_just_landed_in_llamacpps/\\"&gt;thread &lt;/a&gt;with more discussion for the integration in llama.cpp.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6m046/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744190704,"author_flair_text":null,"treatment_tags":[],"created_utc":1744190704,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6lkxm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ComprehensiveBird317","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3nr0q","score":7,"author_fullname":"t2_iaby02kl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you please elaborate with a real word example what speculative decoding is? I come across that term sometimes, but couldn't map it to something useful for my daily work","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6lkxm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you please elaborate with a real word example what speculative decoding is? I come across that term sometimes, but couldn&amp;#39;t map it to something useful for my daily work&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6lkxm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744190436,"author_flair_text":null,"treatment_tags":[],"created_utc":1744190436,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7tq1a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Alert-Surround-3141","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6tdis","score":2,"author_fullname":"t2_okrogjwd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am glad you spoke about it , very few folks seem to speak about the tokenizer even not listed in the AI engineering book by Chip \\n\\nThe assumption is everyone tokenized with the same word2vec","edited":false,"author_flair_css_class":null,"name":"t1_mm7tq1a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am glad you spoke about it , very few folks seem to speak about the tokenizer even not listed in the AI engineering book by Chip &lt;/p&gt;\\n\\n&lt;p&gt;The assumption is everyone tokenized with the same word2vec&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7tq1a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744208877,"author_flair_text":null,"collapsed":false,"created_utc":1744208877,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmf0jy7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Alert-Surround-3141","can_mod_post":false,"created_utc":1744304201,"send_replies":true,"parent_id":"t1_mmcd26w","score":1,"author_fullname":"t2_okrogjwd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep with the Llama.cpp you can try a lot if things and is a must\\n\\nThe current system tends to be a binary model for every thing so the multiple product with a no or zero state will force the final state to be a no or zero , instead if a multi variable system was used the hallucinations should reduce as the product is more like a wave form (those from digital signal processing or modeling can relate)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmf0jy7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep with the Llama.cpp you can try a lot if things and is a must&lt;/p&gt;\\n\\n&lt;p&gt;The current system tends to be a binary model for every thing so the multiple product with a no or zero state will force the final state to be a no or zero , instead if a multi variable system was used the hallucinations should reduce as the product is more like a wave form (those from digital signal processing or modeling can relate)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmf0jy7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744304201,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmcd26w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"created_utc":1744263347,"send_replies":true,"parent_id":"t1_mmc6vxq","score":1,"author_fullname":"t2_8eneodlk","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ok thank you I’ll give it a crack","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mmcd26w","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok thank you I’ll give it a crack&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmcd26w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744263347,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmc6vxq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Chromix_","can_mod_post":false,"created_utc":1744260125,"send_replies":true,"parent_id":"t1_mm9p0qi","score":2,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama.cpp server. You can use the included or other OpenAI compatible UI with it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mmc6vxq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama.cpp server. You can use the included or other OpenAI compatible UI with it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmc6vxq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744260125,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm9p0qi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm754yw","score":1,"author_fullname":"t2_8eneodlk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ok this makes sense but what are you using for inference , LLM studio dosent let me freely use whatever I want.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mm9p0qi","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok this makes sense but what are you using for inference , LLM studio dosent let me freely use whatever I want.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9p0qi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744228478,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744228478,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm754yw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6vrgv","score":9,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"body":"There is no such thing as a draft model. Any model is used as draft model the moment you specify it to be used as draft model. You can even use a IQ3 quant of a model as draft model for a Q8 quant of the very same model. It doesn't make much sense for speeding up inference, but [it works](https://www.reddit.com/r/LocalLLaMA/comments/1iu8f7s/speculative_decoding_can_identify_broken_quants/).\\n\\nSometimes people just label 0.5B models as draft models, because their output alone is too inconsistent for most tasks, but it's sometimes capable of predicting the next few tokens of a larger model.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mm754yw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There is no such thing as a draft model. Any model is used as draft model the moment you specify it to be used as draft model. You can even use a IQ3 quant of a model as draft model for a Q8 quant of the very same model. It doesn&amp;#39;t make much sense for speeding up inference, but &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1iu8f7s/speculative_decoding_can_identify_broken_quants/\\"&gt;it works&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Sometimes people just label 0.5B models as draft models, because their output alone is too inconsistent for most tasks, but it&amp;#39;s sometimes capable of predicting the next few tokens of a larger model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm754yw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744200444,"author_flair_text":null,"treatment_tags":[],"created_utc":1744200444,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6vrgv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6tdis","score":1,"author_fullname":"t2_8eneodlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But you’re using a normal model? I thought it has to specifically be a draft model?","edited":false,"author_flair_css_class":null,"name":"t1_mm6vrgv","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But you’re using a normal model? I thought it has to specifically be a draft model?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6vrgv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744196281,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1744196281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6tdis","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6rc0z","score":10,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not \\"random\\". It needs to be a model that has the same tokenizer. Even if the tokenizer matches it might be possible that you don't get any speedup, as models share the tokenizer yet have a different architecture or were trained on different datasets.\\n\\nSo, the best model you can have for speculative decoding is a model that matches the architecture of the larger model and has been trained on the same dataset, like in this case. Both models are Qwen finetunes on the same dataset.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6tdis","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not &amp;quot;random&amp;quot;. It needs to be a model that has the same tokenizer. Even if the tokenizer matches it might be possible that you don&amp;#39;t get any speedup, as models share the tokenizer yet have a different architecture or were trained on different datasets.&lt;/p&gt;\\n\\n&lt;p&gt;So, the best model you can have for speculative decoding is a model that matches the architecture of the larger model and has been trained on the same dataset, like in this case. Both models are Qwen finetunes on the same dataset.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6tdis/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744195055,"author_flair_text":null,"treatment_tags":[],"created_utc":1744195055,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6rc0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3nr0q","score":2,"author_fullname":"t2_8eneodlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are you randomly using any model of your choice for spec dec? LLM studio has a cry when everything dosent line up and the planets are not in alignment.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6rc0z","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are you randomly using any model of your choice for spec dec? LLM studio has a cry when everything dosent line up and the planets are not in alignment.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6rc0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744193933,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744193933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3nr0q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1744145839,"send_replies":true,"parent_id":"t1_mm3lx33","score":78,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Very nice for speculative decoding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3nr0q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very nice for speculative decoding.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3nr0q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145839,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":78}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5g25s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"my_name_isnt_clever","can_mod_post":false,"created_utc":1744167792,"send_replies":true,"parent_id":"t1_mm3lx33","score":7,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And here I was, thinking earlier today how there was no way I could run a competent coding model on my work laptop. But now I have to give this a try.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5g25s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And here I was, thinking earlier today how there was no way I could run a competent coding model on my work laptop. But now I have to give this a try.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5g25s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744167792,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3v2sp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LankyBig8997","can_mod_post":false,"created_utc":1744148063,"send_replies":true,"parent_id":"t1_mm3lx33","score":7,"author_fullname":"t2_8xgsxi9y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"W","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3v2sp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;W&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3v2sp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148063,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmke66i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thebadslime","can_mod_post":false,"created_utc":1744380780,"send_replies":true,"parent_id":"t1_mm3lx33","score":3,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"be good for running in vscode","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmke66i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;be good for running in vscode&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmke66i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744380780,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3lx33","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Recoil42","can_mod_post":false,"created_utc":1744145319,"send_replies":true,"parent_id":"t3_1juni3t","score":118,"author_fullname":"t2_2kndo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like there's also a 1.5B model: \\n\\n[https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview](https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3lx33","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like there&amp;#39;s also a 1.5B model: &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview\\"&gt;https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3lx33/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145319,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":118}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"0e2e7958-9549-11ee-a999-027a9c984b05","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmelhpg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noneabove1182","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6vfln","score":4,"author_fullname":"t2_7quep","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oop didn't notice it :o","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmelhpg","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Bartowski"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oop didn&amp;#39;t notice it :o&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmelhpg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744299760,"author_flair_text":"Bartowski","treatment_tags":[],"created_utc":1744299760,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#889bdb","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmae04k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cyclonis123","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6vfln","score":1,"author_fullname":"t2_50euckkz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"are there any plans for 7b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmae04k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are there any plans for 7b?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmae04k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744236016,"author_flair_text":null,"treatment_tags":[],"created_utc":1744236016,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6vfln","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm63fb9","score":7,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"He hasn't gotten around to 1.5B yet (for speculative decoding)\\n\\nhttps://huggingface.co/agentica-org/DeepCoder-1.5B-Preview","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6vfln","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He hasn&amp;#39;t gotten around to 1.5B yet (for speculative decoding)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview\\"&gt;https://huggingface.co/agentica-org/DeepCoder-1.5B-Preview&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6vfln/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744196116,"author_flair_text":null,"treatment_tags":[],"created_utc":1744196116,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm9dr91","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"loadsamuny","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm63fb9","score":3,"author_fullname":"t2_10p7p3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"soon you’ll be able to set your watch by Bartowski he’s so reliable! 🙌","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm9dr91","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;soon you’ll be able to set your watch by Bartowski he’s so reliable! 🙌&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9dr91/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744225175,"author_flair_text":null,"treatment_tags":[],"created_utc":1744225175,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm63fb9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emsiem22","can_mod_post":false,"created_utc":1744178900,"send_replies":true,"parent_id":"t1_mm3n7i3","score":39,"author_fullname":"t2_xwb9r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://huggingface.co/bartowski/agentica-org\\\\_DeepCoder-14B-Preview-GGUF](https://huggingface.co/bartowski/agentica-org_DeepCoder-14B-Preview-GGUF)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm63fb9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/bartowski/agentica-org_DeepCoder-14B-Preview-GGUF\\"&gt;https://huggingface.co/bartowski/agentica-org_DeepCoder-14B-Preview-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm63fb9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744178900,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3wayy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PermanentLiminality","can_mod_post":false,"created_utc":1744148442,"send_replies":true,"parent_id":"t1_mm3n7i3","score":10,"author_fullname":"t2_19zqycaf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are a few placekeepers by other for some GGUF 4, 6, and 8 bit versions.  Some have files and others are just placekeepers.  Probably will be in place in later today or tomorrow.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3wayy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are a few placekeepers by other for some GGUF 4, 6, and 8 bit versions.  Some have files and others are just placekeepers.  Probably will be in place in later today or tomorrow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3wayy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148442,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3n7i3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loadsamuny","can_mod_post":false,"created_utc":1744145688,"send_replies":true,"parent_id":"t3_1juni3t","score":140,"author_fullname":"t2_10p7p3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"incase Bartowski’s looking for it\\nhttps://huggingface.co/agentica-org/DeepCoder-14B-Preview","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3n7i3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;incase Bartowski’s looking for it\\n&lt;a href=\\"https://huggingface.co/agentica-org/DeepCoder-14B-Preview\\"&gt;https://huggingface.co/agentica-org/DeepCoder-14B-Preview&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3n7i3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145688,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":140}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4pcx0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codingworkflow","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm45ai0","score":15,"author_fullname":"t2_1kdxd5n9hz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's fine tuning. I'm afraid base model not new.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4pcx0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s fine tuning. I&amp;#39;m afraid base model not new.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4pcx0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158264,"author_flair_text":null,"treatment_tags":[],"created_utc":1744158264,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mm45ai0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DinoAmino","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm41t2z","score":41,"author_fullname":"t2_j1v7f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oops .. that's 65k total rows.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm45ai0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oops .. that&amp;#39;s 65k total rows.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm45ai0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151381,"author_flair_text":null,"treatment_tags":[],"created_utc":1744151381,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}}],"before":null}},"user_reports":[],"saved":false,"id":"mm41t2z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DinoAmino","can_mod_post":false,"created_utc":1744150213,"send_replies":true,"parent_id":"t1_mm3iszl","score":61,"author_fullname":"t2_j1v7f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, they published the datasets too. Shouldn't be too hard to train one - it's about 30K rows total.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm41t2z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, they published the datasets too. Shouldn&amp;#39;t be too hard to train one - it&amp;#39;s about 30K rows total.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm41t2z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150213,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":61}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5igqy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pkmxtw","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":7,"author_fullname":"t2_a2gtk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I recall llama 3 only had issues on llama.cpp at launch time, but it was more of llama.cpp's fault as it was caused by bugs in its tokenizer implementation. Inference engines that used the 🤗 transformer stack worked pretty well.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm5igqy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I recall llama 3 only had issues on llama.cpp at launch time, but it was more of llama.cpp&amp;#39;s fault as it was caused by bugs in its tokenizer implementation. Inference engines that used the 🤗 transformer stack worked pretty well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5igqy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744168759,"author_flair_text":null,"treatment_tags":[],"created_utc":1744168759,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4zdae","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the_renaissance_jack","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":22,"author_fullname":"t2_2frr0ty","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Poor first showing and disappointment. Gemma 3 had issues during launch, but now that it's sorted I'm running the 1b, 4b, and 12b versions locally no problem. Lllama 4 has no version I can run locally. Llama 4 was hyped to be a huge deal, but it seems more geared towards enterprise or large scale rollouts.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm4zdae","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Poor first showing and disappointment. Gemma 3 had issues during launch, but now that it&amp;#39;s sorted I&amp;#39;m running the 1b, 4b, and 12b versions locally no problem. Lllama 4 has no version I can run locally. Llama 4 was hyped to be a huge deal, but it seems more geared towards enterprise or large scale rollouts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4zdae/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744161797,"author_flair_text":null,"treatment_tags":[],"created_utc":1744161797,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmnvjca","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Guilty_Nerve5608","can_mod_post":false,"send_replies":true,"parent_id":"t1_mmck6d2","score":2,"author_fullname":"t2_7q2q3rbq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, I’m running unsloth llama 4 maverick q2_k_xl at 11-15 t/s on my m4 MBP","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mmnvjca","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, I’m running unsloth llama 4 maverick q2_k_xl at 11-15 t/s on my m4 MBP&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmnvjca/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744420848,"author_flair_text":null,"treatment_tags":[],"created_utc":1744420848,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mmck6d2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rushedone","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm5gq3b","score":1,"author_fullname":"t2_ay1zr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can that run on a 128gb MacBook Pro?","edited":false,"author_flair_css_class":null,"name":"t1_mmck6d2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can that run on a 128gb MacBook Pro?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmck6d2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744267463,"author_flair_text":null,"collapsed":false,"created_utc":1744267463,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_mm88vql","id":"mm88vql","parent_id":"t1_mm5gq3b","depth":4,"children":["mm88vql"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5gq3b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eposnix","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4u70c","score":33,"author_fullname":"t2_7oo5j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"100B+ parameters is out of reach for the vast majority, so most people are interacting with it on meta.ai or LM arena. It's performing equally bad on both.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5gq3b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;100B+ parameters is out of reach for the vast majority, so most people are interacting with it on meta.ai or LM arena. It&amp;#39;s performing equally bad on both.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5gq3b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744168054,"author_flair_text":null,"treatment_tags":[],"created_utc":1744168054,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4u70c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LostHisDog","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":27,"author_fullname":"t2_x5jky","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a meme until someone gets it sorted and then folks will be like \\"I love me some Llama 4\\" - Sort of feels like normal growing pains mixed in with a love / HATE relationship with Meta.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm4u70c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a meme until someone gets it sorted and then folks will be like &amp;quot;I love me some Llama 4&amp;quot; - Sort of feels like normal growing pains mixed in with a love / HATE relationship with Meta.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4u70c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744159967,"author_flair_text":null,"treatment_tags":[],"created_utc":1744159967,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5gnq8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Small-Fall-6500","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm5dfls","score":8,"author_fullname":"t2_dssukvlp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep. After the dust settles, Llama 4 models won't be bad, but only okay or good when everyone expected them to be great or better. It is also a big disappointment for many that there's no smaller Llama 4 models, at least for this initial release.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5gnq8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep. After the dust settles, Llama 4 models won&amp;#39;t be bad, but only okay or good when everyone expected them to be great or better. It is also a big disappointment for many that there&amp;#39;s no smaller Llama 4 models, at least for this initial release.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5gnq8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744168029,"author_flair_text":null,"treatment_tags":[],"created_utc":1744168029,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5dfls","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Holly_Shiits","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":8,"author_fullname":"t2_dcgkj1u3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe not bad, but definitely didn't meet expectations","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm5dfls","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe not bad, but definitely didn&amp;#39;t meet expectations&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5dfls/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744166771,"author_flair_text":null,"treatment_tags":[],"created_utc":1744166771,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6mioq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":3,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On LocalLlama the main disappointment is probably that it can't really be run locally.  Second, it was long awaited and fucking expensive for meta to develop/train...and didn't jump ahead in any category in any meaningful way. Third, they kind of cheated in LMarena.\\n\\nThe 10m context is interesting and 10x sota if it's usable, and that hasn't really been tested yet.\\n\\nThe other problem is that in the coming days/weeks/month google / qwen / deepseek will likely release models that make llama 4.0 irrelevant.   And if you are going for API anyway it's hard to justify it over some of the other options. \\n\\nI mean 2.5 flash is going to make llama 4 almost pointless for 90% of users.  \\n\\nLooking forward to 4.1 and possibly some unique distillations into different architectures once behemoth finishes training but I don't have a ton of hope.","edited":1744210949,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6mioq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On LocalLlama the main disappointment is probably that it can&amp;#39;t really be run locally.  Second, it was long awaited and fucking expensive for meta to develop/train...and didn&amp;#39;t jump ahead in any category in any meaningful way. Third, they kind of cheated in LMarena.&lt;/p&gt;\\n\\n&lt;p&gt;The 10m context is interesting and 10x sota if it&amp;#39;s usable, and that hasn&amp;#39;t really been tested yet.&lt;/p&gt;\\n\\n&lt;p&gt;The other problem is that in the coming days/weeks/month google / qwen / deepseek will likely release models that make llama 4.0 irrelevant.   And if you are going for API anyway it&amp;#39;s hard to justify it over some of the other options. &lt;/p&gt;\\n\\n&lt;p&gt;I mean 2.5 flash is going to make llama 4 almost pointless for 90% of users.  &lt;/p&gt;\\n\\n&lt;p&gt;Looking forward to 4.1 and possibly some unique distillations into different architectures once behemoth finishes training but I don&amp;#39;t have a ton of hope.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6mioq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744191034,"author_flair_text":null,"treatment_tags":[],"created_utc":1744191034,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7r0s1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":3,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tried scout for a day and it was bad, ~mistral-24b level but with more coding errors. I'm hoping it's either tooling or my samplers being bad, and that it'll be better in a few weeks because the performance speed was great / easy to run!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm7r0s1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried scout for a day and it was bad, ~mistral-24b level but with more coding errors. I&amp;#39;m hoping it&amp;#39;s either tooling or my samplers being bad, and that it&amp;#39;ll be better in a few weeks because the performance speed was great / easy to run!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7r0s1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744208052,"author_flair_text":null,"treatment_tags":[],"created_utc":1744208052,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmbljwl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious-Tap-4670","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm896mr","score":3,"author_fullname":"t2_n2zhoqg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think what we'll see here is a redemption of sorts once the distillations start","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmbljwl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think what we&amp;#39;ll see here is a redemption of sorts once the distillations start&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbljwl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744251246,"author_flair_text":null,"treatment_tags":[],"created_utc":1744251246,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm896mr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Smile_Clown","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":2,"author_fullname":"t2_qhrmlpjk0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's both with the latter being most prevalent.  Once something comes out and is not super amazing, (virtually) everyone is suddenly an expert and a critic and it is nearly impossible to let that go no matter what information comes out.  Thoe who disagree are downvoted, called names and dismissed because the hate has to rule.\\n\\nLlama is now dead in the eyes of a lot of people, but I take it with a grain of salt because those people, do not really matter. Not in the grand scheme.\\n\\nIt's sad really, if Llama fixes the issues, if Llama 5 is utterly amazing, it will not change anything, karma whores and parroting idiots have already sealed their online perceptions fate.\\n\\nSocial media is like the amazon rainforest, full of loud parrots.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm896mr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s both with the latter being most prevalent.  Once something comes out and is not super amazing, (virtually) everyone is suddenly an expert and a critic and it is nearly impossible to let that go no matter what information comes out.  Thoe who disagree are downvoted, called names and dismissed because the hate has to rule.&lt;/p&gt;\\n\\n&lt;p&gt;Llama is now dead in the eyes of a lot of people, but I take it with a grain of salt because those people, do not really matter. Not in the grand scheme.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s sad really, if Llama fixes the issues, if Llama 5 is utterly amazing, it will not change anything, karma whores and parroting idiots have already sealed their online perceptions fate.&lt;/p&gt;\\n\\n&lt;p&gt;Social media is like the amazon rainforest, full of loud parrots.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm896mr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744213462,"author_flair_text":null,"treatment_tags":[],"created_utc":1744213462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6p22b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"redditedOnion","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dmyg","score":3,"author_fullname":"t2_hxjmjdjre","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"GPU poor people whining about big models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6p22b","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;GPU poor people whining about big models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6p22b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744192600,"author_flair_text":null,"treatment_tags":[],"created_utc":1744192600,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4dmyg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious-Tap-4670","can_mod_post":false,"created_utc":1744154224,"send_replies":true,"parent_id":"t1_mm3iszl","score":27,"author_fullname":"t2_n2zhoqg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is llama4 actually that bad, or are people working off of a collective meme from a poor first showing? didn't llama 2 and 3 have rocky initial launches until inference engines properly supported it?","edited":1744169955,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4dmyg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is llama4 actually that bad, or are people working off of a collective meme from a poor first showing? didn&amp;#39;t llama 2 and 3 have rocky initial launches until inference engines properly supported it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4dmyg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744154224,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3xlkf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lemon07r","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3lhxx","score":3,"author_fullname":"t2_i697e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can we even say it achieved that since it was a different version that we do not get?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3xlkf","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can we even say it achieved that since it was a different version that we do not get?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3xlkf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148849,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1744148849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":3,"name":"t1_mm3lnv1","id":"mm3lnv1","parent_id":"t1_mm3lhxx","depth":3,"children":["mm3lnv1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3lhxx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3kyod","score":9,"author_fullname":"t2_eerln","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Did llama-4 achieve any benchmark apart from the lm”arena“?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm3lhxx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did llama-4 achieve any benchmark apart from the lm”arena“?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3lhxx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145201,"author_flair_text":null,"treatment_tags":[],"created_utc":1744145201,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3kyod","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3iszl","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3kyod/","num_reports":null,"locked":false,"name":"t1_mm3kyod","created":1744145049,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744145049,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3iszl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pseudonerv","can_mod_post":false,"created_utc":1744144445,"send_replies":true,"parent_id":"t3_1juni3t","score":279,"author_fullname":"t2_eerln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow. Just imagine what a 32B model would be. \\n\\nAnd imagine what llama-4 could have been.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3iszl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow. Just imagine what a 32B model would be. &lt;/p&gt;\\n\\n&lt;p&gt;And imagine what llama-4 could have been.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3iszl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744144445,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":279}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6dwz4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3vjwq","score":13,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm so fucking done with these stupid triangle charts, they have to do this pretentious nonsense every fuckin time.\\n\\n\\"Haha you see, our model good and fast, other people model bad and slow!\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6dwz4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m so fucking done with these stupid triangle charts, they have to do this pretentious nonsense every fuckin time.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Haha you see, our model good and fast, other people model bad and slow!&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6dwz4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744185396,"author_flair_text":null,"treatment_tags":[],"created_utc":1744185396,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3vjwq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Orolol","can_mod_post":false,"created_utc":1744148209,"send_replies":true,"parent_id":"t1_mm3l4l6","score":136,"author_fullname":"t2_fbzx9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As usual in this kind of graph, the optimal region is the region where the model they own is.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3vjwq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As usual in this kind of graph, the optimal region is the region where the model they own is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3vjwq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148209,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":136}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm517og","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ToHallowMySleep","can_mod_post":false,"created_utc":1744162456,"send_replies":true,"parent_id":"t1_mm3l4l6","score":18,"author_fullname":"t2_5c9lpcuj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Low in cost high in results. You can draw the line wherever you like, but the top left corner is the best.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm517og","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Low in cost high in results. You can draw the line wherever you like, but the top left corner is the best.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm517og/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744162456,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3l4l6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ASTRdeca","can_mod_post":false,"created_utc":1744145094,"send_replies":true,"parent_id":"t3_1juni3t","score":40,"author_fullname":"t2_e11po","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm confused how the \\"optimal\\" region in the graph is determined. I don't see any mention of it in the blog post.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3l4l6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m confused how the &amp;quot;optimal&amp;quot; region in the graph is determined. I don&amp;#39;t see any mention of it in the blog post.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3l4l6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145094,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmeu5y9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EmberGlitch","can_mod_post":false,"created_utc":1744302315,"send_replies":true,"parent_id":"t1_mmdko6s","score":4,"author_fullname":"t2_h6ljsiqs","approved_by":null,"mod_note":null,"all_awardings":[],"body":"For the most part, we are unfortunately still using ollama, but I'm actively trying to get away from it, so I'm currently exploring vllm on the side.  \\nThe thing I still appreciate about ollama is that it's fairly straightforward to serve multiple models and dynamically load / unload them depending on demand, and that is not quite as straightforward with vllm as I unfortunately found out.  \\n\\nI have plenty of VRAM available to comfortably run 72b models at full context individually, but I can't easily serve a coding-focused model for our developers and also serve a general purpose reasoning model for employees in other departments at the same time. So dynamic loading/unloading is very nice to have.  \\n\\nI currently only have to serve a few select users from the different departments who were excited to give it a go and provide feedback, so the average load is still very manageable, and they expect that responses might take a bit, if their model has to be loaded in first.\\n\\nIn the long run, I'll most likely spec out multiple servers that will just serve one model each. \\n\\nTBH I'm still kinda bumbling about, lol. I actually got hired as tech support 6 months ago but since I had some experience with local models, I offered to help set up some models and open-webui when I overheard the director of the company and my supervisor talking about AI. And now I'm the AI guy, lol. Definitely not complaining, though. Definitely beats doing phone support.","edited":1744302602,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mmeu5y9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For the most part, we are unfortunately still using ollama, but I&amp;#39;m actively trying to get away from it, so I&amp;#39;m currently exploring vllm on the side.&lt;br/&gt;\\nThe thing I still appreciate about ollama is that it&amp;#39;s fairly straightforward to serve multiple models and dynamically load / unload them depending on demand, and that is not quite as straightforward with vllm as I unfortunately found out.  &lt;/p&gt;\\n\\n&lt;p&gt;I have plenty of VRAM available to comfortably run 72b models at full context individually, but I can&amp;#39;t easily serve a coding-focused model for our developers and also serve a general purpose reasoning model for employees in other departments at the same time. So dynamic loading/unloading is very nice to have.  &lt;/p&gt;\\n\\n&lt;p&gt;I currently only have to serve a few select users from the different departments who were excited to give it a go and provide feedback, so the average load is still very manageable, and they expect that responses might take a bit, if their model has to be loaded in first.&lt;/p&gt;\\n\\n&lt;p&gt;In the long run, I&amp;#39;ll most likely spec out multiple servers that will just serve one model each. &lt;/p&gt;\\n\\n&lt;p&gt;TBH I&amp;#39;m still kinda bumbling about, lol. I actually got hired as tech support 6 months ago but since I had some experience with local models, I offered to help set up some models and open-webui when I overheard the director of the company and my supervisor talking about AI. And now I&amp;#39;m the AI guy, lol. Definitely not complaining, though. Definitely beats doing phone support.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmeu5y9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744302315,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mmdko6s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wviana","can_mod_post":false,"created_utc":1744287853,"send_replies":true,"parent_id":"t1_mmdb4xp","score":1,"author_fullname":"t2_dmqoc","approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you use for inference there? Vllm? I think vllm is able to load model in multiple GPUs.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mmdko6s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you use for inference there? Vllm? I think vllm is able to load model in multiple GPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmdko6s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744287853,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmdb4xp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmberGlitch","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm8r69d","score":2,"author_fullname":"t2_h6ljsiqs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just a 4U server in our office's server rack with a few RTX 4090s, nothing too fancy since we are still exploring how we can leverage local AI models for our daily tasks.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mmdb4xp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just a 4U server in our office&amp;#39;s server rack with a few RTX 4090s, nothing too fancy since we are still exploring how we can leverage local AI models for our daily tasks.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmdb4xp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744283771,"author_flair_text":null,"treatment_tags":[],"created_utc":1744283771,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm8r69d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wviana","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm8be27","score":1,"author_fullname":"t2_dmqoc","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh. So it's a bug from boo. Got it. \\n\\nTell me more about this server with vram. Is it pay as you use?","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mm8r69d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh. So it&amp;#39;s a bug from boo. Got it. &lt;/p&gt;\\n\\n&lt;p&gt;Tell me more about this server with vram. Is it pay as you use?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm8r69d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744218744,"author_flair_text":null,"treatment_tags":[],"created_utc":1744218744,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm8be27","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmberGlitch","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm82hyz","score":1,"author_fullname":"t2_h6ljsiqs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Should've been obvious in hindsight. But memory fortunately isn't an issue for me, since the server I have at work to play around with AI has more than enough VRAM. So I didn't bother checking the VRAM usage.  \\nI just have never seen a tool that lets me define a context size only to... not use it at all.","edited":false,"author_flair_css_class":null,"name":"t1_mm8be27","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should&amp;#39;ve been obvious in hindsight. But memory fortunately isn&amp;#39;t an issue for me, since the server I have at work to play around with AI has more than enough VRAM. So I didn&amp;#39;t bother checking the VRAM usage.&lt;br/&gt;\\nI just have never seen a tool that lets me define a context size only to... not use it at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm8be27/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744214107,"author_flair_text":null,"collapsed":false,"created_utc":1744214107,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm82hyz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wviana","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6esob","score":3,"author_fullname":"t2_dmqoc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah. I was going to mention that it could be the default context size value. As you've figured out by your last edit. \\n\\nBut increasing context length increases memory usage so much. \\n\\nTo me having things that needs bigger context local shows the limitations of llm on local. At least currentish hardware.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm82hyz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. I was going to mention that it could be the default context size value. As you&amp;#39;ve figured out by your last edit. &lt;/p&gt;\\n\\n&lt;p&gt;But increasing context length increases memory usage so much. &lt;/p&gt;\\n\\n&lt;p&gt;To me having things that needs bigger context local shows the limitations of llm on local. At least currentish hardware.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm82hyz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744211478,"author_flair_text":null,"treatment_tags":[],"created_utc":1744211478,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmhtty8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mochilongo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6esob","score":1,"author_fullname":"t2_1myl3nm3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you try Deepseek recommended settings and let us know how it goes?\\n\\nOur usage recommendations are similar to those of R1 and R1 Distill series:\\n\\nAvoid adding a system prompt; all instructions should be contained within the user prompt.\\ntemperature = 0.6\\ntop_p = 0.95\\nThis model performs best with max_tokens set to at least 64000","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmhtty8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you try Deepseek recommended settings and let us know how it goes?&lt;/p&gt;\\n\\n&lt;p&gt;Our usage recommendations are similar to those of R1 and R1 Distill series:&lt;/p&gt;\\n\\n&lt;p&gt;Avoid adding a system prompt; all instructions should be contained within the user prompt.\\ntemperature = 0.6\\ntop_p = 0.95\\nThis model performs best with max_tokens set to at least 64000&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmhtty8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744336548,"author_flair_text":null,"treatment_tags":[],"created_utc":1744336548,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6esob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EmberGlitch","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm43jfc","score":10,"author_fullname":"t2_h6ljsiqs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I found most local LLMs to be unusable with Roo, apart from one or two that have been specifically finetuned to work with Roo and Cline.\\n  \\nThe default system prompt is *insanely* long, and it just confuses the LLMs. It's insanely long because Roo needs to explain to the LLM what sort of tools are available, and how to call them. Unfortunately, that leads to the issue that smaller local LLMs can't even find your instructions about what you even want them to do.\\n\\nFor example, I'm in a completely blank workspace, apart from a main.py file, and asked Deepcoder to write a snake game in pygame.  \\nAnd yet, the thinking block starts with \\"Alright, I'm trying to figure out how to create a simple 'Hello World\\" program in Python based on the user's request.\\" The model just starts to hallucinate coding tasks.\\n\\nQwenCoder, QwQ, Gemma3 27b, Deepseek R1 Distills (14b, 32b, 70b) - they all fail. \\n\\nThe only models I found to work moderately well were [tom_himanen/deepseek-r1-roo-cline-tools](https://ollama.com/tom_himanen/deepseek-r1-roo-cline-tools) and [hhao/qwen2.5-coder-tools](https://ollama.com/hhao/qwen2.5-coder-tools)\\n\\n//edit:\\n\\nJust checked: For me, the default system prompt in Roo's code mode is roughly **9000 tokens** long. That doesn't even include the info about your workspace (directory structure, any open files, etc. ) yet.\\n\\n///edit2: **Hold up**. I think this may be a Roo fuckup, and/or mine. You can set a context window in Roo's model settings, and I assumed that would send the \`num_ctx\` parameter to the API, like when you set that parameter in SillyTavern or Open Webui - Roo doesn't do this! So you'll load the model with your default \`num_ctx\` which, if you haven't changed it is ollama's incredibly stupid 2048, or in my case 8192. Still not enough for all that context.  \\nWhen I loaded it manually with a way higher num_ctx it actually understood what I wanted. This is just silly on Roo's part, IMO.","edited":1744187966,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6esob","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found most local LLMs to be unusable with Roo, apart from one or two that have been specifically finetuned to work with Roo and Cline.&lt;/p&gt;\\n\\n&lt;p&gt;The default system prompt is &lt;em&gt;insanely&lt;/em&gt; long, and it just confuses the LLMs. It&amp;#39;s insanely long because Roo needs to explain to the LLM what sort of tools are available, and how to call them. Unfortunately, that leads to the issue that smaller local LLMs can&amp;#39;t even find your instructions about what you even want them to do.&lt;/p&gt;\\n\\n&lt;p&gt;For example, I&amp;#39;m in a completely blank workspace, apart from a main.py file, and asked Deepcoder to write a snake game in pygame.&lt;br/&gt;\\nAnd yet, the thinking block starts with &amp;quot;Alright, I&amp;#39;m trying to figure out how to create a simple &amp;#39;Hello World&amp;quot; program in Python based on the user&amp;#39;s request.&amp;quot; The model just starts to hallucinate coding tasks.&lt;/p&gt;\\n\\n&lt;p&gt;QwenCoder, QwQ, Gemma3 27b, Deepseek R1 Distills (14b, 32b, 70b) - they all fail. &lt;/p&gt;\\n\\n&lt;p&gt;The only models I found to work moderately well were &lt;a href=\\"https://ollama.com/tom_himanen/deepseek-r1-roo-cline-tools\\"&gt;tom_himanen/deepseek-r1-roo-cline-tools&lt;/a&gt; and &lt;a href=\\"https://ollama.com/hhao/qwen2.5-coder-tools\\"&gt;hhao/qwen2.5-coder-tools&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;//edit:&lt;/p&gt;\\n\\n&lt;p&gt;Just checked: For me, the default system prompt in Roo&amp;#39;s code mode is roughly &lt;strong&gt;9000 tokens&lt;/strong&gt; long. That doesn&amp;#39;t even include the info about your workspace (directory structure, any open files, etc. ) yet.&lt;/p&gt;\\n\\n&lt;p&gt;///edit2: &lt;strong&gt;Hold up&lt;/strong&gt;. I think this may be a Roo fuckup, and/or mine. You can set a context window in Roo&amp;#39;s model settings, and I assumed that would send the &lt;code&gt;num_ctx&lt;/code&gt; parameter to the API, like when you set that parameter in SillyTavern or Open Webui - Roo doesn&amp;#39;t do this! So you&amp;#39;ll load the model with your default &lt;code&gt;num_ctx&lt;/code&gt; which, if you haven&amp;#39;t changed it is ollama&amp;#39;s incredibly stupid 2048, or in my case 8192. Still not enough for all that context.&lt;br/&gt;\\nWhen I loaded it manually with a way higher num_ctx it actually understood what I wanted. This is just silly on Roo&amp;#39;s part, IMO.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6esob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744185971,"author_flair_text":null,"treatment_tags":[],"created_utc":1744185971,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5orq5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_raydeStar","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm54syt","score":3,"author_fullname":"t2_7g79z1vy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I like continue. \\n\\nI can just pop it into LM studio and say go. (I know I can do ollama I just LIKE LM studio)","edited":false,"author_flair_css_class":null,"name":"t1_mm5orq5","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like continue. &lt;/p&gt;\\n\\n&lt;p&gt;I can just pop it into LM studio and say go. (I know I can do ollama I just LIKE LM studio)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5orq5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744171464,"author_flair_text":"Llama 3.1","collapsed":false,"created_utc":1744171464,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm54syt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wviana","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4j9q5","score":9,"author_fullname":"t2_dmqoc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[Continue](https://plugins.jetbrains.com/plugin/22707-continue)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm54syt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://plugins.jetbrains.com/plugin/22707-continue\\"&gt;Continue&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm54syt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744163718,"author_flair_text":null,"treatment_tags":[],"created_utc":1744163718,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4j9q5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RickDripps","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm43jfc","score":4,"author_fullname":"t2_5l93v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Anything for IntelliJ's ecosystem?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm4j9q5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anything for IntelliJ&amp;#39;s ecosystem?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4j9q5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744156131,"author_flair_text":null,"treatment_tags":[],"created_utc":1744156131,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5ghnb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"my_name_isnt_clever","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm43jfc","score":3,"author_fullname":"t2_5o567","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not generally a CLI app user, but I've been loving ai-less VSCode with Aider in a separate terminal window. And it's great that it's just committing it's edits in git along with mine, so I'm not tied to any specific IDE.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm5ghnb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not generally a CLI app user, but I&amp;#39;ve been loving ai-less VSCode with Aider in a separate terminal window. And it&amp;#39;s great that it&amp;#39;s just committing it&amp;#39;s edits in git along with mine, so I&amp;#39;m not tied to any specific IDE.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5ghnb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744167962,"author_flair_text":null,"treatment_tags":[],"created_utc":1744167962,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmbvl4o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"send_replies":true,"parent_id":"t1_mmbvh67","score":1,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I will be messaging you in 2 hours on [**2025-04-10 05:15:57 UTC**](http://www.wolframalpha.com/input/?i=2025-04-10%2005:15:57%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbvh67/?context=3)\\n\\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1juni3t%2Fdeepcoder_a_fully_opensource_14b_coder_at_o3mini%2Fmmbvh67%2F%5D%0A%0ARemindMe%21%202025-04-10%2005%3A15%3A57%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201juni3t)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmbvl4o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 2 hours on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2025-04-10%2005:15:57%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2025-04-10 05:15:57 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbvh67/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1juni3t%2Fdeepcoder_a_fully_opensource_14b_coder_at_o3mini%2Fmmbvh67%2F%5D%0A%0ARemindMe%21%202025-04-10%2005%3A15%3A57%20UTC\\"&gt;&lt;strong&gt;CLICK THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201juni3t\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbvl4o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744255002,"author_flair_text":null,"treatment_tags":[],"created_utc":1744255002,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmbvh67","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CheatCodesOfLife","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm43jfc","score":1,"author_fullname":"t2_32el727b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" !remind me 2 hours","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mmbvh67","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;!remind me 2 hours&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbvh67/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744254957,"author_flair_text":null,"treatment_tags":[],"created_utc":1744254957,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":2,"name":"t1_mm5095y","id":"mm5095y","parent_id":"t1_mm43jfc","depth":2,"children":["mm5095y"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm43jfc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Melon__Bread","can_mod_post":false,"created_utc":1744150791,"send_replies":true,"parent_id":"t1_mm3w4gh","score":33,"author_fullname":"t2_6728e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes look up [Cline](https://docs.cline.bot/running-models-locally/ollama) or [Roo](https://docs.roocode.com/providers/ollama/) if you want to stay in the VSCode/VSCodium world (as they are extensions). There is also [Aider](https://aider.chat/docs/llms/ollama.html) if you want to stick to a terminal CLI. All with Ollama support to stay local.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm43jfc","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes look up &lt;a href=\\"https://docs.cline.bot/running-models-locally/ollama\\"&gt;Cline&lt;/a&gt; or &lt;a href=\\"https://docs.roocode.com/providers/ollama/\\"&gt;Roo&lt;/a&gt; if you want to stay in the VSCode/VSCodium world (as they are extensions). There is also &lt;a href=\\"https://aider.chat/docs/llms/ollama.html\\"&gt;Aider&lt;/a&gt; if you want to stick to a terminal CLI. All with Ollama support to stay local.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm43jfc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150791,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3w4gh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RickDripps","can_mod_post":false,"created_utc":1744148386,"send_replies":true,"parent_id":"t3_1juni3t","score":25,"author_fullname":"t2_5l93v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So I've just started messing with Cursor...  I would love to have similar functionality with a local model (indexing the codebase, being able to ask that it makes changes to files for me, etc...) but is this even possible with what is available out there today?  Or would it need to be engineered like they are doing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3w4gh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I&amp;#39;ve just started messing with Cursor...  I would love to have similar functionality with a local model (indexing the codebase, being able to ask that it makes changes to files for me, etc...) but is this even possible with what is available out there today?  Or would it need to be engineered like they are doing?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3w4gh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148386,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3g3rr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TKGaming_11","can_mod_post":false,"created_utc":1744143685,"send_replies":true,"parent_id":"t3_1juni3t","score":58,"author_fullname":"t2_14mlbg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Blog: [DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level](https://www.together.ai/blog/deepcoder)\\n\\nTwitter Post: [https://x.com/togethercompute/status/1909697122372378908](https://x.com/togethercompute/status/1909697122372378908)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3g3rr","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Blog: &lt;a href=\\"https://www.together.ai/blog/deepcoder\\"&gt;DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Twitter Post: &lt;a href=\\"https://x.com/togethercompute/status/1909697122372378908\\"&gt;https://x.com/togethercompute/status/1909697122372378908&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3g3rr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744143685,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":58}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm9cex2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"knownboyofno","can_mod_post":false,"created_utc":1744224781,"send_replies":true,"parent_id":"t1_mm5wdzx","score":3,"author_fullname":"t2_5y9divj7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea, I don't see any difference in performance on my normal daily task that I use QwQ 32B to solve.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mm9cex2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, I don&amp;#39;t see any difference in performance on my normal daily task that I use QwQ 32B to solve.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9cex2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744224781,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5wdzx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ComprehensiveBird317","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm5qkad","score":3,"author_fullname":"t2_iaby02kl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you for testing","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mm5wdzx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for testing&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5wdzx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744175102,"author_flair_text":null,"treatment_tags":[],"created_utc":1744175102,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5qkad","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"knownboyofno","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm5pi19","score":8,"author_fullname":"t2_5y9divj7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I haven't had a chance to yet because I was trying to get some work done. I used it as a drop in replacement but it failed badly. I am going to try more settings tomorrow. I will let you know.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mm5qkad","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I haven&amp;#39;t had a chance to yet because I was trying to get some work done. I used it as a drop in replacement but it failed badly. I am going to try more settings tomorrow. I will let you know.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5qkad/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744172283,"author_flair_text":null,"treatment_tags":[],"created_utc":1744172283,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5pi19","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Silent_Safety","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm4dpzi","score":5,"author_fullname":"t2_43thccy5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's been quite some time. Have you checked?","edited":false,"author_flair_css_class":null,"name":"t1_mm5pi19","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s been quite some time. Have you checked?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5pi19/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744171792,"author_flair_text":null,"collapsed":false,"created_utc":1744171792,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4dpzi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"knownboyofno","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3pa61","score":6,"author_fullname":"t2_5y9divj7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just got back home, and it didn't do well, but I am going to check to make sure my settings are right.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4dpzi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just got back home, and it didn&amp;#39;t do well, but I am going to check to make sure my settings are right.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4dpzi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744154252,"author_flair_text":null,"treatment_tags":[],"created_utc":1744154252,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7f1rh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6y09f","score":3,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"QAT is not possible here, as these are Qwen models that have only been finetuned. So it's also a bit misleading to call them \\"new models\\" and proudly label them \\"fully open source\\" - they can't technically be open source, as the Qwen training dataset isn't even open source.","edited":false,"author_flair_css_class":null,"name":"t1_mm7f1rh","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;QAT is not possible here, as these are Qwen models that have only been finetuned. So it&amp;#39;s also a bit misleading to call them &amp;quot;new models&amp;quot; and proudly label them &amp;quot;fully open source&amp;quot; - they can&amp;#39;t technically be open source, as the Qwen training dataset isn&amp;#39;t even open source.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7f1rh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744204145,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1744204145,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmqm2e9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ReasonableLoss6814","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm7o9nk","score":1,"author_fullname":"t2_55ysrtku","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I usually toss something that is clearly not in the training model like: \\"write a fast and efficient implementation of the Fibonacci sequence in php.\\"\\n\\nThis model failed to figure it out before 3000 tokens. It goes in the trash bin.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mmqm2e9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I usually toss something that is clearly not in the training model like: &amp;quot;write a fast and efficient implementation of the Fibonacci sequence in php.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;This model failed to figure it out before 3000 tokens. It goes in the trash bin.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmqm2e9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744468607,"author_flair_text":null,"treatment_tags":[],"created_utc":1744468607,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm7o9nk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MrWeirdoFace","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6y09f","score":2,"author_fullname":"t2_12e249","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Using Q8 it failed my default python blender scripting tasks I put all local models through unfortunately, in more than one way. It also straight up ignored some very specific requirements. Had more luck with Qwen-2.5 coder instruct, although this also took a couple a attempts to get right. Maybe it's just not suited to my purposes.\\n\\nMaybe will have better luck once Deepcoder is out of preview.","edited":false,"author_flair_css_class":null,"name":"t1_mm7o9nk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using Q8 it failed my default python blender scripting tasks I put all local models through unfortunately, in more than one way. It also straight up ignored some very specific requirements. Had more luck with Qwen-2.5 coder instruct, although this also took a couple a attempts to get right. Maybe it&amp;#39;s just not suited to my purposes.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe will have better luck once Deepcoder is out of preview.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7o9nk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744207197,"author_flair_text":null,"collapsed":false,"created_utc":1744207197,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6y09f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3pa61","score":8,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried a few simple tasks with the Q8 model on a 32gb macbook. \\n\\n- The diffs will work at least. \\n- After the simple task I asked for it to do (insert another button in an html) succeeded, it failed at the last step with: \\"Cline tried to use attempt_completion without value for required parameter 'result'. Retrying...\\"\\n- It retried 2x before successfully figuring out how to use attempt_completion. Note, this is after the file itself was edited correctly. \\n- It made a few other edits decently well. Be careful with clarifications. If you ask it to do A, then clarify also B, it may do B only without doing A. \\n- I suspect this model will score okay ish on the [aider coding benchmark](https://aider.chat/docs/leaderboards/), but will lose some percentage due to edit format. \\n- I set context to 32k, but Cline is yappy and can easily fill up the context. \\n- Using Q8 makes it slower than Q4, but coding is one of those things that are more sensitive to smaller quants, so I'm sticking with Q8 for now. It'd be cool if they release a QAT 4bit version, similar to Gemma 3 QAT. At Q8 it runs around 15tok/sec for me.\\n\\nConclusion: not anywhere near as good as Sonnet 3.7, but I'm not sure if that's due to my computer's limitations (quantized quality loss, context size, quantized kv cache, etc). It's not complete trash, so I'm hopeful. It might be really cheap to run from an inference provider for people who can't run it locally.","edited":1744197601,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6y09f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried a few simple tasks with the Q8 model on a 32gb macbook. &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;The diffs will work at least. &lt;/li&gt;\\n&lt;li&gt;After the simple task I asked for it to do (insert another button in an html) succeeded, it failed at the last step with: &amp;quot;Cline tried to use attempt_completion without value for required parameter &amp;#39;result&amp;#39;. Retrying...&amp;quot;&lt;/li&gt;\\n&lt;li&gt;It retried 2x before successfully figuring out how to use attempt_completion. Note, this is after the file itself was edited correctly. &lt;/li&gt;\\n&lt;li&gt;It made a few other edits decently well. Be careful with clarifications. If you ask it to do A, then clarify also B, it may do B only without doing A. &lt;/li&gt;\\n&lt;li&gt;I suspect this model will score okay ish on the &lt;a href=\\"https://aider.chat/docs/leaderboards/\\"&gt;aider coding benchmark&lt;/a&gt;, but will lose some percentage due to edit format. &lt;/li&gt;\\n&lt;li&gt;I set context to 32k, but Cline is yappy and can easily fill up the context. &lt;/li&gt;\\n&lt;li&gt;Using Q8 makes it slower than Q4, but coding is one of those things that are more sensitive to smaller quants, so I&amp;#39;m sticking with Q8 for now. It&amp;#39;d be cool if they release a QAT 4bit version, similar to Gemma 3 QAT. At Q8 it runs around 15tok/sec for me.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Conclusion: not anywhere near as good as Sonnet 3.7, but I&amp;#39;m not sure if that&amp;#39;s due to my computer&amp;#39;s limitations (quantized quality loss, context size, quantized kv cache, etc). It&amp;#39;s not complete trash, so I&amp;#39;m hopeful. It might be really cheap to run from an inference provider for people who can&amp;#39;t run it locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6y09f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744197362,"author_flair_text":null,"treatment_tags":[],"created_utc":1744197362,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3pa61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ComprehensiveBird317","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3ky1y","score":14,"author_fullname":"t2_iaby02kl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"20 minutes ago! Did it work? Are the diffs diffing?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm3pa61","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;20 minutes ago! Did it work? Are the diffs diffing?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3pa61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744146283,"author_flair_text":null,"treatment_tags":[],"created_utc":1744146283,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3q9f9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dany0","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3ky1y","score":2,"author_fullname":"t2_bc7wl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I imagine it'll be good with coding but needs a post-training for tool use?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm3q9f9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I imagine it&amp;#39;ll be good with coding but needs a post-training for tool use?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3q9f9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744146576,"author_flair_text":null,"treatment_tags":[],"created_utc":1744146576,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3ky1y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"knownboyofno","can_mod_post":false,"created_utc":1744145044,"send_replies":true,"parent_id":"t1_mm3kcwp","score":23,"author_fullname":"t2_5y9divj7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am about to do this now!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3ky1y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am about to do this now!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3ky1y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145044,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4pic0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Throwawayaccount2832","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm430fk","score":22,"author_fullname":"t2_4szr33r7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s a 14b model, ofc o3 mini high is gonna beat it lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4pic0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s a 14b model, ofc o3 mini high is gonna beat it lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4pic0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158317,"author_flair_text":null,"treatment_tags":[],"created_utc":1744158317,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}}],"before":null}},"user_reports":[],"saved":false,"id":"mm430fk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dftba-ftw","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3s8mr","score":10,"author_fullname":"t2_6dg9w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not only that, but they conviently leave o3mini-high out of their graphics so theycan say it's o3mini (low) level - but if you go look up o3mini-high (which is what everyone using o3mini uses for coding) it beats them easily.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm430fk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not only that, but they conviently leave o3mini-high out of their graphics so theycan say it&amp;#39;s o3mini (low) level - but if you go look up o3mini-high (which is what everyone using o3mini uses for coding) it beats them easily.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm430fk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150614,"author_flair_text":null,"treatment_tags":[],"created_utc":1744150614,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3s8mr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OfficialHashPanda","can_mod_post":false,"created_utc":1744147178,"send_replies":true,"parent_id":"t1_mm3kcwp","score":21,"author_fullname":"t2_8w6mm4hmo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Likely not going to be great. They didn't include any software engineering benchmark results... That's probably for a good reason.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3s8mr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Likely not going to be great. They didn&amp;#39;t include any software engineering benchmark results... That&amp;#39;s probably for a good reason.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3s8mr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147178,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmj294x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wemos_D1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6k7wx","score":1,"author_fullname":"t2_3t20nkoj","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ok in the end it managed to understand the language and what was the goal, but didn't manage to generate working code and hallucinated a lot (using components that weren't there), and at some point, it broke the execution on the steps","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mmj294x","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok in the end it managed to understand the language and what was the goal, but didn&amp;#39;t manage to generate working code and hallucinated a lot (using components that weren&amp;#39;t there), and at some point, it broke the execution on the steps&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmj294x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744358708,"author_flair_text":null,"treatment_tags":[],"created_utc":1744358708,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6k7wx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EmberGlitch","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6jupt","score":1,"author_fullname":"t2_h6ljsiqs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No problem. And yeah, I'm guessing many people will run into that one. \\nThe ollama default \`num_ctx\` being 2048 is already incredibly silly, but having an option to set a context window and *not* sending that parameter to ollama is even sillier, and incredibly counter-intuitive. \\n\\nI only realized something was up when I saw that the model took up about half as much VRAM as I thought it should and decided to look into the logs.","edited":false,"author_flair_css_class":null,"name":"t1_mm6k7wx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No problem. And yeah, I&amp;#39;m guessing many people will run into that one. \\nThe ollama default &lt;code&gt;num_ctx&lt;/code&gt; being 2048 is already incredibly silly, but having an option to set a context window and &lt;em&gt;not&lt;/em&gt; sending that parameter to ollama is even sillier, and incredibly counter-intuitive. &lt;/p&gt;\\n\\n&lt;p&gt;I only realized something was up when I saw that the model took up about half as much VRAM as I thought it should and decided to look into the logs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6k7wx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744189555,"author_flair_text":null,"collapsed":false,"created_utc":1744189555,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6jupt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wemos_D1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm6ix0z","score":1,"author_fullname":"t2_3t20nkoj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you I think it was my mistake, tonight I'll give it another try, thank you very much I'll keep you updated ;)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6jupt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you I think it was my mistake, tonight I&amp;#39;ll give it another try, thank you very much I&amp;#39;ll keep you updated ;)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6jupt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744189315,"author_flair_text":null,"treatment_tags":[],"created_utc":1744189315,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6ix0z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EmberGlitch","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm52zki","score":4,"author_fullname":"t2_h6ljsiqs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A few issues here that I also ran into:\\n\\n1. Setting the Context Window Size in Roo's model settings doesn't actually call ollama with the \`num_ctx\` parameter - unlike any other tool you might be familiar with, like Open Webui or Sillytavern. You'll load the model with whatever ollama's default \`num_ctx\` is. By default, that is only 2048 tokens!  \\n2. Roo's default system prompt is around 9000 tokens long in Code mode (doesn't even include the workspace context or any active files you may have opened). So if you run with a 2048 context, well yeah - it doesn't know what's going on. \\n\\nYou need to increase that context window either by changing the ollama default, or the model itself. They describe how in the docs:\\n\\nhttps://docs.roocode.com/providers/ollama","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm6ix0z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A few issues here that I also ran into:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Setting the Context Window Size in Roo&amp;#39;s model settings doesn&amp;#39;t actually call ollama with the &lt;code&gt;num_ctx&lt;/code&gt; parameter - unlike any other tool you might be familiar with, like Open Webui or Sillytavern. You&amp;#39;ll load the model with whatever ollama&amp;#39;s default &lt;code&gt;num_ctx&lt;/code&gt; is. By default, that is only 2048 tokens!&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;Roo&amp;#39;s default system prompt is around 9000 tokens long in Code mode (doesn&amp;#39;t even include the workspace context or any active files you may have opened). So if you run with a 2048 context, well yeah - it doesn&amp;#39;t know what&amp;#39;s going on. &lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;You need to increase that context window either by changing the ollama default, or the model itself. They describe how in the docs:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://docs.roocode.com/providers/ollama\\"&gt;https://docs.roocode.com/providers/ollama&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6ix0z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744188702,"author_flair_text":null,"treatment_tags":[],"created_utc":1744188702,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mm52zki","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wemos_D1","can_mod_post":false,"created_utc":1744163083,"send_replies":true,"parent_id":"t1_mm3kcwp","score":2,"author_fullname":"t2_3t20nkoj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I asked it to make a blog using astro and tailwind css, it gave me a html file to serve with python, I think I did a mistake because it's way too far away from what I asked","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm52zki","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I asked it to make a blog using astro and tailwind css, it gave me a html file to serve with python, I think I did a mistake because it&amp;#39;s way too far away from what I asked&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm52zki/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744163083,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3w5wy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HighwayResponsible63","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3thpi","score":2,"author_fullname":"t2_17qtc88eoc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"thanks a lot , so if I understand correctly  it is basically an LLM but geared towards generating code ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3w5wy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thanks a lot , so if I understand correctly  it is basically an LLM but geared towards generating code ?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3w5wy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148399,"author_flair_text":null,"treatment_tags":[],"created_utc":1744148399,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3thpi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AIgavemethisusername","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3skpa","score":2,"author_fullname":"t2_udgynhwn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A model fine tuned for writing computer code/programs.\\n\\n“Write me a python program that will……”","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm3thpi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A model fine tuned for writing computer code/programs.&lt;/p&gt;\\n\\n&lt;p&gt;“Write me a python program that will……”&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3thpi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147566,"author_flair_text":null,"treatment_tags":[],"created_utc":1744147566,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3skpa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3kcwp","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1744147699,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3skpa/","num_reports":null,"locked":false,"name":"t1_mm3skpa","created":1744147281,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744147281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4i96t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious-Tap-4670","can_mod_post":false,"created_utc":1744155786,"send_replies":true,"parent_id":"t1_mm3kcwp","score":1,"author_fullname":"t2_n2zhoqg5d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This was my question as well. IIUC models like this are good for completions in the editor, but not something necessarily agentic like Cline?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4i96t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was my question as well. IIUC models like this are good for completions in the editor, but not something necessarily agentic like Cline?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4i96t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744155786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3kcwp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ComprehensiveBird317","can_mod_post":false,"created_utc":1744144876,"send_replies":true,"parent_id":"t3_1juni3t","score":35,"author_fullname":"t2_iaby02kl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's impressive, did anyone try if it works with CLINE/ roo code?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3kcwp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s impressive, did anyone try if it works with CLINE/ roo code?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3kcwp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744144876,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":15,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmyq1nz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mikhail_arkhipov","can_mod_post":false,"send_replies":true,"parent_id":"t1_mmsfbal","score":1,"author_fullname":"t2_2h3qgkq9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"UPD: March 31 [blogpost](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model)\\n\\n&gt;37.2% verified resolve rate on SWE-Bench Verified Performance comparable to models with 20x more parameters, including Deepseek V3 0324 (38.8%) with 671B parameters.\\n\\nWell, the details on evaluation are not disclosed: \\n\\n&gt; We evaluated OpenHands LM using our latest iterative evaluation protocol on the SWE-Bench Verified benchmark. \\n\\nwhich is just a Docker for running tests on patches.\\n\\nWhether they used a special scafold for their models or not is not clear from the publication. It is possible just to use right tooling for a model to get much better scores. Whether the tooling was the same for DSV3 and their model is an opened question.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mmyq1nz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;UPD: March 31 &lt;a href=\\"https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model\\"&gt;blogpost&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;37.2% verified resolve rate on SWE-Bench Verified Performance comparable to models with 20x more parameters, including Deepseek V3 0324 (38.8%) with 671B parameters.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Well, the details on evaluation are not disclosed: &lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;We evaluated OpenHands LM using our latest iterative evaluation protocol on the SWE-Bench Verified benchmark. &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;which is just a Docker for running tests on patches.&lt;/p&gt;\\n\\n&lt;p&gt;Whether they used a special scafold for their models or not is not clear from the publication. It is possible just to use right tooling for a model to get much better scores. Whether the tooling was the same for DSV3 and their model is an opened question.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmyq1nz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744580792,"author_flair_text":null,"treatment_tags":[],"created_utc":1744580792,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmsfbal","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mikhail_arkhipov","can_mod_post":false,"created_utc":1744489450,"send_replies":true,"parent_id":"t1_mm40zww","score":2,"author_fullname":"t2_2h3qgkq9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The would show it off if there are any good results (or even compatible). If they show something meaningful on SWE bench later, it might be an indicator that it is hard to make it work properly in agentic mode.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmsfbal","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The would show it off if there are any good results (or even compatible). If they show something meaningful on SWE bench later, it might be an indicator that it is hard to make it work properly in agentic mode.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmsfbal/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744489450,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm40zww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1juni3t","score":15,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1746983670,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm40zww/","num_reports":null,"locked":false,"name":"t1_mm40zww","created":1744149945,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744149945,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7kd4z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Coppermoore","can_mod_post":false,"created_utc":1744205959,"send_replies":true,"parent_id":"t1_mm6a1qc","score":1,"author_fullname":"t2_74ssf59h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's so cute.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm7kd4z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s so cute.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7kd4z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744205959,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmcywh1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Nice-Club9942","can_mod_post":false,"created_utc":1744276972,"send_replies":true,"parent_id":"t1_mm6a1qc","score":1,"author_fullname":"t2_dxn5bscb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Experience the same","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmcywh1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Experience the same&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmcywh1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744276972,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm6a1qc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EmberGlitch","can_mod_post":false,"created_utc":1744182920,"send_replies":true,"parent_id":"t3_1juni3t","score":11,"author_fullname":"t2_h6ljsiqs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Impressive, on paper.\\n\\nHowever, I'm playing around with it right now, and at q8_0 it's failing miserably at stuff that o3-mini easily one-shots.\\n\\nI've had it have 10 attempts at a snake game in pygame where two AI controlled snakes compete against each other.\\nIt has many silly errors like calling undefined functions or variables. In one attempt, it had something like:\\n\\n    # Correction: 'snace' should be 'snake'\\n    y = random.randint(snace_block, height - snake_block)\\n\\nAt least it made me laugh.","edited":1744183228,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6a1qc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Impressive, on paper.&lt;/p&gt;\\n\\n&lt;p&gt;However, I&amp;#39;m playing around with it right now, and at q8_0 it&amp;#39;s failing miserably at stuff that o3-mini easily one-shots.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve had it have 10 attempts at a snake game in pygame where two AI controlled snakes compete against each other.\\nIt has many silly errors like calling undefined functions or variables. In one attempt, it had something like:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;# Correction: &amp;#39;snace&amp;#39; should be &amp;#39;snake&amp;#39;\\ny = random.randint(snace_block, height - snake_block)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;At least it made me laugh.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6a1qc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744182920,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5pzuw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"knownboyofno","can_mod_post":false,"created_utc":1744172019,"send_replies":true,"parent_id":"t1_mm47123","score":2,"author_fullname":"t2_5y9divj7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am wondering if we need to adjust the settings. I will play with them to see if I can get better results. I got the same kinda of results like you but I am using Roo Code.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5pzuw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am wondering if we need to adjust the settings. I will play with them to see if I can get better results. I got the same kinda of results like you but I am using Roo Code.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5pzuw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744172019,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6xxjr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hannibal27","can_mod_post":false,"created_utc":1744197328,"send_replies":true,"parent_id":"t1_mm47123","score":1,"author_fullname":"t2_k47dgcq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If running via ollama you always need to increase the context","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6xxjr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If running via ollama you always need to increase the context&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6xxjr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744197328,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm47123","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"aaronpaulina","can_mod_post":false,"created_utc":1744151985,"send_replies":true,"parent_id":"t3_1juni3t","score":22,"author_fullname":"t2_87q2z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"just tried it in cline, it's not great. gets stuck doing the same thing over and over which is kind of the norm with smaller models trying to use complex tool calling and context such as coding. seems pretty good if you just chat with it instead","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm47123","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just tried it in cline, it&amp;#39;s not great. gets stuck doing the same thing over and over which is kind of the norm with smaller models trying to use complex tool calling and context such as coding. seems pretty good if you just chat with it instead&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm47123/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151985,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm43kdl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"napkinolympics","can_mod_post":false,"created_utc":1744150800,"send_replies":true,"parent_id":"t3_1juni3t","score":10,"author_fullname":"t2_loxnv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I asked it to make me a spinning cube in python. 20,000 tokens later and it's still going.\\n\\nedit: I set the temperature value to 0.6 and now it's behaving as expected.","edited":1744151572,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm43kdl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I asked it to make me a spinning cube in python. 20,000 tokens later and it&amp;#39;s still going.&lt;/p&gt;\\n\\n&lt;p&gt;edit: I set the temperature value to 0.6 and now it&amp;#39;s behaving as expected.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm43kdl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150800,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6zmpe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"petercooper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3y6tr","score":2,"author_fullname":"t2_10a0u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks, I'll take a look!","edited":false,"author_flair_css_class":null,"name":"t1_mm6zmpe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I&amp;#39;ll take a look!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6zmpe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744198113,"author_flair_text":null,"collapsed":false,"created_utc":1744198113,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm9oa3e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3y6tr","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Honestly it works perfectly fine at temp 0.7, min_p 0.06, 1.05 rep. I've given these a short test try and it seems a lot less creative. \\n\\nGood ol' min_p, nothing beats that.","edited":false,"author_flair_css_class":null,"name":"t1_mm9oa3e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly it works perfectly fine at temp 0.7, min_p 0.06, 1.05 rep. I&amp;#39;ve given these a short test try and it seems a lot less creative. &lt;/p&gt;\\n\\n&lt;p&gt;Good ol&amp;#39; min_p, nothing beats that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9oa3e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744228267,"author_flair_text":null,"collapsed":false,"created_utc":1744228267,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3y6tr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hoodfu","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3wkf0","score":23,"author_fullname":"t2_dnq0h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You sure you have the right temp etc settings? QwQ needs very specific ones to work correctly.  \\n\\n        \\"temperature\\": 0.6,\\n    \\n    \\n\\n        \\"top_k\\": 40,\\n    \\n    \\n\\n        \\"top_p\\": 0.95","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3y6tr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You sure you have the right temp etc settings? QwQ needs very specific ones to work correctly.  &lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;    &amp;quot;temperature&amp;quot;: 0.6,\\n\\n\\n\\n    &amp;quot;top_k&amp;quot;: 40,\\n\\n\\n\\n    &amp;quot;top_p&amp;quot;: 0.95\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3y6tr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744149036,"author_flair_text":null,"treatment_tags":[],"created_utc":1744149036,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6zlpp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"petercooper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm45gjp","score":1,"author_fullname":"t2_10a0u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Haha, I hadn't seen that one before, but thanks! I'll take a look.","edited":false,"author_flair_css_class":null,"name":"t1_mm6zlpp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Haha, I hadn&amp;#39;t seen that one before, but thanks! I&amp;#39;ll take a look.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1juni3t","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6zlpp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744198101,"author_flair_text":null,"collapsed":false,"created_utc":1744198101,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm45gjp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AD7GD","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3wkf0","score":10,"author_fullname":"t2_gm98s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"time for my daily: make sure you are not using default ollama context with qwq! reply","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm45gjp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;time for my daily: make sure you are not using default ollama context with qwq! reply&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm45gjp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151439,"author_flair_text":null,"treatment_tags":[],"created_utc":1744151439,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3wkf0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"petercooper","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3nrra","score":7,"author_fullname":"t2_10a0u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is the experience I've had with QwQ locally as well. I've seen so much love for it but whenever I use it it just spends ages thinking over and over before actually getting anywhere.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm3wkf0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the experience I&amp;#39;ve had with QwQ locally as well. I&amp;#39;ve seen so much love for it but whenever I use it it just spends ages thinking over and over before actually getting anywhere.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3wkf0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744148524,"author_flair_text":null,"treatment_tags":[],"created_utc":1744148524,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3nrra","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_slay_nub","can_mod_post":false,"created_utc":1744145845,"send_replies":true,"parent_id":"t1_mm3lint","score":13,"author_fullname":"t2_u8o4d","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"16k tokens for a response, even from a 14B model is painful. 3 minutes on reasonable hardware is ouch.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3nrra","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;16k tokens for a response, even from a 14B model is painful. 3 minutes on reasonable hardware is ouch.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3nrra/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145845,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"more","data":{"count":1,"name":"t1_mm6albs","id":"mm6albs","parent_id":"t1_mm3lint","depth":1,"children":["mm6albs"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3lint","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chelono","can_mod_post":false,"created_utc":1744145206,"send_replies":true,"parent_id":"t3_1juni3t","score":30,"author_fullname":"t2_v9cchwm6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I found this graph the most interesting\\n\\nhttps://preview.redd.it/kwa1sezdaote1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=68135240422661eaa94247ea97afacb501618c6c\\n\\nimo cool that inference time scaling works, but personally I don't find it as useful since even for a small thinking model at some point the wait time is just too long.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3lint","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found this graph the most interesting&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/kwa1sezdaote1.png?width=1129&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68135240422661eaa94247ea97afacb501618c6c\\"&gt;https://preview.redd.it/kwa1sezdaote1.png?width=1129&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68135240422661eaa94247ea97afacb501618c6c&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;imo cool that inference time scaling works, but personally I don&amp;#39;t find it as useful since even for a small thinking model at some point the wait time is just too long.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3lint/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145206,"media_metadata":{"kwa1sezdaote1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":51,"x":108,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3360b7ae2b7087448e711e221f268fd71db06404"},{"y":102,"x":216,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=129800c5a3a46a00eb5c0b6365619cb9e5f3edd9"},{"y":152,"x":320,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c76aba92e2e8958769179a7067bbc4689efb3ffc"},{"y":304,"x":640,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6322c0079e6643133f5b736eb360d55122f61862"},{"y":456,"x":960,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=90db7b1cb6c0170ddbb9821e32800f4ded26edd1"},{"y":513,"x":1080,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=677124fe7cdae7b5780e93a1211aa368e61e5f55"}],"s":{"y":537,"x":1129,"u":"https://preview.redd.it/kwa1sezdaote1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=68135240422661eaa94247ea97afacb501618c6c"},"id":"kwa1sezdaote1"}},"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm766um","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the_renaissance_jack","can_mod_post":false,"created_utc":1744200869,"send_replies":true,"parent_id":"t1_mm47qgx","score":1,"author_fullname":"t2_2frr0ty","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"3b and under models are getting increasingly good when given the right the context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm766um","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;3b and under models are getting increasingly good when given the right the context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm766um/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744200869,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm47qgx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Papabear3339","can_mod_post":false,"created_utc":1744152226,"send_replies":true,"parent_id":"t3_1juni3t","score":7,"author_fullname":"t2_7iw5w8ac","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tried the 1.5b on a (private) test problem. \\n\\nIt is by far the most coherent 1.5b code model i have ever tested.\\n\\nAlthough it lacked the deeper understanding of a bigger model, it did give good suggestions and correct code.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm47qgx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried the 1.5b on a (private) test problem. &lt;/p&gt;\\n\\n&lt;p&gt;It is by far the most coherent 1.5b code model i have ever tested.&lt;/p&gt;\\n\\n&lt;p&gt;Although it lacked the deeper understanding of a bigger model, it did give good suggestions and correct code.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm47qgx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744152226,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4qr51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"getfitdotus","can_mod_post":false,"created_utc":1744158757,"send_replies":true,"parent_id":"t1_mm4633o","score":7,"author_fullname":"t2_dst51dcb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I tested the fp16 and it was not very good. All of the results had to be iterated on multiple times","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4qr51","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tested the fp16 and it was not very good. All of the results had to be iterated on multiple times&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4qr51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158757,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4633o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"makistsa","can_mod_post":false,"created_utc":1744151656,"send_replies":true,"parent_id":"t3_1juni3t","score":7,"author_fullname":"t2_3l1o090d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very good for the size, but it's not close at all to o3-mini.(I tested the q8 gguf not the original)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4633o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very good for the size, but it&amp;#39;s not close at all to o3-mini.(I tested the q8 gguf not the original)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4633o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151656,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4ddp8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thecalmgreen","can_mod_post":false,"created_utc":1744154135,"send_replies":true,"parent_id":"t3_1juni3t","score":18,"author_fullname":"t2_17ktgtm91m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I usually leave positive and encouraging comments when I see new models. But it's getting tiring to see Qwen finetunings that, in practice, don't change a thing, yet are promoted almost as if they're entirely new models. What's worse is seeing the hype from people who don’t even test them and just get excited over a chart image.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4ddp8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I usually leave positive and encouraging comments when I see new models. But it&amp;#39;s getting tiring to see Qwen finetunings that, in practice, don&amp;#39;t change a thing, yet are promoted almost as if they&amp;#39;re entirely new models. What&amp;#39;s worse is seeing the hype from people who don’t even test them and just get excited over a chart image.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4ddp8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744154135,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm40mu2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"davewolfs","can_mod_post":false,"created_utc":1744149826,"send_replies":true,"parent_id":"t3_1juni3t","score":20,"author_fullname":"t2_pms20","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If the Benchmarks are too good to be true, they probably are.  It would be nice if we could get these models targeted at specific languages. I tend to believe they train the models using the languages that the benchmarks run e.g. Javascript or Python which many of us do not use in our day to day.\\n\\nI’m pretty confident this would fail miserably on Aider.","edited":1744151362,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm40mu2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If the Benchmarks are too good to be true, they probably are.  It would be nice if we could get these models targeted at specific languages. I tend to believe they train the models using the languages that the benchmarks run e.g. Javascript or Python which many of us do not use in our day to day.&lt;/p&gt;\\n\\n&lt;p&gt;I’m pretty confident this would fail miserably on Aider.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm40mu2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744149826,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6arsr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dead-Photographer","can_mod_post":false,"created_utc":1744183381,"send_replies":true,"parent_id":"t3_1juni3t","score":4,"author_fullname":"t2_1425v26bz5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does it compare to qwen 2.5 coder 32b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6arsr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does it compare to qwen 2.5 coder 32b?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6arsr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744183381,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm70s4c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Fade78","can_mod_post":false,"created_utc":1744198622,"send_replies":true,"parent_id":"t3_1juni3t","score":6,"author_fullname":"t2_11acru","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No qwen2.5-coder on the chart? I can't compare.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm70s4c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No qwen2.5-coder on the chart? I can&amp;#39;t compare.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm70s4c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744198622,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3s825","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ResearchCrafty1804","can_mod_post":false,"created_utc":1744147173,"send_replies":true,"parent_id":"t3_1juni3t","score":7,"author_fullname":"t2_c705ri9b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s always great when a model is fully open-source! \\n\\nCongratulations to the authors!","edited":1744160850,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3s825","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s always great when a model is fully open-source! &lt;/p&gt;\\n\\n&lt;p&gt;Congratulations to the authors!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3s825/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147173,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mme2hy0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"grubnenah","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm57qtr","score":1,"author_fullname":"t2_ityn8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"An easy way to get a rough guess is to just look at the download size. 14B @ 4bit is still a 9gb download, so it's definitely going to be larger than your 8gb VRAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mme2hy0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;An easy way to get a rough guess is to just look at the download size. 14B @ 4bit is still a 9gb download, so it&amp;#39;s definitely going to be larger than your 8gb VRAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mme2hy0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744294081,"author_flair_text":null,"treatment_tags":[],"created_utc":1744294081,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm57qtr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Soggy_Panic7099","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm427w3","score":1,"author_fullname":"t2_srfi43yao","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My laptop has a 4060 with 8gb VRAM. Should a 14B @ 4bit quant work?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm57qtr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My laptop has a 4060 with 8gb VRAM. Should a 14B @ 4bit quant work?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm57qtr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744164740,"author_flair_text":null,"treatment_tags":[],"created_utc":1744164740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm427w3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Melon__Bread","can_mod_post":false,"created_utc":1744150351,"send_replies":true,"parent_id":"t1_mm3i51k","score":16,"author_fullname":"t2_6728e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\`\`\`\\nollama run hf.co/lmstudio-community/DeepCoder-14B-Preview-GGUF:Q4_K_M\\n\`\`\`\\n  \\nSwap \`Q4_K_M\` with your quant of choice  \\nhttps://huggingface.co/lmstudio-community/DeepCoder-14B-Preview-GGUF/tree/main","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm427w3","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;code&gt;\\nollama run hf.co/lmstudio-community/DeepCoder-14B-Preview-GGUF:Q4_K_M\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Swap &lt;code&gt;Q4_K_M&lt;/code&gt; with your quant of choice&lt;br/&gt;\\n&lt;a href=\\"https://huggingface.co/lmstudio-community/DeepCoder-14B-Preview-GGUF/tree/main\\"&gt;https://huggingface.co/lmstudio-community/DeepCoder-14B-Preview-GGUF/tree/main&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm427w3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150351,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm50uaj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Cacique","can_mod_post":false,"created_utc":1744162324,"send_replies":true,"parent_id":"t1_mm3i51k","score":4,"author_fullname":"t2_ghhr800u8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://ollama.com/library/deepcoder","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm50uaj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://ollama.com/library/deepcoder\\"&gt;https://ollama.com/library/deepcoder&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm50uaj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744162324,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3i51k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DRONE_SIC","can_mod_post":false,"created_utc":1744144263,"send_replies":true,"parent_id":"t3_1juni3t","score":14,"author_fullname":"t2_dyj6ile","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Amazing! Can't wait for this to drop on Ollama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3i51k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Amazing! Can&amp;#39;t wait for this to drop on Ollama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3i51k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744144263,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmkkf3j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vertigo235","can_mod_post":false,"send_replies":true,"parent_id":"t1_mmkgj8s","score":1,"author_fullname":"t2_812in","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"o3 mini low isn’t really that great.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmkkf3j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;o3 mini low isn’t really that great.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmkkf3j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744382662,"author_flair_text":null,"treatment_tags":[],"created_utc":1744382662,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mmkgj8s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahmetegesel","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm7peaz","score":2,"author_fullname":"t2_69skhb61","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Check the title again. They compare with open ai’s reasoning model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mmkgj8s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Check the title again. They compare with open ai’s reasoning model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmkgj8s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744381493,"author_flair_text":null,"treatment_tags":[],"created_utc":1744381493,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm7peaz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vertigo235","can_mod_post":false,"created_utc":1744207550,"send_replies":true,"parent_id":"t1_mm4h3b1","score":3,"author_fullname":"t2_812in","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To be expected, QwQ is more than twice the size and also is a thinking model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm7peaz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To be expected, QwQ is more than twice the size and also is a thinking model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7peaz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744207550,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm69438","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emfloured","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm62wxd","score":1,"author_fullname":"t2_73px95yd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"ok thanks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm69438","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ok thanks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm69438/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744182335,"author_flair_text":null,"treatment_tags":[],"created_utc":1744182335,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm62wxd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm606xt","score":1,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No idea .\\nNever used phi4","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm62wxd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No idea .\\nNever used phi4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm62wxd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744178608,"author_flair_text":null,"treatment_tags":[],"created_utc":1744178608,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm606xt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"emfloured","can_mod_post":false,"created_utc":1744177091,"send_replies":true,"parent_id":"t1_mm4h3b1","score":1,"author_fullname":"t2_73px95yd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How is deepcoder14b against the phi4 in code quality?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm606xt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How is deepcoder14b against the phi4 in code quality?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm606xt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744177091,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4h3b1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1744155390,"send_replies":true,"parent_id":"t3_1juni3t","score":10,"author_fullname":"t2_ogjj6ebj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"tested .. not even remotely close to QwQ code quality ...","edited":1744208150,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4h3b1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;tested .. not even remotely close to QwQ code quality ...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4h3b1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744155390,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmcdl5w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"perk11","can_mod_post":false,"created_utc":1744263643,"send_replies":true,"parent_id":"t1_mm4qwjc","score":1,"author_fullname":"t2_ar5cq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same... I tried a few coding queries I sent to ChatGPT and it had significant errors in all the responses.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmcdl5w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same... I tried a few coding queries I sent to ChatGPT and it had significant errors in all the responses.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmcdl5w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744263643,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm4qwjc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"getfitdotus","can_mod_post":false,"created_utc":1744158810,"send_replies":true,"parent_id":"t3_1juni3t","score":8,"author_fullname":"t2_dst51dcb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure about the claims here, it did not perform well for me. full weights.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4qwjc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure about the claims here, it did not perform well for me. full weights.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4qwjc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158810,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4uuq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lost_Attention_3355","can_mod_post":false,"created_utc":1744160197,"send_replies":true,"parent_id":"t3_1juni3t","score":6,"author_fullname":"t2_1mr4rkpqir","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have found that fine-tuned models are often not very good, they are basically hacks on the results rather than real improvements in performance.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4uuq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have found that fine-tuned models are often not very good, they are basically hacks on the results rather than real improvements in performance.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4uuq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744160197,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm76h6m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the_renaissance_jack","can_mod_post":false,"created_utc":1744200983,"send_replies":true,"parent_id":"t1_mm500wz","score":2,"author_fullname":"t2_2frr0ty","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I get think tags with Open WebUI. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm76h6m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I get think tags with Open WebUI. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm76h6m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744200983,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm583f7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1744164864,"send_replies":true,"parent_id":"t1_mm500wz","score":1,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sometimes UIs hide them… I had issues triggering thinking. I ended up using Silly Tavern to auto insert it to get it started","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm583f7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sometimes UIs hide them… I had issues triggering thinking. I ended up using Silly Tavern to auto insert it to get it started&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm583f7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744164864,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm500wz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_Sub01_","can_mod_post":false,"created_utc":1744162034,"send_replies":true,"parent_id":"t3_1juni3t","score":3,"author_fullname":"t2_ca55nq6y","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/obipn037ppte1.png?width=1201&amp;format=png&amp;auto=webp&amp;s=103ca45fddf56c3fc8df46a235cd78a6c3251c73\\n\\nNot sure if its just me or are there no &lt;think&gt; tags enclosed when its thinking?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm500wz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/obipn037ppte1.png?width=1201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103ca45fddf56c3fc8df46a235cd78a6c3251c73\\"&gt;https://preview.redd.it/obipn037ppte1.png?width=1201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103ca45fddf56c3fc8df46a235cd78a6c3251c73&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Not sure if its just me or are there no &amp;lt;think&amp;gt; tags enclosed when its thinking?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm500wz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744162034,"media_metadata":{"obipn037ppte1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":72,"x":108,"u":"https://preview.redd.it/obipn037ppte1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=636a9ca269c5b03250cf9f6e93ddfbf802469530"},{"y":144,"x":216,"u":"https://preview.redd.it/obipn037ppte1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=007f5c183a6d7267739914232fdfa65cb2d12a93"},{"y":213,"x":320,"u":"https://preview.redd.it/obipn037ppte1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d840f00705ea7e8490921d1b46bebe80a651ddc3"},{"y":427,"x":640,"u":"https://preview.redd.it/obipn037ppte1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=43604c4bb8006e95255380ce185324ecdc9c7f02"},{"y":641,"x":960,"u":"https://preview.redd.it/obipn037ppte1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a2a0e03526f2dc0aef77f0b430db1e32d319082"},{"y":722,"x":1080,"u":"https://preview.redd.it/obipn037ppte1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd73327bf143df014d78cb2952e11a0e14545ddf"}],"s":{"y":803,"x":1201,"u":"https://preview.redd.it/obipn037ppte1.png?width=1201&amp;format=png&amp;auto=webp&amp;s=103ca45fddf56c3fc8df46a235cd78a6c3251c73"},"id":"obipn037ppte1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6jzc2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"zoidme","can_mod_post":false,"created_utc":1744189398,"send_replies":true,"parent_id":"t3_1juni3t","score":6,"author_fullname":"t2_wpj7q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've tried in LMStudio with \\"Bouncing Balls In Rotating Heptagon\\" test. Completely failed to produce a working code. Had 3 iterations to fix runtime errors like missing functions and variables and the result was just a rotating heptagon.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6jzc2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tried in LMStudio with &amp;quot;Bouncing Balls In Rotating Heptagon&amp;quot; test. Completely failed to produce a working code. Had 3 iterations to fix runtime errors like missing functions and variables and the result was just a rotating heptagon.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6jzc2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744189398,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5h29u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vintage2019","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3tfqk","score":1,"author_fullname":"t2_3a8iirsg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Non-reasoning 3.7 is lower? Or simply not published yet?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm5h29u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Non-reasoning 3.7 is lower? Or simply not published yet?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5h29u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744168189,"author_flair_text":null,"treatment_tags":[],"created_utc":1744168189,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3tfqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the__storm","can_mod_post":false,"created_utc":1744147549,"send_replies":true,"parent_id":"t1_mm3lji8","score":11,"author_fullname":"t2_gx0bv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's the only non-reasoning model on the list, not too surprising it gets crushed.  The best non-reasoning model in the wild (with a score published by LCB) is Claude 3.5 Sonnet at **37.2**.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3tfqk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s the only non-reasoning model on the list, not too surprising it gets crushed.  The best non-reasoning model in the wild (with a score published by LCB) is Claude 3.5 Sonnet at &lt;strong&gt;37.2&lt;/strong&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3tfqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147549,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3s2qt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OfficialHashPanda","can_mod_post":false,"created_utc":1744147128,"send_replies":true,"parent_id":"t1_mm3lji8","score":1,"author_fullname":"t2_8w6mm4hmo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, the only non-reasoning model in the lineup. Not really surprising that it scores lower than the others on reasoning-heavy benchmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3s2qt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, the only non-reasoning model in the lineup. Not really surprising that it scores lower than the others on reasoning-heavy benchmarks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3s2qt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147128,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3lji8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Different_Fix_2217","can_mod_post":false,"created_utc":1744145213,"send_replies":true,"parent_id":"t3_1juni3t","score":9,"author_fullname":"t2_4dhrrvi6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/nirlpzg5bote1.png?width=1348&amp;format=png&amp;auto=webp&amp;s=d9a29f16c7f1ea00aab88f4fa0e94ee08c4cb6ca\\n\\nOh. Oh no... That 2T model...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3lji8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/nirlpzg5bote1.png?width=1348&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d9a29f16c7f1ea00aab88f4fa0e94ee08c4cb6ca\\"&gt;https://preview.redd.it/nirlpzg5bote1.png?width=1348&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d9a29f16c7f1ea00aab88f4fa0e94ee08c4cb6ca&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Oh. Oh no... That 2T model...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3lji8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145213,"media_metadata":{"nirlpzg5bote1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":69,"x":108,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=998620056c52c86b7aa6398650e1dbdd71383c5a"},{"y":139,"x":216,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=33f1c335cd39a139c101fec6680c1b2376083545"},{"y":207,"x":320,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cef94e6495bfde4c6c9e78bde675a1fc9c0598f"},{"y":414,"x":640,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=841c8ab6ea2f82b991d6f81c6d50abcb814a45fa"},{"y":621,"x":960,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=233ea90282ea576ff93a394bdf35798b35205b80"},{"y":698,"x":1080,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=486260851167bb80de661e58aeb6e998f01443e3"}],"s":{"y":872,"x":1348,"u":"https://preview.redd.it/nirlpzg5bote1.png?width=1348&amp;format=png&amp;auto=webp&amp;s=d9a29f16c7f1ea00aab88f4fa0e94ee08c4cb6ca"},"id":"nirlpzg5bote1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm5j0nh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Titanusgamer","can_mod_post":false,"created_utc":1744168987,"send_replies":true,"parent_id":"t3_1juni3t","score":2,"author_fullname":"t2_4aytq2jc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"with my RTX 4080s which is the best coder model I can run locally. i sometime feel that if the best model (chatgpt, claude) are all available online whu use local which are heavily quantied to fit in paltry 16gb of vram","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5j0nh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;with my RTX 4080s which is the best coder model I can run locally. i sometime feel that if the best model (chatgpt, claude) are all available online whu use local which are heavily quantied to fit in paltry 16gb of vram&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5j0nh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744168987,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4p74l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"codingworkflow","can_mod_post":false,"created_utc":1744158206,"send_replies":true,"parent_id":"t3_1juni3t","score":3,"author_fullname":"t2_1kdxd5n9hz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Where is the mode card? Context?\\nBlog says based on Llama/Qwen. So no new base here. Mire fine tuning and I'afraid this will not go far.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4p74l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where is the mode card? Context?\\nBlog says based on Llama/Qwen. So no new base here. Mire fine tuning and I&amp;#39;afraid this will not go far.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4p74l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158206,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmbbq19","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jugg3rnaut","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm97ced","score":1,"author_fullname":"t2_642ne","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I dont know what the other 2 datasets they're using are but certainly one of them","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmbbq19","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I dont know what the other 2 datasets they&amp;#39;re using are but certainly one of them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmbbq19/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744247764,"author_flair_text":null,"treatment_tags":[],"created_utc":1744247764,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm97ced","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Free-Combination-773","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm3ph5f","score":1,"author_fullname":"t2_9wrdyt8b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So it's basically fine-tuned for benchmarks?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mm97ced","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So it&amp;#39;s basically fine-tuned for benchmarks?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm97ced/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744223304,"author_flair_text":null,"treatment_tags":[],"created_utc":1744223304,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3ph5f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Jugg3rnaut","can_mod_post":false,"created_utc":1744146341,"send_replies":true,"parent_id":"t1_mm3i6bj","score":13,"author_fullname":"t2_642ne","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Data\\n&gt; Our training dataset consists of approximately 24K unique problem-tests pairs compiled from\\n&gt; Taco-Verified\\n&gt; PrimeIntellect SYNTHETIC-1\\n&gt; LiveCodeBench v5 (5/1/23-7/31/24)\\n\\nand their success metric is\\n\\n&gt; achieves 60.6% Pass@1 accuracy on LiveCodeBench v5 (8/1/24-2/1/25)\\n\\nLiveCodeBench is a collection of LeetCode style problems and so there is significant overlap in the types of problems in it across the date range","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3ph5f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Data\\nOur training dataset consists of approximately 24K unique problem-tests pairs compiled from\\nTaco-Verified\\nPrimeIntellect SYNTHETIC-1\\nLiveCodeBench v5 (5/1/23-7/31/24)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;and their success metric is&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;achieves 60.6% Pass@1 accuracy on LiveCodeBench v5 (8/1/24-2/1/25)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;LiveCodeBench is a collection of LeetCode style problems and so there is significant overlap in the types of problems in it across the date range&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3ph5f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744146341,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4ds94","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thecalmgreen","can_mod_post":false,"created_utc":1744154273,"send_replies":true,"parent_id":"t1_mm3i6bj","score":4,"author_fullname":"t2_17ktgtm91m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But did they do it? Stop hyping up a chart, test it out for yourself.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4ds94","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But did they do it? Stop hyping up a chart, test it out for yourself.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4ds94/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744154273,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3i6bj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ih8tk","can_mod_post":false,"created_utc":1744144273,"send_replies":true,"parent_id":"t3_1juni3t","score":5,"author_fullname":"t2_vpz8xfih6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Woah! How the hell did they manage that?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3i6bj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Woah! How the hell did they manage that?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3i6bj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744144273,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4hdtd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"freedomachiever","can_mod_post":false,"created_utc":1744155488,"send_replies":true,"parent_id":"t3_1juni3t","score":3,"author_fullname":"t2_1swl8bn1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I really can’t believe any 14B can’t be that good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4hdtd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I really can’t believe any 14B can’t be that good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4hdtd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744155488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mm67o56","id":"mm67o56","parent_id":"t1_mm585hv","depth":1,"children":["mm67o56"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm585hv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PhysicsPast8286","can_mod_post":false,"created_utc":1744164884,"send_replies":true,"parent_id":"t3_1juni3t","score":2,"author_fullname":"t2_1c2mqjxrgv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is Qwen Coder 2.5 32B Instruct still the best open source model for coding tasks? Please suggest your Open Source LLMs combos you guys are using for coding tasks..","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm585hv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is Qwen Coder 2.5 32B Instruct still the best open source model for coding tasks? Please suggest your Open Source LLMs combos you guys are using for coding tasks..&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm585hv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744164884,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4qprm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sythic_","can_mod_post":false,"created_utc":1744158743,"send_replies":true,"parent_id":"t3_1juni3t","score":3,"author_fullname":"t2_cvs52","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tried it and its completely useless, it writes paragraphs and paragraphs thinking about what I said instead of just doing it. These reasoning models that talk to themselves cant be the way.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4qprm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried it and its completely useless, it writes paragraphs and paragraphs thinking about what I said instead of just doing it. These reasoning models that talk to themselves cant be the way.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4qprm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744158743,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3naij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Illustrious-Lake2603","can_mod_post":false,"created_utc":1744145711,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_8v00ut7b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yess!! Christmas came early!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3naij","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yess!! Christmas came early!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3naij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744145711,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3tog4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"klop2031","can_mod_post":false,"created_utc":1744147626,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_a1p8p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I want to test this... seems dope","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3tog4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I want to test this... seems dope&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3tog4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744147626,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm76lzz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the_renaissance_jack","can_mod_post":false,"created_utc":1744201034,"send_replies":true,"parent_id":"t1_mm430g5","score":1,"author_fullname":"t2_2frr0ty","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Inside your IDE using Continue, Cline, Cursor, or Aider.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm76lzz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Inside your IDE using Continue, Cline, Cursor, or Aider.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm76lzz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744201034,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm430g5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xpnrt","can_mod_post":false,"created_utc":1744150614,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_oft9a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"what to use this with ? I mean koboldcpp or ollama probably would run it but where to use it for its coding ability ? for example for roleplaying we use sillytavern, is there a similar solution for coding ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm430g5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what to use this with ? I mean koboldcpp or ollama probably would run it but where to use it for its coding ability ? for example for roleplaying we use sillytavern, is there a similar solution for coding ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm430g5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744150614,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm502rr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lc19-","can_mod_post":false,"created_utc":1744162053,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_oszka6ke","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this model also trained on frontier Python/Javascript/Typescript libraries like Langchain/graph, Pydantic, Smolagents etc? Alternatively, what is the training cut-off date?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm502rr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this model also trained on frontier Python/Javascript/Typescript libraries like Langchain/graph, Pydantic, Smolagents etc? Alternatively, what is the training cut-off date?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm502rr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744162053,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm512xj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"felixding","can_mod_post":false,"created_utc":1744162409,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_46rdp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just tried the GGUFs. Too bad it needs 24GB RAM which doesn't fit into my 2080ti 22GB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm512xj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just tried the GGUFs. Too bad it needs 24GB RAM which doesn&amp;#39;t fit into my 2080ti 22GB.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm512xj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744162409,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6vdgp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"1982LikeABoss","can_mod_post":false,"created_utc":1744196085,"send_replies":true,"parent_id":"t1_mm5qfmv","score":1,"author_fullname":"t2_4n5bxnhq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Asking the same thing (RTX 3060)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6vdgp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Asking the same thing (RTX 3060)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6vdgp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744196085,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm5qfmv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Illustrious-Hold-480","can_mod_post":false,"created_utc":1744172222,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_76vz2v05","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How do I know the minimum VRAM for this model ?, is it possible with 12GB of VRAM ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm5qfmv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do I know the minimum VRAM for this model ?, is it possible with 12GB of VRAM ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm5qfmv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744172222,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"f1ee0406-72f3-11ee-a31d-3a87eb85541f","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6ic2i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nanowell","can_mod_post":false,"created_utc":1744188324,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_857aqduw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=2000&amp;format=pjpg&amp;auto=webp&amp;s=d01a1fdcd6ca308444f58a1fc1fef222600fb13b\\n\\nZooming out a bit and it's still impressive!\\n\\nAmazing release.\\n\\nSam Altman will have to release o4-mini level model at this point","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6ic2i","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Waiting for Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d01a1fdcd6ca308444f58a1fc1fef222600fb13b\\"&gt;https://preview.redd.it/imw0ygb8vrte1.jpeg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d01a1fdcd6ca308444f58a1fc1fef222600fb13b&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Zooming out a bit and it&amp;#39;s still impressive!&lt;/p&gt;\\n\\n&lt;p&gt;Amazing release.&lt;/p&gt;\\n\\n&lt;p&gt;Sam Altman will have to release o4-mini level model at this point&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6ic2i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744188324,"media_metadata":{"imw0ygb8vrte1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":75,"x":108,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a4a078891e3a51969787b2b2a7537c03a0352b4e"},{"y":151,"x":216,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=403c0d3f37ca4758dc428b4d9b80cb1b53a00e88"},{"y":224,"x":320,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=12e1194b1db25ae0c091ae52dcf52a842bbcfad9"},{"y":448,"x":640,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=91f7f4cb369a7c97b49e9ea8520a7447fba1fd88"},{"y":672,"x":960,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d6f8a1e9b84cb723056ff97a3790bece7fb065ac"},{"y":756,"x":1080,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f48a06b3a5e9015fa376fd8d413a344e860bfebd"}],"s":{"y":1400,"x":2000,"u":"https://preview.redd.it/imw0ygb8vrte1.jpeg?width=2000&amp;format=pjpg&amp;auto=webp&amp;s=d01a1fdcd6ca308444f58a1fc1fef222600fb13b"},"id":"imw0ygb8vrte1"}},"author_flair_text":"Waiting for Llama 3","treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6j5du","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SpoilerAvoidingAcct","can_mod_post":false,"created_utc":1744188852,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_8b6fu4zta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So when you say coder can I replicate something like Claude Code or Cursor that can actually open read and write files, or do I still need to basically copy paste in ollama?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6j5du","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So when you say coder can I replicate something like Claude Code or Cursor that can actually open read and write files, or do I still need to basically copy paste in ollama?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6j5du/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744188852,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6va0b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"1982LikeABoss","can_mod_post":false,"created_utc":1744196037,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_4n5bxnhq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any chance of squeezing this onto an RTX 3060?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6va0b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any chance of squeezing this onto an RTX 3060?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6va0b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744196037,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6xeqd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nmkd","can_mod_post":false,"created_utc":1744197079,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_rg6rx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"o3 mini above o1? wut","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm6xeqd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;o3 mini above o1? wut&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm6xeqd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744197079,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm70u7d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rootsyl","can_mod_post":false,"created_utc":1744198648,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_4qvdgg7g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why dont you make y axis start from 0? This plot is misleading.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm70u7d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why dont you make y axis start from 0? This plot is misleading.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm70u7d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744198648,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm70vg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Psychological_Box406","can_mod_post":false,"created_utc":1744198663,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_b1a4gdcm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In the coding arena I think that the target should be Claude 3.7 Thinking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm70vg8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In the coding arena I think that the target should be Claude 3.7 Thinking.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm70vg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744198663,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7df0i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"created_utc":1744203568,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_ehhvb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"But how does it handle context?  \\n\\nExample is qwen coder is great for straight code gen.  But when fed a sufficiently large database definition it falls apart on comprehension.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm7df0i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But how does it handle context?  &lt;/p&gt;\\n\\n&lt;p&gt;Example is qwen coder is great for straight code gen.  But when fed a sufficiently large database definition it falls apart on comprehension.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7df0i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744203568,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm7j9u1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MrWeirdoFace","can_mod_post":false,"created_utc":1744205595,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_12e249","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As someone who's never bothered with previews before, how do they tend to differ from their actual release?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm7j9u1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As someone who&amp;#39;s never bothered with previews before, how do they tend to differ from their actual release?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm7j9u1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744205595,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm9fzyp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mm9euwg","score":2,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is around Qwen 2.5 14b coder level, same mistakes, same performance.  \\nThere is just no way that 14b can be compared to 671b, don't trust numbers,  \\nrun your own tests, always.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm9fzyp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is around Qwen 2.5 14b coder level, same mistakes, same performance.&lt;br/&gt;\\nThere is just no way that 14b can be compared to 671b, don&amp;#39;t trust numbers,&lt;br/&gt;\\nrun your own tests, always.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9fzyp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744225840,"author_flair_text":null,"treatment_tags":[],"created_utc":1744225840,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mm9euwg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1744225503,"send_replies":true,"parent_id":"t1_mm9dsi1","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9euwg/","num_reports":null,"locked":false,"name":"t1_mm9euwg","created":1744225503,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mm9dsi1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"created_utc":1744225185,"send_replies":true,"parent_id":"t1_mm99x20","score":1,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol, \\"compare\\", nice one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm9dsi1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol, &amp;quot;compare&amp;quot;, nice one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm9dsi1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744225185,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mm99x20","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm99x20/","num_reports":null,"locked":false,"name":"t1_mm99x20","created":1744224057,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744224057,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmagcav","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hyma","can_mod_post":false,"created_utc":1744236795,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_2s1ae","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Support for cline/roo or copilot?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmagcav","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Support for cline/roo or copilot?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmagcav/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744236795,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmayu1i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Super-Cool-Seaweed","can_mod_post":false,"created_utc":1744243170,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_v6ycww60","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Which programming languages is it covering?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmayu1i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which programming languages is it covering?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmayu1i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744243170,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmdvjn7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"L3Niflheim","can_mod_post":false,"created_utc":1744291823,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_dr7y0h07","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I found it very good for a 14B model from my biased testing. The bigger models do seem to have a big edge though. A decent release just not challenging the leaders as much as this lovel chart would suggest. Insane progress from a couple of years ago though.\\n\\nJust my humble opinion based on my own testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmdvjn7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I found it very good for a 14B model from my biased testing. The bigger models do seem to have a big edge though. A decent release just not challenging the leaders as much as this lovel chart would suggest. Insane progress from a couple of years ago though.&lt;/p&gt;\\n\\n&lt;p&gt;Just my humble opinion based on my own testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmdvjn7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744291823,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmrxqy0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustABro_2321","can_mod_post":false,"created_utc":1744483580,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_1b5t660qi8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would this be called pareto efficient? (Asking genuinely, since Idk)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmrxqy0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would this be called pareto efficient? (Asking genuinely, since Idk)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmrxqy0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744483580,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmuw1om","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bunny_go","can_mod_post":false,"created_utc":1744525993,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_42kidq6u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pure trash. Asked to write a simple function, was thinking for 90 seconds, exhausted all output context but came up with nothing usable.\\n\\nInto the bin it goes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mmuw1om","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pure trash. Asked to write a simple function, was thinking for 90 seconds, exhausted all output context but came up with nothing usable.&lt;/p&gt;\\n\\n&lt;p&gt;Into the bin it goes&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mmuw1om/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744525993,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mn9bdej","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Punjsher2096","can_mod_post":false,"created_utc":1744734965,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_5ckzo43w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't there any app that can suggest which model  this device can run? Like I do have ROG clocking with Processor: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, RAM: 16.0 GB. Not sure which models are best for my device.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mn9bdej","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t there any app that can suggest which model  this device can run? Like I do have ROG clocking with Processor: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, RAM: 16.0 GB. Not sure which models are best for my device.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mn9bdej/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744734965,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mnonguc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"regs01","can_mod_post":false,"created_utc":1744937706,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_52gg4zm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"14b version can't do even simple text formatting","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mnonguc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;14b version can&amp;#39;t do even simple text formatting&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mnonguc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744937706,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"moxws1n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FoxFire17739","can_mod_post":false,"created_utc":1745573271,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_3o7mxn2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I just tried deepcoder within VS Code with the Continue plugin and it completely refuses to look even at my files and expects me to copy paste it into the chat. Like completely unusable.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_moxws1n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just tried deepcoder within VS Code with the Continue plugin and it completely refuses to look even at my files and expects me to copy paste it into the chat. Like completely unusable.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/moxws1n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745573271,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mp0iid7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"beedunc","can_mod_post":false,"created_utc":1745605698,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_18op7raw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it normal for this model (in q\\\\_8 form) to just blab on and on and on about what it wants to do? What's the secret to get him to just shut up and code?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mp0iid7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it normal for this model (in q_8 form) to just blab on and on and on about what it wants to do? What&amp;#39;s the secret to get him to just shut up and code?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mp0iid7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745605698,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm44xqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Stepfunction","can_mod_post":false,"created_utc":1744151261,"send_replies":true,"parent_id":"t1_mm3zpv0","score":11,"author_fullname":"t2_sxigq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably FP32 weights, so 4 bytes per weight \\\\* 14B weights \\\\~ 56GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm44xqk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably FP32 weights, so 4 bytes per weight * 14B weights ~ 56GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1juni3t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm44xqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151261,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":1,"name":"t1_mm55duu","id":"mm55duu","parent_id":"t1_mm3zpv0","depth":1,"children":["mm55duu"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mm3zpv0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KadahCoba","can_mod_post":false,"created_utc":1744149526,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_ayk85","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; 14B\\n\\n&gt; model is almost 60GB\\n\\nI think I'm missing something, this is only slightly smaller than Qwen2.5 32B coder.\\n\\nEdit: FP32","edited":1744168943,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm3zpv0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;14B&lt;/p&gt;\\n\\n&lt;p&gt;model is almost 60GB&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I think I&amp;#39;m missing something, this is only slightly smaller than Qwen2.5 32B coder.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: FP32&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3zpv0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744149526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm44mja","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"created_utc":1744151156,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_on5es7pe3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"wtf is that graph","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm44mja","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;wtf is that graph&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm44mja/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744151156,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm4rl05","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"saosebastiao","can_mod_post":false,"created_utc":1744159050,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_7dsbk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Any insights into how much benchmark hacking has been done?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm4rl05","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Any insights into how much benchmark hacking has been done?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm4rl05/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744159050,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm62ndi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Su1tz","can_mod_post":false,"created_utc":1744178454,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"author_fullname":"t2_tupznx19","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"X to doubt. Until further evidence is presented of course!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mm62ndi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;X to doubt. Until further evidence is presented of course!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm62ndi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744178454,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1juni3t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":1,"removal_reason":null,"link_id":"t3_1juni3t","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm3n46e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1juni3t","score":1,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"LOVE TO SEE IT! \\n\\nGIVE MORE","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LOVE TO SEE IT! &lt;/p&gt;\\n\\n&lt;p&gt;GIVE MORE&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1juni3t/deepcoder_a_fully_opensource_14b_coder_at_o3mini/mm3n46e/","num_reports":null,"locked":false,"name":"t1_mm3n46e","created":1744145662,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1744145662,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":13,"name":"t1_mm3qggd","id":"mm3qggd","parent_id":"t3_1juni3t","depth":0,"children":["mm3qggd","mm3v4wn","mmawk2v","mm3lobl","mm53ygr","mm3v948","mm3zjre"]}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
