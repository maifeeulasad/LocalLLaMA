import{j as e}from"./index-cvG704yx.js";import{R as t}from"./RedditPostRenderer-CBthLTAH.js";import"./index-D-GavSZU.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"The thought progress bar looks cool.\\n\\nUnfortunately, this needs to train something to modify hidden state.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"[PAPER] Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path Lengths in LLMs","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ltstdt","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.85,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_g644e","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"default","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":false,"mod_note":null,"created":1751891156,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"royeisen.github.io","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;The thought progress bar looks cool.&lt;/p&gt;\\n\\n&lt;p&gt;Unfortunately, this needs to train something to modify hidden state.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://royeisen.github.io/OverclockingLLMReasoning-paper/","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1ltstdt","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"foldl-li","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ltstdt/paper_overclocking_llm_reasoning_monitoring_and/","stickied":false,"url":"https://royeisen.github.io/OverclockingLLMReasoning-paper/","subreddit_subscribers":496034,"created_utc":1751891156,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1v86b2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1uzvy0","score":5,"author_fullname":"t2_k7w2h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Things that were once thought impossible are often proven otherwise, given enough time\\n\\nThe [halting problem](https://en.wikipedia.org/wiki/Halting_problem), due to which the amount of thinking tokens cannot accurately be predicted, is fairly persistent in that regard.\\n\\nIt would've been nice if the paper also had a graph with predicted number of tokens on X and actual number of tokens on Y to assess the quality of the predictions. If predictions were perfect then there'd be a straight line. If someone were to do that benchmark then the dots will be all over the place, but we might see some correlation - more dots near the line, as an approximation seems possible.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1v86b2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Things that were once thought impossible are often proven otherwise, given enough time&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The &lt;a href=\\"https://en.wikipedia.org/wiki/Halting_problem\\"&gt;halting problem&lt;/a&gt;, due to which the amount of thinking tokens cannot accurately be predicted, is fairly persistent in that regard.&lt;/p&gt;\\n\\n&lt;p&gt;It would&amp;#39;ve been nice if the paper also had a graph with predicted number of tokens on X and actual number of tokens on Y to assess the quality of the predictions. If predictions were perfect then there&amp;#39;d be a straight line. If someone were to do that benchmark then the dots will be all over the place, but we might see some correlation - more dots near the line, as an approximation seems possible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltstdt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltstdt/paper_overclocking_llm_reasoning_monitoring_and/n1v86b2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751919917,"author_flair_text":null,"treatment_tags":[],"created_utc":1751919917,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n1uzvy0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"teleprint-me","can_mod_post":false,"created_utc":1751917188,"send_replies":true,"parent_id":"t1_n1sq2uc","score":2,"author_fullname":"t2_slcrtxpr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No measurement of progress is perfect. Yet, we still use them because they're useful as an estimate.\\n\\n\\nThey're already doing it, so obviously it is not impossible to get an estimate on progress.\\n\\n\\nThings that were once thought impossible are often proven otherwise, given enough time. LLMs are proof of that in and of themselves.\\n\\n\\nPerfection is the enemy of progress.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uzvy0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No measurement of progress is perfect. Yet, we still use them because they&amp;#39;re useful as an estimate.&lt;/p&gt;\\n\\n&lt;p&gt;They&amp;#39;re already doing it, so obviously it is not impossible to get an estimate on progress.&lt;/p&gt;\\n\\n&lt;p&gt;Things that were once thought impossible are often proven otherwise, given enough time. LLMs are proof of that in and of themselves.&lt;/p&gt;\\n\\n&lt;p&gt;Perfection is the enemy of progress.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltstdt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltstdt/paper_overclocking_llm_reasoning_monitoring_and/n1uzvy0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751917188,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1vc0xi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"created_utc":1751921197,"send_replies":true,"parent_id":"t1_n1sq2uc","score":2,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’m pretty sure estimating reasoning is equivalent to the halting problem lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1vc0xi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m pretty sure estimating reasoning is equivalent to the halting problem lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ltstdt","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltstdt/paper_overclocking_llm_reasoning_monitoring_and/n1vc0xi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751921197,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1sq2uc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1751891752,"send_replies":true,"parent_id":"t3_1ltstdt","score":7,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Predicting how long the LLM will reason for until it found an answer is not possible, at least not accurately. Windows doesn't even get it right in simple cases with the progress bars stuck at 99%. The third \\"Reasoning loading bar\\" example nicely shows how the progress gets slower and slower as reasoning continues.\\n\\n&gt;we manipulate the internal progress encoding during inference to reduce unnecessary steps\\n\\nIt's also not possible to decide ahead of time whether or not specific reasoning tokens will lead to an (in)correct result.\\n\\nThe tests were exclusively done on math benchmarks. Maybe it's possible to shave off some tokens there without much loss. I doubt that this will generalize as-is though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1sq2uc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Predicting how long the LLM will reason for until it found an answer is not possible, at least not accurately. Windows doesn&amp;#39;t even get it right in simple cases with the progress bars stuck at 99%. The third &amp;quot;Reasoning loading bar&amp;quot; example nicely shows how the progress gets slower and slower as reasoning continues.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;we manipulate the internal progress encoding during inference to reduce unnecessary steps&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s also not possible to decide ahead of time whether or not specific reasoning tokens will lead to an (in)correct result.&lt;/p&gt;\\n\\n&lt;p&gt;The tests were exclusively done on math benchmarks. Maybe it&amp;#39;s possible to shave off some tokens there without much loss. I doubt that this will generalize as-is though.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ltstdt/paper_overclocking_llm_reasoning_monitoring_and/n1sq2uc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751891752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ltstdt","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}}]`),s=()=>e.jsx(t,{data:l});export{s as default};
