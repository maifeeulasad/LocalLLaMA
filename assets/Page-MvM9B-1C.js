import{j as e}from"./index-BOnf-UhU.js";import{R as a}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"https://preview.redd.it/4ylsxlbm0oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=7651eb28c5f9703cee17fa9fe2a66f6b575f5a05\\n\\nTrying to perform CPT of llama on a new language (Language is similar to Hindi, hence some tokens already present). The model's validation loss seems to plateau very early on into the training. Here 1 epoch is around 6k steps and validation loss seems to already be lowest at step 750. \\n\\n  \\nMy dataset is around 100k size. Im using Lora as well\\n\\nhttps://preview.redd.it/17g8r8161oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=787998b7dc36f0ea474bfd988a17ba7527b6937b\\n\\nHere are my training arguments\\n\\nhttps://preview.redd.it/zpu2yhq81oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=e2aa754c023801a568a24bdf5b0d4cea92494fce\\n\\nIve tried different arangement, like more r value, embed\\\\_head and lm\\\\_head added onto the modules, different leaerning rates, etc. But similar trend in validation loss, either its around this range or around the range of 1.59-1.60. \\n\\nhttps://preview.redd.it/biejsj3k1oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=68c1fdd74b5fb72da5198132c7a1f821ba6f858e\\n\\nMoreover, Ive also tried mistral-7b-v0.1, same issues.   \\n\\n\\nI thought it might be because the model is not able to learn because of less tokens, so tried vocab expansion, but same issues. \\n\\nWhat else could i try? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Continued pretraining of Llama 3-8b on a new language","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":39,"top_awarded_type":null,"hide_score":false,"media_metadata":{"4ylsxlbm0oef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":30,"x":108,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=88d57c1c26304386dc9643324410f7e924da02bf"},{"y":60,"x":216,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1829acd222438fd79d036ad146b40b99ed5e2274"},{"y":89,"x":320,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b5df9c08b52e96caaddffb6c7613b44d87296bc"},{"y":179,"x":640,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ff99b39523472a17ac34ee8ca73989f1e306fc8"},{"y":268,"x":960,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e8eea30c92d9761f2b85fdaedbeed3a68f9d2b43"},{"y":302,"x":1080,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f98d1b9f94bb67261e57f64684fdd610ffc31344"}],"s":{"y":668,"x":2386,"u":"https://preview.redd.it/4ylsxlbm0oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=7651eb28c5f9703cee17fa9fe2a66f6b575f5a05"},"id":"4ylsxlbm0oef1"},"zpu2yhq81oef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":59,"x":108,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=10939db7873d0be79d7a8902fa93e3c456528b07"},{"y":118,"x":216,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b060d6c331f5ba2303cdf2a7cbfa6a2362b7238"},{"y":174,"x":320,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e26b1f28756de8bc058ab7e363e19aebc60aa1e8"},{"y":349,"x":640,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=60d1e35982d5c449da7df39ae91617d4d73624a3"},{"y":524,"x":960,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0772385bb0d1c46ae8b7154c304493d97380e064"},{"y":590,"x":1080,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b3a54755e23fb71bd2b288a307e643718c932448"}],"s":{"y":1304,"x":2386,"u":"https://preview.redd.it/zpu2yhq81oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=e2aa754c023801a568a24bdf5b0d4cea92494fce"},"id":"zpu2yhq81oef1"},"biejsj3k1oef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":38,"x":108,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49e6f3d108dd2ba89333fa2a8522d3e1b1bddfe9"},{"y":77,"x":216,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f65fbb40cdc0b8c2acefaf73b7c2025e036264e"},{"y":115,"x":320,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04c9f49be579eff990a61f01049f14292def3782"},{"y":230,"x":640,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0e3a6b6cf914943e647acdce7522cea4ebedb85f"},{"y":345,"x":960,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=be9343fefcfdc69e0dc7f570673c516a0fccf602"},{"y":388,"x":1080,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a9b3d48af5bf4011bf7f028eae9d7bbaef55e036"}],"s":{"y":858,"x":2386,"u":"https://preview.redd.it/biejsj3k1oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=68c1fdd74b5fb72da5198132c7a1f821ba6f858e"},"id":"biejsj3k1oef1"},"17g8r8161oef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":15,"x":108,"u":"https://preview.redd.it/17g8r8161oef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=da35b4fc251de49bbc6f7d64063b55761b11dac7"},{"y":31,"x":216,"u":"https://preview.redd.it/17g8r8161oef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b99758d0eab4b7ae5fff716c23661e6ca93d03e5"},{"y":46,"x":320,"u":"https://preview.redd.it/17g8r8161oef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9412d4a0c0e4657c087ba28bca26ec858a607d3d"},{"y":92,"x":640,"u":"https://preview.redd.it/17g8r8161oef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2a85d234a554d7dfbb6cead09a4b74044436d4c"},{"y":138,"x":960,"u":"https://preview.redd.it/17g8r8161oef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d64bdc00a6a46ba8b1dc68e17472b1bb48de3949"},{"y":155,"x":1080,"u":"https://preview.redd.it/17g8r8161oef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=259de3da3401fc95891509dde196e1c8402eca51"}],"s":{"y":344,"x":2386,"u":"https://preview.redd.it/17g8r8161oef1.png?width=2386&amp;format=png&amp;auto=webp&amp;s=787998b7dc36f0ea474bfd988a17ba7527b6937b"},"id":"17g8r8161oef1"}},"name":"t3_1m7gwuo","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.93,"author_flair_background_color":null,"subreddit_type":"public","ups":13,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_ilp0f96k","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":13,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/ugVEN4UtFCv8Wx60MSKJhHoUDDHJb5lYNs6MP2_hSKg.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753294914,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/4ylsxlbm0oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7651eb28c5f9703cee17fa9fe2a66f6b575f5a05\\"&gt;https://preview.redd.it/4ylsxlbm0oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7651eb28c5f9703cee17fa9fe2a66f6b575f5a05&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Trying to perform CPT of llama on a new language (Language is similar to Hindi, hence some tokens already present). The model&amp;#39;s validation loss seems to plateau very early on into the training. Here 1 epoch is around 6k steps and validation loss seems to already be lowest at step 750. &lt;/p&gt;\\n\\n&lt;p&gt;My dataset is around 100k size. Im using Lora as well&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/17g8r8161oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=787998b7dc36f0ea474bfd988a17ba7527b6937b\\"&gt;https://preview.redd.it/17g8r8161oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=787998b7dc36f0ea474bfd988a17ba7527b6937b&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Here are my training arguments&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/zpu2yhq81oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2aa754c023801a568a24bdf5b0d4cea92494fce\\"&gt;https://preview.redd.it/zpu2yhq81oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2aa754c023801a568a24bdf5b0d4cea92494fce&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Ive tried different arangement, like more r value, embed_head and lm_head added onto the modules, different leaerning rates, etc. But similar trend in validation loss, either its around this range or around the range of 1.59-1.60. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/biejsj3k1oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68c1fdd74b5fb72da5198132c7a1f821ba6f858e\\"&gt;https://preview.redd.it/biejsj3k1oef1.png?width=2386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68c1fdd74b5fb72da5198132c7a1f821ba6f858e&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Moreover, Ive also tried mistral-7b-v0.1, same issues.   &lt;/p&gt;\\n\\n&lt;p&gt;I thought it might be because the model is not able to learn because of less tokens, so tried vocab expansion, but same issues. &lt;/p&gt;\\n\\n&lt;p&gt;What else could i try? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m7gwuo","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Awkward-Quiet5795","discussion_type":null,"num_comments":15,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/","subreddit_subscribers":503518,"created_utc":1753294914,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4s1gf7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1753302374,"send_replies":true,"parent_id":"t1_n4rfjlz","score":2,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For large rank, I think you also need to use rslora or else the effective rank of the lora will be abysmal. On the Discord, I believe an Unsloth member recommended r=256 for CPT but left it at 128 for demonstration in the notebook.\\n\\n\\nYou shouldn't go to crazy high numbers as the model will begin to suffer from catastrophic forgetting with the Lora memorizing everything rather than generalizing. \\n\\n\\nhttps://arxiv.org/html/2410.21228v1","edited":1753302649,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4s1gf7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For large rank, I think you also need to use rslora or else the effective rank of the lora will be abysmal. On the Discord, I believe an Unsloth member recommended r=256 for CPT but left it at 128 for demonstration in the notebook.&lt;/p&gt;\\n\\n&lt;p&gt;You shouldn&amp;#39;t go to crazy high numbers as the model will begin to suffer from catastrophic forgetting with the Lora memorizing everything rather than generalizing. &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/html/2410.21228v1\\"&gt;https://arxiv.org/html/2410.21228v1&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4s1gf7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753302374,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4t83pk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Appearance3584","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sjblp","score":1,"author_fullname":"t2_oyxj85n1","approved_by":null,"mod_note":null,"all_awardings":[],"body":"That was actually clever twitter prompt context injection","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4t83pk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That was actually clever twitter prompt context injection&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m7gwuo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4t83pk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753315563,"author_flair_text":null,"treatment_tags":[],"created_utc":1753315563,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sjblp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FriendlyUser_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ruu7z","score":1,"author_fullname":"t2_1papeut323","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"perhaps this is how they did mechhitler","edited":false,"author_flair_css_class":null,"name":"t1_n4sjblp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;perhaps this is how they did mechhitler&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m7gwuo","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4sjblp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753307539,"author_flair_text":null,"collapsed":false,"created_utc":1753307539,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ruu7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Appearance3584","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rgcx4","score":1,"author_fullname":"t2_oyxj85n1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Rule of thumb, alpha should be 2x rank parameter (r), so 128 in your case.\\n\\n\\nAs another rule of thumb, rank 32 is for trivial finetuning (like different conversational tone and a little bit of general information and context about your company or whatever). Think generic, simple customer support.\\n\\n\\n64 is for a little bit deeper knowledge, like learning a small codebase and code style and so on.\\n\\n\\n128 is for a bit deeper domain knowledge, like reading research papers.\\n\\n\\nOver 128 not usually recommended but my experience states that up to 2048 can work for almost complete replacement of the base model behavior. I don't know if it's enough to learn a new language but it can improve the performance of a poorly performing language it already knows.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ruu7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Rule of thumb, alpha should be 2x rank parameter (r), so 128 in your case.&lt;/p&gt;\\n\\n&lt;p&gt;As another rule of thumb, rank 32 is for trivial finetuning (like different conversational tone and a little bit of general information and context about your company or whatever). Think generic, simple customer support.&lt;/p&gt;\\n\\n&lt;p&gt;64 is for a little bit deeper knowledge, like learning a small codebase and code style and so on.&lt;/p&gt;\\n\\n&lt;p&gt;128 is for a bit deeper domain knowledge, like reading research papers.&lt;/p&gt;\\n\\n&lt;p&gt;Over 128 not usually recommended but my experience states that up to 2048 can work for almost complete replacement of the base model behavior. I don&amp;#39;t know if it&amp;#39;s enough to learn a new language but it can improve the performance of a poorly performing language it already knows.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4ruu7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753300534,"author_flair_text":null,"treatment_tags":[],"created_utc":1753300534,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rgcx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awkward-Quiet5795","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rg7u2","score":1,"author_fullname":"t2_ilp0f96k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/5lp3f6ff6oef1.png?width=1064&amp;format=png&amp;auto=webp&amp;s=9b9259aa596b0aa0abde23e733745be8b637a272\\n\\nr=64, alpha=64","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4rgcx4","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5lp3f6ff6oef1.png?width=1064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b9259aa596b0aa0abde23e733745be8b637a272\\"&gt;https://preview.redd.it/5lp3f6ff6oef1.png?width=1064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9b9259aa596b0aa0abde23e733745be8b637a272&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;r=64, alpha=64&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rgcx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753296429,"media_metadata":{"5lp3f6ff6oef1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":29,"x":108,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a80670067c03d262cd1ed3bc3edb1bce526e8a51"},{"y":59,"x":216,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=664e84ffe32892cbbe110613ecb38f719e2ab8b5"},{"y":88,"x":320,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7c8d43927b79a3293e919e712885b292616cc7b"},{"y":176,"x":640,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=48d717fc4f8d3a51104f7ac5b664c7768b7aeaa3"},{"y":265,"x":960,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=94612296afbeb2cdedc5b1ba52e19d177dd0203b"}],"s":{"y":294,"x":1064,"u":"https://preview.redd.it/5lp3f6ff6oef1.png?width=1064&amp;format=png&amp;auto=webp&amp;s=9b9259aa596b0aa0abde23e733745be8b637a272"},"id":"5lp3f6ff6oef1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1753296429,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rg7u2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awkward-Quiet5795","can_mod_post":false,"created_utc":1753296389,"send_replies":true,"parent_id":"t1_n4rfjlz","score":1,"author_fullname":"t2_ilp0f96k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"hmm, im on google colab pro, dont have gpus for r values that high. Tried 64 and alpha, but no increase in performance. I get 64 might not be enough but shouldn't it be doing better than 32?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rg7u2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hmm, im on google colab pro, dont have gpus for r values that high. Tried 64 and alpha, but no increase in performance. I get 64 might not be enough but shouldn&amp;#39;t it be doing better than 32?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rg7u2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753296389,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4s6fp3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Final_Wheel_7486","can_mod_post":false,"created_utc":1753303772,"send_replies":true,"parent_id":"t1_n4rfjlz","score":1,"author_fullname":"t2_cyrs5dhp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Okay, 1024 is too much from my experience. You can already get highly meaningful results with r = 256.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4s6fp3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay, 1024 is too much from my experience. You can already get highly meaningful results with r = 256.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4s6fp3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753303772,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rfjlz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Appearance3584","can_mod_post":false,"created_utc":1753296203,"send_replies":true,"parent_id":"t3_1m7gwuo","score":3,"author_fullname":"t2_oyxj85n1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Your r is abysmally small, it's not going to be enough to learn a new language. Try setting r to min 128, maybe try 256, 512, even 1024. Alpha should be min 2x r\\n\\n\\nIf 1024 doesn't seem to cut it, you're going to have to go full finetuning.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rfjlz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your r is abysmally small, it&amp;#39;s not going to be enough to learn a new language. Try setting r to min 128, maybe try 256, 512, even 1024. Alpha should be min 2x r&lt;/p&gt;\\n\\n&lt;p&gt;If 1024 doesn&amp;#39;t seem to cut it, you&amp;#39;re going to have to go full finetuning.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rfjlz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753296203,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7gwuo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rbhhz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awkward-Quiet5795","can_mod_post":false,"created_utc":1753295077,"send_replies":true,"parent_id":"t3_1m7gwuo","score":1,"author_fullname":"t2_ilp0f96k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Btw ive loaded the model in 4-bit","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rbhhz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Btw ive loaded the model in 4-bit&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rbhhz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753295077,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7gwuo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4sdz16","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Azuriteh","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4rq49h","score":2,"author_fullname":"t2_wmv41","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"From my own experience in fine-tuning LLMs on less-known languages (nahuatl in my case)... you need full fine-tuning, there's no way around it, eventually you'll start finding diminishing results in increasing the LoRa alpha and the time it takes to train.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4sdz16","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From my own experience in fine-tuning LLMs on less-known languages (nahuatl in my case)... you need full fine-tuning, there&amp;#39;s no way around it, eventually you&amp;#39;ll start finding diminishing results in increasing the LoRa alpha and the time it takes to train.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4sdz16/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753305933,"author_flair_text":null,"treatment_tags":[],"created_utc":1753305933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rq49h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awkward-Quiet5795","can_mod_post":false,"created_utc":1753299181,"send_replies":true,"parent_id":"t1_n4rouu5","score":2,"author_fullname":"t2_ilp0f96k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its an Indian tribal language, Spoken in maharashtra/gujarat side","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rq49h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its an Indian tribal language, Spoken in maharashtra/gujarat side&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rq49h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299181,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rouu5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"disillusioned_okapi","can_mod_post":false,"created_utc":1753298818,"send_replies":true,"parent_id":"t3_1m7gwuo","score":1,"author_fullname":"t2_wy3w8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"just out of curiosity, what language is that?\\n\\n\\nif it's a western-hindi predecessor like braj, bundeli, or awadhi, I'd love to learn more about what you are doing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rouu5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just out of curiosity, what language is that?&lt;/p&gt;\\n\\n&lt;p&gt;if it&amp;#39;s a western-hindi predecessor like braj, bundeli, or awadhi, I&amp;#39;d love to learn more about what you are doing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rouu5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753298818,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7gwuo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rpsae","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awkward-Quiet5795","can_mod_post":false,"created_utc":1753299086,"send_replies":true,"parent_id":"t1_n4rphw5","score":1,"author_fullname":"t2_ilp0f96k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That does make sense, but the model is not even completing 1 epoch before validation loss plateauing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rpsae","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That does make sense, but the model is not even completing 1 epoch before validation loss plateauing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7gwuo","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rpsae/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299086,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4rphw5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Needleworker_5247","can_mod_post":false,"created_utc":1753299002,"send_replies":true,"parent_id":"t3_1m7gwuo","score":1,"author_fullname":"t2_1gmprv51a1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"With such a small dataset, you're likely hitting a data bottleneck. You could try data augmentation techniques or unsupervised pretraining on a larger, similar corpus to enrich the training dataset. Also, monitoring early stopping and tuning weight decay could help stabilize training.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rphw5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;With such a small dataset, you&amp;#39;re likely hitting a data bottleneck. You could try data augmentation techniques or unsupervised pretraining on a larger, similar corpus to enrich the training dataset. Also, monitoring early stopping and tuning weight decay could help stabilize training.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rphw5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299002,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7gwuo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4rr4br","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"THEKILLFUS","can_mod_post":false,"created_utc":1753299472,"send_replies":true,"parent_id":"t3_1m7gwuo","score":1,"author_fullname":"t2_gz0msp9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://www.reddit.com/r/LocalLLaMA/s/uUIKCOTYHc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4rr4br","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/s/uUIKCOTYHc\\"&gt;https://www.reddit.com/r/LocalLLaMA/s/uUIKCOTYHc&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7gwuo/continued_pretraining_of_llama_38b_on_a_new/n4rr4br/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753299472,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7gwuo","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(a,{data:t});export{o as default};
