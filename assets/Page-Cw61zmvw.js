import{j as e}from"./index-F0NXdzZX.js";import{R as t}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"T5Gemma released a new encoder-decoder model.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"T5Gemma: A new collection of encoder-decoder Gemma models- Google Developers Blog","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1m16kdm","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.83,"author_flair_background_color":null,"ups":29,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_8jqx3m14","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":29,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=cf3e921e188ce52410c6810f28f99be1a091917a","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752651989,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"developers.googleblog.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;T5Gemma released a new encoder-decoder model.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://developers.googleblog.com/en/t5gemma/","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?auto=webp&amp;s=be53d214730046f4f70ef325e842c4f096c3e4a1","width":860,"height":430},"resolutions":[{"url":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=72b5316e353260b40cfddbb1814bf1be5854d7c9","width":108,"height":54},{"url":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec7568e111028071d64de2a43a06cb4ebc2bc70a","width":216,"height":108},{"url":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=80e400a3214a3712b67659f8c646e9780ab343cd","width":320,"height":160},{"url":"https://external-preview.redd.it/Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbbccb5f228138b777b853e12fc432178fff5f50","width":640,"height":320}],"variants":{},"id":"Ua_6ve9KH9QIRkyagh-mJMhThsokU2TkQCZbS7Cxv8k"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m16kdm","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"DeltaSqueezer","discussion_type":null,"num_comments":6,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/","stickied":false,"url":"https://developers.googleblog.com/en/t5gemma/","subreddit_subscribers":499773,"created_utc":1752651989,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3feqo4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3f8exv","score":1,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's definitely interesting.   I'm not sure it improves normal text gen use cases - but they cited that it did improve \\"safety\\" and control methods.   Wondering what other unique use cases it might serve.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3feqo4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s definitely interesting.   I&amp;#39;m not sure it improves normal text gen use cases - but they cited that it did improve &amp;quot;safety&amp;quot; and control methods.   Wondering what other unique use cases it might serve.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m16kdm","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3feqo4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752665064,"author_flair_text":null,"treatment_tags":[],"created_utc":1752665064,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3f8exv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3f5p80","score":9,"author_fullname":"t2_8jqx3m14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Plus the encoder can in theory create better representations as tokens can attend to future tokens and not just past tokens.\\n\\nDecoder-only architectures 'won' text generation so it is interesting to see enc-dec architectures making a comeback.","edited":1752666171,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3f8exv","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Plus the encoder can in theory create better representations as tokens can attend to future tokens and not just past tokens.&lt;/p&gt;\\n\\n&lt;p&gt;Decoder-only architectures &amp;#39;won&amp;#39; text generation so it is interesting to see enc-dec architectures making a comeback.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m16kdm","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3f8exv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752662109,"author_flair_text":null,"treatment_tags":[],"created_utc":1752662109,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n3f5p80","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"QuackerEnte","can_mod_post":false,"created_utc":1752660683,"send_replies":true,"parent_id":"t1_n3et72e","score":13,"author_fullname":"t2_7trrxhjl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As far as I understood it, it has a (e.g.) 9B encoder and a 9B decoder part. \\n\\nThe decoder works the same as ever before, and the encoder takes an input and \\"reads\\" it once. It's a heavy, one-time-cost operation. It produces a compact REPRESENTATION of the inputs meaning (e.g. a set of 512 summary vectors).\\n\\nNow the 9B decoder's job is easier, it DOESN'T NEED to attend to the original input of e. g. a text of 100k tokens. It only works with the 512-vector summary from the encoder.\\n\\nSo I think the main advantage is context length here!!\\n\\nEdit: under the same compute/memory budget, that is.","edited":1752661211,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3f5p80","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As far as I understood it, it has a (e.g.) 9B encoder and a 9B decoder part. &lt;/p&gt;\\n\\n&lt;p&gt;The decoder works the same as ever before, and the encoder takes an input and &amp;quot;reads&amp;quot; it once. It&amp;#39;s a heavy, one-time-cost operation. It produces a compact REPRESENTATION of the inputs meaning (e.g. a set of 512 summary vectors).&lt;/p&gt;\\n\\n&lt;p&gt;Now the 9B decoder&amp;#39;s job is easier, it DOESN&amp;#39;T NEED to attend to the original input of e. g. a text of 100k tokens. It only works with the 512-vector summary from the encoder.&lt;/p&gt;\\n\\n&lt;p&gt;So I think the main advantage is context length here!!&lt;/p&gt;\\n\\n&lt;p&gt;Edit: under the same compute/memory budget, that is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m16kdm","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3f5p80/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752660683,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n3et72e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Appearance3584","can_mod_post":false,"created_utc":1752653491,"send_replies":true,"parent_id":"t3_1m16kdm","score":12,"author_fullname":"t2_oyxj85n1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone spell out for me why encoder-decoder would make any difference to decoder-only? I don't understand conceptually what difference this makes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3et72e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone spell out for me why encoder-decoder would make any difference to decoder-only? I don&amp;#39;t understand conceptually what difference this makes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3et72e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752653491,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16kdm","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fd8gi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dazz9","can_mod_post":false,"created_utc":1752664398,"send_replies":true,"parent_id":"t3_1m16kdm","score":4,"author_fullname":"t2_4q7j68j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gguf when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fd8gi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gguf when?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3fd8gi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752664398,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16kdm","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3fer2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752665069,"send_replies":true,"parent_id":"t3_1m16kdm","score":2,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"has anyone already tried to extract the encoder and tune it as sentence transformer?\\n\\nI see a trend of using large models like mistral 7B and qwen 8B as sentence transformers, but this is suboptimal since they are decoder only models trained for an autoregressive task. also, since they are autoregressive, the attention use a causal mask that make the model unidirectional, and it is proven that to generate embeddings bidirectionality is really useful. \\n\\nmaybe this can 'feel the gap' (as there is no encoder only models bigger than ~3B as far I know)\\n\\n\\nbtw, I'm really happy they released this model.\\nDecoder-only are really popular right now, but they are not 'better' in any possible way compared to other 'arrangements' of the transformer architecture","edited":1752665423,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3fer2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;has anyone already tried to extract the encoder and tune it as sentence transformer?&lt;/p&gt;\\n\\n&lt;p&gt;I see a trend of using large models like mistral 7B and qwen 8B as sentence transformers, but this is suboptimal since they are decoder only models trained for an autoregressive task. also, since they are autoregressive, the attention use a causal mask that make the model unidirectional, and it is proven that to generate embeddings bidirectionality is really useful. &lt;/p&gt;\\n\\n&lt;p&gt;maybe this can &amp;#39;feel the gap&amp;#39; (as there is no encoder only models bigger than ~3B as far I know)&lt;/p&gt;\\n\\n&lt;p&gt;btw, I&amp;#39;m really happy they released this model.\\nDecoder-only are really popular right now, but they are not &amp;#39;better&amp;#39; in any possible way compared to other &amp;#39;arrangements&amp;#39; of the transformer architecture&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m16kdm/t5gemma_a_new_collection_of_encoderdecoder_gemma/n3fer2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752665069,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m16kdm","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),n=()=>e.jsx(t,{data:a});export{n as default};
