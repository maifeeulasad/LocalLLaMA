import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"This command runs verifiable LLM inference using Parity Protocol, our open decentralized compute engine.\\n\\nhttps://preview.redd.it/fk9nx5j7a2ef1.jpg?width=1226&amp;format=pjpg&amp;auto=webp&amp;s=a90ba9e9b4bac68c43e6af6b453bd0c169b20f25\\n\\n\\\\- Task gets executed in a distributed way  \\n\\\\- Each node returns output + hash  \\n\\\\- Outputs are matched and verified before being accepted  \\n\\\\- No cloud, no GPU access needed on client side  \\n\\\\- Works with any containerized LLM (open models)\\n\\nWe’re college devs building a trustless alternative to AWS Lambda for container-based compute.\\n\\nGitHub: [https://github.com/theblitlabs](https://github.com/theblitlabs)  \\nDocs: [https://blitlabs.xyz/docs](https://blitlabs.xyz/docs)  \\nTwitter: [https://twitter.com/labsblit](https://twitter.com/labsblit)\\n\\nWould love feedback or help. Everything is open source and permissionless.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Decentralized LLM inference from your terminal, verified on-chain","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"media_metadata":{"fk9nx5j7a2ef1":{"status":"valid","e":"Image","m":"image/jpg","p":[{"y":29,"x":108,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcfd05bd9ebb1b5e09b797dc986c1b8e3dee2f48"},{"y":59,"x":216,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f59a7510da507171c55e8f6e4a175d5cab3d97ac"},{"y":88,"x":320,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25fc946b7634a0a9f99e149a3cb66db8ac3c621e"},{"y":176,"x":640,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c56da5db94b55019862462153ee93d4b0497fff9"},{"y":264,"x":960,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b7792351faa725fd4ade35e9715b17166265b11"},{"y":297,"x":1080,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=89730dd20db010eb217fce3a57b8933d935147d9"}],"s":{"y":338,"x":1226,"u":"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=1226&amp;format=pjpg&amp;auto=webp&amp;s=a90ba9e9b4bac68c43e6af6b453bd0c169b20f25"},"id":"fk9nx5j7a2ef1"}},"name":"t3_1m4u914","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.25,"author_flair_background_color":null,"ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_frf7k3no","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/JvOB4teBJPexclfMC0OuzNuMWooM4UHhYEL6W0yN6Es.jpeg?width=140&amp;height=140&amp;crop=140:140,smart&amp;auto=webp&amp;s=3b510a46eef0d8ac0b4fc29a5131b5d4add5127c","edited":1753033303,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1753031395,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;This command runs verifiable LLM inference using Parity Protocol, our open decentralized compute engine.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=1226&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a90ba9e9b4bac68c43e6af6b453bd0c169b20f25\\"&gt;https://preview.redd.it/fk9nx5j7a2ef1.jpg?width=1226&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a90ba9e9b4bac68c43e6af6b453bd0c169b20f25&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;- Task gets executed in a distributed way&lt;br/&gt;\\n- Each node returns output + hash&lt;br/&gt;\\n- Outputs are matched and verified before being accepted&lt;br/&gt;\\n- No cloud, no GPU access needed on client side&lt;br/&gt;\\n- Works with any containerized LLM (open models)&lt;/p&gt;\\n\\n&lt;p&gt;We’re college devs building a trustless alternative to AWS Lambda for container-based compute.&lt;/p&gt;\\n\\n&lt;p&gt;GitHub: &lt;a href=\\"https://github.com/theblitlabs\\"&gt;https://github.com/theblitlabs&lt;/a&gt;&lt;br/&gt;\\nDocs: &lt;a href=\\"https://blitlabs.xyz/docs\\"&gt;https://blitlabs.xyz/docs&lt;/a&gt;&lt;br/&gt;\\nTwitter: &lt;a href=\\"https://twitter.com/labsblit\\"&gt;https://twitter.com/labsblit&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Would love feedback or help. Everything is open source and permissionless.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/JvOB4teBJPexclfMC0OuzNuMWooM4UHhYEL6W0yN6Es.jpeg?auto=webp&amp;s=63a41c95c44b4f27c1e60c9673a368e0e9bfee2c","width":280,"height":280},"resolutions":[{"url":"https://external-preview.redd.it/JvOB4teBJPexclfMC0OuzNuMWooM4UHhYEL6W0yN6Es.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=53c3b00d143605b43ec731d87b95add6cf7cf10c","width":108,"height":108},{"url":"https://external-preview.redd.it/JvOB4teBJPexclfMC0OuzNuMWooM4UHhYEL6W0yN6Es.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a988393a6aa764ec2374ed982711663785ab0ad5","width":216,"height":216}],"variants":{},"id":"JvOB4teBJPexclfMC0OuzNuMWooM4UHhYEL6W0yN6Es"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m4u914","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Efficient-Ad-2913","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/","subreddit_subscribers":502273,"created_utc":1753031395,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4au8h8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"arekku255","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49oywo","score":1,"author_fullname":"t2_15rugs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But not practically as you get \\"random\\" rounding errors due to lack of precision.\\n\\nEssentially (0.1+0.2)+0.3 != 0.1 + (0.2+0.3) due to rounding errors, and when you have billions of rounding errors things have the potential to add up.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4au8h8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But not practically as you get &amp;quot;random&amp;quot; rounding errors due to lack of precision.&lt;/p&gt;\\n\\n&lt;p&gt;Essentially (0.1+0.2)+0.3 != 0.1 + (0.2+0.3) due to rounding errors, and when you have billions of rounding errors things have the potential to add up.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u914","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n4au8h8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753081608,"author_flair_text":null,"treatment_tags":[],"created_utc":1753081608,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49oywo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awwtifishal","can_mod_post":false,"created_utc":1753062888,"send_replies":true,"parent_id":"t1_n47rdru","score":2,"author_fullname":"t2_1d96a8k10t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LLM inference is theoretically deterministic when the samplers and seed are chosen explicitly. In practice there's some variance in hardware configuration, which could be solved if all operations were always done in the same order.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49oywo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LLM inference is theoretically deterministic when the samplers and seed are chosen explicitly. In practice there&amp;#39;s some variance in hardware configuration, which could be solved if all operations were always done in the same order.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u914","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n49oywo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062888,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n47rdru","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Tempstudio","can_mod_post":false,"created_utc":1753039250,"send_replies":true,"parent_id":"t3_1m4u914","score":9,"author_fullname":"t2_3k0v4gfu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LLM inference is not deterministic. Your \\"verification\\" is to run it 3 times on 3 machines and make sure outputs match. How do you handle anything for temperature &gt; 0? Even for temp == 0, different hardware would produce different results.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47rdru","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LLM inference is not deterministic. Your &amp;quot;verification&amp;quot; is to run it 3 times on 3 machines and make sure outputs match. How do you handle anything for temperature &amp;gt; 0? Even for temp == 0, different hardware would produce different results.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47rdru/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039250,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47ky8e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BumbleSlob","can_mod_post":false,"created_utc":1753037253,"send_replies":true,"parent_id":"t3_1m4u914","score":8,"author_fullname":"t2_1j7fhlcqkp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"pass. Please stop trying to graft crypto bullshit onto actually useful technology","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47ky8e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;pass. Please stop trying to graft crypto bullshit onto actually useful technology&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47ky8e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037253,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47x4r4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"arekku255","can_mod_post":false,"created_utc":1753041076,"send_replies":true,"parent_id":"t3_1m4u914","score":6,"author_fullname":"t2_15rugs","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like a solution in need of a problem.\\n\\nA trustless alternative to AWS Lambda for container-based compute sounds like a terrible way to do LLM inference compared to just doing an API call.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47x4r4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like a solution in need of a problem.&lt;/p&gt;\\n\\n&lt;p&gt;A trustless alternative to AWS Lambda for container-based compute sounds like a terrible way to do LLM inference compared to just doing an API call.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47x4r4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753041076,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47ocl3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EspritFort","can_mod_post":false,"send_replies":true,"parent_id":"t1_n478hvc","score":4,"author_fullname":"t2_dkj9t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; Definitely. But verifiability’s been too long ignored, no trust in outputs means no scalable coordination.  \\n&gt; Local LLMs solve your needs. Verifiable LLMs unlock networked use.  \\n  \\nNone of this makes any sense. There *are* only personal needs, and I don't see how \\"networked use\\" or \\"scalable coordination\\" are one of them. Do note that you're posting this in r/**Local**LLaMA. You may have the wrong crowd, but I also have no idea who the correct target audience *would* be.","edited":false,"author_flair_css_class":null,"name":"t1_n47ocl3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Definitely. But verifiability’s been too long ignored, no trust in outputs means no scalable coordination.&lt;br/&gt;\\nLocal LLMs solve your needs. Verifiable LLMs unlock networked use.  &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;None of this makes any sense. There &lt;em&gt;are&lt;/em&gt; only personal needs, and I don&amp;#39;t see how &amp;quot;networked use&amp;quot; or &amp;quot;scalable coordination&amp;quot; are one of them. Do note that you&amp;#39;re posting this in r/&lt;strong&gt;Local&lt;/strong&gt;LLaMA. You may have the wrong crowd, but I also have no idea who the correct target audience &lt;em&gt;would&lt;/em&gt; be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4u914","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47ocl3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753038306,"author_flair_text":null,"collapsed":false,"created_utc":1753038306,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n485nft","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47km41","score":1,"author_fullname":"t2_1opxde6hyq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"As best I can see ...  \\nIf you don't control the hardware and the LLM configs, then this is meaningless as inference providers may not guarantee quant and settings remain the same from one session to the next.  \\nValidating that hardware and configuration are good can be done much more cheaply, computationally speaking, than what this does.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n485nft","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As best I can see ...&lt;br/&gt;\\nIf you don&amp;#39;t control the hardware and the LLM configs, then this is meaningless as inference providers may not guarantee quant and settings remain the same from one session to the next.&lt;br/&gt;\\nValidating that hardware and configuration are good can be done much more cheaply, computationally speaking, than what this does.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u914","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n485nft/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043708,"author_flair_text":null,"treatment_tags":[],"created_utc":1753043708,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49obtf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awwtifishal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47km41","score":1,"author_fullname":"t2_1d96a8k10t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't want trustless LLM systems, because it cannot be done in a trustless way, period. Unless all you do with them is already public, for some reason. When you do ANYTHING involving private data, some machine needs to have such data unencrypted at some point. So you have to trust them that they won't store or sell or leak it.\\n\\nYou need to be able to explain at least one practical use case for your proposal. Because as it stands, I don't understand how it can ever be viable.\\n\\nThe only thing I can think of that doesn't require privacy is scientific research, like folding@home. But people already donate their resources for free for those purposes, so there's no profitable business there.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n49obtf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t want trustless LLM systems, because it cannot be done in a trustless way, period. Unless all you do with them is already public, for some reason. When you do ANYTHING involving private data, some machine needs to have such data unencrypted at some point. So you have to trust them that they won&amp;#39;t store or sell or leak it.&lt;/p&gt;\\n\\n&lt;p&gt;You need to be able to explain at least one practical use case for your proposal. Because as it stands, I don&amp;#39;t understand how it can ever be viable.&lt;/p&gt;\\n\\n&lt;p&gt;The only thing I can think of that doesn&amp;#39;t require privacy is scientific research, like &lt;a href=\\"mailto:folding@home\\"&gt;folding@home&lt;/a&gt;. But people already donate their resources for free for those purposes, so there&amp;#39;s no profitable business there.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u914","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n49obtf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062649,"author_flair_text":null,"treatment_tags":[],"created_utc":1753062649,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47km41","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Efficient-Ad-2913","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47b2se","score":1,"author_fullname":"t2_frf7k3no","approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're describing a trusted proxy setup, which is fine for solo use, but not composable.\\n\\nThe goal isn't just inference, it's coordination. Distributed agents, apps, contracts, anything that consumes or chains off LLM output, needs verification at the execution layer.\\n\\nAnd this isn’t just for LLMs. Same stack also runs federated training and general serverless workloads. verifiable, decentralized, deterministic.\\n\\nIf you want trustless systems to talk to each other, verifying what they say is step one.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n47km41","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re describing a trusted proxy setup, which is fine for solo use, but not composable.&lt;/p&gt;\\n\\n&lt;p&gt;The goal isn&amp;#39;t just inference, it&amp;#39;s coordination. Distributed agents, apps, contracts, anything that consumes or chains off LLM output, needs verification at the execution layer.&lt;/p&gt;\\n\\n&lt;p&gt;And this isn’t just for LLMs. Same stack also runs federated training and general serverless workloads. verifiable, decentralized, deterministic.&lt;/p&gt;\\n\\n&lt;p&gt;If you want trustless systems to talk to each other, verifying what they say is step one.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4u914","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47km41/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753037147,"author_flair_text":null,"treatment_tags":[],"created_utc":1753037147,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47b2se","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awwtifishal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n478hvc","score":3,"author_fullname":"t2_1d96a8k10t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't really see how can privacy layers be added later, or why anybody would bother. I can already spin up 2 separate servers in different services and do inference with the same parameters to check that they match. That way I'm trusting 2 hosts with my data, and I can obfuscate it but there's always a way for the owners to decode my inference. There's another huge problem that doesn't seem to be addressed: each model is HUGE, and it takes time to download dozens or even hundreds of GB of data just to \\\\*start\\\\* with the inference. And people don't want to be waiting for a response after it has started. So you're stuck with whatever host had the model downloaded. Both storing or re-downloading the model costs money.\\n\\nBesides, there's already plenty of inference services that could have identical systems (usually with vLLM) for a deterministic output (by choosing a seed). I haven't checked but I think that's likely.\\n\\nBesides, I already use an inference service (or rather, a proxy of other services) which I can pay with crypto, and it already serves my needs.","edited":false,"author_flair_css_class":null,"name":"t1_n47b2se","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t really see how can privacy layers be added later, or why anybody would bother. I can already spin up 2 separate servers in different services and do inference with the same parameters to check that they match. That way I&amp;#39;m trusting 2 hosts with my data, and I can obfuscate it but there&amp;#39;s always a way for the owners to decode my inference. There&amp;#39;s another huge problem that doesn&amp;#39;t seem to be addressed: each model is HUGE, and it takes time to download dozens or even hundreds of GB of data just to *start* with the inference. And people don&amp;#39;t want to be waiting for a response after it has started. So you&amp;#39;re stuck with whatever host had the model downloaded. Both storing or re-downloading the model costs money.&lt;/p&gt;\\n\\n&lt;p&gt;Besides, there&amp;#39;s already plenty of inference services that could have identical systems (usually with vLLM) for a deterministic output (by choosing a seed). I haven&amp;#39;t checked but I think that&amp;#39;s likely.&lt;/p&gt;\\n\\n&lt;p&gt;Besides, I already use an inference service (or rather, a proxy of other services) which I can pay with crypto, and it already serves my needs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4u914","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n47b2se/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753034235,"author_flair_text":null,"collapsed":false,"created_utc":1753034235,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n478hvc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Efficient-Ad-2913","can_mod_post":false,"send_replies":true,"parent_id":"t1_n477sia","score":-3,"author_fullname":"t2_frf7k3no","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Definitely. But verifiability’s been too long ignored, no trust in outputs means no scalable coordination.  \\nLocal LLMs solve *your* needs. Verifiable LLMs unlock *networked* use.  \\nWe're building the base layer. Privacy layers can stack right on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n478hvc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Definitely. But verifiability’s been too long ignored, no trust in outputs means no scalable coordination.&lt;br/&gt;\\nLocal LLMs solve &lt;em&gt;your&lt;/em&gt; needs. Verifiable LLMs unlock &lt;em&gt;networked&lt;/em&gt; use.&lt;br/&gt;\\nWe&amp;#39;re building the base layer. Privacy layers can stack right on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u914","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n478hvc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033484,"author_flair_text":null,"treatment_tags":[],"created_utc":1753033484,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"n477sia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Awwtifishal","can_mod_post":false,"send_replies":true,"parent_id":"t1_n477iuh","score":7,"author_fullname":"t2_1d96a8k10t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I know. But it doesn't solve the first which is a pretty big deal. In fact that's probably the #1 reason for most people wanting to use local LLMs.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n477sia","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know. But it doesn&amp;#39;t solve the first which is a pretty big deal. In fact that&amp;#39;s probably the #1 reason for most people wanting to use local LLMs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u914","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n477sia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033281,"author_flair_text":null,"treatment_tags":[],"created_utc":1753033281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n477iuh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Efficient-Ad-2913","can_mod_post":false,"created_utc":1753033203,"send_replies":true,"parent_id":"t1_n4772y1","score":-5,"author_fullname":"t2_frf7k3no","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You’re confusing *private inference* with *verifiable inference*.  \\nPrivacy hides inputs. Verifiability proves outputs.  \\nDifferent problems. Both matter. This solves the second.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n477iuh","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You’re confusing &lt;em&gt;private inference&lt;/em&gt; with &lt;em&gt;verifiable inference&lt;/em&gt;.&lt;br/&gt;\\nPrivacy hides inputs. Verifiability proves outputs.&lt;br/&gt;\\nDifferent problems. Both matter. This solves the second.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4u914","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n477iuh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033203,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4772y1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Awwtifishal","can_mod_post":false,"created_utc":1753033075,"send_replies":true,"parent_id":"t3_1m4u914","score":6,"author_fullname":"t2_1d96a8k10t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why would anyone want to do LLM inference with no privacy? Unless it's meant only for content that you don't mind other people seeing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4772y1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would anyone want to do LLM inference with no privacy? Unless it&amp;#39;s meant only for content that you don&amp;#39;t mind other people seeing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n4772y1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753033075,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n483s6w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"croninsiglos","can_mod_post":false,"created_utc":1753043137,"send_replies":true,"parent_id":"t3_1m4u914","score":2,"author_fullname":"t2_v7qje","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don’t believe this solves any real world problems so although it might be fun, it’s probably a waste of your time.\\n\\nIt adds completely unnecessary compute, latency, and steps which are simply not required for verifiable llm inference outputs. In real dollars, this also means higher costs.\\n\\nMy advice would be to abandon this effort. \\n\\nNow there are still efforts on the training side to do. Companies have private data and want to share models without sharing their data. This means a need for private distributed training while sharing weight updates but ensuring no data leakage. There are a couple approaches already, but this is an area of active research for many. Company A, Company B, and Company C should be able to jointly train a single shared model without sharing their training data with each other.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n483s6w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t believe this solves any real world problems so although it might be fun, it’s probably a waste of your time.&lt;/p&gt;\\n\\n&lt;p&gt;It adds completely unnecessary compute, latency, and steps which are simply not required for verifiable llm inference outputs. In real dollars, this also means higher costs.&lt;/p&gt;\\n\\n&lt;p&gt;My advice would be to abandon this effort. &lt;/p&gt;\\n\\n&lt;p&gt;Now there are still efforts on the training side to do. Companies have private data and want to share models without sharing their data. This means a need for private distributed training while sharing weight updates but ensuring no data leakage. There are a couple approaches already, but this is an area of active research for many. Company A, Company B, and Company C should be able to jointly train a single shared model without sharing their training data with each other.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n483s6w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753043137,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n480xx1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"created_utc":1753042266,"send_replies":true,"parent_id":"t3_1m4u914","score":1,"author_fullname":"t2_1opxde6hyq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this useful within a heterogeneous local cluster?  \\nIf so, I could maybe see a use case for myself.  \\nOtherwise, hard pass.\\n\\nEdit: after a bit more reading, yeah, solution in search of a problem, and hard pass.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n480xx1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this useful within a heterogeneous local cluster?&lt;br/&gt;\\nIf so, I could maybe see a use case for myself.&lt;br/&gt;\\nOtherwise, hard pass.&lt;/p&gt;\\n\\n&lt;p&gt;Edit: after a bit more reading, yeah, solution in search of a problem, and hard pass.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4u914/decentralized_llm_inference_from_your_terminal/n480xx1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753042266,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4u914","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(t,{data:a});export{o as default};
