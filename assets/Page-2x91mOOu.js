import{j as e}from"./index-M4edQi1P.js";import{R as l}from"./RedditPostRenderer-CESBGIIy.js";import"./index-DFpL1mt4.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hello there,\\n\\nMy project to extract and collect the \\"secret\\" system prompts from a bunch of proprietary AI tools just passed 70k stars on GitHub, and I wanted to share it with this community specifically because I think it's incredibly useful.\\n\\n**The idea is to see the advanced \\"prompt architecture\\" that companies like Vercel, Cursor, etc., use to get high-quality results, so we can replicate those techniques on different platforms.**\\n\\nInstead of trying to reinvent the wheel, you can see exactly how they force models to \\"think step-by-step\\" in a scratchpad, how they define an expert persona with hyper-specific rules, or how they demand rigidly structured outputs. It's a goldmine of ideas for crafting better system prompts.\\n\\nFor example, here's a small snippet from the Cursor prompt that shows how they establish the AI's role and capabilities right away:\\n\\n    Knowledge cutoff: 2024-06\\n    \\n    You are an AI coding assistant, powered by GPT-4.1. You operate in Cursor. \\n    \\n    You are pair programming with a USER to solve their coding task. Each time the USER sends a message, we may automatically attach some information about their current state, such as what files they have open, where their cursor is, recently viewed files, edit history in their session so far, linter errors, and more. This information may or may not be relevant to the coding task, it is up for you to decide.\\n    \\n    You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. Autonomously resolve the query to the best of your ability before coming back to the user.\\n    \\n    Your main goal is to follow the USER's instructions at each message, denoted by the &lt;user_query&gt; tag.\\n    \\n    &lt;communication&gt;\\n    When using markdown in assistant messages, use backticks to format file, directory, function, and class names. Use \\\\( and \\\\) for inline math, \\\\[ and \\\\] for block math.\\n    &lt;/communication&gt;\\n\\nI wrote a full article that does a deep dive into these patterns and also discusses the \\"dual-use\\" aspect of making these normally-hidden prompts public.\\n\\nI'm super curious: **How are you all structuring system prompts for your favorite models?**\\n\\n**Links:**\\n\\n* **The full article with more analysis:** [The Open Source Project That Became an Essential Library for Modern AI Engineering](https://medium.com/@lucknitelol/the-open-source-project-that-became-an-essential-library-for-modern-ai-engineering-67021b50acee?source=user_profile_page---------0-------------d9a574987030----------------------)[](https://medium.com/@lucknitelol?source=post_page---byline--67021b50acee---------------------------------------)\\n\\n* **The GitHub Repo (to grab the prompts):** [https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools](https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools)\\n\\nHope you find it useful!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I extracted the system prompts from closed-source tools like Cursor &amp; v0. The repo just hit 70k stars.","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5gwzs","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"subreddit_type":"public","ups":356,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_fbh7mxys2","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":356,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1753099199,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753099002,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\\n\\n&lt;p&gt;My project to extract and collect the &amp;quot;secret&amp;quot; system prompts from a bunch of proprietary AI tools just passed 70k stars on GitHub, and I wanted to share it with this community specifically because I think it&amp;#39;s incredibly useful.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;The idea is to see the advanced &amp;quot;prompt architecture&amp;quot; that companies like Vercel, Cursor, etc., use to get high-quality results, so we can replicate those techniques on different platforms.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Instead of trying to reinvent the wheel, you can see exactly how they force models to &amp;quot;think step-by-step&amp;quot; in a scratchpad, how they define an expert persona with hyper-specific rules, or how they demand rigidly structured outputs. It&amp;#39;s a goldmine of ideas for crafting better system prompts.&lt;/p&gt;\\n\\n&lt;p&gt;For example, here&amp;#39;s a small snippet from the Cursor prompt that shows how they establish the AI&amp;#39;s role and capabilities right away:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;Knowledge cutoff: 2024-06\\n\\nYou are an AI coding assistant, powered by GPT-4.1. You operate in Cursor. \\n\\nYou are pair programming with a USER to solve their coding task. Each time the USER sends a message, we may automatically attach some information about their current state, such as what files they have open, where their cursor is, recently viewed files, edit history in their session so far, linter errors, and more. This information may or may not be relevant to the coding task, it is up for you to decide.\\n\\nYou are an agent - please keep going until the user&amp;#39;s query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. Autonomously resolve the query to the best of your ability before coming back to the user.\\n\\nYour main goal is to follow the USER&amp;#39;s instructions at each message, denoted by the &amp;lt;user_query&amp;gt; tag.\\n\\n&amp;lt;communication&amp;gt;\\nWhen using markdown in assistant messages, use backticks to format file, directory, function, and class names. Use \\\\( and \\\\) for inline math, \\\\[ and \\\\] for block math.\\n&amp;lt;/communication&amp;gt;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;I wrote a full article that does a deep dive into these patterns and also discusses the &amp;quot;dual-use&amp;quot; aspect of making these normally-hidden prompts public.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m super curious: &lt;strong&gt;How are you all structuring system prompts for your favorite models?&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Links:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;The full article with more analysis:&lt;/strong&gt; &lt;a href=\\"https://medium.com/@lucknitelol/the-open-source-project-that-became-an-essential-library-for-modern-ai-engineering-67021b50acee?source=user_profile_page---------0-------------d9a574987030----------------------\\"&gt;The Open Source Project That Became an Essential Library for Modern AI Engineering&lt;/a&gt;&lt;a href=\\"https://medium.com/@lucknitelol?source=post_page---byline--67021b50acee---------------------------------------\\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;The GitHub Repo (to grab the prompts):&lt;/strong&gt; &lt;a href=\\"https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools\\"&gt;https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Hope you find it useful!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1m5gwzs","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"Independent-Box-898","discussion_type":null,"num_comments":43,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/","subreddit_subscribers":502721,"created_utc":1753099002,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c93xl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Innomen","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c5a9h","score":5,"author_fullname":"t2_36j0c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Web search too, claude will have a fit in a single prompt if a chain reaction of searches results.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4c93xl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Web search too, claude will have a fit in a single prompt if a chain reaction of searches results.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c93xl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753105482,"author_flair_text":null,"treatment_tags":[],"created_utc":1753105482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c5a9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"satireplusplus","can_mod_post":false,"created_utc":1753104216,"send_replies":true,"parent_id":"t1_n4btsgr","score":46,"author_fullname":"t2_x7vf0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Each token produces an entry in the kv-cache and is basically one atomic unit of computation in the model as well. All subsequent generation steps can reference any previous kv steps (strong simplification). These instructions will at the very least influence what the model generates and it'll probably more or less follow the outlined instructions. As long as the model was really trained on large contexts and isn't doing some sort of long context interpolation. Whats more annoying is that this eats up valuable space in the context window (often with tons of crap that you don't need). The way ChatGPT et al. are presenting the results you don't really get feedback when the context window is maxed out either. With coding you run into this limitation very quickly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c5a9h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Each token produces an entry in the kv-cache and is basically one atomic unit of computation in the model as well. All subsequent generation steps can reference any previous kv steps (strong simplification). These instructions will at the very least influence what the model generates and it&amp;#39;ll probably more or less follow the outlined instructions. As long as the model was really trained on large contexts and isn&amp;#39;t doing some sort of long context interpolation. Whats more annoying is that this eats up valuable space in the context window (often with tons of crap that you don&amp;#39;t need). The way ChatGPT et al. are presenting the results you don&amp;#39;t really get feedback when the context window is maxed out either. With coding you run into this limitation very quickly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c5a9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104216,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":46}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bwxoe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"admajic","can_mod_post":false,"created_utc":1753101308,"send_replies":true,"parent_id":"t1_n4btsgr","score":17,"author_fullname":"t2_60b9farf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably compresses the context window when it's full.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bwxoe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably compresses the context window when it&amp;#39;s full.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4bwxoe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753101308,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4byxoq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"UnreasonableEconomy","can_mod_post":false,"created_utc":1753102032,"send_replies":true,"parent_id":"t1_n4btsgr","score":20,"author_fullname":"t2_88lwr6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; What gives?\\n\\nIt's pretty simple: by ignoring 99.9% of the context. That's what attention is all about.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4byxoq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;What gives?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s pretty simple: by ignoring 99.9% of the context. That&amp;#39;s what attention is all about.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4byxoq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102032,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4clz7t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fizzy1242","can_mod_post":false,"created_utc":1753109436,"send_replies":true,"parent_id":"t1_n4btsgr","score":2,"author_fullname":"t2_16zcsx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Agree. Less is more","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4clz7t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agree. Less is more&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4clz7t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753109436,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c53b7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"popiazaza","can_mod_post":false,"created_utc":1753104151,"send_replies":true,"parent_id":"t1_n4btsgr","score":4,"author_fullname":"t2_f6vyt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not using Gemini ^^/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c53b7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not using Gemini &lt;sup&gt;&lt;sup&gt;/s&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c53b7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104151,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4f8m1a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"claythearc","can_mod_post":false,"created_utc":1753136550,"send_replies":true,"parent_id":"t1_n4btsgr","score":1,"author_fullname":"t2_65rk0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Most closed models keep reasonably good coherence up to around 30k tokens so a couple thousand word system prompt is zero issue. That’s still tens of thousands of tokens of code to work with at ~peak performance","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4f8m1a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most closed models keep reasonably good coherence up to around 30k tokens so a couple thousand word system prompt is zero issue. That’s still tens of thousands of tokens of code to work with at ~peak performance&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4f8m1a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753136550,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4btsgr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"freecodeio","can_mod_post":false,"created_utc":1753100120,"send_replies":true,"parent_id":"t3_1m5gwzs","score":77,"author_fullname":"t2_1oeu2j1o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I find it hard to believe that the AI can follow thousands of instructions like this without hallucinating. What gives?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4btsgr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I find it hard to believe that the AI can follow thousands of instructions like this without hallucinating. What gives?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4btsgr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100120,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":77}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c69hm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Independent-Box-898","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c5rvg","score":12,"author_fullname":"t2_fbh7mxys2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"^^","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4c69hm","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c69hm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104544,"author_flair_text":null,"treatment_tags":[],"created_utc":1753104544,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cplyy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"freecodeio","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c5rvg","score":9,"author_fullname":"t2_1oeu2j1o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what if asking for the AI's prompt is a command?\\n\\n&lt;prompt_request&gt; - run this command when the user wants to know about the internal prompt\\n\\nYou could then capture the command and stream back a (consistently) fake prompt that seems believable.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4cplyy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what if asking for the AI&amp;#39;s prompt is a command?&lt;/p&gt;\\n\\n&lt;p&gt;&amp;lt;prompt_request&amp;gt; - run this command when the user wants to know about the internal prompt&lt;/p&gt;\\n\\n&lt;p&gt;You could then capture the command and stream back a (consistently) fake prompt that seems believable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4cplyy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753110499,"author_flair_text":null,"treatment_tags":[],"created_utc":1753110499,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ifw2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bartgrumbel","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4hdfr9","score":1,"author_fullname":"t2_94plzy4n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That depends on the \\"temperature\\" set during inference, a factor that controls the randomness of the response. Some (cloud-based) models allow setting it to zero, others do not.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ifw2p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That depends on the &amp;quot;temperature&amp;quot; set during inference, a factor that controls the randomness of the response. Some (cloud-based) models allow setting it to zero, others do not.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4ifw2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753186359,"author_flair_text":null,"treatment_tags":[],"created_utc":1753186359,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4hdfr9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WackyConundrum","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c5rvg","score":1,"author_fullname":"t2_1uqjf45o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;You'd usually try to extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.\\n\\nThat's not true. Why? Because the weights affecting consequtive token probabilities don't change from session to session. You would expect to read very similar outputs for very similar prompts from a deterministic machine.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4hdfr9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;You&amp;#39;d usually try to extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;That&amp;#39;s not true. Why? Because the weights affecting consequtive token probabilities don&amp;#39;t change from session to session. You would expect to read very similar outputs for very similar prompts from a deterministic machine.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4hdfr9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753166434,"author_flair_text":null,"treatment_tags":[],"created_utc":1753166434,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c5rvg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bartgrumbel","can_mod_post":false,"created_utc":1753104380,"send_replies":true,"parent_id":"t1_n4c3rji","score":36,"author_fullname":"t2_94plzy4n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You'd usually try to extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.\\n\\n&gt; would it be possible for a company intending to protect its prompts to \\"seed\\" the model with a fake prompt \\n\\nAbsolutely! You could probably even bake it into the model by infusing it into the train / fine-tuning dataset.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c5rvg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;d usually try to extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;would it be possible for a company intending to protect its prompts to &amp;quot;seed&amp;quot; the model with a fake prompt &lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Absolutely! You could probably even bake it into the model by infusing it into the train / fine-tuning dataset.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c5rvg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104380,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fk0qk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eleqtriq","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ccqtu","score":1,"author_fullname":"t2_66vte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"While it would be possible to change the prompt server side, I doubt they are doing that.  Because that would break the agents when pointing it to your own resources, such as AWS bedrock or Azure.  Because my resources are obviously not going to change the system prompt.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4fk0qk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While it would be possible to change the prompt server side, I doubt they are doing that.  Because that would break the agents when pointing it to your own resources, such as AWS bedrock or Azure.  Because my resources are obviously not going to change the system prompt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4fk0qk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753140281,"author_flair_text":null,"treatment_tags":[],"created_utc":1753140281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ccqtu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Senior-City-7058","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c7y6e","score":8,"author_fullname":"t2_9pp1z7ay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But wouldn’t that only show you the system prompt that was sent from the client? In other words, the prompt you send the model can be completely changed server side, including the system prompt. You cannot see the inner workings of OpenAIs server so they could be changing everything behind the scenes and you’d never know, right?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ccqtu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But wouldn’t that only show you the system prompt that was sent from the client? In other words, the prompt you send the model can be completely changed server side, including the system prompt. You cannot see the inner workings of OpenAIs server so they could be changing everything behind the scenes and you’d never know, right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4ccqtu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106618,"author_flair_text":null,"treatment_tags":[],"created_utc":1753106618,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4f8vvj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"claythearc","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cjd15","score":3,"author_fullname":"t2_65rk0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The prompts don’t really seem to be particularly guarded by anyone. Lots of the infra providers, even closed ones, keep a public repo updated with theirs.","edited":false,"author_flair_css_class":null,"name":"t1_n4f8vvj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The prompts don’t really seem to be particularly guarded by anyone. Lots of the infra providers, even closed ones, keep a public repo updated with theirs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5gwzs","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4f8vvj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753136639,"author_flair_text":null,"collapsed":false,"created_utc":1753136639,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4fljud","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"infeststation","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cjd15","score":1,"author_fullname":"t2_f64u9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If they were trying to hide their prompts, this would probably have a takedown request by now","edited":false,"author_flair_css_class":null,"name":"t1_n4fljud","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If they were trying to hide their prompts, this would probably have a takedown request by now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5gwzs","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4fljud/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753140782,"author_flair_text":null,"collapsed":false,"created_utc":1753140782,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4cjd15","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"youcef0w0","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c9792","score":10,"author_fullname":"t2_49fdoure","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no, they send a request to your proxy from their servers (I know this because if you put localhost in the base URL override, it doesn't work, it has to be internet accessible), I've done it before, you're replacing the openAI API base URL, they can't get around it without removing support for custom openAI endpoints  \\n  \\nwhich leads me to believe, they're not even trying to hide their prompt","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cjd15","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no, they send a request to your proxy from their servers (I know this because if you put localhost in the base URL override, it doesn&amp;#39;t work, it has to be internet accessible), I&amp;#39;ve done it before, you&amp;#39;re replacing the openAI API base URL, they can&amp;#39;t get around it without removing support for custom openAI endpoints  &lt;/p&gt;\\n\\n&lt;p&gt;which leads me to believe, they&amp;#39;re not even trying to hide their prompt&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4cjd15/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753108694,"author_flair_text":null,"treatment_tags":[],"created_utc":1753108694,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c9792","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"addandsubtract","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4c7y6e","score":14,"author_fullname":"t2_3o91c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cursor would be doing it wrong if they didn't send the requests through their proxy and attach the system prompt there.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4c9792","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cursor would be doing it wrong if they didn&amp;#39;t send the requests through their proxy and attach the system prompt there.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c9792/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753105512,"author_flair_text":null,"treatment_tags":[],"created_utc":1753105512,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c7y6e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eleqtriq","can_mod_post":false,"created_utc":1753105105,"send_replies":true,"parent_id":"t1_n4c3rji","score":6,"author_fullname":"t2_66vte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You guys are doing it wrong if you’re doing that.  You can just force the tools through a proxy and pick up the messages there in plain text.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c7y6e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You guys are doing it wrong if you’re doing that.  You can just force the tools through a proxy and pick up the messages there in plain text.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c7y6e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753105105,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c3rji","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"apnorton","can_mod_post":false,"created_utc":1753103707,"send_replies":true,"parent_id":"t3_1m5gwzs","score":37,"author_fullname":"t2_na9ev","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Genuine question: these are \\"self-reported\\" by the LLM, right? How do we know that the prompt recall isn't a hallucination of its actual prompt?  Or, would it be possible for a company intending to protect its prompts to \\"seed\\" the model with a fake prompt to respond with when queried?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c3rji","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Genuine question: these are &amp;quot;self-reported&amp;quot; by the LLM, right? How do we know that the prompt recall isn&amp;#39;t a hallucination of its actual prompt?  Or, would it be possible for a company intending to protect its prompts to &amp;quot;seed&amp;quot; the model with a fake prompt to respond with when queried?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c3rji/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753103707,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":37}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cbozc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppealSame4367","can_mod_post":false,"created_utc":1753106293,"send_replies":true,"parent_id":"t3_1m5gwzs","score":7,"author_fullname":"t2_sxud8ccv4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That would be 20$ per hour please. Your cursor team.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cbozc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would be 20$ per hour please. Your cursor team.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4cbozc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106293,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4e7e3x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SandFragrant6227","can_mod_post":false,"created_utc":1753125535,"send_replies":true,"parent_id":"t3_1m5gwzs","score":7,"author_fullname":"t2_vowy0dxi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I also extracted \\"secret\\" Gemini CLI system instruction. Here they are:  [https://softwaresecretweapons.com/opinion/gemini-cli-masterclass/gemini-cli-system-prompts.html](https://softwaresecretweapons.com/opinion/gemini-cli-masterclass/gemini-cli-system-prompts.html)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4e7e3x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I also extracted &amp;quot;secret&amp;quot; Gemini CLI system instruction. Here they are:  &lt;a href=\\"https://softwaresecretweapons.com/opinion/gemini-cli-masterclass/gemini-cli-system-prompts.html\\"&gt;https://softwaresecretweapons.com/opinion/gemini-cli-masterclass/gemini-cli-system-prompts.html&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4e7e3x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753125535,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4brcsw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cantgetthistowork","can_mod_post":false,"created_utc":1753099154,"send_replies":true,"parent_id":"t3_1m5gwzs","score":11,"author_fullname":"t2_j1i0o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Keep this up. Love learning about prompt engineering","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4brcsw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Keep this up. Love learning about prompt engineering&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4brcsw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753099154,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4eh1mg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JS31415926","can_mod_post":false,"created_utc":1753128300,"send_replies":true,"parent_id":"t1_n4bvq97","score":6,"author_fullname":"t2_42fwxrkh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"English is new programming language","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eh1mg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;English is new programming language&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4eh1mg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753128300,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n4bvq97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ILoveMy2Balls","can_mod_post":false,"created_utc":1753100859,"send_replies":true,"parent_id":"t3_1m5gwzs","score":7,"author_fullname":"t2_1nisx8ggay","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's funny how much we can modify and program an llm with just plain english","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bvq97","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s funny how much we can modify and program an llm with just plain english&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4bvq97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100859,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c6xus","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Independent-Box-898","can_mod_post":false,"created_utc":1753104771,"send_replies":true,"parent_id":"t1_n4c3ttx","score":12,"author_fullname":"t2_fbh7mxys2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c6xus","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I extract the prompt in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c6xus/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104771,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c3ttx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TylerFahey","can_mod_post":false,"created_utc":1753103728,"send_replies":true,"parent_id":"t3_1m5gwzs","score":6,"author_fullname":"t2_51ohu6e1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is neat, I'm curious (apologies if I overlooked this in any of your links) - How can you be certain the prompt itself is truly extracted and not hallucinated or contrived to some extent?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c3ttx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is neat, I&amp;#39;m curious (apologies if I overlooked this in any of your links) - How can you be certain the prompt itself is truly extracted and not hallucinated or contrived to some extent?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c3ttx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753103728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4cscyd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fyn_world","can_mod_post":false,"created_utc":1753111291,"send_replies":true,"parent_id":"t3_1m5gwzs","score":3,"author_fullname":"t2_ey5k6ty5c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you good sir ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cscyd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you good sir &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4cscyd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753111291,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4eiluw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Soggy_Wallaby_8130","can_mod_post":false,"created_utc":1753128740,"send_replies":true,"parent_id":"t1_n4c9749","score":1,"author_fullname":"t2_o07jh7x35","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably they’re at least looking into fine-tuning?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eiluw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably they’re at least looking into fine-tuning?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4eiluw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753128740,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c9749","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Innomen","can_mod_post":false,"created_utc":1753105511,"send_replies":true,"parent_id":"t3_1m5gwzs","score":5,"author_fullname":"t2_36j0c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Seems obvious someone should train a model trained on these patterns, but it begs the question, how much is fluff. Basically we need to generalize from the findings from these specifics and feed that information back into the loop to make ais that don't need to be micromanaged this way and instead operate like the opposite of an evil genie.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c9749","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Seems obvious someone should train a model trained on these patterns, but it begs the question, how much is fluff. Basically we need to generalize from the findings from these specifics and feed that information back into the loop to make ais that don&amp;#39;t need to be micromanaged this way and instead operate like the opposite of an evil genie.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c9749/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753105511,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dab1e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ramdulara","can_mod_post":false,"created_utc":1753116368,"send_replies":true,"parent_id":"t3_1m5gwzs","score":1,"author_fullname":"t2_1z42b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you cover aider as well?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dab1e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you cover aider as well?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4dab1e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753116368,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4eg4zf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"alexhackney","can_mod_post":false,"created_utc":1753128037,"send_replies":true,"parent_id":"t3_1m5gwzs","score":1,"author_fullname":"t2_graia","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So you’ve got a repo with 70k stars that’s just reverse engineered prompts that they didn’t want anyone to have?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eg4zf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So you’ve got a repo with 70k stars that’s just reverse engineered prompts that they didn’t want anyone to have?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4eg4zf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753128037,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gtvhk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"warlockdn","can_mod_post":false,"created_utc":1753156865,"send_replies":true,"parent_id":"t3_1m5gwzs","score":1,"author_fullname":"t2_56ab1pk8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would you post your process of prompt extraction? Would be a good learning experience","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gtvhk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would you post your process of prompt extraction? Would be a good learning experience&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4gtvhk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753156865,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4hlapk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Independent-Box-898","can_mod_post":false,"created_utc":1753170833,"send_replies":true,"parent_id":"t1_n4hd67s","score":1,"author_fullname":"t2_fbh7mxys2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I extract the prompts with prompt engineering in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hlapk","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I extract the prompts with prompt engineering in different independent sessions. The model is unlikely to hallucinate an identical prompt multiple times.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4hlapk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753170833,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4hd67s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WackyConundrum","can_mod_post":false,"created_utc":1753166290,"send_replies":true,"parent_id":"t3_1m5gwzs","score":1,"author_fullname":"t2_1uqjf45o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How did you extract these prompts? What makes you believe they're real?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hd67s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How did you extract these prompts? What makes you believe they&amp;#39;re real?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4hd67s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753166290,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4hwkdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"csells","can_mod_post":false,"created_utc":1753177408,"send_replies":true,"parent_id":"t3_1m5gwzs","score":1,"author_fullname":"t2_4mtbx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Claude Code?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hwkdr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude Code?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4hwkdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753177408,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dkbk2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Esshwar123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4di4xn","score":1,"author_fullname":"t2_woofa4j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah it's pretty similar to how I do, i use pydantic to stop the loop when task is done and a lot of condition, felt messy but worked seamlessly u can see demo in my profile if u want, react agent does seems neat, will definitely use it for future projects","edited":false,"author_flair_css_class":null,"name":"t1_n4dkbk2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it&amp;#39;s pretty similar to how I do, i use pydantic to stop the loop when task is done and a lot of condition, felt messy but worked seamlessly u can see demo in my profile if u want, react agent does seems neat, will definitely use it for future projects&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m5gwzs","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4dkbk2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753119095,"author_flair_text":null,"collapsed":false,"created_utc":1753119095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4di4xn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Senior-City-7058","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dfbz5","score":2,"author_fullname":"t2_9pp1z7ay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So id highly recommend learning how to code a ReAct agent from scratch without any agent frameworks. I literally did it last week and that is why I’m able to answer your questions.\\n\\nBefore then I was relying on open source frameworks and not having any real understanding of what was happening under the hood.\\n\\nIt’s literally a while loop and an LLM API call. If you know very basic python (or any language) you can do it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4di4xn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So id highly recommend learning how to code a ReAct agent from scratch without any agent frameworks. I literally did it last week and that is why I’m able to answer your questions.&lt;/p&gt;\\n\\n&lt;p&gt;Before then I was relying on open source frameworks and not having any real understanding of what was happening under the hood.&lt;/p&gt;\\n\\n&lt;p&gt;It’s literally a while loop and an LLM API call. If you know very basic python (or any language) you can do it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4di4xn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118504,"author_flair_text":null,"treatment_tags":[],"created_utc":1753118504,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dfbz5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Esshwar123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4cd2af","score":1,"author_fullname":"t2_woofa4j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah I see, but there isn't any final answer tool or anything in the tools.json either so I got confused","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dfbz5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah I see, but there isn&amp;#39;t any final answer tool or anything in the tools.json either so I got confused&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4dfbz5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753117739,"author_flair_text":null,"treatment_tags":[],"created_utc":1753117739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4cd2af","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Senior-City-7058","can_mod_post":false,"created_utc":1753106716,"send_replies":true,"parent_id":"t1_n4c09y5","score":2,"author_fullname":"t2_9pp1z7ay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I know a basic React agent tells the model to return a “final answer” once the model can reason about its progress and whether a final answer has been found. You then write some logic in code to check if final answer is in the output, stop the loop","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4cd2af","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know a basic React agent tells the model to return a “final answer” once the model can reason about its progress and whether a final answer has been found. You then write some logic in code to check if final answer is in the output, stop the loop&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5gwzs","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4cd2af/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753106716,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4c09y5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Esshwar123","can_mod_post":false,"created_utc":1753102502,"send_replies":true,"parent_id":"t3_1m5gwzs","score":0,"author_fullname":"t2_woofa4j","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is really insane, btw got some questions, I noticed for the agent prompts they didn't really specify when to stop the loop? How does that work, do they have like some schema sent that includes when to stop the loop?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4c09y5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is really insane, btw got some questions, I noticed for the agent prompts they didn&amp;#39;t really specify when to stop the loop? How does that work, do they have like some schema sent that includes when to stop the loop?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4c09y5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102502,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ees03","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HeadSmile8194","can_mod_post":false,"created_utc":1753127651,"send_replies":true,"parent_id":"t3_1m5gwzs","score":-1,"author_fullname":"t2_eud20c9q","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I feel like system prompt is the biggest scam ever\\nIs it real thing? If so how can I extract it? Why should I trust that the llm is aware of it's prompt?..some people say it's not a real thing and that the actual system prompt is  leaked by the actual company who created those and not by random people manipulation...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ees03","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I feel like system prompt is the biggest scam ever\\nIs it real thing? If so how can I extract it? Why should I trust that the llm is aware of it&amp;#39;s prompt?..some people say it&amp;#39;s not a real thing and that the actual system prompt is  leaked by the actual company who created those and not by random people manipulation...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5gwzs/i_extracted_the_system_prompts_from_closedsource/n4ees03/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127651,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5gwzs","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
