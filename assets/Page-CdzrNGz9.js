import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"New qwen tested on Fiction.liveBench","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1m6172l","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.92,"author_flair_background_color":null,"ups":99,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_7pfgfkis","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":99,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/TLf5BqdXyD8b18S_CjlBuka8R6DaWW-Nnyc_DD4KFcw.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753148000,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/9rynne03xbef1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/9rynne03xbef1.png?auto=webp&amp;s=4f7e2275d4e835b0f01387fc4e2f5de4682c92f8","width":1520,"height":2266},"resolutions":[{"url":"https://preview.redd.it/9rynne03xbef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c72f32848579ff8381bbc07e00d52af73ccb790","width":108,"height":161},{"url":"https://preview.redd.it/9rynne03xbef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c05a3489ce34f1c0d3c48da6ac4fb493a3af2239","width":216,"height":322},{"url":"https://preview.redd.it/9rynne03xbef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7758dc0729434a0929fb46f9640d8ed72e9ba4f","width":320,"height":477},{"url":"https://preview.redd.it/9rynne03xbef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8cc832729da290425257b97f9e8171f9cd64ec1e","width":640,"height":954},{"url":"https://preview.redd.it/9rynne03xbef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1dd97abb7b7a97ba53a5a60797a4df72dbe1e9e","width":960,"height":1431},{"url":"https://preview.redd.it/9rynne03xbef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=51749430f3b47afde5a4eee467854e441af14310","width":1080,"height":1610}],"variants":{},"id":"OE4XOhVwW7bVZ94xo4IF074gf7GQOtJgsoNbI-IyttA"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1m6172l","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"fictionlive","discussion_type":null,"num_comments":35,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/","stickied":false,"url":"https://i.redd.it/9rynne03xbef1.png","subreddit_subscribers":503254,"created_utc":1753148000,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4irg9c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4gneyk","score":1,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So they are not ditching their own architecture because a nonthinking model came up, good. So this is more of an experiment to see how Qwen can be when purely nonthinking.","edited":false,"author_flair_css_class":null,"name":"t1_n4irg9c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So they are not ditching their own architecture because a nonthinking model came up, good. So this is more of an experiment to see how Qwen can be when purely nonthinking.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6172l","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4irg9c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753190415,"author_flair_text":null,"collapsed":false,"created_utc":1753190415,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4gneyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4g8gnp","score":11,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wait a little bit for the thinking version then.  This one is explicitly non-thinking.  It's comparable to V3 or Kimi where it scores similarly but a bit worse - very much in line with being ~1/3 the weights and ~2/3 the active parameters. Unlike those two, though, it goes beyond 120k context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gneyk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait a little bit for the thinking version then.  This one is explicitly non-thinking.  It&amp;#39;s comparable to V3 or Kimi where it scores similarly but a bit worse - very much in line with being ~1/3 the weights and ~2/3 the active parameters. Unlike those two, though, it goes beyond 120k context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gneyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753154190,"author_flair_text":null,"treatment_tags":[],"created_utc":1753154190,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gvyx1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Capable-Ad-7494","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4g8gnp","score":4,"author_fullname":"t2_9so78ol2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"One up kimi? it’s a 5th of the size?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gvyx1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One up kimi? it’s a 5th of the size?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gvyx1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753157768,"author_flair_text":null,"treatment_tags":[],"created_utc":1753157768,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n4g8gnp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4g85fb","score":8,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not much of an improvement now, is it? Should have improved its thinking instead of trying to one-up Kimi, Qwennie. Lol","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4g8gnp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not much of an improvement now, is it? Should have improved its thinking instead of trying to one-up Kimi, Qwennie. Lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4g8gnp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753148689,"author_flair_text":null,"treatment_tags":[],"created_utc":1753148689,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gwef1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lordpuddingcup","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4g85fb","score":1,"author_fullname":"t2_vc4z2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ya seems bad I mean I know it’s not a reasoning model but eww","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4gwef1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ya seems bad I mean I know it’s not a reasoning model but eww&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gwef1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753157959,"author_flair_text":null,"treatment_tags":[],"created_utc":1753157959,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4g85fb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fractalcrust","can_mod_post":false,"created_utc":1753148583,"send_replies":true,"parent_id":"t1_n4g7l09","score":54,"author_fullname":"t2_17psnpt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it looks bad","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4g85fb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it looks bad&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4g85fb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753148583,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4lwo3i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4lgm7e","score":1,"author_fullname":"t2_9xer9y5w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it's logical that thinking models are supposed to (think) producing better results.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4lwo3i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s logical that thinking models are supposed to (think) producing better results.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6172l","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4lwo3i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753222574,"author_flair_text":null,"treatment_tags":[],"created_utc":1753222574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4lgm7e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pvt_Twinkietoes","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4jk8h8","score":1,"author_fullname":"t2_3k9qfjsr","approved_by":null,"mod_note":null,"all_awardings":[],"body":"And made you say \\"of course she, because of non-thinoking'\\" with such confidence","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4lgm7e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And made you say &amp;quot;of course she, because of non-thinoking&amp;#39;&amp;quot; with such confidence&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m6172l","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4lgm7e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753217785,"author_flair_text":null,"treatment_tags":[],"created_utc":1753217785,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4jk8h8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4iz5sn","score":1,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No idea, not an ai expert.","edited":false,"author_flair_css_class":null,"name":"t1_n4jk8h8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No idea, not an ai expert.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m6172l","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4jk8h8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753198799,"author_flair_text":null,"collapsed":false,"created_utc":1753198799,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4iz5sn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pvt_Twinkietoes","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4iw3yd","score":1,"author_fullname":"t2_3k9qfjsr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hmmm I wonder if it's because that \\"thinking\\" forces the model to get better at handle long context since \\"thinking\\" generates far more tokens.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4iz5sn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmmm I wonder if it&amp;#39;s because that &amp;quot;thinking&amp;quot; forces the model to get better at handle long context since &amp;quot;thinking&amp;quot; generates far more tokens.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4iz5sn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753192841,"author_flair_text":null,"treatment_tags":[],"created_utc":1753192841,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4iw3yd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ivppw","score":1,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"of course, because nonthinking, and not enough mass behind it (Kimi K2)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4iw3yd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;of course, because nonthinking, and not enough mass behind it (Kimi K2)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4iw3yd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753191915,"author_flair_text":null,"treatment_tags":[],"created_utc":1753191915,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ivppw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pvt_Twinkietoes","can_mod_post":false,"created_utc":1753191789,"send_replies":true,"parent_id":"t1_n4g7l09","score":3,"author_fullname":"t2_3k9qfjsr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looks like it got worse?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ivppw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like it got worse?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4ivppw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753191789,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4irm8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silver-Champion-4846","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ip4ed","score":1,"author_fullname":"t2_9xer9y5w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hmm, so tldr: bad?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4irm8t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmm, so tldr: bad?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4irm8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753190469,"author_flair_text":null,"treatment_tags":[],"created_utc":1753190469,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ip4ed","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robertotomas","can_mod_post":false,"created_utc":1753189638,"send_replies":true,"parent_id":"t1_n4g7l09","score":1,"author_fullname":"t2_65zz9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The testing itself looks incomplete. They only tested through 16k. Base ggufs support 32k and the ones with yarn long context blocks with rope scaling support 128k. (EDIT: that’s apparently because the “seed data” is in addition to context “filler” in the test, and these numbers reflect filler data with 1k-8k seed data.) Interestingly the &lt;=14b start to do poor even at 16k and the small moe does bad with any context at all. I can say that the qwen team have repeatedly claimed (or patiently reminded, i guess is the better term) to the effect that not testing with rope-enabled models should *improve* the performance in the smaller context.\\n\\nMost of them get less than 100% with no context, suggesting they fundamentally are not well measured by this benchmark. (In that, i would expect that either it should be recall-based and so always 100% with no filler, or logical/recall and so some questions complex enough that no model gets 100% with no filler - orherwise we make assumptions about what demands are acceptable to make of the reader)\\n\\nEdit 2: They note:\\n\\n- Qwen-max is good at the small context windows where we have data. qwq is great, better than R1.\\n- Qwen3 does not beat qwq-32b but is competitive against other models from other companies.\\n\\nhttps://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87","edited":1753190725,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ip4ed","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The testing itself looks incomplete. They only tested through 16k. Base ggufs support 32k and the ones with yarn long context blocks with rope scaling support 128k. (EDIT: that’s apparently because the “seed data” is in addition to context “filler” in the test, and these numbers reflect filler data with 1k-8k seed data.) Interestingly the &amp;lt;=14b start to do poor even at 16k and the small moe does bad with any context at all. I can say that the qwen team have repeatedly claimed (or patiently reminded, i guess is the better term) to the effect that not testing with rope-enabled models should &lt;em&gt;improve&lt;/em&gt; the performance in the smaller context.&lt;/p&gt;\\n\\n&lt;p&gt;Most of them get less than 100% with no context, suggesting they fundamentally are not well measured by this benchmark. (In that, i would expect that either it should be recall-based and so always 100% with no filler, or logical/recall and so some questions complex enough that no model gets 100% with no filler - orherwise we make assumptions about what demands are acceptable to make of the reader)&lt;/p&gt;\\n\\n&lt;p&gt;Edit 2: They note:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Qwen-max is good at the small context windows where we have data. qwq is great, better than R1.&lt;/li&gt;\\n&lt;li&gt;Qwen3 does not beat qwq-32b but is competitive against other models from other companies.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87\\"&gt;https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4ip4ed/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753189638,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4g7l09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Silver-Champion-4846","can_mod_post":false,"created_utc":1753148391,"send_replies":true,"parent_id":"t3_1m6172l","score":47,"author_fullname":"t2_9xer9y5w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can you summarize what it says? I'm blind and can't read images.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4g7l09","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you summarize what it says? I&amp;#39;m blind and can&amp;#39;t read images.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4g7l09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753148391,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4h9xli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LinkSea8324","can_mod_post":false,"created_utc":1753164535,"send_replies":true,"parent_id":"t3_1m6172l","score":17,"author_fullname":"t2_152zyn72n4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fucking hell why can't he learn how to make tables in HTML/Markdown","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4h9xli","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fucking hell why can&amp;#39;t he learn how to make tables in HTML/Markdown&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4h9xli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753164535,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ggl8g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NixTheFolf","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4gfl1e","score":5,"author_fullname":"t2_x8oqwupf0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It could possibly be related to how much a model outputs normally? Not entirely sure, but given that QWQ was known for having very long reasoning chains, it makes sense that those long reasoning chains helped greatly in terms of long context performance during training.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ggl8g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It could possibly be related to how much a model outputs normally? Not entirely sure, but given that QWQ was known for having very long reasoning chains, it makes sense that those long reasoning chains helped greatly in terms of long context performance during training.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4ggl8g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753151580,"author_flair_text":null,"treatment_tags":[],"created_utc":1753151580,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4gfl1e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"triynizzles1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4galtz","score":5,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does make me wonder why qwen is a clear step back in long context performance. Both have thinking capabilities.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4gfl1e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does make me wonder why qwen is a clear step back in long context performance. Both have thinking capabilities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gfl1e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753151207,"author_flair_text":null,"treatment_tags":[],"created_utc":1753151207,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n4galtz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NixTheFolf","can_mod_post":false,"created_utc":1753149427,"send_replies":true,"parent_id":"t1_n4g8wkh","score":14,"author_fullname":"t2_x8oqwupf0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Really goes to show how training reasoning into a model can really improve the long context performance! I wonder if reinforcement learning can be used for context improvement instead of reasoning, which could help allow non-reasoning models to have extremely strong context.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4galtz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really goes to show how training reasoning into a model can really improve the long context performance! I wonder if reinforcement learning can be used for context improvement instead of reasoning, which could help allow non-reasoning models to have extremely strong context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4galtz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753149427,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gbjhd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ForsookComparison","can_mod_post":false,"created_utc":1753149752,"send_replies":true,"parent_id":"t1_n4g8wkh","score":9,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"QwQ's reasoning tokens basically regurgitate the book line by line as it reads. Of course it's going to good on fiction bench if you let it run long enough","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gbjhd","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;QwQ&amp;#39;s reasoning tokens basically regurgitate the book line by line as it reads. Of course it&amp;#39;s going to good on fiction bench if you let it run long enough&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gbjhd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753149752,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"n4g8wkh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"triynizzles1","can_mod_post":false,"created_utc":1753148840,"send_replies":true,"parent_id":"t3_1m6172l","score":30,"author_fullname":"t2_zr0g49ixt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"QWQ still goated in open source models out to 60k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4g8wkh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;QWQ still goated in open source models out to 60k&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4g8wkh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753148840,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gdjbj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mtmttuan","can_mod_post":false,"created_utc":1753150463,"send_replies":true,"parent_id":"t3_1m6172l","score":14,"author_fullname":"t2_6mjqz0at","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is just nit picking but you can improve visibility by adding bolder outline or something to indicate the model that you're showing us. Like it took me 1 or 2 sec to scan for the qwen part and just to found no new model. You're posting a table full of text and it's really hard to know what you're trying to show.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gdjbj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is just nit picking but you can improve visibility by adding bolder outline or something to indicate the model that you&amp;#39;re showing us. Like it took me 1 or 2 sec to scan for the qwen part and just to found no new model. You&amp;#39;re posting a table full of text and it&amp;#39;s really hard to know what you&amp;#39;re trying to show.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gdjbj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753150463,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gd60h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OmarBessa","can_mod_post":false,"created_utc":1753150332,"send_replies":true,"parent_id":"t3_1m6172l","score":12,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"at this point i only want a new QwQ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gd60h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;at this point i only want a new QwQ&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gd60h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753150332,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4i68dk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1753182352,"send_replies":true,"parent_id":"t1_n4hf1ld","score":2,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Maybe there's a simple way of undoing this change\\n\\nYea.. I hope so. I only used the ~32k model before. I like the slight bump in trivia of the new one and never used the thinking. \\n\\nGGUF you have to edit metadata and resave or put it on the command line vs just changing a number in the config file :(","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4i68dk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Maybe there&amp;#39;s a simple way of undoing this change&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yea.. I hope so. I only used the ~32k model before. I like the slight bump in trivia of the new one and never used the thinking. &lt;/p&gt;\\n\\n&lt;p&gt;GGUF you have to edit metadata and resave or put it on the command line vs just changing a number in the config file :(&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4i68dk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753182352,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4hf1ld","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Chromix_","can_mod_post":false,"created_utc":1753167303,"send_replies":true,"parent_id":"t3_1m6172l","score":8,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks a lot for the timely testing of new models! The score dropped a lot. Aside from non-thinking I see two alternative explanations here:\\n\\n1) There are issues with the prompt template ([unsloth has a fix](https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF)). Even a single additional whitespace in the template will degrade the scores. Maybe the issue they fixed also impacts performance.\\n\\n2) The context size was increased to 262144 from 40960 of the previous model version. This looks like the kind of scaling done using RoPE / YaRN, which reduces model performance even at small context sizes. That's why you usually only extrapolate the context size when needed. Maybe there's a simple way of undoing this change, running the model with a smaller RoPE Theta, shorter context and getting better results.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hf1ld","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks a lot for the timely testing of new models! The score dropped a lot. Aside from non-thinking I see two alternative explanations here:&lt;/p&gt;\\n\\n&lt;p&gt;1) There are issues with the prompt template (&lt;a href=\\"https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF\\"&gt;unsloth has a fix&lt;/a&gt;). Even a single additional whitespace in the template will degrade the scores. Maybe the issue they fixed also impacts performance.&lt;/p&gt;\\n\\n&lt;p&gt;2) The context size was increased to 262144 from 40960 of the previous model version. This looks like the kind of scaling done using RoPE / YaRN, which reduces model performance even at small context sizes. That&amp;#39;s why you usually only extrapolate the context size when needed. Maybe there&amp;#39;s a simple way of undoing this change, running the model with a smaller RoPE Theta, shorter context and getting better results.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4hf1ld/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753167303,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4h4xmw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1753161953,"send_replies":true,"parent_id":"t1_n4ga4sf","score":8,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not a 1-to-1 comparison, but disabling thinking will destroy the long-context following of Gemini models too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4h4xmw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not a 1-to-1 comparison, but disabling thinking will destroy the long-context following of Gemini models too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4h4xmw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753161953,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4hhryq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1753168816,"send_replies":true,"parent_id":"t1_n4ga4sf","score":2,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma is not \\"average\\" it is awful st long context. Deepseek is average.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hhryq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma is not &amp;quot;average&amp;quot; it is awful st long context. Deepseek is average.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4hhryq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753168816,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ga4sf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NixTheFolf","can_mod_post":false,"created_utc":1753149263,"send_replies":true,"parent_id":"t3_1m6172l","score":15,"author_fullname":"t2_x8oqwupf0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It makes sense that reasoning models have a better grasp on context because of the long reasoning chains they learn and minute details within them that they have to pull out to get a correct answer.\\n\\nFrom the looks of it, since Qwen3-235B-A22B-Instruct-2507 is a pure non-reasoning model, comparing it to other similar models shows it is about average in that department for context performance. It is a bit worse than Deepseek V3-0324, but similar when it comes to Gemma 3 27B.\\n\\nA bit sad to see the context performance being between eh and average, as well as some of the benchmarks like the massive boost in SimpleQA being suspicious. I have yet to personally try this model, but I will in the coming hours and will test it myself. It is the perfect size for my 128GB RAM and 2x 3090 system, and I did enjoy the older model with non-thinking. So for me, as long as the performance is better in my own vibe checks, even just a little bit, then I will be happy.","edited":1753149799,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ga4sf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It makes sense that reasoning models have a better grasp on context because of the long reasoning chains they learn and minute details within them that they have to pull out to get a correct answer.&lt;/p&gt;\\n\\n&lt;p&gt;From the looks of it, since Qwen3-235B-A22B-Instruct-2507 is a pure non-reasoning model, comparing it to other similar models shows it is about average in that department for context performance. It is a bit worse than Deepseek V3-0324, but similar when it comes to Gemma 3 27B.&lt;/p&gt;\\n\\n&lt;p&gt;A bit sad to see the context performance being between eh and average, as well as some of the benchmarks like the massive boost in SimpleQA being suspicious. I have yet to personally try this model, but I will in the coming hours and will test it myself. It is the perfect size for my 128GB RAM and 2x 3090 system, and I did enjoy the older model with non-thinking. So for me, as long as the performance is better in my own vibe checks, even just a little bit, then I will be happy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4ga4sf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753149263,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gepgb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"koushd","can_mod_post":false,"created_utc":1753150887,"send_replies":true,"parent_id":"t3_1m6172l","score":8,"author_fullname":"t2_4yut6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"sudden bump at 120k. and absurdly low at 400, like comically bad. these numbers seem off.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gepgb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;sudden bump at 120k. and absurdly low at 400, like comically bad. these numbers seem off.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gepgb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753150887,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gr3rl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Faze-MeCarryU30","can_mod_post":false,"created_utc":1753155700,"send_replies":true,"parent_id":"t3_1m6172l","score":4,"author_fullname":"t2_3y1f7as1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"100% accuracy up to 8k context would have been insane 2 years ago, it's insane how far we've come. like getting full performance up to 8 thousand tokens is genuinely insane","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gr3rl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;100% accuracy up to 8k context would have been insane 2 years ago, it&amp;#39;s insane how far we&amp;#39;ve come. like getting full performance up to 8 thousand tokens is genuinely insane&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gr3rl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753155700,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ihr4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tarruda","can_mod_post":false,"created_utc":1753187058,"send_replies":true,"parent_id":"t1_n4gcrk6","score":1,"author_fullname":"t2_dphk4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The thinking version will surpass it in tasks which benefit from thinking. IIRC the previous 235b version did better in aider benchmark with thinking disabled.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ihr4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The thinking version will surpass it in tasks which benefit from thinking. IIRC the previous 235b version did better in aider benchmark with thinking disabled.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4ihr4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753187058,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4gcrk6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HomeBrewUser","can_mod_post":false,"created_utc":1753150189,"send_replies":true,"parent_id":"t3_1m6172l","score":1,"author_fullname":"t2_ddyduwi7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The 60 at 120k just shows me that they trained it on long context data to be \\"good\\" at long context while neglecting everything else pretty much. That being said, I think the reasoning version has the potential to be the best open model yet, maybe finally dethroning QwQ here.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gcrk6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The 60 at 120k just shows me that they trained it on long context data to be &amp;quot;good&amp;quot; at long context while neglecting everything else pretty much. That being said, I think the reasoning version has the potential to be the best open model yet, maybe finally dethroning QwQ here.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gcrk6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753150189,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4k6flw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bulky_Maize_5218","can_mod_post":false,"created_utc":1753204916,"send_replies":true,"parent_id":"t3_1m6172l","score":1,"author_fullname":"t2_14eaf3pxd6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"well, it was so bad for that purpose that i could've told you that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4k6flw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;well, it was so bad for that purpose that i could&amp;#39;ve told you that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4k6flw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753204916,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4gay3n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fictionlive","can_mod_post":false,"created_utc":1753149546,"send_replies":true,"parent_id":"t1_n4g96g2","score":15,"author_fullname":"t2_7pfgfkis","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's the name on openrouter, blame them https://openrouter.ai/qwen/qwen3-235b-a22b-07-25:free","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4gay3n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s the name on openrouter, blame them &lt;a href=\\"https://openrouter.ai/qwen/qwen3-235b-a22b-07-25:free\\"&gt;https://openrouter.ai/qwen/qwen3-235b-a22b-07-25:free&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m6172l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4gay3n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753149546,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n4g96g2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1753148935,"send_replies":true,"parent_id":"t3_1m6172l","score":-6,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Can't trust your benchmark if you can't even name the model correctly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4g96g2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can&amp;#39;t trust your benchmark if you can&amp;#39;t even name the model correctly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m6172l/new_qwen_tested_on_fictionlivebench/n4g96g2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753148935,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m6172l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
