import{j as e}from"./index-Ce60G8KS.js";import{R as t}from"./RedditPostRenderer-Dxoi04TZ.js";import"./index-D3PeynhN.js";const a=[{kind:"Listing",data:{after:null,dist:1,modhash:"",geo_filter:"",children:[{kind:"t3",data:{approved_at_utc:null,subreddit:"LocalLLaMA",selftext:"I used 1500 rows from this dataset [https://huggingface.co/datasets/Pravincoder/law\\_llm\\_dataSample](https://huggingface.co/datasets/Pravincoder/law_llm_dataSample) to fine tune the unsloth/Llama-3.2-3B-Instruct model using Unsloth notebook. When running 10 epochs, the loss decreased from 1.65 to 0.2, but after running the test, the result was not the same as in the train set. I tried a few questions, the model answered incorrectly and made up answers. Can you tell me how to fine tune so that the model answers correctly? Thank you.",user_reports:[],saved:!1,mod_reason_title:null,gilded:0,clicked:!1,title:"Hi everyone, I have a problem with fine tuning LLM on law",link_flair_richtext:[{e:"text",t:"Question | Help"}],subreddit_name_prefixed:"r/LocalLLaMA",hidden:!1,pwls:6,link_flair_css_class:"",downs:0,thumbnail_height:null,top_awarded_type:null,hide_score:!0,name:"t3_1lmjs43",quarantine:!1,link_flair_text_color:"dark",upvote_ratio:.5,author_flair_background_color:null,subreddit_type:"public",ups:0,total_awards_received:0,media_embed:{},thumbnail_width:null,author_flair_template_id:null,is_original_content:!1,author_fullname:"t2_1sfgh26ksb",secure_media:null,is_reddit_media_domain:!1,is_meta:!1,category:null,secure_media_embed:{},link_flair_text:"Question | Help",can_mod_post:!1,score:0,approved_by:null,is_created_from_ads_ui:!1,author_premium:!1,thumbnail:"self",edited:!1,author_flair_css_class:null,author_flair_richtext:[],gildings:{},post_hint:"self",content_categories:null,is_self:!0,mod_note:null,created:1751107228,link_flair_type:"richtext",wls:6,removed_by_category:null,banned_by:null,author_flair_type:"text",domain:"self.LocalLLaMA",allow_live_comments:!1,selftext_html:`&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I used 1500 rows from this dataset &lt;a href="https://huggingface.co/datasets/Pravincoder/law_llm_dataSample"&gt;https://huggingface.co/datasets/Pravincoder/law_llm_dataSample&lt;/a&gt; to fine tune the unsloth/Llama-3.2-3B-Instruct model using Unsloth notebook. When running 10 epochs, the loss decreased from 1.65 to 0.2, but after running the test, the result was not the same as in the train set. I tried a few questions, the model answered incorrectly and made up answers. Can you tell me how to fine tune so that the model answers correctly? Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;`,likes:null,suggested_sort:null,banned_at_utc:null,view_count:null,archived:!1,no_follow:!0,is_crosspostable:!1,pinned:!1,over_18:!1,preview:{images:[{source:{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?auto=webp&amp;s=76673771e9889715017ba58928091766275dca59",width:1200,height:648},resolutions:[{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4322d88a09a0c1aeb52f783f62f28db0a13a24ac",width:108,height:58},{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d59ad96efbfa5b93fa4bb271b67dd28b6797c94a",width:216,height:116},{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5dcfc6eebd13b233b0d2b21a497c425b9c6669a5",width:320,height:172},{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b102bbcdeb89b8153608077988448d71d2b8b5ab",width:640,height:345},{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=573981e9b4591093a8fc74aeccc59dc3e37d0119",width:960,height:518},{url:"https://external-preview.redd.it/Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2dfe468f1877febe9cd4de64d0e95e968dbb7fa6",width:1080,height:583}],variants:{},id:"Ui67_vJAnZ8n21iF9KGXDPxF7y-gH_ecZvo7GY5JO24"}],enabled:!1},all_awardings:[],awarders:[],media_only:!1,link_flair_template_id:"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",can_gild:!1,spoiler:!1,locked:!1,author_flair_text:null,treatment_tags:[],visited:!1,removed_by:null,num_reports:null,distinguished:null,subreddit_id:"t5_81eyvm",author_is_blocked:!1,mod_reason_by:null,removal_reason:null,link_flair_background_color:"#5a74cc",id:"1lmjs43",is_robot_indexable:!0,num_duplicates:0,report_reasons:null,author:"Winter_Address2969",discussion_type:null,num_comments:0,send_replies:!0,media:null,contest_mode:!1,author_patreon_flair:!1,author_flair_text_color:null,permalink:"/r/LocalLLaMA/comments/1lmjs43/hi_everyone_i_have_a_problem_with_fine_tuning_llm/",stickied:!1,url:"https://www.reddit.com/r/LocalLLaMA/comments/1lmjs43/hi_everyone_i_have_a_problem_with_fine_tuning_llm/",subreddit_subscribers:492232,created_utc:1751107228,num_crossposts:0,mod_reports:[],is_video:!1}}],before:null}},{kind:"Listing",data:{after:null,dist:null,modhash:"",geo_filter:"",children:[],before:null}}],r=()=>e.jsx(t,{data:a});export{r as default};
