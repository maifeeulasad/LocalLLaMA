import{j as l}from"./index-DFOnUtq9.js";import{R as e}from"./RedditPostRenderer-B-dx19nm.js";import"./index-CUOQn61u.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Yay! Been waiting for this one for a while, guessing I'm not the only one?\\n[https://github.com/vllm-project/vllm/pull/17280](https://github.com/vllm-project/vllm/pull/17280)\\n\\nOn 70B I'm maxing out around 1400T/s on the Pro 6000 with 100 threads.\\n\\n\\n\\n\\n\\nQuick install instructions if you want to try it:\\n\\n\\n\\nmkdir vllm-src  \\ncd vllm-src  \\npython3 -m venv myenv  \\nsource myenv/bin/activate  \\npip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu128](https://download.pytorch.org/whl/cu128)  \\ngit clone [https://github.com/huggingface/transformers.git](https://github.com/huggingface/transformers.git)  \\ngit clone [https://github.com/vllm-project/vllm.git](https://github.com/vllm-project/vllm.git)  \\ncd transformers  \\npip install -e .  \\ncd ../vllm  \\npython use\\\\_existing\\\\_torch.py  \\npip install -r requirements/build.txt  \\npip install -r requirements/cuda.txt  \\npip install -e . --no-build-isolation  \\nvllm serve RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic  \\nvllm serve RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic --max-model-len 8000  ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"FP8 fixed on VLLM for RTX Pro 6000 (and RTX 5000 desktop cards)","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lq79xx","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.93,"author_flair_background_color":null,"subreddit_type":"public","ups":50,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_9hl4ymvj","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":50,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751493785,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751490166,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Yay! Been waiting for this one for a while, guessing I&amp;#39;m not the only one?\\n&lt;a href=\\"https://github.com/vllm-project/vllm/pull/17280\\"&gt;https://github.com/vllm-project/vllm/pull/17280&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;On 70B I&amp;#39;m maxing out around 1400T/s on the Pro 6000 with 100 threads.&lt;/p&gt;\\n\\n&lt;p&gt;Quick install instructions if you want to try it:&lt;/p&gt;\\n\\n&lt;p&gt;mkdir vllm-src&lt;br/&gt;\\ncd vllm-src&lt;br/&gt;\\npython3 -m venv myenv&lt;br/&gt;\\nsource myenv/bin/activate&lt;br/&gt;\\npip install torch torchvision torchaudio --index-url &lt;a href=\\"https://download.pytorch.org/whl/cu128\\"&gt;https://download.pytorch.org/whl/cu128&lt;/a&gt;&lt;br/&gt;\\ngit clone &lt;a href=\\"https://github.com/huggingface/transformers.git\\"&gt;https://github.com/huggingface/transformers.git&lt;/a&gt;&lt;br/&gt;\\ngit clone &lt;a href=\\"https://github.com/vllm-project/vllm.git\\"&gt;https://github.com/vllm-project/vllm.git&lt;/a&gt;&lt;br/&gt;\\ncd transformers&lt;br/&gt;\\npip install -e .&lt;br/&gt;\\ncd ../vllm&lt;br/&gt;\\npython use_existing_torch.py&lt;br/&gt;\\npip install -r requirements/build.txt&lt;br/&gt;\\npip install -r requirements/cuda.txt&lt;br/&gt;\\npip install -e . --no-build-isolation&lt;br/&gt;\\nvllm serve RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic&lt;br/&gt;\\nvllm serve RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic --max-model-len 8000  &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?auto=webp&amp;s=1fd49f52128f28276a9c3c68af9e44fdad153b60","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ca1383baae7b6b423ab28be5aa67c437fc35d82","width":108,"height":54},{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=956653e6b1a4f46fc6ca33cac434e66b784cead1","width":216,"height":108},{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=492af444cd23147c8e4b5d077cb10778a32e9013","width":320,"height":160},{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd275d8b8a4e92c894a1ce9e9acaac8850dbcf46","width":640,"height":320},{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4b6c033a53916e713ab613f45a38513898643074","width":960,"height":480},{"url":"https://external-preview.redd.it/R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=360efab2869f72fe40846702b38102749bc6fff6","width":1080,"height":540}],"variants":{},"id":"R0YaLypW8v8YI57W9FPZsNuYoTjtBqD3Vh8AMMEsQF0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lq79xx","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Conscious_Cut_6144","discussion_type":null,"num_comments":23,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/","subreddit_subscribers":494198,"created_utc":1751490166,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10su9y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1751494132,"send_replies":true,"parent_id":"t3_1lq79xx","score":9,"author_fullname":"t2_qf8h7ka8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My word, that's fast.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10su9y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My word, that&amp;#39;s fast.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n10su9y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751494132,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10vadh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SashaUsesReddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n10uzuj","score":3,"author_fullname":"t2_57wafqev","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I patched a fix for nvfp4 on the current vllm git, but I haven't contributed it yet. Coming soon!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n10vadh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I patched a fix for nvfp4 on the current vllm git, but I haven&amp;#39;t contributed it yet. Coming soon!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n10vadh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751494933,"author_flair_text":null,"treatment_tags":[],"created_utc":1751494933,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n10uzuj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751494835,"send_replies":true,"parent_id":"t1_n10uoem","score":1,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice, fp4 will be my next endeavor","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10uzuj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice, fp4 will be my next endeavor&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n10uzuj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751494835,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n10uoem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SashaUsesReddit","can_mod_post":false,"created_utc":1751494732,"send_replies":true,"parent_id":"t3_1lq79xx","score":3,"author_fullname":"t2_57wafqev","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Was very happy to see this! \\n\\nAlso nvfp4 is working on the latest trtllm container","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10uoem","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Was very happy to see this! &lt;/p&gt;\\n\\n&lt;p&gt;Also nvfp4 is working on the latest trtllm container&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n10uoem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751494732,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14n4u2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"caetydid","can_mod_post":false,"created_utc":1751551413,"send_replies":true,"parent_id":"t3_1lq79xx","score":2,"author_fullname":"t2_2b6dk0nt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That means also for RTX5090! Good times are coming!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14n4u2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That means also for RTX5090! Good times are coming!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n14n4u2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751551413,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12e8wx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SashaUsesReddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n12ds9k","score":2,"author_fullname":"t2_57wafqev","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Vllm has some issues with tensor parallel right now on Blackwell with NCCL issues. Expect trouble","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n12e8wx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Vllm has some issues with tensor parallel right now on Blackwell with NCCL issues. Expect trouble&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n12e8wx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751513680,"author_flair_text":null,"treatment_tags":[],"created_utc":1751513680,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n12ds9k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751513490,"send_replies":true,"parent_id":"t1_n12cer0","score":1,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I only have 1 right now, but I would think so.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12ds9k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I only have 1 right now, but I would think so.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n12ds9k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751513490,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n12cer0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751512936,"send_replies":true,"parent_id":"t3_1lq79xx","score":1,"author_fullname":"t2_1rig07ocmc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"does it work with -tp 2 or 4 ? tensor parallelism?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12cer0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;does it work with -tp 2 or 4 ? tensor parallelism?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n12cer0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751512936,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n12ybec","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aroochacha","can_mod_post":false,"created_utc":1751522980,"send_replies":true,"parent_id":"t3_1lq79xx","score":1,"author_fullname":"t2_e0hy0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s fantastic.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12ybec","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s fantastic.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n12ybec/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751522980,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14y28n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751554633,"send_replies":true,"parent_id":"t1_n1361hf","score":1,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It wouldn't run, just threw an error complaining about missing a kernel.  \\nYa 1400 t/s gen, so 100 threads each getting 14 t/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14y28n","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It wouldn&amp;#39;t run, just threw an error complaining about missing a kernel.&lt;br/&gt;\\nYa 1400 t/s gen, so 100 threads each getting 14 t/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n14y28n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751554633,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1361hf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mr_Enzyme","can_mod_post":false,"created_utc":1751527226,"send_replies":true,"parent_id":"t3_1lq79xx","score":1,"author_fullname":"t2_93vtx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is that 1400 tokens/sec generation? Was it just broken before or significantly slower?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1361hf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is that 1400 tokens/sec generation? Was it just broken before or significantly slower?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n1361hf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751527226,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n14xal6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751554415,"send_replies":true,"parent_id":"t1_n13d5vu","score":2,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it's just a model that I know is well optimized for performance testing.  \\n  \\ndots.llm q4-k-xl is one possibility   \\nqwen2 coder, qwen3 32b  \\nOr maybe even UD-Q2\\\\_K\\\\_XL qwen 235b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n14xal6","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it&amp;#39;s just a model that I know is well optimized for performance testing.  &lt;/p&gt;\\n\\n&lt;p&gt;dots.llm q4-k-xl is one possibility&lt;br/&gt;\\nqwen2 coder, qwen3 32b&lt;br/&gt;\\nOr maybe even UD-Q2_K_XL qwen 235b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n14xal6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751554415,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n13d5vu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sorry_Ad191","can_mod_post":false,"created_utc":1751531380,"send_replies":true,"parent_id":"t3_1lq79xx","score":1,"author_fullname":"t2_1rig07ocmc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"so is Llama-3.3-70B-Instruct-FP8-dynamic the best model we can fit in 1x rtx 6000 pro 96gb now? or are there any other gode models? especially for coding in aider , roo code etc","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13d5vu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so is Llama-3.3-70B-Instruct-FP8-dynamic the best model we can fit in 1x rtx 6000 pro 96gb now? or are there any other gode models? especially for coding in aider , roo code etc&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n13d5vu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751531380,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n15but2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1309cj","score":2,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Should be within a few percent on smaller models.  \\n70b isn't going to fit on a 5090.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n15but2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should be within a few percent on smaller models.&lt;br/&gt;\\n70b isn&amp;#39;t going to fit on a 5090.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n15but2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751558506,"author_flair_text":null,"treatment_tags":[],"created_utc":1751558506,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1309cj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11f0h2","score":1,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same tokens per second?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1309cj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same tokens per second?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n1309cj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751524015,"author_flair_text":null,"treatment_tags":[],"created_utc":1751524015,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n11f0h2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751501384,"send_replies":true,"parent_id":"t1_n1180sk","score":5,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"First of all I have to say that Nvidia sucks at naming stuff...\\n\\nIf you are comparing an RTX 5090 to a Pro 6000 (both blackwell) then:  \\n5090 has about 10% less compute, same memory bandwidth, 1/3 memory amount.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11f0h2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;First of all I have to say that Nvidia sucks at naming stuff...&lt;/p&gt;\\n\\n&lt;p&gt;If you are comparing an RTX 5090 to a Pro 6000 (both blackwell) then:&lt;br/&gt;\\n5090 has about 10% less compute, same memory bandwidth, 1/3 memory amount.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n11f0h2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751501384,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n132i4v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henfiber","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1307mq","score":2,"author_fullname":"t2_lw9me25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Compared to the 6000 Pro, the 5000 Pro is 59% as fast in prompt processing (PP)  t/s, and 75% as fast in token generation (TG) t/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n132i4v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Compared to the 6000 Pro, the 5000 Pro is 59% as fast in prompt processing (PP)  t/s, and 75% as fast in token generation (TG) t/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n132i4v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751525241,"author_flair_text":null,"treatment_tags":[],"created_utc":1751525241,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1307mq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n11ag2p","score":1,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do these numbers translate to tokens per second?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1307mq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do these numbers translate to tokens per second?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n1307mq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751523990,"author_flair_text":null,"treatment_tags":[],"created_utc":1751523990,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n11ag2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"henfiber","can_mod_post":false,"created_utc":1751499918,"send_replies":true,"parent_id":"t1_n1180sk","score":3,"author_fullname":"t2_lw9me25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"59% compute throughput, 75% VRAM bandwidth, 50% VRAM size, 50% TDP\\n\\n[Specs](https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units#RTX_PRO_Blackwell_series)\\n\\n\\n\\nBonus - compared to previous 6000 Ada:   \\n81% compute, 140% VRAM bandwidth, same VRAM size, same TDP.","edited":1751500749,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n11ag2p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;59% compute throughput, 75% VRAM bandwidth, 50% VRAM size, 50% TDP&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units#RTX_PRO_Blackwell_series\\"&gt;Specs&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Bonus - compared to previous 6000 Ada:&lt;br/&gt;\\n81% compute, 140% VRAM bandwidth, same VRAM size, same TDP.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n11ag2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751499918,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13v5av","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"send_replies":true,"parent_id":"t1_n13j97c","score":1,"author_fullname":"t2_g8xg6sut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What??","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n13v5av","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What??&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n13v5av/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751541166,"author_flair_text":null,"treatment_tags":[],"created_utc":1751541166,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n13j97c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Xamanthas","can_mod_post":false,"created_utc":1751534946,"send_replies":true,"parent_id":"t1_n1180sk","score":1,"author_fullname":"t2_e6bnx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What on earth are you talking about dude. Deepseek effect","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13j97c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What on earth are you talking about dude. Deepseek effect&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lq79xx","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n13j97c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751534946,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1180sk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Forgot_Password_Dude","can_mod_post":false,"created_utc":1751499112,"send_replies":true,"parent_id":"t3_1lq79xx","score":1,"author_fullname":"t2_g8xg6sut","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Are 5000 series just as fast as 6000?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1180sk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are 5000 series just as fast as 6000?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lq79xx/fp8_fixed_on_vllm_for_rtx_pro_6000_and_rtx_5000/n1180sk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751499112,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lq79xx","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>l.jsx(e,{data:t});export{o as default};
