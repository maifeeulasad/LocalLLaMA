import{j as e}from"./index-BpC9hjVs.js";import{R as l}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const a=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"does this track with your experiences?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"LLM Hallucination Detection Leaderboard for both RAG and Chat","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1luybka","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.93,"author_flair_background_color":null,"ups":12,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_a69yx","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":12,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=b9671186a5dc7becd1fc7ef2212a568f9f350c4c","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752004003,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"huggingface.co","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;does this track with your experiences?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/spaces/kluster-ai/LLM-Hallucination-Detection-Leaderboard","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?auto=webp&amp;s=2c46870392bb29bae9141ee2fd627f4754c0a234","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e77c6a3e5ceaf4ca04c01c56574a179359a460b","width":108,"height":58},{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c8338670b61dbca485b97af21a49193266b4820","width":216,"height":116},{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=534146b0fcdb651c123a00976fdf0c37c5d5f82c","width":320,"height":172},{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=69ebf8eb874819abf47adedb14a04f419a0c710d","width":640,"height":345},{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee579ea39d3063e70b47139ceec3f47b5f29a8cf","width":960,"height":518},{"url":"https://external-preview.redd.it/ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5878c9347f3017b0440fe94efe8c2fd7072cd5aa","width":1080,"height":583}],"variants":{},"id":"ivBG2cnyJkFTv2OERYiecz9C9knlSS7GfSBDDNC5kNs"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1luybka","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"cakesir","discussion_type":null,"num_comments":5,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/","stickied":false,"url":"https://huggingface.co/spaces/kluster-ai/LLM-Hallucination-Detection-Leaderboard","subreddit_subscribers":496591,"created_utc":1752004003,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n22kfwa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waltercrypto","can_mod_post":false,"created_utc":1752013830,"send_replies":true,"parent_id":"t3_1luybka","score":2,"author_fullname":"t2_chwsdhpy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hmm I kinda think below 2% is acceptable but most models are above this. Kinda interesting that RAG is worse, you would think it would be the other way around. So when a model does an external search on the web the results are less accurate. Not surprising the web is full of crap.","edited":1752014157,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n22kfwa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmm I kinda think below 2% is acceptable but most models are above this. Kinda interesting that RAG is worse, you would think it would be the other way around. So when a model does an external search on the web the results are less accurate. Not surprising the web is full of crap.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/n22kfwa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752013830,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luybka","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n23151e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DinoAmino","can_mod_post":false,"created_utc":1752019172,"send_replies":true,"parent_id":"t3_1luybka","score":1,"author_fullname":"t2_j1v7f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does the HaluEval use a system prompt to instruct the model to only use the given context for its response? From the sound of it only the source doc and question are provided for the eval. Does that make this benchmark kind of  meaningless for real-world tasks that use a specialized system prompt for RAG?\\n\\nOr is this more of a marketing tool for the Verify service?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n23151e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does the HaluEval use a system prompt to instruct the model to only use the given context for its response? From the sound of it only the source doc and question are provided for the eval. Does that make this benchmark kind of  meaningless for real-world tasks that use a specialized system prompt for RAG?&lt;/p&gt;\\n\\n&lt;p&gt;Or is this more of a marketing tool for the Verify service?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/n23151e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752019172,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luybka","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24vblp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752045963,"send_replies":true,"parent_id":"t3_1luybka","score":1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"No. It does not track my experience. Lech Mazurs benchmark does, this one is disconnected from reality. Gemma 3 27b hallucinates badly at RAG, and it is laughable idea that Qwen2.5-7b-VL would have less factual hallucinations than Mistral Small 2501. Mistral has SimpleQA around 10, and qwens have notoriously low SimpleQA, around 3. Same for DS V3 0324 - SimpleQA is 27 (?) and Gemma 3 around 10.\\n\\nSpeaking of RAG, Mistral Small is much better at not hallucinating than any  Gemma, which is very sensitive to context interference.","edited":1752048310,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n24vblp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No. It does not track my experience. Lech Mazurs benchmark does, this one is disconnected from reality. Gemma 3 27b hallucinates badly at RAG, and it is laughable idea that Qwen2.5-7b-VL would have less factual hallucinations than Mistral Small 2501. Mistral has SimpleQA around 10, and qwens have notoriously low SimpleQA, around 3. Same for DS V3 0324 - SimpleQA is 27 (?) and Gemma 3 around 10.&lt;/p&gt;\\n\\n&lt;p&gt;Speaking of RAG, Mistral Small is much better at not hallucinating than any  Gemma, which is very sensitive to context interference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/n24vblp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752045963,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luybka","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2566ig","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"created_utc":1752052197,"send_replies":true,"parent_id":"t3_1luybka","score":1,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Will be interesting when theyve tested more than 15 models.\\n\\n\\nHunyuan A13B feels really bad in terms of hallucinations, but im not sure if its the llama.cpp implementation or quant or if its a model problem.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2566ig","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Will be interesting when theyve tested more than 15 models.&lt;/p&gt;\\n\\n&lt;p&gt;Hunyuan A13B feels really bad in terms of hallucinations, but im not sure if its the llama.cpp implementation or quant or if its a model problem.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/n2566ig/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752052197,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luybka","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n25a91g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Xamanthas","can_mod_post":false,"created_utc":1752054456,"send_replies":true,"parent_id":"t3_1luybka","score":0,"author_fullname":"t2_e6bnx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Have a look at HalluEval dataset (which is used for this). You will see there are lots of errors in it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25a91g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have a look at HalluEval dataset (which is used for this). You will see there are lots of errors in it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1luybka/llm_hallucination_detection_leaderboard_for_both/n25a91g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752054456,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1luybka","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]'),s=()=>e.jsx(l,{data:a});export{s as default};
