import{j as e}from"./index-C1Ow6vlP.js";import{R as t}from"./RedditPostRenderer-DsOAP7P6.js";import"./index-DduDModv.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi everyone! I've been building AI products for 9 years (at my own startup, then at Apple, now at a second startup) and learned a lot along the way. I’ve been talking to a bunch of folks about evals lately, and I’ve realized most people aren’t creating them because they don’t know how to get started.\\n\\n**TL;DR** You probably should setup your project for many small evals, and not try to create one big eval for product quality. If you can generate a new small/focused eval in under 10 mins, your team will create them when they spot issues, and your quality will get much better over time.\\n\\nAt a high level, here’s why this works:\\n\\n* The easier it is to add an eval, the more you’ll do it, and that improves quality. Small and focused evals are much easier to add than large multi-focus evals.\\n* Products change over time, so big evals are almost impossible to keep up to date.\\n* Small evals help you pinpoint errors, which makes them easier to fix.\\n* Different team members bring unique insights (PM, Eng, QA, DS, etc). Letting them all contribute to evals leads to higher quality AI systems.\\n\\n# Example\\n\\nHere’s an example of what I mean by “many small evals”. You can see the small evals are a lot more interesting than just the final total (+4%). You can break-out product goals or issues, track them separately and see exactly what breaks and when (kinda like unit tests + CI in software). In this case looking at overall alone (+4%), would hide really critical regressions (-18% in one area).\\n\\n|Many Small Eval Scorecard|Comparing Models|\\n|:-|:-|\\n|Clarify unclear requests|93% (+9%)|\\n|Refuse to discuss competitors|100% (+1%)|\\n|Reject toxic requests|100% (even)|\\n|Offer rebate before cancelation|72% (-18%)|\\n|Follow brand styleguide|85% (-1%)|\\n|Only link to official docs|99% (even)|\\n|Avoid 'clickbait' titles|96% (+5%)|\\n|Knowledge base retrieval recall|94% (+7%)|\\n|Overall|94% (+4%)|\\n\\nThe cost of getting started is also much lower: you can add small evals here and there. Over time you’ll build a comprehensive eval suite.\\n\\n# How to get started\\n\\n* **Setup a good eval tool**: to be fast an easy you need 1) synthetic eval data gen, 2) intuitive UI, 3) human preferences baselining, 4) rapid side-by-side comparisons of run-methods.\\n* **Teach your team to build evals**: a quick 30 mins is enough if your tool is intuitive.\\n* **Create a culture of evaluation**: continually encourage folks to create evals when they spot quality issues or fix bugs.\\n\\nI've been building a free and open tool called \\\\~[Kiln](https://getkiln.ai/)\\\\~ which makes this process easy. It includes:\\n\\n* Create new evals in a few clicks: LLM-as-Judge and G-Eval\\n* Synthetic data gen for eval and golden datasets\\n* Baseline LLM judges to human ratings\\n* Using evals to find the best way to run your AI workload (model/prompt/tunes)\\n* Completely free on Github!\\n\\nIf you want to check out the tool or our guides:\\n\\n* \\\\~[Kiln AI on Github - over 3800 stars](https://getkiln.ai/)\\\\~\\n* \\\\~[Our Evals Guide/Docs](https://docs.getkiln.ai/docs/evaluations)\\\\~\\n* \\\\~[Blog post on small evals vs large evals (same ideas as above in more depth)](https://getkiln.ai/blog/you_need_many_small_evals_for_ai_products)\\\\~\\n* \\\\~[Kiln AI - Overview and Docs](https://getkiln.ai/)\\\\~\\n\\nI'm happy to answer questions if anyone wants to dive deeper on specific aspects!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Many small evals are better than one big eval [techniques]","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lmmvmj","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.87,"author_flair_background_color":null,"subreddit_type":"public","ups":30,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_slbscky","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":30,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751117439,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;ve been building AI products for 9 years (at my own startup, then at Apple, now at a second startup) and learned a lot along the way. I’ve been talking to a bunch of folks about evals lately, and I’ve realized most people aren’t creating them because they don’t know how to get started.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; You probably should setup your project for many small evals, and not try to create one big eval for product quality. If you can generate a new small/focused eval in under 10 mins, your team will create them when they spot issues, and your quality will get much better over time.&lt;/p&gt;\\n\\n&lt;p&gt;At a high level, here’s why this works:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;The easier it is to add an eval, the more you’ll do it, and that improves quality. Small and focused evals are much easier to add than large multi-focus evals.&lt;/li&gt;\\n&lt;li&gt;Products change over time, so big evals are almost impossible to keep up to date.&lt;/li&gt;\\n&lt;li&gt;Small evals help you pinpoint errors, which makes them easier to fix.&lt;/li&gt;\\n&lt;li&gt;Different team members bring unique insights (PM, Eng, QA, DS, etc). Letting them all contribute to evals leads to higher quality AI systems.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;Example&lt;/h1&gt;\\n\\n&lt;p&gt;Here’s an example of what I mean by “many small evals”. You can see the small evals are a lot more interesting than just the final total (+4%). You can break-out product goals or issues, track them separately and see exactly what breaks and when (kinda like unit tests + CI in software). In this case looking at overall alone (+4%), would hide really critical regressions (-18% in one area).&lt;/p&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th align=\\"left\\"&gt;Many Small Eval Scorecard&lt;/th&gt;\\n&lt;th align=\\"left\\"&gt;Comparing Models&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Clarify unclear requests&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;93% (+9%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Refuse to discuss competitors&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;100% (+1%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Reject toxic requests&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;100% (even)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Offer rebate before cancelation&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;72% (-18%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Follow brand styleguide&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;85% (-1%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Only link to official docs&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;99% (even)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Avoid &amp;#39;clickbait&amp;#39; titles&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;96% (+5%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Knowledge base retrieval recall&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;94% (+7%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td align=\\"left\\"&gt;Overall&lt;/td&gt;\\n&lt;td align=\\"left\\"&gt;94% (+4%)&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n\\n&lt;p&gt;The cost of getting started is also much lower: you can add small evals here and there. Over time you’ll build a comprehensive eval suite.&lt;/p&gt;\\n\\n&lt;h1&gt;How to get started&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Setup a good eval tool&lt;/strong&gt;: to be fast an easy you need 1) synthetic eval data gen, 2) intuitive UI, 3) human preferences baselining, 4) rapid side-by-side comparisons of run-methods.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Teach your team to build evals&lt;/strong&gt;: a quick 30 mins is enough if your tool is intuitive.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Create a culture of evaluation&lt;/strong&gt;: continually encourage folks to create evals when they spot quality issues or fix bugs.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been building a free and open tool called ~&lt;a href=\\"https://getkiln.ai/\\"&gt;Kiln&lt;/a&gt;~ which makes this process easy. It includes:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Create new evals in a few clicks: LLM-as-Judge and G-Eval&lt;/li&gt;\\n&lt;li&gt;Synthetic data gen for eval and golden datasets&lt;/li&gt;\\n&lt;li&gt;Baseline LLM judges to human ratings&lt;/li&gt;\\n&lt;li&gt;Using evals to find the best way to run your AI workload (model/prompt/tunes)&lt;/li&gt;\\n&lt;li&gt;Completely free on Github!&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;If you want to check out the tool or our guides:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;~&lt;a href=\\"https://getkiln.ai/\\"&gt;Kiln AI on Github - over 3800 stars&lt;/a&gt;~&lt;/li&gt;\\n&lt;li&gt;~&lt;a href=\\"https://docs.getkiln.ai/docs/evaluations\\"&gt;Our Evals Guide/Docs&lt;/a&gt;~&lt;/li&gt;\\n&lt;li&gt;~&lt;a href=\\"https://getkiln.ai/blog/you_need_many_small_evals_for_ai_products\\"&gt;Blog post on small evals vs large evals (same ideas as above in more depth)&lt;/a&gt;~&lt;/li&gt;\\n&lt;li&gt;~&lt;a href=\\"https://getkiln.ai/\\"&gt;Kiln AI - Overview and Docs&lt;/a&gt;~&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I&amp;#39;m happy to answer questions if anyone wants to dive deeper on specific aspects!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?auto=webp&amp;s=7bf3b6f2e008a14e5a7ba350c22ca8c5004ad9f3","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f7d2c98f11ee7e007262b0eeb2d4b47eee7e6c7a","width":108,"height":54},{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d49c86458cbdc55e3fe6836414a1ca035ece6e47","width":216,"height":108},{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6149c2e8f6335454286c3bd3c60b56e48c098647","width":320,"height":160},{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=005c04f071aeac512fb86cbe0b68d4c96e240eb2","width":640,"height":320},{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9fad1801158405b14b9f822c0e790a9f6c66ed77","width":960,"height":480},{"url":"https://external-preview.redd.it/XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=38c507070bf86833470c0b58f74304a8227ad0cc","width":1080,"height":540}],"variants":{},"id":"XakaA1XhTLjl2Tl4uMyvMZIXSFLrVmJ26POYXKL-zXM"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lmmvmj","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"davernow","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/","subreddit_subscribers":492840,"created_utc":1751117439,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09qexa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sixx7","can_mod_post":false,"created_utc":1751130757,"send_replies":true,"parent_id":"t1_n09mxky","score":4,"author_fullname":"t2_jxjl6u","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I build agents and yes everything u/davernow listed applies.  A critical eval to add for agents is for tool calling.  Did the LLM call the correct tool/function with the correct inputs?   Beyond that,  you can think of each agent run as an extended LLM call.  You provide some input to the agent and eval the output","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09qexa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I build agents and yes everything &lt;a href=\\"/u/davernow\\"&gt;u/davernow&lt;/a&gt; listed applies.  A critical eval to add for agents is for tool calling.  Did the LLM call the correct tool/function with the correct inputs?   Beyond that,  you can think of each agent run as an extended LLM call.  You provide some input to the agent and eval the output&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmmvmj","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/n09qexa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751130757,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0a9x4k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"davernow","can_mod_post":false,"created_utc":1751136784,"send_replies":true,"parent_id":"t1_n09mxky","score":2,"author_fullname":"t2_slbscky","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same applies to agents. At two levels:\\n\\n1) have small evals for each part\\n2) break up your integration tests into smaller evals based on use case","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0a9x4k","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same applies to agents. At two levels:&lt;/p&gt;\\n\\n&lt;p&gt;1) have small evals for each part\\n2) break up your integration tests into smaller evals based on use case&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lmmvmj","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/n0a9x4k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751136784,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n09mxky","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Primary_Ad_689","can_mod_post":false,"created_utc":1751129692,"send_replies":true,"parent_id":"t3_1lmmvmj","score":2,"author_fullname":"t2_tpp2lpjh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"100% agree. Better to start small, even while prototyping.\\nThe industry is pushing towards agents. Do you have thoughts on this? Does the same apply here?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09mxky","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;100% agree. Better to start small, even while prototyping.\\nThe industry is pushing towards agents. Do you have thoughts on this? Does the same apply here?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/n09mxky/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751129692,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lmmvmj","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dgmy8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1751182703,"send_replies":true,"parent_id":"t3_1lmmvmj","score":2,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yep, I'll agree with all of that, and add that you'll also want short evals specific to skills of interest.\\n\\nWith one big eval, it's hard to tell which skills are being utilized, and how well.  If a test exercises one specific skill, it's easier to figure out what's going on.  It also makes comparing models on a skill-by-skill basis possible.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dgmy8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, I&amp;#39;ll agree with all of that, and add that you&amp;#39;ll also want short evals specific to skills of interest.&lt;/p&gt;\\n\\n&lt;p&gt;With one big eval, it&amp;#39;s hard to tell which skills are being utilized, and how well.  If a test exercises one specific skill, it&amp;#39;s easier to figure out what&amp;#39;s going on.  It also makes comparing models on a skill-by-skill basis possible.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lmmvmj/many_small_evals_are_better_than_one_big_eval/n0dgmy8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751182703,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lmmvmj","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
