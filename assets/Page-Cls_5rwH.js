import{j as e}from"./index-F0NXdzZX.js";import{R as l}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"It's leaking the chat formatting, instructions, whatever. It's saying nonesense outside the current session.I am genuinely confused and can't research cuz I don't know what this is\\n\\nThis is a dockerized OpenWebUI and native Llana.cpp","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Why does it do this? Why does ALL models do this?","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":108,"top_awarded_type":null,"hide_score":false,"name":"t3_1m2i79e","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.4,"author_flair_background_color":null,"ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_cw6v7ot8","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/J-Y56-GIgTD4mtA_cnFPHie9o8cV2-_ATtU1Qq9TS4A.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752783639,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s leaking the chat formatting, instructions, whatever. It&amp;#39;s saying nonesense outside the current session.I am genuinely confused and can&amp;#39;t research cuz I don&amp;#39;t know what this is&lt;/p&gt;\\n\\n&lt;p&gt;This is a dockerized OpenWebUI and native Llana.cpp&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/oqb0uoafthdf1.png","view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/oqb0uoafthdf1.png?auto=webp&amp;s=c0763130bb6f694b9c1922e3f998e0ddd855000b","width":1022,"height":791},"resolutions":[{"url":"https://preview.redd.it/oqb0uoafthdf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7bb6388e4519280e155fcd152181f81be05f8b80","width":108,"height":83},{"url":"https://preview.redd.it/oqb0uoafthdf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e1cfa22e7315ccfc60579dee44b8dbf9e4c4407","width":216,"height":167},{"url":"https://preview.redd.it/oqb0uoafthdf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=60224c8e2013bd1ce42ac3659b452b4d585fd24a","width":320,"height":247},{"url":"https://preview.redd.it/oqb0uoafthdf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=039e46ee77c912d2c7ab564dea897828bae9b8c2","width":640,"height":495},{"url":"https://preview.redd.it/oqb0uoafthdf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4e5855ec0c100026cb94fbcddae619574dac67e6","width":960,"height":743}],"variants":{},"id":"VvZgBoljS1wAfZ1PW4-PaVQ_0hl_XFRzdj4s4npGYGo"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m2i79e","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Leather_Flan5071","discussion_type":null,"num_comments":19,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/","stickied":false,"url":"https://i.redd.it/oqb0uoafthdf1.png","subreddit_subscribers":500896,"created_utc":1752783639,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3rs05i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MR_-_501","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rrli7","score":2,"author_fullname":"t2_14fb6edg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Personally on a Radeon VII PRO (which back then was still supported with the newest ROCM) i had it output a lot of gibberish after more than ~100 tokens. Both in ROCM and Vulkan. In VLLM i did not have this issue.\\n\\nI should probably try this too.","edited":false,"author_flair_css_class":null,"name":"t1_n3rs05i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Personally on a Radeon VII PRO (which back then was still supported with the newest ROCM) i had it output a lot of gibberish after more than ~100 tokens. Both in ROCM and Vulkan. In VLLM i did not have this issue.&lt;/p&gt;\\n\\n&lt;p&gt;I should probably try this too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m2i79e","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3rs05i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819594,"author_flair_text":null,"collapsed":false,"created_utc":1752819594,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rrli7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3rnioj","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah. Also I'm diving into chat templates and I can get stuff to work","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3rrli7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. Also I&amp;#39;m diving into chat templates and I can get stuff to work&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3rrli7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752819380,"author_flair_text":null,"treatment_tags":[],"created_utc":1752819380,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3rnioj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MR_-_501","can_mod_post":false,"send_replies":true,"parent_id":"t1_n3qqu70","score":2,"author_fullname":"t2_14fb6edg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you running an AMD gpu by any chance?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n3rnioj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you running an AMD gpu by any chance?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3rnioj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752817287,"author_flair_text":null,"treatment_tags":[],"created_utc":1752817287,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n3qqu70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752803586,"send_replies":true,"parent_id":"t1_n3p2s9g","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I did, even mistral 7B and Gemma 3 4B. Both showed the same thing for me. But I got it working by adding --jinja when running the llama.cpp server","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qqu70","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did, even mistral 7B and Gemma 3 4B. Both showed the same thing for me. But I got it working by adding --jinja when running the llama.cpp server&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qqu70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803586,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p2s9g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MR_-_501","can_mod_post":false,"created_utc":1752783970,"send_replies":true,"parent_id":"t3_1m2i79e","score":23,"author_fullname":"t2_14fb6edg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are using a older tiny 1.1 billion parameter model, that can barely form correct sentences. Try something like Gemma 3 4B instead.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p2s9g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are using a older tiny 1.1 billion parameter model, that can barely form correct sentences. Try something like Gemma 3 4B instead.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p2s9g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752783970,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qqgei","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752803445,"send_replies":true,"parent_id":"t1_n3p4anx","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, even mistral 7B and Gemma 3 showed the same symptoms. Looking at this here template, [https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama\\\\_chat\\\\_apply\\\\_template](https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template), there's some similarly supported templates for this particular model. A user here also said to use --jinja so llama.cpp uses the model's template, but the template is not directly listed on the website so.\\n\\nAnyways, it works now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qqgei","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, even mistral 7B and Gemma 3 showed the same symptoms. Looking at this here template, &lt;a href=\\"https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template\\"&gt;https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template&lt;/a&gt;, there&amp;#39;s some similarly supported templates for this particular model. A user here also said to use --jinja so llama.cpp uses the model&amp;#39;s template, but the template is not directly listed on the website so.&lt;/p&gt;\\n\\n&lt;p&gt;Anyways, it works now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qqgei/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803445,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p4anx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Top9254","can_mod_post":false,"created_utc":1752784394,"send_replies":true,"parent_id":"t3_1m2i79e","score":16,"author_fullname":"t2_1e4s71l3kv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1. You are using a tiny quantized model that has barely 500MB. Try something like 4-5GB or 8-12B parameters at Q4.\\n\\n2. You probably have bad settings, the &lt;|user|&gt; &lt;|assistant|&gt; markers should be truncated by webUI automatically if configured correctly.\\n\\nI also think even such a small model should be able to answer these questions, your sampler settings could be just wrong, try searching them for your model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p4anx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;You are using a tiny quantized model that has barely 500MB. Try something like 4-5GB or 8-12B parameters at Q4.&lt;/p&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;p&gt;You probably have bad settings, the &amp;lt;|user|&amp;gt; &amp;lt;|assistant|&amp;gt; markers should be truncated by webUI automatically if configured correctly.&lt;/p&gt;&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;I also think even such a small model should be able to answer these questions, your sampler settings could be just wrong, try searching them for your model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p4anx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752784394,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qoq3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752802815,"send_replies":true,"parent_id":"t1_n3p34cg","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I tried Mistral 7B and Gemma 3 and they were all broke, mistral even generated stuff repeatedly and I had to stop it manually","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qoq3g","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I tried Mistral 7B and Gemma 3 and they were all broke, mistral even generated stuff repeatedly and I had to stop it manually&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qoq3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802815,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p34cg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1752784063,"send_replies":true,"parent_id":"t3_1m2i79e","score":6,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't understand what you're trying to say. Do you mean that all the LLM models you've tested locally are broken for you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p34cg","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t understand what you&amp;#39;re trying to say. Do you mean that all the LLM models you&amp;#39;ve tested locally are broken for you?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p34cg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752784063,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qprgs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752803192,"send_replies":true,"parent_id":"t1_n3p4mda","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i hadn't really set up anything in OpenWebUI, there is the system prompt settings but I got it empty right now. A user here said to use the --jinja flag so that llama.cpp uses the template of the model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qprgs","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i hadn&amp;#39;t really set up anything in OpenWebUI, there is the system prompt settings but I got it empty right now. A user here said to use the --jinja flag so that llama.cpp uses the template of the model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qprgs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803192,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p4mda","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Blizado","can_mod_post":false,"created_utc":1752784486,"send_replies":true,"parent_id":"t3_1m2i79e","score":4,"author_fullname":"t2_j0e2r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hm, sounds more like a setting issue. Did you set the correct instruction format in OpenWebUI (don't know it and what setting it has)? Maybe you can also set \\"&lt;|user|&gt;\\" as extra stop token.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p4mda","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hm, sounds more like a setting issue. Did you set the correct instruction format in OpenWebUI (don&amp;#39;t know it and what setting it has)? Maybe you can also set &amp;quot;&amp;lt;|user|&amp;gt;&amp;quot; as extra stop token.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p4mda/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752784486,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qpdt5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752803054,"send_replies":true,"parent_id":"t1_n3p8x01","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks man, appreciate it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qpdt5","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks man, appreciate it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qpdt5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803054,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p8x01","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok-Lobster-919","can_mod_post":false,"created_utc":1752785694,"send_replies":true,"parent_id":"t3_1m2i79e","score":3,"author_fullname":"t2_kkovi1fh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Your program is completely ignoring the AI's chat/instruction template. I use wrappers so I never have to deal with llama.cpp directly or even templates. But since you are raw-dogging llama.cpp you need to specify the template.\\n\\n[https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama\\\\_chat\\\\_apply\\\\_template](https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template)  \\nI don't know if this link or solution is the proper one, like I said I don't use llama.cpp raw, but it should get you pointed in the right direction. Better than some of the other suggestions here.\\n\\nGood luck.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p8x01","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Your program is completely ignoring the AI&amp;#39;s chat/instruction template. I use wrappers so I never have to deal with llama.cpp directly or even templates. But since you are raw-dogging llama.cpp you need to specify the template.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template\\"&gt;https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template&lt;/a&gt;&lt;br/&gt;\\nI don&amp;#39;t know if this link or solution is the proper one, like I said I don&amp;#39;t use llama.cpp raw, but it should get you pointed in the right direction. Better than some of the other suggestions here.&lt;/p&gt;\\n\\n&lt;p&gt;Good luck.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p8x01/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752785694,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qp8dc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752802999,"send_replies":true,"parent_id":"t1_n3pdr7q","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I already tried mistral and gemma 3 and it showed the same behavior to me. I'll see what that flag is and see if stuff changes","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qp8dc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I already tried mistral and gemma 3 and it showed the same behavior to me. I&amp;#39;ll see what that flag is and see if stuff changes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qp8dc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752802999,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3pdr7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Awwtifishal","can_mod_post":false,"created_utc":1752787106,"send_replies":true,"parent_id":"t3_1m2i79e","score":3,"author_fullname":"t2_1d96a8k10t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Two problems:\\n\\n\\\\- Wrong template format. Usually you need to add --jinja to llama.cpp so it uses the template built into the gguf.  \\n\\\\- Very old model, and extremely small esp. for its age. A more recent model of the same size should perform much better. But for general purpose tasks you should probably use a 4B-8B model at least.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3pdr7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Two problems:&lt;/p&gt;\\n\\n&lt;p&gt;- Wrong template format. Usually you need to add --jinja to llama.cpp so it uses the template built into the gguf.&lt;br/&gt;\\n- Very old model, and extremely small esp. for its age. A more recent model of the same size should perform much better. But for general purpose tasks you should probably use a 4B-8B model at least.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3pdr7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752787106,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3qqov2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Leather_Flan5071","can_mod_post":false,"created_utc":1752803531,"send_replies":true,"parent_id":"t1_n3p470w","score":1,"author_fullname":"t2_cw6v7ot8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I see, I see, thanks! I already have gemma 3 and mistral 7B here but they also showed the same symptoms. I used a flag --jinja and in this model, it now works properly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3qqov2","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I see, I see, thanks! I already have gemma 3 and mistral 7B here but they also showed the same symptoms. I used a flag --jinja and in this model, it now works properly.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3qqov2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752803531,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3p4ld6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lordpuddingcup","can_mod_post":false,"created_utc":1752784478,"send_replies":true,"parent_id":"t1_n3p470w","score":-1,"author_fullname":"t2_vc4z2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not true Gemma is perfectly good and several others in the 3-4b area","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p4ld6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not true Gemma is perfectly good and several others in the 3-4b area&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m2i79e","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p4ld6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752784478,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n3p470w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Feztopia","can_mod_post":false,"created_utc":1752784365,"send_replies":true,"parent_id":"t3_1m2i79e","score":1,"author_fullname":"t2_34dar1xn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not a great model, nothing below 7b is really useful, also you might use your chat template settings to hinder this kind of problems","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3p470w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not a great model, nothing below 7b is really useful, also you might use your chat template settings to hinder this kind of problems&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3p470w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752784365,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n3sgqzp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CattailRed","can_mod_post":false,"created_utc":1752833373,"send_replies":true,"parent_id":"t3_1m2i79e","score":2,"author_fullname":"t2_ils5pp48","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Bugged chat template. Undefined stop token. Since all models are trained to complete text and chat models are trained on conversations, it's doing exactly that: answering, then continuing the conversation for both sides on its own endlessly.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n3sgqzp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Bugged chat template. Undefined stop token. Since all models are trained to complete text and chat models are trained on conversations, it&amp;#39;s doing exactly that: answering, then continuing the conversation for both sides on its own endlessly.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m2i79e/why_does_it_do_this_why_does_all_models_do_this/n3sgqzp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752833373,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m2i79e","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
