import{j as e}from"./index-DAwUrOQb.js";import{R as l}from"./RedditPostRenderer-DESUWA8s.js";import"./index-CA_ihzEz.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"\\"snugly fits in a h100, quantized 4 bit\\"","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1jsshhe","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":1442,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dievh","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":1442,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/PWPItfaWKxYAakDk-KKm_RKWYBorPNXteWt7R5Qktos.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1743940748,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/g2mj9lg4f7te1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?auto=webp&amp;s=5d94801271c7a71916ddc4ea7bad7bbc0e07a2e7","width":1024,"height":1137},"resolutions":[{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=51926e2d8ef9e10a58295284e8644888ec4e2517","width":108,"height":119},{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=483b25fd827ddc9a0b80e84319c7a37fcde6d2ac","width":216,"height":239},{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0aee8c1a42548cd1115d28de9329c9ac04f96ff5","width":320,"height":355},{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b3f27828a4984437b27e38b91aa497b1074ed5d","width":640,"height":710},{"url":"https://preview.redd.it/g2mj9lg4f7te1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=303fbb9c3ee2c36422c3e36c50aef9a491297c45","width":960,"height":1065}],"variants":{},"id":"O_4RfCpft2_pnUyZ_q0xRZsVeEvNmUwdQDISguFB5eM"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1jsshhe","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"LoSboccacc","discussion_type":null,"num_comments":175,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/","stickied":false,"url":"https://i.redd.it/g2mj9lg4f7te1.png","subreddit_subscribers":492315,"created_utc":1743940748,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqolp5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Seeker_Of_Knowledge2","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq5o7z","score":17,"author_fullname":"t2_slc08vd4x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"**NO**","edited":false,"author_flair_css_class":null,"name":"t1_mlqolp5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;NO&lt;/strong&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqolp5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965166,"author_flair_text":null,"collapsed":false,"created_utc":1743965166,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq5o7z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tovefrakommunen","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq09ua","score":40,"author_fullname":"t2_16mpx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq5o7z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq5o7z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743959219,"author_flair_text":null,"treatment_tags":[],"created_utc":1743959219,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq09ua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IamFuckinTomato","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpfsc8","score":58,"author_fullname":"t2_uj0aki1h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Right?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlq09ua","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq09ua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743957491,"author_flair_text":null,"treatment_tags":[],"created_utc":1743957491,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":58}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlr5qx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nuclearbananana","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpfsc8","score":17,"author_fullname":"t2_27hg4b53","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"just dig around your cable box, I'm sure there's one sitting around","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlr5qx4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;just dig around your cable box, I&amp;#39;m sure there&amp;#39;s one sitting around&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlr5qx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743970682,"author_flair_text":null,"treatment_tags":[],"created_utc":1743970682,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlwsq8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KellerMB","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlvfvwu","score":1,"author_fullname":"t2_j4gqb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I have a few of those about as close as the local microcenter. Who wants to do a group-buy?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlwsq8y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have a few of those about as close as the local microcenter. Who wants to do a group-buy?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlwsq8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744052946,"author_flair_text":null,"treatment_tags":[],"created_utc":1744052946,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlvfvwu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Old_Key_5090","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpfsc8","score":5,"author_fullname":"t2_1c57sa46jv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nah you have to pick it off the shelf at your local AWS datacenter","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlvfvwu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nah you have to pick it off the shelf at your local AWS datacenter&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlvfvwu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744038040,"author_flair_text":null,"treatment_tags":[],"created_utc":1744038040,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpfsc8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KellerMB","can_mod_post":false,"created_utc":1743950786,"send_replies":true,"parent_id":"t1_mlpbsgc","score":121,"author_fullname":"t2_j4gqb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can pick one of those up off the shelf at my local bestbuy right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpfsc8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can pick one of those up off the shelf at my local bestbuy right?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpfsc8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950786,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":121}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrts6v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RoomyRoots","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":33,"author_fullname":"t2_tog05cit","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlrts6v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrts6v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743978801,"author_flair_text":null,"treatment_tags":[],"created_utc":1743978801,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":33}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlry6cm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShadowbanRevival","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":13,"author_fullname":"t2_vjwnrmfn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"One brazillion yen (hence the B)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlry6cm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One brazillion yen (hence the B)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlry6cm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743980377,"author_flair_text":null,"treatment_tags":[],"created_utc":1743980377,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlt0jv4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Virtualcosmos","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":7,"author_fullname":"t2_2ixm0xdt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Enough to buy a modern electric car with all the lastest tech in it. But nvida cards are not overpriced at all.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlt0jv4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Enough to buy a modern electric car with all the lastest tech in it. But nvida cards are not overpriced at all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlt0jv4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743995225,"author_flair_text":null,"treatment_tags":[],"created_utc":1743995225,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlylxwv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"KindnessBiasedBoar","can_mod_post":false,"send_replies":true,"parent_id":"t1_mltwkhz","score":1,"author_fullname":"t2_p343vczn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So they technically should be... mine?  Do they need to be fresh?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlylxwv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So they technically should be... mine?  Do they need to be fresh?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlylxwv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744074791,"author_flair_text":null,"treatment_tags":[],"created_utc":1744074791,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mltwkhz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"XBenjiaminX","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":4,"author_fullname":"t2_aj5arkbd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They now accept organs as a payment method, thanks Nvidia &lt;3","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mltwkhz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They now accept organs as a payment method, thanks Nvidia &amp;lt;3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mltwkhz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744012457,"author_flair_text":null,"treatment_tags":[],"created_utc":1744012457,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mls4zzu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Apprehensive_Put_610","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":3,"author_fullname":"t2_8v9spvga","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you have to ask....","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mls4zzu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you have to ask....&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mls4zzu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743982845,"author_flair_text":null,"treatment_tags":[],"created_utc":1743982845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlu1kw2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"titoffklim","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":2,"author_fullname":"t2_6cql35ze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A hundred of B2","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlu1kw2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A hundred of B2&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlu1kw2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744015856,"author_flair_text":null,"treatment_tags":[],"created_utc":1744015856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mmmlxxo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Osama_Saba","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlrhq0m","score":1,"author_fullname":"t2_19ejkdlfsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Mazda 3","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mmmlxxo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mazda 3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mmmlxxo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744404652,"author_flair_text":null,"treatment_tags":[],"created_utc":1744404652,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlrhq0m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DangerousBrat","can_mod_post":false,"created_utc":1743974552,"send_replies":true,"parent_id":"t1_mlpbsgc","score":15,"author_fullname":"t2_1gmik7kinq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much is a B200?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlrhq0m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much is a B200?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrhq0m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743974552,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpbsgc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pigeon57434","can_mod_post":false,"created_utc":1743949451,"send_replies":true,"parent_id":"t3_1jsshhe","score":455,"author_fullname":"t2_8j5t7yjq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Designed to fit on a single GPU\\"  \\nthe GPU in question: B200","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpbsgc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Designed to fit on a single GPU&amp;quot;&lt;br/&gt;\\nthe GPU in question: B200&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpbsgc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949451,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":455}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlq07gd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chuckaholic","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpt99i","score":8,"author_fullname":"t2_6s523","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh wow, yeah 250 is pretty low compared to HBM3.","edited":false,"author_flair_css_class":null,"name":"t1_mlq07gd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh wow, yeah 250 is pretty low compared to HBM3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq07gd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743957470,"author_flair_text":null,"collapsed":false,"created_utc":1743957470,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlwnumf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kubas_inko","can_mod_post":false,"created_utc":1744051450,"send_replies":true,"parent_id":"t1_mlvcnfh","score":1,"author_fullname":"t2_l2c5r","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't know with LLMs. Maybe not. As I wrote in different response, I am more interested in having a single PC for everything, so my major reason for a PCIe slot would be gaming. You would definitely see the difference there.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlwnumf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t know with LLMs. Maybe not. As I wrote in different response, I am more interested in having a single PC for everything, so my major reason for a PCIe slot would be gaming. You would definitely see the difference there.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlwnumf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744051450,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlvcnfh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ruin-Capable","can_mod_post":false,"created_utc":1744037067,"send_replies":true,"parent_id":"t1_mlqyoa3","score":1,"author_fullname":"t2_2g4fwosy","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm running an second GPU via Occulink into a 4.0x4 m.2 slot, and LLM performance really does not seem that bad.  I have a free 4.0x8 slot, but it's physically blocked by the primary GPU.  I've thought of building an open frame and getting some riser cables.  Do you think I would see a significant performance increase switching from occulink to a 4.0x8 slot?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlvcnfh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m running an second GPU via Occulink into a 4.0x4 m.2 slot, and LLM performance really does not seem that bad.  I have a free 4.0x8 slot, but it&amp;#39;s physically blocked by the primary GPU.  I&amp;#39;ve thought of building an open frame and getting some riser cables.  Do you think I would see a significant performance increase switching from occulink to a 4.0x8 slot?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlvcnfh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744037067,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqyoa3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kubas_inko","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqts77","score":4,"author_fullname":"t2_l2c5r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"PCIe 3.0x16 (4.0x8) is barely enough for 4090 (you lose about 1-2% compared to 4.0x16). Anything below will limit it significantly. PCIe 3.0x8 (4.0x4) is limiting even for mid-range GPUs.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlqyoa3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;PCIe 3.0x16 (4.0x8) is barely enough for 4090 (you lose about 1-2% compared to 4.0x16). Anything below will limit it significantly. PCIe 3.0x8 (4.0x4) is limiting even for mid-range GPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqyoa3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743968455,"author_flair_text":null,"treatment_tags":[],"created_utc":1743968455,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrms1q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pyr0kid","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqts77","score":4,"author_fullname":"t2_utk4aim","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;Not necessarily. Newer GPUs yes, but for example, running a 4090 at 4.0 x4 results in what, a \\\\~6% total performance/bandwidth drop?\\n\\nin games? yeah 6% is about bang on.\\n\\nyou have to be running gpus at something really horrible like 3.0x4 (7.8gb/sec) for pcie to consistently and significantly bottleneck a 4090, according to TPU data.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlrms1q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Not necessarily. Newer GPUs yes, but for example, running a 4090 at 4.0 x4 results in what, a ~6% total performance/bandwidth drop?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;in games? yeah 6% is about bang on.&lt;/p&gt;\\n\\n&lt;p&gt;you have to be running gpus at something really horrible like 3.0x4 (7.8gb/sec) for pcie to consistently and significantly bottleneck a 4090, according to TPU data.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrms1q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743976295,"author_flair_text":null,"treatment_tags":[],"created_utc":1743976295,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqts77","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fonix232","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqfnr5","score":5,"author_fullname":"t2_aricd","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not necessarily. Newer GPUs yes, but for example, running a 4090 at 4.0 x4 results in what, a ~6% total performance/bandwidth drop?\\n\\nObviously you won't be running a 4x5090 setup on that port, but for a single older card, it's just barely but enough.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqts77","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not necessarily. Newer GPUs yes, but for example, running a 4090 at 4.0 x4 results in what, a ~6% total performance/bandwidth drop?&lt;/p&gt;\\n\\n&lt;p&gt;Obviously you won&amp;#39;t be running a 4x5090 setup on that port, but for a single older card, it&amp;#39;s just barely but enough.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqts77/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743966842,"author_flair_text":null,"treatment_tags":[],"created_utc":1743966842,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrk4ll","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pyr0kid","can_mod_post":false,"created_utc":1743975374,"send_replies":true,"parent_id":"t1_mlqtsrb","score":1,"author_fullname":"t2_utk4aim","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Can Vulkan do multi card splits?\\n\\ntried it in koboldcpp with a spare gtx 900, its either broken or the option existing in the gui at all is a mistake.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlrk4ll","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Can Vulkan do multi card splits?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;tried it in koboldcpp with a spare gtx 900, its either broken or the option existing in the gui at all is a mistake.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrk4ll/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743975374,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqtsrb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqs9ct","score":2,"author_fullname":"t2_d2nyh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can Vulkan do multi card splits? Would be interesting if it were possible to do seamless inference over something like an external 7900XT as much as it can fit and the rest on the iGPU.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlqtsrb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can Vulkan do multi card splits? Would be interesting if it were possible to do seamless inference over something like an external 7900XT as much as it can fit and the rest on the iGPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqtsrb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743966848,"author_flair_text":null,"treatment_tags":[],"created_utc":1743966848,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mm6pvem","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aidfulAI","can_mod_post":false,"created_utc":1744193080,"send_replies":true,"parent_id":"t1_mlr2h9s","score":1,"author_fullname":"t2_tnwrgyge","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for making me aware of the GMKtec EVO-X2 which is powered by the new AI Max chip from AMD. Just read that the presale will start on the 15th of April.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mm6pvem","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for making me aware of the GMKtec EVO-X2 which is powered by the new AI Max chip from AMD. Just read that the presale will start on the 15th of April.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mm6pvem/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744193080,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlr2h9s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kubas_inko","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqs9ct","score":2,"author_fullname":"t2_l2c5r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am much more interested in having the Framework as my main PC for everything, thus having a gaming card (my 4090) in there. But I guess I'll have it purely for LLMs, in which case I might go for GMKtec instead (as it launches sooner and will be cheaper).\\n\\nAnyways, PCIe 3.0x16 (4.0x8) is barely enough for 4090 (about 1-2% difference compared to 4.0x16). So going even lower will definitely limit modern GPUs. And as we know from the 4060ti (low-range GPU?), PCIe 3.0x8 can be seriously limiting even for that GPU.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlr2h9s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am much more interested in having the Framework as my main PC for everything, thus having a gaming card (my 4090) in there. But I guess I&amp;#39;ll have it purely for LLMs, in which case I might go for GMKtec instead (as it launches sooner and will be cheaper).&lt;/p&gt;\\n\\n&lt;p&gt;Anyways, PCIe 3.0x16 (4.0x8) is barely enough for 4090 (about 1-2% difference compared to 4.0x16). So going even lower will definitely limit modern GPUs. And as we know from the 4060ti (low-range GPU?), PCIe 3.0x8 can be seriously limiting even for that GPU.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlr2h9s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743969667,"author_flair_text":null,"treatment_tags":[],"created_utc":1743969667,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqs9ct","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"boissez","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqfnr5","score":1,"author_fullname":"t2_5e5n5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah. It's not optimal. But from what I've gathered from comments around here, the performance loss at 4.0x4 is not too bad. I guess we'll see when the first Strix Halo units gets benchmarked.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqs9ct","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. It&amp;#39;s not optimal. But from what I&amp;#39;ve gathered from comments around here, the performance loss at 4.0x4 is not too bad. I guess we&amp;#39;ll see when the first Strix Halo units gets benchmarked.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqs9ct/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743966348,"author_flair_text":null,"treatment_tags":[],"created_utc":1743966348,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqfnr5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Kubas_inko","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpt99i","score":3,"author_fullname":"t2_l2c5r","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The strix halo motherboards (the one in framework and in the GMKtec EVO-X2) have full pcie slots?\\n\\nEdit: Just checked. The Framework one does have PCIe slot, but only 4.0x4 (equivalent to PCIe 2.0x16), which is very limiting for GPUs.","edited":1743963071,"author_flair_css_class":null,"name":"t1_mlqfnr5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The strix halo motherboards (the one in framework and in the GMKtec EVO-X2) have full pcie slots?&lt;/p&gt;\\n\\n&lt;p&gt;Edit: Just checked. The Framework one does have PCIe slot, but only 4.0x4 (equivalent to PCIe 2.0x16), which is very limiting for GPUs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqfnr5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962330,"author_flair_text":null,"collapsed":false,"created_utc":1743962330,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpt99i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boissez","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpq6ze","score":21,"author_fullname":"t2_5e5n5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just keep in mind that you're getting 250 GB/s worth of bandwidth max. I'm still on the fence whether I should upgrade my 1x3090 system with another 3090 or to a Strix Halo plus a single 3090.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpt99i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just keep in mind that you&amp;#39;re getting 250 GB/s worth of bandwidth max. I&amp;#39;m still on the fence whether I should upgrade my 1x3090 system with another 3090 or to a Strix Halo plus a single 3090.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpt99i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743955190,"author_flair_text":null,"treatment_tags":[],"created_utc":1743955190,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"5c2a2958-309b-11ee-9109-22869f0a11dc","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlre9l5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"candre23","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpq6ze","score":0,"author_fullname":"t2_4wc8s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Be aware that with anything reasonably large, that APU will *crawl*.  Memory bandwidth is terrible compared to a real GPU, compute isn't much better, and it's AMD so even if you manage to get rocm working, it's going to be trash compared to cuda.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlre9l5","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"koboldcpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Be aware that with anything reasonably large, that APU will &lt;em&gt;crawl&lt;/em&gt;.  Memory bandwidth is terrible compared to a real GPU, compute isn&amp;#39;t much better, and it&amp;#39;s AMD so even if you manage to get rocm working, it&amp;#39;s going to be trash compared to cuda.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlre9l5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743973404,"author_flair_text":"koboldcpp","treatment_tags":[],"created_utc":1743973404,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpq6ze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"chuckaholic","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpgblw","score":27,"author_fullname":"t2_6s523","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you. I didn't know this existed. So I don't have to buy 4 3090's...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpq6ze","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. I didn&amp;#39;t know this existed. So I don&amp;#39;t have to buy 4 3090&amp;#39;s...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpq6ze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743954195,"author_flair_text":null,"treatment_tags":[],"created_utc":1743954195,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpgblw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boissez","can_mod_post":false,"created_utc":1743950963,"send_replies":true,"parent_id":"t1_mlotgzz","score":79,"author_fullname":"t2_5e5n5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It does fit nicely in a 1699$ Framework Strix Halo board. It would have been amazing news, if it had been any good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpgblw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does fit nicely in a 1699$ Framework Strix Halo board. It would have been amazing news, if it had been any good.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpgblw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950963,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":79}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpun0w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Super_Sierra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlplj5u","score":-3,"author_fullname":"t2_9757bxah","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma 3 is semi incoherent for my complex cards. I hated it, and didn't obey my simple instructions.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlpun0w","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3 is semi incoherent for my complex cards. I hated it, and didn&amp;#39;t obey my simple instructions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpun0w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743955642,"author_flair_text":null,"treatment_tags":[],"created_utc":1743955642,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlplj5u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lemon07r","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpb2zf","score":8,"author_fullname":"t2_i697e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gemma 3 is okay, its a little resistant to instruction though as far as writing style goes, but still writes better than scout from what ive seen. the thing is, llama has always been kinda bad for writing, at least relative to gemma which punches above its weight in this aspect. I would still rather use a good gemma 2 finetune if i want good writing style, or just use deepseek r1 for cheap, which has largely made local llms irrelevant for me lately, because most local llms are either too censored, or the ones that arent just arent very good. phi 4 is much less censored and not too bad, but gemma still has it beat in writing quality. these are just my observations from testing, and mostly based on my preferences/biases so you should probably still do your own testing.","edited":false,"author_flair_css_class":null,"name":"t1_mlplj5u","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma 3 is okay, its a little resistant to instruction though as far as writing style goes, but still writes better than scout from what ive seen. the thing is, llama has always been kinda bad for writing, at least relative to gemma which punches above its weight in this aspect. I would still rather use a good gemma 2 finetune if i want good writing style, or just use deepseek r1 for cheap, which has largely made local llms irrelevant for me lately, because most local llms are either too censored, or the ones that arent just arent very good. phi 4 is much less censored and not too bad, but gemma still has it beat in writing quality. these are just my observations from testing, and mostly based on my preferences/biases so you should probably still do your own testing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlplj5u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743952663,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1743952663,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpcpww","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Super_Sierra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpcije","score":-2,"author_fullname":"t2_9757bxah","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ive tested a lot of models on there and the only ones that are any decent dense models below Deekseek and Sonnet 3.7 are none. MoEs good","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlpcpww","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ive tested a lot of models on there and the only ones that are any decent dense models below Deekseek and Sonnet 3.7 are none. MoEs good&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpcpww/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949765,"author_flair_text":null,"treatment_tags":[],"created_utc":1743949765,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mlqbybj","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqbybj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"adriosi","can_mod_post":false,"created_utc":1743961179,"send_replies":true,"parent_id":"t1_mlq2ujw","score":4,"author_fullname":"t2_61vnxhkv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, that was exactly my point - the whole benchmark is mostly only useful for writers who believe the judgement of Sonet 3.7. Nothing wrong with that, but much like a human eval - it's highly susceptible to bias.\\n\\nCoding and math benchmarks are better by simply being more objective, despite being susceptible to overfitting. Regardless, if we are evaluating a new llama model - using creative writing results to conclude it's useless is a really weird choice.\\n\\n\\"It is better than a human to evaluate because it is not taking any sides.\\" - I don't even know what you are referring to. Chatbot Arena doesn't show you the names of the model before voting. LMMs are just as subject to bias, if not more. Just as an example, an LLM will literally assume that anything in the prompt is worth considering, that's how attention mechanism works. This is how we got Grok talking about Trump and Musk in prompts that had nothing to do with them - they were mentioned in the system prompt. The only benefit is that you can run them in this kind of converging loop, which doesn't remove the bias, not to mention - probably exacerbates the ones that are intrinsic to LLMs (like prompt or order biases).\\n\\n\\n\\"All models evaluated my 3 stories very similar in the scale 0 to 100.\\" - which is great for you, but nowhere close to being objective.\\n\\n\\"So yes AI can do that quite well if even is not able to write it better. \\" - can it? how does one evaluate how good of a judge some other LLM is?\\n\\n\\n\\"Is like a reader ...you can say if a book is good written even you can't do that by yourself.\\" - which is going to be highly subjective and in no way descriptive of the actual value the book provides. Problem solving benchmarks are closer to being objective since they have concrete answers. This doesn't mean writing benchmarks are useless - but even if we just assume that sonet 3.7 is a good judge - it is only meant to judge the writing style. Much like in your analogy with a book - subjective writing style score says nothing about the value of the information in the book.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqbybj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, that was exactly my point - the whole benchmark is mostly only useful for writers who believe the judgement of Sonet 3.7. Nothing wrong with that, but much like a human eval - it&amp;#39;s highly susceptible to bias.&lt;/p&gt;\\n\\n&lt;p&gt;Coding and math benchmarks are better by simply being more objective, despite being susceptible to overfitting. Regardless, if we are evaluating a new llama model - using creative writing results to conclude it&amp;#39;s useless is a really weird choice.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;It is better than a human to evaluate because it is not taking any sides.&amp;quot; - I don&amp;#39;t even know what you are referring to. Chatbot Arena doesn&amp;#39;t show you the names of the model before voting. LMMs are just as subject to bias, if not more. Just as an example, an LLM will literally assume that anything in the prompt is worth considering, that&amp;#39;s how attention mechanism works. This is how we got Grok talking about Trump and Musk in prompts that had nothing to do with them - they were mentioned in the system prompt. The only benefit is that you can run them in this kind of converging loop, which doesn&amp;#39;t remove the bias, not to mention - probably exacerbates the ones that are intrinsic to LLMs (like prompt or order biases).&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;All models evaluated my 3 stories very similar in the scale 0 to 100.&amp;quot; - which is great for you, but nowhere close to being objective.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;So yes AI can do that quite well if even is not able to write it better. &amp;quot; - can it? how does one evaluate how good of a judge some other LLM is?&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;Is like a reader ...you can say if a book is good written even you can&amp;#39;t do that by yourself.&amp;quot; - which is going to be highly subjective and in no way descriptive of the actual value the book provides. Problem solving benchmarks are closer to being objective since they have concrete answers. This doesn&amp;#39;t mean writing benchmarks are useless - but even if we just assume that sonet 3.7 is a good judge - it is only meant to judge the writing style. Much like in your analogy with a book - subjective writing style score says nothing about the value of the information in the book.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqbybj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743961179,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mltndys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Desm0nt","can_mod_post":false,"created_utc":1744006887,"send_replies":true,"parent_id":"t1_mlq2ujw","score":1,"author_fullname":"t2_130mhq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;It is better than a human to evaluate because it is not taking any side\\n\\nOh, seriously. Get any (good written!) porn story or historical fictional about slavery, pass in to Sonnet or GPT and see how this \\"I can't process such harmful content\\" model \\"unbiased\\" compared to even Deepseek R1...\\n\\nIt's literally has hard-coded via RLHF biased opinion about wide range of topics and about some stylistically and emotional gradation of the text, which leads to biased and incorrect evaluation of some types of texts and overestimation of others, especially those similar to the model's native training set.\\n\\nIt is either to make a weighted average evaluation from a good dozen LLMs, including uncensored and evil finetunes + models trained for other languages (different text corpus and style), or to take such a result with a high degree of skepticism.","edited":1744007358,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mltndys","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;It is better than a human to evaluate because it is not taking any side&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Oh, seriously. Get any (good written!) porn story or historical fictional about slavery, pass in to Sonnet or GPT and see how this &amp;quot;I can&amp;#39;t process such harmful content&amp;quot; model &amp;quot;unbiased&amp;quot; compared to even Deepseek R1...&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s literally has hard-coded via RLHF biased opinion about wide range of topics and about some stylistically and emotional gradation of the text, which leads to biased and incorrect evaluation of some types of texts and overestimation of others, especially those similar to the model&amp;#39;s native training set.&lt;/p&gt;\\n\\n&lt;p&gt;It is either to make a weighted average evaluation from a good dozen LLMs, including uncensored and evil finetunes + models trained for other languages (different text corpus and style), or to take such a result with a high degree of skepticism.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mltndys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744006887,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq2ujw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1743958321,"send_replies":true,"parent_id":"t1_mlq0nv6","score":-3,"author_fullname":"t2_ogjj6ebj","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is better than a human to evaluate because it is not taking any sides. \\n\\n\\nI also was making similar tests by myself with o3 mini , gpt4o , sonnet 3.7 and gpt 4 5.\\n\\n\\nAll models evaluated my 3 stories very similar in the scale 0 to 100.\\n\\n\\nSo yes AI can do that quite well if even is not able to write it better. \\n\\n\\nIs like a reader ...you can say if a book is good written even you can't do that by yourself.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlq2ujw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is better than a human to evaluate because it is not taking any sides. &lt;/p&gt;\\n\\n&lt;p&gt;I also was making similar tests by myself with o3 mini , gpt4o , sonnet 3.7 and gpt 4 5.&lt;/p&gt;\\n\\n&lt;p&gt;All models evaluated my 3 stories very similar in the scale 0 to 100.&lt;/p&gt;\\n\\n&lt;p&gt;So yes AI can do that quite well if even is not able to write it better. &lt;/p&gt;\\n\\n&lt;p&gt;Is like a reader ...you can say if a book is good written even you can&amp;#39;t do that by yourself.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq2ujw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743958321,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq0nv6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"adriosi","can_mod_post":false,"created_utc":1743957620,"send_replies":true,"parent_id":"t1_mlps0nh","score":-1,"author_fullname":"t2_61vnxhkv","approved_by":null,"mod_note":null,"all_awardings":[],"body":"It uses sonet 3.7 as a judge. So are people concluding that llama 4 is useless based on a creative writing benchmark of all things, graded by another LLM against other options? Am I missing something, how is that a good evaluation of the model's capabilities in general? Those benchmarks are by definition biased, no matter how many pairwise loops you're gonna run.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlq0nv6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It uses sonet 3.7 as a judge. So are people concluding that llama 4 is useless based on a creative writing benchmark of all things, graded by another LLM against other options? Am I missing something, how is that a good evaluation of the model&amp;#39;s capabilities in general? Those benchmarks are by definition biased, no matter how many pairwise loops you&amp;#39;re gonna run.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq0nv6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743957620,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlps0nh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpns4o","score":-7,"author_fullname":"t2_ogjj6ebj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Great - good to know that a random guy from the internet of course knows better than independent tests designed to estimate writing quality as well as possible.\\n\\n\\nI assume you do not even read how that new benchmark works.","edited":1743955729,"gildings":{},"author_flair_css_class":null,"name":"t1_mlps0nh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great - good to know that a random guy from the internet of course knows better than independent tests designed to estimate writing quality as well as possible.&lt;/p&gt;\\n\\n&lt;p&gt;I assume you do not even read how that new benchmark works.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlps0nh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743954788,"author_flair_text":null,"treatment_tags":[],"created_utc":1743954788,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpns4o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Desm0nt","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpcije","score":-7,"author_fullname":"t2_130mhq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Another useless benchmark, IMHO, [DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324) higher than R1, while on real RP/eRP test R1 understand all puns, humor, double speak, euphemisms and strongly stick to the character's personality and info, while V3.1 isn't (just writes really good, but don't give a feeling that it's really understand what it writes, comparing to R1).\\n\\nSo maybe v3.1 have benefit in some particular mesurable things like less repetitions and less slops (can confirm)  - in general and in whole R1 prose is better. Especially on long distance.\\n\\nP.S. I don't believe in general to benchmark where LLM is a part of judgement pipeline, especially proprietary censored LLM stuffed with modern \\"safety\\" agenda (which makes it extremely biased)","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlpns4o","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Another useless benchmark, IMHO, &lt;a href=\\"https://huggingface.co/deepseek-ai/DeepSeek-V3-0324\\"&gt;DeepSeek-V3-0324&lt;/a&gt; higher than R1, while on real RP/eRP test R1 understand all puns, humor, double speak, euphemisms and strongly stick to the character&amp;#39;s personality and info, while V3.1 isn&amp;#39;t (just writes really good, but don&amp;#39;t give a feeling that it&amp;#39;s really understand what it writes, comparing to R1).&lt;/p&gt;\\n\\n&lt;p&gt;So maybe v3.1 have benefit in some particular mesurable things like less repetitions and less slops (can confirm)  - in general and in whole R1 prose is better. Especially on long distance.&lt;/p&gt;\\n\\n&lt;p&gt;P.S. I don&amp;#39;t believe in general to benchmark where LLM is a part of judgement pipeline, especially proprietary censored LLM stuffed with modern &amp;quot;safety&amp;quot; agenda (which makes it extremely biased)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpns4o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743953411,"author_flair_text":null,"treatment_tags":[],"created_utc":1743953411,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpcije","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpb2zf","score":2,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"look\\n\\n[https://eqbench.com/creative\\\\_writing\\\\_longform.html](https://eqbench.com/creative_writing_longform.html)\\n\\nHow hat and not coherent and respective is and degradation ...","edited":false,"author_flair_css_class":null,"name":"t1_mlpcije","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;look&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://eqbench.com/creative_writing_longform.html\\"&gt;https://eqbench.com/creative_writing_longform.html&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;How hat and not coherent and respective is and degradation ...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpcije/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949695,"author_flair_text":null,"collapsed":false,"created_utc":1743949695,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpb2zf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Super_Sierra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp71g7","score":15,"author_fullname":"t2_9757bxah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had the worst experiences with Gemma 3, it doesn't like writing in the style that I like and keeps going back to what it was trained on, which is the hallmark for overfitted to training data.\\n\\nScout seems to be able to stick with the prose and formatting better and remain coherent.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpb2zf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had the worst experiences with Gemma 3, it doesn&amp;#39;t like writing in the style that I like and keeps going back to what it was trained on, which is the hallmark for overfitted to training data.&lt;/p&gt;\\n\\n&lt;p&gt;Scout seems to be able to stick with the prose and formatting better and remain coherent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpb2zf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949208,"author_flair_text":null,"treatment_tags":[],"created_utc":1743949208,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp71g7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0c2m","score":40,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So coherent that in writing is worse than Gemma 3 4b...sure","edited":1743949569,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlp71g7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So coherent that in writing is worse than Gemma 3 4b...sure&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp71g7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947776,"author_flair_text":null,"treatment_tags":[],"created_utc":1743947776,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpua0d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Super_Sierra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlptawg","score":1,"author_fullname":"t2_9757bxah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"People defending Gemma 3 when I had huge issues with it. This scout is leagues better???","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpua0d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People defending Gemma 3 when I had huge issues with it. This scout is leagues better???&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpua0d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743955522,"author_flair_text":null,"treatment_tags":[],"created_utc":1743955522,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlptawg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FrizzItKing","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0c2m","score":3,"author_fullname":"t2_12iezm60xt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't know why people are in such hurry to dismiss.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlptawg","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t know why people are in such hurry to dismiss.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlptawg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743955204,"author_flair_text":null,"treatment_tags":[],"created_utc":1743955204,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp0c2m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Super_Sierra","can_mod_post":false,"created_utc":1743945203,"send_replies":true,"parent_id":"t1_mlotgzz","score":36,"author_fullname":"t2_9757bxah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have people even tested it yet? I messed with it a little on openrouter and even though it has some slop, it remains coherent pretty well, way better compared to 70b and 32b models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp0c2m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have people even tested it yet? I messed with it a little on openrouter and even though it has some slop, it remains coherent pretty well, way better compared to 70b and 32b models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp0c2m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743945203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp46yr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sovereignrk","can_mod_post":false,"created_utc":1743946724,"send_replies":true,"parent_id":"t1_mlotgzz","score":5,"author_fullname":"t2_ozvsm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://i.redd.it/zed7xzazw7te1.gif","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp46yr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://i.redd.it/zed7xzazw7te1.gif\\"&gt;https://i.redd.it/zed7xzazw7te1.gif&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp46yr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743946724,"media_metadata":{"zed7xzazw7te1":{"status":"valid","e":"AnimatedImage","m":"image/gif","p":[{"y":49,"x":108,"u":"https://preview.redd.it/zed7xzazw7te1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=92b001d08984f6fe9c33e8de070fc824460da006"},{"y":99,"x":216,"u":"https://preview.redd.it/zed7xzazw7te1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=145a3b9dac39548abc6834c72d590fe4107c5ccb"}],"s":{"y":101,"gif":"https://i.redd.it/zed7xzazw7te1.gif","mp4":"https://preview.redd.it/zed7xzazw7te1.gif?format=mp4&amp;s=c44d1ff3b49cadedccd834fd7c1d247850c7be25","x":220},"id":"zed7xzazw7te1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqp5kk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lemon07r","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqbtdf","score":0,"author_fullname":"t2_i697e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I know, but it still isn't good for its size. R1 is good for its size, and that one is even bigger, definitely not targeted for single users.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlqp5kk","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I know, but it still isn&amp;#39;t good for its size. R1 is good for its size, and that one is even bigger, definitely not targeted for single users.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqp5kk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965344,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1743965344,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqbtdf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Someone13574","can_mod_post":false,"created_utc":1743961136,"send_replies":true,"parent_id":"t1_mlotgzz","score":2,"author_fullname":"t2_77zysoao","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Single users aren't the target users of this model, datacenters are. If you look at it under that assumption, where memory doesn't matter, but speed does, then its good for its *speed*. Thats why they like to compare in the 17b class of model, because that's what matters to non-local users.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqbtdf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Single users aren&amp;#39;t the target users of this model, datacenters are. If you look at it under that assumption, where memory doesn&amp;#39;t matter, but speed does, then its good for its &lt;em&gt;speed&lt;/em&gt;. Thats why they like to compare in the 17b class of model, because that&amp;#39;s what matters to non-local users.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqbtdf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743961136,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlotgzz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"lemon07r","can_mod_post":false,"created_utc":1743942166,"send_replies":true,"parent_id":"t3_1jsshhe","score":402,"author_fullname":"t2_i697e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And the worst part is, it's not even good for its size.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlotgzz","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And the worst part is, it&amp;#39;s not even good for its size.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlotgzz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743942166,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":402}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlr86gs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BuildAQuad","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqpcdr","score":6,"author_fullname":"t2_p57a5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You could in theory run this on a dual xeon e5 server with 8 ddr4 lanes. With a theoretical t/s of around 9. But im looking forward to see some benchmarks here","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlr86gs","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You could in theory run this on a dual xeon e5 server with 8 ddr4 lanes. With a theoretical t/s of around 9. But im looking forward to see some benchmarks here&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlr86gs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743971454,"author_flair_text":null,"treatment_tags":[],"created_utc":1743971454,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlu1wun","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TechnicalGeologist99","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqpcdr","score":2,"author_fullname":"t2_6341erin","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In INT 4 it's about 0.5:1\\nINT 8 about 1:1\\nFP16 about 2:1\\nFP32 about 4:1\\n\\nIn bits:parameter\\n\\nThough I've noticed these models with interleaved layers like Gemma3 tend to have larger overheads at runtime. (Though that may also have been due to teething issues on ollama's part)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlu1wun","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In INT 4 it&amp;#39;s about 0.5:1\\nINT 8 about 1:1\\nFP16 about 2:1\\nFP32 about 4:1&lt;/p&gt;\\n\\n&lt;p&gt;In bits:parameter&lt;/p&gt;\\n\\n&lt;p&gt;Though I&amp;#39;ve noticed these models with interleaved layers like Gemma3 tend to have larger overheads at runtime. (Though that may also have been due to teething issues on ollama&amp;#39;s part)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlu1wun/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744016080,"author_flair_text":null,"treatment_tags":[],"created_utc":1744016080,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlzduev","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JerryWong048","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqpcdr","score":1,"author_fullname":"t2_23tc1x7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A big model a decade later will also be bigger. The average people are never meant to run a larger model locally, and that's fine really.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlzduev","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A big model a decade later will also be bigger. The average people are never meant to run a larger model locally, and that&amp;#39;s fine really.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlzduev/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744085816,"author_flair_text":null,"treatment_tags":[],"created_utc":1744085816,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqpcdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Seeker_Of_Knowledge2","can_mod_post":false,"created_utc":1743965404,"send_replies":true,"parent_id":"t1_mlpb93b","score":17,"author_fullname":"t2_slc08vd4x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;4x3090\\n\\nSo almost 1GB of Vram for every 1B? \\n\\nMan that is expensive.  I guess no big models for us poor consumers until a decade later.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqpcdr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;4x3090&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;So almost 1GB of Vram for every 1B? &lt;/p&gt;\\n\\n&lt;p&gt;Man that is expensive.  I guess no big models for us poor consumers until a decade later.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqpcdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965404,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mltjt74","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"some_user_2021","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpsmhw","score":1,"author_fullname":"t2_cmfeo4yq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We want to see your pp","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mltjt74","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We want to see your pp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mltjt74/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744004752,"author_flair_text":null,"treatment_tags":[],"created_utc":1744004752,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpsmhw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Distinct-Target7503","can_mod_post":false,"created_utc":1743954985,"send_replies":true,"parent_id":"t1_mlpb93b","score":15,"author_fullname":"t2_vl9fvibh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;running it on 4x3090 is not going to be a problem,\\n\\nhey, if you run it, please let us know the latency and token/sec","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpsmhw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;running it on 4x3090 is not going to be a problem,&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;hey, if you run it, please let us know the latency and token/sec&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpsmhw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743954985,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlswedc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CybaKilla","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqfkdr","score":1,"author_fullname":"t2_6fbo2kz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try 0.3 temp and set context and output tokens to correct values manually. Start with have actual stock.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlswedc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try 0.3 temp and set context and output tokens to correct values manually. Start with have actual stock.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlswedc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743993523,"author_flair_text":null,"treatment_tags":[],"created_utc":1743993523,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqfkdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ZippyZebras","can_mod_post":false,"created_utc":1743962300,"send_replies":true,"parent_id":"t1_mlpb93b","score":8,"author_fullname":"t2_2obsv3gu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Right now, it's not a useable model, and I don't believe we got a correctly working model.\\n\\nIt doesn't answer simple questions sensibly, it has very odd repetition problems, and it's less coherent than recent &lt;8B parameter models meant for edge use.\\n\\n---\\n\\nYou literally cannot not use this model for any usecase (business or personal) and see performance that's even *somewhat* comparable to any modern LLM release. \\n\\nEither something has gone fantastically wrong at Meta (so wrong that they're going to give up on LLMs) or we're simply seeing a broken Saturday release, and on Monday someone's going to realize they screwed up something and roll out a fix.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqfkdr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right now, it&amp;#39;s not a useable model, and I don&amp;#39;t believe we got a correctly working model.&lt;/p&gt;\\n\\n&lt;p&gt;It doesn&amp;#39;t answer simple questions sensibly, it has very odd repetition problems, and it&amp;#39;s less coherent than recent &amp;lt;8B parameter models meant for edge use.&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;You literally cannot not use this model for any usecase (business or personal) and see performance that&amp;#39;s even &lt;em&gt;somewhat&lt;/em&gt; comparable to any modern LLM release. &lt;/p&gt;\\n\\n&lt;p&gt;Either something has gone fantastically wrong at Meta (so wrong that they&amp;#39;re going to give up on LLMs) or we&amp;#39;re simply seeing a broken Saturday release, and on Monday someone&amp;#39;s going to realize they screwed up something and roll out a fix.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqfkdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962300,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqcpsl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"gpupoor","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpjj0p","score":6,"author_fullname":"t2_1hcyral852","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"???? this is a MoE with only *seventeen* billion active parameters, I suggest you to ask your local LLM what MoE entails","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlqcpsl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;???? this is a MoE with only &lt;em&gt;seventeen&lt;/em&gt; billion active parameters, I suggest you to ask your local LLM what MoE entails&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqcpsl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743961419,"author_flair_text":null,"treatment_tags":[],"created_utc":1743961419,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpjj0p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"created_utc":1743952003,"send_replies":true,"parent_id":"t1_mlpb93b","score":6,"author_fullname":"t2_8jqx3m14","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, the initial feedback wasn't great. I'd be interested to hear the comparison between Mistral Large 123B. Given that this has come some time after that, it would be very disappointing if it isn't significantly better than that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpjj0p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, the initial feedback wasn&amp;#39;t great. I&amp;#39;d be interested to hear the comparison between Mistral Large 123B. Given that this has come some time after that, it would be very disappointing if it isn&amp;#39;t significantly better than that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpjj0p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743952003,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpb93b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Lissanro","can_mod_post":false,"created_utc":1743949268,"send_replies":true,"parent_id":"t3_1jsshhe","score":77,"author_fullname":"t2_fpfao9g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My biggest concern that feedback so far is not exactly positive from people who tried it. And I am yet to see if its context size is as good as promised because in my experience needle in hay stack test does not mean much on its own, a model can be good at it and useless in the real world tasks that actually need the long context.\\n\\nAs of its size, it is smaller than Mistral Large 123B, Pixtral 124B or Command A 111B... so I assume running it on 4x3090 is not going to be a problem, but since there were no EXL2 or GGUF quants last time I checked, I did not tried it yet. But I plan to - I prefer to judge myself, since there are many different categories of tasks, even if it is not great general model, it could be useful for some long context tasks even if it just retrieving some data for a different LLM.","edited":1743949458,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpb93b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My biggest concern that feedback so far is not exactly positive from people who tried it. And I am yet to see if its context size is as good as promised because in my experience needle in hay stack test does not mean much on its own, a model can be good at it and useless in the real world tasks that actually need the long context.&lt;/p&gt;\\n\\n&lt;p&gt;As of its size, it is smaller than Mistral Large 123B, Pixtral 124B or Command A 111B... so I assume running it on 4x3090 is not going to be a problem, but since there were no EXL2 or GGUF quants last time I checked, I did not tried it yet. But I plan to - I prefer to judge myself, since there are many different categories of tasks, even if it is not great general model, it could be useful for some long context tasks even if it just retrieving some data for a different LLM.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpb93b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949268,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":77}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpo675","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Useful44723","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlosd7p","score":10,"author_fullname":"t2_13wwxa4z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The intermittent piracy of RAM always put the R in memory access.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpo675","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The intermittent piracy of RAM always put the R in memory access.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpo675/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743953540,"author_flair_text":null,"treatment_tags":[],"created_utc":1743953540,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mlosd7p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Apprehensive-Mark241","can_mod_post":false,"created_utc":1743941629,"send_replies":true,"parent_id":"t1_mlos955","score":43,"author_fullname":"t2_cgjdztdb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I downloaded some of yours, do you want it back?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlosd7p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I downloaded some of yours, do you want it back?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlosd7p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941629,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":43}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlph37k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jmsanzg","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpaze4","score":7,"author_fullname":"t2_4shfl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"After that install DoubleSpace and you can cuadruple the amount of storage!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlph37k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;After that install DoubleSpace and you can cuadruple the amount of storage!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlph37k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743951214,"author_flair_text":null,"treatment_tags":[],"created_utc":1743951214,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpf8u9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmvr","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpaze4","score":9,"author_fullname":"t2_11qlhv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/5lic0rbi88te1.jpeg?width=620&amp;format=pjpg&amp;auto=webp&amp;s=834d6c306b6833e7cdca1b24325c761708d68a37","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpf8u9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/5lic0rbi88te1.jpeg?width=620&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=834d6c306b6833e7cdca1b24325c761708d68a37\\"&gt;https://preview.redd.it/5lic0rbi88te1.jpeg?width=620&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=834d6c306b6833e7cdca1b24325c761708d68a37&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpf8u9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950605,"media_metadata":{"5lic0rbi88te1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":71,"x":108,"u":"https://preview.redd.it/5lic0rbi88te1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=872b53bd425e5dcbd15c5db79d43e5c01581845a"},{"y":143,"x":216,"u":"https://preview.redd.it/5lic0rbi88te1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bcc7f8d177df28ad57e178ff6030adbca0cb9014"},{"y":212,"x":320,"u":"https://preview.redd.it/5lic0rbi88te1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4c50e48c0e4d14254945bf78844ba9605d539ee"}],"s":{"y":412,"x":620,"u":"https://preview.redd.it/5lic0rbi88te1.jpeg?width=620&amp;format=pjpg&amp;auto=webp&amp;s=834d6c306b6833e7cdca1b24325c761708d68a37"},"id":"5lic0rbi88te1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1743950605,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpaze4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wkw3","can_mod_post":false,"created_utc":1743949174,"send_replies":true,"parent_id":"t1_mlos955","score":16,"author_fullname":"t2_3npyc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Download Stacker and double your storage capacity immediately!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpaze4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Download Stacker and double your storage capacity immediately!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpaze4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949174,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlue8z9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"VisitingCookies","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpfsdz","score":2,"author_fullname":"t2_scl10","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I downloaded RAM (ford car)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlue8z9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I downloaded RAM (ford car)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlue8z9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744023617,"author_flair_text":null,"treatment_tags":[],"created_utc":1744023617,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpfsdz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dutch_dynamite","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpf0hg","score":4,"author_fullname":"t2_aa9c721qm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I dont think you would","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpfsdz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I dont think you would&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpfsdz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950786,"author_flair_text":null,"treatment_tags":[],"created_utc":1743950786,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpf0hg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OrdoRidiculous","can_mod_post":false,"created_utc":1743950528,"send_replies":true,"parent_id":"t1_mlos955","score":8,"author_fullname":"t2_h8cmiarlt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I downloaded a car","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpf0hg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I downloaded a car&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpf0hg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950528,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpegrx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"UniqueAttourney","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpb19y","score":7,"author_fullname":"t2_p45vso65","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"he never recovered","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpegrx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;he never recovered&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpegrx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950349,"author_flair_text":null,"treatment_tags":[],"created_utc":1743950349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpb19y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hunting-Succcubus","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp9ou4","score":8,"author_fullname":"t2_3wxyen0t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i once downloaded porno","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpb19y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i once downloaded porno&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpb19y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949192,"author_flair_text":null,"treatment_tags":[],"created_utc":1743949192,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp9ou4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MarinatedPickachu","can_mod_post":false,"created_utc":1743948727,"send_replies":true,"parent_id":"t1_mlos955","score":6,"author_fullname":"t2_bwdb8qqfj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I once dowloaded a modem","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp9ou4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I once dowloaded a modem&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp9ou4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743948727,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlsxnlr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"avalon01","can_mod_post":false,"created_utc":1743994032,"send_replies":true,"parent_id":"t1_mlos955","score":1,"author_fullname":"t2_9mg9b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I remember SoftRAM! Got scammed by that way back in 1995 when I was a kid and wanted to play Star Wars: Dark Forces","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlsxnlr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I remember SoftRAM! Got scammed by that way back in 1995 when I was a kid and wanted to play Star Wars: Dark Forces&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlsxnlr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743994032,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlos955","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Titanusgamer","can_mod_post":false,"created_utc":1743941572,"send_replies":true,"parent_id":"t3_1jsshhe","score":152,"author_fullname":"t2_4aytq2jc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"back in my day you could download more RAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlos955","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;back in my day you could download more RAM.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlos955/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941572,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":152}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"moxm0cz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Haunting-Young6488","can_mod_post":false,"created_utc":1745566487,"send_replies":true,"parent_id":"t1_mlorc47","score":1,"author_fullname":"t2_1guvrev0in","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Hey, I was trying to load it in my H100 (single GPU) but it didn't work out... I found out that even after int4 quantization, I am not able to get the model size reduces by 4x when compared to fp16 (fp16 size is 207 GB appx). Can you help me with this? I am using bitsandbytes config with \\"nf4\\" quant.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_moxm0cz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, I was trying to load it in my H100 (single GPU) but it didn&amp;#39;t work out... I found out that even after int4 quantization, I am not able to get the model size reduces by 4x when compared to fp16 (fp16 size is 207 GB appx). Can you help me with this? I am using bitsandbytes config with &amp;quot;nf4&amp;quot; quant.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/moxm0cz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745566487,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlorc47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DeltaSqueezer","can_mod_post":false,"created_utc":1743941117,"send_replies":true,"parent_id":"t3_1jsshhe","score":67,"author_fullname":"t2_8jqx3m14","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Also fits in a RTX 6000 Pro 96GB.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlorc47","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also fits in a RTX 6000 Pro 96GB.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlorc47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941117,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":67}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrbfel","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DunamisMax","can_mod_post":false,"created_utc":1743972475,"send_replies":true,"parent_id":"t1_mlppm1t","score":1,"author_fullname":"t2_122qvtjo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And is a fantastic model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlrbfel","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And is a fantastic model&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrbfel/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743972475,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlppm1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sicarius_The_First","can_mod_post":false,"created_utc":1743954007,"send_replies":true,"parent_id":"t3_1jsshhe","score":23,"author_fullname":"t2_ik8czvp65","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Meanwhile Gemma3 runs on my toaster and smart fridge","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlppm1t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meanwhile Gemma3 runs on my toaster and smart fridge&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlppm1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743954007,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlrnf3k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Maleficent_Age1577","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq9vsc","score":4,"author_fullname":"t2_gxl5vlowd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hardware pretty much do last. people do use 10y old nvidia gpus and intels dont they? mostly hardware gets updated, not because it breaks down.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlrnf3k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hardware pretty much do last. people do use 10y old nvidia gpus and intels dont they? mostly hardware gets updated, not because it breaks down.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrnf3k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743976517,"author_flair_text":null,"treatment_tags":[],"created_utc":1743976517,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqguhc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq9vsc","score":2,"author_fullname":"t2_1jwmlwo64i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's why I buy the warranty and amortize that across the years of ownership. \\n\\n-\\n\\nI dont know what kind of deal datacenters get, but they are making hella money inferencing against the cost of the cards. The market should flood soon with h100's. I'm down for it and I hope we don't let China suck them all up.\\n\\n-\\n\\n\\nThe only reason solar isn't even cheaper in the United States is because we let China beat us to being the leader in that industry and we tariff the snot out of solar panels imported from China.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlqguhc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s why I buy the warranty and amortize that across the years of ownership. &lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;I dont know what kind of deal datacenters get, but they are making hella money inferencing against the cost of the cards. The market should flood soon with h100&amp;#39;s. I&amp;#39;m down for it and I hope we don&amp;#39;t let China suck them all up.&lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;The only reason solar isn&amp;#39;t even cheaper in the United States is because we let China beat us to being the leader in that industry and we tariff the snot out of solar panels imported from China.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqguhc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962702,"author_flair_text":null,"treatment_tags":[],"created_utc":1743962702,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq9vsc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sluuuurp","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq46co","score":11,"author_fullname":"t2_jqr3y","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, if you think hardware lasts forever and is free. With that logic all the data centers are free too.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlq9vsc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, if you think hardware lasts forever and is free. With that logic all the data centers are free too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq9vsc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960532,"author_flair_text":null,"treatment_tags":[],"created_utc":1743960532,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mls072r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maleficent_Age1577","can_mod_post":false,"created_utc":1743981103,"send_replies":true,"parent_id":"t1_mlrwjau","score":1,"author_fullname":"t2_gxl5vlowd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"for that use, sure its cheaper. you could probably go with free chatgpt version too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mls072r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;for that use, sure its cheaper. you could probably go with free chatgpt version too.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mls072r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743981103,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlrwjau","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ivxk","can_mod_post":false,"created_utc":1743979787,"send_replies":true,"parent_id":"t1_mlrn67j","score":2,"author_fullname":"t2_945b9bd4","approved_by":null,"mod_note":null,"all_awardings":[],"body":"4o-mini is 0.6/Mt, and DeepseekV3 is 1.1/Mt.\\n\\nI don't need image/video/audio, all i use is text API on low volume stuff, on preferably stronger models. I'm probably on the deep end of this cost discrepancy, but even then a 5k rig for a 20/month is still 20 years worth.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlrwjau","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4o-mini is 0.6/Mt, and DeepseekV3 is 1.1/Mt.&lt;/p&gt;\\n\\n&lt;p&gt;I don&amp;#39;t need image/video/audio, all i use is text API on low volume stuff, on preferably stronger models. I&amp;#39;m probably on the deep end of this cost discrepancy, but even then a 5k rig for a 20/month is still 20 years worth.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrwjau/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743979787,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlrn67j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maleficent_Age1577","can_mod_post":false,"created_utc":1743976429,"send_replies":true,"parent_id":"t1_mlr7cqr","score":1,"author_fullname":"t2_gxl5vlowd","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unlimited chatgpt is 200 / m\\n\\nVideoservices are about 1000-3000 / y\\n\\n4x3090 and rig is about 4-5k. \\n\\nI have no idea where you get 15k rig for less than 10$ / m.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlrn67j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unlimited chatgpt is 200 / m&lt;/p&gt;\\n\\n&lt;p&gt;Videoservices are about 1000-3000 / y&lt;/p&gt;\\n\\n&lt;p&gt;4x3090 and rig is about 4-5k. &lt;/p&gt;\\n\\n&lt;p&gt;I have no idea where you get 15k rig for less than 10$ / m.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlrn67j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743976429,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlr7cqr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ivxk","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqb957","score":2,"author_fullname":"t2_945b9bd4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It really it is sad that local is the premium option. I spend less than 10$ a month on models that I'd need at least a 15k rig to run locally on any useable speed, that's 125 years of subscription on a machine that id not have another serious use for.\\n\\nI even switched one of my personal projects to Mistral free tier because I'd beet to use it three times as much for it to hit the rate limit.\\n\\nMaybe after the bubble bursts, inferences cost rise and GPUs drop it may look better. As it stands it's comically expensive to run locally compared to using any inference service. Especially for bulk inference, as some services offer dirt cheap prices for that.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlr7cqr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It really it is sad that local is the premium option. I spend less than 10$ a month on models that I&amp;#39;d need at least a 15k rig to run locally on any useable speed, that&amp;#39;s 125 years of subscription on a machine that id not have another serious use for.&lt;/p&gt;\\n\\n&lt;p&gt;I even switched one of my personal projects to Mistral free tier because I&amp;#39;d beet to use it three times as much for it to hit the rate limit.&lt;/p&gt;\\n\\n&lt;p&gt;Maybe after the bubble bursts, inferences cost rise and GPUs drop it may look better. As it stands it&amp;#39;s comically expensive to run locally compared to using any inference service. Especially for bulk inference, as some services offer dirt cheap prices for that.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlr7cqr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743971194,"author_flair_text":null,"treatment_tags":[],"created_utc":1743971194,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqb957","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikew_reddit","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq46co","score":8,"author_fullname":"t2_h0ea9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Solar panels, charge controller, batteries, inverter, wiring, mounts for the panels + ground or roof top space, ground rods, tools,  probably want a monitoring system and the knowledge and time to put all of this together if you do-it-yourself.\\n\\nThousand dollars minimum depending on your power requirements. Or spend more to save time and  buy an all-in-one system.\\n\\nMain point is it's certainly not cheap; and you'd have to weigh it against the many years of AI subscriptions this would pay for.","edited":1744043089,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqb957","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Solar panels, charge controller, batteries, inverter, wiring, mounts for the panels + ground or roof top space, ground rods, tools,  probably want a monitoring system and the knowledge and time to put all of this together if you do-it-yourself.&lt;/p&gt;\\n\\n&lt;p&gt;Thousand dollars minimum depending on your power requirements. Or spend more to save time and  buy an all-in-one system.&lt;/p&gt;\\n\\n&lt;p&gt;Main point is it&amp;#39;s certainly not cheap; and you&amp;#39;d have to weigh it against the many years of AI subscriptions this would pay for.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqb957/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960960,"author_flair_text":null,"treatment_tags":[],"created_utc":1743960960,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqd00y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"timschwartz","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq46co","score":1,"author_fullname":"t2_3co8s","approved_by":null,"mod_note":null,"all_awardings":[],"body":"lol","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqd00y","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqd00y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743961507,"author_flair_text":null,"treatment_tags":[],"created_utc":1743961507,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq46co","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Wildfire788","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlphe9o","score":-5,"author_fullname":"t2_al69jl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A couple solar panels and your operating costs approach zero???","edited":false,"author_flair_css_class":null,"name":"t1_mlq46co","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A couple solar panels and your operating costs approach zero???&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq46co/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743958745,"author_flair_text":null,"collapsed":true,"created_utc":1743958745,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlphe9o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sluuuurp","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlperpb","score":15,"author_fullname":"t2_jqr3y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree locally is much more private. But locally is much more expensive, we could never compete with datacenter operating costs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlphe9o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree locally is much more private. But locally is much more expensive, we could never compete with datacenter operating costs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlphe9o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743951315,"author_flair_text":null,"treatment_tags":[],"created_utc":1743951315,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mlperpb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Maleficent_Age1577","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0akl","score":29,"author_fullname":"t2_gxl5vlowd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We all should think locally. \\n\\nThinking consumerism way we lack both privacy and cheap operating costs.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlperpb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We all should think locally. &lt;/p&gt;\\n\\n&lt;p&gt;Thinking consumerism way we lack both privacy and cheap operating costs.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlperpb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950449,"author_flair_text":null,"treatment_tags":[],"created_utc":1743950449,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp8rze","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Aaaaaaaaaeeeee","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp6fj1","score":3,"author_fullname":"t2_el5pibmej","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, I'm just curious. I don't really know how to calculate the number either like llms But I think if you quantize the KV you can get good enough milage to summarize a book or 2!","edited":false,"author_flair_css_class":null,"name":"t1_mlp8rze","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, I&amp;#39;m just curious. I don&amp;#39;t really know how to calculate the number either like llms But I think if you quantize the KV you can get good enough milage to summarize a book or 2!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp8rze/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743948403,"author_flair_text":null,"collapsed":false,"created_utc":1743948403,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp6fj1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sluuuurp","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp4sqr","score":7,"author_fullname":"t2_jqr3y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"99% of AI inference happens at very short context lengths. And the total size of all experts is somewhat unrelated to the size of the KV cache at long contexts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp6fj1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;99% of AI inference happens at very short context lengths. And the total size of all experts is somewhat unrelated to the size of the KV cache at long contexts.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp6fj1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947556,"author_flair_text":null,"treatment_tags":[],"created_utc":1743947556,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp4sqr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Aaaaaaaaaeeeee","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0akl","score":-5,"author_fullname":"t2_el5pibmej","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much ram is needed for kvcache of 10M? Apparently LLMs don't all agree when asked and given the config, 23000GB or 1750GB, which would still be an unshakeable number compared to SSM. 10M looks tough for providers.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlp4sqr","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much ram is needed for kvcache of 10M? Apparently LLMs don&amp;#39;t all agree when asked and given the config, 23000GB or 1750GB, which would still be an unshakeable number compared to SSM. 10M looks tough for providers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp4sqr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743946950,"author_flair_text":null,"treatment_tags":[],"created_utc":1743946950,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlptzpt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Distinct-Target7503","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0akl","score":-1,"author_fullname":"t2_vl9fvibh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"also that's relevant for training... using a MoE let you train natively on much longer context length. another relevant aspect in that direction is their interleaved attention, aka layers with global attention + layers with sliding window (nothing new... command A, R7B, ModernBERT and EuroBERT used that approach) \\n\\nie minimax trained natively on 1M context, using MoE and interleaved layers (anyway, they used layers with lightning attention instead of the sliding window (so still 'global') , interleaved with layers with classic softmax global attention like other transformers","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlptzpt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;also that&amp;#39;s relevant for training... using a MoE let you train natively on much longer context length. another relevant aspect in that direction is their interleaved attention, aka layers with global attention + layers with sliding window (nothing new... command A, R7B, ModernBERT and EuroBERT used that approach) &lt;/p&gt;\\n\\n&lt;p&gt;ie minimax trained natively on 1M context, using MoE and interleaved layers (anyway, they used layers with lightning attention instead of the sliding window (so still &amp;#39;global&amp;#39;) , interleaved with layers with classic softmax global attention like other transformers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlptzpt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743955427,"author_flair_text":null,"treatment_tags":[],"created_utc":1743955427,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqvn7c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eisenstein","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqgpz8","score":4,"author_fullname":"t2_5aiux","approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you don't think Zuck operates in 'grand schemes' you have never read any of his leaked emails.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqvn7c","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you don&amp;#39;t think Zuck operates in &amp;#39;grand schemes&amp;#39; you have never read any of his leaked emails.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqvn7c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743967452,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1743967452,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqgpz8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dead_Internet_Theory","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq94rm","score":1,"author_fullname":"t2_srolmvkm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"???\\n\\nWhat does Meta gain from sabotaging OpenAI at the cost of billions of dollars? You're making it sound like a grand scheme but I don't see how it benefits them to do this much to \\"sabotage OpenAI\\".","edited":false,"author_flair_css_class":null,"name":"t1_mlqgpz8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;???&lt;/p&gt;\\n\\n&lt;p&gt;What does Meta gain from sabotaging OpenAI at the cost of billions of dollars? You&amp;#39;re making it sound like a grand scheme but I don&amp;#39;t see how it benefits them to do this much to &amp;quot;sabotage OpenAI&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqgpz8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962663,"author_flair_text":null,"collapsed":false,"created_utc":1743962663,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq94rm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inteblio","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq5oma","score":3,"author_fullname":"t2_bzdh4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The whole point was to sabotage openAI by outsourcing innovation to \\"the open source community\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq94rm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The whole point was to sabotage openAI by outsourcing innovation to &amp;quot;the open source community&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq94rm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960302,"author_flair_text":null,"treatment_tags":[],"created_utc":1743960302,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqilg9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sluuuurp","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq5oma","score":1,"author_fullname":"t2_jqr3y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yes. This still accomplishes that, now it can run in any data center and not just on OpenAI/Microsoft data centers, thats much less centralized.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqilg9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes. This still accomplishes that, now it can run in any data center and not just on OpenAI/Microsoft data centers, thats much less centralized.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqilg9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963256,"author_flair_text":null,"treatment_tags":[],"created_utc":1743963256,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq5oma","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Dead_Internet_Theory","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp0akl","score":-1,"author_fullname":"t2_srolmvkm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Isn't the whole point of Llama to decentralize LLMs?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlq5oma","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t the whole point of Llama to decentralize LLMs?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq5oma/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743959222,"author_flair_text":null,"treatment_tags":[],"created_utc":1743959222,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp0akl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sluuuurp","can_mod_post":false,"created_utc":1743945185,"send_replies":true,"parent_id":"t1_mlorlme","score":56,"author_fullname":"t2_jqr3y","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Youre thinking locally. Fitting things into VRAM isnt the main bottleneck for data centers. And 99% of AI inference happens in data centers rather than locally.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp0akl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Youre thinking locally. Fitting things into VRAM isnt the main bottleneck for data centers. And 99% of AI inference happens in data centers rather than locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp0akl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743945185,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":56}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mlqo5z9","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqo5z9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1743965027,"send_replies":true,"parent_id":"t1_mlqi2he","score":1,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh man, that's the dream. A real balanced model in sizes for everyone. If I was meta I would do all that stuff and just not put it in writing. Maybe a smarter company will go that route. \\n\\nI heard good things about grok and then I heard it got censored over time so Elon isn't paying much more attention than these other corporate heads. Nobody will eat their own dogfood so we can't have nice things.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqo5z9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh man, that&amp;#39;s the dream. A real balanced model in sizes for everyone. If I was meta I would do all that stuff and just not put it in writing. Maybe a smarter company will go that route. &lt;/p&gt;\\n\\n&lt;p&gt;I heard good things about grok and then I heard it got censored over time so Elon isn&amp;#39;t paying much more attention than these other corporate heads. Nobody will eat their own dogfood so we can&amp;#39;t have nice things.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqo5z9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965027,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqi2he","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dead_Internet_Theory","can_mod_post":false,"created_utc":1743963088,"send_replies":true,"parent_id":"t1_mlqd78a","score":5,"author_fullname":"t2_srolmvkm","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I cannot even imagine how good a model would be if you fired every single trust and safety employee from a huge company like Meta and only paid people that make the model better instead of worse. They even committed a crime with that 81TB torrent (the crime being not seeding after downloading, obviously) but somehow it's like HR is in the room.\\n\\nMy hope is Elon tries throwing stuff at Grok for a while one day, goes \\"wtf?\\" and DOGE's his own company. The money is there, unlike with DeepSeek that did their best with what they had.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlqi2he","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I cannot even imagine how good a model would be if you fired every single trust and safety employee from a huge company like Meta and only paid people that make the model better instead of worse. They even committed a crime with that 81TB torrent (the crime being not seeding after downloading, obviously) but somehow it&amp;#39;s like HR is in the room.&lt;/p&gt;\\n\\n&lt;p&gt;My hope is Elon tries throwing stuff at Grok for a while one day, goes &amp;quot;wtf?&amp;quot; and DOGE&amp;#39;s his own company. The money is there, unlike with DeepSeek that did their best with what they had.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqi2he/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963088,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqd78a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1743961569,"send_replies":true,"parent_id":"t1_mlq98yw","score":2,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not a bad theory. Probably less truck stop novels in china. They also don't care about copyrights and just took the best, widest variety of data.\\n\\nScout: https://ibb.co/gLmWV1Gz\\n\\nGemini-2.5: https://ibb.co/KYbzJFg\\n\\nForgotten-Abomination (L3 merge): https://ibb.co/5gC8SxVW\\n\\nLast one I'm not even that happy with over the nevoria it's made from, but L4, come on.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlqd78a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not a bad theory. Probably less truck stop novels in china. They also don&amp;#39;t care about copyrights and just took the best, widest variety of data.&lt;/p&gt;\\n\\n&lt;p&gt;Scout: &lt;a href=\\"https://ibb.co/gLmWV1Gz\\"&gt;https://ibb.co/gLmWV1Gz&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Gemini-2.5: &lt;a href=\\"https://ibb.co/KYbzJFg\\"&gt;https://ibb.co/KYbzJFg&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Forgotten-Abomination (L3 merge): &lt;a href=\\"https://ibb.co/5gC8SxVW\\"&gt;https://ibb.co/5gC8SxVW&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Last one I&amp;#39;m not even that happy with over the nevoria it&amp;#39;s made from, but L4, come on.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqd78a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743961569,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq98yw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dead_Internet_Theory","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq70an","score":4,"author_fullname":"t2_srolmvkm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, DeepSeek is so good by comparison. Of course we can't run it locally, but it's not nearly that level of slop that LLama has.\\n\\nMy theory is that DeepSeek, despite speaking in English, learnt a lot from Chinese content, and content that is widely pirated in China. China is much more conservative than the west, so it probably doesn't come across all the safe and mollycoddled language that we often associate with \\"slop\\" like \\"shivers down the spine\\", \\"barely above a whisper\\" and other descriptions that you expect on a children's novel or female literature.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mlq98yw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, DeepSeek is so good by comparison. Of course we can&amp;#39;t run it locally, but it&amp;#39;s not nearly that level of slop that LLama has.&lt;/p&gt;\\n\\n&lt;p&gt;My theory is that DeepSeek, despite speaking in English, learnt a lot from Chinese content, and content that is widely pirated in China. China is much more conservative than the west, so it probably doesn&amp;#39;t come across all the safe and mollycoddled language that we often associate with &amp;quot;slop&amp;quot; like &amp;quot;shivers down the spine&amp;quot;, &amp;quot;barely above a whisper&amp;quot; and other descriptions that you expect on a children&amp;#39;s novel or female literature.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq98yw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960338,"author_flair_text":null,"treatment_tags":[],"created_utc":1743960338,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq70an","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq63ot","score":2,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"We used to laugh at this. *Yea next llama is going to be 3b and 200b.*\\n\\nI'm cool with a 109b, but not one that has the smarts of a 40b. The only way they can save it is if the reasoning elevates it back up to dense level. After using the models on OR, not holding my breath.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlq70an","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We used to laugh at this. &lt;em&gt;Yea next llama is going to be 3b and 200b.&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m cool with a 109b, but not one that has the smarts of a 40b. The only way they can save it is if the reasoning elevates it back up to dense level. After using the models on OR, not holding my breath.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq70an/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743959639,"author_flair_text":null,"treatment_tags":[],"created_utc":1743959639,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq63ot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dead_Internet_Theory","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq2r9p","score":4,"author_fullname":"t2_srolmvkm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The choice between 7B or 109B is kinda sad! Then again, I don't think base 109B would be of much use outside of the certainly helpful 10M context.","edited":false,"author_flair_css_class":null,"name":"t1_mlq63ot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The choice between 7B or 109B is kinda sad! Then again, I don&amp;#39;t think base 109B would be of much use outside of the certainly helpful 10M context.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq63ot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743959353,"author_flair_text":null,"collapsed":false,"created_utc":1743959353,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq2r9p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpykim","score":1,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Meta started thinking about providers. Selling it on being cheaper to host with many users at once. *You only need the compute of a 17b when processing your giga-batches*\\n\\nIf the mask didn't fall off when they dropped their 30b models completely, it certainly did now. But hey, someone found some 7b strings so maybe that is what's coming for llama-*con*.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq2r9p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta started thinking about providers. Selling it on being cheaper to host with many users at once. &lt;em&gt;You only need the compute of a 17b when processing your giga-batches&lt;/em&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If the mask didn&amp;#39;t fall off when they dropped their 30b models completely, it certainly did now. But hey, someone found some 7b strings so maybe that is what&amp;#39;s coming for llama-&lt;em&gt;con&lt;/em&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq2r9p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743958292,"author_flair_text":null,"treatment_tags":[],"created_utc":1743958292,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpykim","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eisenstein","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlovjc5","score":6,"author_fullname":"t2_5aiux","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That doesn't explain it though. Mixtral is a forgotten memory from Llama 2 days, and I can't imagine they only started thinking about Llama 4 architecture after Deepseek R1 came out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpykim","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That doesn&amp;#39;t explain it though. Mixtral is a forgotten memory from Llama 2 days, and I can&amp;#39;t imagine they only started thinking about Llama 4 architecture after Deepseek R1 came out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpykim/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743956930,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1743956930,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mlovjc5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1743943133,"send_replies":true,"parent_id":"t1_mlorlme","score":22,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It 100% comes from mixtral. People ran it on a potato and the training data made it closer to a 70b of the time. R1 hype reinforced that idea. \\n\\nJust like that people started to advocate for an architecture that mainly helps providers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlovjc5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It 100% comes from mixtral. People ran it on a potato and the training data made it closer to a 70b of the time. R1 hype reinforced that idea. &lt;/p&gt;\\n\\n&lt;p&gt;Just like that people started to advocate for an architecture that mainly helps providers.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlovjc5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743943133,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqq7e5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Eastwindy123","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpw1ne","score":3,"author_fullname":"t2_b7rpxtz6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama scout should fit easily in a g6.12x instance. And be way faster than llama 3 70b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqq7e5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama scout should fit easily in a g6.12x instance. And be way faster than llama 3 70b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqq7e5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965684,"author_flair_text":null,"treatment_tags":[],"created_utc":1743965684,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpw1ne","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nore_se_kra","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlotyp7","score":3,"author_fullname":"t2_1bpvzzmckh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I always hear \\"its for enterprises\\" but how many enterprises have these kind of gpus in their basement? My enterprise not, i have to escalate to google to get a H200 and it still takes a while.. despite premium support and whatnot.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpw1ne","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I always hear &amp;quot;its for enterprises&amp;quot; but how many enterprises have these kind of gpus in their basement? My enterprise not, i have to escalate to google to get a H200 and it still takes a while.. despite premium support and whatnot.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpw1ne/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743956106,"author_flair_text":null,"treatment_tags":[],"created_utc":1743956106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpbama","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Hunting-Succcubus","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlotyp7","score":-5,"author_fullname":"t2_3wxyen0t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"power user mean elon musk?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpbama","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;power user mean elon musk?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpbama/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949282,"author_flair_text":null,"treatment_tags":[],"created_utc":1743949282,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlotyp7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eastwindy123","can_mod_post":false,"created_utc":1743942402,"send_replies":true,"parent_id":"t1_mlorlme","score":20,"author_fullname":"t2_b7rpxtz6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is for enterprise and power users. This is amazing for someone like me for example where I run millions of inference daily at my work. As long as performance is comparable this is 4x improvement in throughput.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlotyp7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is for enterprise and power users. This is amazing for someone like me for example where I run millions of inference daily at my work. As long as performance is comparable this is 4x improvement in throughput.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlotyp7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743942402,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlr03yt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"itchykittehs","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq66x3","score":1,"author_fullname":"t2_38jclcjj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, I went for it, and it's sweet...deepseek 3.1 quant 4 at  18-20 tk/s is really pretty good. It's not perfect, but it ain't bad =)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlr03yt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I went for it, and it&amp;#39;s sweet...deepseek 3.1 quant 4 at  18-20 tk/s is really pretty good. It&amp;#39;s not perfect, but it ain&amp;#39;t bad =)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlr03yt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743968919,"author_flair_text":null,"treatment_tags":[],"created_utc":1743968919,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq66x3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Slackalope2","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlovrks","score":2,"author_fullname":"t2_1812z8kb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The DGX spark looks promising for sure, especially with these new MOE models. Been agonizing over the choice between picking up a couple sparks or just getting a m3 ultra with 512gb.\\n\\nI'm leaning toward the mac because I don't think Nvidia will have solved the scarcity problem by then. The ultra studios are available and replaceable right now.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlq66x3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The DGX spark looks promising for sure, especially with these new MOE models. Been agonizing over the choice between picking up a couple sparks or just getting a m3 ultra with 512gb.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m leaning toward the mac because I don&amp;#39;t think Nvidia will have solved the scarcity problem by then. The ultra studios are available and replaceable right now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq66x3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743959381,"author_flair_text":null,"treatment_tags":[],"created_utc":1743959381,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlovrks","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1743943236,"send_replies":true,"parent_id":"t1_mlorlme","score":7,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It works very well on Macs with integrated memory. And should be perfect for those new specialized ai computers like Digits with 260GBps memory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlovrks","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It works very well on Macs with integrated memory. And should be perfect for those new specialized ai computers like Digits with 260GBps memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlovrks/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743943236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpfkt4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"stduhpf","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp684n","score":2,"author_fullname":"t2_yzn9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Deepseek V2 lite and similar things like the recent Ling Lite (and hopefully Qwen 3 soon) are actually pretty nice for local use. Small MoEs are good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpfkt4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek V2 lite and similar things like the recent Ling Lite (and hopefully Qwen 3 soon) are actually pretty nice for local use. Small MoEs are good.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpfkt4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950716,"author_flair_text":null,"treatment_tags":[],"created_utc":1743950716,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp684n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LoSboccacc","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp4n8z","score":5,"author_fullname":"t2_dievh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"nah, prompt processing would suck the life out of these solutions.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlp684n","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nah, prompt processing would suck the life out of these solutions.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp684n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947482,"author_flair_text":null,"treatment_tags":[],"created_utc":1743947482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp4n8z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Euphoric_Ad9500","can_mod_post":false,"created_utc":1743946894,"send_replies":true,"parent_id":"t1_mlorlme","score":4,"author_fullname":"t2_8kbjrt7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I actually think MOE is the future for local ai with the way Macs and ai mini pc are going where they have lots of ram but poor compute","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp4n8z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I actually think MOE is the future for local ai with the way Macs and ai mini pc are going where they have lots of ram but poor compute&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp4n8z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743946894,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpzr2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Eisenstein","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp567b","score":2,"author_fullname":"t2_5aiux","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meta isn't making money from hobbyists for sure, but it is getting a ton of free tooling and repairing their image amongst the tech crowd.  Facebook has a legacy of playing to that crowd by releasing a lot of their tools that no normal person would ever care about, but the people they might want to hire would like. They had some real trouble getting talent when they went all-in publicly on being evil and tried to walk it back a bit. Who knows though, the way things are looking they may have just said 'fuck it, lets do what we do best and not hide it' at this point.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpzr2k","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta isn&amp;#39;t making money from hobbyists for sure, but it is getting a ton of free tooling and repairing their image amongst the tech crowd.  Facebook has a legacy of playing to that crowd by releasing a lot of their tools that no normal person would ever care about, but the people they might want to hire would like. They had some real trouble getting talent when they went all-in publicly on being evil and tried to walk it back a bit. Who knows though, the way things are looking they may have just said &amp;#39;fuck it, lets do what we do best and not hide it&amp;#39; at this point.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpzr2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743957318,"author_flair_text":"Alpaca","treatment_tags":[],"created_utc":1743957318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp567b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1743947089,"send_replies":true,"parent_id":"t1_mlorlme","score":4,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It works better if you have scale, as in you want to serve your models to 300 million users on 16384 GPUs. There, compute is the bottleneck and this approach can make your model 2-3x cheaper.\\n\\nVRAM size and bandwidth is mostly a concern for people running LLMs on small home hobbyist scale, which is honestly not a huge market as it's not as economically viable as running 300 concurrent requests on datacenter GPUs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp567b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It works better if you have scale, as in you want to serve your models to 300 million users on 16384 GPUs. There, compute is the bottleneck and this approach can make your model 2-3x cheaper.&lt;/p&gt;\\n\\n&lt;p&gt;VRAM size and bandwidth is mostly a concern for people running LLMs on small home hobbyist scale, which is honestly not a huge market as it&amp;#39;s not as economically viable as running 300 concurrent requests on datacenter GPUs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp567b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947089,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp4u7g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Paint-9490","can_mod_post":false,"created_utc":1743946966,"send_replies":true,"parent_id":"t1_mlorlme","score":3,"author_fullname":"t2_rpm5owysg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can run MoE in system RAM, so no need for \\"enough\\" VRAM. You can do without GPU altogether, or use one much smaller than the whole model footprint.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp4u7g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can run MoE in system RAM, so no need for &amp;quot;enough&amp;quot; VRAM. You can do without GPU altogether, or use one much smaller than the whole model footprint.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp4u7g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743946966,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp8roo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1743948400,"send_replies":true,"parent_id":"t1_mlorlme","score":2,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think at an industrial scale, the limit is compute (especially for training), and locally the limit is memory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp8roo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think at an industrial scale, the limit is compute (especially for training), and locally the limit is memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp8roo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743948400,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp30vv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1743946279,"send_replies":true,"parent_id":"t1_mlorlme","score":-4,"author_fullname":"t2_1by73qs5e5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meta clearly lacks the talent and vision to bring us frontier models any longer now that the Chinese have joined the game.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp30vv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta clearly lacks the talent and vision to bring us frontier models any longer now that the Chinese have joined the game.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp30vv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743946279,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlorlme","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nore_se_kra","can_mod_post":false,"created_utc":1743941249,"send_replies":true,"parent_id":"t3_1jsshhe","score":50,"author_fullname":"t2_1bpvzzmckh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah i dont get this MoE ram hungry  approach given that often the bottleneck today seems to get enough vram. I dont want to use like 4 times A100 or so","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlorlme","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah i dont get this MoE ram hungry  approach given that often the bottleneck today seems to get enough vram. I dont want to use like 4 times A100 or so&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlorlme/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743941249,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpam5b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SaynedBread","can_mod_post":false,"created_utc":1743949048,"send_replies":true,"parent_id":"t1_mlousok","score":8,"author_fullname":"t2_cfsztgp4x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, that is definitely slop. I actually get better responses with Gemma 3 27B (and even 12B), than with Llama 4 400B.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpam5b","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, that is definitely slop. I actually get better responses with Gemma 3 27B (and even 12B), than with Llama 4 400B.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpam5b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949048,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlp548m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Euphoric_Ad9500","can_mod_post":false,"created_utc":1743947068,"send_replies":true,"parent_id":"t1_mlousok","score":10,"author_fullname":"t2_8kbjrt7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I wonder if the slop factor is the difference in pre training tokens 40T for scout vs 22t for maverick!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp548m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if the slop factor is the difference in pre training tokens 40T for scout vs 22t for maverick!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp548m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947068,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpg2qk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1743950881,"send_replies":true,"parent_id":"t1_mlousok","score":9,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Fun fact when I tried Maverick out for RP literally the first message it generated had \\"Shivers down your spine\\" and \\"barely above a whisper\\" and I wasn't even trying to test the sloppiness, it was a completely normal prompt.\\n\\nThe model feels extremely sloppy, one of the worst I've experienced in a long time.","edited":1743951065,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpg2qk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fun fact when I tried Maverick out for RP literally the first message it generated had &amp;quot;Shivers down your spine&amp;quot; and &amp;quot;barely above a whisper&amp;quot; and I wasn&amp;#39;t even trying to test the sloppiness, it was a completely normal prompt.&lt;/p&gt;\\n\\n&lt;p&gt;The model feels extremely sloppy, one of the worst I&amp;#39;ve experienced in a long time.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpg2qk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950881,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"mlousok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1743942792,"send_replies":true,"parent_id":"t3_1jsshhe","score":28,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its up for free on open router now.\\n\\nThe 400b is bit average in performance to other mid models. Classically slopped. Slightly less censored. https://ibb.co/mVnLxV13\\n\\nThe 109b is dumber and more censored but slightly less sloppy. Did they really do that to us? For the one we even have a chance to use locally? https://ibb.co/CKxvt0ff\\n\\nThis is meta's idea of \\"dirty talk\\" as prompted for. Worthless is an understatement. I read somewhere they added child safety?! We are all children now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlousok","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its up for free on open router now.&lt;/p&gt;\\n\\n&lt;p&gt;The 400b is bit average in performance to other mid models. Classically slopped. Slightly less censored. &lt;a href=\\"https://ibb.co/mVnLxV13\\"&gt;https://ibb.co/mVnLxV13&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;The 109b is dumber and more censored but slightly less sloppy. Did they really do that to us? For the one we even have a chance to use locally? &lt;a href=\\"https://ibb.co/CKxvt0ff\\"&gt;https://ibb.co/CKxvt0ff&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This is meta&amp;#39;s idea of &amp;quot;dirty talk&amp;quot; as prompted for. Worthless is an understatement. I read somewhere they added child safety?! We are all children now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlousok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743942792,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqt05r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Extension_Wheel5335","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlprich","score":3,"author_fullname":"t2_o6tx4oh0s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unless I missed something in the last few months that seems insane to expect on a local model. Did something change?","edited":false,"author_flair_css_class":null,"name":"t1_mlqt05r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless I missed something in the last few months that seems insane to expect on a local model. Did something change?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqt05r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743966589,"author_flair_text":null,"collapsed":false,"created_utc":1743966589,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mlprich","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpmuih","score":-6,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"10 m","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlprich","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;10 m&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlprich/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743954622,"author_flair_text":null,"treatment_tags":[],"created_utc":1743954622,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpmuih","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tigraw","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlp7d62","score":6,"author_fullname":"t2_ys6gw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Define reasonable context size","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpmuih","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Define reasonable context size&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpmuih/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743953099,"author_flair_text":null,"treatment_tags":[],"created_utc":1743953099,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp7d62","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Healthy-Nebula-3603","can_mod_post":false,"created_utc":1743947895,"send_replies":true,"parent_id":"t1_mloz9tp","score":2,"author_fullname":"t2_ogjj6ebj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"128 GB ram is not enough to reasonable context size ...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlp7d62","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;128 GB ram is not enough to reasonable context size ...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp7d62/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743947895,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mloz9tp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ayyndrew","can_mod_post":false,"created_utc":1743944758,"send_replies":true,"parent_id":"t3_1jsshhe","score":20,"author_fullname":"t2_17dzkg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"people were saying digits/dgx spark and framework desktop were stuck in an awkward place, too slow for the 70b dense models but not enough ram for the relevant MoEs (v3 &amp; r1), llama 4 scout 109B seems perfect for those machines now\\n\\nassuming it's actually a good model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mloz9tp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;people were saying digits/dgx spark and framework desktop were stuck in an awkward place, too slow for the 70b dense models but not enough ram for the relevant MoEs (v3 &amp;amp; r1), llama 4 scout 109B seems perfect for those machines now&lt;/p&gt;\\n\\n&lt;p&gt;assuming it&amp;#39;s actually a good model&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mloz9tp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743944758,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":11,"removal_reason":null,"link_id":"t3_1jsshhe","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqfzml","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ZippyZebras","can_mod_post":false,"created_utc":1743962434,"send_replies":true,"parent_id":"t1_mlp804q","score":9,"author_fullname":"t2_2obsv3gu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a very bad model, even for business.\\n\\nI was extremely excited that they aimed at fitting in a single H100 for a target: it's in fact much easier to get good performing single H100s. Typically to get 2+ H100s with solid interconnects you need to go up to a full host with 8xH100.\\n\\nBut the performance is (currently) so abysmal there's absolutely no reason to take Command A/Deepseek V3/ R1 Distills/Llama 3.3 over this\\n\\nEdit: To clarify (and repeat myself like a broken record) I don't believe this is intentional, it smells like there's a bug or broken upload involved","edited":1743965234,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqfzml","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a very bad model, even for business.&lt;/p&gt;\\n\\n&lt;p&gt;I was extremely excited that they aimed at fitting in a single H100 for a target: it&amp;#39;s in fact much easier to get good performing single H100s. Typically to get 2+ H100s with solid interconnects you need to go up to a full host with 8xH100.&lt;/p&gt;\\n\\n&lt;p&gt;But the performance is (currently) so abysmal there&amp;#39;s absolutely no reason to take Command A/Deepseek V3/ R1 Distills/Llama 3.3 over this&lt;/p&gt;\\n\\n&lt;p&gt;Edit: To clarify (and repeat myself like a broken record) I don&amp;#39;t believe this is intentional, it smells like there&amp;#39;s a bug or broken upload involved&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqfzml/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962434,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpcey2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PermanentLiminality","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlpauwj","score":8,"author_fullname":"t2_19zqycaf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"They\\" are giving us models that fit in a 3090.   The \\"they\\" just doesn't include Meta.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlpcey2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;They&amp;quot; are giving us models that fit in a 3090.   The &amp;quot;they&amp;quot; just doesn&amp;#39;t include Meta.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpcey2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949660,"author_flair_text":null,"treatment_tags":[],"created_utc":1743949660,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mlpauwj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"phata-phat","can_mod_post":false,"created_utc":1743949131,"send_replies":true,"parent_id":"t1_mlp804q","score":12,"author_fullname":"t2_mukucqv5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We demand they give us models we can on our beloved 3090s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpauwj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We demand they give us models we can on our beloved 3090s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpauwj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743949131,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpjhsg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1743951992,"send_replies":true,"parent_id":"t1_mlp804q","score":3,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its possible someone will merge experts or cut parameters and get similar performance.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpjhsg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its possible someone will merge experts or cut parameters and get similar performance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpjhsg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743951992,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlpfver","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Maleficent_Age1577","can_mod_post":false,"created_utc":1743950814,"send_replies":true,"parent_id":"t1_mlp804q","score":0,"author_fullname":"t2_gxl5vlowd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And a model designed for one purpose would be much more efficient than a model that tries to be all that there is.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlpfver","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And a model designed for one purpose would be much more efficient than a model that tries to be all that there is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlpfver/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743950814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mlp804q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1jsshhe","score":11,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1744637980,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlp804q/","num_reports":null,"locked":false,"name":"t1_mlp804q","created":1743948126,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1743948126,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqkbjo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sammoga123","can_mod_post":false,"created_utc":1743963805,"send_replies":true,"parent_id":"t3_1jsshhe","score":2,"author_fullname":"t2_xqykf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think even Command A is better than this version of Llama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqkbjo","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think even Command A is better than this version of Llama&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqkbjo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963805,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqon64","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Borgie32","can_mod_post":false,"created_utc":1743965179,"send_replies":true,"parent_id":"t3_1jsshhe","score":2,"author_fullname":"t2_17f0kill40","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Rtx 6000 blackwell only option ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqon64","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Rtx 6000 blackwell only option &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqon64/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743965179,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlufh9v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqsgl4","score":2,"author_fullname":"t2_1jwmlwo64i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Demand and usecase has changed dramatically since the 1080ti. Nvidia was mostly a company that produced video accelerators. Today we have many more use cases for general processing units than before when we used them to game mostly. Gaming is now niche compared the revenues from selling general compute to datacenters. Ai is now the main focus for gpu's.\\n\\n-\\n\\nThe 1080ti was a stepping stone to what is being produced today, but the kinds of systems Nvidia are developing now are a new beast entirely. The kind of gains you want require moores law solely through transistors and we simply are not doubling anymore in that regard, but that does not mean that significant improvements in other areas have not been made. What does a 1080ti have to do with card configurations above 6 or 8? Really nothing. \\n\\n-\\n\\nThen ask yourself what it really takes to start scaling a system past 6-8 cards and interconnecting them. It's not the same engineering problem as building a single card and applying a new GPU with double the transistors. Nobody is handing them yeilds or scale they can market like that. At the end of the day it isn't Nvidia you are complaining about, it's TSMC who provides the raw fab.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlufh9v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Demand and usecase has changed dramatically since the 1080ti. Nvidia was mostly a company that produced video accelerators. Today we have many more use cases for general processing units than before when we used them to game mostly. Gaming is now niche compared the revenues from selling general compute to datacenters. Ai is now the main focus for gpu&amp;#39;s.&lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;The 1080ti was a stepping stone to what is being produced today, but the kinds of systems Nvidia are developing now are a new beast entirely. The kind of gains you want require moores law solely through transistors and we simply are not doubling anymore in that regard, but that does not mean that significant improvements in other areas have not been made. What does a 1080ti have to do with card configurations above 6 or 8? Really nothing. &lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;Then ask yourself what it really takes to start scaling a system past 6-8 cards and interconnecting them. It&amp;#39;s not the same engineering problem as building a single card and applying a new GPU with double the transistors. Nobody is handing them yeilds or scale they can market like that. At the end of the day it isn&amp;#39;t Nvidia you are complaining about, it&amp;#39;s TSMC who provides the raw fab.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlufh9v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744024233,"author_flair_text":null,"treatment_tags":[],"created_utc":1744024233,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlue0wi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mls46vn","score":1,"author_fullname":"t2_1jwmlwo64i","approved_by":null,"mod_note":null,"all_awardings":[],"body":"At the end of the day they have to make money to pay for innovation. RnD is not free. As a consumer I've actually always gotten surprisingly good value out of the GPU's even though they are expensive.\\n\\nThere is no replacement. \\n\\nInstead of talking about how Nvidia isn't trying as they push the boundaries of terra and petabye bandwidth you should be focusing your ire on Intel and AMD for essentially parting the seas for Nvidia to walk as a sole competitor.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mlue0wi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;At the end of the day they have to make money to pay for innovation. RnD is not free. As a consumer I&amp;#39;ve actually always gotten surprisingly good value out of the GPU&amp;#39;s even though they are expensive.&lt;/p&gt;\\n\\n&lt;p&gt;There is no replacement. &lt;/p&gt;\\n\\n&lt;p&gt;Instead of talking about how Nvidia isn&amp;#39;t trying as they push the boundaries of terra and petabye bandwidth you should be focusing your ire on Intel and AMD for essentially parting the seas for Nvidia to walk as a sole competitor.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlue0wi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744023506,"author_flair_text":null,"treatment_tags":[],"created_utc":1744023506,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mls46vn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TechnoByte_","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlru96e","score":1,"author_fullname":"t2_4w91lkml","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is a lack of trying, NVIDIA has a monopoly on the AI GPU market thanks to CUDA, they have no reason to innovate when they can just make tiny improvements once every few years while using misleading marketing to make people think they're actually improving and keep buying their horribly overpriced GPUs","edited":false,"author_flair_css_class":null,"name":"t1_mls46vn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is a lack of trying, NVIDIA has a monopoly on the AI GPU market thanks to CUDA, they have no reason to innovate when they can just make tiny improvements once every few years while using misleading marketing to make people think they&amp;#39;re actually improving and keep buying their horribly overpriced GPUs&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mls46vn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743982552,"author_flair_text":null,"collapsed":false,"created_utc":1743982552,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mludc0h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlsg2zm","score":1,"author_fullname":"t2_1jwmlwo64i","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I use to say the same thing, but they came out with the RTX PRO cards and I don't really feel the need to chastise them so much anymore. They have a pretty linear segmentation in their products and you can buy whatever configuration you need. \\n\\n-\\n\\nIf you disagree please tell me what kind of card you feel like you can't buy at the moment? Just because it isn't the price you like does not mean they are not trying to push the boundaries and innovate. Sorry, but we have to give Nvidia and Jensen credit where credit is due. I am one of his toughest critics, but I also recognize the immense work and efforts Nvidia has put in to get us to where we are and their vision for the future. Doubt all you want, but every other company is bungling this in comparison.\\n\\n-\\n\\nIt's a hard realization, but we are not entitled to cheap gpu's.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mludc0h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use to say the same thing, but they came out with the RTX PRO cards and I don&amp;#39;t really feel the need to chastise them so much anymore. They have a pretty linear segmentation in their products and you can buy whatever configuration you need. &lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;If you disagree please tell me what kind of card you feel like you can&amp;#39;t buy at the moment? Just because it isn&amp;#39;t the price you like does not mean they are not trying to push the boundaries and innovate. Sorry, but we have to give Nvidia and Jensen credit where credit is due. I am one of his toughest critics, but I also recognize the immense work and efforts Nvidia has put in to get us to where we are and their vision for the future. Doubt all you want, but every other company is bungling this in comparison.&lt;/p&gt;\\n\\n&lt;h2&gt;&lt;/h2&gt;\\n\\n&lt;p&gt;It&amp;#39;s a hard realization, but we are not entitled to cheap gpu&amp;#39;s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mludc0h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744023162,"author_flair_text":null,"treatment_tags":[],"created_utc":1744023162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlsg2zm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Yellow_The_White","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlru96e","score":-1,"author_fullname":"t2_m085q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's precisely for a lack of trying. It's official name is \`market segmentation\`. It's artificial and entirely intentional.\\n\\nWhen Chinese hackshops can frankenstien 96GB onto a 4090, don't think for a second Nvidia couldn't.","edited":false,"author_flair_css_class":null,"name":"t1_mlsg2zm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s precisely for a lack of trying. It&amp;#39;s official name is &lt;code&gt;market segmentation&lt;/code&gt;. It&amp;#39;s artificial and entirely intentional.&lt;/p&gt;\\n\\n&lt;p&gt;When Chinese hackshops can frankenstien 96GB onto a 4090, don&amp;#39;t think for a second Nvidia couldn&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1jsshhe","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlsg2zm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743987043,"author_flair_text":null,"collapsed":false,"created_utc":1743987043,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlru96e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlqsgl4","score":-1,"author_fullname":"t2_1jwmlwo64i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not for a lack of trying. They are literally producing chips as fast as they can. Improvements can't be made the same way they were in the past. We're reaching physical limits and have to innovate in new ways.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlru96e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not for a lack of trying. They are literally producing chips as fast as they can. Improvements can&amp;#39;t be made the same way they were in the past. We&amp;#39;re reaching physical limits and have to innovate in new ways.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlru96e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743978972,"author_flair_text":null,"treatment_tags":[],"created_utc":1743978972,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqsgl4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PlastikHateAccount","can_mod_post":false,"send_replies":false,"parent_id":"t1_mlqixaa","score":15,"author_fullname":"t2_78c9nu0x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the 1080ti is almost a decade old and was 11gb vram\\n\\nBack in the day cpu speed or ram or disk space made these kinds of improvements every 18 months, not every 8 years","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlqsgl4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the 1080ti is almost a decade old and was 11gb vram&lt;/p&gt;\\n\\n&lt;p&gt;Back in the day cpu speed or ram or disk space made these kinds of improvements every 18 months, not every 8 years&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqsgl4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743966413,"author_flair_text":null,"treatment_tags":[],"created_utc":1743966413,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqixaa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"ROOFisonFIRE_usa","can_mod_post":false,"created_utc":1743963360,"send_replies":true,"parent_id":"t1_mlqb28l","score":-5,"author_fullname":"t2_1jwmlwo64i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We demand both and are receiving both.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqixaa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We demand both and are receiving both.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqixaa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963360,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqb28l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PlastikHateAccount","can_mod_post":false,"created_utc":1743960900,"send_replies":false,"parent_id":"t3_1jsshhe","score":5,"author_fullname":"t2_78c9nu0x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's frustrating to me that people demand smaller models instead of bigger vram cards\\n\\nIt used to be, back in the day, that computer hardware doubled and doubled and doubled.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqb28l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s frustrating to me that people demand smaller models instead of bigger vram cards&lt;/p&gt;\\n\\n&lt;p&gt;It used to be, back in the day, that computer hardware doubled and doubled and doubled.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqb28l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960900,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqinas","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FUS3N","can_mod_post":false,"created_utc":1743963272,"send_replies":true,"parent_id":"t1_mlq9a95","score":9,"author_fullname":"t2_38bya2m8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"except deepseek is good for its size or even better, and is way bigger model that beats other big proprietary, so no one has complains. they know what they messing with.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqinas","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;except deepseek is good for its size or even better, and is way bigger model that beats other big proprietary, so no one has complains. they know what they messing with.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqinas/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963272,"author_flair_text":"Ollama","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqko5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Super_Sierra","can_mod_post":false,"created_utc":1743963917,"send_replies":true,"parent_id":"t1_mlq9a95","score":-1,"author_fullname":"t2_9757bxah","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The gemma bois are out in force today, I fucking hated that model but I'm really liking the coherency of the replies for gemma 3 for fleshed out characters.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqko5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The gemma bois are out in force today, I fucking hated that model but I&amp;#39;m really liking the coherency of the replies for gemma 3 for fleshed out characters.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqko5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963917,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq9a95","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cashmate","can_mod_post":false,"created_utc":1743960349,"send_replies":true,"parent_id":"t3_1jsshhe","score":4,"author_fullname":"t2_5r0sd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[Some of you people](https://imgur.com/a/sxRWPdz)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq9a95","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://imgur.com/a/sxRWPdz\\"&gt;Some of you people&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq9a95/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960349,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"moxm61q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Haunting-Young6488","can_mod_post":false,"created_utc":1745566588,"send_replies":true,"parent_id":"t1_mlqjlgy","score":2,"author_fullname":"t2_1guvrev0in","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I also tried with int4 quantization and didn't fit. How on earth is it taking 191 GB with int4 quantization with fp16 size being 207 GB","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_moxm61q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I also tried with int4 quantization and didn&amp;#39;t fit. How on earth is it taking 191 GB with int4 quantization with fp16 size being 207 GB&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/moxm61q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1745566588,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mlqjlgy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"floridianfisher","can_mod_post":false,"created_utc":1743963573,"send_replies":true,"parent_id":"t3_1jsshhe","score":2,"author_fullname":"t2_5ac5a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I doesnt even fit in an h100. They made that part up.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqjlgy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I doesnt even fit in an h100. They made that part up.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqjlgy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743963573,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqvryf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MostlyRocketScience","can_mod_post":false,"created_utc":1743967495,"send_replies":true,"parent_id":"t3_1jsshhe","score":2,"author_fullname":"t2_9k5pfull","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The question is when will it be destilled to a smaller model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlqvryf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The question is when will it be destilled to a smaller model.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqvryf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743967495,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mls5wry","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"maturax","can_mod_post":false,"created_utc":1743983179,"send_replies":true,"parent_id":"t3_1jsshhe","score":1,"author_fullname":"t2_p4p19","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Since it doesn't bother Zuck that he has 30k H100s, everyone assumes they have access to the same resources. Our models fit onto a single 30k H100  Yay! Dude, you might be disappointed, but not everyone can afford H100s like you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mls5wry","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Since it doesn&amp;#39;t bother Zuck that he has 30k H100s, everyone assumes they have access to the same resources. Our models fit onto a single 30k H100  Yay! Dude, you might be disappointed, but not everyone can afford H100s like you.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mls5wry/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743983179,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mltgqsr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"anshulsingh8326","can_mod_post":false,"created_utc":1744003018,"send_replies":true,"parent_id":"t3_1jsshhe","score":1,"author_fullname":"t2_4sqglud7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Needs about 7 5070s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mltgqsr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Needs about 7 5070s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mltgqsr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744003018,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlu6azt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nore_se_kra","can_mod_post":false,"created_utc":1744019022,"send_replies":true,"parent_id":"t3_1jsshhe","score":1,"author_fullname":"t2_1bpvzzmckh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Anything with L4 and its tiny vram was so far a pain to setup with vllm and bot even fast at the end. Probably im doing it wrong but i rather jump right to A100s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlu6azt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Anything with L4 and its tiny vram was so far a pain to setup with vllm and bot even fast at the end. Probably im doing it wrong but i rather jump right to A100s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlu6azt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744019022,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlum5vm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_hypochonder_","can_mod_post":false,"created_utc":1744027411,"send_replies":true,"parent_id":"t3_1jsshhe","score":1,"author_fullname":"t2_p03a6f5s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So I can use it with iq3 xs/xss on my computer. (56GB VRAM)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlum5vm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I can use it with iq3 xs/xss on my computer. (56GB VRAM)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlum5vm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744027411,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mly3jbh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Stock-Union6934","can_mod_post":false,"created_utc":1744068151,"send_replies":true,"parent_id":"t3_1jsshhe","score":1,"author_fullname":"t2_52f5mhhel","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For the size and the thousands h100 for training,  I was expecting AGI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mly3jbh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For the size and the thousands h100 for training,  I was expecting AGI.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mly3jbh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1744068151,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mlqgypw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SanDiegoDude","can_mod_post":false,"send_replies":true,"parent_id":"t1_mlq9dzb","score":0,"author_fullname":"t2_3h3gm","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Dude, literally the next post down from this one is asking about the best ERP model. Let's not kid ourselves. I'm not judging, in fact creative writing is important for some jobs and it sounds like Scout won't be good for those. I'm curious about vision applications though.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mlqgypw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dude, literally the next post down from this one is asking about the best ERP model. Let&amp;#39;s not kid ourselves. I&amp;#39;m not judging, in fact creative writing is important for some jobs and it sounds like Scout won&amp;#39;t be good for those. I&amp;#39;m curious about vision applications though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlqgypw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743962739,"author_flair_text":null,"treatment_tags":[],"created_utc":1743962739,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq9dzb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AmazinglyObliviouse","can_mod_post":false,"created_utc":1743960380,"send_replies":true,"parent_id":"t1_mlq3puo","score":4,"author_fullname":"t2_c1qzfso6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pretty bold to come in here and assume people are just disappointed because they're gooners.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq9dzb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty bold to come in here and assume people are just disappointed because they&amp;#39;re gooners.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1jsshhe","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq9dzb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743960380,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mlq3puo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SanDiegoDude","can_mod_post":false,"created_utc":1743958599,"send_replies":true,"parent_id":"t3_1jsshhe","score":-2,"author_fullname":"t2_3h3gm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Pretty obvious it's not good for the gooner/\\"creative writing\\" crowd judging by all the disappointed comments on here. I currently use 70B for various tasks, and curious how it stacks up. Also curious how it performs for vision related tasks (the sfw variety). Gemini flash 2.0 is the first model that feels like it can hang with GPT-V for detail and understanding, curious how this new scout model holds up vs other omni models performing vision tasks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mlq3puo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty obvious it&amp;#39;s not good for the gooner/&amp;quot;creative writing&amp;quot; crowd judging by all the disappointed comments on here. I currently use 70B for various tasks, and curious how it stacks up. Also curious how it performs for vision related tasks (the sfw variety). Gemini flash 2.0 is the first model that feels like it can hang with GPT-V for detail and understanding, curious how this new scout model holds up vs other omni models performing vision tasks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1jsshhe/snugly_fits_in_a_h100_quantized_4_bit/mlq3puo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1743958599,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1jsshhe","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}}]`),s=()=>e.jsx(l,{data:a});export{s as default};
