import{j as e}from"./index-M5RGZ30t.js";import{R as l}from"./RedditPostRenderer-d9C3p581.js";import"./index-DmZ84jx5.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Looking at [some examples from Llama 4](https://www.designarena.ai/models/llama-4-maverick), it seems absolutely horrific at any kind of UI/UX. Also on this [benchmark for UI/UX](https://www.designarena.ai/leaderboard), Llama 4 Maverick and Llama 4 Scout sit in the bottom 25% when compared to toher models such as GPT, Claude, Grok, etc. \\n\\nWhat would you say are Llama's strengths are there if it's not coding interfaces and design? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Is anyone here using Llama to code websites and apps? From my experience, it sucks","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1ln93o3","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.83,"author_flair_background_color":null,"subreddit_type":"public","ups":24,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_98ouo03z","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":24,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751183333,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking at &lt;a href=\\"https://www.designarena.ai/models/llama-4-maverick\\"&gt;some examples from Llama 4&lt;/a&gt;, it seems absolutely horrific at any kind of UI/UX. Also on this &lt;a href=\\"https://www.designarena.ai/leaderboard\\"&gt;benchmark for UI/UX&lt;/a&gt;, Llama 4 Maverick and Llama 4 Scout sit in the bottom 25% when compared to toher models such as GPT, Claude, Grok, etc. &lt;/p&gt;\\n\\n&lt;p&gt;What would you say are Llama&amp;#39;s strengths are there if it&amp;#39;s not coding interfaces and design? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?auto=webp&amp;s=be810d8c53cb7be86e02810848134110fed32281","width":1024,"height":1024},"resolutions":[{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=665dd32e0413a097a6bd53f03dc03b3053e8ba60","width":108,"height":108},{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=527da9be0c4dbdbdd90a100e4336612140b37170","width":216,"height":216},{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=321cc7b6cca357a8ddf4233c8c9cf5760034e5db","width":320,"height":320},{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=325597b3c72f12582b9d0b5b6188fcbe1b75fb51","width":640,"height":640},{"url":"https://external-preview.redd.it/VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2b215709cfb3ca9899bcbca03bf19069e3db4812","width":960,"height":960}],"variants":{},"id":"VWTM0rHJfQzEfowPuYqfBaNAz2NOKVzZAXKVZ11QEDo"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1ln93o3","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Accomplished-Copy332","discussion_type":null,"num_comments":15,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/","subreddit_subscribers":492625,"created_utc":1751183333,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0eybt7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"created_utc":1751208399,"send_replies":true,"parent_id":"t1_n0djvml","score":1,"author_fullname":"t2_usojvms","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is the way. I want a 70b release! Glm is still my secret weapon at work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0eybt7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the way. I want a 70b release! Glm is still my secret weapon at work.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ln93o3","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0eybt7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751208399,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0djvml","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ali0une","can_mod_post":false,"created_utc":1751184658,"send_replies":true,"parent_id":"t3_1ln93o3","score":14,"author_fullname":"t2_ciytjqdyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try GLM-4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0djvml","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try GLM-4&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0djvml/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184658,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0digic","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sunshinecheung","can_mod_post":false,"created_utc":1751183804,"send_replies":true,"parent_id":"t3_1ln93o3","score":22,"author_fullname":"t2_u398xzta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"so why not use deepseek","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0digic","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so why not use deepseek&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0digic/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751183804,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0e52hd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SpacemanCraig3","can_mod_post":false,"created_utc":1751197061,"send_replies":true,"parent_id":"t3_1ln93o3","score":5,"author_fullname":"t2_13jvln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I use LLMs a lot.\\n\\nA lot.\\n\\nI build LLMs, I build tooling around LLMs, I build agents and agentic workflows, and I use LLMs to assist with those tasks.\\n\\nI do these things professionally in my day job.\\n\\nEvery time I green fields a new project I evaluate open weights models vs APIs for the task, open weights never win.  Even against the cheapest API models (Gemini flash or 4.1mini these days).  They just aren't consistent enough with tool calling or smart enough at the scale that is feasible for me to deploy.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0e52hd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use LLMs a lot.&lt;/p&gt;\\n\\n&lt;p&gt;A lot.&lt;/p&gt;\\n\\n&lt;p&gt;I build LLMs, I build tooling around LLMs, I build agents and agentic workflows, and I use LLMs to assist with those tasks.&lt;/p&gt;\\n\\n&lt;p&gt;I do these things professionally in my day job.&lt;/p&gt;\\n\\n&lt;p&gt;Every time I green fields a new project I evaluate open weights models vs APIs for the task, open weights never win.  Even against the cheapest API models (Gemini flash or 4.1mini these days).  They just aren&amp;#39;t consistent enough with tool calling or smart enough at the scale that is feasible for me to deploy.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0e52hd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751197061,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dj9bm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Noiselexer","can_mod_post":false,"created_utc":1751184282,"send_replies":true,"parent_id":"t3_1ln93o3","score":4,"author_fullname":"t2_n4xpz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I only use cloud models for coding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dj9bm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I only use cloud models for coding.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0dj9bm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184282,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dojhm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"megadonkeyx","can_mod_post":false,"created_utc":1751187526,"send_replies":true,"parent_id":"t3_1ln93o3","score":5,"author_fullname":"t2_unvzb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the best option would be something like qwen3 or devstral but compared to commercial models they are very weak, you would spend more time correcting them than getting anything done.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dojhm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the best option would be something like qwen3 or devstral but compared to commercial models they are very weak, you would spend more time correcting them than getting anything done.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0dojhm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751187526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f961b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TrashPandaSavior","can_mod_post":false,"created_utc":1751211843,"send_replies":true,"parent_id":"t3_1ln93o3","score":2,"author_fullname":"t2_6l8zqdgk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most local models \\\\*are\\\\* absolute trash at generating sites, can confirm. I had a prototype I whipped up for a dead-web type of browser with all search results and pages generated via LLM ... and it was too boring and hideous looking. 😅\\n\\nGLM4, as mentioned, does pretty good. I also did \\\\*some\\\\* testing with UIGEN-T3-14B, but not enough to give any useful review: [https://huggingface.co/Tesslate/UIGEN-T3-14B-Preview](https://huggingface.co/Tesslate/UIGEN-T3-14B-Preview)  ...\\n\\nAlso, there's this page where someone used a lot of models to try and generate a webpage based on a design prompt and you can see the results: [https://blog.kekepower.com/ai/](https://blog.kekepower.com/ai/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f961b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most local models *are* absolute trash at generating sites, can confirm. I had a prototype I whipped up for a dead-web type of browser with all search results and pages generated via LLM ... and it was too boring and hideous looking. 😅&lt;/p&gt;\\n\\n&lt;p&gt;GLM4, as mentioned, does pretty good. I also did *some* testing with UIGEN-T3-14B, but not enough to give any useful review: &lt;a href=\\"https://huggingface.co/Tesslate/UIGEN-T3-14B-Preview\\"&gt;https://huggingface.co/Tesslate/UIGEN-T3-14B-Preview&lt;/a&gt;  ...&lt;/p&gt;\\n\\n&lt;p&gt;Also, there&amp;#39;s this page where someone used a lot of models to try and generate a webpage based on a design prompt and you can see the results: &lt;a href=\\"https://blog.kekepower.com/ai/\\"&gt;https://blog.kekepower.com/ai/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0f961b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751211843,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dj3kr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lothariusdark","can_mod_post":false,"created_utc":1751184186,"send_replies":true,"parent_id":"t3_1ln93o3","score":3,"author_fullname":"t2_idhb522c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\n\\nA model doesnt have to have a strength in anything.\\n\\n\\nSometimes models are just bad. \\n\\n\\nLike Llama 4.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dj3kr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A model doesnt have to have a strength in anything.&lt;/p&gt;\\n\\n&lt;p&gt;Sometimes models are just bad. &lt;/p&gt;\\n\\n&lt;p&gt;Like Llama 4.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0dj3kr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751184186,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dv691","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Daemontatox","can_mod_post":false,"created_utc":1751191601,"send_replies":true,"parent_id":"t3_1ln93o3","score":3,"author_fullname":"t2_1rm9syq1nb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sometimes You have great models ,\\n\\nSometimes you have good models, \\n\\nSometimes you have bad models, \\n\\nAnd then there llama 4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dv691","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sometimes You have great models ,&lt;/p&gt;\\n\\n&lt;p&gt;Sometimes you have good models, &lt;/p&gt;\\n\\n&lt;p&gt;Sometimes you have bad models, &lt;/p&gt;\\n\\n&lt;p&gt;And then there llama 4&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0dv691/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751191601,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dz1r1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"zss36909","can_mod_post":false,"created_utc":1751193886,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_261xlain","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I like local models for repetitive functions, data privacy and they are just fun : never would use them for real coding tho","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dz1r1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like local models for repetitive functions, data privacy and they are just fun : never would use them for real coding tho&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0dz1r1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751193886,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0e4968","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vesko26","can_mod_post":false,"created_utc":1751196651,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_11fewf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Claude does the best with UI in my experience. I use Svelte so you have to remind it its svelte 5 but it works","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0e4968","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Claude does the best with UI in my experience. I use Svelte so you have to remind it its svelte 5 but it works&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0e4968/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751196651,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0erje8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Lesser-than","can_mod_post":false,"created_utc":1751206146,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_98d256k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The tooling just is not their yet for smaller local llms to spit out what foundation models are doing. they are good at touch ups and finetuning once its made but they need to work on very small tasks at a time. Where the cloud models have enough context to manage larger multi-tasking projects heck most of the foundation models re-write half your codebase with every query.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0erje8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The tooling just is not their yet for smaller local llms to spit out what foundation models are doing. they are good at touch ups and finetuning once its made but they need to work on very small tasks at a time. Where the cloud models have enough context to manage larger multi-tasking projects heck most of the foundation models re-write half your codebase with every query.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0erje8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751206146,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0eswme","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1751206619,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try devstral or glm","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0eswme","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try devstral or glm&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0eswme/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751206619,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0f3tfs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Competitive_Ideal866","can_mod_post":false,"created_utc":1751210149,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_1d13xm6n7f","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; What would you say are Llama's strengths are there if it's not coding interfaces and design?\\n\\nNot coding in general, IME.\\n\\nI'd say the llama series of models are all relatively good at writing emotive, captivating and alluring text. The most obvious practical application for them would be something like writing catchy click-bait headlines or marketing in general.\\n\\nI get the impression they're trained on a lot of news including tabloid media rather than scientific or mathematical literature. So they are better at language but worse at logic and reasoning and, therefore, coding.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0f3tfs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;What would you say are Llama&amp;#39;s strengths are there if it&amp;#39;s not coding interfaces and design?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Not coding in general, IME.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d say the llama series of models are all relatively good at writing emotive, captivating and alluring text. The most obvious practical application for them would be something like writing catchy click-bait headlines or marketing in general.&lt;/p&gt;\\n\\n&lt;p&gt;I get the impression they&amp;#39;re trained on a lot of news including tabloid media rather than scientific or mathematical literature. So they are better at language but worse at logic and reasoning and, therefore, coding.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0f3tfs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751210149,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fcswg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Just_Lingonberry_352","can_mod_post":false,"created_utc":1751212999,"send_replies":true,"parent_id":"t3_1ln93o3","score":1,"author_fullname":"t2_1dvb1fztcc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm just surprised people are still using llama 4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fcswg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m just surprised people are still using llama 4&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ln93o3/is_anyone_here_using_llama_to_code_websites_and/n0fcswg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751212999,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ln93o3","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
