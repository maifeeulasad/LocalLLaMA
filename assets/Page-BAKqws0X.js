import{j as e}from"./index-xfnGEtuL.js";import{R as a}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Project Website: [https://memos.openmem.net/](https://memos.openmem.net/) \\n\\nCode: [https://github.com/MemTensor/MemOS](https://github.com/MemTensor/MemOS)\\n\\nAbstract\\n\\n&gt;Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge consistency. Existing models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended periods. While Retrieval-Augmented Generation (RAG) introduces external knowledge in plain text, it remains a stateless workaround without lifecycle control or integration with persistent representations. Recent work has modeled the training and inference cost of LLMs from a memory hierarchy perspective, showing that introducing an explicit memory layer between parameter memory and external retrieval can substantially reduce these costs by externalizing specific knowledge \\\\[1\\\\]. Beyond computational efficiency, LLMs face broader challenges arising from how information is distributed over time and context, requiring systems capable of managing heterogeneous knowledge spanning different temporal scales and sources. To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource. It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning. MemCubes can be composed, migrated, and fused over time, enabling flexible transitions between memory types and bridging retrieval with parameter-based learning. MemOS establishes a memory-centric system framework that brings controllability, plasticity, and evolvability to LLMs, laying the foundation for continual learning and personalized modeling.\\n\\n","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"MemOS: A Memory OS for AI System","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lv9m3j","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.81,"author_flair_background_color":"#93b1ba","subreddit_type":"public","ups":34,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","is_original_content":false,"author_fullname":"t2_qjpsv","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":34,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"default","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"gildings":{},"content_categories":null,"is_self":false,"mod_note":null,"created":1752034933,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"arxiv.org","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Project Website: &lt;a href=\\"https://memos.openmem.net/\\"&gt;https://memos.openmem.net/&lt;/a&gt; &lt;/p&gt;\\n\\n&lt;p&gt;Code: &lt;a href=\\"https://github.com/MemTensor/MemOS\\"&gt;https://github.com/MemTensor/MemOS&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Abstract&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge consistency. Existing models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended periods. While Retrieval-Augmented Generation (RAG) introduces external knowledge in plain text, it remains a stateless workaround without lifecycle control or integration with persistent representations. Recent work has modeled the training and inference cost of LLMs from a memory hierarchy perspective, showing that introducing an explicit memory layer between parameter memory and external retrieval can substantially reduce these costs by externalizing specific knowledge [1]. Beyond computational efficiency, LLMs face broader challenges arising from how information is distributed over time and context, requiring systems capable of managing heterogeneous knowledge spanning different temporal scales and sources. To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource. It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning. MemCubes can be composed, migrated, and fused over time, enabling flexible transitions between memory types and bridging retrieval with parameter-based learning. MemOS establishes a memory-centric system framework that brings controllability, plasticity, and evolvability to LLMs, laying the foundation for continual learning and personalized modeling.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://arxiv.org/abs/2507.03724","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"Llama 3.1","treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lv9m3j","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ninjasaid13","discussion_type":null,"num_comments":14,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/","stickied":false,"url":"https://arxiv.org/abs/2507.03724","subreddit_subscribers":497025,"created_utc":1752034933,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n28l8iw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahmadawaiscom","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2759px","score":1,"author_fullname":"t2_4g5zlnqq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not really. Itâ€™s autonomous RAG and KV cache and a reasoning engine with rerankers. I havenâ€™t read their paper I read their landing page which is pretty much felt like the same thing just with new invented names.","edited":false,"author_flair_css_class":null,"name":"t1_n28l8iw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not really. Itâ€™s autonomous RAG and KV cache and a reasoning engine with rerankers. I havenâ€™t read their paper I read their landing page which is pretty much felt like the same thing just with new invented names.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lv9m3j","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n28l8iw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752091536,"author_flair_text":null,"collapsed":false,"created_utc":1752091536,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29e9jy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2759px","score":1,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It looks like RAG and it doesn't mention loading KV caches or any LLM-specific memory structures from disk.\\n\\nSaving KV caches to disk requires a huge amount of storage that gets larger with larger models.","edited":false,"author_flair_css_class":null,"name":"t1_n29e9jy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It looks like RAG and it doesn&amp;#39;t mention loading KV caches or any LLM-specific memory structures from disk.&lt;/p&gt;\\n\\n&lt;p&gt;Saving KV caches to disk requires a huge amount of storage that gets larger with larger models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lv9m3j","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n29e9jy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752099857,"author_flair_text":null,"collapsed":false,"created_utc":1752099857,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2759px","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"searcher1k","can_mod_post":false,"send_replies":true,"parent_id":"t1_n27307s","score":3,"author_fullname":"t2_sn1h4esl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't that RAG? that's different from what the paper claims.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2759px","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t that RAG? that&amp;#39;s different from what the paper claims.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lv9m3j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n2759px/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077309,"author_flair_text":null,"treatment_tags":[],"created_utc":1752077309,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n27307s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ahmadawaiscom","can_mod_post":false,"send_replies":true,"parent_id":"t1_n25u2q9","score":2,"author_fullname":"t2_4g5zlnqq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Been there done that years ago https://Langbase.com/docs/memory ðŸ˜Ž","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n27307s","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Been there done that years ago &lt;a href=\\"https://Langbase.com/docs/memory\\"&gt;https://Langbase.com/docs/memory&lt;/a&gt; ðŸ˜Ž&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lv9m3j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n27307s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752076684,"author_flair_text":null,"treatment_tags":[],"created_utc":1752076684,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n25u2q9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1752063135,"send_replies":true,"parent_id":"t1_n25jyc5","score":1,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For real though, having a vector database containing embeddings and summarized prompts, which is then linked to KV cache files on disk? That sounds like a Matrix \\"downloading kungfu\\" moment. You're trading compute for storage but you gain the ability to reload past conversations without any prompt re-processing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25u2q9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For real though, having a vector database containing embeddings and summarized prompts, which is then linked to KV cache files on disk? That sounds like a Matrix &amp;quot;downloading kungfu&amp;quot; moment. You&amp;#39;re trading compute for storage but you gain the ability to reload past conversations without any prompt re-processing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lv9m3j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n25u2q9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752063135,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n25jyc5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ahmadawaiscom","can_mod_post":false,"created_utc":1752059099,"send_replies":true,"parent_id":"t3_1lv9m3j","score":27,"author_fullname":"t2_4g5zlnqq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So tired of people coming up with weird names for simple KV, disk, and vector stores.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25jyc5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So tired of people coming up with weird names for simple KV, disk, and vector stores.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n25jyc5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752059099,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n24ifi0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KillerX629","can_mod_post":false,"created_utc":1752039192,"send_replies":true,"parent_id":"t3_1lv9m3j","score":4,"author_fullname":"t2_1ve6ehh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is it me or the abstract has links on \\"this http\\"? Weird","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n24ifi0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is it me or the abstract has links on &amp;quot;this http&amp;quot;? Weird&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n24ifi0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752039192,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n275tqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"searcher1k","can_mod_post":false,"created_utc":1752077464,"send_replies":true,"parent_id":"t1_n26f1z0","score":4,"author_fullname":"t2_sn1h4esl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/w2cxs93uhvbf1.png?width=2270&amp;format=png&amp;auto=webp&amp;s=ec24bc83919d02b8038445116a49db1c1ac3b3d2","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n275tqo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/w2cxs93uhvbf1.png?width=2270&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec24bc83919d02b8038445116a49db1c1ac3b3d2\\"&gt;https://preview.redd.it/w2cxs93uhvbf1.png?width=2270&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec24bc83919d02b8038445116a49db1c1ac3b3d2&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lv9m3j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n275tqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752077464,"media_metadata":{"w2cxs93uhvbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":58,"x":108,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=535f538d6b215217a32107eda74f69d52bf7f784"},{"y":116,"x":216,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=05271a8e291ee4bf795e447f670429294ddd27ee"},{"y":173,"x":320,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=29670dd4f4ab503343bc1870973a7aab204c7627"},{"y":346,"x":640,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe4bfd0978bca3b8ef3bf7573e67cf27bae406a4"},{"y":519,"x":960,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b6c6f660237ad66f1c8860e856c7ad5372638ae2"},{"y":584,"x":1080,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c36214c1ce46fbe71abeb779b28b34417e1c2c27"}],"s":{"y":1228,"x":2270,"u":"https://preview.redd.it/w2cxs93uhvbf1.png?width=2270&amp;format=png&amp;auto=webp&amp;s=ec24bc83919d02b8038445116a49db1c1ac3b3d2"},"id":"w2cxs93uhvbf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n26f1z0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"patbhakta","can_mod_post":false,"created_utc":1752069994,"send_replies":true,"parent_id":"t3_1lv9m3j","score":2,"author_fullname":"t2_1e5sho1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"How does this compare to mem0, mongodb AI suite, and other projects on git?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n26f1z0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does this compare to mem0, mongodb AI suite, and other projects on git?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n26f1z0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752069994,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n25if3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hideo_kuze_","can_mod_post":false,"created_utc":1752058432,"send_replies":true,"parent_id":"t3_1lv9m3j","score":1,"author_fullname":"t2_47x1vr66","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for sharing. This looks really cool.\\n\\nI've skimmed through the material and the paper does reference previous work and other systems. But there aren't any benchmarks. Apart from the OpenAI comparison on github.\\n\\nI'm just curious how it compares against other tools","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n25if3g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for sharing. This looks really cool.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve skimmed through the material and the paper does reference previous work and other systems. But there aren&amp;#39;t any benchmarks. Apart from the OpenAI comparison on github.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m just curious how it compares against other tools&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n25if3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752058432,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aejm0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"rockybaby2025","can_mod_post":false,"created_utc":1752112068,"send_replies":true,"parent_id":"t3_1lv9m3j","score":1,"author_fullname":"t2_1t3515o2d2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Actually how does one store KV pairs? Aren't these self attention matrices?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aejm0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually how does one store KV pairs? Aren&amp;#39;t these self attention matrices?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n2aejm0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112068,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bcegl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GusYe1234","can_mod_post":false,"created_utc":1752125892,"send_replies":true,"parent_id":"t3_1lv9m3j","score":1,"author_fullname":"t2_3rrlt5iv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's really complex and powered by LLM. I doubt myself will use this in production, because I don't know when the memories go wrong and how can I fix it. Mem0 and Memobase is much better, you can easily understand how it works, and edit/delete memories when things go wrong","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bcegl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s really complex and powered by LLM. I doubt myself will use this in production, because I don&amp;#39;t know when the memories go wrong and how can I fix it. Mem0 and Memobase is much better, you can easily understand how it works, and edit/delete memories when things go wrong&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n2bcegl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752125892,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n268uqd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"__Maximum__","can_mod_post":false,"created_utc":1752068135,"send_replies":true,"parent_id":"t1_n24ods2","score":1,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sometimes, that's a revolutionary, haven't read the paper yet though, might be shite","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n268uqd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sometimes, that&amp;#39;s a revolutionary, haven&amp;#39;t read the paper yet though, might be shite&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lv9m3j","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n268uqd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752068135,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n24ods2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"megadonkeyx","can_mod_post":false,"created_utc":1752042202,"send_replies":true,"parent_id":"t3_1lv9m3j","score":1,"author_fullname":"t2_unvzb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"it doesnt seem to be anything revolutionary but rather a packaging of existing concepts, certainly interesting.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n24ods2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it doesnt seem to be anything revolutionary but rather a packaging of existing concepts, certainly interesting.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lv9m3j/memos_a_memory_os_for_ai_system/n24ods2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752042202,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lv9m3j","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),s=()=>e.jsx(a,{data:l});export{s as default};
