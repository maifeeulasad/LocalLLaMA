import{j as e}from"./index-BOnf-UhU.js";import{R as t}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Puget Systems Threadripper PRO 9000WX Llama Prompt Processing &amp; Token Generation benchmarks","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":140,"top_awarded_type":null,"hide_score":false,"name":"t3_1m7ld4z","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.63,"author_flair_background_color":null,"ups":2,"total_awards_received":0,"media_embed":{"content":"&lt;iframe class=\\"embedly-embed\\" src=\\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D500&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z&amp;image=https%3A%2F%2Fi.imgur.com%2Fk257k3u.jpg%3Ffb&amp;type=text%2Fhtml&amp;schema=imgur\\" width=\\"500\\" height=\\"60\\" scrolling=\\"no\\" title=\\"Imgur embed\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; encrypted-media; picture-in-picture;\\" allowfullscreen=\\"true\\"&gt;&lt;/iframe&gt;","width":500,"scrolling":false,"height":60},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_ql2vu0wz","secure_media":{"oembed":{"provider_url":"http://imgur.com","description":"Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.","title":"Imgur","url":"https://imgur.com/a/EDYfW8Z","thumbnail_width":769,"height":60,"width":500,"html":"&lt;iframe class=\\"embedly-embed\\" src=\\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D500&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z&amp;image=https%3A%2F%2Fi.imgur.com%2Fk257k3u.jpg%3Ffb&amp;type=text%2Fhtml&amp;schema=imgur\\" width=\\"500\\" height=\\"60\\" scrolling=\\"no\\" title=\\"Imgur embed\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; encrypted-media; picture-in-picture;\\" allowfullscreen=\\"true\\"&gt;&lt;/iframe&gt;","version":"1.0","provider_name":"Imgur","thumbnail_url":"https://i.imgur.com/k257k3u.jpg?fb","type":"rich","thumbnail_height":913},"type":"imgur.com"},"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{"content":"&lt;iframe class=\\"embedly-embed\\" src=\\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D500&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z&amp;image=https%3A%2F%2Fi.imgur.com%2Fk257k3u.jpg%3Ffb&amp;type=text%2Fhtml&amp;schema=imgur\\" width=\\"500\\" height=\\"60\\" scrolling=\\"no\\" title=\\"Imgur embed\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; encrypted-media; picture-in-picture;\\" allowfullscreen=\\"true\\"&gt;&lt;/iframe&gt;","width":500,"scrolling":false,"media_domain_url":"https://www.redditmedia.com/mediaembed/1m7ld4z","height":60},"link_flair_text":"Discussion","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/1TY3ekkN1BvY7efk8vkTqbWYLMpL6rdncgaIYqt8mrc.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1753305060,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"imgur.com","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://imgur.com/a/EDYfW8Z","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/EoAqgMVFxHtMcH_N1MqDCS4XiJk394hpgLml-L9lTR8.jpg?auto=webp&amp;s=6b99863e0ee515acfb7baf827a1475ae8c08c99a","width":769,"height":913},"resolutions":[{"url":"https://external-preview.redd.it/EoAqgMVFxHtMcH_N1MqDCS4XiJk394hpgLml-L9lTR8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad075926dde531bde6baeaa59a7e8de8b9783ff7","width":108,"height":128},{"url":"https://external-preview.redd.it/EoAqgMVFxHtMcH_N1MqDCS4XiJk394hpgLml-L9lTR8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d3c27b03235dce4ba1a94fcdd7b3e3e8f73f33dd","width":216,"height":256},{"url":"https://external-preview.redd.it/EoAqgMVFxHtMcH_N1MqDCS4XiJk394hpgLml-L9lTR8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b8963a8fad73e01a1dc59518f26cdba96f13efd8","width":320,"height":379},{"url":"https://external-preview.redd.it/EoAqgMVFxHtMcH_N1MqDCS4XiJk394hpgLml-L9lTR8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e6a4654ee6d198617faffc7ca553b7e86c784d3","width":640,"height":759}],"variants":{},"id":"GLm1hgJojxMbTwvUw-Lc6StlFj9R36mDvuxy3H3bcNc"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m7ld4z","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Caffdy","discussion_type":null,"num_comments":7,"send_replies":true,"media":{"oembed":{"provider_url":"http://imgur.com","description":"Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.","title":"Imgur","url":"https://imgur.com/a/EDYfW8Z","thumbnail_width":769,"height":60,"width":500,"html":"&lt;iframe class=\\"embedly-embed\\" src=\\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D500&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FEDYfW8Z&amp;image=https%3A%2F%2Fi.imgur.com%2Fk257k3u.jpg%3Ffb&amp;type=text%2Fhtml&amp;schema=imgur\\" width=\\"500\\" height=\\"60\\" scrolling=\\"no\\" title=\\"Imgur embed\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; encrypted-media; picture-in-picture;\\" allowfullscreen=\\"true\\"&gt;&lt;/iframe&gt;","version":"1.0","provider_name":"Imgur","thumbnail_url":"https://i.imgur.com/k257k3u.jpg?fb","type":"rich","thumbnail_height":913},"type":"imgur.com"},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/","stickied":false,"url":"https://imgur.com/a/EDYfW8Z","subreddit_subscribers":503517,"created_utc":1753305060,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ssgpc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eloquentemu","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sgrv3","score":0,"author_fullname":"t2_lpdsy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Imagine buying a threadripper to run a 4B model at Q4 :D.\\n\\nI wonder if their benchmarks might have been a bit more consistent if they chose a larger model that would actually be able to really benefit the multi-core multi-CCD processor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ssgpc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imagine buying a threadripper to run a 4B model at Q4 :D.&lt;/p&gt;\\n\\n&lt;p&gt;I wonder if their benchmarks might have been a bit more consistent if they chose a larger model that would actually be able to really benefit the multi-core multi-CCD processor.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7ld4z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4ssgpc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753310425,"author_flair_text":null,"treatment_tags":[],"created_utc":1753310425,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sgrv3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4sf205","score":1,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They tested Phi-3 Mini Q4_K_M, while not the most interesting or exciting model, we can get some impressions from their results about how well these systems scale with thread/core count. \\n\\nPhi-3 Mini is 3.8B parameters, given several statements made around these parts that as long as a MoE model fit in the same memory (in this case, RAM), we can expect the same performance as their activation parameters; Qwen3 30B with 3B active could be expected to perform in similar fashion. Naturally, I posted this because there could a good discussion around how can these systems perform with the big-league models","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4sgrv3","is_submitter":true,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They tested Phi-3 Mini Q4_K_M, while not the most interesting or exciting model, we can get some impressions from their results about how well these systems scale with thread/core count. &lt;/p&gt;\\n\\n&lt;p&gt;Phi-3 Mini is 3.8B parameters, given several statements made around these parts that as long as a MoE model fit in the same memory (in this case, RAM), we can expect the same performance as their activation parameters; Qwen3 30B with 3B active could be expected to perform in similar fashion. Naturally, I posted this because there could a good discussion around how can these systems perform with the big-league models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7ld4z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4sgrv3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753306766,"author_flair_text":null,"treatment_tags":[],"created_utc":1753306766,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sf205","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1753306257,"send_replies":true,"parent_id":"t1_n4sb8kg","score":1,"author_fullname":"t2_by77ogdhr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which one? Behemoth?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sf205","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which one? Behemoth?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7ld4z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4sf205/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753306257,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sb8kg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"created_utc":1753305132,"send_replies":true,"parent_id":"t3_1m7ld4z","score":2,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[According to their testing](https://www.pugetsystems.com/labs/articles/amd-ryzen-threadripper-pro-9000wx-content-creation-review/):\\n\\n&gt;One of the more recent benchmarks we have begun to use is an LLM benchmark based on Llama.cpp. The benchmark looks at the performance in prompt processing and token generation (essentially, the input and output of a user-facing chatbot) using a lightweight model that scales across both CPUs and GPUs.\\n\\n&gt;Starting with prompt processing (Chart #1), we found that the benchmark performance appears to scale well with core count. The 9995WX was the fastest CPU tested, leading the 9985WX by 9% and the 7995WX by 16%. This 16% generational uplift is fairly representative, with the 64-core seeing a 16% uplift, the 32-core an 18%, and the 24-core a 17% gain. Much like in our rendering benchmarks, Intel’s 60-core Xeon part falls just behind AMD’s 9975WX, with the other Xeons roughly matching the AMD CPU two tiers below them.\\n\\n&gt;In the token generation portion of the benchmark (Chart #2), the results are much less clear. The spread of results is much larger than we would typically expect if it were random, but there doesn’t seem to be a great pattern to which CPUs perform best. Nonetheless, the Threadripper PRO 9000WX processors perform well, though we would recommend most users stick to GPUs for LLMs unless VRAM is a serious issue.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sb8kg","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.pugetsystems.com/labs/articles/amd-ryzen-threadripper-pro-9000wx-content-creation-review/\\"&gt;According to their testing&lt;/a&gt;:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;One of the more recent benchmarks we have begun to use is an LLM benchmark based on Llama.cpp. The benchmark looks at the performance in prompt processing and token generation (essentially, the input and output of a user-facing chatbot) using a lightweight model that scales across both CPUs and GPUs.&lt;/p&gt;\\n\\n&lt;p&gt;Starting with prompt processing (Chart #1), we found that the benchmark performance appears to scale well with core count. The 9995WX was the fastest CPU tested, leading the 9985WX by 9% and the 7995WX by 16%. This 16% generational uplift is fairly representative, with the 64-core seeing a 16% uplift, the 32-core an 18%, and the 24-core a 17% gain. Much like in our rendering benchmarks, Intel’s 60-core Xeon part falls just behind AMD’s 9975WX, with the other Xeons roughly matching the AMD CPU two tiers below them.&lt;/p&gt;\\n\\n&lt;p&gt;In the token generation portion of the benchmark (Chart #2), the results are much less clear. The spread of results is much larger than we would typically expect if it were random, but there doesn’t seem to be a great pattern to which CPUs perform best. Nonetheless, the Threadripper PRO 9000WX processors perform well, though we would recommend most users stick to GPUs for LLMs unless VRAM is a serious issue.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4sb8kg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753305132,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m7ld4z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4t3uhr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4t0kx4","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I cannot agree more, people should up vote you","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4t3uhr","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I cannot agree more, people should up vote you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7ld4z","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4t3uhr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753314124,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753314124,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4t0kx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"created_utc":1753313044,"send_replies":true,"parent_id":"t1_n4sxxsz","score":2,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; how would it scale with a bigger moe?\\n\\nthat's the crux of the matter. People who already have a 7000WX should chime in to share some of their experience with MoE models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4t0kx4","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;how would it scale with a bigger moe?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;that&amp;#39;s the crux of the matter. People who already have a 7000WX should chime in to share some of their experience with MoE models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m7ld4z","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4t0kx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753313044,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4sxxsz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1753312181,"send_replies":true,"parent_id":"t3_1m7ld4z","score":1,"author_fullname":"t2_cj9kap4bx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Check the token gen for 7595WX, very surprising..\\n\\nAnyways, that should give an idea for token gen, how about pp, how would it scale with a bigger moe?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4sxxsz","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Check the token gen for 7595WX, very surprising..&lt;/p&gt;\\n\\n&lt;p&gt;Anyways, that should give an idea for token gen, how about pp, how would it scale with a bigger moe?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m7ld4z/puget_systems_threadripper_pro_9000wx_llama/n4sxxsz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753312181,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m7ld4z","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),o=()=>e.jsx(t,{data:l});export{o as default};
