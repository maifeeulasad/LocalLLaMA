import{j as e}from"./index-DACS7Nh6.js";import{R as l}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Kimi K2 is basically DeepSeek V3 but with fewer heads and more experts.\\n\\nSource: @rasbt on X","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Interesting info about Kimi K2","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":73,"top_awarded_type":null,"hide_score":false,"name":"t3_1ly42e5","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.99,"author_flair_background_color":null,"ups":428,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_jqxb4pte","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":428,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/3oX4rR_wq13aNVBkwN9gy-7Ly3awWuKmao4xX-wZHPw.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752336334,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Kimi K2 is basically DeepSeek V3 but with fewer heads and more experts.&lt;/p&gt;\\n\\n&lt;p&gt;Source: @rasbt on X&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/klm2b78lvgcf1.jpeg","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?auto=webp&amp;s=d65bbcd2f22adb9cfb21adc9eac026b92732d6e6","width":4096,"height":2142},"resolutions":[{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de7eb96ece8068540bfea48d2417469c7f222dea","width":108,"height":56},{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5b3e2c8e32db02490d668ba0df54614ac60fe47","width":216,"height":112},{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1e27745898fe8ede1bbd082b7fec7ccae87d2bf","width":320,"height":167},{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=32a0ebb795c06ba955385d6c0102e57e0fd85423","width":640,"height":334},{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9c7c244ab2396650f24e6eb34e6826ebd524c6e5","width":960,"height":502},{"url":"https://preview.redd.it/klm2b78lvgcf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bc382959f7974e6a25c0797c6abdfd2b739eef68","width":1080,"height":564}],"variants":{},"id":"Mc3JulkX7jC-xZrG5vXyMeTKbsu1euUGH0q8C22y1zs"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1ly42e5","is_robot_indexable":true,"num_duplicates":2,"report_reasons":null,"author":"No_Conversation9561","discussion_type":null,"num_comments":15,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/","stickied":false,"url":"https://i.redd.it/klm2b78lvgcf1.jpeg","subreddit_subscribers":498345,"created_utc":1752336334,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2r5g1e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Affectionate-Cap-600","can_mod_post":false,"created_utc":1752339095,"send_replies":true,"parent_id":"t3_1ly42e5","score":50,"author_fullname":"t2_5oltmr5b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"out of curiosity, is there any paper about different approaches to MoE? ie, using heterogeneous experts/FFN, including some attention in the router dependant paths etch?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2r5g1e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;out of curiosity, is there any paper about different approaches to MoE? ie, using heterogeneous experts/FFN, including some attention in the router dependant paths etch?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2r5g1e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752339095,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":50}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2uz4uc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BalorNG","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2rg8ey","score":4,"author_fullname":"t2_b6gw9q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tzeentch cares not from whence the data flows, only that it does flow... and is not bus-bottlenecked!\\n\\nEven raid of fast SSDs will do for MoE, we just need hierachical sram/vram/ram/ssd smart storage that juggles offloaded experts according to usage.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2uz4uc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tzeentch cares not from whence the data flows, only that it does flow... and is not bus-bottlenecked!&lt;/p&gt;\\n\\n&lt;p&gt;Even raid of fast SSDs will do for MoE, we just need hierachical sram/vram/ram/ssd smart storage that juggles offloaded experts according to usage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly42e5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2uz4uc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752390322,"author_flair_text":null,"treatment_tags":[],"created_utc":1752390322,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rnrde","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Accomplished_Mode170","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2rg8ey","score":5,"author_fullname":"t2_4hfmiefj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"methinks* the 🧵OP was talking about how VRAM at lower latency would allow more experimentation re: attention heads needed to properly map experts to the [underlying sparsity of the data](https://www.tilderesearch.com/blog/sparse-attn)\\n\\n *sorry; couldn’t miss the chance","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2rnrde","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;methinks* the 🧵OP was talking about how VRAM at lower latency would allow more experimentation re: attention heads needed to properly map experts to the &lt;a href=\\"https://www.tilderesearch.com/blog/sparse-attn\\"&gt;underlying sparsity of the data&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;*sorry; couldn’t miss the chance&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly42e5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2rnrde/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752344674,"author_flair_text":null,"treatment_tags":[],"created_utc":1752344674,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2rg8ey","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fzzzy","can_mod_post":false,"created_utc":1752342340,"send_replies":true,"parent_id":"t1_n2rbbol","score":20,"author_fullname":"t2_533l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think cpu ram usage will eventually take over. There'll be some people that still go for vram, but for most people, the cost won't be worth it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rg8ey","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think cpu ram usage will eventually take over. There&amp;#39;ll be some people that still go for vram, but for most people, the cost won&amp;#39;t be worth it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly42e5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2rg8ey/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752342340,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"n2rbbol","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xmBQWugdxjaA","can_mod_post":false,"created_utc":1752340868,"send_replies":true,"parent_id":"t3_1ly42e5","score":51,"author_fullname":"t2_nyyscwdgr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think Kimi's approach makes sense, with more attention heads you are paying that cost on every single inference, all the time. Whereas with more MoE, you only pay for what you use (although you need enough attention heads so that the experts can be well chosen).\\n\\nBut you can see the downside of needing even more VRAM for the greater number of experts (more parameters), even when you won't use many of them for a specific prompt.\\n\\nWe really need more competition in the GPU space so we can reach a new generation of VRAM availability - imagine consumer cards shipping with 48-96GB and the compute focussed cards starting from 128GB etc. - the B100 series is already like this a bit, but there's still so little movement in the consumer GPU space.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rbbol","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think Kimi&amp;#39;s approach makes sense, with more attention heads you are paying that cost on every single inference, all the time. Whereas with more MoE, you only pay for what you use (although you need enough attention heads so that the experts can be well chosen).&lt;/p&gt;\\n\\n&lt;p&gt;But you can see the downside of needing even more VRAM for the greater number of experts (more parameters), even when you won&amp;#39;t use many of them for a specific prompt.&lt;/p&gt;\\n\\n&lt;p&gt;We really need more competition in the GPU space so we can reach a new generation of VRAM availability - imagine consumer cards shipping with 48-96GB and the compute focussed cards starting from 128GB etc. - the B100 series is already like this a bit, but there&amp;#39;s still so little movement in the consumer GPU space.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2rbbol/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752340868,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":51}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2t867o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Alkeryn","can_mod_post":false,"created_utc":1752363377,"send_replies":true,"parent_id":"t3_1ly42e5","score":9,"author_fullname":"t2_xbcpo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would be cool if moe models came with a predictor that tried to predict what expert will be used after the one currently being generated, that way you could preload the next n experts on gpu, and in case of no prediction miss you could gain some speed on memory bottlenecked hardware.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2t867o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would be cool if moe models came with a predictor that tried to predict what expert will be used after the one currently being generated, that way you could preload the next n experts on gpu, and in case of no prediction miss you could gain some speed on memory bottlenecked hardware.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2t867o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752363377,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2v3uma","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HumbleThought123","can_mod_post":false,"created_utc":1752393005,"send_replies":true,"parent_id":"t3_1ly42e5","score":3,"author_fullname":"t2_6br7b7oe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sometime i feel, it’s all just guess work. If training was not expensive, everyone would be publishing their SOTA.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2v3uma","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sometime i feel, it’s all just guess work. If training was not expensive, everyone would be publishing their SOTA.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2v3uma/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752393005,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2s3yys","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"created_utc":1752349893,"send_replies":true,"parent_id":"t3_1ly42e5","score":7,"author_fullname":"t2_101haj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I tried it for creative writing. It's not smart, which makes sense since it's not a reasoning model and is essentially doing stream-of-consciousness writing without preplanning anything, but it's deliciously good. About comparable to o3 in prose, if not a bit better.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2s3yys","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I tried it for creative writing. It&amp;#39;s not smart, which makes sense since it&amp;#39;s not a reasoning model and is essentially doing stream-of-consciousness writing without preplanning anything, but it&amp;#39;s deliciously good. About comparable to o3 in prose, if not a bit better.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2s3yys/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752349893,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2rvep2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Trick-Independent469","can_mod_post":false,"created_utc":1752347099,"send_replies":true,"parent_id":"t3_1ly42e5","score":2,"author_fullname":"t2_fs6bx6g5r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Next model 32 heads , double the number of experts","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2rvep2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Next model 32 heads , double the number of experts&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2rvep2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752347099,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2va9nu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tempetemplar","can_mod_post":false,"created_utc":1752396758,"send_replies":true,"parent_id":"t3_1ly42e5","score":1,"author_fullname":"t2_atvw2aj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yess","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2va9nu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yess&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2va9nu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752396758,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2wr713","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"created_utc":1752419519,"send_replies":true,"parent_id":"t3_1ly42e5","score":1,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And more censorship I hear. That only bothers me as it sometimes interferes with the most innocent of requests.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2wr713","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And more censorship I hear. That only bothers me as it sometimes interferes with the most innocent of requests.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2wr713/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752419519,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ujvlz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752382269,"send_replies":true,"parent_id":"t3_1ly42e5","score":1,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So is blue team or red team better?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ujvlz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So is blue team or red team better?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2ujvlz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752382269,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2t3tkc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ontorealist","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2soqlc","score":8,"author_fullname":"t2_pglwn8yb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's worse—he could be using [Kimi](https://www.kimi.com/share/d1pek2851tqdukdhbvhg) to find out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2t3tkc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s worse—he could be using &lt;a href=\\"https://www.kimi.com/share/d1pek2851tqdukdhbvhg\\"&gt;Kimi&lt;/a&gt; to find out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly42e5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2t3tkc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752361856,"author_flair_text":null,"treatment_tags":[],"created_utc":1752361856,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n2soqlc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Bananadite","can_mod_post":false,"created_utc":1752356626,"send_replies":true,"parent_id":"t1_n2sh25s","score":3,"author_fullname":"t2_y3wj4h5xn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not that hard to google\\n\\nhttps://preview.redd.it/8nzxx0rxjicf1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=0b41680d7776a322221fb3c3adec40c911b8c642","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2soqlc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not that hard to google&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/8nzxx0rxjicf1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b41680d7776a322221fb3c3adec40c911b8c642\\"&gt;https://preview.redd.it/8nzxx0rxjicf1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b41680d7776a322221fb3c3adec40c911b8c642&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1ly42e5","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2soqlc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752356626,"media_metadata":{"8nzxx0rxjicf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":93,"x":108,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=afae62e109d198b18f1ba3c6ffd9bff8414d4737"},{"y":186,"x":216,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb26927171f83c78eae9dae4877e83aa2482d7f8"},{"y":275,"x":320,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4cdffd638e0ee68b33e3937cbbf320df351add5b"},{"y":551,"x":640,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4c5610acc2aae606d3d6627e1b11b9ab68273d09"},{"y":826,"x":960,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2cf9af723d1d7ae0b7dc968699e1fda225c8b1ed"},{"y":930,"x":1080,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32e04a1a99d08e610010ffbf5ea31a79a40072f0"}],"s":{"y":930,"x":1080,"u":"https://preview.redd.it/8nzxx0rxjicf1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=0b41680d7776a322221fb3c3adec40c911b8c642"},"id":"8nzxx0rxjicf1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2sh25s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"shark8866","can_mod_post":false,"created_utc":1752354077,"send_replies":true,"parent_id":"t3_1ly42e5","score":0,"author_fullname":"t2_1237cb8qq5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"IS THERE A PAPER?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2sh25s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;IS THERE A PAPER?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1ly42e5/interesting_info_about_kimi_k2/n2sh25s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752354077,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1ly42e5","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
