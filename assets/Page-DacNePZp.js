import{j as e}from"./index-BOnf-UhU.js";import{R as a}from"./RedditPostRenderer-Ce39qICS.js";import"./index-CDase6VD.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"It's been a while and llama maverick and scout are still shite. I have tried nearly every provider at this point. \\n\\nAny updates if they're gonna launch any improvements to these models or any new reasoning models? \\n\\nHow are they fucking up this bad? Near unlimited money, resources, researchers. What are they doing wrong? \\n\\nThey weren't that far behind in the LLM race compared to Google and now they are like behind everyone at this point. \\n\\nAnd any updates on Microsoft? They're not gonna do their own models \\"Big Ones\\" and are completely reliant on OpenAI?\\n\\nChinese companies are releasing models left and right... I tested Ernie models and they're better than Llama 4s\\n\\nDeepSeek-V3-0324 seems to be the best non-reasoning open source LLM we have.\\n\\nAre there even any projects that have attempted to improve Llama4s via fine-tuning it or other magical techniques we have? God it's so shite, it's comprehension abilities are just embarrassing. It feels like you can find a million models that are far better than llama 4s for almost anything. The only thing they seem to have is speed on VRAM constrained setups but what's the point when then responses are useless? It's a waste of resource at this point. ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Any updates on Llama models from Meta?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lqhers","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.66,"author_flair_background_color":null,"subreddit_type":"public","ups":9,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_yfi9sqrzf","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":9,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751519922,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s been a while and llama maverick and scout are still shite. I have tried nearly every provider at this point. &lt;/p&gt;\\n\\n&lt;p&gt;Any updates if they&amp;#39;re gonna launch any improvements to these models or any new reasoning models? &lt;/p&gt;\\n\\n&lt;p&gt;How are they fucking up this bad? Near unlimited money, resources, researchers. What are they doing wrong? &lt;/p&gt;\\n\\n&lt;p&gt;They weren&amp;#39;t that far behind in the LLM race compared to Google and now they are like behind everyone at this point. &lt;/p&gt;\\n\\n&lt;p&gt;And any updates on Microsoft? They&amp;#39;re not gonna do their own models &amp;quot;Big Ones&amp;quot; and are completely reliant on OpenAI?&lt;/p&gt;\\n\\n&lt;p&gt;Chinese companies are releasing models left and right... I tested Ernie models and they&amp;#39;re better than Llama 4s&lt;/p&gt;\\n\\n&lt;p&gt;DeepSeek-V3-0324 seems to be the best non-reasoning open source LLM we have.&lt;/p&gt;\\n\\n&lt;p&gt;Are there even any projects that have attempted to improve Llama4s via fine-tuning it or other magical techniques we have? God it&amp;#39;s so shite, it&amp;#39;s comprehension abilities are just embarrassing. It feels like you can find a million models that are far better than llama 4s for almost anything. The only thing they seem to have is speed on VRAM constrained setups but what&amp;#39;s the point when then responses are useless? It&amp;#39;s a waste of resource at this point. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lqhers","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"True_Requirement_891","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/","subreddit_subscribers":494198,"created_utc":1751519922,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13zn8w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RickyRickC137","can_mod_post":false,"created_utc":1751543135,"send_replies":true,"parent_id":"t1_n12y39a","score":3,"author_fullname":"t2_mhdt7ir5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How's Ernie doing by the way?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13zn8w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How&amp;#39;s Ernie doing by the way?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13zn8w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751543135,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n12y39a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kataryna91","can_mod_post":false,"created_utc":1751522859,"send_replies":true,"parent_id":"t3_1lqhers","score":20,"author_fullname":"t2_tyn24pi9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They just hired a bunch of ML experts from other companies.  \\nIt will take a few months for them to build and execute a new training regime and RLHF loops etc.  \\nWe will see if they can take back the lead, but in the meantime the open source community is fine, there is Deepseek, Mistral, Qwen3 and now ERNIE to fill the last use of Llama4 (big VL model).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12y39a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They just hired a bunch of ML experts from other companies.&lt;br/&gt;\\nIt will take a few months for them to build and execute a new training regime and RLHF loops etc.&lt;br/&gt;\\nWe will see if they can take back the lead, but in the meantime the open source community is fine, there is Deepseek, Mistral, Qwen3 and now ERNIE to fill the last use of Llama4 (big VL model).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n12y39a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751522859,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13ph5f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"night0x63","can_mod_post":false,"created_utc":1751538385,"send_replies":true,"parent_id":"t1_n12vgp4","score":0,"author_fullname":"t2_3h2irqtz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was pondering llama4 recently. If you think of the history: llama3.1:405b is great quality/benchmarks but vram requirements is too much and even when you have the vram ... too many ops per token and so it is slow even on two h200; llama3.2 is great for small models; llama3.3 is great with same quality as 405b but about 10x faster.Â \\n\\n\\nI think I'm term of quality and benchmarks... Llama couldn't go bigger than 405b with dense. So they had to significantly innovate with mixture of experts and llama4 if they wanted to get bigger models than 405b... So IMO llama4 first attempt at mixture of experts was pretty good actually.Â \\n\\n\\nIMO the reason everyone gave it thumbs down was because IMO they targeted consumer cards... Running on 4090... So llama4 only has 17b active parameters. Which is great for single GPU 4090. But is about 2.3x less parameters than Mistral and deepseek active parameters. To get equivalent benchmarks as Deepseek would have needed 39b active parameters ... This is my guess. But they targeted 17b parameters.\\n\\n\\nHopefully next version of llama MOE has 39b active parameters. Or more IMO. I vote 40-70b with 400-1T total parameters.Â \\n\\n\\nP.s. For reference I heard ChatGPT has 1.8T parameters and MOE and 280b active parameters.Â \\n\\n\\nP.p.s. Also everyone ignored llama4's big innovation of 10m tokens. IMO that is big innovation too! But I don't know how you would run that (how much vram/ram is needed).","edited":1751538690,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13ph5f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was pondering llama4 recently. If you think of the history: llama3.1:405b is great quality/benchmarks but vram requirements is too much and even when you have the vram ... too many ops per token and so it is slow even on two h200; llama3.2 is great for small models; llama3.3 is great with same quality as 405b but about 10x faster.Â &lt;/p&gt;\\n\\n&lt;p&gt;I think I&amp;#39;m term of quality and benchmarks... Llama couldn&amp;#39;t go bigger than 405b with dense. So they had to significantly innovate with mixture of experts and llama4 if they wanted to get bigger models than 405b... So IMO llama4 first attempt at mixture of experts was pretty good actually.Â &lt;/p&gt;\\n\\n&lt;p&gt;IMO the reason everyone gave it thumbs down was because IMO they targeted consumer cards... Running on 4090... So llama4 only has 17b active parameters. Which is great for single GPU 4090. But is about 2.3x less parameters than Mistral and deepseek active parameters. To get equivalent benchmarks as Deepseek would have needed 39b active parameters ... This is my guess. But they targeted 17b parameters.&lt;/p&gt;\\n\\n&lt;p&gt;Hopefully next version of llama MOE has 39b active parameters. Or more IMO. I vote 40-70b with 400-1T total parameters.Â &lt;/p&gt;\\n\\n&lt;p&gt;P.s. For reference I heard ChatGPT has 1.8T parameters and MOE and 280b active parameters.Â &lt;/p&gt;\\n\\n&lt;p&gt;P.p.s. Also everyone ignored llama4&amp;#39;s big innovation of 10m tokens. IMO that is big innovation too! But I don&amp;#39;t know how you would run that (how much vram/ram is needed).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13ph5f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751538385,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n12vgp4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1751521494,"send_replies":true,"parent_id":"t3_1lqhers","score":17,"author_fullname":"t2_9hl4ymvj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Based on the hiring spree it seems llama 4.1 isnâ€™t going well.\\n\\nGive them a few months I guess.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12vgp4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Based on the hiring spree it seems llama 4.1 isnâ€™t going well.&lt;/p&gt;\\n\\n&lt;p&gt;Give them a few months I guess.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n12vgp4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751521494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n144b6i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Terminator857","can_mod_post":false,"send_replies":true,"parent_id":"t1_n12t7xj","score":0,"author_fullname":"t2_m40tjcn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Google failed miserably with gemini 1 and 2.  Only after a couple of years did it figure out the winning formula with gemini 2.5.  Keep in mind that Google has more than twice the data, twice the compute, and twice the scientists of anyone else, and just barely manages to come out on top.\\n\\nWith Gemini 1 it was a great product but after 6 months of safety training they managed to lobotomize it.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n144b6i","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google failed miserably with gemini 1 and 2.  Only after a couple of years did it figure out the winning formula with gemini 2.5.  Keep in mind that Google has more than twice the data, twice the compute, and twice the scientists of anyone else, and just barely manages to come out on top.&lt;/p&gt;\\n\\n&lt;p&gt;With Gemini 1 it was a great product but after 6 months of safety training they managed to lobotomize it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n144b6i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751544996,"author_flair_text":null,"treatment_tags":[],"created_utc":1751544996,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n12t7xj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"True_Requirement_891","can_mod_post":false,"created_utc":1751520368,"send_replies":true,"parent_id":"t1_n12so1t","score":5,"author_fullname":"t2_yfi9sqrzf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Man it's fucking sad at this point.\\n\\nGoogle is a chonker itself yet somehow they're SOTA now.\\n\\nAnd meta can't figure it out? Zuckerberg needs to take notes from Pichai.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12t7xj","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Man it&amp;#39;s fucking sad at this point.&lt;/p&gt;\\n\\n&lt;p&gt;Google is a chonker itself yet somehow they&amp;#39;re SOTA now.&lt;/p&gt;\\n\\n&lt;p&gt;And meta can&amp;#39;t figure it out? Zuckerberg needs to take notes from Pichai.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n12t7xj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751520368,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n12so1t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Terminator857","can_mod_post":false,"created_utc":1751520095,"send_replies":true,"parent_id":"t3_1lqhers","score":8,"author_fullname":"t2_m40tjcn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Corporate think.  Small agile teams with greater risk and rewards perform better.  Corporate people lie on their butts and go through the motions.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n12so1t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Corporate think.  Small agile teams with greater risk and rewards perform better.  Corporate people lie on their butts and go through the motions.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n12so1t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751520095,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n15l6mb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"created_utc":1751561177,"send_replies":true,"parent_id":"t1_n1318e3","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"*The basilisk will remember that*","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n15l6mb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;em&gt;The basilisk will remember that&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n15l6mb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751561177,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1318e3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751524548,"send_replies":true,"parent_id":"t3_1lqhers","score":7,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is super puzzling is what happened to Maverick experimental. It had nice vibe, comparable to v3 0324 and Qwen 3 232. As if they deliberately botched llama 4 for some stock manipulation shenanigans.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1318e3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is super puzzling is what happened to Maverick experimental. It had nice vibe, comparable to v3 0324 and Qwen 3 232. As if they deliberately botched llama 4 for some stock manipulation shenanigans.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n1318e3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751524548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13sflr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sunshinecheung","can_mod_post":false,"created_utc":1751539885,"send_replies":true,"parent_id":"t3_1lqhers","score":4,"author_fullname":"t2_u398xzta","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"maybe waiting for their new llama5 models (by new top folks)Â \\n\\nhttps://preview.redd.it/b78btijo3naf1.png?width=1320&amp;format=png&amp;auto=webp&amp;s=fa9e3fc407f24ed88d14dddaa50bd55511ec998f","edited":1751540099,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13sflr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;maybe waiting for their new llama5 models (by new top folks)Â &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/b78btijo3naf1.png?width=1320&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fa9e3fc407f24ed88d14dddaa50bd55511ec998f\\"&gt;https://preview.redd.it/b78btijo3naf1.png?width=1320&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fa9e3fc407f24ed88d14dddaa50bd55511ec998f&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13sflr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751539885,"media_metadata":{"b78btijo3naf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":155,"x":108,"u":"https://preview.redd.it/b78btijo3naf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=270669fbc78dc760dd21af043444d4ea21e76777"},{"y":311,"x":216,"u":"https://preview.redd.it/b78btijo3naf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d12a9c28fedd909046cb5f8f78a40e19fa0bbda4"},{"y":461,"x":320,"u":"https://preview.redd.it/b78btijo3naf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=118c6535ef78e32cf158131fddf49ab167e81b86"},{"y":923,"x":640,"u":"https://preview.redd.it/b78btijo3naf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7f17e9e5eabca4348d45f47a96742734085ad63"},{"y":1385,"x":960,"u":"https://preview.redd.it/b78btijo3naf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c3efaec37573945b5a7b2e391e5ef84a83595d1"},{"y":1558,"x":1080,"u":"https://preview.redd.it/b78btijo3naf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b2d93455fdd4602b4840f2c384462876dd8fa473"}],"s":{"y":1905,"x":1320,"u":"https://preview.redd.it/b78btijo3naf1.png?width=1320&amp;format=png&amp;auto=webp&amp;s=fa9e3fc407f24ed88d14dddaa50bd55511ec998f"},"id":"b78btijo3naf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13ucl5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"created_utc":1751540794,"send_replies":true,"parent_id":"t3_1lqhers","score":2,"author_fullname":"t2_s4zzntp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/eb9rmhm16naf1.png?width=400&amp;format=png&amp;auto=webp&amp;s=81ae27cbbcc9d04a4bc51df9f262754a9d38ddea","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13ucl5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/eb9rmhm16naf1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81ae27cbbcc9d04a4bc51df9f262754a9d38ddea\\"&gt;https://preview.redd.it/eb9rmhm16naf1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81ae27cbbcc9d04a4bc51df9f262754a9d38ddea&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13ucl5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751540794,"media_metadata":{"eb9rmhm16naf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":81,"x":108,"u":"https://preview.redd.it/eb9rmhm16naf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=521d6642222a1c0cc64db5ba7080ef772a5f09af"},{"y":163,"x":216,"u":"https://preview.redd.it/eb9rmhm16naf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7455f8c4730743320b81d875b4d8e8418bf8253a"},{"y":241,"x":320,"u":"https://preview.redd.it/eb9rmhm16naf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=17b5709cff63133d003442cc22793891a832c87b"}],"s":{"y":302,"x":400,"u":"https://preview.redd.it/eb9rmhm16naf1.png?width=400&amp;format=png&amp;auto=webp&amp;s=81ae27cbbcc9d04a4bc51df9f262754a9d38ddea"},"id":"eb9rmhm16naf1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n13m5vv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"brown2green","can_mod_post":false,"created_utc":1751536607,"send_replies":true,"parent_id":"t1_n13lbfi","score":5,"author_fullname":"t2_f010l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The pre-release and anonymous Llama 4 models on LMArena seemed OK, great even in some aspects. Something must have happened just before their official release, prompting the team in charge of it to completely change course at the last minute. I'm speculating legal- and \\"safety\\"-related.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13m5vv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The pre-release and anonymous Llama 4 models on LMArena seemed OK, great even in some aspects. Something must have happened just before their official release, prompting the team in charge of it to completely change course at the last minute. I&amp;#39;m speculating legal- and &amp;quot;safety&amp;quot;-related.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13m5vv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751536607,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n17auo1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iamgladiator","can_mod_post":false,"send_replies":true,"parent_id":"t1_n13xos1","score":1,"author_fullname":"t2_capf2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Whats your experience actually using it entsnack? You liking it? Whats it doing well at for you?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n17auo1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Whats your experience actually using it entsnack? You liking it? Whats it doing well at for you?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n17auo1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751579246,"author_flair_text":null,"treatment_tags":[],"created_utc":1751579246,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n13xos1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"created_utc":1751542300,"send_replies":true,"parent_id":"t1_n13lbfi","score":0,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How is it DOA? It's in the top 2 on intelligence rankings.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13xos1","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How is it DOA? It&amp;#39;s in the top 2 on intelligence rankings.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqhers","unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13xos1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751542300,"author_flair_text":":X:","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n13lbfi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1751536133,"send_replies":true,"parent_id":"t3_1lqhers","score":0,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was bombed with dislikes when I said Llama 4 will be DOA. I guess some people have to see to believe. ðŸ˜Š","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n13lbfi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was bombed with dislikes when I said Llama 4 will be DOA. I guess some people have to see to believe. ðŸ˜Š&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqhers/any_updates_on_llama_models_from_meta/n13lbfi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751536133,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqhers","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}}]`),o=()=>e.jsx(a,{data:l});export{o as default};
