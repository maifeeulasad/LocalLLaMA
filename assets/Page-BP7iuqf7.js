import{j as e}from"./index-CeRg6Q3f.js";import{R as l}from"./RedditPostRenderer-D7n1g-D8.js";import"./index-DPToWe3n.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Who's down? [https://www.reddit.com/r/RooCode/comments/1lufep2/lets\\\\_train\\\\_a\\\\_local\\\\_opensource\\\\_model\\\\_to\\\\_use\\\\_roo/](https://www.reddit.com/r/RooCode/comments/1lufep2/lets_train_a_local_opensource_model_to_use_roo/)\\n\\nFYI Roo Code is an open source VS Code extension, forked from Cline, which is comparable to Github Copilot.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Let's train a local open-source coding agent model and kick BigAI's ass!","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lufhso","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.56,"author_flair_background_color":null,"subreddit_type":"public","ups":2,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1w2kbht","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":2,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751948761,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Who&amp;#39;s down? &lt;a href=\\"https://www.reddit.com/r/RooCode/comments/1lufep2/lets_train_a_local_opensource_model_to_use_roo/\\"&gt;https://www.reddit.com/r/RooCode/comments/1lufep2/lets_train_a_local_opensource_model_to_use_roo/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;FYI Roo Code is an open source VS Code extension, forked from Cline, which is comparable to Github Copilot.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lufhso","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"InstrumentalAsylum","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/","subreddit_subscribers":496035,"created_utc":1751948761,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xyf10","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1xur48","score":1,"author_fullname":"t2_6lmlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's less that I find debugging crappy LLM code joyless and more that it rapidly breaks down if you need to integrate it into anything. It's usually OK for rapid prototyping. Claude benchmark at about 90% (which is a LOT higher than every other model) for refactoring on code benchmarks but still not nearly enough for reliable refactoring, imo. I welcome someone else giving it a proper go","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1xyf10","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s less that I find debugging crappy LLM code joyless and more that it rapidly breaks down if you need to integrate it into anything. It&amp;#39;s usually OK for rapid prototyping. Claude benchmark at about 90% (which is a LOT higher than every other model) for refactoring on code benchmarks but still not nearly enough for reliable refactoring, imo. I welcome someone else giving it a proper go&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lufhso","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xyf10/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751956237,"author_flair_text":null,"treatment_tags":[],"created_utc":1751956237,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1xur48","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InstrumentalAsylum","can_mod_post":false,"created_utc":1751954274,"send_replies":true,"parent_id":"t1_n1xtybn","score":1,"author_fullname":"t2_1w2kbht","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exactly, a future where human devs are just there to debug crappy chatGPT code sounds pretty joyless. \\n\\n\\nAnecdotally, Claude sonnet has crossed this threshold of usefulness. That's why I'm looking to distill this emergent capability into a local model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xur48","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly, a future where human devs are just there to debug crappy chatGPT code sounds pretty joyless. &lt;/p&gt;\\n\\n&lt;p&gt;Anecdotally, Claude sonnet has crossed this threshold of usefulness. That&amp;#39;s why I&amp;#39;m looking to distill this emergent capability into a local model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lufhso","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xur48/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751954274,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1xtybn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ylsid","can_mod_post":false,"created_utc":1751953863,"send_replies":true,"parent_id":"t3_1lufhso","score":4,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think code LLM trainers are too hung up on having them score well on tests. I'd like to see an LLM that I can actually use for difficult to automate drudgery, like code refactoring. I don't want it to write new code, I want it to assist me with existing code.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xtybn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think code LLM trainers are too hung up on having them score well on tests. I&amp;#39;d like to see an LLM that I can actually use for difficult to automate drudgery, like code refactoring. I don&amp;#39;t want it to write new code, I want it to assist me with existing code.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xtybn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751953863,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lufhso","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xjxzj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Juan_Laulu","can_mod_post":false,"created_utc":1751949038,"send_replies":true,"parent_id":"t3_1lufhso","score":2,"author_fullname":"t2_t8924u3o","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Okay","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xjxzj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xjxzj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751949038,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lufhso","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1xrh47","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InstrumentalAsylum","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1xovwc","score":1,"author_fullname":"t2_1w2kbht","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean it's a tough problem, letting an llm make open-ended decisions. If you have a specific flow, you can hardcode nodes which require a response in a certain tool call format. Just telling an llm to follow a specific format is going to be pretty flimsy, unless the model was specifically trained to use your format. Devstral was actually fine-tuned to use their Open hands agent platform, which is likely why it performs best out of the box, despite being a smaller model. \\n\\n\\nFortunately, since we have open source models and agent platforms, it's only a small step to qlora a model to be able to code reliably on its own, we just need to distill some examples from a SOTA model like Claude.","edited":1751952866,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xrh47","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean it&amp;#39;s a tough problem, letting an llm make open-ended decisions. If you have a specific flow, you can hardcode nodes which require a response in a certain tool call format. Just telling an llm to follow a specific format is going to be pretty flimsy, unless the model was specifically trained to use your format. Devstral was actually fine-tuned to use their Open hands agent platform, which is likely why it performs best out of the box, despite being a smaller model. &lt;/p&gt;\\n\\n&lt;p&gt;Fortunately, since we have open source models and agent platforms, it&amp;#39;s only a small step to qlora a model to be able to code reliably on its own, we just need to distill some examples from a SOTA model like Claude.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lufhso","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xrh47/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751952602,"author_flair_text":null,"treatment_tags":[],"created_utc":1751952602,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1xovwc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Agreeable-Prompt-666","can_mod_post":false,"send_replies":true,"parent_id":"t1_n1xmln8","score":2,"author_fullname":"t2_1l3z4stvkq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you feel it's the fault of the code or the LLM? Assuming speed not an issue would 70B not get hung up for example","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1xovwc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you feel it&amp;#39;s the fault of the code or the LLM? Assuming speed not an issue would 70B not get hung up for example&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lufhso","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xovwc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751951336,"author_flair_text":null,"treatment_tags":[],"created_utc":1751951336,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1xmln8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"InstrumentalAsylum","can_mod_post":false,"created_utc":1751950259,"send_replies":true,"parent_id":"t1_n1xla2q","score":2,"author_fullname":"t2_1w2kbht","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've tried qwen 235b, qwen coder 32b and the new QwQ. They're quite smart, but they can only run autonomously for a couple messages before they get hung up Trying to edit a file and failing over and over. The system prompt for Roo is just not strong enough to get them to use the tools correctly if they weren't specifically trained on them. For a true coding agent, I expect it to crank on its own for an entire work day without hitting a wall.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xmln8","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tried qwen 235b, qwen coder 32b and the new QwQ. They&amp;#39;re quite smart, but they can only run autonomously for a couple messages before they get hung up Trying to edit a file and failing over and over. The system prompt for Roo is just not strong enough to get them to use the tools correctly if they weren&amp;#39;t specifically trained on them. For a true coding agent, I expect it to crank on its own for an entire work day without hitting a wall.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lufhso","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xmln8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751950259,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n1xla2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1751949645,"send_replies":true,"parent_id":"t3_1lufhso","score":1,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"But you don't need a specific coding agent, roo+qwen3-32B is good enough.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1xla2q","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But you don&amp;#39;t need a specific coding agent, roo+qwen3-32B is good enough.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lufhso/lets_train_a_local_opensource_coding_agent_model/n1xla2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751949645,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1lufhso","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
