import{j as e}from"./index-Cd3v0jxz.js";import{R as t}from"./RedditPostRenderer-cI96YLhy.js";import"./index-DGBoKyQm.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I recently started thinking about using local AI, but I don't know where to start, what I need, or if I can afford it. So I wanted to ask a few questions.\\n\\n1. What do I need at a minimum to use a local AI?\\n2. Where can I find it to download?\\n3. What do I need to know before I start?\\n4. What really changes from one model to the other?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I want to start with local AI","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m5nt6s","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.33,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lrleoa4b0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753115868,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I recently started thinking about using local AI, but I don&amp;#39;t know where to start, what I need, or if I can afford it. So I wanted to ask a few questions.&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;What do I need at a minimum to use a local AI?&lt;/li&gt;\\n&lt;li&gt;Where can I find it to download?&lt;/li&gt;\\n&lt;li&gt;What do I need to know before I start?&lt;/li&gt;\\n&lt;li&gt;What really changes from one model to the other?&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1m5nt6s","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Then-History2046","discussion_type":null,"num_comments":8,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/","subreddit_subscribers":502721,"created_utc":1753115868,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4da7fi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"3z3ki3l","can_mod_post":false,"created_utc":1753116341,"send_replies":true,"parent_id":"t3_1m5nt6s","score":3,"author_fullname":"t2_7u9zp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1) A computer or phone.\\n\\n2) Huggingface.\\n\\n3) Honestly, ask your favorite LLM.\\n\\n4) Buncha stuff. Mostly fine tuning.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4da7fi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1) A computer or phone.&lt;/p&gt;\\n\\n&lt;p&gt;2) Huggingface.&lt;/p&gt;\\n\\n&lt;p&gt;3) Honestly, ask your favorite LLM.&lt;/p&gt;\\n\\n&lt;p&gt;4) Buncha stuff. Mostly fine tuning.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4da7fi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753116341,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dgskz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nazihater3000","can_mod_post":false,"created_utc":1753118142,"send_replies":true,"parent_id":"t3_1m5nt6s","score":2,"author_fullname":"t2_j3brbc6qz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does a black screen with a blinking cursor scares you?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dgskz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does a black screen with a blinking cursor scares you?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dgskz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753118142,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dfglv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"optimisticalish","can_mod_post":false,"created_utc":1753117774,"send_replies":true,"parent_id":"t3_1m5nt6s","score":2,"author_fullname":"t2_iu9wdkoe","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"First you need the desktop hardware, and thus the initial questions are: \\"what have I already got\\" and \\"how much can I afford to spend (to upgrade)\\"? Everything hinges on this. I see you're in Brazil, and I hear (for some reason) a decent graphics card there is incredibly expensive compared to the USA, so you may be at a disadvantage there.\\n\\nAssuming you have or can get and fit and power a good NVIDIA card in your desktop PC, then your choice is with the OS: Windows 11 (Superlite, perhaps) or Linux (likely Mint).  \\n\\nThen you get a big sheet of paper and draw a diagram of all the things you want to *do* with local AI / LLMs / image and video generation, with offshoot bubbles to note the other desktop software you'll also need (Photoshop etc). Novel, comics, research, academic writing, guidebooks, picturebooks, videos, maps, games, 3D models, audiobooks with soundscapes, etc etc. \\n\\nI suggest Msty as an initial 'learning about it all' host for local LLM AIs. ComfyUI as your image and video generator/editor, along with Photoshop. NovelForge for a creative writing local offline creative-writing tool (can tap into local LLMs).\\n\\nThen... you look at the sizes and dependencies of all the items on your big sheet of paper, and you likely realise you're going to need a much bigger SSD.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dfglv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;First you need the desktop hardware, and thus the initial questions are: &amp;quot;what have I already got&amp;quot; and &amp;quot;how much can I afford to spend (to upgrade)&amp;quot;? Everything hinges on this. I see you&amp;#39;re in Brazil, and I hear (for some reason) a decent graphics card there is incredibly expensive compared to the USA, so you may be at a disadvantage there.&lt;/p&gt;\\n\\n&lt;p&gt;Assuming you have or can get and fit and power a good NVIDIA card in your desktop PC, then your choice is with the OS: Windows 11 (Superlite, perhaps) or Linux (likely Mint).  &lt;/p&gt;\\n\\n&lt;p&gt;Then you get a big sheet of paper and draw a diagram of all the things you want to &lt;em&gt;do&lt;/em&gt; with local AI / LLMs / image and video generation, with offshoot bubbles to note the other desktop software you&amp;#39;ll also need (Photoshop etc). Novel, comics, research, academic writing, guidebooks, picturebooks, videos, maps, games, 3D models, audiobooks with soundscapes, etc etc. &lt;/p&gt;\\n\\n&lt;p&gt;I suggest Msty as an initial &amp;#39;learning about it all&amp;#39; host for local LLM AIs. ComfyUI as your image and video generator/editor, along with Photoshop. NovelForge for a creative writing local offline creative-writing tool (can tap into local LLMs).&lt;/p&gt;\\n\\n&lt;p&gt;Then... you look at the sizes and dependencies of all the items on your big sheet of paper, and you likely realise you&amp;#39;re going to need a much bigger SSD.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dfglv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753117774,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4hb4ij","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AutomataManifold","can_mod_post":false,"created_utc":1753165170,"send_replies":true,"parent_id":"t3_1m5nt6s","score":2,"author_fullname":"t2_bfs5bk7y8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1. At minimum? Something that can run a model. Having more resources (more VRAM, etc.) makes it easier to run a big model with the relatively easy setup. If you're resource constrained and are stuck running a small model with odd hardware you'll have to tinker with it more to get it going.  \\n2. Huggingface. There's other places but if you want a one-stop shop the Huggingface model tab is the place to look.  \\n3. Probably the first thing to learn is the difference between the model, the inference engine, and the front-end UI.  \\n4. Everything and nothing. Which is a flippant answer, but kinda true in that yes, different models will respond very differently, but there's no one characteristic that tracks the changes and there's a lot of models that do similar things.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4hb4ij","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;ol&gt;\\n&lt;li&gt;At minimum? Something that can run a model. Having more resources (more VRAM, etc.) makes it easier to run a big model with the relatively easy setup. If you&amp;#39;re resource constrained and are stuck running a small model with odd hardware you&amp;#39;ll have to tinker with it more to get it going.&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;Huggingface. There&amp;#39;s other places but if you want a one-stop shop the Huggingface model tab is the place to look.&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;Probably the first thing to learn is the difference between the model, the inference engine, and the front-end UI.&lt;br/&gt;&lt;/li&gt;\\n&lt;li&gt;Everything and nothing. Which is a flippant answer, but kinda true in that yes, different models will respond very differently, but there&amp;#39;s no one characteristic that tracks the changes and there&amp;#39;s a lot of models that do similar things.&lt;/li&gt;\\n&lt;/ol&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4hb4ij/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753165170,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dez46","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kironlau","can_mod_post":false,"created_utc":1753117641,"send_replies":true,"parent_id":"t3_1m5nt6s","score":1,"author_fullname":"t2_tb0dz2ds","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A easy starting point is: downloading a gui, which could  download model and inference at the same time.  \\nAndroid: Pocketpal  \\nWindow/Linux/MacOS: LM Studio\\n\\nThen download a small model, and talk with the LLM.\\n\\nAfter you gain experience, you could choose other model, or finetune the setting/parameter of the model.\\n\\nI suggest you could watch some tutorial video in YT. You will get a rough idea to start.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dez46","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A easy starting point is: downloading a gui, which could  download model and inference at the same time.&lt;br/&gt;\\nAndroid: Pocketpal&lt;br/&gt;\\nWindow/Linux/MacOS: LM Studio&lt;/p&gt;\\n\\n&lt;p&gt;Then download a small model, and talk with the LLM.&lt;/p&gt;\\n\\n&lt;p&gt;After you gain experience, you could choose other model, or finetune the setting/parameter of the model.&lt;/p&gt;\\n\\n&lt;p&gt;I suggest you could watch some tutorial video in YT. You will get a rough idea to start.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dez46/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753117641,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dxzkf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4dw0ao","score":-2,"author_fullname":"t2_1tpuoj72sa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately, thanks to Ngreedia. I have a used one. I can give you discount. If you are poor you need to settle for a RTX Pro 6000.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4dxzkf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately, thanks to Ngreedia. I have a used one. I can give you discount. If you are poor you need to settle for a RTX Pro 6000.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5nt6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dxzkf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122876,"author_flair_text":null,"treatment_tags":[],"created_utc":1753122876,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dw0ao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"supernova3301","can_mod_post":false,"created_utc":1753122320,"send_replies":true,"parent_id":"t1_n4dtngn","score":2,"author_fullname":"t2_1owsmjnmvy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Itâ€™s pretty costly. 39,000$ ðŸ˜µâ€ðŸ’«","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dw0ao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Itâ€™s pretty costly. 39,000$ ðŸ˜µâ€ðŸ’«&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m5nt6s","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dw0ao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122320,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dtngn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GPTrack_ai","can_mod_post":false,"created_utc":1753121658,"send_replies":true,"parent_id":"t3_1m5nt6s","score":-1,"author_fullname":"t2_1tpuoj72sa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"1.) What do I need at a minimum to use a local AI?  \\nA: If you are serious: GH200 624GB from GPTshop.ai or GPTrack.ai \\n\\n2.) Where can I find it to download?  \\nA: [https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)\\n\\n3.) What do I need to know before I start?  \\nA: Linux\\n\\n4.) What really changes from one model to the other?  \\nA: Everything","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dtngn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;1.) What do I need at a minimum to use a local AI?&lt;br/&gt;\\nA: If you are serious: GH200 624GB from GPTshop.ai or GPTrack.ai &lt;/p&gt;\\n\\n&lt;p&gt;2.) Where can I find it to download?&lt;br/&gt;\\nA: &lt;a href=\\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507\\"&gt;https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;3.) What do I need to know before I start?&lt;br/&gt;\\nA: Linux&lt;/p&gt;\\n\\n&lt;p&gt;4.) What really changes from one model to the other?&lt;br/&gt;\\nA: Everything&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m5nt6s/i_want_to_start_with_local_ai/n4dtngn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753121658,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m5nt6s","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),r=()=>e.jsx(t,{data:l});export{r as default};
