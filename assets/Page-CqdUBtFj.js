import{j as e}from"./index-DACS7Nh6.js";import{R as l}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Possible size of new the open model from openai","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":96,"top_awarded_type":null,"hide_score":false,"name":"t3_1lvwya4","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.89,"author_flair_background_color":null,"ups":347,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_dyvrh","secure_media":null,"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":347,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/SWE3wKhFq64W19U8vrSnM4JhB3rrFvjK8ka3DKWgysk.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"image","content_categories":null,"is_self":false,"subreddit_type":"public","created":1752101694,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"i.redd.it","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://i.redd.it/622w5dyvhxbf1.png","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://preview.redd.it/622w5dyvhxbf1.png?auto=webp&amp;s=a2c619e25718a02777bbfccf1e457faeec66291e","width":1080,"height":746},"resolutions":[{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=69c3323c05b9e9e24c72ce6d4331170952c6539b","width":108,"height":74},{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2058d759bbe6568a23d5ba18b34f5d8e8f676b3","width":216,"height":149},{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1585e0e58618c37cdfe1fdba6c0c1fbcd64e53c3","width":320,"height":221},{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f278161d7e564140ede28f9eff15dc776e5ab6df","width":640,"height":442},{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=15aac87a5266c6f4637f48e9a986a0d830cea8e5","width":960,"height":663},{"url":"https://preview.redd.it/622w5dyvhxbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77bb6536d895705fee43ebe991bd07b835b00a2a","width":1080,"height":746}],"variants":{},"id":"8YmohOSgc8VabZC-CUEtYfc1-XLSW8tYibkJW3Qz4Ac"}],"enabled":true},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lvwya4","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"celsowm","discussion_type":null,"num_comments":102,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/","stickied":false,"url":"https://i.redd.it/622w5dyvhxbf1.png","subreddit_subscribers":497354,"created_utc":1752101694,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2djrpm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2dhgzu","score":4,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nobody knows what the proprietary models are doing but having such scaling optimisation opportunity and not using it seems don't seem realistic.  \\nThat being said if for a given size of model the infrastructure is compute bound and not vram limited then quantization isn't worth it.  \\nBut if you want to make a \\"light weight\\" model for easy deployment like say for a open source model or edge model, then quantization is a must And QAT just make it better.  \\nAlso we train in fp32, bf16 or fp8, but now modern hardware is also optimised for 4 bits, so would be a shame to bot do inference on 4 bits","edited":1752160305,"author_flair_css_class":null,"name":"t1_n2djrpm","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nobody knows what the proprietary models are doing but having such scaling optimisation opportunity and not using it seems don&amp;#39;t seem realistic.&lt;br/&gt;\\nThat being said if for a given size of model the infrastructure is compute bound and not vram limited then quantization isn&amp;#39;t worth it.&lt;br/&gt;\\nBut if you want to make a &amp;quot;light weight&amp;quot; model for easy deployment like say for a open source model or edge model, then quantization is a must And QAT just make it better.&lt;br/&gt;\\nAlso we train in fp32, bf16 or fp8, but now modern hardware is also optimised for 4 bits, so would be a shame to bot do inference on 4 bits&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2djrpm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752160112,"author_flair_text":"llama.cpp","collapsed":false,"created_utc":1752160112,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2dhgzu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DragonfruitIll660","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cxd35","score":3,"author_fullname":"t2_duscbn82","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is QAT pretty standard now? I think I've only seen it on the Google Gemma model so far.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2dhgzu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is QAT pretty standard now? I think I&amp;#39;ve only seen it on the Google Gemma model so far.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2dhgzu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752159466,"author_flair_text":null,"treatment_tags":[],"created_utc":1752159466,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cxd35","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aiuh2","score":6,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it's QAT you really don't need 8bit.  \\nIf it's not QAT they are screwing with us","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cxd35","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s QAT you really don&amp;#39;t need 8bit.&lt;br/&gt;\\nIf it&amp;#39;s not QAT they are screwing with us&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cxd35/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752153455,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752153455,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aiuh2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"dash_bro","can_mod_post":false,"created_utc":1752113576,"send_replies":true,"parent_id":"t1_n29lg4l","score":25,"author_fullname":"t2_4bzd6saj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Honestly if it's a SoTA small model, I'm open to upgrading my hardware to support 8bit quantized weights\\n\\nGive us something that's better than when/Mistral at a 14B size and we'll talk, openai!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aiuh2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly if it&amp;#39;s a SoTA small model, I&amp;#39;m open to upgrading my hardware to support 8bit quantized weights&lt;/p&gt;\\n\\n&lt;p&gt;Give us something that&amp;#39;s better than when/Mistral at a 14B size and we&amp;#39;ll talk, openai!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aiuh2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752113576,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2b2zap","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShengrenR","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ayj2k","score":9,"author_fullname":"t2_ji4n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For 'creative writing' I doubt you'll feel much - but for coding, which is a bit more picky, that little bit of extra precision can help - that said, a bigger model is usually better, so if there's a q4 that still fits and is larger that'd be my personal bet over higher precision.","edited":false,"author_flair_css_class":null,"name":"t1_n2b2zap","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For &amp;#39;creative writing&amp;#39; I doubt you&amp;#39;ll feel much - but for coding, which is a bit more picky, that little bit of extra precision can help - that said, a bigger model is usually better, so if there&amp;#39;s a q4 that still fits and is larger that&amp;#39;d be my personal bet over higher precision.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b2zap/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752121481,"author_flair_text":null,"collapsed":false,"created_utc":1752121481,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ghmc3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"droptableadventures","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cmfmj","score":2,"author_fullname":"t2_52zg0eoq","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Makes sense because 3/5/6 don't evenly fit into a byte, so you'd potentially have to read two bytes to deal with them if they sat across a boundary.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2ghmc3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Makes sense because 3/5/6 don&amp;#39;t evenly fit into a byte, so you&amp;#39;d potentially have to read two bytes to deal with them if they sat across a boundary.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ghmc3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752190918,"author_flair_text":null,"treatment_tags":[],"created_utc":1752190918,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cmfmj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ayj2k","score":2,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"FWIW, I've found q3/5/6 are often slower than q4.","edited":false,"author_flair_css_class":null,"name":"t1_n2cmfmj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;FWIW, I&amp;#39;ve found q3/5/6 are often slower than q4.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cmfmj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752149611,"author_flair_text":null,"collapsed":false,"created_utc":1752149611,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ayj2k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheMaestroCleansing","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2aoadf","score":7,"author_fullname":"t2_7sxunipg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice writeup! With my m3 max/36gb system most 32b models run decently well at 4 bit. Wondering if I should push to 6 or if there isn’t much of a quality difference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ayj2k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice writeup! With my m3 max/36gb system most 32b models run decently well at 4 bit. Wondering if I should push to 6 or if there isn’t much of a quality difference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ayj2k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752119587,"author_flair_text":null,"treatment_tags":[],"created_utc":1752119587,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n2aoadf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teachersecret","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":68,"author_fullname":"t2_ddyte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It’s a trade off due to common vram and speed constraints. Most of us are running a configuration that is 24gb of vram, or less. I’ve got a 4090 onboard, 24gb. There are lots of 12gb peeps, 8gb too. And a few lucky 48 gb members. At basically all of those sizes, the best model you’re likely to run on the card fully in vram with decent context is going to be 4 bit quantized.\\n\\nA 32b model run in 4 bit is just small enough that it fits inside 24gb vram along with a nice chunk of context. It’s not going to be giving you 100k context windows or anything, but it’s usable.\\n\\nThat’s about the smartest thing you can run on 24gb. You can run the 22-24b style mistral models if you like but they’ll usually be less performant even if you do run them in 6 bit, meaning you usually want to be running the best model you can at the edge of what your card can manage.\\n\\nThis is mostly what pushes the use of 4 bit at the 24gb range. That’s the best bang for the buck.\\n\\nOn 48gb (dual 3090/4090 or one of those fancy 48gb a6000s or something) you can run 70b models at speed… in 4 bit. Any larger and it just won’t fit. And there isn’t much point in going to a smaller model at a higher quant, because it won’t beat the 70b at 4 bit.\\n\\nOn smaller cards like 8gb and 12gb vram cards or models that can run cpu only at decent speed (qwen 30b3a model comes to mind), 4 bit gives you most of the intelligence at a size small enough that 7b-14b models and the aforementioned MOE 30ba3b model run at a tolerable speed… and at 8gb vram you can fit decent 8B and below models fully on the card and run them at reasonably blazing speeds at 4 bit :).\\n\\nOn a 12gb card like a 3080ti, things like Nemo 12b  and qwen 14b fit great, at 4 bit.\\n\\nI will say that 4 bit noticeably degrades a model in my experience compared to the same model running in 8 bit. I doubt I could tell you if a model was running in fp8 or fp16, but I think I could absolutely spot the 4 bit model if you gave me a few minutes to play with the same exact model at different quant levels. It starts to lose some of the fidelity in a way you can feel when you do some serious writing with it, and it only really makes sense to run them at 4 bit because it’s the path to the most intelligence you can run on the home hardware without cranking up a server class rig full of unobtanium nvidia parts. :)\\n\\nUltimately, 4 bit is “good enough” for most of what you’re likely to do with a home-run llm. If you’re chasing maximum quality, pay Claude for api access. If you’re just screwing around with making Dixie Flatline manage your house lights and climate control, 4 bit is probably fine.\\n\\nGo lower than 4 bit and the fact that you’ve substantially degraded the model is obvious. I’d run 32b at 4 bit before I’d use a 70b at 2 bit. The 2 bit 70b is going to be an atrocious writer.","edited":1752115845,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2aoadf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s a trade off due to common vram and speed constraints. Most of us are running a configuration that is 24gb of vram, or less. I’ve got a 4090 onboard, 24gb. There are lots of 12gb peeps, 8gb too. And a few lucky 48 gb members. At basically all of those sizes, the best model you’re likely to run on the card fully in vram with decent context is going to be 4 bit quantized.&lt;/p&gt;\\n\\n&lt;p&gt;A 32b model run in 4 bit is just small enough that it fits inside 24gb vram along with a nice chunk of context. It’s not going to be giving you 100k context windows or anything, but it’s usable.&lt;/p&gt;\\n\\n&lt;p&gt;That’s about the smartest thing you can run on 24gb. You can run the 22-24b style mistral models if you like but they’ll usually be less performant even if you do run them in 6 bit, meaning you usually want to be running the best model you can at the edge of what your card can manage.&lt;/p&gt;\\n\\n&lt;p&gt;This is mostly what pushes the use of 4 bit at the 24gb range. That’s the best bang for the buck.&lt;/p&gt;\\n\\n&lt;p&gt;On 48gb (dual 3090/4090 or one of those fancy 48gb a6000s or something) you can run 70b models at speed… in 4 bit. Any larger and it just won’t fit. And there isn’t much point in going to a smaller model at a higher quant, because it won’t beat the 70b at 4 bit.&lt;/p&gt;\\n\\n&lt;p&gt;On smaller cards like 8gb and 12gb vram cards or models that can run cpu only at decent speed (qwen 30b3a model comes to mind), 4 bit gives you most of the intelligence at a size small enough that 7b-14b models and the aforementioned MOE 30ba3b model run at a tolerable speed… and at 8gb vram you can fit decent 8B and below models fully on the card and run them at reasonably blazing speeds at 4 bit :).&lt;/p&gt;\\n\\n&lt;p&gt;On a 12gb card like a 3080ti, things like Nemo 12b  and qwen 14b fit great, at 4 bit.&lt;/p&gt;\\n\\n&lt;p&gt;I will say that 4 bit noticeably degrades a model in my experience compared to the same model running in 8 bit. I doubt I could tell you if a model was running in fp8 or fp16, but I think I could absolutely spot the 4 bit model if you gave me a few minutes to play with the same exact model at different quant levels. It starts to lose some of the fidelity in a way you can feel when you do some serious writing with it, and it only really makes sense to run them at 4 bit because it’s the path to the most intelligence you can run on the home hardware without cranking up a server class rig full of unobtanium nvidia parts. :)&lt;/p&gt;\\n\\n&lt;p&gt;Ultimately, 4 bit is “good enough” for most of what you’re likely to do with a home-run llm. If you’re chasing maximum quality, pay Claude for api access. If you’re just screwing around with making Dixie Flatline manage your house lights and climate control, 4 bit is probably fine.&lt;/p&gt;\\n\\n&lt;p&gt;Go lower than 4 bit and the fact that you’ve substantially degraded the model is obvious. I’d run 32b at 4 bit before I’d use a 70b at 2 bit. The 2 bit 70b is going to be an atrocious writer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aoadf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115535,"author_flair_text":null,"treatment_tags":[],"created_utc":1752115535,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":68}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bfr6s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"bull_bear25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a03hh","score":3,"author_fullname":"t2_eabbhyzu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for explaining","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bfr6s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for explaining&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bfr6s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752127593,"author_flair_text":null,"treatment_tags":[],"created_utc":1752127593,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a03hh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":75,"author_fullname":"t2_qhlcbiy3k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Q4 is one of, if not the most popular quant because it's the lowest quant you can run without substantial quality loss.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2a03hh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q4 is one of, if not the most popular quant because it&amp;#39;s the lowest quant you can run without substantial quality loss.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a03hh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107046,"author_flair_text":null,"treatment_tags":[],"created_utc":1752107046,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":75}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2eac1x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2b28ql","score":2,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; It's strange to think how we can represent knowledge as bits\\n\\nI mean, we've done it since the outset of binary computation, heck, even back to the 1600s some thinkers were starting to propose the representation of knowledge using binary numbers","edited":false,"author_flair_css_class":null,"name":"t1_n2eac1x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;It&amp;#39;s strange to think how we can represent knowledge as bits&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I mean, we&amp;#39;ve done it since the outset of binary computation, heck, even back to the 1600s some thinkers were starting to propose the representation of knowledge using binary numbers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2eac1x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752167540,"author_flair_text":null,"collapsed":false,"created_utc":1752167540,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2b28ql","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheRealMasonMac","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a07uq","score":14,"author_fullname":"t2_101haj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Really interesting since it's estimated neurons might store \\\\~4.6 bits per synapse. It's strange to think how we can represent knowledge as bits. [https://www.salk.edu/news-release/memory-capacity-of-brain-is-10-times-more-than-previously-thought/](https://www.salk.edu/news-release/memory-capacity-of-brain-is-10-times-more-than-previously-thought/)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b28ql","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really interesting since it&amp;#39;s estimated neurons might store ~4.6 bits per synapse. It&amp;#39;s strange to think how we can represent knowledge as bits. &lt;a href=\\"https://www.salk.edu/news-release/memory-capacity-of-brain-is-10-times-more-than-previously-thought/\\"&gt;https://www.salk.edu/news-release/memory-capacity-of-brain-is-10-times-more-than-previously-thought/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b28ql/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752121159,"author_flair_text":null,"treatment_tags":[],"created_utc":1752121159,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a07uq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jsonmona","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":36,"author_fullname":"t2_1icp9m5egw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There's a reaearch paper called \\"How much do language models memorize\\" which estimates that LLMs memorize 3.64 bits per parameter. While it doesn't imply LLMs can operate at 4bits per parameter, but should be a good estimate.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2a07uq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a reaearch paper called &amp;quot;How much do language models memorize&amp;quot; which estimates that LLMs memorize 3.64 bits per parameter. While it doesn&amp;#39;t imply LLMs can operate at 4bits per parameter, but should be a good estimate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a07uq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107088,"author_flair_text":null,"treatment_tags":[],"created_utc":1752107088,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2d5d4g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2d13cv","score":2,"author_fullname":"t2_8xi6x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Trial and error is part of it.  \\n\\nDepends on your gpu, the model and its architecture and size, your desired use case, etc.\\n\\nPeople with a single 12GB card are going to probably use local LLMs in a different way than those with 48GB GPUs.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2d5d4g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Trial and error is part of it.  &lt;/p&gt;\\n\\n&lt;p&gt;Depends on your gpu, the model and its architecture and size, your desired use case, etc.&lt;/p&gt;\\n\\n&lt;p&gt;People with a single 12GB card are going to probably use local LLMs in a different way than those with 48GB GPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2d5d4g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752155950,"author_flair_text":null,"treatment_tags":[],"created_utc":1752155950,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2d13cv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LeonidasTMT","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2cy8od","score":2,"author_fullname":"t2_13nvo6","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah so its more trial and error for that. Thank you!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2d13cv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah so its more trial and error for that. Thank you!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2d13cv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154660,"author_flair_text":null,"treatment_tags":[],"created_utc":1752154660,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2cy8od","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2bp3nj","score":2,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Don't know if there is any.  Depends on too many factors.","edited":false,"author_flair_css_class":null,"name":"t1_n2cy8od","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Don&amp;#39;t know if there is any.  Depends on too many factors.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cy8od/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752153738,"author_flair_text":null,"collapsed":false,"created_utc":1752153738,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2bp3nj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LeonidasTMT","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2b21y5","score":2,"author_fullname":"t2_13nvo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for the detailed write up and additional reading sources.\\n\\nWhat is the good rule of thumb for how to \\"leave enough for context\\"?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bp3nj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the detailed write up and additional reading sources.&lt;/p&gt;\\n\\n&lt;p&gt;What is the good rule of thumb for how to &amp;quot;leave enough for context&amp;quot;?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bp3nj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752132634,"author_flair_text":null,"treatment_tags":[],"created_utc":1752132634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2b21y5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Freonr2","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":11,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Q4 is roughly the \\"elbow point\\" below which perplexity rises fairly rapidly from some prior research papers on the subject that I recall reading.  The rise in perplexity may indicate the point where general performance starts to drop off more rapidly.  \\n\\nIt's probably something that should be analyzed continually, though.  I'd consider Q4 as a decent rule of thumb more than anything, and not try to treat it too religiously. It's very possible some models lose more from a given quant, and not all quants are equal just based on bits-per-weight since we now have various quant techniques.  In a perfect world, full benchmark suites (MMLU, SWEBench, etc) would be run for every quant and every model so you could be better informed.\\n\\nIn practice, as a localllama herder, it gets complicated when you want to compare, say, a 40B model you could fit on your GPUs in Q3 but you could load a 20B model in Q6.  Which is better? Well, good question. It's hard to find perfect info.\\n\\nI personally run whatever I can fit into VRAM.  If I have enough VRAM to run Q8 and leave enough for context, I run Q8.  If I can run it in bf16, I'm probably going to just run a different, larger model.\\n\\nedit: dug up some goods from back when here:\\n\\nhttps://github.com/ggml-org/llama.cpp/pull/1684\\n\\nhttps://github.com/ggml-org/llama.cpp/discussions/4110\\n\\nhttps://arxiv.org/pdf/2402.16775v1","edited":1752121656,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2b21y5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q4 is roughly the &amp;quot;elbow point&amp;quot; below which perplexity rises fairly rapidly from some prior research papers on the subject that I recall reading.  The rise in perplexity may indicate the point where general performance starts to drop off more rapidly.  &lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s probably something that should be analyzed continually, though.  I&amp;#39;d consider Q4 as a decent rule of thumb more than anything, and not try to treat it too religiously. It&amp;#39;s very possible some models lose more from a given quant, and not all quants are equal just based on bits-per-weight since we now have various quant techniques.  In a perfect world, full benchmark suites (MMLU, SWEBench, etc) would be run for every quant and every model so you could be better informed.&lt;/p&gt;\\n\\n&lt;p&gt;In practice, as a localllama herder, it gets complicated when you want to compare, say, a 40B model you could fit on your GPUs in Q3 but you could load a 20B model in Q6.  Which is better? Well, good question. It&amp;#39;s hard to find perfect info.&lt;/p&gt;\\n\\n&lt;p&gt;I personally run whatever I can fit into VRAM.  If I have enough VRAM to run Q8 and leave enough for context, I run Q8.  If I can run it in bf16, I&amp;#39;m probably going to just run a different, larger model.&lt;/p&gt;\\n\\n&lt;p&gt;edit: dug up some goods from back when here:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/pull/1684\\"&gt;https://github.com/ggml-org/llama.cpp/pull/1684&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/discussions/4110\\"&gt;https://github.com/ggml-org/llama.cpp/discussions/4110&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/pdf/2402.16775v1\\"&gt;https://arxiv.org/pdf/2402.16775v1&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b21y5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752121076,"author_flair_text":null,"treatment_tags":[],"created_utc":1752121076,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29ztwo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Warguy387","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":2,"author_fullname":"t2_113d6jvz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"they're probably assuming vram required for some given parameter size","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29ztwo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;they&amp;#39;re probably assuming vram required for some given parameter size&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29ztwo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106954,"author_flair_text":null,"treatment_tags":[],"created_utc":1752106954,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2amb25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":1,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When you see the curve showing degradation, Q4 is really close to higher, hier is still better but drops off hard below Q4 normally.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2amb25","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When you see the curve showing degradation, Q4 is really close to higher, hier is still better but drops off hard below Q4 normally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2amb25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752114813,"author_flair_text":null,"treatment_tags":[],"created_utc":1752114813,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cm4op","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29x55a","score":0,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; I'm new to local llama. Is q4 quants generally considered the gold standard between speed as well as knowledge?\\n\\nYes.\\n\\nq3 is substantial degradation and q2 is basically useless. Note that q4_k_m is usually much better than q4_0 too.\\n\\nMoving from q4 to q8 gets you a marginal gain in capability (~1-4% on benchmarks) at the cost of 2x slower inference which isn't worthwhile for most people.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2cm4op","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I&amp;#39;m new to local llama. Is q4 quants generally considered the gold standard between speed as well as knowledge?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Yes.&lt;/p&gt;\\n\\n&lt;p&gt;q3 is substantial degradation and q2 is basically useless. Note that q4_k_m is usually much better than q4_0 too.&lt;/p&gt;\\n\\n&lt;p&gt;Moving from q4 to q8 gets you a marginal gain in capability (~1-4% on benchmarks) at the cost of 2x slower inference which isn&amp;#39;t worthwhile for most people.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cm4op/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752149498,"author_flair_text":null,"treatment_tags":[],"created_utc":1752149498,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n29x55a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LeonidasTMT","can_mod_post":false,"created_utc":1752106024,"send_replies":true,"parent_id":"t1_n29lg4l","score":27,"author_fullname":"t2_13nvo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm new to local llama. Is q4 quants generally considered the gold standard between speed as well as knowledge?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29x55a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m new to local llama. Is q4 quants generally considered the gold standard between speed as well as knowledge?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29x55a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106024,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c99yv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"natandestroyer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2bhduz","score":5,"author_fullname":"t2_h22b5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Also, h100s, plural. So not even close","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2c99yv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Also, h100s, plural. So not even close&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2c99yv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752143965,"author_flair_text":null,"treatment_tags":[],"created_utc":1752143965,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2bhduz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JS31415926","can_mod_post":false,"created_utc":1752128449,"send_replies":true,"parent_id":"t1_n29lg4l","score":1,"author_fullname":"t2_42fwxrkh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Needs seems to imply regardless of quant","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bhduz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Needs seems to imply regardless of quant&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bhduz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752128449,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29v2sq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"The_GSingh","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29pi4y","score":30,"author_fullname":"t2_fy4qc98m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s not how it works…you can quantize any model.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29v2sq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s not how it works…you can quantize any model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29v2sq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105321,"author_flair_text":null,"treatment_tags":[],"created_utc":1752105321,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29zcd9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nihnuhname","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29vb1d","score":4,"author_fullname":"t2_6g9v8k15","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;All models can be quantized\\n\\nAnd distilled","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29zcd9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;All models can be quantized&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;And distilled&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29zcd9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106785,"author_flair_text":null,"treatment_tags":[],"created_utc":1752106785,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2a08nn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"New_Comfortable7240","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29vb1d","score":2,"author_fullname":"t2_8k6ihe63","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey thanks for clarify it! Any online resource to learn more on this? Thanks in advance!\\n\\n\\nUpdate: Perplexity returned this supporting the idea: https://www.perplexity.ai/search/i-see-a-claim-in-internet-abou-B2sTGRcQSfK1pH8CPWuHQw#0","edited":1752107551,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a08nn","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey thanks for clarify it! Any online resource to learn more on this? Thanks in advance!&lt;/p&gt;\\n\\n&lt;p&gt;Update: Perplexity returned this supporting the idea: &lt;a href=\\"https://www.perplexity.ai/search/i-see-a-claim-in-internet-abou-B2sTGRcQSfK1pH8CPWuHQw#0\\"&gt;https://www.perplexity.ai/search/i-see-a-claim-in-internet-abou-B2sTGRcQSfK1pH8CPWuHQw#0&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a08nn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107096,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1752107096,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n29vb1d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29pi4y","score":13,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All models can be quantized, it's just a question of implementing it. Even if OpenAI does not provide any official quants (though I suspect they will) it's still entirely possible for llama.cpp to add support for the model. And given how high profile this release is it would be shocking if support was not added.","edited":1752106473,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29vb1d","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All models can be quantized, it&amp;#39;s just a question of implementing it. Even if OpenAI does not provide any official quants (though I suspect they will) it&amp;#39;s still entirely possible for llama.cpp to add support for the model. And given how high profile this release is it would be shocking if support was not added.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29vb1d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105398,"author_flair_text":null,"treatment_tags":[],"created_utc":1752105398,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"n29pi4y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"New_Comfortable7240","can_mod_post":false,"created_utc":1752103498,"send_replies":true,"parent_id":"t1_n29lg4l","score":-27,"author_fullname":"t2_8k6ihe63","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Assuming it have quant support...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29pi4y","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Assuming it have quant support...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29pi4y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103498,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-27}}],"before":null}},"user_reports":[],"saved":false,"id":"n29lg4l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Admirable-Star7088","can_mod_post":false,"created_utc":1752102185,"send_replies":true,"parent_id":"t3_1lvwya4","score":245,"author_fullname":"t2_qhlcbiy3k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Does he mean in full precision? Even a \\\\~14b model in full precision would require a H100 GPU to run.\\n\\nThe meaningful and interesting question is, what hardware does this model require at Q4 quant?","edited":1752102520,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29lg4l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does he mean in full precision? Even a ~14b model in full precision would require a H100 GPU to run.&lt;/p&gt;\\n\\n&lt;p&gt;The meaningful and interesting question is, what hardware does this model require at Q4 quant?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29lg4l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102185,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":245}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2belho","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redoubt515","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29xpvb","score":11,"author_fullname":"t2_kehp8nb59","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Companies often prefer (pretend) \\"\\"leaks\\"\\" to come from outside the company. (Adds to the hype, gets people engaged, gives people the idea they are privvy to some 'forbidden knowledge' which grabs attention better than a press release from the company, it's PR.). I don't know if this is a case of a fake leak like that, but if it is, OpenAI certainly wouldn't be the first company to engage in this.","edited":false,"author_flair_css_class":null,"name":"t1_n2belho","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Companies often prefer (pretend) &amp;quot;&amp;quot;leaks&amp;quot;&amp;quot; to come from outside the company. (Adds to the hype, gets people engaged, gives people the idea they are privvy to some &amp;#39;forbidden knowledge&amp;#39; which grabs attention better than a press release from the company, it&amp;#39;s PR.). I don&amp;#39;t know if this is a case of a fake leak like that, but if it is, OpenAI certainly wouldn&amp;#39;t be the first company to engage in this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2belho/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752127002,"author_flair_text":null,"collapsed":false,"created_utc":1752127002,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ausxw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Friendly_Willingness","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29xpvb","score":7,"author_fullname":"t2_4763uud5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"this random dude runs a cloud LLM provider, he might have the model already","edited":false,"author_flair_css_class":null,"name":"t1_n2ausxw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this random dude runs a cloud LLM provider, he might have the model already&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ausxw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752118081,"author_flair_text":null,"collapsed":false,"created_utc":1752118081,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bhoxk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29xpvb","score":1,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OpenAI seems to have sent the model (or at least its specs) to hosting companies already, all the rumors are coming from such sources.","edited":false,"author_flair_css_class":null,"name":"t1_n2bhoxk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenAI seems to have sent the model (or at least its specs) to hosting companies already, all the rumors are coming from such sources.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bhoxk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752128612,"author_flair_text":null,"collapsed":false,"created_utc":1752128612,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29xpvb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_BreakingGood_","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29sg3q","score":26,"author_fullname":"t2_ah9bj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, also why would this random dude have information and be authorized to release it before anybody from OpenAI... lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29xpvb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, also why would this random dude have information and be authorized to release it before anybody from OpenAI... lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29xpvb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106224,"author_flair_text":null,"treatment_tags":[],"created_utc":1752106224,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":26}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29th6j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"loyalekoinu88","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29sg3q","score":8,"author_fullname":"t2_1x5p0ubz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don’t think he has either. Other posts say “I hear” meaning he’s hedging his bets based on good sources.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29th6j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t think he has either. Other posts say “I hear” meaning he’s hedging his bets based on good sources.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29th6j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104790,"author_flair_text":null,"treatment_tags":[],"created_utc":1752104790,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2che5k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mpasila","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29sg3q","score":3,"author_fullname":"t2_lhhagpdw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"API access? I thought his company HOSTED these models? (he said \\"We're **hosting** it on Hyperbolic.\\") Aka they are an API unlike OpenRouter.. which just takes APIs and resells them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2che5k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;API access? I thought his company HOSTED these models? (he said &amp;quot;We&amp;#39;re &lt;strong&gt;hosting&lt;/strong&gt; it on Hyperbolic.&amp;quot;) Aka they are an API unlike OpenRouter.. which just takes APIs and resells them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2che5k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752147622,"author_flair_text":null,"treatment_tags":[],"created_utc":1752147622,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n29sg3q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Klutzy-Snow8016","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29peax","score":53,"author_fullname":"t2_1d5l610jz3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"His full tweet is:\\n\\n\\"\\"\\"\\n\\nit's better than DeepSeek R1 for sure\\n\\nthere is no point to open source a worse model\\n\\n\\"\\"\\"\\n\\nIt reads, to me, like he is saying that it's better than Deepseek R1 because he thinks it wouldn't make sense to release a weaker model, not that he has seen the model and knows its performance. If he's selling API access, OpenAI could have just given him inference code but not the weights.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29sg3q","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;His full tweet is:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;it&amp;#39;s better than DeepSeek R1 for sure&lt;/p&gt;\\n\\n&lt;p&gt;there is no point to open source a worse model&lt;/p&gt;\\n\\n&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;It reads, to me, like he is saying that it&amp;#39;s better than Deepseek R1 because he thinks it wouldn&amp;#39;t make sense to release a weaker model, not that he has seen the model and knows its performance. If he&amp;#39;s selling API access, OpenAI could have just given him inference code but not the weights.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29sg3q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104452,"author_flair_text":null,"treatment_tags":[],"created_utc":1752104452,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}}],"before":null}},"user_reports":[],"saved":false,"id":"n29peax","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rnosov","can_mod_post":false,"created_utc":1752103464,"send_replies":true,"parent_id":"t1_n29kgyo","score":28,"author_fullname":"t2_18x6fa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In other [tweet](https://x.com/Yuchenj_UW/status/1943010047568842953) he claims it's better than Deepseek R1. Rumours about o3-mini level are not from this guy. His company is selling API access/hosting for open source models so he should know what he is talking about.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29peax","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In other &lt;a href=\\"https://x.com/Yuchenj_UW/status/1943010047568842953\\"&gt;tweet&lt;/a&gt; he claims it&amp;#39;s better than Deepseek R1. Rumours about o3-mini level are not from this guy. His company is selling API access/hosting for open source models so he should know what he is talking about.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29peax/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103464,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ap6gg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mxforest","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a8xbd","score":22,"author_fullname":"t2_kenmq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wait.. a smaller model is worse than their SOTA?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ap6gg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait.. a smaller model is worse than their SOTA?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ap6gg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115865,"author_flair_text":null,"treatment_tags":[],"created_utc":1752115865,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a8xbd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Corporate_Drone31","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1650","score":3,"author_fullname":"t2_32o8hu91","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Compared to the full o3? I'd say it is.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2a8xbd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Compared to the full o3? I&amp;#39;d say it is.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a8xbd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752110104,"author_flair_text":null,"treatment_tags":[],"created_utc":1752110104,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2d0fwb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MerePotato","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2asu7p","score":2,"author_fullname":"t2_14t2wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It will however be a lot less dry and censored","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2d0fwb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It will however be a lot less dry and censored&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2d0fwb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154451,"author_flair_text":null,"treatment_tags":[],"created_utc":1752154451,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2eawcd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2asu7p","score":1,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"[Mistral Small level, not even Qwen3_235B](https://imgur.com/a/rfjf76V)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2eawcd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://imgur.com/a/rfjf76V\\"&gt;Mistral Small level, not even Qwen3_235B&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2eawcd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752167690,"author_flair_text":null,"treatment_tags":[],"created_utc":1752167690,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2asu7p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nomorebuttsplz","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1650","score":2,"author_fullname":"t2_syq52","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it's about qwen 235 level. Not garbage but if it was huge, a regression.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2asu7p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it&amp;#39;s about qwen 235 level. Not garbage but if it was huge, a regression.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2asu7p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752117288,"author_flair_text":null,"treatment_tags":[],"created_utc":1752117288,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a1650","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1752107419,"send_replies":true,"parent_id":"t1_n29kgyo","score":20,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"o3-mini is not garbage.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a1650","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;o3-mini is not garbage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a1650/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107419,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}}],"before":null}},"user_reports":[],"saved":false,"id":"n29kgyo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No-Source-9920","can_mod_post":false,"created_utc":1752101865,"send_replies":true,"parent_id":"t3_1lvwya4","score":99,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It’s not a small model and it benchmarks like o3-mini? So it’s garbage?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29kgyo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It’s not a small model and it benchmarks like o3-mini? So it’s garbage?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29kgyo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101865,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":99}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aqqr2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Alkeryn","can_mod_post":false,"created_utc":1752116465,"send_replies":true,"parent_id":"t3_1lvwya4","score":15,"author_fullname":"t2_xbcpo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I won't care until weights are dropped lol.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aqqr2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I won&amp;#39;t care until weights are dropped lol.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aqqr2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116465,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ahrgh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"busylivin_322","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29y1ct","score":4,"author_fullname":"t2_7dke2mrk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Absolutely (love how Llama.cpp/Ollama are Day 1 ready). \\n\\nBut I would assume they’re NDA’d the week prior.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ahrgh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Absolutely (love how Llama.cpp/Ollama are Day 1 ready). &lt;/p&gt;\\n\\n&lt;p&gt;But I would assume they’re NDA’d the week prior.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ahrgh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752113194,"author_flair_text":null,"treatment_tags":[],"created_utc":1752113194,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n29y1ct","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mikael110","can_mod_post":false,"created_utc":1752106333,"send_replies":true,"parent_id":"t1_n29vuxc","score":12,"author_fullname":"t2_4amlo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm also a bit skeptical, but to be fair it is quite common for companies to seed their models out to inference companies a week or so ahead of launch. So that they can be ready with a well configured deployment the moment the announcement goes live.\\n\\nWe've gotten early Llama info leaks and similar in the past through the same process.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29y1ct","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m also a bit skeptical, but to be fair it is quite common for companies to seed their models out to inference companies a week or so ahead of launch. So that they can be ready with a well configured deployment the moment the announcement goes live.&lt;/p&gt;\\n\\n&lt;p&gt;We&amp;#39;ve gotten early Llama info leaks and similar in the past through the same process.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29y1ct/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752106333,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}}],"before":null}},"user_reports":[],"saved":false,"id":"n29vuxc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"busylivin_322","can_mod_post":false,"created_utc":1752105584,"send_replies":true,"parent_id":"t3_1lvwya4","score":61,"author_fullname":"t2_7dke2mrk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Screenshots of tweets as sources /sigh. Anyone know who he is and why he would know this?\\n\\nFrom the comments, hosting a small scale cloud early stage startup is not a reason for him to know OAI internals. Except to advertise unverified info that is beneficial for such a service.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29vuxc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Screenshots of tweets as sources /sigh. Anyone know who he is and why he would know this?&lt;/p&gt;\\n\\n&lt;p&gt;From the comments, hosting a small scale cloud early stage startup is not a reason for him to know OAI internals. Except to advertise unverified info that is beneficial for such a service.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29vuxc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752105584,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":61}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2d1d25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FuguSandwich","can_mod_post":false,"created_utc":1752154744,"send_replies":true,"parent_id":"t1_n29so8v","score":2,"author_fullname":"t2_r3xju","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm excited for its release but I'm not naive regarding their motive.  There's nothing altruistic about it.  Companies like Meta and Google released open weight models specifically to erode any moat OpenAI and Anthropic had.  OpenAI is now going to do the same to them.  It'll be better than Llama and Gemma but worse than their cheapest current closed model.  The message will be \\"if you want the best pay us, if you want the next best use our free open model, no need to use anything else ever\\".","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2d1d25","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m excited for its release but I&amp;#39;m not naive regarding their motive.  There&amp;#39;s nothing altruistic about it.  Companies like Meta and Google released open weight models specifically to erode any moat OpenAI and Anthropic had.  OpenAI is now going to do the same to them.  It&amp;#39;ll be better than Llama and Gemma but worse than their cheapest current closed model.  The message will be &amp;quot;if you want the best pay us, if you want the next best use our free open model, no need to use anything else ever&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2d1d25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154744,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2an5bi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1752115116,"send_replies":true,"parent_id":"t1_n29so8v","score":2,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Static layers should fit in 48gb GPU and experts should be tiny 2B with ideally only needing 2 or 3 experts. Make a 16 and 128 expert version like META and they'll have a highly capable and widely usable model. Anything bigger and it's just a dick waving contest and as unusable as deepseek or grok.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2an5bi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Static layers should fit in 48gb GPU and experts should be tiny 2B with ideally only needing 2 or 3 experts. Make a 16 and 128 expert version like META and they&amp;#39;ll have a highly capable and widely usable model. Anything bigger and it&amp;#39;s just a dick waving contest and as unusable as deepseek or grok.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2an5bi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115116,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aen9t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PmMeForPCBuilds","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a0zf2","score":3,"author_fullname":"t2_lkljr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What are you talking about? They said June then they delayed to July. Probably coming out in a week, we’ll see then","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2aen9t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are you talking about? They said June then they delayed to July. Probably coming out in a week, we’ll see then&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aen9t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112103,"author_flair_text":null,"treatment_tags":[],"created_utc":1752112103,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aq0hi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mxforest","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a0zf2","score":3,"author_fullname":"t2_kenmq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The delay could be a blessing in disguise. If it had released when they first announced, it would have competed with far worse models. Now it has to compete with a high bar set by Qwen 3 series.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2aq0hi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The delay could be a blessing in disguise. If it had released when they first announced, it would have competed with far worse models. Now it has to compete with a high bar set by Qwen 3 series.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aq0hi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116182,"author_flair_text":null,"treatment_tags":[],"created_utc":1752116182,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2edzzy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2eb31c","score":1,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And my bow","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2edzzy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And my bow&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2edzzy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752168519,"author_flair_text":null,"treatment_tags":[],"created_utc":1752168519,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2eb31c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1rh3","score":1,"author_fullname":"t2_ql2vu0wz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"and my axe!","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2eb31c","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;and my axe!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2eb31c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752167740,"author_flair_text":null,"treatment_tags":[],"created_utc":1752167740,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ancex","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1svk","score":3,"author_fullname":"t2_1b7gjxtue9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lol, they release a fine tune of llama 4 Maverick. I'd actually personally love it if it was good.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n2ancex","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol, they release a fine tune of llama 4 Maverick. I&amp;#39;d actually personally love it if it was good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ancex/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752115187,"author_flair_text":null,"treatment_tags":[],"created_utc":1752115187,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a1svk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1rh3","score":1,"author_fullname":"t2_dissgzyl","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’ll probably still be on llama 3.3","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n2a1svk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ll probably still be on llama 3.3&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a1svk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107640,"author_flair_text":null,"treatment_tags":[],"created_utc":1752107640,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a1rh3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1qdm","score":3,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And the requirements","edited":false,"author_flair_css_class":null,"name":"t1_n2a1rh3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And the requirements&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a1rh3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107627,"author_flair_text":null,"collapsed":false,"created_utc":1752107627,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a1qdm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a1pjl","score":5,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And the performance","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a1qdm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And the performance&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a1qdm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107616,"author_flair_text":null,"treatment_tags":[],"created_utc":1752107616,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a1pjl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"silenceimpaired","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2a0zf2","score":4,"author_fullname":"t2_dissgzyl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wait until we see the license.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2a1pjl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wait until we see the license.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a1pjl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107608,"author_flair_text":null,"treatment_tags":[],"created_utc":1752107608,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a0zf2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Refrigerator-1672","can_mod_post":false,"created_utc":1752107356,"send_replies":true,"parent_id":"t1_n29so8v","score":0,"author_fullname":"t2_baavelp5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;I’m rooting for them.\\n\\nI'm not. I do welcome new open weights models, but announcing that you'll release something, and then saying \\"it just needs a bit of polish\\" while dragging the thing for months is never a good sign. The probability that this mystery model will be never released or will turn out to be a flop is too high.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a0zf2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I’m rooting for them.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I&amp;#39;m not. I do welcome new open weights models, but announcing that you&amp;#39;ll release something, and then saying &amp;quot;it just needs a bit of polish&amp;quot; while dragging the thing for months is never a good sign. The probability that this mystery model will be never released or will turn out to be a flop is too high.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a0zf2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107356,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n29so8v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AlwaysInconsistant","can_mod_post":false,"created_utc":1752104526,"send_replies":true,"parent_id":"t3_1lvwya4","score":30,"author_fullname":"t2_65e1spw7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m rooting for them. It’s their first open endeavor they’ve undertaken in a while - at the very least I’m curious to see what they’ve cooked for us. Either it’s great or it ain’t - life will go on - but I’m hoping they’re hearing what the community of enthusiasts are chanting for and if this one goes well they do take a stab at another open endeavor sooner next time. \\n\\nIf you look around you’ll see making everyone happy is going to be flat impossible - everyone has their own dream scenario that’s valid for them - and few see it as realistic or in alignment with their assumptions on OpenAI’s profitability strategy.\\n\\nMy own dream scenario is for something pretty close to o4-mini level and can run at q4+ on a MBP w/ 128gb or RTX PRO 6000 w/ 96gb.\\n\\nIf it hits there quantized I know it will run even better on runpod or through openrouter at decent prices when you need speed.\\n\\nBut we’ll see. Only time and testing will tell in the end. I’m not counting them out yet. Wished they’d either shut up or spill. Fingers crossed on next week, but not holding my breath on anything till it comes out and we see it for what it is and under which license.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29so8v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m rooting for them. It’s their first open endeavor they’ve undertaken in a while - at the very least I’m curious to see what they’ve cooked for us. Either it’s great or it ain’t - life will go on - but I’m hoping they’re hearing what the community of enthusiasts are chanting for and if this one goes well they do take a stab at another open endeavor sooner next time. &lt;/p&gt;\\n\\n&lt;p&gt;If you look around you’ll see making everyone happy is going to be flat impossible - everyone has their own dream scenario that’s valid for them - and few see it as realistic or in alignment with their assumptions on OpenAI’s profitability strategy.&lt;/p&gt;\\n\\n&lt;p&gt;My own dream scenario is for something pretty close to o4-mini level and can run at q4+ on a MBP w/ 128gb or RTX PRO 6000 w/ 96gb.&lt;/p&gt;\\n\\n&lt;p&gt;If it hits there quantized I know it will run even better on runpod or through openrouter at decent prices when you need speed.&lt;/p&gt;\\n\\n&lt;p&gt;But we’ll see. Only time and testing will tell in the end. I’m not counting them out yet. Wished they’d either shut up or spill. Fingers crossed on next week, but not holding my breath on anything till it comes out and we see it for what it is and under which license.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29so8v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bo58o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Striking-Warning9533","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ad6r6","score":1,"author_fullname":"t2_70mnmect","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would argue it’s better if the new architecture bring significant advantages, like speed or performance. It will push the area forward not only in LLMs but also in CV or image generation models. It worth the wait if this is the case","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2bo58o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would argue it’s better if the new architecture bring significant advantages, like speed or performance. It will push the area forward not only in LLMs but also in CV or image generation models. It worth the wait if this is the case&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bo58o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752132107,"author_flair_text":null,"treatment_tags":[],"created_utc":1752132107,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ad6r6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Conversation9561","can_mod_post":false,"created_utc":1752111594,"send_replies":true,"parent_id":"t1_n2a8am4","score":2,"author_fullname":"t2_jqxb4pte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"interesting architecture… hope it doesn’t take forever to support in llama.cpp","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ad6r6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;interesting architecture… hope it doesn’t take forever to support in llama.cpp&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ad6r6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111594,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aayqt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"celsowm","can_mod_post":false,"created_utc":1752110814,"send_replies":true,"parent_id":"t1_n2a8am4","score":1,"author_fullname":"t2_dyvrh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Me too","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aayqt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Me too&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aayqt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752110814,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bid8t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752128974,"send_replies":true,"parent_id":"t1_n2a8am4","score":0,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would not be surprised if it is nothing new. Whatever OpenAI is using currently had to have been leaked (through hosting companies and former workers) and other companies had to have tried training very similar models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bid8t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would not be surprised if it is nothing new. Whatever OpenAI is using currently had to have been leaked (through hosting companies and former workers) and other companies had to have tried training very similar models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bid8t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752128974,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a8am4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Accomplished_Ad9530","can_mod_post":false,"created_utc":1752109887,"send_replies":true,"parent_id":"t3_1lvwya4","score":15,"author_fullname":"t2_88fma001","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Am I the only one more excited about potential architectural advancements than the actual model? Don't get me wrong, the weights are essential, but I'm hoping for an interesting architecture.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a8am4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Am I the only one more excited about potential architectural advancements than the actual model? Don&amp;#39;t get me wrong, the weights are essential, but I&amp;#39;m hoping for an interesting architecture.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a8am4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752109887,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bhyzq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752128762,"send_replies":true,"parent_id":"t1_n29nqk4","score":4,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"OpenAI is only doing MoE now IMHO.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bhyzq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;OpenAI is only doing MoE now IMHO.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bhyzq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752128762,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2agw0u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thrownawaymane","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29sg8s","score":1,"author_fullname":"t2_14v1py","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The R is silent","edited":false,"author_flair_css_class":null,"name":"t1_n2agw0u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The R is silent&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2agw0u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752112890,"author_flair_text":null,"collapsed":false,"created_utc":1752112890,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29sg8s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"oxygen_addiction","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29q4hu","score":22,"author_fullname":"t2_66k6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"R1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29sg8s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29sg8s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104453,"author_flair_text":null,"treatment_tags":[],"created_utc":1752104453,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cuhtk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aldarund","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2ctlbt","score":1,"author_fullname":"t2_bu5xy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its a bit worse than.last r1","edited":false,"author_flair_css_class":null,"name":"t1_n2cuhtk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its a bit worse than.last r1&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lvwya4","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cuhtk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752152501,"author_flair_text":null,"collapsed":false,"created_utc":1752152501,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ctlbt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Popular_Brief335","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29q4hu","score":1,"author_fullname":"t2_1j9oxxzd6c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"MiniMax-M1-80k","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ctlbt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;MiniMax-M1-80k&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ctlbt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752152196,"author_flair_text":null,"treatment_tags":[],"created_utc":1752152196,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29q4hu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Aldarund","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29p28t","score":15,"author_fullname":"t2_bu5xy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Who is?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29q4hu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Who is?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29q4hu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103698,"author_flair_text":null,"treatment_tags":[],"created_utc":1752103698,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}}],"before":null}},"user_reports":[],"saved":false,"id":"n29p28t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Popular_Brief335","can_mod_post":false,"created_utc":1752103354,"send_replies":true,"parent_id":"t1_n29nqk4","score":-16,"author_fullname":"t2_1j9oxxzd6c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1 is not the leader ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29p28t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 is not the leader &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29p28t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103354,"author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-16}}],"before":null}},"user_reports":[],"saved":false,"id":"n29nqk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"panchovix","can_mod_post":false,"created_utc":1752102929,"send_replies":true,"parent_id":"t3_1lvwya4","score":18,"author_fullname":"t2_j1kqr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it's a \\\\~680B MoE I can run it at 4bit with offloading.\\n\\nIf it's a \\\\~680B dense model I'm fucked lol.\\n\\nStill they for sure did a \\"big\\" claim that is the better reasoning open model, so that means better than R1 0528. We will have to see how much true is that (I don't think it's true at all lol)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29nqk4","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s a ~680B MoE I can run it at 4bit with offloading.&lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s a ~680B dense model I&amp;#39;m fucked lol.&lt;/p&gt;\\n\\n&lt;p&gt;Still they for sure did a &amp;quot;big&amp;quot; claim that is the better reasoning open model, so that means better than R1 0528. We will have to see how much true is that (I don&amp;#39;t think it&amp;#39;s true at all lol)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29nqk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102929,"author_flair_text":"Llama 405B","treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ebikx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"created_utc":1752167856,"send_replies":true,"parent_id":"t1_n2ams89","score":1,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; so it could be inferior to DS or even Qwen-235B\\n\\nif it's on the o3-mini level as people say, [*it's gonna be worse than Qwen_235B*](https://imgur.com/a/rfjf76V)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ebikx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;so it could be inferior to DS or even Qwen-235B&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;if it&amp;#39;s on the o3-mini level as people say, &lt;a href=\\"https://imgur.com/a/rfjf76V\\"&gt;&lt;em&gt;it&amp;#39;s gonna be worse than Qwen_235B&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ebikx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752167856,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2ams89","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1752114984,"send_replies":true,"parent_id":"t3_1lvwya4","score":9,"author_fullname":"t2_g177e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My bet is something that rivals Deepseek, but at the 200-300 GB size. They cannot go over Deepseek because it undercuts their products, and cannot go too much under it because nobody would use it. However I believe the only reason they are releasing it is to comply with Elon's lawsuit, so it could be inferior to DS or even Qwen-235B.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ams89","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My bet is something that rivals Deepseek, but at the 200-300 GB size. They cannot go over Deepseek because it undercuts their products, and cannot go too much under it because nobody would use it. However I believe the only reason they are releasing it is to comply with Elon&amp;#39;s lawsuit, so it could be inferior to DS or even Qwen-235B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ams89/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752114984,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bn7h1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Roubbes","can_mod_post":false,"created_utc":1752131593,"send_replies":true,"parent_id":"t3_1lvwya4","score":4,"author_fullname":"t2_aoir7erh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"He says H100s so I guess it'll be at least a 100B model","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bn7h1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;He says H100s so I guess it&amp;#39;ll be at least a 100B model&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bn7h1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752131593,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29pc53","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hainesk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n29ot89","score":10,"author_fullname":"t2_5rprd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My Casio watch can code!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n29pc53","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My Casio watch can code!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29pc53/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103445,"author_flair_text":null,"treatment_tags":[],"created_utc":1752103445,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n29ot89","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ShinyAnkleBalls","can_mod_post":false,"created_utc":1752103274,"send_replies":true,"parent_id":"t1_n29ktd4","score":18,"author_fullname":"t2_2m3au2xb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unsloth comes in. Make a 0.5 bit dynamic I quant or some black magic thingy. Runs on a toaster.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29ot89","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unsloth comes in. Make a 0.5 bit dynamic I quant or some black magic thingy. Runs on a toaster.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29ot89/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752103274,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"n29ktd4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nazihater3000","can_mod_post":false,"created_utc":1752101977,"send_replies":true,"parent_id":"t3_1lvwya4","score":21,"author_fullname":"t2_j3brbc6qz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"They all start as giant models, in 3 days they are running on an Arduino.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29ktd4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They all start as giant models, in 3 days they are running on an Arduino.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29ktd4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101977,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2aq5yn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1752116242,"send_replies":true,"parent_id":"t1_n2a41pg","score":8,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sign me up","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2aq5yn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sign me up&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2aq5yn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752116242,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2b3mkp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Freonr2","can_mod_post":false,"created_utc":1752121765,"send_replies":true,"parent_id":"t1_n2a41pg","score":3,"author_fullname":"t2_8xi6x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://tenor.com/view/addams-family-fool-gif-8806926","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b3mkp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://tenor.com/view/addams-family-fool-gif-8806926\\"&gt;https://tenor.com/view/addams-family-fool-gif-8806926&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b3mkp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752121765,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2fb84l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thick-Protection-458","can_mod_post":false,"created_utc":1752177908,"send_replies":true,"parent_id":"t1_n2a41pg","score":1,"author_fullname":"t2_abr7phdd","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Now thinking about that gives me a good cyberpunk vibes, lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2fb84l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Now thinking about that gives me a good cyberpunk vibes, lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2fb84l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752177908,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2a41pg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"101m4n","can_mod_post":false,"created_utc":1752108424,"send_replies":true,"parent_id":"t3_1lvwya4","score":14,"author_fullname":"t2_p7nc2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Needs to run on h100s\\"\\n\\nBet\\n\\nSome jackass on here will have it running on a shitty xeon and some 3090s stuffed in a cardboard box before the week is out. \\n\\nGodspeed 🫡","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a41pg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Needs to run on h100s&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Bet&lt;/p&gt;\\n\\n&lt;p&gt;Some jackass on here will have it running on a shitty xeon and some 3090s stuffed in a cardboard box before the week is out. &lt;/p&gt;\\n\\n&lt;p&gt;Godspeed 🫡&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a41pg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752108424,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2a4bg0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NeonRitual","can_mod_post":false,"created_utc":1752108516,"send_replies":true,"parent_id":"t3_1lvwya4","score":4,"author_fullname":"t2_mvtna","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just release it already 🥱🥱","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a4bg0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just release it already 🥱🥱&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a4bg0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752108516,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2c6ng7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Commercial-Celery769","can_mod_post":false,"created_utc":1752142623,"send_replies":true,"parent_id":"t3_1lvwya4","score":2,"author_fullname":"t2_zws5yqyow","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fingers crossed its good and not just benchmaxxed","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2c6ng7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fingers crossed its good and not just benchmaxxed&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2c6ng7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752142623,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2elij2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Conscious_Cut_6144","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2beujn","score":2,"author_fullname":"t2_9hl4ymvj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Single system, they only have 4x pcie lanes each","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2elij2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Single system, they only have 4x pcie lanes each&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2elij2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752170538,"author_flair_text":null,"treatment_tags":[],"created_utc":1752170538,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2beujn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ortegaalfredo","can_mod_post":false,"created_utc":1752127131,"send_replies":true,"parent_id":"t1_n29svap","score":1,"author_fullname":"t2_g177e","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you have a single system or mutiple nodes?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2beujn","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you have a single system or mutiple nodes?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2beujn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752127131,"author_flair_text":"Alpaca","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n29svap","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious_Cut_6144","can_mod_post":false,"created_utc":1752104590,"send_replies":true,"parent_id":"t3_1lvwya4","score":5,"author_fullname":"t2_9hl4ymvj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My 16 3090's beg to differ :D  \\nSounds like they might actually mean they are going to beat R1","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29svap","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My 16 3090&amp;#39;s beg to differ :D&lt;br/&gt;\\nSounds like they might actually mean they are going to beat R1&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29svap/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752104590,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2amhmm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NNN_Throwaway2","can_mod_post":false,"created_utc":1752114878,"send_replies":true,"parent_id":"t3_1lvwya4","score":7,"author_fullname":"t2_8rrihts9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Its not gonna run on anything until they release it 🙄","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2amhmm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its not gonna run on anything until they release it 🙄&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2amhmm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752114878,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2b93rv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FateOfMuffins","can_mod_post":false,"created_utc":1752124261,"send_replies":true,"parent_id":"t3_1lvwya4","score":2,"author_fullname":"t2_yjyze","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Honestly that doesn't make sense, because 4o is estimated to be about 200B parameters (and given the price, speed and \\"vibes\\" when using 4.1, it feels even smaller), and o3 runs off that. \\n\\nMultiple H100s would literally be able to run o3, and I doubt they'd retrain a new 200B parameter model from scratch just to release open.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b93rv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Honestly that doesn&amp;#39;t make sense, because 4o is estimated to be about 200B parameters (and given the price, speed and &amp;quot;vibes&amp;quot; when using 4.1, it feels even smaller), and o3 runs off that. &lt;/p&gt;\\n\\n&lt;p&gt;Multiple H100s would literally be able to run o3, and I doubt they&amp;#39;d retrain a new 200B parameter model from scratch just to release open.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b93rv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752124261,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2b5n5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Limp_Classroom_2645","can_mod_post":false,"created_utc":1752122659,"send_replies":true,"parent_id":"t3_1lvwya4","score":3,"author_fullname":"t2_1lwf5vg68e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Stop posting this horseshit!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2b5n5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Stop posting this horseshit!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2b5n5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752122659,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ad8gb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Conversation9561","can_mod_post":false,"created_utc":1752111610,"send_replies":true,"parent_id":"t1_n29k5zx","score":4,"author_fullname":"t2_jqxb4pte","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I hope so","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ad8gb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope so&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lvwya4","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2ad8gb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752111610,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n29k5zx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thick-Protection-458","can_mod_post":false,"created_utc":1752101767,"send_replies":true,"parent_id":"t3_1lvwya4","score":1,"author_fullname":"t2_abr7phdd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"200-600b?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29k5zx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;200-600b?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29k5zx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752101767,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2bh60m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ajmusic15","can_mod_post":false,"created_utc":1752128334,"send_replies":true,"parent_id":"t3_1lvwya4","score":1,"author_fullname":"t2_62puzq0k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"🗿","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2bh60m","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;🗿&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2bh60m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752128334,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2biubz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bullerwins","can_mod_post":false,"created_utc":1752129231,"send_replies":true,"parent_id":"t3_1lvwya4","score":0,"author_fullname":"t2_d3wk5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Unless is bigger than 700B if it’s a moe we are good I think. 700b dense is another story. \\n200b dense would be the biggest it could make sense I think","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2biubz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unless is bigger than 700B if it’s a moe we are good I think. 700b dense is another story. \\n200b dense would be the biggest it could make sense I think&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2biubz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752129231,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2cr33x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1752151324,"send_replies":true,"parent_id":"t3_1lvwya4","score":1,"author_fullname":"t2_79slapln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"so either openai are idiots or this Jin guy is flexing his H100s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2cr33x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so either openai are idiots or this Jin guy is flexing his H100s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2cr33x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752151324,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2czzep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BidWestern1056","can_mod_post":false,"created_utc":1752154305,"send_replies":true,"parent_id":"t3_1lvwya4","score":1,"author_fullname":"t2_uzxql7po","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"stupid !","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2czzep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;stupid !&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2czzep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752154305,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2a2lh7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TPLINKSHIT","can_mod_post":false,"created_utc":1752107918,"send_replies":true,"parent_id":"t3_1lvwya4","score":0,"author_fullname":"t2_pzphni3bh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"there is s... so maybe 200 H100s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2a2lh7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;there is s... so maybe 200 H100s&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n2a2lh7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752107918,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n29lalp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pro-editor-1105","can_mod_post":false,"created_utc":1752102134,"send_replies":true,"parent_id":"t3_1lvwya4","score":-3,"author_fullname":"t2_uptissiz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And this is exactly what we expected","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n29lalp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And this is exactly what we expected&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lvwya4/possible_size_of_new_the_open_model_from_openai/n29lalp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752102134,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lvwya4","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
