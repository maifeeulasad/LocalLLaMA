const e=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"# Dir-Assistant: Chat with your current directory's files using a local or API LLM\\n\\nHello All! I am happy to announce Dir-Assistant v1.7.0 and the passing of its one year anniversary. If you haven't tried Dir-Assistant, now is a great time to. In my personal testing, Dir-Assistant is the best LLM UI for working on large code repositories, outperforming all commercial and open source options I've tested due to sophisticated and unique methodology it utilizes. A big difference compared to other LLM UIs is you don't need to @ files and directories for each prompt. Dir-assistant automatically includes the most relevant parts of any file in the entire repository every time.\\n\\n# New: Context Prefix Caching\\n\\n**1.7.0's big new feature is \\"Context Prefix Caching\\"**, which optimizes the context sent to your LLM by remembering which combinations of file chunks were previously sent, and attempting to maximize the number of tokens at the beginning of a prompt which match a previously sent prompt. The bottom line is that this can, and in my testing regularly does, completely eliminate prompt processing if your LLM supports prefix caching. Additionally, some APIs automatically support this feature and reduce cost for matching tokens. For instance, Google offers a 75% discount on all its Gemini 2.5 models for prefix cache hits like this (this feature is enabled by default for Gemini).\\n\\nThis feature massively improves performance when working with a local LLM on large codebases. In my local testing running an LMStudio server with Gemma 3n e4b and 100k token context, this feature dropped overall dir-assistant CGRAG-enabled response time from 3:40 to 0:16 on my 7900 XTX. That includes prompt processing and token generation.\\n\\nGet started by installing with pip:\\n\\n    pip install dir-assistant\\n\\nFull usage documentation available on GitHub:\\n\\n[https://github.com/curvedinf/dir-assistant](https://github.com/curvedinf/dir-assistant)\\n\\nMore information about Dir-Assistant's context prefix caching implementation:\\n\\n[https://github.com/curvedinf/dir-assistant?tab=readme-ov-file#RAG-Caching-and-Context-Optimization](https://github.com/curvedinf/dir-assistant?tab=readme-ov-file#RAG-Caching-and-Context-Optimization)\\n\\nPlease report issues to the GitHub. PRs are welcome. Let me know if you have any question!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Dir-Assistant v0.7 Release Announcement: Up to 100% reduced prompt processing using new intelligent context prefix caching","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lm9xlq","quarantine":false,"link_flair_text_color":"light","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":6,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_lrannsv","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":6,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":1751071918,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"mod_note":null,"created":1751071453,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;h1&gt;Dir-Assistant: Chat with your current directory&amp;#39;s files using a local or API LLM&lt;/h1&gt;\\n\\n&lt;p&gt;Hello All! I am happy to announce Dir-Assistant v1.7.0 and the passing of its one year anniversary. If you haven&amp;#39;t tried Dir-Assistant, now is a great time to. In my personal testing, Dir-Assistant is the best LLM UI for working on large code repositories, outperforming all commercial and open source options I&amp;#39;ve tested due to sophisticated and unique methodology it utilizes. A big difference compared to other LLM UIs is you don&amp;#39;t need to @ files and directories for each prompt. Dir-assistant automatically includes the most relevant parts of any file in the entire repository every time.&lt;/p&gt;\\n\\n&lt;h1&gt;New: Context Prefix Caching&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;strong&gt;1.7.0&amp;#39;s big new feature is &amp;quot;Context Prefix Caching&amp;quot;&lt;/strong&gt;, which optimizes the context sent to your LLM by remembering which combinations of file chunks were previously sent, and attempting to maximize the number of tokens at the beginning of a prompt which match a previously sent prompt. The bottom line is that this can, and in my testing regularly does, completely eliminate prompt processing if your LLM supports prefix caching. Additionally, some APIs automatically support this feature and reduce cost for matching tokens. For instance, Google offers a 75% discount on all its Gemini 2.5 models for prefix cache hits like this (this feature is enabled by default for Gemini).&lt;/p&gt;\\n\\n&lt;p&gt;This feature massively improves performance when working with a local LLM on large codebases. In my local testing running an LMStudio server with Gemma 3n e4b and 100k token context, this feature dropped overall dir-assistant CGRAG-enabled response time from 3:40 to 0:16 on my 7900 XTX. That includes prompt processing and token generation.&lt;/p&gt;\\n\\n&lt;p&gt;Get started by installing with pip:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;pip install dir-assistant\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Full usage documentation available on GitHub:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/curvedinf/dir-assistant\\"&gt;https://github.com/curvedinf/dir-assistant&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;More information about Dir-Assistant&amp;#39;s context prefix caching implementation:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/curvedinf/dir-assistant?tab=readme-ov-file#RAG-Caching-and-Context-Optimization\\"&gt;https://github.com/curvedinf/dir-assistant?tab=readme-ov-file#RAG-Caching-and-Context-Optimization&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Please report issues to the GitHub. PRs are welcome. Let me know if you have any question!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?auto=webp&amp;s=6789ab72c23de3df9868a02098bb16bbb58b9685","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=62618d3a4b15d5aa453f0599776b9c9a3756024c","width":108,"height":54},{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ba7f091472b3c72ba308ba9105b03bc2204d399","width":216,"height":108},{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=14048b2086efe9bf0ef6be11628148b02784141a","width":320,"height":160},{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=47f45f24dd013c7a4a21b519baedd95521c6f94a","width":640,"height":320},{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=339ae6e012ad0acbf58661a8c2ee1d61371315a5","width":960,"height":480},{"url":"https://external-preview.redd.it/tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c8ab1cbf349d3abe6602c9de5f96ae09630d71c","width":1080,"height":540}],"variants":{},"id":"tadazH7yoMPbc8iW84saWeDmnwB7nWgGfswgcjK1B5k"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1lm9xlq","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"1ncehost","discussion_type":null,"num_comments":1,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lm9xlq/dirassistant_v07_release_announcement_up_to_100/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lm9xlq/dirassistant_v07_release_announcement_up_to_100/","subreddit_subscribers":492232,"created_utc":1751071453,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n079s44","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Chromix_","can_mod_post":false,"created_utc":1751092948,"send_replies":true,"parent_id":"t3_1lm9xlq","score":1,"author_fullname":"t2_k7w2h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This could potentially be optimized even more - for larger projects - by trading prompt processing time for maybe 100 GB+ of fast SSD space, at least with [local servers](https://www.reddit.com/r/LocalLLaMA/comments/1lewhla/comment/myl30uy/).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n079s44","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This could potentially be optimized even more - for larger projects - by trading prompt processing time for maybe 100 GB+ of fast SSD space, at least with &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lewhla/comment/myl30uy/\\"&gt;local servers&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm9xlq/dirassistant_v07_release_announcement_up_to_100/n079s44/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092948,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm9xlq","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`);export{e as default};
