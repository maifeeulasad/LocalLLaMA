import{j as e}from"./index-xjtrh7Y1.js";import{R as l}from"./RedditPostRenderer-D0LT1YWU.js";import"./index-C26yY6uW.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Nvidia announces $3,000 personal AI supercomputer called Digits","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":73,"top_awarded_type":null,"hide_score":false,"name":"t3_1hvj4wn","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":null,"ups":1654,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_un3a1n31m","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":1654,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/3HMYYKyry88hgtOB7W0Gvablh-kVyG8pBRZqVHJ_gzI.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1736223378,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"theverge.com","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://www.theverge.com/2025/1/6/24337530/nvidia-ces-digits-super-computer-ai","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?auto=webp&amp;s=f58a76c5692a45eeac0023864f9819e37f4ce8de","width":1200,"height":628},"resolutions":[{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9057e931f447636545e78c9ad4449d4c6637aac","width":108,"height":56},{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9b3a76cf56473b24fa69dbfea19c48880c43c40","width":216,"height":113},{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2381b503d2c232f7bd376d63e8f57bf21ecc122","width":320,"height":167},{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c64890b0dea791601b5a6719c0468df66f41c33","width":640,"height":334},{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=88f024a327a555b6caff02f38a9f9e9fb5f494f8","width":960,"height":502},{"url":"https://external-preview.redd.it/JTaFAeW2ovmKm4g_0oF_TYz510_Ra5xuaGCjwMiquQM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b79fd88d384230eb2840cc20d7b58b251ae5a09d","width":1080,"height":565}],"variants":{},"id":"NwcqydRgIi37Yxdqm8bPJypG9rXCadnQiFNr5atbSHI"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1hvj4wn","is_robot_indexable":true,"num_duplicates":20,"report_reasons":null,"author":"DubiousLLM","discussion_type":null,"num_comments":463,"send_replies":false,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/","stickied":false,"url":"https://www.theverge.com/2025/1/6/24337530/nvidia-ces-digits-super-computer-ai","subreddit_subscribers":492315,"created_utc":1736223378,"num_crossposts":1,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":178,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":7,"name":"t1_m5upq5b","id":"m5upq5b","parent_id":"t1_m5u8y60","depth":3,"children":["m5upq5b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u8y60","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Esies","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tocok","score":169,"author_fullname":"t2_9a6gpnp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They are going straight for the Mac Studio market share of LLM developers/enthusiasts. Bravo","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u8y60","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They are going straight for the Mac Studio market share of LLM developers/enthusiasts. Bravo&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u8y60/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736235524,"author_flair_text":null,"treatment_tags":[],"created_utc":1736235524,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":169}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":16,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5wpgun","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pedalnomica","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5wo3ts","score":2,"author_fullname":"t2_b0d7j6x9","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think the crazy rigs are for most people. I just disagree with the \\"no need for dgpu and building your own rig\\"\\n\\n\\nIf you care about speed, there is still a need.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m5wpgun","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think the crazy rigs are for most people. I just disagree with the &amp;quot;no need for dgpu and building your own rig&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;If you care about speed, there is still a need.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wpgun/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736273022,"author_flair_text":null,"treatment_tags":[],"created_utc":1736273022,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wo3ts","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5w5mak","score":3,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"People bashed me around here for saying this. 4x, 8x, etc GPUs are not a realistic solution in the long term. Don't get me starting on the fire hazard on setting up such monstruosity on your home","edited":false,"author_flair_css_class":null,"name":"t1_m5wo3ts","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;People bashed me around here for saying this. 4x, 8x, etc GPUs are not a realistic solution in the long term. Don&amp;#39;t get me starting on the fire hazard on setting up such monstruosity on your home&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wo3ts/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736272629,"author_flair_text":null,"collapsed":false,"created_utc":1736272629,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":2,"name":"t1_m5wnui6","id":"m5wnui6","parent_id":"t1_m5w5mak","depth":4,"children":["m5wnui6"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5w5mak","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5voivh","score":16,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w5mak/","num_reports":null,"locked":false,"name":"t1_m5w5mak","created":1736267224,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736267224,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":12,"name":"t1_m5zqhf1","id":"m5zqhf1","parent_id":"t1_m5vuibf","depth":4,"children":["m5zqhf1","m5vycnb","m5xtlgl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vuibf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WillmanRacing","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5voivh","score":4,"author_fullname":"t2_474rxc5v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Local inference is honestly a niche use case, I expect most future local LLM users will just use pre-trained models with a RAG agent.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vuibf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Local inference is honestly a niche use case, I expect most future local LLM users will just use pre-trained models with a RAG agent.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vuibf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736263871,"author_flair_text":null,"treatment_tags":[],"created_utc":1736263871,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":1,"name":"t1_m5xnlih","id":"m5xnlih","parent_id":"t1_m5voivh","depth":3,"children":["m5xnlih"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5voivh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pedalnomica","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tocok","score":11,"author_fullname":"t2_b0d7j6x9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably not. No specs yet, but memory bandwidth is probably less than a single 3090 at 4x the cost. https://www.reddit.com/r/LocalLLaMA/comments/1hvlbow/to_understand_the_project_digits_desktop_128_gb/ speculates about half the bandwidth...\\n\\n\\nLocal inference is largely bandwidth bound. So, 4 or 8x 3090 systems with tensor parallel will likely offer much faster inference than one or two of these.\\n\\n\\n\\nSo, don't worry, we'll still be getting insane rig posts for awhile!","edited":1736264250,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5voivh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably not. No specs yet, but memory bandwidth is probably less than a single 3090 at 4x the cost. &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1hvlbow/to_understand_the_project_digits_desktop_128_gb/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1hvlbow/to_understand_the_project_digits_desktop_128_gb/&lt;/a&gt; speculates about half the bandwidth...&lt;/p&gt;\\n\\n&lt;p&gt;Local inference is largely bandwidth bound. So, 4 or 8x 3090 systems with tensor parallel will likely offer much faster inference than one or two of these.&lt;/p&gt;\\n\\n&lt;p&gt;So, don&amp;#39;t worry, we&amp;#39;ll still be getting insane rig posts for awhile!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5voivh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736261948,"author_flair_text":null,"treatment_tags":[],"created_utc":1736261948,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":2,"name":"t1_m6lnr7r","id":"m6lnr7r","parent_id":"t1_m5tocok","depth":2,"children":["m6lnr7r"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tocok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tm7ct","score":178,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tocok/","num_reports":null,"locked":false,"name":"t1_m5tocok","created":1736224894,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736224894,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":2,"name":"t1_m5tnqlw","id":"m5tnqlw","parent_id":"t1_m5tm7ct","depth":1,"children":["m5tnqlw","m5y0a7e"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tm7ct","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacek2023","can_mod_post":false,"created_utc":1736223982,"send_replies":true,"parent_id":"t3_1hvj4wn","score":644,"author_fullname":"t2_vqgbql9w","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is definitely much more interesting that all these 5090 posts.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tm7ct","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is definitely much more interesting that all these 5090 posts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tm7ct/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223982,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":644}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m64zbzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m62k9mp","score":7,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Long story short. If 1092GB/s, it will kill. If 546GB/s, it will have a place. If 273GB/s, meh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m64zbzf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Long story short. If 1092GB/s, it will kill. If 546GB/s, it will have a place. If 273GB/s, meh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m64zbzf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736379751,"author_flair_text":null,"treatment_tags":[],"created_utc":1736379751,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m62k9mp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Exotic-Chemist-3392","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqgcn","score":5,"author_fullname":"t2_1b1k9l1icr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it is anywhere close to 1092GB/s then it's a bargain. \\n\\nThe Jetson Orin has 64GB @ 204.8GB/s and costs ~$2500. I am more inclined to believe it's going to be 546GB/s, as that would mean the digit doubles the memory capacity, 2.6x the bandwidth, all for easy less than double the cost. \\n\\nBut let's hope for 1092GB/s...\\n\\nEither way it sounds like a great product. I think the size of capable open source models, and the capabilities of consumer hardware are converging nicely.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m62k9mp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it is anywhere close to 1092GB/s then it&amp;#39;s a bargain. &lt;/p&gt;\\n\\n&lt;p&gt;The Jetson Orin has 64GB @ 204.8GB/s and costs ~$2500. I am more inclined to believe it&amp;#39;s going to be 546GB/s, as that would mean the digit doubles the memory capacity, 2.6x the bandwidth, all for easy less than double the cost. &lt;/p&gt;\\n\\n&lt;p&gt;But let&amp;#39;s hope for 1092GB/s...&lt;/p&gt;\\n\\n&lt;p&gt;Either way it sounds like a great product. I think the size of capable open source models, and the capabilities of consumer hardware are converging nicely.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m62k9mp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736353863,"author_flair_text":null,"treatment_tags":[],"created_utc":1736353863,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5u8tdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u5myr","score":41,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Because m1 ultra and m2 ultra both have 64 memory controllers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u8tdr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because m1 ultra and m2 ultra both have 64 memory controllers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u8tdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736235443,"author_flair_text":null,"treatment_tags":[],"created_utc":1736235443,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w0rg8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RangmanAlpha","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u5myr","score":5,"author_fullname":"t2_2nyscyef","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"M2 ultra is just attached 2x M2 Max. I wonder this applies to m1, but i suppose m4 will be Same,","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5w0rg8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;M2 ultra is just attached 2x M2 Max. I wonder this applies to m1, but i suppose m4 will be Same,&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w0rg8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736265777,"author_flair_text":null,"treatment_tags":[],"created_utc":1736265777,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5zco4p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u5myr","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"The Ultra chip has traditionally just used double the memory controllers of the Max chip.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The Ultra chip has traditionally just used double the memory controllers of the Max chip.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zco4p/","num_reports":null,"locked":false,"name":"t1_m5zco4p","created":1736302135,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736302135,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u5myr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crafty-Struggle7810","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqgcn","score":15,"author_fullname":"t2_sbmgyk5rk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you referring to the Apple M4 Ultra chip that hasn't released yet? If so, where did you get the 64 memory controllers from?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u5myr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you referring to the Apple M4 Ultra chip that hasn&amp;#39;t released yet? If so, where did you get the 64 memory controllers from?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u5myr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233533,"author_flair_text":null,"treatment_tags":[],"created_utc":1736233533,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uv2ub","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JacketHistorical2321","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqgcn","score":3,"author_fullname":"t2_bsvkuoyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The M1 uses LPDDR5X also and I'm pretty sure it's clocked at 6400 MHz which is around where I would assume a machine that cost $3k would be.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uv2ub","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The M1 uses LPDDR5X also and I&amp;#39;m pretty sure it&amp;#39;s clocked at 6400 MHz which is around where I would assume a machine that cost $3k would be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uv2ub/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736249666,"author_flair_text":null,"treatment_tags":[],"created_utc":1736249666,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m5xjcxy","id":"m5xjcxy","parent_id":"t1_m5tqgcn","depth":2,"children":["m5xjcxy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tqgcn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1736225801,"send_replies":true,"parent_id":"t1_m5tpgaw","score":74,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It is LPDDR5X in the pic which is the same memory used by M4. M4 is using LPDDR5X-8533. If GB10 is to be competitive, it should be the same. If it has the same number of memory controller (ie 32) as M4 Max, then bandwidth is 546GB/s. If it has 64 memory controllers like M4 Ultra, then it is 1092GB/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tqgcn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is LPDDR5X in the pic which is the same memory used by M4. M4 is using LPDDR5X-8533. If GB10 is to be competitive, it should be the same. If it has the same number of memory controller (ie 32) as M4 Max, then bandwidth is 546GB/s. If it has 64 memory controllers like M4 Ultra, then it is 1092GB/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqgcn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225801,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":74}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_m68hgsy","id":"m68hgsy","parent_id":"t1_m5y30uf","depth":3,"children":["m68hgsy","m60digz"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5y30uf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Able-Tip240","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5xio6g","score":22,"author_fullname":"t2_7lzlk0u3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'll wait to see how it goes. As an ML Engineer doing my own generative projects at home just having 128GB would be a game changer. I was debating on getting 2 5090's if I could get a build for &lt; $5k. This will allow me to train much larger models for testing and then if I like what I see I can spend the time setting everything to be deployed and trained in the cloud for finalization.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5y30uf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll wait to see how it goes. As an ML Engineer doing my own generative projects at home just having 128GB would be a game changer. I was debating on getting 2 5090&amp;#39;s if I could get a build for &amp;lt; $5k. This will allow me to train much larger models for testing and then if I like what I see I can spend the time setting everything to be deployed and trained in the cloud for finalization.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5y30uf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736287309,"author_flair_text":null,"treatment_tags":[],"created_utc":1736287309,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5zd3bn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1736302282,"send_replies":true,"parent_id":"t1_m5xio6g","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"How do you think this GPU is half a datacenter Blackwell? Which datacenter Blackwell?","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you think this GPU is half a datacenter Blackwell? Which datacenter Blackwell?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zd3bn/","num_reports":null,"locked":false,"name":"t1_m5zd3bn","created":1736302282,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5yg2do","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tweakingforjesus","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5xio6g","score":3,"author_fullname":"t2_5ww8c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Which is what every manufacturer does to optimize chip yields.  You really think Intel makes umpteen versions of the same processor?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5yg2do","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which is what every manufacturer does to optimize chip yields.  You really think Intel makes umpteen versions of the same processor?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5yg2do/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736291326,"author_flair_text":null,"treatment_tags":[],"created_utc":1736291326,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":4,"name":"t1_m5ydasy","id":"m5ydasy","parent_id":"t1_m5xio6g","depth":2,"children":["m5ydasy","m6ge6il","m5yutfd","m5ydcmg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5xio6g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PoliteCanadian","can_mod_post":false,"created_utc":1736281476,"send_replies":true,"parent_id":"t1_m5tpgaw","score":36,"author_fullname":"t2_6wz7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's worse than that.\\n\\nThey're trying to sell all the broken Blackwells to consumers since the yield that is actually sellable to the datacenter market is so low due to the thermal cracking issues. They've got a large pool of Blackwell chips that can only run with half the chip disabled and at low clockspeeds. Obviously they're not going to put a bunch of expensive HBM on those chips.\\n\\nBut I don't think Blackwell has an onboard LPDDR controller, the LPDDR in Digits must be connected to the Grace CPU. So not only will the GPU only have LPDDR, it's accessing it across the system bus. Yikes.\\n\\nThere's no such thing as bad products, only bad prices, and $3000 might be a good price for what they're selling. I just hope nobody buys this expecting a full speed Blackwell since this will not even come close. Expect it to be at least 10x slower than a B100 on LLM workloads just from memory bandwidth alone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5xio6g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s worse than that.&lt;/p&gt;\\n\\n&lt;p&gt;They&amp;#39;re trying to sell all the broken Blackwells to consumers since the yield that is actually sellable to the datacenter market is so low due to the thermal cracking issues. They&amp;#39;ve got a large pool of Blackwell chips that can only run with half the chip disabled and at low clockspeeds. Obviously they&amp;#39;re not going to put a bunch of expensive HBM on those chips.&lt;/p&gt;\\n\\n&lt;p&gt;But I don&amp;#39;t think Blackwell has an onboard LPDDR controller, the LPDDR in Digits must be connected to the Grace CPU. So not only will the GPU only have LPDDR, it&amp;#39;s accessing it across the system bus. Yikes.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s no such thing as bad products, only bad prices, and $3000 might be a good price for what they&amp;#39;re selling. I just hope nobody buys this expecting a full speed Blackwell since this will not even come close. Expect it to be at least 10x slower than a B100 on LLM workloads just from memory bandwidth alone.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xio6g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736281476,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":36}},{"kind":"more","data":{"count":4,"name":"t1_md1fk0m","id":"md1fk0m","parent_id":"t1_m5tpgaw","depth":1,"children":["md1fk0m"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tpgaw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ttkciar","can_mod_post":false,"created_utc":1736225364,"send_replies":true,"parent_id":"t3_1hvj4wn","score":120,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"According to the \\"specs\\" image (third image from the top) it's using LPDDR5 for memory.\\n\\nIt's impossible to say for sure without knowing how many memory channels it's using, but I expect this thing to spend most of its time bottlenecked on main memory.\\n\\nStill, it should be faster than pure CPU inference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tpgaw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;According to the &amp;quot;specs&amp;quot; image (third image from the top) it&amp;#39;s using LPDDR5 for memory.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s impossible to say for sure without knowing how many memory channels it&amp;#39;s using, but I expect this thing to spend most of its time bottlenecked on main memory.&lt;/p&gt;\\n\\n&lt;p&gt;Still, it should be faster than pure CPU inference.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tpgaw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225364,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":120}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uocsg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wen_mars","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tnlfb","score":17,"author_fullname":"t2_g04t0lxq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's a 72 core Grace, this is a 20 core Grace. It doesn't necessarily have the same bandwidth. It's also 128 GB, not 120.","edited":false,"author_flair_css_class":null,"name":"t1_m5uocsg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s a 72 core Grace, this is a 20 core Grace. It doesn&amp;#39;t necessarily have the same bandwidth. It&amp;#39;s also 128 GB, not 120.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uocsg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736245587,"author_flair_text":null,"collapsed":false,"created_utc":1736245587,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5y02kj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gloomy-Reception8480","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tnlfb","score":3,"author_fullname":"t2_q3ts9eki","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Keep in mind this GB10 is a very different beast than the \\"full\\" grace.  In particular it has 10 cortex-x925 cores instead of the Neoverse cores.  I wouldn't draw any conclusion on the GB10 based on the GB200.  Keep in mind the tf4 performance is 1/40th of the full gb200.","edited":false,"author_flair_css_class":null,"name":"t1_m5y02kj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Keep in mind this GB10 is a very different beast than the &amp;quot;full&amp;quot; grace.  In particular it has 10 cortex-x925 cores instead of the Neoverse cores.  I wouldn&amp;#39;t draw any conclusion on the GB10 based on the GB200.  Keep in mind the tf4 performance is 1/40th of the full gb200.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5y02kj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736286455,"author_flair_text":null,"collapsed":false,"created_utc":1736286455,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m5xk8ot","id":"m5xk8ot","parent_id":"t1_m5tnlfb","depth":4,"children":["m5xk8ot"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tnlfb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emprahsFury","can_mod_post":false,"send_replies":false,"parent_id":"t1_m5tlq7t","score":65,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"the grace cpu in other blackwell products has 1TB/s. But that's for 2. According to the [datasheet](https://resources.nvidia.com/en-us-data-center-overview/hpc-datasheet-grace-cpu-superchip)- Up to 480 gigabytes (GB) of LPDDR5X memory with up to 512GB/s of memory bandwidth. It also says it comes in a 120 gb config that does have the full fat 512 GB/s.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tnlfb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the grace cpu in other blackwell products has 1TB/s. But that&amp;#39;s for 2. According to the &lt;a href=\\"https://resources.nvidia.com/en-us-data-center-overview/hpc-datasheet-grace-cpu-superchip\\"&gt;datasheet&lt;/a&gt;- Up to 480 gigabytes (GB) of LPDDR5X memory with up to 512GB/s of memory bandwidth. It also says it comes in a 120 gb config that does have the full fat 512 GB/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tnlfb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224571,"author_flair_text":null,"treatment_tags":[],"created_utc":1736224571,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":65}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ugr2c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"maifee","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tlq7t","score":20,"author_fullname":"t2_1fuhylzi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In token per second??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ugr2c","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In token per second??&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ugr2c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736240550,"author_flair_text":"Ollama","treatment_tags":[],"created_utc":1736240550,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_m5uqnkx","id":"m5uqnkx","parent_id":"t1_m5ucwnp","depth":7,"children":["m5uqnkx"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ucwnp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wen_mars","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uauwt","score":41,"author_fullname":"t2_g04t0lxq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LP stands for Low Power. The image says \\"Low Power DDR5X\\". So it's LPDDR5X.","edited":1736238232,"gildings":{},"author_flair_css_class":null,"name":"t1_m5ucwnp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LP stands for Low Power. The image says &amp;quot;Low Power DDR5X&amp;quot;. So it&amp;#39;s LPDDR5X.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ucwnp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736238015,"author_flair_text":null,"treatment_tags":[],"created_utc":1736238015,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":41}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uauwt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CatalyticDragon","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u1107","score":8,"author_fullname":"t2_3h1nb","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Their website specifically says \\"DDR5X\\". Confusing but I'm sure you're right.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m5uauwt","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their website specifically says &amp;quot;DDR5X&amp;quot;. Confusing but I&amp;#39;m sure you&amp;#39;re right.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uauwt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736236715,"author_flair_text":null,"treatment_tags":[],"created_utc":1736236715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u1107","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wen_mars","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tq7qt","score":42,"author_fullname":"t2_g04t0lxq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"LPDDR5X, not DDR5","edited":false,"author_flair_css_class":null,"name":"t1_m5u1107","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LPDDR5X, not DDR5&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u1107/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736230947,"author_flair_text":null,"collapsed":false,"created_utc":1736230947,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tq7qt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CatalyticDragon","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tlq7t","score":28,"author_fullname":"t2_3h1nb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Each Project Digits system comes equipped with 128GB of unified, coherent memory\\"\\n\\nIt's DDR5 according to the [NVIDIA site](https://www.nvidia.com/en-us/project-digits/).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tq7qt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Each Project Digits system comes equipped with 128GB of unified, coherent memory&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s DDR5 according to the &lt;a href=\\"https://www.nvidia.com/en-us/project-digits/\\"&gt;NVIDIA site&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tq7qt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225695,"author_flair_text":null,"treatment_tags":[],"created_utc":1736225695,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"more","data":{"count":13,"name":"t1_m5tmnur","id":"m5tmnur","parent_id":"t1_m5tlq7t","depth":3,"children":["m5tmnur","m5ygxpi","m6ravus","m5xgkoq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlq7t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tlg9q","score":123,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips](https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips)\\n\\n1PFLOPS FP4 sparse =&gt; 125TFLOPS FP16\\n\\nDon't know about the memory bandwidth yet.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tlq7t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips\\"&gt;https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;1PFLOPS FP4 sparse =&amp;gt; 125TFLOPS FP16&lt;/p&gt;\\n\\n&lt;p&gt;Don&amp;#39;t know about the memory bandwidth yet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlq7t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223782,"author_flair_text":null,"treatment_tags":[],"created_utc":1736223782,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":123}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5wrvz1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5wfgxf","score":4,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you're trying to imply they're intended to be swapped out for each other... then obviously no the $3000 \\"personal AI machine\\" is not a GH200 replacement?\\n\\n  \\nMy point is that the GH200 despite its insane compute and power limits is \\\\*still\\\\* slow at generation for models large enough to require its unified memory.\\n\\nThis won't be faster than (even at FP4) and all the memory will be unified memory, so the short answer is: it will run large models abysmally slow.","edited":false,"author_flair_css_class":null,"name":"t1_m5wrvz1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re trying to imply they&amp;#39;re intended to be swapped out for each other... then obviously no the $3000 &amp;quot;personal AI machine&amp;quot; is not a GH200 replacement?&lt;/p&gt;\\n\\n&lt;p&gt;My point is that the GH200 despite its insane compute and power limits is *still* slow at generation for models large enough to require its unified memory.&lt;/p&gt;\\n\\n&lt;p&gt;This won&amp;#39;t be faster than (even at FP4) and all the memory will be unified memory, so the short answer is: it will run large models abysmally slow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wrvz1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736273729,"author_flair_text":null,"collapsed":false,"created_utc":1736273729,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wfgxf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"norcalnatv","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u29ug","score":3,"author_fullname":"t2_12mdhn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The GH200 is a data center part that needs 1000W of power.  This is a desktop application, certainly not intended for the same work loads.\\n\\nThe elegance is both run the same software stack.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wfgxf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The GH200 is a data center part that needs 1000W of power.  This is a desktop application, certainly not intended for the same work loads.&lt;/p&gt;\\n\\n&lt;p&gt;The elegance is both run the same software stack.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wfgxf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736270121,"author_flair_text":null,"treatment_tags":[],"created_utc":1736270121,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u29ug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tlg9q","score":23,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Short Answer? Abysmal speeds if the GH200 is anything to go by.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u29ug","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Short Answer? Abysmal speeds if the GH200 is anything to go by.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u29ug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736231623,"author_flair_text":null,"treatment_tags":[],"created_utc":1736231623,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlg9q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Erdeem","can_mod_post":false,"created_utc":1736223668,"send_replies":true,"parent_id":"t1_m5tks5x","score":106,"author_fullname":"t2_4mpro","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, but what but at what speeds?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tlg9q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, but what but at what speeds?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlg9q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223668,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":106}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":19,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5wf45z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iamthewhatt","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5wbeiz","score":7,"author_fullname":"t2_9whlksiz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"new LTT video: unlimited digits unlimited gamers","edited":false,"author_flair_css_class":null,"name":"t1_m5wf45z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;new LTT video: unlimited digits unlimited gamers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wf45z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736270019,"author_flair_text":null,"collapsed":false,"created_utc":1736270019,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wbeiz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"cafedude","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vam8h","score":8,"author_fullname":"t2_23o6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm imagining old-fashioned LAN parties where people get together to chain their Digit boxes to run larger models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wbeiz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m imagining old-fashioned LAN parties where people get together to chain their Digit boxes to run larger models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wbeiz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736268929,"author_flair_text":null,"treatment_tags":[],"created_utc":1736268929,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":6,"name":"t1_m5yysr3","id":"m5yysr3","parent_id":"t1_m5vam8h","depth":3,"children":["m5yysr3","m5vphm0"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vam8h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iamthewhatt","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tm65c","score":11,"author_fullname":"t2_9whlksiz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would be surprised if it's only 2 considering each one has 2 ConnectX ports, you could theoretically have unlimited by daisy-chaining. Only limited by software and bandwidth.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5vam8h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would be surprised if it&amp;#39;s only 2 considering each one has 2 ConnectX ports, you could theoretically have unlimited by daisy-chaining. Only limited by software and bandwidth.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vam8h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736256921,"author_flair_text":null,"treatment_tags":[],"created_utc":1736256921,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5zsnm8","id":"m5zsnm8","parent_id":"t1_m5wwq68","depth":4,"children":["m5zsnm8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wwq68","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShengrenR","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vvyv4","score":3,"author_fullname":"t2_ji4n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The bottleneck for LLMs is the memory speed - the memory speed is fixed across all of them, so having more doesn't help, it just means a larger pool of ram for the really huge models. It does, however, mean you could load up a bunch of smaller, specialized models and have each machine serve a couple - lots to be seen, but the notion of a set of fine-tuned llama4 70s makes me happier than a single huge ds v3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wwq68","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The bottleneck for LLMs is the memory speed - the memory speed is fixed across all of them, so having more doesn&amp;#39;t help, it just means a larger pool of ram for the really huge models. It does, however, mean you could load up a bunch of smaller, specialized models and have each machine serve a couple - lots to be seen, but the notion of a set of fine-tuned llama4 70s makes me happier than a single huge ds v3&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wwq68/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736275124,"author_flair_text":null,"treatment_tags":[],"created_utc":1736275124,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vvyv4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Johnroberts95000","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tm65c","score":4,"author_fullname":"t2_x4n1v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So it would be 3 for deepseek3? Does stringing multiple together increase the TPS by combining processing power or just extend the ram?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5vvyv4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So it would be 3 for deepseek3? Does stringing multiple together increase the TPS by combining processing power or just extend the ram?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vvyv4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736264327,"author_flair_text":null,"treatment_tags":[],"created_utc":1736264327,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tm65c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tks5x","score":19,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Dang only two? I guess natively. There should be software to run more in parallel like people do with Linux servers and macs in order to run something like Deepseek 3.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dang only two? I guess natively. There should be software to run more in parallel like people do with Linux servers and macs in order to run something like Deepseek 3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tm65c/","num_reports":null,"locked":false,"name":"t1_m5tm65c","created":1736223968,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736223968,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vd06e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jointheredditarmy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5v8mje","score":3,"author_fullname":"t2_4g00a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"2 of them would be 256 gb of ram, so right about what youd need for q4","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5vd06e","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;2 of them would be 256 gb of ram, so right about what youd need for q4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vd06e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736257847,"author_flair_text":null,"treatment_tags":[],"created_utc":1736257847,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5zdayg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1736302355,"send_replies":true,"parent_id":"t1_m5v8mje","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Q4 is a very popular quant these days. If you insist on Q8, this setup would run 70B at Q8 very well which a GPU card setup would struggle to do.","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Q4 is a very popular quant these days. If you insist on Q8, this setup would run 70B at Q8 very well which a GPU card setup would struggle to do.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zdayg/","num_reports":null,"locked":false,"name":"t1_m5zdayg","created":1736302355,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5v8mje","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"segmond","can_mod_post":false,"created_utc":1736256125,"send_replies":true,"parent_id":"t1_m5tks5x","score":9,"author_fullname":"t2_ah13x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yeah, that 405b model will be at Q4.   I don't count that, Q8 minimum.  Or else they might as well claim that 1 Digit system can handle a 405B model.  I mean at Q2 or Q1 you can stuff a 405b model into 128gb.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5v8mje","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yeah, that 405b model will be at Q4.   I don&amp;#39;t count that, Q8 minimum.  Or else they might as well claim that 1 Digit system can handle a 405B model.  I mean at Q2 or Q1 you can stuff a 405b model into 128gb.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5v8mje/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736256125,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"more","data":{"count":22,"name":"t1_m64j3es","id":"m64j3es","parent_id":"t1_m5tks5x","depth":1,"children":["m64j3es","m5vd5m1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tks5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DubiousLLM","can_mod_post":false,"created_utc":1736223397,"send_replies":false,"parent_id":"t3_1hvj4wn","score":454,"author_fullname":"t2_un3a1n31m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;\\ttwo Project Digits systems can be linked together to handle models with up to 405 billion parameters (Metas best model, Llama 3.1, has 405 billion parameters).\\n\\nInsane!!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tks5x","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;two Project Digits systems can be linked together to handle models with up to 405 billion parameters (Metas best model, Llama 3.1, has 405 billion parameters).&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Insane!!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tks5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223397,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":454}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":34,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w5lu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OkDimension","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vwea4","score":19,"author_fullname":"t2_trpeh84","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because IT is usually underfunded, trying to hold the place together with prayers and duct tape, and only gets the resources when the CEO wants something. Particularly here in Canada I see IT often assigned to the same corner (and director) like facilities, purely treated as a cost center, and not as a place of development and innovation.","edited":false,"author_flair_css_class":null,"name":"t1_m5w5lu1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because IT is usually underfunded, trying to hold the place together with prayers and duct tape, and only gets the resources when the CEO wants something. Particularly here in Canada I see IT often assigned to the same corner (and director) like facilities, purely treated as a cost center, and not as a place of development and innovation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w5lu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736267220,"author_flair_text":null,"collapsed":false,"created_utc":1736267220,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5xkgu1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Smeetilus","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5wnoao","score":4,"author_fullname":"t2_e3fsq5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just right click it and check off \\"Unblock\\"","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m5xkgu1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just right click it and check off &amp;quot;Unblock&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xkgu1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736281995,"author_flair_text":null,"treatment_tags":[],"created_utc":1736281995,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wnoao","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"alastor0x","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vwea4","score":7,"author_fullname":"t2_poayp51k0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Going to assume you've never worked corporate IT. I can't imagine what your opinions of the InfoSec office are. I do love being told I'm \\"holding up the business\\" because I won't allow some obscure application that a junior dev found on the Internet.","edited":false,"author_flair_css_class":null,"name":"t1_m5wnoao","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Going to assume you&amp;#39;ve never worked corporate IT. I can&amp;#39;t imagine what your opinions of the InfoSec office are. I do love being told I&amp;#39;m &amp;quot;holding up the business&amp;quot; because I won&amp;#39;t allow some obscure application that a junior dev found on the Internet.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wnoao/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736272505,"author_flair_text":null,"collapsed":false,"created_utc":1736272505,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w7pf7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inkybinkyfoo","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vwea4","score":10,"author_fullname":"t2_pryf9um25","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ive worked in IT for 10+ years and IT is notorious for being over worked and under funded. Many times wed like to take on projects that help everyone but our hands are always tied because until executive has a crisis or need.","edited":false,"author_flair_css_class":null,"name":"t1_m5w7pf7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ive worked in IT for 10+ years and IT is notorious for being over worked and under funded. Many times wed like to take on projects that help everyone but our hands are always tied because until executive has a crisis or need.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w7pf7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736267841,"author_flair_text":null,"collapsed":false,"created_utc":1736267841,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vwea4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ToronoYYZ","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vuuuc","score":13,"author_fullname":"t2_sktvt71gw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I find IT departments get in the way of innovation or business efficiency sometimes. IT is a black box to most non-IT people","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vwea4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I find IT departments get in the way of innovation or business efficiency sometimes. IT is a black box to most non-IT people&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vwea4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736264458,"author_flair_text":null,"treatment_tags":[],"created_utc":1736264458,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"more","data":{"count":1,"name":"t1_m5xw6o1","id":"m5xw6o1","parent_id":"t1_m5vuuuc","depth":3,"children":["m5xw6o1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vuuuc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1736263980,"send_replies":true,"parent_id":"t1_m5v7jnw","score":34,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vuuuc/","num_reports":null,"locked":false,"name":"t1_m5vuuuc","created":1736263980,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vd2ie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CSharpSauce","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5v7jnw","score":2,"author_fullname":"t2_37u65","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"laughing through the tears","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5vd2ie","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;laughing through the tears&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vd2ie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736257872,"author_flair_text":null,"treatment_tags":[],"created_utc":1736257872,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5v7jnw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ToronoYYZ","can_mod_post":false,"created_utc":1736255682,"send_replies":true,"parent_id":"t1_m5uczs7","score":28,"author_fullname":"t2_sktvt71gw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Classic IT","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5v7jnw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Classic IT&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5v7jnw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736255682,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5zg841","id":"m5zg841","parent_id":"t1_m5zfapt","depth":5,"children":["m5zg841"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5zfapt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Independent_Skirt301","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5zdtkg","score":3,"author_fullname":"t2_3zhku27a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh boy. I could write volumes... Security policy documentation, endpoint management software that is operating system specific, end user policy application (good like with AD group policy), deployment automation (Apple has special tools for managing and deploying macs), network access control compatibility, etc, etc, etc...","edited":false,"author_flair_css_class":null,"name":"t1_m5zfapt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh boy. I could write volumes... Security policy documentation, endpoint management software that is operating system specific, end user policy application (good like with AD group policy), deployment automation (Apple has special tools for managing and deploying macs), network access control compatibility, etc, etc, etc...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zfapt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736303056,"author_flair_text":null,"collapsed":false,"created_utc":1736303056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5zdtkg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5yf76h","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"What is there to work with? Leave it behind the corporate firewall.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is there to work with? Leave it behind the corporate firewall.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zdtkg/","num_reports":null,"locked":false,"name":"t1_m5zdtkg","created":1736302535,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736302535,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5yf76h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CSharpSauce","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5xzzen","score":2,"author_fullname":"t2_37u65","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Okay, this is funny because I spoke to one of the directors about it today, and his response was something like \\"I'm not sure our security software will work on it\\"","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5yf76h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Okay, this is funny because I spoke to one of the directors about it today, and his response was something like &amp;quot;I&amp;#39;m not sure our security software will work on it&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5yf76h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736291046,"author_flair_text":null,"treatment_tags":[],"created_utc":1736291046,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5xzzen","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Independent_Skirt301","can_mod_post":false,"created_utc":1736286430,"send_replies":true,"parent_id":"t1_m5uczs7","score":2,"author_fullname":"t2_3zhku27a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"Wouldn't know how\\" usually means, \\"Told us that we'd need to make a 5 figure investment for licensing and administrative software, and that ain't happenin'! \\\\*laughter\\\\*\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5xzzen","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Wouldn&amp;#39;t know how&amp;quot; usually means, &amp;quot;Told us that we&amp;#39;d need to make a 5 figure investment for licensing and administrative software, and that ain&amp;#39;t happenin&amp;#39;! *laughter*&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xzzen/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736286430,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_m66o15p","id":"m66o15p","parent_id":"t1_m5uczs7","depth":1,"children":["m66o15p","m5uk7yq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uczs7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CSharpSauce","can_mod_post":false,"created_utc":1736238072,"send_replies":true,"parent_id":"t3_1hvj4wn","score":63,"author_fullname":"t2_37u65","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My company currently pays Azure $2k/month for an A100 in the cloud.... think I can convince them to let me get one of these for my desk?\\n\\n:( i know the answer is \\"IT wouldn't know how to manage it\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uczs7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My company currently pays Azure $2k/month for an A100 in the cloud.... think I can convince them to let me get one of these for my desk?&lt;/p&gt;\\n\\n&lt;p&gt;:( i know the answer is &amp;quot;IT wouldn&amp;#39;t know how to manage it&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uczs7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736238072,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":63}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5wz0lb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uv9o1","score":6,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The GH200 still has at least 96 GB of VRAM hooked up directly to a H100-equivalent GPU, so running FP8 Llama 70B is much faster than you'll see on any unified memory-only machine.\\n\\nThe model was likely in VRAM entirely too so _just_ the KV cache spilling into unified memory was enough for the 2.6x slowdown. Move the entire model into unified memory and cut compute to 1/4th and those TTFT numbers especially are going to get painful.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wz0lb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The GH200 still has at least 96 GB of VRAM hooked up directly to a H100-equivalent GPU, so running FP8 Llama 70B is much faster than you&amp;#39;ll see on any unified memory-only machine.&lt;/p&gt;\\n\\n&lt;p&gt;The model was likely in VRAM entirely too so &lt;em&gt;just&lt;/em&gt; the KV cache spilling into unified memory was enough for the 2.6x slowdown. Move the entire model into unified memory and cut compute to 1/4th and those TTFT numbers especially are going to get painful.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wz0lb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736275778,"author_flair_text":null,"treatment_tags":[],"created_utc":1736275778,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_m5wulwb","id":"m5wulwb","parent_id":"t1_m5uv9o1","depth":3,"children":["m5wulwb"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uv9o1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok-Perception2973","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tr4bi","score":10,"author_fullname":"t2_5mlgys93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Im really curious to know more about your experience with this. Im looking into the GH200, I found benchmarks showing &gt;1000 tok/sec on Llama 3.1 70B and around 300 with 120K context offloading (240 gb CPU offloading). Source: https://www.substratus.ai/blog/benchmarking-llama-3.1-70b-on-gh200-vllm","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uv9o1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Im really curious to know more about your experience with this. Im looking into the GH200, I found benchmarks showing &amp;gt;1000 tok/sec on Llama 3.1 70B and around 300 with 120K context offloading (240 gb CPU offloading). Source: &lt;a href=\\"https://www.substratus.ai/blog/benchmarking-llama-3.1-70b-on-gh200-vllm\\"&gt;https://www.substratus.ai/blog/benchmarking-llama-3.1-70b-on-gh200-vllm&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uv9o1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736249770,"author_flair_text":null,"treatment_tags":[],"created_utc":1736249770,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ugkqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u3qe7","score":8,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not going to be much faster. The GH200 still has 96 GB of VRAM hooked up directly to essentially an H100, so FP8 quantized 70B models would run much faster than this thing can.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ugkqo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not going to be much faster. The GH200 still has 96 GB of VRAM hooked up directly to essentially an H100, so FP8 quantized 70B models would run much faster than this thing can.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ugkqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736240434,"author_flair_text":null,"treatment_tags":[],"created_utc":1736240434,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u3qe7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CharacterCheck389","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tr4bi","score":13,"author_fullname":"t2_shcq1guo1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"did you try a 70b model? I need to know the benchmarks, mention any, and thanks for help!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u3qe7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;did you try a 70b model? I need to know the benchmarks, mention any, and thanks for help!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u3qe7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736232438,"author_flair_text":null,"treatment_tags":[],"created_utc":1736232438,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uk1tm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uhdmz","score":9,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The underlying issue is unified memory is still a bottleneck: the GH200 has a 4x compute advantage over this and was still that slow.\\n\\nThe mental model for unified memory should be it makes CPU offloading go from impossibly slow to just slow. Slow is better than nothing, but if your task has a performance floor then everything below that is still not really of any use.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uk1tm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The underlying issue is unified memory is still a bottleneck: the GH200 has a 4x compute advantage over this and was still that slow.&lt;/p&gt;\\n\\n&lt;p&gt;The mental model for unified memory should be it makes CPU offloading go from impossibly slow to just slow. Slow is better than nothing, but if your task has a performance floor then everything below that is still not really of any use.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uk1tm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736242761,"author_flair_text":null,"treatment_tags":[],"created_utc":1736242761,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uhdmz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VancityGaming","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tr4bi","score":5,"author_fullname":"t2_oeun0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This will have cuda support though right? Will that make a difference?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uhdmz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This will have cuda support though right? Will that make a difference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uhdmz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736240969,"author_flair_text":null,"treatment_tags":[],"created_utc":1736240969,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5xue6e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"samjongenelen","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vj7z3","score":2,"author_fullname":"t2_151fnc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Exactly.  And some people just want to spend money not be tweaking all day.\\nHaving that said, this device isn't convincing enough for me","edited":false,"author_flair_css_class":null,"name":"t1_m5xue6e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exactly.  And some people just want to spend money not be tweaking all day.\\nHaving that said, this device isn&amp;#39;t convincing enough for me&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xue6e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736284816,"author_flair_text":null,"collapsed":false,"created_utc":1736284816,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vj7z3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"L3Niflheim","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u69yi","score":5,"author_fullname":"t2_dr7y0h07","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It doesn't really have any competition if you want to run large models at home without a mining rack and a stack of 3090s. I would prefer the latter by not massively practical for most people.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vj7z3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It doesn&amp;#39;t really have any competition if you want to run large models at home without a mining rack and a stack of 3090s. I would prefer the latter by not massively practical for most people.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vj7z3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736260132,"author_flair_text":null,"treatment_tags":[],"created_utc":1736260132,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u69yi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Only-Letterhead-3411","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tr4bi","score":9,"author_fullname":"t2_pbfqmgf8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, that's what I was expecting. 3k$ is way too expensive for this.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u69yi","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, that&amp;#39;s what I was expecting. 3k$ is way too expensive for this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u69yi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233913,"author_flair_text":null,"treatment_tags":[],"created_utc":1736233913,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"more","data":{"count":2,"name":"t1_m5u82to","id":"m5u82to","parent_id":"t1_m5tr4bi","depth":2,"children":["m5u82to","maztj7l"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tr4bi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"created_utc":1736226095,"send_replies":true,"parent_id":"t1_m5tlsqc","score":78,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've tried the GH200's unified setup which iirc is 4 PFLOPs @ FP8 and even that was too slow for most realtime applications with a model that'd tax its memory.\\n\\nMistral 123B W8A8 (FP8) was about 3-4 tk/s which is enough for offline batch-style processing but not something you want to sit around for.\\n\\nIt felt incredibly similar to trying to run large models on my 128 GB M4 Macbook: Technically it can run them... but it's not a fun experience and I'd only do it for academic reasons.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tr4bi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve tried the GH200&amp;#39;s unified setup which iirc is 4 PFLOPs @ FP8 and even that was too slow for most realtime applications with a model that&amp;#39;d tax its memory.&lt;/p&gt;\\n\\n&lt;p&gt;Mistral 123B W8A8 (FP8) was about 3-4 tk/s which is enough for offline batch-style processing but not something you want to sit around for.&lt;/p&gt;\\n\\n&lt;p&gt;It felt incredibly similar to trying to run large models on my 128 GB M4 Macbook: Technically it can run them... but it&amp;#39;s not a fun experience and I&amp;#39;d only do it for academic reasons.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tr4bi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736226095,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":78}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uiou1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Arcanu","can_mod_post":false,"created_utc":1736241848,"send_replies":true,"parent_id":"t1_m5tlsqc","score":6,"author_fullname":"t2_solzk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sounds like an ssd but full of RAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uiou1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sounds like an ssd but full of RAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uiou1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736241848,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlsqc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Only-Letterhead-3411","can_mod_post":false,"created_utc":1736223811,"send_replies":true,"parent_id":"t3_1hvj4wn","score":152,"author_fullname":"t2_pbfqmgf8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"128gb unified ram","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tlsqc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;128gb unified ram&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlsqc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223811,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":152}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_m7cha8l","id":"m7cha8l","parent_id":"t1_m5u5sg3","depth":4,"children":["m7cha8l","m60tpm4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u5sg3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ReginaldBundy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u0woe","score":22,"author_fullname":"t2_s6tkhhn76","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'll wait for benchmarks, obviously. But with this configuration Nvidia would win on price because Apple overcharges for RAM and storage.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u5sg3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ll wait for benchmarks, obviously. But with this configuration Nvidia would win on price because Apple overcharges for RAM and storage.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u5sg3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233623,"author_flair_text":null,"treatment_tags":[],"created_utc":1736233623,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w7zp6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"GeT_NoT","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u0woe","score":9,"author_fullname":"t2_osga1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What do you mean by inference vs prompt processing? Doesn't these two mean the same thing? Do you mean input token processing?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5w7zp6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you mean by inference vs prompt processing? Doesn&amp;#39;t these two mean the same thing? Do you mean input token processing?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w7zp6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736267924,"author_flair_text":null,"treatment_tags":[],"created_utc":1736267924,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u0woe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u0aei","score":8,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But if the memory bandwidth is only 546gb/s and you care more a out inference than prompt processing, then you still can't count m4 ultra out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u0woe","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But if the memory bandwidth is only 546gb/s and you care more a out inference than prompt processing, then you still can&amp;#39;t count m4 ultra out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u0woe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736230882,"author_flair_text":null,"treatment_tags":[],"created_utc":1736230882,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u0aei","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ReginaldBundy","can_mod_post":false,"created_utc":1736230551,"send_replies":true,"parent_id":"t1_m5tllh2","score":23,"author_fullname":"t2_s6tkhhn76","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I was planning on getting a Studio with M4 Ultra when available, will definitely wait now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u0aei","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I was planning on getting a Studio with M4 Ultra when available, will definitely wait now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u0aei/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736230551,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mzqgmbg","id":"mzqgmbg","parent_id":"t1_m5wrmgk","depth":5,"children":["mzqgmbg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wrmgk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5ub3lp","score":2,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"And the guy you replied to got 16 upvotes smh. People really need some classes on how hardware works","edited":false,"author_flair_css_class":null,"name":"t1_m5wrmgk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And the guy you replied to got 16 upvotes smh. People really need some classes on how hardware works&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wrmgk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736273652,"author_flair_text":null,"collapsed":false,"created_utc":1736273652,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ub3lp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"non1979","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tw5r8","score":17,"author_fullname":"t2_acldi8o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Dual-Channel (2-Channel) Configuration:\\n\\n\\\\*\\\\*\\\\* Total Bus Width:2 channels \\\\* 128 bits/channel = 256 bits = 32 bytes\\n\\n\\\\*\\\\*\\\\*\\\\* Theoretical Maximum Bandwidth:8533 MHz \\\\* 32 bytes = 273056 MB/s =273.056 GB/s\\n\\nQuad-Channel (4-Channel) Configuration:\\n\\n\\\\*\\\\*\\\\* Total Bus Width:4 channels \\\\* 128 bits/channel = 512 bits = 64 bytes\\n\\n\\\\*\\\\*\\\\* Theoretical Maximum Bandwidth:8533 MHz \\\\* 64 bytes = 546112 MB/s =546.112 GB/s\\n\\n\\n\\n6 channels for 128gb? not mathematics  modules","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ub3lp","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Dual-Channel (2-Channel) Configuration:&lt;/p&gt;\\n\\n&lt;p&gt;*** Total Bus Width:2 channels * 128 bits/channel = 256 bits = 32 bytes&lt;/p&gt;\\n\\n&lt;p&gt;**** Theoretical Maximum Bandwidth:8533 MHz * 32 bytes = 273056 MB/s =273.056 GB/s&lt;/p&gt;\\n\\n&lt;p&gt;Quad-Channel (4-Channel) Configuration:&lt;/p&gt;\\n\\n&lt;p&gt;*** Total Bus Width:4 channels * 128 bits/channel = 512 bits = 64 bytes&lt;/p&gt;\\n\\n&lt;p&gt;*** Theoretical Maximum Bandwidth:8533 MHz * 64 bytes = 546112 MB/s =546.112 GB/s&lt;/p&gt;\\n\\n&lt;p&gt;6 channels for 128gb? not mathematics  modules&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ub3lp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736236864,"author_flair_text":null,"treatment_tags":[],"created_utc":1736236864,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tw5r8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CubicleHermit","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqmg7","score":14,"author_fullname":"t2_2zy9fn1j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe 6 channels, probably around 800-900GB/s per https://www.theregister.com/2025/01/07/nvidia_project_digits_mini_pc/\\n\\nAround half that of a 5090 if so.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tw5r8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe 6 channels, probably around 800-900GB/s per &lt;a href=\\"https://www.theregister.com/2025/01/07/nvidia_project_digits_mini_pc/\\"&gt;https://www.theregister.com/2025/01/07/nvidia_project_digits_mini_pc/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Around half that of a 5090 if so.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tw5r8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736228448,"author_flair_text":null,"treatment_tags":[],"created_utc":1736228448,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"more","data":{"count":3,"name":"t1_m5tueg2","id":"m5tueg2","parent_id":"t1_m5tqmg7","depth":2,"children":["m5tueg2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tqmg7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious-Map6957","can_mod_post":false,"created_utc":1736225876,"send_replies":true,"parent_id":"t1_m5tllh2","score":39,"author_fullname":"t2_7p99opl4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"the VRAM is stated to be DDR5X, so it will definitely be slower than a GPU server but a viable option for some nonetheless.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tqmg7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;the VRAM is stated to be DDR5X, so it will definitely be slower than a GPU server but a viable option for some nonetheless.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqmg7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225876,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":43,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5z1aoe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tweus","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"cost+space+power+usability effective in combo yes. Each alone ehhhhh.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;cost+space+power+usability effective in combo yes. Each alone ehhhhh.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5z1aoe/","num_reports":null,"locked":false,"name":"t1_m5z1aoe","created":1736298285,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736298285,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tweus","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"claythearc","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tmejb","score":19,"author_fullname":"t2_65rk0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For inference its mildly popular. Theyre one of the most cost effective systems for tons of vram*","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tweus","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For inference its mildly popular. Theyre one of the most cost effective systems for tons of vram*&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tweus/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736228573,"author_flair_text":null,"treatment_tags":[],"created_utc":1736228573,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":8,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m61b4g3","id":"m61b4g3","parent_id":"t1_m5xixia","depth":4,"children":["m61b4g3"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5xixia","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ChocolatySmoothie","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uck23","score":2,"author_fullname":"t2_59jgukkk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"M4 Ultra most likely will be 256GB RAM since it will support two maxed out M4 Max chips.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5xixia","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;M4 Ultra most likely will be 256GB RAM since it will support two maxed out M4 Max chips.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xixia/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736281551,"author_flair_text":null,"treatment_tags":[],"created_utc":1736281551,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uck23","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"created_utc":1736237789,"send_replies":true,"parent_id":"t1_m5tmejb","score":8,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uck23/","num_reports":null,"locked":false,"name":"t1_m5uck23","created":1736237789,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ws21h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Caffdy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tn6cn","score":7,"author_fullname":"t2_ql2vu0wz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's not gonna be the same as the 5090, why people keep repeating that? It's has been already stated that this one uses LPDDR5X, it's not the same as GDDR7. This thing is either gonna be 273 or 546 GB/s","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ws21h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not gonna be the same as the 5090, why people keep repeating that? It&amp;#39;s has been already stated that this one uses LPDDR5X, it&amp;#39;s not the same as GDDR7. This thing is either gonna be 273 or 546 GB/s&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ws21h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736273779,"author_flair_text":null,"treatment_tags":[],"created_utc":1736273779,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":15,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5yymnu","id":"m5yymnu","parent_id":"t1_m5vammt","depth":5,"children":["m5yymnu"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vammt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqgds","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"collapsed":true,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vammt/","num_reports":null,"locked":false,"name":"t1_m5vammt","created":1736256925,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736256925,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tqgds","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tn6cn","score":15,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Key word macbooks. Apple's laptops benefit greatly from this since they are primarily very good business machines and now they get an added perk with LLM performance.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Key word macbooks. Apple&amp;#39;s laptops benefit greatly from this since they are primarily very good business machines and now they get an added perk with LLM performance.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqgds/","num_reports":null,"locked":false,"name":"t1_m5tqgds","created":1736225801,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736225801,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ucm2s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BangkokPadang","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tn6cn","score":6,"author_fullname":"t2_3v4ud","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"For inference, the key component here will be that this will support CUDA. That means Exllamav2 and flashmemory 2 support, which is markedly faster than llamacpp on like hardware.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ucm2s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For inference, the key component here will be that this will support CUDA. That means Exllamav2 and flashmemory 2 support, which is markedly faster than llamacpp on like hardware.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ucm2s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736237825,"author_flair_text":null,"treatment_tags":[],"created_utc":1736237825,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5vaxkg","id":"m5vaxkg","parent_id":"t1_m5ulegc","depth":4,"children":["m5vaxkg"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ulegc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tn6cn","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ulegc/","num_reports":null,"locked":false,"name":"t1_m5ulegc","created":1736243661,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736243661,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":1,"name":"t1_m5uurox","id":"m5uurox","parent_id":"t1_m5tn6cn","depth":3,"children":["m5uurox"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tn6cn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tmejb","score":12,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, Apple official site talks about using their high end macbooks for LLMs. So they are also serious about this market even though it is not that big for them. M4 Ultra is likely to be 256GB and 1092GB/s bandwidth. So RAM is the same as two GB10s. GB10 bandwidth is unknown. If it is the same architecture as 5070, then it is 672GB/s. But since it is 128GB, it can also be the same as 5090's 1792GB/s.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tn6cn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, Apple official site talks about using their high end macbooks for LLMs. So they are also serious about this market even though it is not that big for them. M4 Ultra is likely to be 256GB and 1092GB/s bandwidth. So RAM is the same as two GB10s. GB10 bandwidth is unknown. If it is the same architecture as 5070, then it is 672GB/s. But since it is 128GB, it can also be the same as 5090&amp;#39;s 1792GB/s.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tn6cn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224391,"author_flair_text":null,"treatment_tags":[],"created_utc":1736224391,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5tqbmq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tn69n","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Local just means not API or cloud, correct. But mac mini LLM clusters only became talked about with the very new M4 generation, and even those were worse than the M2 Ultra based Mac Studio which was never widely used like that. Mac based server clusters are almost entirely for app development.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Local just means not API or cloud, correct. But mac mini LLM clusters only became talked about with the very new M4 generation, and even those were worse than the M2 Ultra based Mac Studio which was never widely used like that. Mac based server clusters are almost entirely for app development.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqbmq/","num_reports":null,"locked":false,"name":"t1_m5tqbmq","created":1736225743,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736225743,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tn69n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"reggionh","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tmejb","score":2,"author_fullname":"t2_66xam","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i dont know the scale of it but people do buy mac minis to host LLMs in their local network. local doesnt always mean on-device.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tn69n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i dont know the scale of it but people do buy mac minis to host LLMs in their local network. local doesnt always mean on-device.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tn69n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224390,"author_flair_text":null,"treatment_tags":[],"created_utc":1736224390,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":1,"name":"t1_m5ydxid","id":"m5ydxid","parent_id":"t1_m5tmejb","depth":2,"children":["m5ydxid"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tmejb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tllh2","score":43,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I don't think Apple has much of a desktop LLM market, their AI appeal is almost entirely laptops that happen to run LLMs well. But their next Ultra chip likely will have more RAM and more RAM throughput than this.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think Apple has much of a desktop LLM market, their AI appeal is almost entirely laptops that happen to run LLMs well. But their next Ultra chip likely will have more RAM and more RAM throughput than this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tmejb/","num_reports":null,"locked":false,"name":"t1_m5tmejb","created":1736224065,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736224065,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uittj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeakBrave8235","can_mod_post":false,"created_utc":1736241941,"send_replies":true,"parent_id":"t1_m5tllh2","score":2,"author_fullname":"t2_t67p3945q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not really? You can spec up to 192 GB and probably 256 with the next M4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uittj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not really? You can spec up to 192 GB and probably 256 with the next M4&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uittj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736241941,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5tqrcl","id":"m5tqrcl","parent_id":"t1_m5tn5or","depth":2,"children":["m5tqrcl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tn5or","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"godVishnu","can_mod_post":false,"created_utc":1736224383,"send_replies":true,"parent_id":"t1_m5tllh2","score":7,"author_fullname":"t2_m9stiqk8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is me. Absolutely don't want mac except for LLM but then deciding between GPU cloud vs this, digits could be potentially a winner","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tn5or","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is me. Absolutely don&amp;#39;t want mac except for LLM but then deciding between GPU cloud vs this, digits could be potentially a winner&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tn5or/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224383,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":8,"name":"t1_m5uv84s","id":"m5uv84s","parent_id":"t1_m5tllh2","depth":1,"children":["m5uv84s","m67h1f9","m5ug15d","m5uivr4","m5vbntw"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tllh2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1736223728,"send_replies":true,"parent_id":"t3_1hvj4wn","score":175,"author_fullname":"t2_s6sfw4yy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is a big deal as the huge 128GB VRAM size will eat into Apple's LLM market. Many people may opt for this instead of 5090 as well. For now, we only know FP16 will be around 125TFLOPS which is around the speed of 3090. VRAM speed is still unknown but if it is around 3090 level or better, it can be a good deal over 5090.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tllh2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a big deal as the huge 128GB VRAM size will eat into Apple&amp;#39;s LLM market. Many people may opt for this instead of 5090 as well. For now, we only know FP16 will be around 125TFLOPS which is around the speed of 3090. VRAM speed is still unknown but if it is around 3090 level or better, it can be a good deal over 5090.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tllh2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223728,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":175}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5umoa5","id":"m5umoa5","parent_id":"t1_m5uhqbn","depth":2,"children":["m5umoa5"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uhqbn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VancityGaming","can_mod_post":false,"created_utc":1736241203,"send_replies":true,"parent_id":"t1_m5tn2n3","score":47,"author_fullname":"t2_oeun0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looking forward to my MSI - Bad Dragon Edition Goonbox.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uhqbn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking forward to my MSI - Bad Dragon Edition Goonbox.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uhqbn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736241203,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":47}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5xjdti","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"spinozasrobot","can_mod_post":false,"created_utc":1736281682,"send_replies":true,"parent_id":"t1_m5tn2n3","score":4,"author_fullname":"t2_3mrdy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; *starting* at $3,000\\n\\nHeh, heh","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5xjdti","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;&lt;em&gt;starting&lt;/em&gt; at $3,000&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Heh, heh&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5xjdti/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736281682,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":1,"name":"t1_m5tqk6c","id":"m5tqk6c","parent_id":"t1_m5tn2n3","depth":1,"children":["m5tqk6c"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tn2n3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kind_bekind","can_mod_post":false,"created_utc":1736224347,"send_replies":true,"parent_id":"t3_1hvj4wn","score":53,"author_fullname":"t2_c3s3hhu","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"**Availability**  \\nProject DIGITS will be available in May from NVIDIA and top partners, starting at $3,000","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tn2n3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;br/&gt;\\nProject DIGITS will be available in May from NVIDIA and top partners, starting at $3,000&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tn2n3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224347,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w97ce","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"space_man_2","can_mod_post":false,"created_utc":1736268281,"send_replies":true,"parent_id":"t1_m5upgvm","score":13,"author_fullname":"t2_bcd7h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"mooooooo","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5w97ce","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;mooooooo&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w97ce/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736268281,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}}],"before":null}},"user_reports":[],"saved":false,"id":"m5upgvm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Bowbowjowjow","can_mod_post":false,"created_utc":1736246297,"send_replies":true,"parent_id":"t3_1hvj4wn","score":60,"author_fullname":"t2_3wf5efvf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=1212&amp;format=pjpg&amp;auto=webp&amp;s=d5de44769085a1d00d1e84e9ae27909a52344ce4","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5upgvm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=1212&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d5de44769085a1d00d1e84e9ae27909a52344ce4\\"&gt;https://preview.redd.it/yfsnzermvjbe1.jpeg?width=1212&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d5de44769085a1d00d1e84e9ae27909a52344ce4&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5upgvm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246297,"media_metadata":{"yfsnzermvjbe1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":80,"x":108,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35c1f5e6f34a65333f1a66000e1aed0fae44e524"},{"y":161,"x":216,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac86794d0101371116e71f1bf2a597f4631a8744"},{"y":239,"x":320,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e2bc69102b7ef46440ad6613e317aae8e8355f5"},{"y":478,"x":640,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72baad01714e0f8877ad959f902cb1a2becede0a"},{"y":717,"x":960,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4b24287c72b6da4b9a4eae0883963f0d8ca9684b"},{"y":807,"x":1080,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3be40af0b33cef006991d77c7ae48b39803c06f6"}],"s":{"y":906,"x":1212,"u":"https://preview.redd.it/yfsnzermvjbe1.jpeg?width=1212&amp;format=pjpg&amp;auto=webp&amp;s=d5de44769085a1d00d1e84e9ae27909a52344ce4"},"id":"yfsnzermvjbe1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":60}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_mfhhsbx","id":"mfhhsbx","parent_id":"t1_m5w6qdb","depth":4,"children":["mfhhsbx","m5yv9tn"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5w6qdb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DavidAdamsAuthor","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5w5enl","score":3,"author_fullname":"t2_763gn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Price will be an issue; 2x 5090's will run you $4k USD, whereas this is $3k.\\n\\nI guess it depends on if you want more ram or faster responses.\\n\\nI'm tempted to change my plan to get a 5090, and instead get a 5070 (which will handle all my gaming needs) and one of these instead for ~~waifus~~ AI work. But I'm not going to mentally commit until I see some benchmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5w6qdb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Price will be an issue; 2x 5090&amp;#39;s will run you $4k USD, whereas this is $3k.&lt;/p&gt;\\n\\n&lt;p&gt;I guess it depends on if you want more ram or faster responses.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m tempted to change my plan to get a 5090, and instead get a 5070 (which will handle all my gaming needs) and one of these instead for &lt;del&gt;waifus&lt;/del&gt; AI work. But I&amp;#39;m not going to mentally commit until I see some benchmarks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w6qdb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736267554,"author_flair_text":null,"treatment_tags":[],"created_utc":1736267554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5w5enl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"greentea05","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vofnx","score":2,"author_fullname":"t2_wa5ut","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah, I'm wondering, will this really be better than two 5090s? I suppose you've got the bigger memory available which is the most useful aspect.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5w5enl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, I&amp;#39;m wondering, will this really be better than two 5090s? I suppose you&amp;#39;ve got the bigger memory available which is the most useful aspect.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w5enl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736267162,"author_flair_text":null,"treatment_tags":[],"created_utc":1736267162,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vofnx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DavidAdamsAuthor","can_mod_post":false,"created_utc":1736261919,"send_replies":true,"parent_id":"t1_m5tok2a","score":39,"author_fullname":"t2_763gn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"As always, bench for waitmarks.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vofnx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;As always, bench for waitmarks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vofnx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736261919,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tok2a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Estrava","can_mod_post":false,"created_utc":1736224982,"send_replies":true,"parent_id":"t3_1hvj4wn","score":40,"author_fullname":"t2_za6aw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Woah. I dont need a 5090. All I want is inference this is huge.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tok2a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Woah. I dont need a 5090. All I want is inference this is huge.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tok2a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224982,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uebuu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"UltrMgns","can_mod_post":false,"created_utc":1736238950,"send_replies":true,"parent_id":"t3_1hvj4wn","score":13,"author_fullname":"t2_nvmilgf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Am I the only one excited about the QSFP ports... stacking those things... The Nvidia data center networking is pretty insane, if this brings those specs at home, it would be an insane opportunity to get this exposure at home at that form factor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uebuu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Am I the only one excited about the QSFP ports... stacking those things... The Nvidia data center networking is pretty insane, if this brings those specs at home, it would be an insane opportunity to get this exposure at home at that form factor.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uebuu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736238950,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vxea1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PMARC14","can_mod_post":false,"created_utc":1736264763,"send_replies":true,"parent_id":"t1_m5vcmuk","score":6,"author_fullname":"t2_1lbp3hj8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How are they going to put 128 GB of ram on a 7800xt? The real counter is a Strix Halo Laptops &amp; Desktops with 128 GB of ram, but it is RDNA3.5, a future update with their newer Unified Architecture (UDNA) would be the real competitor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vxea1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How are they going to put 128 GB of ram on a 7800xt? The real counter is a Strix Halo Laptops &amp;amp; Desktops with 128 GB of ram, but it is RDNA3.5, a future update with their newer Unified Architecture (UDNA) would be the real competitor.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vxea1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736264763,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5w3dgd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noiserr","can_mod_post":false,"created_utc":1736266561,"send_replies":true,"parent_id":"t1_m5vcmuk","score":4,"author_fullname":"t2_2khn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"AMD already announced Strix Halo which will be coming in laptops this quarter. I'm sure we will see mini PC versions of it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5w3dgd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AMD already announced Strix Halo which will be coming in laptops this quarter. I&amp;#39;m sure we will see mini PC versions of it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5w3dgd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736266561,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mb3aqdb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Front-Concert3854","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5wgs0p","score":2,"author_fullname":"t2_br6akiy2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Never is a long time so they may get there but you should purchase hardware based on what it can do now, not some theoretical future situation.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mb3aqdb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Never is a long time so they may get there but you should purchase hardware based on what it can do now, not some theoretical future situation.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/mb3aqdb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738756318,"author_flair_text":null,"treatment_tags":[],"created_utc":1738756318,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wgs0p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"norcalnatv","can_mod_post":false,"created_utc":1736270505,"send_replies":true,"parent_id":"t1_m5vcmuk","score":3,"author_fullname":"t2_12mdhn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Holding hope for AMD is a losing bet in the AI space.   Software will never get there, they have no strategy and want 3rd parties to do all the heavy lifting.  just dumb","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wgs0p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Holding hope for AMD is a losing bet in the AI space.   Software will never get there, they have no strategy and want 3rd parties to do all the heavy lifting.  just dumb&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wgs0p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736270505,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vcmuk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Zyj","can_mod_post":false,"created_utc":1736257705,"send_replies":true,"parent_id":"t3_1hvj4wn","score":13,"author_fullname":"t2_9dnfa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"AMD could counter the \\"NVIDIA Mini\\" by offering something like the 7800 XT (with 624GB/s RAM bandwidth) in a 128GB variant for 2000-2500.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vcmuk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AMD could counter the &amp;quot;NVIDIA Mini&amp;quot; by offering something like the 7800 XT (with 624GB/s RAM bandwidth) in a 128GB variant for 2000-2500.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vcmuk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736257705,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":35,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5xcysb","id":"m5xcysb","parent_id":"t1_m5u5j73","depth":5,"children":["m5xcysb","mb3ayjd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u5j73","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RobbinDeBank","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u3y5m","score":2,"author_fullname":"t2_5dt1knqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So its viable for training too? Or maybe its too slow for training?","edited":false,"author_flair_css_class":null,"name":"t1_m5u5j73","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So its viable for training too? Or maybe its too slow for training?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u5j73/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233471,"author_flair_text":null,"collapsed":false,"created_utc":1736233471,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u3y5m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u3mrr","score":4,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It should be able to do Fp16 at 1/4 speed","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u3y5m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It should be able to do Fp16 at 1/4 speed&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u3y5m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736232561,"author_flair_text":null,"treatment_tags":[],"created_utc":1736232561,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u3mrr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RobbinDeBank","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tnsd3","score":3,"author_fullname":"t2_5dt1knqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is this new computer just solely for 4-bit inference?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u3mrr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this new computer just solely for 4-bit inference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u3mrr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736232380,"author_flair_text":null,"treatment_tags":[],"created_utc":1736232380,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tnsd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1736224654,"send_replies":true,"parent_id":"t1_m5tlyoq","score":24,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"5070 has 988TFLOPS FP4 sparse, so it is likely GB10 is just 5070 with 128GB RAM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tnsd3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;5070 has 988TFLOPS FP4 sparse, so it is likely GB10 is just 5070 with 128GB RAM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tnsd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224654,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":3,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5trcuw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tlyoq","score":3,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Does Lovelace support FP4?","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Does Lovelace support FP4?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5trcuw/","num_reports":null,"locked":false,"name":"t1_m5trcuw","created":1736226201,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736226201,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ty5mq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"learn-deeply","can_mod_post":false,"created_utc":1736229434,"send_replies":true,"parent_id":"t1_m5tlyoq","score":2,"author_fullname":"t2_sfkw0pdx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What are you talking about? 4070 doesn't support fp4.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ty5mq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are you talking about? 4070 doesn&amp;#39;t support fp4.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ty5mq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736229434,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlyoq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1hvj4wn","score":35,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlyoq/","num_reports":null,"locked":false,"name":"t1_m5tlyoq","created":1736223880,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736223880,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uj9wt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__Maximum__","can_mod_post":false,"created_utc":1736242242,"send_replies":true,"parent_id":"t1_m5tsccw","score":6,"author_fullname":"t2_fzqff6k3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nope, they've got 128GB GPU RAM, albeit for 15k. Obviously, there are other advantages and disadvantages as well, but the VRAM will should make the biggest difference when it comes to training and inference.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uj9wt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope, they&amp;#39;ve got 128GB GPU RAM, albeit for 15k. Obviously, there are other advantages and disadvantages as well, but the VRAM will should make the biggest difference when it comes to training and inference.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uj9wt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736242242,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uby2f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Orolol","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u1oeb","score":6,"author_fullname":"t2_fbzx9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For a bigger price.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uby2f","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For a bigger price.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uby2f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736237399,"author_flair_text":null,"treatment_tags":[],"created_utc":1736237399,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u1oeb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"wen_mars","can_mod_post":false,"created_utc":1736231299,"send_replies":true,"parent_id":"t1_m5tsccw","score":12,"author_fullname":"t2_g04t0lxq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not really, a tinybox has much more compute and aggregate memory bandwidth","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u1oeb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not really, a tinybox has much more compute and aggregate memory bandwidth&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u1oeb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736231299,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"more","data":{"count":2,"name":"t1_m5ws79q","id":"m5ws79q","parent_id":"t1_m5tsccw","depth":1,"children":["m5ws79q"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tsccw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Dr_Hayden","can_mod_post":false,"created_utc":1736226648,"send_replies":true,"parent_id":"t3_1hvj4wn","score":31,"author_fullname":"t2_2kzva7fl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So I guess Tinycorp is useless overnight.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tsccw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So I guess Tinycorp is useless overnight.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tsccw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736226648,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":10,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5zd0yl","id":"m5zd0yl","parent_id":"t1_m5utapq","depth":1,"children":["m5zd0yl"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5utapq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1hvj4wn","score":10,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"Very first NVIDIA Product offering I am interested in since the 10th series GPU's.\\n\\n\\nIt will come down to Digits vs Strix Halo Solutions for me. I will pick the price/perf winner of those two.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very first NVIDIA Product offering I am interested in since the 10th series GPU&amp;#39;s.&lt;/p&gt;\\n\\n&lt;p&gt;It will come down to Digits vs Strix Halo Solutions for me. I will pick the price/perf winner of those two.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5utapq/","num_reports":null,"locked":false,"name":"t1_m5utapq","created":1736248638,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736248638,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5zcr9i","id":"m5zcr9i","parent_id":"t1_m5tvlqo","depth":1,"children":["m5zcr9i","m5znmui"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tvlqo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"holdenk","can_mod_post":false,"created_utc":1736228180,"send_replies":true,"parent_id":"t3_1hvj4wn","score":21,"author_fullname":"t2_6bfy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Im suspicious but cautiously optimistic. My experiences with the Jetson devices is the software toolchain is severely lacking.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tvlqo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Im suspicious but cautiously optimistic. My experiences with the Jetson devices is the software toolchain is severely lacking.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tvlqo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736228180,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m60c6pw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"boodleboodle","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5vcevl","score":3,"author_fullname":"t2_mwy6r93","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"We work with DGX at work and updating the OS bricks them. Reseller guys had to come in and fix them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m60c6pw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We work with DGX at work and updating the OS bricks them. Reseller guys had to come in and fix them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m60c6pw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736316470,"author_flair_text":null,"treatment_tags":[],"created_utc":1736316470,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vcevl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"uhuge","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uqoo2","score":7,"author_fullname":"t2_742ne6tg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"so this likely will be possible to flash over for some Arch-based distro or whatnot, but better just a more recent ubuntu where you'd migrate the same drivers","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5vcevl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so this likely will be possible to flash over for some Arch-based distro or whatnot, but better just a more recent ubuntu where you&amp;#39;d migrate the same drivers&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vcevl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736257620,"author_flair_text":null,"treatment_tags":[],"created_utc":1736257620,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":1,"name":"t1_mb3b8dk","id":"mb3b8dk","parent_id":"t1_m5uqoo2","depth":2,"children":["mb3b8dk"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uqoo2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inagy","can_mod_post":false,"created_utc":1736247058,"send_replies":true,"parent_id":"t1_m5u10xj","score":10,"author_fullname":"t2_jfiw6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;DGX OS 6 \\\\[..\\\\] Based on Ubuntu 22.04 with the latest long-term Linux kernel version 5.15\\n\\nIt's not the latest Linux experience by any means, but I guess it'll do. If it can run any of Flatpak/AppImage/Docker, it's livable.","edited":1736263271,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uqoo2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;DGX OS 6 [..] Based on Ubuntu 22.04 with the latest long-term Linux kernel version 5.15&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;It&amp;#39;s not the latest Linux experience by any means, but I guess it&amp;#39;ll do. If it can run any of Flatpak/AppImage/Docker, it&amp;#39;s livable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uqoo2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736247058,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u10xj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ennuiro","can_mod_post":false,"created_utc":1736230946,"send_replies":true,"parent_id":"t3_1hvj4wn","score":19,"author_fullname":"t2_lyr63nxj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it can run mainline linux, it might even make sense as a daily driver","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u10xj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it can run mainline linux, it might even make sense as a daily driver&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u10xj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736230946,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5vc0sr","id":"m5vc0sr","parent_id":"t1_m5ux25t","depth":2,"children":["m5vc0sr"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ux25t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shark_and_kaya","can_mod_post":false,"created_utc":1736250741,"send_replies":true,"parent_id":"t1_m5tlhdt","score":25,"author_fullname":"t2_jga97","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If its is anything like the DGX h100 or DGX a100 servers DGX OS is just NVIDIA flavored Ubuntu. Been using it for years but it is essentially Ubuntu with NVIDIA Support.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ux25t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If its is anything like the DGX h100 or DGX a100 servers DGX OS is just NVIDIA flavored Ubuntu. Been using it for years but it is essentially Ubuntu with NVIDIA Support.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ux25t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736250741,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"more","data":{"count":5,"name":"t1_m5tr9rr","id":"m5tr9rr","parent_id":"t1_m5tlhdt","depth":1,"children":["m5tr9rr"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlhdt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Recoil42","can_mod_post":false,"created_utc":1736223681,"send_replies":true,"parent_id":"t3_1hvj4wn","score":42,"author_fullname":"t2_2kndo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;The system runs on Linux-based Nvidia DGX OS and supports popular frameworks like PyTorch, Python, and Jupyter notebooks.\\n\\nHuh.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tlhdt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The system runs on Linux-based Nvidia DGX OS and supports popular frameworks like PyTorch, Python, and Jupyter notebooks.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Huh.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlhdt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223681,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":42}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":55,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5uiesa","id":"m5uiesa","parent_id":"t1_m5u56rw","depth":3,"children":["m5uiesa"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u56rw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThinkExtension2328","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5to9y9","score":18,"author_fullname":"t2_8eneodlk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can only be chronically so solid ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5u56rw","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can only be chronically so solid &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u56rw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233271,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1736233271,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"m5to9y9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"emprahsFury","can_mod_post":false,"created_utc":1736224861,"send_replies":false,"parent_id":"t1_m5tncaq","score":32,"author_fullname":"t2_177r8n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i certainly hope these will be chronically solid","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5to9y9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i certainly hope these will be chronically solid&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5to9y9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224861,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vbeoj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"iamthewhatt","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uor29","score":7,"author_fullname":"t2_9whlksiz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Which is crazy considering the lack of competition right now. They can produce as much as they possibly can and people will still buy them. 4090 didn't have consistent stock until almost 2 years after launch and it STILL doesn't have competition.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vbeoj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Which is crazy considering the lack of competition right now. They can produce as much as they possibly can and people will still buy them. 4090 didn&amp;#39;t have consistent stock until almost 2 years after launch and it STILL doesn&amp;#39;t have competition.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vbeoj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736257232,"author_flair_text":null,"treatment_tags":[],"created_utc":1736257232,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uor29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"boredquince","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u96pn","score":3,"author_fullname":"t2_nhmpr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a way to keep the hype and high prices","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uor29","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a way to keep the hype and high prices&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uor29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736245839,"author_flair_text":null,"treatment_tags":[],"created_utc":1736245839,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u96pn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MustyMustelidae","can_mod_post":false,"created_utc":1736235670,"send_replies":true,"parent_id":"t1_m5tncaq","score":4,"author_fullname":"t2_ed11z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Chronically sold out because of low production maybe?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u96pn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Chronically sold out because of low production maybe?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u96pn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736235670,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":1,"name":"t1_m5ttai1","id":"m5ttai1","parent_id":"t1_m5tncaq","depth":1,"children":["m5ttai1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tncaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1hvj4wn","score":55,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tncaq/","num_reports":null,"locked":false,"name":"t1_m5tncaq","created":1736224462,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736224462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m8favyf","id":"m8favyf","parent_id":"t1_m5tvqcl","depth":1,"children":["m8favyf"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tvqcl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TechnoTherapist","can_mod_post":false,"created_utc":1736228241,"send_replies":true,"parent_id":"t3_1hvj4wn","score":14,"author_fullname":"t2_69izf2uy2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Great! I honestly can't wait for it to be *game over* for OpenAI and the walled garden empire wanna-be's.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tvqcl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Great! I honestly can&amp;#39;t wait for it to be &lt;em&gt;game over&lt;/em&gt; for OpenAI and the walled garden empire wanna-be&amp;#39;s.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tvqcl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736228241,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uqbm3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheTerrasque","can_mod_post":false,"created_utc":1736246833,"send_replies":true,"parent_id":"t1_m5u6o7l","score":4,"author_fullname":"t2_9uv8v","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; As long as you have enough memory, you can run inference on a potato.\\n\\nAnd remember disk is just very slow memory.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uqbm3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;As long as you have enough memory, you can run inference on a potato.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;And remember disk is just very slow memory.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uqbm3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246833,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u6o7l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MountainGoatAOE","can_mod_post":false,"created_utc":1736234147,"send_replies":true,"parent_id":"t3_1hvj4wn","score":12,"author_fullname":"t2_4xhh78pb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"\\"Sounds good\\" but I am pretty sure the speeds will be abysmal. My guess is also that it's for inference only, and mostly not intended for training.\\n\\nAs long as you have enough memory, you can run inference on a potato. That doesn't mean it will be a good experience...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u6o7l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Sounds good&amp;quot; but I am pretty sure the speeds will be abysmal. My guess is also that it&amp;#39;s for inference only, and mostly not intended for training.&lt;/p&gt;\\n\\n&lt;p&gt;As long as you have enough memory, you can run inference on a potato. That doesn&amp;#39;t mean it will be a good experience...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u6o7l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736234147,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5ujzp2","id":"m5ujzp2","parent_id":"t1_m5ttow9","depth":1,"children":["m5ujzp2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ttow9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ab2377","can_mod_post":false,"created_utc":1736227271,"send_replies":true,"parent_id":"t3_1hvj4wn","score":6,"author_fullname":"t2_144o7g","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"now this is exciting","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ttow9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;now this is exciting&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ttow9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736227271,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5veoyh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jarec707","can_mod_post":false,"created_utc":1736258479,"send_replies":true,"parent_id":"t3_1hvj4wn","score":7,"author_fullname":"t2_mjsmz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sign up for notifications re availability: [https://www.nvidia.com/en-us/project-digits/](https://www.nvidia.com/en-us/project-digits/) Done!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5veoyh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sign up for notifications re availability: &lt;a href=\\"https://www.nvidia.com/en-us/project-digits/\\"&gt;https://www.nvidia.com/en-us/project-digits/&lt;/a&gt; Done!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5veoyh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736258479,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mb555tj","id":"mb555tj","parent_id":"t1_mb3e5jm","depth":3,"children":["mb555tj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mb3e5jm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Front-Concert3854","can_mod_post":false,"send_replies":true,"parent_id":"t1_m604cm9","score":3,"author_fullname":"t2_br6akiy2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You don't need to go that far backwards. The Deep Blue supercomputer by IBM which was released for sale in 1997 had max performance at 11.38 GFLOPS. The Samsung Galaxy S9, released in 2018 had max CPU processing speed at 247 GFLOPs \\\\*and\\\\* GPU processing speed at 727 GFLOPs, so about 1 TFLOPS in a smartphone about 7 years ago, or equivalent to 85 full year 1997 supercomputers!\\n\\nOf course, supercomputers are more about RAM, storage and interconnects. The year 1997 Deep Blue had 30 GB RAM which is a lot more than Samsung S9 has despite the fact that Samsung S9 has 85x the processing power.\\n\\nI'd say it takes about 15 years from supercomputer to high-end smartphone for the processing speed alone and maybe about 20 years for the supercomputer RAM capacity to high-end smartphone.\\n\\n[https://en.wikipedia.org/wiki/Deep\\\\_Blue\\\\_(chess\\\\_computer)](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer))\\n\\n[https://www.anandtech.com/show/12520/the-galaxy-s9-review/6](https://www.anandtech.com/show/12520/the-galaxy-s9-review/6)\\n\\n[https://www.sciencedirect.com/science/article/pii/S0004370201001291/pdf](https://www.sciencedirect.com/science/article/pii/S0004370201001291/pdf)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mb3e5jm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You don&amp;#39;t need to go that far backwards. The Deep Blue supercomputer by IBM which was released for sale in 1997 had max performance at 11.38 GFLOPS. The Samsung Galaxy S9, released in 2018 had max CPU processing speed at 247 GFLOPs *and* GPU processing speed at 727 GFLOPs, so about 1 TFLOPS in a smartphone about 7 years ago, or equivalent to 85 full year 1997 supercomputers!&lt;/p&gt;\\n\\n&lt;p&gt;Of course, supercomputers are more about RAM, storage and interconnects. The year 1997 Deep Blue had 30 GB RAM which is a lot more than Samsung S9 has despite the fact that Samsung S9 has 85x the processing power.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d say it takes about 15 years from supercomputer to high-end smartphone for the processing speed alone and maybe about 20 years for the supercomputer RAM capacity to high-end smartphone.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer\\"&gt;https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)&lt;/a&gt;)&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.anandtech.com/show/12520/the-galaxy-s9-review/6\\"&gt;https://www.anandtech.com/show/12520/the-galaxy-s9-review/6&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.sciencedirect.com/science/article/pii/S0004370201001291/pdf\\"&gt;https://www.sciencedirect.com/science/article/pii/S0004370201001291/pdf&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/mb3e5jm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738757958,"author_flair_text":null,"treatment_tags":[],"created_utc":1738757958,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m604cm9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jarec707","can_mod_post":false,"created_utc":1736312698,"send_replies":true,"parent_id":"t1_m5ytl8p","score":4,"author_fullname":"t2_mjsmz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Apple Watch &gt; NASA 1968","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m604cm9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Apple Watch &amp;gt; NASA 1968&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m604cm9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736312698,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m6t21yx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Amazing_Swimmer9385","can_mod_post":false,"created_utc":1736714997,"send_replies":true,"parent_id":"t1_m5ytl8p","score":3,"author_fullname":"t2_1fhx26qqgu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nvidia loves using deceptive marketing tactics just like claiming a 5070 is just as powerful as a 4090 only with DLSS or something along those lines. Like sure only maybe with the DLSS tech, but it's very misleading. They really tried hiding the actual raw power bc they know it's nothing crazy to overhype for. The fact that they do that, proves those marketing tactics work unfortunately. Luckily I ain't falling for that one","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m6t21yx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nvidia loves using deceptive marketing tactics just like claiming a 5070 is just as powerful as a 4090 only with DLSS or something along those lines. Like sure only maybe with the DLSS tech, but it&amp;#39;s very misleading. They really tried hiding the actual raw power bc they know it&amp;#39;s nothing crazy to overhype for. The fact that they do that, proves those marketing tactics work unfortunately. Luckily I ain&amp;#39;t falling for that one&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m6t21yx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736714997,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mb4ogyt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BigBlueCeiling","can_mod_post":false,"send_replies":true,"parent_id":"t1_mb3ehhx","score":2,"author_fullname":"t2_15uda9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To your point, this would have been a MONUMENTAL machine in 2007 - it would have been #1 on the TOP500 (and maybe still barely edged out or tied the 1PFlop newcomer the following year). But either of my current workstations with A6000 cards in them would have also dominated the list back then, and I dont go around talking about my home supercomputer.\\n\\nI think what bothers me the most about it is that the marketing speech never clarifies it, and everybody writing about it professionally or Reddit/LinkedIn/FB/etc. echoes it, without a hint of skepticism.\\n\\nWhen people think supercomputer they think El Capitan with its 2.7ExaFlops peak performance.\\n\\nHonestly the best thing about this machine may be its power efficiency. Roadrunner - the IBM machine that first broke the 1PFlop limit in 2008 - drew 2.3MW!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mb4ogyt","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To your point, this would have been a MONUMENTAL machine in 2007 - it would have been #1 on the TOP500 (and maybe still barely edged out or tied the 1PFlop newcomer the following year). But either of my current workstations with A6000 cards in them would have also dominated the list back then, and I dont go around talking about my home supercomputer.&lt;/p&gt;\\n\\n&lt;p&gt;I think what bothers me the most about it is that the marketing speech never clarifies it, and everybody writing about it professionally or Reddit/LinkedIn/FB/etc. echoes it, without a hint of skepticism.&lt;/p&gt;\\n\\n&lt;p&gt;When people think supercomputer they think El Capitan with its 2.7ExaFlops peak performance.&lt;/p&gt;\\n\\n&lt;p&gt;Honestly the best thing about this machine may be its power efficiency. Roadrunner - the IBM machine that first broke the 1PFlop limit in 2008 - drew 2.3MW!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/mb4ogyt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738773361,"author_flair_text":"Llama 70B","treatment_tags":[],"created_utc":1738773361,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mb3ehhx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Front-Concert3854","can_mod_post":false,"created_utc":1738758108,"send_replies":true,"parent_id":"t1_m5ytl8p","score":2,"author_fullname":"t2_br6akiy2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think using marketing speech such as \\"supercomputer on your desk\\" makes perfect sense as long as you somehow define the supercomputer you're referring to. If they said \\"year 2010 supercomputer on your desk for $3000\\" that would make perfect sense.\\n\\nOn the other hand, you can say that you have \\"year 2000 supercomputer in your pocket\\" about any modern smartphone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mb3ehhx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think using marketing speech such as &amp;quot;supercomputer on your desk&amp;quot; makes perfect sense as long as you somehow define the supercomputer you&amp;#39;re referring to. If they said &amp;quot;year 2010 supercomputer on your desk for $3000&amp;quot; that would make perfect sense.&lt;/p&gt;\\n\\n&lt;p&gt;On the other hand, you can say that you have &amp;quot;year 2000 supercomputer in your pocket&amp;quot; about any modern smartphone.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/mb3ehhx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738758108,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ytl8p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BigBlueCeiling","can_mod_post":false,"created_utc":1736295757,"send_replies":true,"parent_id":"t3_1hvj4wn","score":6,"author_fullname":"t2_15uda9n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can we please stop calling computers supercomputers?\\n\\nUsing decades old performance profiles to justify nonsensical naming isnt useful. Everything today is a 1990s supercomputer. Your smart thermostat might qualify. There are no $3000 supercomputers.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ytl8p","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can we please stop calling computers supercomputers?&lt;/p&gt;\\n\\n&lt;p&gt;Using decades old performance profiles to justify nonsensical naming isnt useful. Everything today is a 1990s supercomputer. Your smart thermostat might qualify. There are no $3000 supercomputers.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ytl8p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736295757,"author_flair_text":"Llama 70B","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_m60en31","id":"m60en31","parent_id":"t1_m5tqo4n","depth":3,"children":["m60en31","m5tzhx1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tqo4n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"swagonflyyyy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tnu6t","score":23,"author_fullname":"t2_iev1qh7k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ok, change of plans. No more 5090. This...THIS...is what I need.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tqo4n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok, change of plans. No more 5090. This...THIS...is what I need.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqo4n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225897,"author_flair_text":null,"treatment_tags":[],"created_utc":1736225897,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5v7872","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"swagonflyyyy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5ts31w","score":4,"author_fullname":"t2_iev1qh7k","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'd be ok with that bandwidth. My RTX 8000 Quadro has 600 GB/s and it runs LLMs at decent speeds, so I'm sure using that device for fine-tuning shouldn't be a big deal, which is what I want it for anyway.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_m5v7872","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;d be ok with that bandwidth. My RTX 8000 Quadro has 600 GB/s and it runs LLMs at decent speeds, so I&amp;#39;m sure using that device for fine-tuning shouldn&amp;#39;t be a big deal, which is what I want it for anyway.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5v7872/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736255550,"author_flair_text":null,"treatment_tags":[],"created_utc":1736255550,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ts31w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious-Map6957","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tr1rf","score":8,"author_fullname":"t2_7p99opl4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Assuming a 512-bit bus width it should be about 563 GB/s. You are right I suppose it is not that bad but still half the 3090/4090 and a quarter of the H100.\\n\\nGiven the price point it should definetely fill some gaps.","edited":false,"author_flair_css_class":null,"name":"t1_m5ts31w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Assuming a 512-bit bus width it should be about 563 GB/s. You are right I suppose it is not that bad but still half the 3090/4090 and a quarter of the H100.&lt;/p&gt;\\n\\n&lt;p&gt;Given the price point it should definetely fill some gaps.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1hvj4wn","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ts31w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736226531,"author_flair_text":null,"collapsed":false,"created_utc":1736226531,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tr1rf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqtss","score":9,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, we don't know the bandwidth of the memory yet. If it is at the slow end like 546GB/s, it can still allow you to fine tune bigger model than is possible now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tr1rf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, we don&amp;#39;t know the bandwidth of the memory yet. If it is at the slow end like 546GB/s, it can still allow you to fine tune bigger model than is possible now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tr1rf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736226063,"author_flair_text":null,"treatment_tags":[],"created_utc":1736226063,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uqcv2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"inagy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tqtss","score":5,"author_fullname":"t2_jfiw6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it's not a power hog in terms of electricity, I can leave it doing it's job all day long, being not noisy and stuff. At least I don't have a server room or closet dedicated for this :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uqcv2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s not a power hog in terms of electricity, I can leave it doing it&amp;#39;s job all day long, being not noisy and stuff. At least I don&amp;#39;t have a server room or closet dedicated for this :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uqcv2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246855,"author_flair_text":null,"treatment_tags":[],"created_utc":1736246855,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_mb3bim8","id":"mb3bim8","parent_id":"t1_m5tqtss","depth":3,"children":["mb3bim8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tqtss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Conscious-Map6957","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tnu6t","score":11,"author_fullname":"t2_7p99opl4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"how is it ideal with such a slow memory?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5tqtss","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how is it ideal with such a slow memory?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tqtss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225967,"author_flair_text":null,"treatment_tags":[],"created_utc":1736225967,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":2,"name":"t1_m6a6es4","id":"m6a6es4","parent_id":"t1_m5tnu6t","depth":2,"children":["m6a6es4"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tnu6t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1736224676,"send_replies":true,"parent_id":"t1_m5tmzs7","score":22,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes it is the ideal machine to fine tune models at home.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tnu6t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes it is the ideal machine to fine tune models at home.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tnu6t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224676,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tmzs7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"swagonflyyyy","can_mod_post":false,"created_utc":1736224313,"send_replies":true,"parent_id":"t3_1hvj4wn","score":19,"author_fullname":"t2_iev1qh7k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So this is a...way to fine-tune models at home?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tmzs7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So this is a...way to fine-tune models at home?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tmzs7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224313,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":30,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uwc1k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uv9s8","score":11,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Well, you can extrapolate the spec of M2 Ultra and M4 Max to get an educated guess of the spec of M4 Ultra. Based on that, M4 Ultra will have 256GB RAM at 1092GB/s and FP16 at 68.8128TFLOPS. That means bandwidth will likely be double that of GB10 while FP16 is about half. So it is likely that M4 Ultra will double the inference speed of GB10 but for prompt processing it will be half. If you take into account of the CUDA advantage, then GB10 will become more attractive.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uwc1k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, you can extrapolate the spec of M2 Ultra and M4 Max to get an educated guess of the spec of M4 Ultra. Based on that, M4 Ultra will have 256GB RAM at 1092GB/s and FP16 at 68.8128TFLOPS. That means bandwidth will likely be double that of GB10 while FP16 is about half. So it is likely that M4 Ultra will double the inference speed of GB10 but for prompt processing it will be half. If you take into account of the CUDA advantage, then GB10 will become more attractive.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uwc1k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736250353,"author_flair_text":null,"treatment_tags":[],"created_utc":1736250353,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"more","data":{"count":1,"name":"t1_mb3bqad","id":"mb3bqad","parent_id":"t1_m5uv9s8","depth":3,"children":["mb3bqad"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uv9s8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JacketHistorical2321","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tm4uv","score":5,"author_fullname":"t2_bsvkuoyj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"M4 ultra isn't even released so you can't say anything regarding how it would compare.\\n\\nWith a price point of $3k there is zero chance a unified system with 128gb of RAM will be at all comparable to an M4 ultra. The cost of silicon production is fairly standard across all organizations because the tools themselves are generally all sourced by the same manufacturers. I work for one of those manufacturers and they supply around 80% of the entire market share across any company that produces its own silicon","edited":1736249954,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uv9s8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;M4 ultra isn&amp;#39;t even released so you can&amp;#39;t say anything regarding how it would compare.&lt;/p&gt;\\n\\n&lt;p&gt;With a price point of $3k there is zero chance a unified system with 128gb of RAM will be at all comparable to an M4 ultra. The cost of silicon production is fairly standard across all organizations because the tools themselves are generally all sourced by the same manufacturers. I work for one of those manufacturers and they supply around 80% of the entire market share across any company that produces its own silicon&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uv9s8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736249772,"author_flair_text":null,"treatment_tags":[],"created_utc":1736249772,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5v0p0k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5uecsc","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"ofc it will be there, i see this as super powered jetson series, which does have cuda support","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ofc it will be there, i see this as super powered jetson series, which does have cuda support&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5v0p0k/","num_reports":null,"locked":false,"name":"t1_m5v0p0k","created":1736252598,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736252598,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uecsc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"allinasecond","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tm4uv","score":2,"author_fullname":"t2_11jy35","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is there any CUDA advantage for inference?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uecsc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there any CUDA advantage for inference?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uecsc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736238966,"author_flair_text":null,"treatment_tags":[],"created_utc":1736238966,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_m5uj3cx","id":"m5uj3cx","parent_id":"t1_m5tm4uv","depth":2,"children":["m5uj3cx","m5tneik"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tm4uv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Warning2146","can_mod_post":false,"created_utc":1736223952,"send_replies":true,"parent_id":"t1_m5tlve3","score":53,"author_fullname":"t2_s6sfw4yy","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pricing is not bad. Two GB10s will have the same price and RAM size as M4 Ultra but FP16 speed is double that of M4 Ultra. This plus the CUDA advantage, no one will buy the M4 Ultra unless the RAM bandwidth is too slow.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tm4uv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pricing is not bad. Two GB10s will have the same price and RAM size as M4 Ultra but FP16 speed is double that of M4 Ultra. This plus the CUDA advantage, no one will buy the M4 Ultra unless the RAM bandwidth is too slow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tm4uv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736223952,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":53}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vme5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pablogelo","can_mod_post":false,"created_utc":1736261236,"send_replies":true,"parent_id":"t1_m5tlve3","score":9,"author_fullname":"t2_g6a4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Their direct competitor (M2 Ultra, M4 Ultra) charges $4800 when using this much RAM. He's doing it for almost half the price.","edited":1736261775,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vme5x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Their direct competitor (M2 Ultra, M4 Ultra) charges $4800 when using this much RAM. He&amp;#39;s doing it for almost half the price.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vme5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736261236,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tlve3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1hvj4wn","score":30,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I thought he was going to unveil a crazy price like $600","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought he was going to unveil a crazy price like $600&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tlve3/","num_reports":null,"locked":false,"name":"t1_m5tlve3","created":1736223842,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736223842,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m60a0j3","id":"m60a0j3","parent_id":"t1_m5x6nvm","depth":2,"children":["m60a0j3"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5x6nvm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"More-Acadia2355","can_mod_post":false,"created_utc":1736277989,"send_replies":true,"parent_id":"t1_m5tnuui","score":2,"author_fullname":"t2_iom84v7m6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"...as a shareholder: \\"Jensen, stop talking and make my money.\\"","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5x6nvm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...as a shareholder: &amp;quot;Jensen, stop talking and make my money.&amp;quot;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5x6nvm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736277989,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tnuui","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PermanentLiminality","can_mod_post":false,"created_utc":1736224684,"send_replies":true,"parent_id":"t3_1hvj4wn","score":15,"author_fullname":"t2_19zqycaf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jensen, stop talking and take my money.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tnuui","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jensen, stop talking and take my money.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tnuui/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736224684,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5v0e4l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pure-Specialist","can_mod_post":false,"created_utc":1736252447,"send_replies":true,"parent_id":"t1_m5u4pxo","score":4,"author_fullname":"t2_56371zxf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"They let us do it..\\" we are going to pay for the high stock price ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5v0e4l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;They let us do it..&amp;quot; we are going to pay for the high stock price &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5v0e4l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736252447,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"more","data":{"count":1,"name":"t1_mb3bvqc","id":"mb3bvqc","parent_id":"t1_m5u4pxo","depth":1,"children":["mb3bvqc"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u4pxo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sdmat","can_mod_post":false,"created_utc":1736233001,"send_replies":true,"parent_id":"t3_1hvj4wn","score":12,"author_fullname":"t2_7hlsk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"LPDDR costs $5/GB retail. Likely circa $3/GB for Nvidia.\\n\\nSo like Apple they are pricing this with absolutely gratuitous margins.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u4pxo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;LPDDR costs $5/GB retail. Likely circa $3/GB for Nvidia.&lt;/p&gt;\\n\\n&lt;p&gt;So like Apple they are pricing this with absolutely gratuitous margins.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u4pxo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736233001,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5uvz0b","id":"m5uvz0b","parent_id":"t1_m5tr6g8","depth":2,"children":["m5uvz0b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tr6g8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"milo-75","can_mod_post":false,"created_utc":1736226121,"send_replies":true,"parent_id":"t1_m5tpv2d","score":6,"author_fullname":"t2_txewhr0q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is Thor the replacement for Orin? He didnt mention the Thor name when unveiling this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tr6g8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is Thor the replacement for Orin? He didnt mention the Thor name when unveiling this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tr6g8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736226121,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5wh5hj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"norcalnatv","can_mod_post":false,"created_utc":1736270614,"send_replies":true,"parent_id":"t1_m5tpv2d","score":2,"author_fullname":"t2_12mdhn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, it's a new part co-developed with Mediatek, ARM cores and Blackwell GPU.  The replacement for Orin is Thor.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wh5hj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, it&amp;#39;s a new part co-developed with Mediatek, ARM cores and Blackwell GPU.  The replacement for Orin is Thor.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wh5hj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736270614,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tpv2d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Birchi","can_mod_post":false,"created_utc":1736225539,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_121tzw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this the new Orin AGX?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tpv2d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this the new Orin AGX?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tpv2d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225539,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vgazr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Desxon","can_mod_post":false,"created_utc":1736259083,"send_replies":true,"parent_id":"t3_1hvj4wn","score":4,"author_fullname":"t2_ufq7ns","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can it run Crysis ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vgazr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can it run Crysis ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vgazr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736259083,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":4,"removal_reason":null,"link_id":"t3_1hvj4wn","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5y3x5o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Gloomy-Reception8480","can_mod_post":false,"created_utc":1736287577,"send_replies":true,"parent_id":"t1_m5vj9n0","score":2,"author_fullname":"t2_q3ts9eki","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Say you want to run a 70B model that doesn't fit on a RTX 4090 or 5090.  Unclear how fast it will be, but having a much faster memory bus than a normal 128 bit wide PC should really help.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5y3x5o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Say you want to run a 70B model that doesn&amp;#39;t fit on a RTX 4090 or 5090.  Unclear how fast it will be, but having a much faster memory bus than a normal 128 bit wide PC should really help.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5y3x5o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736287577,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vj9n0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1hvj4wn","score":4,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vj9n0/","num_reports":null,"locked":false,"name":"t1_m5vj9n0","created":1736260148,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1736260148,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5zaj24","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"seymores","can_mod_post":false,"created_utc":1736301392,"send_replies":true,"parent_id":"t1_m5z557d","score":3,"author_fullname":"t2_4qom","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Not now, May-June.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5zaj24","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not now, May-June.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5zaj24/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736301392,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5z557d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jerryfappington","can_mod_post":false,"created_utc":1736299570,"send_replies":true,"parent_id":"t3_1hvj4wn","score":3,"author_fullname":"t2_3bfygb1i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is a 128gb M4 useless now?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5z557d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is a 128gb M4 useless now?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5z557d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736299570,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5uqhr2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"inagy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5u72ve","score":3,"author_fullname":"t2_jfiw6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think we'll get anything more specific than this until the May release, unfortunately.\\n\\nI'm really eager to see concrete use case statistics, speed of LLM/VLM with Ollama and also image/video generation with ComfyUI.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5uqhr2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think we&amp;#39;ll get anything more specific than this until the May release, unfortunately.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m really eager to see concrete use case statistics, speed of LLM/VLM with Ollama and also image/video generation with ComfyUI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uqhr2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246940,"author_flair_text":null,"treatment_tags":[],"created_utc":1736246940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u72ve","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fuckingpieceofrice","can_mod_post":false,"created_utc":1736234391,"send_replies":true,"parent_id":"t1_m5tp826","score":20,"author_fullname":"t2_7jtc6wsw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"By the wording in the website, it seems 128GB unified memory is in all of them and the upgrades are mostly in the storage department. But We shouldn't also see too much into the literal meaning in an article of a news website.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u72ve","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By the wording in the website, it seems 128GB unified memory is in all of them and the upgrades are mostly in the storage department. But We shouldn&amp;#39;t also see too much into the literal meaning in an article of a news website.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u72ve/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736234391,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"more","data":{"count":4,"name":"t1_mb3f0ql","id":"mb3f0ql","parent_id":"t1_m5tp826","depth":1,"children":["mb3f0ql","m5vkc0f","m5trar1"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tp826","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NickCanCode","can_mod_post":false,"created_utc":1736225266,"send_replies":true,"parent_id":"t3_1hvj4wn","score":30,"author_fullname":"t2_srx5k6vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"STARTING at $3000...\\nThe base model maybe only have 8GB RAM. XD","edited":1736226236,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tp826","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;STARTING at $3000...\\nThe base model maybe only have 8GB RAM. XD&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tp826/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225266,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":30}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mgfku9j","id":"mgfku9j","parent_id":"t1_m5ups0v","depth":1,"children":["mgfku9j"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5ups0v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"3-4pm","can_mod_post":false,"created_utc":1736246493,"send_replies":true,"parent_id":"t3_1hvj4wn","score":3,"author_fullname":"t2_6ob1kzo0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Due to extreme ignorance I keep expecting a new CPU only breakthrough that will render GPUs obsolete for inference. On the plus side I've saved a lot of money by not purchasing a new system","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ups0v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Due to extreme ignorance I keep expecting a new CPU only breakthrough that will render GPUs obsolete for inference. On the plus side I&amp;#39;ve saved a lot of money by not purchasing a new system&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ups0v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246493,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vg8ht","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"L3Niflheim","can_mod_post":false,"created_utc":1736259057,"send_replies":true,"parent_id":"t3_1hvj4wn","score":3,"author_fullname":"t2_dr7y0h07","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Side note, that jacket is quite something!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vg8ht","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Side note, that jacket is quite something!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vg8ht/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736259057,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m627ou5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JustCheckReadmeFFS","can_mod_post":false,"created_utc":1736350055,"send_replies":true,"parent_id":"t1_m5x2vt6","score":3,"author_fullname":"t2_bh20elrgg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Easy: sudo apt-get install doom-wad-shareware prboom","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m627ou5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Easy: sudo apt-get install doom-wad-shareware prboom&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m627ou5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736350055,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_mb3f4ek","id":"mb3f4ek","parent_id":"t1_m5x2vt6","depth":1,"children":["mb3f4ek"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5x2vt6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Technical_Tactician","can_mod_post":false,"created_utc":1736276887,"send_replies":true,"parent_id":"t3_1hvj4wn","score":3,"author_fullname":"t2_9dy484gq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"But can it run Doom?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5x2vt6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But can it run Doom?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5x2vt6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736276887,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5uedms","id":"m5uedms","parent_id":"t1_m5uasdd","depth":2,"children":["m5uedms","m5ufdmi"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uasdd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThisWillPass","can_mod_post":false,"created_utc":1736236671,"send_replies":true,"parent_id":"t1_m5u9eg1","score":10,"author_fullname":"t2_4mmtr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"210b at q4, 3-5 tokens/sec?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uasdd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;210b at q4, 3-5 tokens/sec?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uasdd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736236671,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"more","data":{"count":3,"name":"t1_m5uwewa","id":"m5uwewa","parent_id":"t1_m5u9eg1","depth":1,"children":["m5uwewa"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5u9eg1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CulturedNiichan","can_mod_post":false,"created_utc":1736235805,"send_replies":true,"parent_id":"t3_1hvj4wn","score":6,"author_fullname":"t2_97k8056i9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can someone translate all of this comment thread into something tangible? I don't care for DDR 5, 6 or 20. I have little idea what the differences are.\\n\\nWhat I think many of us would like to know is just what could be run on such a device. What LLMs could be run with a decent token per second rate, let's say on a Q4 level. 22B? 70B? 200B? 8B? Something that those of us who aren't interested in the technicalities, only in running LLMs locally, can understand.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5u9eg1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can someone translate all of this comment thread into something tangible? I don&amp;#39;t care for DDR 5, 6 or 20. I have little idea what the differences are.&lt;/p&gt;\\n\\n&lt;p&gt;What I think many of us would like to know is just what could be run on such a device. What LLMs could be run with a decent token per second rate, let&amp;#39;s say on a Q4 level. 22B? 70B? 200B? 8B? Something that those of us who aren&amp;#39;t interested in the technicalities, only in running LLMs locally, can understand.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5u9eg1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736235805,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5ufn8g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chanc2","can_mod_post":false,"created_utc":1736239816,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_swb12","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I guess I need to return my Jetson Orin Nano Super.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5ufn8g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I guess I need to return my Jetson Orin Nano Super.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5ufn8g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736239816,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_m5xhvq7","id":"m5xhvq7","parent_id":"t1_m5wj4u1","depth":2,"children":["m5xhvq7"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wj4u1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Fun_Firefighter_7785","can_mod_post":false,"created_utc":1736271194,"send_replies":true,"parent_id":"t1_m5wd4xn","score":2,"author_fullname":"t2_k2imfzu6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"HP's Z2 with latest Intel has 3.2k$ pricetag.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wj4u1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;HP&amp;#39;s Z2 with latest Intel has 3.2k$ pricetag.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wj4u1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736271194,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":2,"name":"t1_mf4ivqo","id":"mf4ivqo","parent_id":"t1_m5wd4xn","depth":1,"children":["mf4ivqo"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wd4xn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cafedude","can_mod_post":false,"created_utc":1736269436,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_23o6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Still waiting to see prices on SFF AMD AI Max systems. It's going to come down to one of those or a Digits looks like.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wd4xn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still waiting to see prices on SFF AMD AI Max systems. It&amp;#39;s going to come down to one of those or a Digits looks like.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wd4xn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736269436,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m627fgm","id":"m627fgm","parent_id":"t1_m5wp2je","depth":1,"children":["m627fgm"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wp2je","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RabbitEater2","can_mod_post":false,"created_utc":1736272905,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_w61xk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can this also run image/video generators using all that RAM?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wp2je","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can this also run image/video generators using all that RAM?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wp2je/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736272905,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_m5wveef","id":"m5wveef","parent_id":"t1_m5wptni","depth":1,"children":["m5wveef","m604ozt"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5wptni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"jnk_str","can_mod_post":false,"created_utc":1736273127,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_5ct4y4k6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Up to 200B Parameters ATM it can not handle Deepseek right?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5wptni","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Up to 200B Parameters ATM it can not handle Deepseek right?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5wptni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736273127,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5x1q24","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FaceDeer","can_mod_post":false,"created_utc":1736276549,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_4ljvm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm thinking a computer like this might be a trial run or \\"learning experience\\" model in preparation for making brains for robots. Compact, modular, capable of sophisticated \\"thought\\" but not focused on the sort of massive throughput that desktop assistants might require. Handy as an onboard source for high-level \\"cognition\\" in a robot that doesn't necessarily always have a cloud connection.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5x1q24","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m thinking a computer like this might be a trial run or &amp;quot;learning experience&amp;quot; model in preparation for making brains for robots. Compact, modular, capable of sophisticated &amp;quot;thought&amp;quot; but not focused on the sort of massive throughput that desktop assistants might require. Handy as an onboard source for high-level &amp;quot;cognition&amp;quot; in a robot that doesn&amp;#39;t necessarily always have a cloud connection.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5x1q24/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736276549,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5yt93h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Independent_Line6673","can_mod_post":false,"created_utc":1736295646,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_17004hkkzk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think the implication is that all/most simple AI LLM model can be run on the laptop and that overcomes the issue of data privacy; but the first adopters will still likely be the tech industry. \\n\\nLook forward to your comments on future.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5yt93h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think the implication is that all/most simple AI LLM model can be run on the laptop and that overcomes the issue of data privacy; but the first adopters will still likely be the tech industry. &lt;/p&gt;\\n\\n&lt;p&gt;Look forward to your comments on future.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5yt93h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736295646,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m611wdi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"model_mial","can_mod_post":false,"created_utc":1736332177,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_p8hcuh363","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I still do not understand the device we can install various os like our windows machine or like Linux??.. disposable I am still thinking these are cheap or it is just like a GPU ??","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m611wdi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I still do not understand the device we can install various os like our windows machine or like Linux??.. disposable I am still thinking these are cheap or it is just like a GPU ??&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m611wdi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736332177,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m9j9omm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"BlazinHotNachoCheese","can_mod_post":false,"created_utc":1738017193,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_8u438p6i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Implications of this product with regard to DeepSeek?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m9j9omm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Implications of this product with regard to DeepSeek?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m9j9omm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1738017193,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5uk3iy","id":"m5uk3iy","parent_id":"t1_m5tpk90","depth":2,"children":["m5uk3iy"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tpk90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Gyroshark","can_mod_post":false,"created_utc":1736225410,"send_replies":true,"parent_id":"t1_m5toxot","score":17,"author_fullname":"t2_d59k0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Did he upgrade to an alligator skin jacket as well?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tpk90","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did he upgrade to an alligator skin jacket as well?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tpk90/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225410,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"m5toxot","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ohtani-Enjoyer","can_mod_post":false,"created_utc":1736225143,"send_replies":true,"parent_id":"t3_1hvj4wn","score":6,"author_fullname":"t2_fybfylcg0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jensen Huang does not miss","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5toxot","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jensen Huang does not miss&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5toxot/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225143,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vy57g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PMARC14","can_mod_post":false,"created_utc":1736264988,"send_replies":true,"parent_id":"t1_m5uq0wo","score":3,"author_fullname":"t2_1lbp3hj8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No idea on the pricing for HP Z2 Mini specced similarly. But it will probably be close in price for 128 GB of VRAM. The AMD chip will be better as a general chip, but I don't think the RDNA 3.5 Architecture is great at AI tasks, only really suitable to inference. It also has likely has less memory bandwidth. The Nvidia Digits will have all the power and performance brought by Nvidia, but for only AI.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vy57g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No idea on the pricing for HP Z2 Mini specced similarly. But it will probably be close in price for 128 GB of VRAM. The AMD chip will be better as a general chip, but I don&amp;#39;t think the RDNA 3.5 Architecture is great at AI tasks, only really suitable to inference. It also has likely has less memory bandwidth. The Nvidia Digits will have all the power and performance brought by Nvidia, but for only AI.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vy57g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736264988,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"more","data":{"count":1,"name":"t1_m5urdpx","id":"m5urdpx","parent_id":"t1_m5uq0wo","depth":1,"children":["m5urdpx"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5uq0wo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"martinerous","can_mod_post":false,"created_utc":1736246647,"send_replies":true,"parent_id":"t3_1hvj4wn","score":4,"author_fullname":"t2_5tp54ey","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The spring will be interesting... This or HP Z2 Mini G1a from AMD? Or even Intel's new rumored 24GB GPU for a budget-friendly solution.\\n\\nAnyway, this means I need to be patient and stick with my 4060 16GB for a few more months.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5uq0wo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The spring will be interesting... This or HP Z2 Mini G1a from AMD? Or even Intel&amp;#39;s new rumored 24GB GPU for a budget-friendly solution.&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, this means I need to be patient and stick with my 4060 16GB for a few more months.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5uq0wo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246647,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mb3firw","id":"mb3firw","parent_id":"t1_m5vfzzm","depth":1,"children":["mb3firw"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5vfzzm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Inevitable-Start-653","can_mod_post":false,"created_utc":1736258970,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_9clwj2hf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A few things I'm noticing, there is no mention of quantization of models being necessary (I suspect quantization will be necessary), loading the model and being able to access the full context are 2 extremely different experiences running a 405b model with 20k context is not good,, they mention 4tb nvme for heavy loads?  Does this mean they are counting on people offloading inference to nvme... because that is really really bad.\\n\\nI'm not trying to put this down as a definite dud, but I think people should be cautious about the claims.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vfzzm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A few things I&amp;#39;m noticing, there is no mention of quantization of models being necessary (I suspect quantization will be necessary), loading the model and being able to access the full context are 2 extremely different experiences running a 405b model with 20k context is not good,, they mention 4tb nvme for heavy loads?  Does this mean they are counting on people offloading inference to nvme... because that is really really bad.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m not trying to put this down as a definite dud, but I think people should be cautious about the claims.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vfzzm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736258970,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"m5vwpi2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AlwaysNever22","can_mod_post":false,"created_utc":1736264554,"send_replies":true,"parent_id":"t3_1hvj4wn","score":3,"author_fullname":"t2_1ds6klhn9k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is the Mac mini of AI","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5vwpi2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the Mac mini of AI&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5vwpi2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736264554,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_m5v3ye9","id":"m5v3ye9","parent_id":"t1_m5upgr8","depth":3,"children":["m5v3ye9"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5upgr8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"quantum_guy","can_mod_post":false,"send_replies":true,"parent_id":"t1_m5tzmil","score":7,"author_fullname":"t2_46axt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You can do CUDA compilation of llama.cpp on ARM. No issue there. I have it running on an Orin device.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_m5upgr8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You can do CUDA compilation of llama.cpp on ARM. No issue there. I have it running on an Orin device.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5upgr8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736246295,"author_flair_text":null,"treatment_tags":[],"created_utc":1736246295,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tzmil","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fallingdowndizzyvr","can_mod_post":false,"created_utc":1736230198,"send_replies":true,"parent_id":"t1_m5tot9o","score":8,"author_fullname":"t2_o65i6kx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; If we can get llama.cpp to run on it, we can link up 3 or more to run DeepSeekv3\\n\\nWhy wouldn't llama.cpp run? With Vulkan llama.cpp runs on pretty much anything. Nvidia has supported Vulkan on their GPUs since there's been a Vulkan to support.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tzmil","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;If we can get llama.cpp to run on it, we can link up 3 or more to run DeepSeekv3&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Why wouldn&amp;#39;t llama.cpp run? With Vulkan llama.cpp runs on pretty much anything. Nvidia has supported Vulkan on their GPUs since there&amp;#39;s been a Vulkan to support.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1hvj4wn","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tzmil/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736230198,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"more","data":{"count":1,"name":"t1_m5ukaqa","id":"m5ukaqa","parent_id":"t1_m5tot9o","depth":1,"children":["m5ukaqa"]}}],"before":null}},"user_reports":[],"saved":false,"id":"m5tot9o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"segmond","can_mod_post":false,"created_utc":1736225090,"send_replies":true,"parent_id":"t3_1hvj4wn","score":2,"author_fullname":"t2_ah13x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If we can get llama.cpp to run on it, we can link up 3 or more to run DeepSeekv3\\n\\nI wish they gave specs, if this has good spec then it's a better buy than 5090's.   But if we decide to wait till May to get 5090's the price will probably have gone upwards.   Decisions abound.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_m5tot9o","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If we can get llama.cpp to run on it, we can link up 3 or more to run DeepSeekv3&lt;/p&gt;\\n\\n&lt;p&gt;I wish they gave specs, if this has good spec then it&amp;#39;s a better buy than 5090&amp;#39;s.   But if we decide to wait till May to get 5090&amp;#39;s the price will probably have gone upwards.   Decisions abound.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1hvj4wn/nvidia_announces_3000_personal_ai_supercomputer/m5tot9o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1736225090,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1hvj4wn","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":114,"name":"t1_m5txqes","id":"m5txqes","parent_id":"t3_1hvj4wn","depth":0,"children":["m5txqes","m5vasnm","m5uuyrw","m5u5f8l","m5u93tc","m5uj0dc","m5wsvrp","m5xw6xn","m5uxbit","m5uy9dh","m653z5j","m5va2wy","m5ubn8f","m5upimz","m5uhi59","m5vt9ys","m5xksqp","m5wzisw","m5x9uxs","m5y3gtt","m5vq2ek","m5zc6ks","m5uyvze","m5v01jk","m66nvve","m6axdgu","m5vakb9","m5ul3gm","m5vizt8","m5vwe63","m5vmbhe","m5x8sd2","m5umt6r","m5uml5d","m5y5e2k","m5yi1mh","m5yp6az","m5zpljb","m60awsj","m60dh9r","m61x3f0","m5xks9k","m69m5o2","m6jrrl8","m5velsx","m5up8si","m5xlof2","m5vnupo","m5upd9q","m5xjm41","m5tz9f0","m5yi9up","m5uuoow","m5ys401","m5u3py7","m5uwxk4","m5zsv9r","m5u4oim","m60dafa","m610ekp","m5uz2pj","m62dgiz","m64hzpz","m5u5aiu","m5v3vw1","m5v3t05","m6a12i8","m5v5mxu","m5tnt1v","m5ukgps","m5vll6t","m5v75r9","m5wkopx","m5vov9s","m5vuu4r","m5tummy","m5xf0l8"]}}],"before":null}}]`),o=()=>e.jsx(l,{data:a});export{o as default};
