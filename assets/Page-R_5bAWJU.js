import{j as e}from"./index-DACS7Nh6.js";import{R as t}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const a=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hi everyone,\\n\\nIf youâ€™ve ever wondered what really happens inside modern vision-language models, hereâ€™s a hands-on look. I profiled the Google Gemma 3n model on an NVIDIA GPU using PyTorch Profiler, asking it to describe a [bee image](https://cdn-lfs.hf.co/datasets/huggingface/documentation-images/8b21ba78250f852ca5990063866b1ace6432521d0251bde7f8de783b22c99a6d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bee.jpg%3B+filename%3D%22bee.jpg%22%3B&amp;response-content-type=image%2Fjpeg&amp;Expires=1751892238&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTg5MjIzOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy84YjIxYmE3ODI1MGY4NTJjYTU5OTAwNjM4NjZiMWFjZTY0MzI1MjFkMDI1MWJkZTdmOGRlNzgzYjIyYzk5YTZkP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&amp;Signature=FWMAYJoqhsk9AHs1%7EyIoOHBmh53A16J6Xyj-vhFVXTW%7EFkL2tRptgpALUSWppQKXjCnJZsnMXtDFcZAvDm-PFgQaK3UycJD%7ElNShdj5yopPA2F5U2gT4wEvXc-AibMF5mUrzeNKxfY56CjsiFWCfKczLZKzV-kfrXZu7t60d4o5ZdY6jmkdeMHMkYmLROTFE-tmPiKqmN7jVcMIdW43xmaEvova9oA4akIqKphaQUUvvVTToqPjILfn2LLhqwH5BgnbAE5OZ9DtreQirvzS75Xhkgi8GN7LEyrX2nt7LSYtS2vv1SfeSmWca8MY0eO7KEqF71jyA5DquPofRkEEesQ__&amp;Key-Pair-Id=K3RPWS32NSSJCE).\\n\\nI visualized the profiling results using [https://ui.perfetto.dev/](https://ui.perfetto.dev/), as shown in the animated GIF below:\\n\\nhttps://i.redd.it/frlijkwkwfbf1.gif\\n\\nAlong the way, I captured and analyzed the key inference phases, including:\\n\\n* **Image feature extraction** with MobileNetV5 (74 msec) - the trace shows theÂ `get_image_features`Â function of Gemma3n ([source](https://github.com/huggingface/transformers/blob/main/src/transformers/models/gemma3n/modular_gemma3n.py#L2253)), which then callsÂ `forward_features`Â in MobileNetV5 ([source](https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/mobilenetv5.py#L535)).\\n\\nhttps://preview.redd.it/afzke1tdxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=899a055b776818546205514b3d9e29fe7dee38cd\\n\\n* **Text decoding** through a stack of Gemma3nTextDecoderLayer layers (142 msec) - a series ofÂ `Gemma3nTextDecoderLayer`Â ([source](https://github.com/huggingface/transformers/blob/ca7e1a3756c022bf31429c452b2f313f043f32de/src/transformers/models/gemma3n/modular_gemma3n.py#L1829)) calls. \\n\\nhttps://preview.redd.it/6hlcdthfxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=833ae582e5eb759a1eba9adbca1841deeba07195\\n\\n* **Token generation** with per-token execution broken down to kernel launches and synchronizations (244 msec total for 10 tokens, \\\\~24 msec per token) \\n\\nhttps://preview.redd.it/xzoilykgxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=16f504610e8821d686d63aa83e255a4feb8dfd60\\n\\nIâ€™ve shared the full code, profiling scripts, and raw trace data, so you can dive in, reproduce the results, and explore the modelâ€™s internals for yourself.\\n\\nðŸ‘‰ [https://github.com/sbnb-io/gemma3n-profiling/](https://github.com/sbnb-io/gemma3n-profiling/)\\n\\nIf youâ€™re looking to better understand how these models run under the hood, this is a solid place to start. Happy to hear your thoughts or suggestions!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Inside Google Gemma 3n: my PyTorch Profiler insights","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":93,"top_awarded_type":null,"hide_score":false,"media_metadata":{"afzke1tdxfbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":63,"x":108,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ab7c72a9f8aecded2f00bc8865097f30de1f41a"},{"y":126,"x":216,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c5fd27400e391a94c665413698945174705ee565"},{"y":187,"x":320,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef80f273e8a85a5cd1d01f44ee262749c08a31fc"},{"y":374,"x":640,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5117d90547b930df9e54b9c3fad506c22ab1ae1"},{"y":561,"x":960,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e54ad763a532de519abd08a38ccb258cbb3afe9e"},{"y":631,"x":1080,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9f230de7d151523eb7f7afe0ba7a0c14cc289199"}],"s":{"y":1684,"x":2880,"u":"https://preview.redd.it/afzke1tdxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=899a055b776818546205514b3d9e29fe7dee38cd"},"id":"afzke1tdxfbf1"},"xzoilykgxfbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":63,"x":108,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2e2122355fbfbcb6b9b2d464564f44993a960c32"},{"y":126,"x":216,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e609249fdb59bad542c85449b2a78c3465e74101"},{"y":186,"x":320,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2dbb6520549df1a735c12b6d087fec3fd66b1ae0"},{"y":373,"x":640,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=37c6afa0444dec946bf9374a87d066d328326a0d"},{"y":560,"x":960,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=437c0bdc061b128e388b18be716b9429178f7fa1"},{"y":630,"x":1080,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1f0dedd282630c6f2624900dcbaefb0083f6c9b4"}],"s":{"y":1680,"x":2880,"u":"https://preview.redd.it/xzoilykgxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=16f504610e8821d686d63aa83e255a4feb8dfd60"},"id":"xzoilykgxfbf1"},"6hlcdthfxfbf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":62,"x":108,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8422541cd17f0ca3eabbe25af102f78e20753810"},{"y":125,"x":216,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fda39ab6b06df9f5722313c7a8740143ba6cdc86"},{"y":186,"x":320,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e508282d7adda78f81122fd502c5493b60fb6e0"},{"y":372,"x":640,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=24aa5fdca1f6c137630e934f1683b90d733f1930"},{"y":559,"x":960,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c9d7b345f4c1081f74cd8f3bebd92e70185c85f"},{"y":629,"x":1080,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=282d3641aa1fcca96fde881e515d063937e64cab"}],"s":{"y":1678,"x":2880,"u":"https://preview.redd.it/6hlcdthfxfbf1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=833ae582e5eb759a1eba9adbca1841deeba07195"},"id":"6hlcdthfxfbf1"},"frlijkwkwfbf1":{"status":"valid","e":"AnimatedImage","m":"image/gif","p":[{"y":60,"x":108,"u":"https://preview.redd.it/frlijkwkwfbf1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=5dfb14b1603aac425c6d93f40f0a8439d49cbd74"},{"y":120,"x":216,"u":"https://preview.redd.it/frlijkwkwfbf1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=dcecc2027058adb2497e67213be0b36b0675aa99"},{"y":178,"x":320,"u":"https://preview.redd.it/frlijkwkwfbf1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=764371ba518a8f078a155b9551e9d63613545b4d"},{"y":357,"x":640,"u":"https://preview.redd.it/frlijkwkwfbf1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=c95aa5bc2293ab6ca18c6aee3c8e1ea90495c999"},{"y":536,"x":960,"u":"https://preview.redd.it/frlijkwkwfbf1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=9703fea076c19d6aeda80b0741f46cbe3cf9dc49"}],"s":{"y":572,"gif":"https://i.redd.it/frlijkwkwfbf1.gif","mp4":"https://preview.redd.it/frlijkwkwfbf1.gif?format=mp4&amp;s=1f394b41d1398d7df12724bb80778958586d4718","x":1024},"id":"frlijkwkwfbf1"}},"name":"t3_1lts4wd","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.95,"author_flair_background_color":null,"ups":72,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_1bwqj3rc","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":72,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=140&amp;height=93&amp;crop=140:93,smart&amp;auto=webp&amp;s=eca88b22fa7d9eb504faf340e3ee26e8f4de7b99","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1751889110,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\\n\\n&lt;p&gt;If youâ€™ve ever wondered what really happens inside modern vision-language models, hereâ€™s a hands-on look. I profiled the Google Gemma 3n model on an NVIDIA GPU using PyTorch Profiler, asking it to describe a &lt;a href=\\"https://cdn-lfs.hf.co/datasets/huggingface/documentation-images/8b21ba78250f852ca5990063866b1ace6432521d0251bde7f8de783b22c99a6d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bee.jpg%3B+filename%3D%22bee.jpg%22%3B&amp;amp;response-content-type=image%2Fjpeg&amp;amp;Expires=1751892238&amp;amp;Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTg5MjIzOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy84YjIxYmE3ODI1MGY4NTJjYTU5OTAwNjM4NjZiMWFjZTY0MzI1MjFkMDI1MWJkZTdmOGRlNzgzYjIyYzk5YTZkP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&amp;amp;Signature=FWMAYJoqhsk9AHs1%7EyIoOHBmh53A16J6Xyj-vhFVXTW%7EFkL2tRptgpALUSWppQKXjCnJZsnMXtDFcZAvDm-PFgQaK3UycJD%7ElNShdj5yopPA2F5U2gT4wEvXc-AibMF5mUrzeNKxfY56CjsiFWCfKczLZKzV-kfrXZu7t60d4o5ZdY6jmkdeMHMkYmLROTFE-tmPiKqmN7jVcMIdW43xmaEvova9oA4akIqKphaQUUvvVTToqPjILfn2LLhqwH5BgnbAE5OZ9DtreQirvzS75Xhkgi8GN7LEyrX2nt7LSYtS2vv1SfeSmWca8MY0eO7KEqF71jyA5DquPofRkEEesQ__&amp;amp;Key-Pair-Id=K3RPWS32NSSJCE\\"&gt;bee image&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;I visualized the profiling results using &lt;a href=\\"https://ui.perfetto.dev/\\"&gt;https://ui.perfetto.dev/&lt;/a&gt;, as shown in the animated GIF below:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://i.redd.it/frlijkwkwfbf1.gif\\"&gt;https://i.redd.it/frlijkwkwfbf1.gif&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Along the way, I captured and analyzed the key inference phases, including:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Image feature extraction&lt;/strong&gt; with MobileNetV5 (74 msec) - the trace shows theÂ &lt;code&gt;get_image_features&lt;/code&gt;Â function of Gemma3n (&lt;a href=\\"https://github.com/huggingface/transformers/blob/main/src/transformers/models/gemma3n/modular_gemma3n.py#L2253\\"&gt;source&lt;/a&gt;), which then callsÂ &lt;code&gt;forward_features&lt;/code&gt;Â in MobileNetV5 (&lt;a href=\\"https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/mobilenetv5.py#L535\\"&gt;source&lt;/a&gt;).&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/afzke1tdxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=899a055b776818546205514b3d9e29fe7dee38cd\\"&gt;https://preview.redd.it/afzke1tdxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=899a055b776818546205514b3d9e29fe7dee38cd&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Text decoding&lt;/strong&gt; through a stack of Gemma3nTextDecoderLayer layers (142 msec) - a series ofÂ &lt;code&gt;Gemma3nTextDecoderLayer&lt;/code&gt;Â (&lt;a href=\\"https://github.com/huggingface/transformers/blob/ca7e1a3756c022bf31429c452b2f313f043f32de/src/transformers/models/gemma3n/modular_gemma3n.py#L1829\\"&gt;source&lt;/a&gt;) calls. &lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/6hlcdthfxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=833ae582e5eb759a1eba9adbca1841deeba07195\\"&gt;https://preview.redd.it/6hlcdthfxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=833ae582e5eb759a1eba9adbca1841deeba07195&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Token generation&lt;/strong&gt; with per-token execution broken down to kernel launches and synchronizations (244 msec total for 10 tokens, ~24 msec per token) &lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/xzoilykgxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16f504610e8821d686d63aa83e255a4feb8dfd60\\"&gt;https://preview.redd.it/xzoilykgxfbf1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16f504610e8821d686d63aa83e255a4feb8dfd60&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Iâ€™ve shared the full code, profiling scripts, and raw trace data, so you can dive in, reproduce the results, and explore the modelâ€™s internals for yourself.&lt;/p&gt;\\n\\n&lt;p&gt;ðŸ‘‰ &lt;a href=\\"https://github.com/sbnb-io/gemma3n-profiling/\\"&gt;https://github.com/sbnb-io/gemma3n-profiling/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;If youâ€™re looking to better understand how these models run under the hood, this is a solid place to start. Happy to hear your thoughts or suggestions!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?auto=webp&amp;s=8a617c5f425011b9032e3def871f80ef48b3de3d","width":5184,"height":3456},"resolutions":[{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6b62e31fc287d856fbed4d44bd158f876184d07","width":108,"height":72},{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=009d89ce6da149457f09c0ffd601a88ca7087204","width":216,"height":144},{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c09c8c426b37fdc09d086fda5ad6aa990ac924ea","width":320,"height":213},{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25644e360804c2abbce6ff1e1b66b61cd330cee0","width":640,"height":426},{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=289bc7531aa89b87a77afa19f270ff97f1097b80","width":960,"height":640},{"url":"https://external-preview.redd.it/iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8d6f69708f742e89f84df2affc8dbc1fb8bb1491","width":1080,"height":720}],"variants":{},"id":"iyG6eCUPhSylmQBjhmsazmQyUh0CUb3n-N54OyLJmm0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lts4wd","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"aospan","discussion_type":null,"num_comments":4,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/","subreddit_subscribers":496034,"created_utc":1751889110,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"body":"Cool, never seen something like this .","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1swrvm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TechnicianHot154","can_mod_post":false,"created_utc":1751894213,"send_replies":true,"parent_id":"t3_1lts4wd","score":8,"author_fullname":"t2_porip5lt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"author_cakeday":true,"edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1swrvm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cool, never seen something like this .&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/n1swrvm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751894213,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lts4wd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1uqm5x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Wooden-Potential2226","can_mod_post":false,"created_utc":1751914117,"send_replies":true,"parent_id":"t3_1lts4wd","score":1,"author_fullname":"t2_9mo23y823","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Impressive!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1uqm5x","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Impressive!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/n1uqm5x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751914117,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lts4wd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1wl3sq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"meatmanek","can_mod_post":false,"created_utc":1751936049,"send_replies":true,"parent_id":"t1_n1v62qz","score":1,"author_fullname":"t2_3s1bp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They have example code for using voice at [https://ai.google.dev/gemma/docs/capabilities/audio#stt](https://ai.google.dev/gemma/docs/capabilities/audio#stt) \\\\-- instead of URLs, you can also use paths to local audio files.\\n\\nIn my testing, Whisper large-v3 does better at transcription though, and is also locally hostable. I was hoping I could include context like acronyms / jargon that might appear in the audio and that would help Gemma 3n -- it does help it with the specific acronyms/jargon you give it, but it also makes other transcription mistakes that Whisper seems to avoid. I\'m planning to play around with having Gemma (or some other local model) inspect the output from Whisper to look for problem areas and then re-transcribe those. (I also need to play around with prompting Whisper; though its prompt is quite limited - 224 tokens.)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1wl3sq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They have example code for using voice at &lt;a href=\\"https://ai.google.dev/gemma/docs/capabilities/audio#stt\\"&gt;https://ai.google.dev/gemma/docs/capabilities/audio#stt&lt;/a&gt; -- instead of URLs, you can also use paths to local audio files.&lt;/p&gt;\\n\\n&lt;p&gt;In my testing, Whisper large-v3 does better at transcription though, and is also locally hostable. I was hoping I could include context like acronyms / jargon that might appear in the audio and that would help Gemma 3n -- it does help it with the specific acronyms/jargon you give it, but it also makes other transcription mistakes that Whisper seems to avoid. I&amp;#39;m planning to play around with having Gemma (or some other local model) inspect the output from Whisper to look for problem areas and then re-transcribe those. (I also need to play around with prompting Whisper; though its prompt is quite limited - 224 tokens.)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lts4wd","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/n1wl3sq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751936049,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1v62qz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"gt_9000","can_mod_post":false,"created_utc":1751919224,"send_replies":true,"parent_id":"t3_1lts4wd","score":1,"author_fullname":"t2_3rnn6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Do you know how to run Gemma 3n with audio input? (Or with audio and text)\\n\\nI want to do audio transcription. Ollama does not seem to support audio.\\n\\nEdit2:\\n\\nOk found example though not very clear.\\n\\nhttps://ai.google.dev/gemma/docs/core/huggingface_inference\\n\\nEdit: OK transformers library can do it, like OP used. But no example code because F U I guess.\\n\\nhttps://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/docs/source/en/model_doc/gemma3n.md\\n\\nhttps://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/src/transformers/models/gemma3n/feature_extraction_gemma3n.py","edited":1751920252,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1v62qz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you know how to run Gemma 3n with audio input? (Or with audio and text)&lt;/p&gt;\\n\\n&lt;p&gt;I want to do audio transcription. Ollama does not seem to support audio.&lt;/p&gt;\\n\\n&lt;p&gt;Edit2:&lt;/p&gt;\\n\\n&lt;p&gt;Ok found example though not very clear.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://ai.google.dev/gemma/docs/core/huggingface_inference\\"&gt;https://ai.google.dev/gemma/docs/core/huggingface_inference&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Edit: OK transformers library can do it, like OP used. But no example code because F U I guess.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/docs/source/en/model_doc/gemma3n.md\\"&gt;https://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/docs/source/en/model_doc/gemma3n.md&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/src/transformers/models/gemma3n/feature_extraction_gemma3n.py\\"&gt;https://github.com/huggingface/transformers/blob/41e865bb8dd373451a4db1874cf25252bdb0a1c6/src/transformers/models/gemma3n/feature_extraction_gemma3n.py&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lts4wd/inside_google_gemma_3n_my_pytorch_profiler/n1v62qz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751919224,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lts4wd","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),d=()=>e.jsx(t,{data:a});export{d as default};
