import{j as e}from"./index-F0NXdzZX.js";import{R as t}from"./RedditPostRenderer-CoEZB1dt.js";import"./index-DrtravXm.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"From the Repo:\\n\\n&gt;Fact-RAR is a symbolic mini-language for writing declarative knowledge in an **LLM-friendly**, **token-efficient**, and **human-readable** format. (Some humans may find it tedious or dense.) It is a mini-language which was inspired by Japanese grammar, low-resource syntax, and programming idioms and syntax.\\n\\nI hope you find benefit from compressing your knowledge in a token-efficient format that LLMs apparently understand without prior knowledge of the spec.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"I Designed an LLM Shorthand Based on Language Attributes, Math and Python","link_flair_richtext":[{"e":"text","t":"Resources"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":70,"top_awarded_type":null,"hide_score":false,"name":"t3_1lp4h7t","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.76,"author_flair_background_color":null,"ups":4,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_b68un","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Resources","can_mod_post":false,"score":4,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=bd30d5d2faf47065b5f98fe3d2788aa91bf381d9","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751383351,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"github.com","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;From the Repo:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Fact-RAR is a symbolic mini-language for writing declarative knowledge in an &lt;strong&gt;LLM-friendly&lt;/strong&gt;, &lt;strong&gt;token-efficient&lt;/strong&gt;, and &lt;strong&gt;human-readable&lt;/strong&gt; format. (Some humans may find it tedious or dense.) It is a mini-language which was inspired by Japanese grammar, low-resource syntax, and programming idioms and syntax.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I hope you find benefit from compressing your knowledge in a token-efficient format that LLMs apparently understand without prior knowledge of the spec.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://github.com/sidewaysthought/fact-rar","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?auto=webp&amp;s=c1c997d2ba3223d011b5f8ab9138d34005f8291c","width":1200,"height":600},"resolutions":[{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f64131dcc862ee413ef14c21f37d360c76dcc84c","width":108,"height":54},{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=49b7522ee1bf892f6672ddf1df49db63a9ea87b4","width":216,"height":108},{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=13ba0da5e0f7b74df6310fd9797a2251f270f823","width":320,"height":160},{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=03423193e5f99a7b14385a26b16c8e15c8211b1a","width":640,"height":320},{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4b796af0355497579f13b48c85abb96e3708c16d","width":960,"height":480},{"url":"https://external-preview.redd.it/S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=103880725007d672d49ca85f69bb1ebfe8aa9e52","width":1080,"height":540}],"variants":{},"id":"S9o0IA1U3pGH6QHTYM7xe67F2sJ2lrkOFphUXXN9Wf0"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ccac2b","id":"1lp4h7t","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"cddelgado","discussion_type":null,"num_comments":2,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lp4h7t/i_designed_an_llm_shorthand_based_on_language/","stickied":false,"url":"https://github.com/sidewaysthought/fact-rar","subreddit_subscribers":493457,"created_utc":1751383351,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0vrhbu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cddelgado","can_mod_post":false,"created_utc":1751427102,"send_replies":true,"parent_id":"t1_n0u11ph","score":2,"author_fullname":"t2_b68un","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"My hope is that people who are in other domains beyond mine (education) can either help to propose and extend to be more inclusive (there are absolutely cases where this isn't adequate) while still adhering to concepts which LLMs have internalized.\\n\\nI can see mathematics, engineering, and medical fields needing extensions or conventions specific to communication. \\n\\nThere is also a need to continue experimenting with different materials to get accurate estimates and find ambiguities. I can say now that literature with a lack of repetition typically compresses by 50%. Where things like news and entertainment compress by 60-70%. \\n\\nI've also noticed that LLMs take the spec and invent their own .... \\"dialects\\". Claude, DeepSeek, GPT-4o and Gemini 2.5 Flash all have different opinions on how to order the information. In the end it doesn't matter because the spec takes advantage of the idea that language is relative in reference.\\n\\nThank you for taking the time to look. As interest is demonstrated, I'll add to the documentation. I made some updates today based on experiments.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0vrhbu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My hope is that people who are in other domains beyond mine (education) can either help to propose and extend to be more inclusive (there are absolutely cases where this isn&amp;#39;t adequate) while still adhering to concepts which LLMs have internalized.&lt;/p&gt;\\n\\n&lt;p&gt;I can see mathematics, engineering, and medical fields needing extensions or conventions specific to communication. &lt;/p&gt;\\n\\n&lt;p&gt;There is also a need to continue experimenting with different materials to get accurate estimates and find ambiguities. I can say now that literature with a lack of repetition typically compresses by 50%. Where things like news and entertainment compress by 60-70%. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve also noticed that LLMs take the spec and invent their own .... &amp;quot;dialects&amp;quot;. Claude, DeepSeek, GPT-4o and Gemini 2.5 Flash all have different opinions on how to order the information. In the end it doesn&amp;#39;t matter because the spec takes advantage of the idea that language is relative in reference.&lt;/p&gt;\\n\\n&lt;p&gt;Thank you for taking the time to look. As interest is demonstrated, I&amp;#39;ll add to the documentation. I made some updates today based on experiments.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lp4h7t","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp4h7t/i_designed_an_llm_shorthand_based_on_language/n0vrhbu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751427102,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0u11ph","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished_Mode170","can_mod_post":false,"created_utc":1751405589,"send_replies":true,"parent_id":"t3_1lp4h7t","score":2,"author_fullname":"t2_4hfmiefj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Awesome; any plans for domain-specific semantics? 📊 🤩","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0u11ph","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Awesome; any plans for domain-specific semantics? 📊 🤩&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lp4h7t/i_designed_an_llm_shorthand_based_on_language/n0u11ph/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751405589,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lp4h7t","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}}]`),r=()=>e.jsx(t,{data:a});export{r as default};
