import{j as e}from"./index-BpC9hjVs.js";import{R as l}from"./RedditPostRenderer-BEo6AnSR.js";import"./index-DwkJHX1_.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Looking for something small but still usable.\\nWhat's your go-to?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What's the smartest tiny LLM you've actually used?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1m4of82","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":176,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_n2kmftzjf","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":176,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1753016677,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking for something small but still usable.\\nWhat&amp;#39;s your go-to?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1m4of82","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Luston03","discussion_type":null,"num_comments":112,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/","subreddit_subscribers":502516,"created_utc":1753016677,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46ccni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"entsnack","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45zwpq","score":11,"author_fullname":"t2_1a48h7vf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"+1, Llama 3.2 3B is very close to 3.1 8B in my tests.\\n\\nQwen3 4B is very good at zero-shot but doesn't fine-tune well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46ccni","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;+1, Llama 3.2 3B is very close to 3.1 8B in my tests.&lt;/p&gt;\\n\\n&lt;p&gt;Qwen3 4B is very good at zero-shot but doesn&amp;#39;t fine-tune well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46ccni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753023831,"author_flair_text":":X:","treatment_tags":[],"created_utc":1753023831,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n461t2r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"simracerman","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45zwpq","score":6,"author_fullname":"t2_vbzgnic","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My exact sentiment for Llama3.2-3B. The previous Llama models were amazing at generalizing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n461t2r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My exact sentiment for Llama3.2-3B. The previous Llama models were amazing at generalizing.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n461t2r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753020389,"author_flair_text":null,"treatment_tags":[],"created_utc":1753020389,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n466w4r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"testuserpk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45zwpq","score":3,"author_fullname":"t2_y9r5wbx2k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I agree with you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n466w4r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree with you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n466w4r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753022079,"author_flair_text":null,"treatment_tags":[],"created_utc":1753022079,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48rz7a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45zwpq","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Fresh from the vision dataset","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48rz7a","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Fresh from the vision dataset&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48rz7a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753050940,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753050940,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4eevi2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"created_utc":1753127678,"send_replies":true,"parent_id":"t1_n4edpat","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"body":"leaving it on will improve tool calling performance so I am not sure why you would want to turn it off unless you need faster responses.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4eevi2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;leaving it on will improve tool calling performance so I am not sure why you would want to turn it off unless you need faster responses.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4eevi2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127678,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4edpat","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeithonKing","can_mod_post":false,"created_utc":1753127345,"send_replies":true,"parent_id":"t1_n4dv6ae","score":1,"author_fullname":"t2_bul2x6po","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Oh u can do that! Wait... let me try... if that works it would actually be great because qwen supports tooling which gemma doesn't","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4edpat","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh u can do that! Wait... let me try... if that works it would actually be great because qwen supports tooling which gemma doesn&amp;#39;t&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4edpat/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127345,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4dv6ae","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4d1847","score":1,"author_fullname":"t2_idqkwio0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"qwen2.5 loses to qwen3 across the board for me.\\n\\ntry turning off the reasoning by adding \\\\\`/no\\\\_think\\\\\` to the prompt if you don't \\"believe\\" in it.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_n4dv6ae","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen2.5 loses to qwen3 across the board for me.&lt;/p&gt;\\n\\n&lt;p&gt;try turning off the reasoning by adding \`/no_think\` to the prompt if you don&amp;#39;t &amp;quot;believe&amp;quot; in it.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4dv6ae/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122084,"author_flair_text":null,"treatment_tags":[],"created_utc":1753122084,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4d1847","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeithonKing","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4byxvz","score":0,"author_fullname":"t2_bul2x6po","approved_by":null,"mod_note":null,"all_awardings":[],"body":"No no... the thing is... qwen starts reasoning... and in my experince reasoning is a scam for these types of tasks... look even qwen2.5:1.5b (older version and lesser param) is working great...","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4d1847","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No no... the thing is... qwen starts reasoning... and in my experince reasoning is a scam for these types of tasks... look even qwen2.5:1.5b (older version and lesser param) is working great...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4d1847/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753113803,"author_flair_text":null,"treatment_tags":[],"created_utc":1753113803,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n4byxvz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4brta6","score":1,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I just have a hard time believing that qwen3 4b is worse than gemma3 4b, gemma is terrible in my experience.\\n\\nu should really give qwen3 another try, and you should also give llama3.2 3b a shot, its a seriously strong model and it generalizes very well.","edited":false,"author_flair_css_class":null,"name":"t1_n4byxvz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just have a hard time believing that qwen3 4b is worse than gemma3 4b, gemma is terrible in my experience.&lt;/p&gt;\\n\\n&lt;p&gt;u should really give qwen3 another try, and you should also give llama3.2 3b a shot, its a seriously strong model and it generalizes very well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4byxvz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753102034,"author_flair_text":null,"collapsed":false,"created_utc":1753102034,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4brta6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PeithonKing","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45zwpq","score":1,"author_fullname":"t2_bul2x6po","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don't what you are using it for... but small models like those I use mostly for some automation tasks I can delegate to... running on my pi5... and I think gemma3 4b does better than qwen3 4b atleast it follows instructions really well given 2-3 examples... tried qwen2.5:1.5B today which also worked quite good... just gemma3 doesn't have tool usage which qwen2.5 has","edited":1753113678,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4brta6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t what you are using it for... but small models like those I use mostly for some automation tasks I can delegate to... running on my pi5... and I think gemma3 4b does better than qwen3 4b atleast it follows instructions really well given 2-3 examples... tried qwen2.5:1.5B today which also worked quite good... just gemma3 doesn&amp;#39;t have tool usage which qwen2.5 has&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4brta6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753099337,"author_flair_text":null,"treatment_tags":[],"created_utc":1753099337,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n45zwpq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45z5wq","score":24,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma 4b is horrible in my experience.\\n\\nGood vision (relative to everything else), but it’s terrible at everything else. It just feels very rigid, overfit, and doesn’t generalize to new scenarios very well.\\n\\nLlama3.2 3b on the other hand, I couldn’t tell the difference between 3.1 8b in 90% of my tests.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n45zwpq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 4b is horrible in my experience.&lt;/p&gt;\\n\\n&lt;p&gt;Good vision (relative to everything else), but it’s terrible at everything else. It just feels very rigid, overfit, and doesn’t generalize to new scenarios very well.&lt;/p&gt;\\n\\n&lt;p&gt;Llama3.2 3b on the other hand, I couldn’t tell the difference between 3.1 8b in 90% of my tests.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45zwpq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019736,"author_flair_text":null,"treatment_tags":[],"created_utc":1753019736,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":24}}],"before":null}},"user_reports":[],"saved":false,"id":"n45z5wq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SnooFoxes6180","can_mod_post":false,"created_utc":1753019476,"send_replies":true,"parent_id":"t1_n45s70f","score":32,"author_fullname":"t2_536xc59m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have better exp w gemma3 4b over llama3.2 3b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45z5wq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have better exp w gemma3 4b over llama3.2 3b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45z5wq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019476,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c5d3j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harsh_khokhariya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4b7zqa","score":1,"author_fullname":"t2_171ciy82e8","approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh, i didn't think about that!, I think I should have tried, that. i was so busy doing many things, i just went with whatever model that did the job. \\n\\n  \\nAnd I Appreciate your Suggestion, \\n\\nI will Definitely try that\\n\\nThanks","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n4c5d3j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh, i didn&amp;#39;t think about that!, I think I should have tried, that. i was so busy doing many things, i just went with whatever model that did the job. &lt;/p&gt;\\n\\n&lt;p&gt;And I Appreciate your Suggestion, &lt;/p&gt;\\n\\n&lt;p&gt;I will Definitely try that&lt;/p&gt;\\n\\n&lt;p&gt;Thanks&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4c5d3j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753104242,"author_flair_text":null,"treatment_tags":[],"created_utc":1753104242,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4b7zqa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mediocre_Leg_754","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4axvsg","score":2,"author_fullname":"t2_z9t0whjda","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do you modify the prompt as well to suit these models that you test? ","edited":false,"author_flair_css_class":null,"name":"t1_n4b7zqa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do you modify the prompt as well to suit these models that you test? &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4b7zqa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753089599,"author_flair_text":null,"collapsed":false,"created_utc":1753089599,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4axvsg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harsh_khokhariya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ale2t","score":1,"author_fullname":"t2_171ciy82e8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"nah, just testing them one by one, just \\"vibe testing\\", which would be the best fit for speed and instruction following, locally!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4axvsg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;nah, just testing them one by one, just &amp;quot;vibe testing&amp;quot;, which would be the best fit for speed and instruction following, locally!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4axvsg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753083685,"author_flair_text":null,"treatment_tags":[],"created_utc":1753083685,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ale2t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mediocre_Leg_754","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46qocz","score":2,"author_fullname":"t2_z9t0whjda","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do you keep trying these many models? Do you use some kind of a tool to test your data on these various models? ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4ale2t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you keep trying these many models? Do you use some kind of a tool to test your data on these various models? &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4ale2t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753076821,"author_flair_text":null,"treatment_tags":[],"created_utc":1753076821,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48rghg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harsh_khokhariya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n487rej","score":3,"author_fullname":"t2_171ciy82e8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i said i have used these models, and from those models, qwen4b and llama 3.2 are the best ones!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48rghg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i said i have used these models, and from those models, qwen4b and llama 3.2 are the best ones!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48rghg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753050759,"author_flair_text":null,"treatment_tags":[],"created_utc":1753050759,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n487rej","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IanAbsentia","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46qocz","score":1,"author_fullname":"t2_1vdfhj1l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do I hello world whatever you’re talkin’ ‘bout?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n487rej","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do I hello world whatever you’re talkin’ ‘bout?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n487rej/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753044357,"author_flair_text":null,"treatment_tags":[],"created_utc":1753044357,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n46qocz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harsh_khokhariya","can_mod_post":false,"created_utc":1753028208,"send_replies":true,"parent_id":"t1_n45s70f","score":11,"author_fullname":"t2_171ciy82e8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"currently i have these models, :\\n\\nqwen4b8k:latest           \\n\\nqwen68k:latest            \\n\\nqwen4b16k:latest           \\n\\nqwen4b:latest              \\n\\nqwen3:0.6b                 \\n\\ngemma3:latest               \\n\\nphi4-mini:latest           \\n\\ngranite3.2:2b              \\n\\ndeep1.58k:latest           \\n\\ndeepseek8k:latest          \\n\\nexa8k:latest               \\n\\ndeep4k:latest              \\n\\ndeep8k:latest              \\n\\nexaone:latest              \\n\\ndeephermes:latest          \\n\\nllama1b4k:latest           \\n\\nllama3.2:1b                \\n\\ndeepseek:latest            \\n\\nllama8k:latest             \\n\\nsmol:latest                \\n\\ntiny:latest                \\n\\nphi3.5mini:latest                 \\n\\nllama:latest               \\n\\ndeepseek-r1:1.5b           \\n\\nmoondream:latest           \\n\\nnomic-embed-text:latest    \\n\\n\\n\\nbut i rarely use most of them, \\n\\n  \\nqwen4b8k for function calling, and other tasks, i tried gemma, but it was chatty, and couldn't follow instructions properly, not as much as qwen4b. also when i dont want quick responses, i like to use deephermes model, with thinking prompt.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46qocz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;currently i have these models, :&lt;/p&gt;\\n\\n&lt;p&gt;qwen4b8k:latest           &lt;/p&gt;\\n\\n&lt;p&gt;qwen68k:latest            &lt;/p&gt;\\n\\n&lt;p&gt;qwen4b16k:latest           &lt;/p&gt;\\n\\n&lt;p&gt;qwen4b:latest              &lt;/p&gt;\\n\\n&lt;p&gt;qwen3:0.6b                 &lt;/p&gt;\\n\\n&lt;p&gt;gemma3:latest               &lt;/p&gt;\\n\\n&lt;p&gt;phi4-mini:latest           &lt;/p&gt;\\n\\n&lt;p&gt;granite3.2:2b              &lt;/p&gt;\\n\\n&lt;p&gt;deep1.58k:latest           &lt;/p&gt;\\n\\n&lt;p&gt;deepseek8k:latest          &lt;/p&gt;\\n\\n&lt;p&gt;exa8k:latest               &lt;/p&gt;\\n\\n&lt;p&gt;deep4k:latest              &lt;/p&gt;\\n\\n&lt;p&gt;deep8k:latest              &lt;/p&gt;\\n\\n&lt;p&gt;exaone:latest              &lt;/p&gt;\\n\\n&lt;p&gt;deephermes:latest          &lt;/p&gt;\\n\\n&lt;p&gt;llama1b4k:latest           &lt;/p&gt;\\n\\n&lt;p&gt;llama3.2:1b                &lt;/p&gt;\\n\\n&lt;p&gt;deepseek:latest            &lt;/p&gt;\\n\\n&lt;p&gt;llama8k:latest             &lt;/p&gt;\\n\\n&lt;p&gt;smol:latest                &lt;/p&gt;\\n\\n&lt;p&gt;tiny:latest                &lt;/p&gt;\\n\\n&lt;p&gt;phi3.5mini:latest                 &lt;/p&gt;\\n\\n&lt;p&gt;llama:latest               &lt;/p&gt;\\n\\n&lt;p&gt;deepseek-r1:1.5b           &lt;/p&gt;\\n\\n&lt;p&gt;moondream:latest           &lt;/p&gt;\\n\\n&lt;p&gt;nomic-embed-text:latest    &lt;/p&gt;\\n\\n&lt;p&gt;but i rarely use most of them, &lt;/p&gt;\\n\\n&lt;p&gt;qwen4b8k for function calling, and other tasks, i tried gemma, but it was chatty, and couldn&amp;#39;t follow instructions properly, not as much as qwen4b. also when i dont want quick responses, i like to use deephermes model, with thinking prompt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46qocz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753028208,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4a3i84","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedLordezhVenom","can_mod_post":false,"created_utc":1753068519,"send_replies":true,"parent_id":"t1_n45s70f","score":3,"author_fullname":"t2_3y6qg05j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I used the 0.6b version, and honestly , it's just as awesome, stopped using gemma (qwen3 0.6 was better than gemma3 and 3n)!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a3i84","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I used the 0.6b version, and honestly , it&amp;#39;s just as awesome, stopped using gemma (qwen3 0.6 was better than gemma3 and 3n)!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4a3i84/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753068519,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4axnc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"harsh_khokhariya","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4all10","score":1,"author_fullname":"t2_171ciy82e8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"i tested them for making an ai agent, so i just used my laptop with ryzen 5600h, and rtx 3050 laptop gpu, and i mostly run them using laptop because i want my agent to run locally, and when i want to test online inference, i mostly use groq and cerebras, and i love the speed cerebras offers!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4axnc4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i tested them for making an ai agent, so i just used my laptop with ryzen 5600h, and rtx 3050 laptop gpu, and i mostly run them using laptop because i want my agent to run locally, and when i want to test online inference, i mostly use groq and cerebras, and i love the speed cerebras offers!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4axnc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753083550,"author_flair_text":null,"treatment_tags":[],"created_utc":1753083550,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4all10","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mediocre_Leg_754","can_mod_post":false,"created_utc":1753076921,"send_replies":true,"parent_id":"t1_n45s70f","score":2,"author_fullname":"t2_z9t0whjda","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Where do you run it for fast inference? ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4all10","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Where do you run it for fast inference? &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4all10/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753076921,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n45s70f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"harsh_khokhariya","can_mod_post":false,"created_utc":1753016946,"send_replies":true,"parent_id":"t3_1m4of82","score":129,"author_fullname":"t2_171ciy82e8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"qwen3 4b does the job, before that llama 3.2 3b was my favourite","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45s70f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen3 4b does the job, before that llama 3.2 3b was my favourite&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45s70f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753016946,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":129}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45zlrw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eden1506","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45ycyo","score":21,"author_fullname":"t2_2ezqqypt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The abliteration process makes the model unable to say no by removing certain layers responsible for denial and judgement.\\n\\nYou will never get a denial from them but they suffer from losing those layers. \\n\\n\\nIts better to find a gemma 4b model that was finetuned to be less restrictive.\\n\\nIt might still say no occasionally but after rerolling the answer it will most often answer.","edited":1753019819,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n45zlrw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The abliteration process makes the model unable to say no by removing certain layers responsible for denial and judgement.&lt;/p&gt;\\n\\n&lt;p&gt;You will never get a denial from them but they suffer from losing those layers. &lt;/p&gt;\\n\\n&lt;p&gt;Its better to find a gemma 4b model that was finetuned to be less restrictive.&lt;/p&gt;\\n\\n&lt;p&gt;It might still say no occasionally but after rerolling the answer it will most often answer.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45zlrw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019630,"author_flair_text":null,"treatment_tags":[],"created_utc":1753019630,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}}],"before":null}},"user_reports":[],"saved":false,"id":"n45ycyo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Luston03","can_mod_post":false,"created_utc":1753019195,"send_replies":true,"parent_id":"t1_n45wp17","score":6,"author_fullname":"t2_n2kmftzjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What do you sugget for uncensored but not dumb models? I dont know why uncensored versions of llama dumber than normal version","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45ycyo","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What do you sugget for uncensored but not dumb models? I dont know why uncensored versions of llama dumber than normal version&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45ycyo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019195,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49gdxt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"OrbMan99","can_mod_post":false,"created_utc":1753059683,"send_replies":true,"parent_id":"t1_n45wp17","score":3,"author_fullname":"t2_4mqay","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;\\nYou can run them on your phone via google ai edge gallery app on github.\\n\\nWhich blows my mind! Sometimes I'm at the cottage with no internet or cell signal, and I can't believe the amount of information contained in those tiny models. Still really useful for coding, fact checking, brainstorming. And it's quite fast!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49gdxt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;You can run them on your phone via google ai edge gallery app on github.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Which blows my mind! Sometimes I&amp;#39;m at the cottage with no internet or cell signal, and I can&amp;#39;t believe the amount of information contained in those tiny models. Still really useful for coding, fact checking, brainstorming. And it&amp;#39;s quite fast!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49gdxt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753059683,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n45wp17","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Eden1506","can_mod_post":false,"created_utc":1753018606,"send_replies":true,"parent_id":"t3_1m4of82","score":39,"author_fullname":"t2_2ezqqypt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma 3n e2b &amp; gemma 3n e4b are great for their size but very censored. \\n\\nYou can run them on your phone via google ai edge gallery app on github.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45wp17","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma 3n e2b &amp;amp; gemma 3n e4b are great for their size but very censored. &lt;/p&gt;\\n\\n&lt;p&gt;You can run them on your phone via google ai edge gallery app on github.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45wp17/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018606,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":39}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4b633h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"z_3454_pfk","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4a5pqg","score":2,"author_fullname":"t2_askwa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"gemini models are huge so you’ll need the hardware to produce results like that. you can still get 90% with qwen models.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4b633h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemini models are huge so you’ll need the hardware to produce results like that. you can still get 90% with qwen models.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4b633h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753088476,"author_flair_text":null,"treatment_tags":[],"created_utc":1753088476,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4c27qn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Expensive-Apricot-25","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4a5pqg","score":1,"author_fullname":"t2_idqkwio0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"if u use the ollama api, u can force the model to fill in a pre-defined json structure.\\n\\nalthough i dont think it works with thinking models (ie, it places tokens in the response which overwrites the thinking tokens with the json schema)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4c27qn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;if u use the ollama api, u can force the model to fill in a pre-defined json structure.&lt;/p&gt;\\n\\n&lt;p&gt;although i dont think it works with thinking models (ie, it places tokens in the response which overwrites the thinking tokens with the json schema)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4c27qn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753103177,"author_flair_text":null,"treatment_tags":[],"created_utc":1753103177,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4a5pqg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedLordezhVenom","can_mod_post":false,"created_utc":1753069448,"send_replies":true,"parent_id":"t1_n45s163","score":2,"author_fullname":"t2_3y6qg05j","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"oh, just when I was testing both !  \\n  \\nI want a local LLM to better understand context,   \\nlike classifying several items into a specific format  \\nbut qwen0.6b couldn't do it, it generated a structure, but that was literally what I wanted the json to look like\\n\\ngemini (API) gives me a good json structure after classifying into several topics, I want that , locally.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4a5pqg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;oh, just when I was testing both !  &lt;/p&gt;\\n\\n&lt;p&gt;I want a local LLM to better understand context,&lt;br/&gt;\\nlike classifying several items into a specific format&lt;br/&gt;\\nbut qwen0.6b couldn&amp;#39;t do it, it generated a structure, but that was literally what I wanted the json to look like&lt;/p&gt;\\n\\n&lt;p&gt;gemini (API) gives me a good json structure after classifying into several topics, I want that , locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4a5pqg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753069448,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4ase2q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"andreasntr","can_mod_post":false,"created_utc":1753080590,"send_replies":true,"parent_id":"t1_n45s163","score":2,"author_fullname":"t2_k93afr7ze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen 0.6 is just spitting garbage when used for function calling in my simple tests, 1.7 is truly better at that task","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ase2q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 0.6 is just spitting garbage when used for function calling in my simple tests, 1.7 is truly better at that task&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4ase2q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753080590,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n45s163","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"z_3454_pfk","can_mod_post":false,"created_utc":1753016885,"send_replies":true,"parent_id":"t3_1m4of82","score":54,"author_fullname":"t2_askwa","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Prob Qwen3 1.7b, 0.6b is only good for &lt;1k context","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45s163","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Prob Qwen3 1.7b, 0.6b is only good for &amp;lt;1k context&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45s163/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753016885,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n470pdr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vegatx40","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46vcq4","score":3,"author_fullname":"t2_18dhiarv40","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you I will definitely do that. \\n\\nI must admit I find myself browsing the RTX pro 6000 with 96 gig of VRAM. Only $10,000 as opposed to 30,000 for an h100","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n470pdr","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you I will definitely do that. &lt;/p&gt;\\n\\n&lt;p&gt;I must admit I find myself browsing the RTX pro 6000 with 96 gig of VRAM. Only $10,000 as opposed to 30,000 for an h100&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n470pdr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031213,"author_flair_text":null,"treatment_tags":[],"created_utc":1753031213,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n46vcq4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Regular_Wonder_1350","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46umku","score":2,"author_fullname":"t2_40tlq98b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I am jealous.. I have an \\"old\\" 1080TI, on a old i7.. so I kinda crawl.   You might want to take a look at Qwen2.5-VL, as well.. it's very capable!","edited":false,"author_flair_css_class":null,"name":"t1_n46vcq4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am jealous.. I have an &amp;quot;old&amp;quot; 1080TI, on a old i7.. so I kinda crawl.   You might want to take a look at Qwen2.5-VL, as well.. it&amp;#39;s very capable!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46vcq4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029627,"author_flair_text":null,"collapsed":false,"created_utc":1753029627,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n46umku","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vegatx40","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46673m","score":4,"author_fullname":"t2_18dhiarv40","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm almost glad that my plot to use a spare rtx4090 didn't pan out and I'm stuck with just the one. I had been obsessed with llama 3 70 B but now I'm so done with it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46umku","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m almost glad that my plot to use a spare rtx4090 didn&amp;#39;t pan out and I&amp;#39;m stuck with just the one. I had been obsessed with llama 3 70 B but now I&amp;#39;m so done with it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46umku/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029408,"author_flair_text":null,"treatment_tags":[],"created_utc":1753029408,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n46673m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Regular_Wonder_1350","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45y217","score":7,"author_fullname":"t2_40tlq98b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"it really is, it has wonderful alignment, even without a system prompt and without a goal","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46673m","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;it really is, it has wonderful alignment, even without a system prompt and without a goal&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46673m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021849,"author_flair_text":null,"treatment_tags":[],"created_utc":1753021849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47ribu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Not4Fame","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45y217","score":1,"author_fullname":"t2_9vjlnmv0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I was totally on that boat, until Qwen3 dropped...","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47ribu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was totally on that boat, until Qwen3 dropped...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47ribu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753039290,"author_flair_text":null,"treatment_tags":[],"created_utc":1753039290,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n45y217","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vegatx40","can_mod_post":false,"created_utc":1753019090,"send_replies":true,"parent_id":"t1_n45vv78","score":12,"author_fullname":"t2_18dhiarv40","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Gemma3 is fabulous in all sizes! My go-to","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45y217","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma3 is fabulous in all sizes! My go-to&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45y217/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019090,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49z59j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Regular_Wonder_1350","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49t94u","score":1,"author_fullname":"t2_40tlq98b","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have experience with Qwen 2.5 VL, and it is very good, so I imagine that the Qwen 3 is even better.  I had limited compute, so the 4b, was the best option, but I really the 12b or 27b, are so much better. The 4b has some odd \\"action-identification\\" with it, I've found. It confuses things that it does and what I do. Example prompt: \\"Create a summary and I will save it to a text file\\". Output: \\\\*summary, and I will save it to a text file\\".   12b did not have that issue.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n49z59j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have experience with Qwen 2.5 VL, and it is very good, so I imagine that the Qwen 3 is even better.  I had limited compute, so the 4b, was the best option, but I really the 12b or 27b, are so much better. The 4b has some odd &amp;quot;action-identification&amp;quot; with it, I&amp;#39;ve found. It confuses things that it does and what I do. Example prompt: &amp;quot;Create a summary and I will save it to a text file&amp;quot;. Output: *summary, and I will save it to a text file&amp;quot;.   12b did not have that issue.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49z59j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066758,"author_flair_text":null,"treatment_tags":[],"created_utc":1753066758,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49t94u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SkyFeistyLlama8","can_mod_post":false,"created_utc":1753064481,"send_replies":true,"parent_id":"t1_n45vv78","score":1,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How do you find it compared to Qwen 3 4B with thinking turned off?\\n\\nI've been using Gemma 3 4B for a lot of simpler classification and summarization tasks. It's pretty good with simpler zero-shot and one-shot prompts. I find Qwen 4B to be better at tool calling but I rarely use it much because Gemma 4B has much better multilingual capabilities.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49t94u","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How do you find it compared to Qwen 3 4B with thinking turned off?&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve been using Gemma 3 4B for a lot of simpler classification and summarization tasks. It&amp;#39;s pretty good with simpler zero-shot and one-shot prompts. I find Qwen 4B to be better at tool calling but I rarely use it much because Gemma 4B has much better multilingual capabilities.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49t94u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753064481,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n45vv78","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Regular_Wonder_1350","can_mod_post":false,"created_utc":1753018305,"send_replies":true,"parent_id":"t3_1m4of82","score":34,"author_fullname":"t2_40tlq98b","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3 4b, my beloved :) The 1b is ok, if you can read broken english. :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45vv78","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3 4b, my beloved :) The 1b is ok, if you can read broken english. :)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45vv78/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018305,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47fgyl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"danigoncalves","can_mod_post":false,"created_utc":1753035559,"send_replies":true,"parent_id":"t1_n45x92e","score":4,"author_fullname":"t2_6d2qv6jc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How does it compare with Qwen coder 2.5 3B? (I have been using that one)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47fgyl","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How does it compare with Qwen coder 2.5 3B? (I have been using that one)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47fgyl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035559,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n45x92e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"molbal","can_mod_post":false,"created_utc":1753018805,"send_replies":true,"parent_id":"t3_1m4of82","score":15,"author_fullname":"t2_g1srl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3 1.7b for the instant one liner autocompletion in Jetbrain IDEs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45x92e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 1.7b for the instant one liner autocompletion in Jetbrain IDEs&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45x92e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018805,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"41af45de-fdc0-11ee-a05e-8227e0534943","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46urk4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Weird-Consequence366","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46lwi9","score":5,"author_fullname":"t2_f55dbowo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Probably. One way to find out.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46urk4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably. One way to find out.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46urk4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029450,"author_flair_text":null,"treatment_tags":[],"created_utc":1753029450,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n46lwi9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bwjxjelsbd","can_mod_post":false,"created_utc":1753026754,"send_replies":true,"parent_id":"t1_n45z1my","score":3,"author_fullname":"t2_lurv0xw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can this run on phone?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46lwi9","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 8B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can this run on phone?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46lwi9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753026754,"author_flair_text":"Llama 8B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n45z1my","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Weird-Consequence366","can_mod_post":false,"created_utc":1753019434,"send_replies":true,"parent_id":"t3_1m4of82","score":12,"author_fullname":"t2_f55dbowo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Moondream and SmolVLM","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45z1my","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Moondream and SmolVLM&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45z1my/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019434,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"2b12e2b8-fdc0-11ee-9a03-6e2f48afd456","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4657gi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kryptkpr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45typu","score":7,"author_fullname":"t2_30i1a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Using the chat template included with the model.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4657gi","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Using the chat template included with the model.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4657gi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021526,"author_flair_text":"Llama 3","treatment_tags":[],"created_utc":1753021526,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}}],"before":null}},"user_reports":[],"saved":false,"id":"n45typu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rwitz4","can_mod_post":false,"send_replies":true,"parent_id":"t1_n45tff7","score":5,"author_fullname":"t2_1b4pne9v7k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you using the correct chat format?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n45typu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you using the correct chat format?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45typu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753017606,"author_flair_text":null,"treatment_tags":[],"created_utc":1753017606,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n45tff7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kryptkpr","can_mod_post":false,"created_utc":1753017407,"send_replies":true,"parent_id":"t1_n45s8ok","score":15,"author_fullname":"t2_30i1a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can't get phi-4-mini-reasoning to do much of anything useful, it scores pitifully in my evaluations - any tips?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45tff7","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can&amp;#39;t get phi-4-mini-reasoning to do much of anything useful, it scores pitifully in my evaluations - any tips?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45tff7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753017407,"author_flair_text":"Llama 3","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#c7b594","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":15}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46mpxl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ikkiyikki","can_mod_post":false,"created_utc":1753027001,"send_replies":true,"parent_id":"t1_n45s8ok","score":8,"author_fullname":"t2_f8icj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Phi is the only &lt;30B model that can recite Shakespeare opening lines without hallucinating, which suggests better at RL facts in general.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46mpxl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi is the only &amp;lt;30B model that can recite Shakespeare opening lines without hallucinating, which suggests better at RL facts in general.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46mpxl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753027001,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n45s8ok","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rwitz4","can_mod_post":false,"created_utc":1753016964,"send_replies":true,"parent_id":"t3_1m4of82","score":21,"author_fullname":"t2_1b4pne9v7k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3-4B or Phi-4-mini-reasoning","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45s8ok","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3-4B or Phi-4-mini-reasoning&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45s8ok/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753016964,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":21}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45ym8n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1753019285,"send_replies":true,"parent_id":"t3_1m4of82","score":9,"author_fullname":"t2_i5os0v0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Gemma 3 1B if you mean tiny tiny, Phi 4B if you mean small.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45ym8n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Gemma 3 1B if you mean tiny tiny, Phi 4B if you mean small.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45ym8n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019285,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n472tvz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Ninja7526","can_mod_post":false,"send_replies":true,"parent_id":"t1_n46zyrc","score":5,"author_fullname":"t2_ti5m9mpc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try lfm2-1.2b","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n472tvz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try lfm2-1.2b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n472tvz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753031837,"author_flair_text":null,"treatment_tags":[],"created_utc":1753031837,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n46zyrc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Luston03","can_mod_post":false,"created_utc":1753030995,"send_replies":true,"parent_id":"t1_n46uez3","score":6,"author_fullname":"t2_n2kmftzjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah it's really surprising o3 mini level I never saw about that in anywhere however I asked for small llm, thanks for advice","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46zyrc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah it&amp;#39;s really surprising o3 mini level I never saw about that in anywhere however I asked for small llm, thanks for advice&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46zyrc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753030995,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47eymm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"created_utc":1753035404,"send_replies":true,"parent_id":"t1_n46uez3","score":3,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Isn’t phi-4-reasoning-plus a 14b model?\\n\\n\\nI mean I know there is no official definition of what tiny, small, large etc is.\\n\\n\\nBut I personally wouldn’t consider 14b as tiny and as you can see in the comments, most users' view of what tiny is seem to be maximum ~4b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47eymm","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn’t phi-4-reasoning-plus a 14b model?&lt;/p&gt;\\n\\n&lt;p&gt;I mean I know there is no official definition of what tiny, small, large etc is.&lt;/p&gt;\\n\\n&lt;p&gt;But I personally wouldn’t consider 14b as tiny and as you can see in the comments, most users&amp;#39; view of what tiny is seem to be maximum ~4b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47eymm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035404,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n46uez3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Ninja7526","can_mod_post":false,"created_utc":1753029345,"send_replies":true,"parent_id":"t3_1m4of82","score":7,"author_fullname":"t2_ti5m9mpc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Phi-4-reasoning-plus le goat !","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46uez3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi-4-reasoning-plus le goat !&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46uez3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029345,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48q4e8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Evening_Ad6637","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47j7cj","score":1,"author_fullname":"t2_p45er6oo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow this sounds truly interesting! I would really like to read the results of your work or the entire work as soon as it is finished. Would that be possible?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48q4e8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow this sounds truly interesting! I would really like to read the results of your work or the entire work as soon as it is finished. Would that be possible?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48q4e8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753050298,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1753050298,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49xli2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Reader3123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n49vvx6","score":2,"author_fullname":"t2_2880mqc6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sft has been enough for our needs fortunately","edited":false,"author_flair_css_class":null,"name":"t1_n49xli2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sft has been enough for our needs fortunately&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49xli2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066146,"author_flair_text":null,"collapsed":false,"created_utc":1753066146,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n49vvx6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vichustephen","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47j7cj","score":1,"author_fullname":"t2_p68pth83l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sounds cool and yeah I also had good experience with qwen3 0.6b. and i suppose you're currently doing GRPO fine tuning techniques","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49vvx6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sounds cool and yeah I also had good experience with qwen3 0.6b. and i suppose you&amp;#39;re currently doing GRPO fine tuning techniques&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49vvx6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753065484,"author_flair_text":null,"treatment_tags":[],"created_utc":1753065484,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47j7cj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Reader3123","can_mod_post":false,"send_replies":true,"parent_id":"t1_n47hzsm","score":8,"author_fullname":"t2_2880mqc6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For sure! Im currently part of an university project to develop an interpretable LLM model that makes utilitarian decisions on controversial issues.   \\nInterpretable in our context stands for how can we track down why an LLM made a decision to go a certain route instead of others. \\n\\nFirst we tested it with our proprietary 300B LLM and while it was amazing for its usecase... it was 300B. when we tested it with smaller models the CoT to final decision score started to fall apart (CoT had no relation what the final output was)\\n\\nSo now we are breaking the process into smaller models and training these 0.6B models to only specialize in those specific parts. \\n\\nFor example, one of the parts of utlitarian reasoning is finding all the stakeholders of a situation, so we trained a 0.6B model to only do that. And we found that its infact doing very well... almost as good as our benchmark 300B model for that specific purpose.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n47j7cj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For sure! Im currently part of an university project to develop an interpretable LLM model that makes utilitarian decisions on controversial issues.&lt;br/&gt;\\nInterpretable in our context stands for how can we track down why an LLM made a decision to go a certain route instead of others. &lt;/p&gt;\\n\\n&lt;p&gt;First we tested it with our proprietary 300B LLM and while it was amazing for its usecase... it was 300B. when we tested it with smaller models the CoT to final decision score started to fall apart (CoT had no relation what the final output was)&lt;/p&gt;\\n\\n&lt;p&gt;So now we are breaking the process into smaller models and training these 0.6B models to only specialize in those specific parts. &lt;/p&gt;\\n\\n&lt;p&gt;For example, one of the parts of utlitarian reasoning is finding all the stakeholders of a situation, so we trained a 0.6B model to only do that. And we found that its infact doing very well... almost as good as our benchmark 300B model for that specific purpose.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47j7cj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036709,"author_flair_text":null,"treatment_tags":[],"created_utc":1753036709,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n47hzsm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vichustephen","can_mod_post":false,"created_utc":1753036334,"send_replies":true,"parent_id":"t1_n46w7bw","score":3,"author_fullname":"t2_p68pth83l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What are the usecase that you have finetuned\\nCan you explain in more detail","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47hzsm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What are the usecase that you have finetuned\\nCan you explain in more detail&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47hzsm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036334,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n46w7bw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Reader3123","can_mod_post":false,"created_utc":1753029881,"send_replies":true,"parent_id":"t3_1m4of82","score":7,"author_fullname":"t2_2880mqc6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"0.6b qwen 3 is the only model thats cohernt and kinda smart in that level.\\n\\nIve finetuned them to be good at certain tasks for my project and they are more useful than a singuar 32B while being able to run it on my smart phone","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46w7bw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;0.6b qwen 3 is the only model thats cohernt and kinda smart in that level.&lt;/p&gt;\\n\\n&lt;p&gt;Ive finetuned them to be good at certain tasks for my project and they are more useful than a singuar 32B while being able to run it on my smart phone&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46w7bw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753029881,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bw2zk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"andreasntr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4btd8v","score":2,"author_fullname":"t2_k93afr7ze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wonderful, thank you for sharing","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bw2zk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wonderful, thank you for sharing&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4bw2zk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100992,"author_flair_text":null,"treatment_tags":[],"created_utc":1753100992,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4btd8v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-Ellary-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ashoa","score":1,"author_fullname":"t2_s4zzntp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ryzen 5500 6/12 10\\\\~tps.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4btd8v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ryzen 5500 6/12 10~tps.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4btd8v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753099954,"author_flair_text":null,"treatment_tags":[],"created_utc":1753099954,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4efuw7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StellanWay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4eei8w","score":1,"author_fullname":"t2_1t3su0kyam","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is using the cpu, not the gpu, but I tested both and with llama-cpp too and the difference is marginal between them, because the bottleneck is the memory (24 GB LPDDR5X, 85.4 GB/s)","edited":1753128233,"author_flair_css_class":null,"name":"t1_n4efuw7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is using the cpu, not the gpu, but I tested both and with llama-cpp too and the difference is marginal between them, because the bottleneck is the memory (24 GB LPDDR5X, 85.4 GB/s)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1m4of82","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4efuw7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127957,"author_flair_text":null,"collapsed":false,"created_utc":1753127957,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4eei8w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"andreasntr","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4edjt3","score":1,"author_fullname":"t2_k93afr7ze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Mobile cpus have igpus or something like that, they are not built as desktop cpus. Still, impressive how far we have come in 1 year","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4eei8w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Mobile cpus have igpus or something like that, they are not built as desktop cpus. Still, impressive how far we have come in 1 year&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4eei8w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127574,"author_flair_text":null,"treatment_tags":[],"created_utc":1753127574,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4edjt3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"StellanWay","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4ashoa","score":1,"author_fullname":"t2_1t3su0kyam","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meanwhile Qwen3-14B on my phone's CPU (Qualcomm Snapdragon 8 Elite).\\n\\nhttps://preview.redd.it/bnfiz7oj7aef1.jpeg?width=1440&amp;format=pjpg&amp;auto=webp&amp;s=88021b17c4cf97435842b9cd0e05311915c2af28","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n4edjt3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meanwhile Qwen3-14B on my phone&amp;#39;s CPU (Qualcomm Snapdragon 8 Elite).&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=1440&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=88021b17c4cf97435842b9cd0e05311915c2af28\\"&gt;https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=1440&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=88021b17c4cf97435842b9cd0e05311915c2af28&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4edjt3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753127304,"media_metadata":{"bnfiz7oj7aef1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":216,"x":108,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=807b6061c27b6153be36cdf318dd1c13973591ba"},{"y":432,"x":216,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccfd2ebc171e4e1e74623d098a858fbed5cdd4eb"},{"y":640,"x":320,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44dc6871e3f9bc46f50476db969a7a993a62764f"},{"y":1280,"x":640,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ed38a4c920dd1a2056b6c8abe8b298d097ea8e1"},{"y":1920,"x":960,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8f849bd3243f5017bdb628e246ae0628740486f5"},{"y":2160,"x":1080,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18f80a0eb383b07fca3b5a4198ec3f19ae699ec3"}],"s":{"y":3918,"x":1440,"u":"https://preview.redd.it/bnfiz7oj7aef1.jpeg?width=1440&amp;format=pjpg&amp;auto=webp&amp;s=88021b17c4cf97435842b9cd0e05311915c2af28"},"id":"bnfiz7oj7aef1"}},"author_flair_text":null,"treatment_tags":[],"created_utc":1753127304,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4ashoa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"andreasntr","can_mod_post":false,"created_utc":1753080644,"send_replies":true,"parent_id":"t1_n4652v9","score":1,"author_fullname":"t2_k93afr7ze","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"4b on cpu? Wow, what cpu do you have?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4ashoa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;4b on cpu? Wow, what cpu do you have?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4ashoa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753080644,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n4652v9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-Ellary-","can_mod_post":false,"created_utc":1753021484,"send_replies":true,"parent_id":"t3_1m4of82","score":5,"author_fullname":"t2_s4zzntp","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen 3 4b and Gemma 3n E4B do all the light routine work quite good. (I usually run them on CPU).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4652v9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 3 4b and Gemma 3n E4B do all the light routine work quite good. (I usually run them on CPU).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4652v9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48bxjf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"theblackcat99","can_mod_post":false,"created_utc":1753045646,"send_replies":true,"parent_id":"t1_n465v1m","score":14,"author_fullname":"t2_fh0ev","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I mean, you are absolutely correct, Qwen3-30b-a3b for its size it performs really well. \\nBUT I wouldn't call a 30b model a small model... (Thinking of the majority of people and hardware requirements)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48bxjf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean, you are absolutely correct, Qwen3-30b-a3b for its size it performs really well. \\nBUT I wouldn&amp;#39;t call a 30b model a small model... (Thinking of the majority of people and hardware requirements)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48bxjf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045646,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n465v1m","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"TheActualStudy","can_mod_post":false,"created_utc":1753021739,"send_replies":true,"parent_id":"t3_1m4of82","score":11,"author_fullname":"t2_7b7fm","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My floor is Qwen3-30B-A3B. I would need an awfully good reason to use something that didn't perform as well as that, considering how well it works with mmap and CPUs.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n465v1m","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My floor is Qwen3-30B-A3B. I would need an awfully good reason to use something that didn&amp;#39;t perform as well as that, considering how well it works with mmap and CPUs.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n465v1m/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021739,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46flwz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CourageOne3590","can_mod_post":false,"created_utc":1753024850,"send_replies":true,"parent_id":"t3_1m4of82","score":8,"author_fullname":"t2_9k220b84","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Jan-nano 4b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46flwz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Jan-nano 4b&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46flwz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753024850,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45xsm3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xhehab_","can_mod_post":false,"created_utc":1753018996,"send_replies":true,"parent_id":"t3_1m4of82","score":6,"author_fullname":"t2_e9mfhlg7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3-1.7B  \\nQwen3-4B  \\nGemma-3-4b-it-qat  \\nEXAONE-4.0-1.2B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45xsm3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3-1.7B&lt;br/&gt;\\nQwen3-4B&lt;br/&gt;\\nGemma-3-4b-it-qat&lt;br/&gt;\\nEXAONE-4.0-1.2B&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45xsm3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018996,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49586n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"johnerp","can_mod_post":false,"created_utc":1753055550,"send_replies":true,"parent_id":"t1_n47ffnq","score":1,"author_fullname":"t2_100h8g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This reads well, I’ll give it a go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49586n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This reads well, I’ll give it a go.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49586n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753055550,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n47ffnq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DirectCurrent_","can_mod_post":false,"created_utc":1753035548,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_vl1u9ir8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I've found that the POLARIS 4B finetune of qwen3 punches above their weight -- they also just released a 1.7B version that I've yet to use:\\n\\nhttps://huggingface.co/POLARIS-Project","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47ffnq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve found that the POLARIS 4B finetune of qwen3 punches above their weight -- they also just released a 1.7B version that I&amp;#39;ve yet to use:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/POLARIS-Project\\"&gt;https://huggingface.co/POLARIS-Project&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47ffnq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035548,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48a2je","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No-Source-9920","can_mod_post":false,"created_utc":1753045067,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_1gew47j6vy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"lfm2 is fantastic for 1.2b and jan-nano is amazing with tool calling","edited":1753046085,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48a2je","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;lfm2 is fantastic for 1.2b and jan-nano is amazing with tool calling&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48a2je/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045067,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48xk8p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"imakesound-","can_mod_post":false,"created_utc":1753052870,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_3v281j7r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma 4b for quick image captioning, gemma3n e2b on my home server for generating tags/creating summaries for karakeep and, for autocomplete/assistance in obsidian.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48xk8p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma 4b for quick image captioning, gemma3n e2b on my home server for generating tags/creating summaries for karakeep and, for autocomplete/assistance in obsidian.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48xk8p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753052870,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49zjxt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AndreVallestero","can_mod_post":false,"created_utc":1753066919,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_1gvigeuo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's a great benchmark for this: https://huggingface.co/spaces/k-mktr/gpu-poor-llm-arena","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49zjxt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s a great benchmark for this: &lt;a href=\\"https://huggingface.co/spaces/k-mktr/gpu-poor-llm-arena\\"&gt;https://huggingface.co/spaces/k-mktr/gpu-poor-llm-arena&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49zjxt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066919,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49mcts","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Jattoe","can_mod_post":false,"created_utc":1753061915,"send_replies":true,"parent_id":"t1_n462y8c","score":1,"author_fullname":"t2_d887zj2w0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting... How does it hold up to say, 27B/12B Gemmas? And 8B Nous Research Hermes?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49mcts","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting... How does it hold up to say, 27B/12B Gemmas? And 8B Nous Research Hermes?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49mcts/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753061915,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n462y8c","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sicarius_The_First","can_mod_post":false,"created_utc":1753020776,"send_replies":true,"parent_id":"t3_1m4of82","score":6,"author_fullname":"t2_ik8czvp65","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If you want creative stuff and roleplay, Impish\\\\_LLAMA\\\\_4B is nice\\n\\n[https://huggingface.co/SicariusSicariiStuff/Impish\\\\_LLAMA\\\\_4B](https://huggingface.co/SicariusSicariiStuff/Impish_LLAMA_4B)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n462y8c","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you want creative stuff and roleplay, Impish_LLAMA_4B is nice&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/SicariusSicariiStuff/Impish_LLAMA_4B\\"&gt;https://huggingface.co/SicariusSicariiStuff/Impish_LLAMA_4B&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n462y8c/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753020776,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47i38o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"vichustephen","can_mod_post":false,"created_utc":1753036363,"send_replies":true,"parent_id":"t3_1m4of82","score":2,"author_fullname":"t2_p68pth83l","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3 all the way","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47i38o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 all the way&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47i38o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036363,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47k4vk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OmarBessa","can_mod_post":false,"created_utc":1753036998,"send_replies":true,"parent_id":"t3_1m4of82","score":2,"author_fullname":"t2_guxix","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3 4b punches way above its weight","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47k4vk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 4b punches way above its weight&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47k4vk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753036998,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n46a4fh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"swagonflyyyy","can_mod_post":false,"send_replies":true,"parent_id":"t1_n4671wl","score":2,"author_fullname":"t2_iev1qh7k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Its so funny that there are \`Qwen3\` haters out there who hate it because its relevant. I guess they enjoy running bloated, dumber models out of defiance lmao.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n46a4fh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Its so funny that there are &lt;code&gt;Qwen3&lt;/code&gt; haters out there who hate it because its relevant. I guess they enjoy running bloated, dumber models out of defiance lmao.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46a4fh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753023120,"author_flair_text":null,"treatment_tags":[],"created_utc":1753023120,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n4671wl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"testuserpk","can_mod_post":false,"created_utc":1753022131,"send_replies":true,"parent_id":"t1_n45xa5h","score":3,"author_fullname":"t2_y9r5wbx2k","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3 is the goat","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4671wl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 is the goat&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4671wl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753022131,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n45xa5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"swagonflyyyy","can_mod_post":false,"created_utc":1753018816,"send_replies":true,"parent_id":"t3_1m4of82","score":5,"author_fullname":"t2_iev1qh7k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Did someone say \`Qwen3\`? Because I heard the wind whisper \`Qwen3\`!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45xa5h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did someone say &lt;code&gt;Qwen3&lt;/code&gt;? Because I heard the wind whisper &lt;code&gt;Qwen3&lt;/code&gt;!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45xa5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018816,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"c07aa42e-51fe-11f0-afcc-462aad931709","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45wlhp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"entsnack","can_mod_post":false,"created_utc":1753018570,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_1a48h7vf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama 3.2 3B. I've been using it for reinforcement fine-tuning and it takes to private data so well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45wlhp","is_submitter":false,"downs":0,"author_flair_richtext":[{"a":":X:","u":"https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X","e":"emoji"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama 3.2 3B. I&amp;#39;ve been using it for reinforcement fine-tuning and it takes to private data so well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45wlhp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753018570,"author_flair_text":":X:","treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"transparent","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n460smd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lavilao","can_mod_post":false,"created_utc":1753020044,"send_replies":true,"parent_id":"t3_1m4of82","score":4,"author_fullname":"t2_8r6zinl9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma 3 1b qat, the one from lmstudio page on huggingface","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n460smd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma 3 1b qat, the one from lmstudio page on huggingface&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n460smd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753020044,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4663a0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"averroeis","can_mod_post":false,"created_utc":1753021814,"send_replies":true,"parent_id":"t3_1m4of82","score":3,"author_fullname":"t2_2vthm3of","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The LLM that comes with [Jan.ai](http://Jan.ai) is really good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4663a0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The LLM that comes with &lt;a href=\\"http://Jan.ai\\"&gt;Jan.ai&lt;/a&gt; is really good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4663a0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753021814,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45t39s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ilintar","can_mod_post":false,"created_utc":1753017283,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_cctud","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Polaris 4B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45t39s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Polaris 4B&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45t39s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753017283,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"41af45de-fdc0-11ee-a05e-8227e0534943","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n474935","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Luston03","can_mod_post":false,"created_utc":1753032254,"send_replies":true,"parent_id":"t1_n46lz34","score":2,"author_fullname":"t2_n2kmftzjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen 3 1.7b and 3b for Reasoning and Gemma 3 4b and llama 3.2 for Conversations","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n474935","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen 3 1.7b and 3b for Reasoning and Gemma 3 4b and llama 3.2 for Conversations&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n474935/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753032254,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n46lz34","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"bwjxjelsbd","can_mod_post":false,"created_utc":1753026776,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_lurv0xw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ping me when you found good one OP","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n46lz34","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 8B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ping me when you found good one OP&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n46lz34/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753026776,"author_flair_text":"Llama 8B","treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47fbpw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"danigoncalves","can_mod_post":false,"created_utc":1753035514,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_6d2qv6jc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Moondrea, SmolLM, Gemma 3n, Qwen coder 3B, phi4 mini. They are all very nice models to the point where actually you don't need be GPU rich (or even have One) in order to take advantage of local AI awesomeness","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47fbpw","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Moondrea, SmolLM, Gemma 3n, Qwen coder 3B, phi4 mini. They are all very nice models to the point where actually you don&amp;#39;t need be GPU rich (or even have One) in order to take advantage of local AI awesomeness&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47fbpw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753035514,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n47u38g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HackinDoge","can_mod_post":false,"created_utc":1753040112,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_idxww","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’ve had a good all around experience with Cogito 3b on an Alder Lake N100 / 32GB RAM","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n47u38g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve had a good all around experience with Cogito 3b on an Alder Lake N100 / 32GB RAM&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n47u38g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753040112,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bvv1b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"giant3","can_mod_post":false,"created_utc":1753100909,"send_replies":true,"parent_id":"t1_n48gwzk","score":1,"author_fullname":"t2_82esi","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"can you run it with llama.cpp? I thought there is some outstanding pull request?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bvv1b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;can you run it with llama.cpp? I thought there is some outstanding pull request?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4bvv1b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753100909,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n48gwzk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ok_Road_8293","can_mod_post":false,"created_utc":1753047239,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_7ilphrsw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Exaone 4 1.2B is the best. It even beats Qwen 4B in my use cases (world knowledge, light-midly math, and lots of assistant-style dialogue). I don't even use reasoning mode.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48gwzk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Exaone 4 1.2B is the best. It even beats Qwen 4B in my use cases (world knowledge, light-midly math, and lots of assistant-style dialogue). I don&amp;#39;t even use reasoning mode.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48gwzk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753047239,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48r3ai","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rich_Artist_8327","can_mod_post":false,"created_utc":1753050631,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_1jk2ep8a52","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"gemma3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48r3ai","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;gemma3&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48r3ai/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753050631,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49n2r4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Black-Mack","can_mod_post":false,"created_utc":1753062186,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_1s8rdwqx9a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Qwen3 1.7b for more accurate summaries\\n\\nGemma 3 1b is more creative but adheres less to the system prompt\\n\\nInternVL 3 1b for vision","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49n2r4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 1.7b for more accurate summaries&lt;/p&gt;\\n\\n&lt;p&gt;Gemma 3 1b is more creative but adheres less to the system prompt&lt;/p&gt;\\n\\n&lt;p&gt;InternVL 3 1b for vision&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49n2r4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753062186,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49vd3g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Feztopia","can_mod_post":false,"created_utc":1753065285,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_34dar1xn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Depends on the definition of tiny, but the one I'm using on my phone right now is this one (8b): Yuma42/Llama3.1-DeepDilemma-V1-8B\\n\\n\\nIs it perfect? No, by far not but for it's size it's good. I don't have good experience with smaller models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49vd3g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends on the definition of tiny, but the one I&amp;#39;m using on my phone right now is this one (8b): Yuma42/Llama3.1-DeepDilemma-V1-8B&lt;/p&gt;\\n\\n&lt;p&gt;Is it perfect? No, by far not but for it&amp;#39;s size it&amp;#39;s good. I don&amp;#39;t have good experience with smaller models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49vd3g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753065285,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49z7wv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"created_utc":1753066787,"send_replies":true,"parent_id":"t1_n49z4qo","score":1,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will be messaging you in 1 day on [**2025-07-22 02:59:12 UTC**](http://www.wolframalpha.com/input/?i=2025-07-22%2002:59:12%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49z4qo/?context=3)\\n\\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1m4of82%2Fwhats_the_smartest_tiny_llm_youve_actually_used%2Fn49z4qo%2F%5D%0A%0ARemindMe%21%202025-07-22%2002%3A59%3A12%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201m4of82)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49z7wv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 1 day on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2025-07-22%2002:59:12%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2025-07-22 02:59:12 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49z4qo/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1m4of82%2Fwhats_the_smartest_tiny_llm_youve_actually_used%2Fn49z4qo%2F%5D%0A%0ARemindMe%21%202025-07-22%2002%3A59%3A12%20UTC\\"&gt;&lt;strong&gt;CLICK THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201m4of82\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1m4of82","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49z7wv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066787,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n49z4qo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hashms0a","can_mod_post":false,"created_utc":1753066752,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_zw9z0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"RemindMe! Tomorrow","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49z4qo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RemindMe! Tomorrow&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49z4qo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753066752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4acnrf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Andre4s11","can_mod_post":false,"created_utc":1753072512,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_uitx4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What abot tiny kimi?)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4acnrf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What abot tiny kimi?)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4acnrf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753072512,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4agv5j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"aero-spike","can_mod_post":false,"created_utc":1753074513,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_a167u3s9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Llama3.2 1B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4agv5j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama3.2 1B&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4agv5j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753074513,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4bl846","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"xtremx12","can_mod_post":false,"created_utc":1753096509,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_3op05s7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"qwen2.5 3b and 7b","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4bl846","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen2.5 3b and 7b&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4bl846/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753096509,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4dwuqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nostageshere","can_mod_post":false,"created_utc":1753122557,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_1u0zpsnh6z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Lfm2 1.2B and Qwen3 1.7B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4dwuqk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lfm2 1.2B and Qwen3 1.7B&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4dwuqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753122557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48baf5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"theblackcat99","can_mod_post":false,"created_utc":1753045445,"send_replies":true,"parent_id":"t3_1m4of82","score":1,"author_fullname":"t2_fh0ev","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Without any question: Jan-Nano128k:4b\\n\\nHere is the huggingface link https://huggingface.co/unsloth/Jan-nano-128k\\n\\nI have a 7900xt with 20gb VRAM, and that's the only model that I've been able to consistently run with around 30000 ctx.\\nDid I mention it's also multimodal? If you use it with browsermcp it does a decent job at completing small tasks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48baf5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Without any question: Jan-Nano128k:4b&lt;/p&gt;\\n\\n&lt;p&gt;Here is the huggingface link &lt;a href=\\"https://huggingface.co/unsloth/Jan-nano-128k\\"&gt;https://huggingface.co/unsloth/Jan-nano-128k&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I have a 7900xt with 20gb VRAM, and that&amp;#39;s the only model that I&amp;#39;ve been able to consistently run with around 30000 ctx.\\nDid I mention it&amp;#39;s also multimodal? If you use it with browsermcp it does a decent job at completing small tasks!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48baf5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753045445,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n48j9j3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Revolutionalredstone","can_mod_post":false,"created_utc":1753047990,"send_replies":true,"parent_id":"t3_1m4of82","score":0,"author_fullname":"t2_6crrj","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"COGITO it's insanely good, I try to talk about it here and people say 'meh' I can only assume people are dumb, (whoever made it) this thing is a GENIUS, very ChatGPT at-home and with TINY models!\\n\\nAbsolutely and easily the strongest small models from my testing.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n48j9j3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;COGITO it&amp;#39;s insanely good, I try to talk about it here and people say &amp;#39;meh&amp;#39; I can only assume people are dumb, (whoever made it) this thing is a GENIUS, very ChatGPT at-home and with TINY models!&lt;/p&gt;\\n\\n&lt;p&gt;Absolutely and easily the strongest small models from my testing.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n48j9j3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753047990,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n45yho9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"robertofmeregote","can_mod_post":false,"created_utc":1753019240,"send_replies":true,"parent_id":"t3_1m4of82","score":0,"author_fullname":"t2_yunug","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"SmolLm3","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n45yho9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;SmolLm3&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n45yho9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019240,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4604uk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Sure_Explorer_6698","can_mod_post":false,"created_utc":1753019814,"send_replies":true,"parent_id":"t3_1m4of82","score":0,"author_fullname":"t2_nmk9dlpa9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"My default for testing is SmolLM2-360M-Instruct-Q8_0, and then I play with what fits on my phone. I can't get a Phi model to work, and reasoning models just spit gibberish or end up in a loop.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4604uk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;My default for testing is SmolLM2-360M-Instruct-Q8_0, and then I play with what fits on my phone. I can&amp;#39;t get a Phi model to work, and reasoning models just spit gibberish or end up in a loop.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4604uk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019814,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n4608y7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wooloomulu","can_mod_post":false,"created_utc":1753019854,"send_replies":true,"parent_id":"t3_1m4of82","score":0,"author_fullname":"t2_1evbsb4j6i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Phi-4-mini","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n4608y7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Phi-4-mini&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n4608y7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753019854,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n49cbeh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"chisleu","can_mod_post":false,"created_utc":1753058168,"send_replies":true,"parent_id":"t3_1m4of82","score":-5,"author_fullname":"t2_cbxyn","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"This is the perfect shit post.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n49cbeh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the perfect shit post.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1m4of82/whats_the_smartest_tiny_llm_youve_actually_used/n49cbeh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1753058168,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1m4of82","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-5}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
