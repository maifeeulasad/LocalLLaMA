import{j as e}from"./index-DACS7Nh6.js";import{R as t}from"./RedditPostRenderer-Dqa1NZuX.js";import"./index-DiMIVQx4.js";const l=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"Hey everyone, I am building a time tracking app for mac that can automatically assign activities to the project without any manual assignment (at least that my goal).\\n\\nHere the data that I track:  \\n\\\\- Window title  \\n\\\\- File path  \\n\\\\- URL (browser)  \\n\\\\- App name\\n\\nFrom my experience with that limited data it very hard for the local LLM model to figure out which project that activities should belongs to. \\n\\nI have tried to add more context to the prompt like most recent assignment but local LLM is still reliable enough.\\n\\nI am using 3B up to 12B model (Gemma3 12B)\\n\\nIn the end I changed to use fastText (https://fasttext.cc/) to do the classification, the result is not that good compare to LLM but it way faster, I mean under 1 second prediction.\\n\\nIf anyone have any ideas to solve this problem, please let me know, thank you!","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Local vs Cloud AI in my time tracking app - the struggle is real","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":87,"top_awarded_type":null,"hide_score":false,"name":"t3_1lqyd4l","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.82,"author_flair_background_color":null,"ups":14,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_96a94uyw","secure_media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/p91ir3elkpaf1/DASH_1080.mp4?source=fallback","has_audio":false,"height":1080,"width":1722,"scrubber_media_url":"https://v.redd.it/p91ir3elkpaf1/DASH_96.mp4","dash_url":"https://v.redd.it/p91ir3elkpaf1/DASHPlaylist.mpd?a=1754199098%2CODRjNTBkMTQwMDdkNTJlZmM1OTQ0NDU1YjBmNTU4MDBmYzg5NmEyNWI2YWY3OTQ0Y2RiMGIxNDcxMTQyYmQ2OA%3D%3D&amp;v=1&amp;f=sd","duration":16,"hls_url":"https://v.redd.it/p91ir3elkpaf1/HLSPlaylist.m3u8?a=1754199098%2CODY3YjM0M2Y4NThjODhjOTY4NGRhYzU5NmViMzJkZDJlNGNkZWEzZTUxMDAyMThhMzk1ZjlmMzc3MjllMjc0OA%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"is_reddit_media_domain":true,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":14,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=140&amp;height=87&amp;crop=140:87,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=8bfff12e59ede1bf23feb09a6a3d6f3e12061202","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"hosted:video","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751570488,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"v.redd.it","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey everyone, I am building a time tracking app for mac that can automatically assign activities to the project without any manual assignment (at least that my goal).&lt;/p&gt;\\n\\n&lt;p&gt;Here the data that I track:&lt;br/&gt;\\n- Window title&lt;br/&gt;\\n- File path&lt;br/&gt;\\n- URL (browser)&lt;br/&gt;\\n- App name&lt;/p&gt;\\n\\n&lt;p&gt;From my experience with that limited data it very hard for the local LLM model to figure out which project that activities should belongs to. &lt;/p&gt;\\n\\n&lt;p&gt;I have tried to add more context to the prompt like most recent assignment but local LLM is still reliable enough.&lt;/p&gt;\\n\\n&lt;p&gt;I am using 3B up to 12B model (Gemma3 12B)&lt;/p&gt;\\n\\n&lt;p&gt;In the end I changed to use fastText (&lt;a href=\\"https://fasttext.cc/\\"&gt;https://fasttext.cc/&lt;/a&gt;) to do the classification, the result is not that good compare to LLM but it way faster, I mean under 1 second prediction.&lt;/p&gt;\\n\\n&lt;p&gt;If anyone have any ideas to solve this problem, please let me know, thank you!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://v.redd.it/p91ir3elkpaf1","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?format=pjpg&amp;auto=webp&amp;s=aaf11120e1a18825609091b1e05d7753f5e416f2","width":3024,"height":1896},"resolutions":[{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e91963378eb454634f685ae7a0138d76d1caa127","width":108,"height":67},{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=81339ee5eadd37d6997cb0ceb57aa05a13bdbf91","width":216,"height":135},{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=d16c188094e6944e0f03ef2fe82e8187dfe560a0","width":320,"height":200},{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c39c685d56306a4642816fe972d5a22c6a0cc067","width":640,"height":401},{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4b0d0b65bfc73ff9055d6b4678b036f005facbe2","width":960,"height":601},{"url":"https://external-preview.redd.it/ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=beb13354135d401e0cfef39be5230f43ea05c384","width":1080,"height":677}],"variants":{},"id":"ODh6a2swZWxrcGFmMVKisIIIDpMaavY9LjAqBDoFDXVsEVBGewqNBfZhZkXp"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lqyd4l","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"tuanvuvn007","discussion_type":null,"num_comments":9,"send_replies":true,"media":{"reddit_video":{"bitrate_kbps":5000,"fallback_url":"https://v.redd.it/p91ir3elkpaf1/DASH_1080.mp4?source=fallback","has_audio":false,"height":1080,"width":1722,"scrubber_media_url":"https://v.redd.it/p91ir3elkpaf1/DASH_96.mp4","dash_url":"https://v.redd.it/p91ir3elkpaf1/DASHPlaylist.mpd?a=1754199098%2CODRjNTBkMTQwMDdkNTJlZmM1OTQ0NDU1YjBmNTU4MDBmYzg5NmEyNWI2YWY3OTQ0Y2RiMGIxNDcxMTQyYmQ2OA%3D%3D&amp;v=1&amp;f=sd","duration":16,"hls_url":"https://v.redd.it/p91ir3elkpaf1/HLSPlaylist.m3u8?a=1754199098%2CODY3YjM0M2Y4NThjODhjOTY4NGRhYzU5NmViMzJkZDJlNGNkZWEzZTUxMDAyMThhMzk1ZjlmMzc3MjllMjc0OA%3D%3D&amp;v=1&amp;f=sd","is_gif":false,"transcoding_status":"completed"}},"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/","stickied":false,"url":"https://v.redd.it/p91ir3elkpaf1","subreddit_subscribers":494198,"created_utc":1751570488,"num_crossposts":0,"mod_reports":[],"is_video":true}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n18o6jz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuanvuvn007","can_mod_post":false,"created_utc":1751596875,"send_replies":true,"parent_id":"t1_n16pim0","score":1,"author_fullname":"t2_96a94uyw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have tried embeddings and use cosine similarity to find relevant activities, but the information that I have is very limited, I have a feeling that my fundamental approach is wrong, this is not a classification problem, it much more.\\n\\nIt is a contexture classification, where we need to consider the context of any given activities to its surrounding (like active project that user working on, past interactions, ....)\\n\\nOne way to enrich the data is to capture screenshot and use it to create embedding but I do think it quite overkill for this kind of app.\\n\\nMay be I just leave it as is and focus on other aspect of the app like reporting features, export template .... instead of chasing a perfect AI classification solution","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n18o6jz","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have tried embeddings and use cosine similarity to find relevant activities, but the information that I have is very limited, I have a feeling that my fundamental approach is wrong, this is not a classification problem, it much more.&lt;/p&gt;\\n\\n&lt;p&gt;It is a contexture classification, where we need to consider the context of any given activities to its surrounding (like active project that user working on, past interactions, ....)&lt;/p&gt;\\n\\n&lt;p&gt;One way to enrich the data is to capture screenshot and use it to create embedding but I do think it quite overkill for this kind of app.&lt;/p&gt;\\n\\n&lt;p&gt;May be I just leave it as is and focus on other aspect of the app like reporting features, export template .... instead of chasing a perfect AI classification solution&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqyd4l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n18o6jz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751596875,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n16pim0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ZookeepergameOdd4599","can_mod_post":false,"created_utc":1751572781,"send_replies":true,"parent_id":"t3_1lqyd4l","score":3,"author_fullname":"t2_f0g9hzoc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So basically classification task? Have you tried to use just embeddings model or layer?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n16pim0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So basically classification task? Have you tried to use just embeddings model or layer?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n16pim0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751572781,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqyd4l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n18n9by","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuanvuvn007","can_mod_post":false,"created_utc":1751596521,"send_replies":true,"parent_id":"t1_n16suaq","score":1,"author_fullname":"t2_96a94uyw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"thats a monster machine, but my app is mean for consumer  and they dont have this power.\\n\\nI think I need to fine tune a small LLM to improve the performance","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n18n9by","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;thats a monster machine, but my app is mean for consumer  and they dont have this power.&lt;/p&gt;\\n\\n&lt;p&gt;I think I need to fine tune a small LLM to improve the performance&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqyd4l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n18n9by/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751596521,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n16suaq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"allenasm","can_mod_post":false,"created_utc":1751573772,"send_replies":true,"parent_id":"t3_1lqyd4l","score":2,"author_fullname":"t2_fouwt","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"one of the reasons I just got an m3 studio ultra with 512gb vram was so i could run much larger more accurate models with longer context windows. I've given up on anything complex in small and even mid sized models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n16suaq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;one of the reasons I just got an m3 studio ultra with 512gb vram was so i could run much larger more accurate models with longer context windows. I&amp;#39;ve given up on anything complex in small and even mid sized models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n16suaq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751573772,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqyd4l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1811g2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Far-Incident822","can_mod_post":false,"send_replies":true,"parent_id":"t1_n17gt6s","score":2,"author_fullname":"t2_gc8qgt9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"[https://github.com/grunsab/Time-Tracker-Mac](https://github.com/grunsab/Time-Tracker-Mac)\\n\\nHere you go! Send me a DM if you have any trouble running it locally.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n1811g2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://github.com/grunsab/Time-Tracker-Mac\\"&gt;https://github.com/grunsab/Time-Tracker-Mac&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Here you go! Send me a DM if you have any trouble running it locally.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqyd4l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n1811g2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751588186,"author_flair_text":null,"treatment_tags":[],"created_utc":1751588186,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n17gt6s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"iamgladiator","can_mod_post":false,"created_utc":1751581194,"send_replies":true,"parent_id":"t1_n1720ie","score":1,"author_fullname":"t2_capf2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm interested!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n17gt6s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m interested!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lqyd4l","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n17gt6s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751581194,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n1720ie","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Far-Incident822","can_mod_post":false,"created_utc":1751576484,"send_replies":true,"parent_id":"t3_1lqyd4l","score":2,"author_fullname":"t2_gc8qgt9n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Super cool project. I happened to implement the same idea about a month ago, using Gemma3. I found the classification works well enough when using the 4BB parameter model. It just requires the right prompts. Happy to open source my code so that you can look at it. Let me know!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1720ie","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Super cool project. I happened to implement the same idea about a month ago, using Gemma3. I found the classification works well enough when using the 4BB parameter model. It just requires the right prompts. Happy to open source my code so that you can look at it. Let me know!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n1720ie/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751576484,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqyd4l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n16ic7h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuanvuvn007","can_mod_post":false,"created_utc":1751570643,"send_replies":true,"parent_id":"t3_1lqyd4l","score":2,"author_fullname":"t2_96a94uyw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The app is Chronoid (https://chronoid.app/) if anyone want to try out","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n16ic7h","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The app is Chronoid (&lt;a href=\\"https://chronoid.app/\\"&gt;https://chronoid.app/&lt;/a&gt;) if anyone want to try out&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n16ic7h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751570643,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqyd4l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n16ktt7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tuanvuvn007","can_mod_post":false,"created_utc":1751571391,"send_replies":true,"parent_id":"t3_1lqyd4l","score":1,"author_fullname":"t2_96a94uyw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Another problem with small local model is native tool calling support is pretty bad, from my testing using prompt only and ask the model what tool to call and response as JSON is way more reliable than the native tool calling.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n16ktt7","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Another problem with small local model is native tool calling support is pretty bad, from my testing using prompt only and ask the model what tool to call and response as JSON is way more reliable than the native tool calling.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lqyd4l/local_vs_cloud_ai_in_my_time_tracking_app_the/n16ktt7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751571391,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lqyd4l","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]`),n=()=>e.jsx(t,{data:l});export{n as default};
