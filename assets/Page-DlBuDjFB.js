import{j as e}from"./index-BlGsFJYy.js";import{R as t}from"./RedditPostRenderer-B6uvq_Zl.js";import"./index-DDvVtNwD.js";const l=JSON.parse('[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"I’m building a local AI agent system using n8n to handle technical SQL Q&amp;A and dashboard generation based on database results — with tool execution via MCP Server.\\n\\nMy setup:\\n\\nGPU: NVIDIA A10 (24GB VRAM)\\n\\nSo I’m limited to small to medium models (&lt;=14B): \\n\\n* llama3.1:8b-instruct-fp16\\n* qwen2.5:14b-instruct\\n\\nIssue: Even though I explicitly prompt with something like: “Step 1: Call Tool A to run a SQL query. Step 2: Use Tool B to generate a chart.” …the models just don’t follow — they output generic answers instead of invoking the defined tools.:  \\nFOR example:  \\n\\\\-------------------------------------------------------------------------------\\n\\nquestion: can you name top sql id that make low cpu?  \\n\\\\-------------------------------------------------------------------------------\\n\\nanswer:    \\n\\\\-------------------------------------------------------------------------------  \\nStep 0: Execute tool `schema` to get all information about Tables Definition for next step.\\n\\n{\\"name\\": \\"schema\\", \\"parameters\\": {}}\\n\\nStep 1: Try to execute tool `Execute_sql_query` based on user question to get new data. Always limit 25.\\n\\nSince the user asked about performance của database theo aas không tóm tắt, I will assume they want to know the performance metrics of the database for AAS (Application and Service Architecture) without summarization. Here is the SQL query:\\n\\nSELECT \\\\* FROM public\\\\_2.aas\\\\_performance LIMIT 25;  \\n... etc  \\n\\\\----------------------------------------------------------------------------------------  \\n\\n\\nI tested the same prompt with GPT-4, and it executes each step correctly — calls tools properly, reasons well, and behaves exactly as expected.  \\nHas anyone found a small-to-mid size local model that can reliably follow structured, tool-calling prompts like GPT-4 does or any technique that can fix this issue","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"local model for SQL Q&amp;A + dashboard agent","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lzhlvb","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":1,"author_flair_background_color":null,"subreddit_type":"public","ups":1,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_efnhbt7w0","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":1,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752484127,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m building a local AI agent system using n8n to handle technical SQL Q&amp;amp;A and dashboard generation based on database results — with tool execution via MCP Server.&lt;/p&gt;\\n\\n&lt;p&gt;My setup:&lt;/p&gt;\\n\\n&lt;p&gt;GPU: NVIDIA A10 (24GB VRAM)&lt;/p&gt;\\n\\n&lt;p&gt;So I’m limited to small to medium models (&amp;lt;=14B): &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;llama3.1:8b-instruct-fp16&lt;/li&gt;\\n&lt;li&gt;qwen2.5:14b-instruct&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Issue: Even though I explicitly prompt with something like: “Step 1: Call Tool A to run a SQL query. Step 2: Use Tool B to generate a chart.” …the models just don’t follow — they output generic answers instead of invoking the defined tools.:&lt;br/&gt;\\nFOR example:&lt;br/&gt;\\n-------------------------------------------------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;question: can you name top sql id that make low cpu?&lt;br/&gt;\\n-------------------------------------------------------------------------------&lt;/p&gt;\\n\\n&lt;p&gt;answer:&lt;br/&gt;\\n-------------------------------------------------------------------------------&lt;br/&gt;\\nStep 0: Execute tool &lt;code&gt;schema&lt;/code&gt; to get all information about Tables Definition for next step.&lt;/p&gt;\\n\\n&lt;p&gt;{&amp;quot;name&amp;quot;: &amp;quot;schema&amp;quot;, &amp;quot;parameters&amp;quot;: {}}&lt;/p&gt;\\n\\n&lt;p&gt;Step 1: Try to execute tool &lt;code&gt;Execute_sql_query&lt;/code&gt; based on user question to get new data. Always limit 25.&lt;/p&gt;\\n\\n&lt;p&gt;Since the user asked about performance của database theo aas không tóm tắt, I will assume they want to know the performance metrics of the database for AAS (Application and Service Architecture) without summarization. Here is the SQL query:&lt;/p&gt;\\n\\n&lt;p&gt;SELECT * FROM public_2.aas_performance LIMIT 25;&lt;br/&gt;\\n... etc&lt;br/&gt;\\n----------------------------------------------------------------------------------------  &lt;/p&gt;\\n\\n&lt;p&gt;I tested the same prompt with GPT-4, and it executes each step correctly — calls tools properly, reasons well, and behaves exactly as expected.&lt;br/&gt;\\nHas anyone found a small-to-mid size local model that can reliably follow structured, tool-calling prompts like GPT-4 does or any technique that can fix this issue&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1lzhlvb","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"Practical-Corgi-9906","discussion_type":null,"num_comments":1,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lzhlvb/local_model_for_sql_qa_dashboard_agent/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lzhlvb/local_model_for_sql_qa_dashboard_agent/","subreddit_subscribers":499296,"created_utc":1752484127,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n31pnxq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MaxKruse96","can_mod_post":false,"created_utc":1752485338,"send_replies":true,"parent_id":"t3_1lzhlvb","score":1,"author_fullname":"t2_pfi81","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"so far, for SQL specifically, i had the most luck with qwen3 at q8 (for you, that\'d be 14b) or bf16 (for you, 8b), whichever u can use or try back and forth.  \\nif you need the instruct to be very very strong, devstral is good to try here (strong instruct mistral base, good tool use, knows code). U just wanna keep it in check so that it doesnt start generating random code though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n31pnxq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;so far, for SQL specifically, i had the most luck with qwen3 at q8 (for you, that&amp;#39;d be 14b) or bf16 (for you, 8b), whichever u can use or try back and forth.&lt;br/&gt;\\nif you need the instruct to be very very strong, devstral is good to try here (strong instruct mistral base, good tool use, knows code). U just wanna keep it in check so that it doesnt start generating random code though.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lzhlvb/local_model_for_sql_qa_dashboard_agent/n31pnxq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752485338,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lzhlvb","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}}]'),s=()=>e.jsx(t,{data:l});export{s as default};
