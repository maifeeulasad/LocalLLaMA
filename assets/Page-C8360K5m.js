import{j as e}from"./index-CNyNkRpk.js";import{R as l}from"./RedditPostRenderer-Dza0u9i2.js";import"./index-BUchu_-K.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[https:\\\\/\\\\/x.com\\\\/huybery\\\\/status\\\\/1938655788849098805](https://preview.redd.it/415iw73n6k9f1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=e4e66852a8d0b6a8981e1e0f23da6ddfd4d0744c)\\n\\nsource: [https://x.com/huybery/status/1938655788849098805](https://x.com/huybery/status/1938655788849098805)\\n\\ni hope they release these models soon! ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Qwen3 Coder Soon?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":40,"top_awarded_type":null,"hide_score":false,"media_metadata":{"415iw73n6k9f1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":31,"x":108,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6cb1345112bddc3f949a0f74cb436dad24658e36"},{"y":63,"x":216,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=31652b01b0e3be443b495cee205ec3e984b41113"},{"y":93,"x":320,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e3d6b2846b8fd14d328983608ce4e2c59dd945c"},{"y":186,"x":640,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=20b45a6177696507d47628870ce2c458e02b265e"},{"y":280,"x":960,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=073fd7e5cdec88b7bd7eb28683c852334b435799"},{"y":315,"x":1080,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=59ce0954db49ab56a1a543ee4f37fe6376d5be9a"}],"s":{"y":319,"x":1093,"u":"https://preview.redd.it/415iw73n6k9f1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=e4e66852a8d0b6a8981e1e0f23da6ddfd4d0744c"},"id":"415iw73n6k9f1"}},"name":"t3_1lm92se","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"subreddit_type":"public","ups":177,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_7g0m6735","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":177,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/KDJV-rJVdBsUxEikcR6mcx63y02QfY38vq7JUDazoWM.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751068903,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/415iw73n6k9f1.png?width=1093&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e4e66852a8d0b6a8981e1e0f23da6ddfd4d0744c\\"&gt;https://x.com/huybery/status/1938655788849098805&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;source: &lt;a href=\\"https://x.com/huybery/status/1938655788849098805\\"&gt;https://x.com/huybery/status/1938655788849098805&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;i hope they release these models soon! &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lm92se","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"ApprehensiveAd3629","discussion_type":null,"num_comments":53,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/","subreddit_subscribers":492929,"created_utc":1751068903,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bcrog","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"marcosscriven","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06pt9h","score":2,"author_fullname":"t2_byihk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what’s better bro?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0bcrog","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what’s better bro?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0bcrog/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751149671,"author_flair_text":null,"treatment_tags":[],"created_utc":1751149671,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n06pt9h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"neotorama","can_mod_post":false,"created_utc":1751082900,"send_replies":true,"parent_id":"t1_n05tu76","score":20,"author_fullname":"t2_45wzf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ditch Aliexpress, Use the better bro, taobao and aliyun","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06pt9h","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ditch Aliexpress, Use the better bro, taobao and aliyun&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06pt9h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751082900,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n05wmm2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__JockY__","can_mod_post":false,"created_utc":1751071315,"send_replies":true,"parent_id":"t1_n05tu76","score":34,"author_fullname":"t2_qf8h7ka8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You mean Qwen3 235B A22B? In Coder distillation?\\n\\nTake my money.\\n\\nOk, it's free, but yes. Please.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05wmm2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You mean Qwen3 235B A22B? In Coder distillation?&lt;/p&gt;\\n\\n&lt;p&gt;Take my money.&lt;/p&gt;\\n\\n&lt;p&gt;Ok, it&amp;#39;s free, but yes. Please.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05wmm2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751071315,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0e0eln","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Creative-Size2658","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0dh841","score":1,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh! I didn't even think about their other MoE... A bigger coding MoE could be nice indeed. Something like 10x7b.\\n\\nAnd I also wonder how their 10x3b MoE will perform as a fine-tune for coding now.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0e0eln","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh! I didn&amp;#39;t even think about their other MoE... A bigger coding MoE could be nice indeed. Something like 10x7b.&lt;/p&gt;\\n\\n&lt;p&gt;And I also wonder how their 10x3b MoE will perform as a fine-tune for coding now.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0e0eln/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751194632,"author_flair_text":null,"treatment_tags":[],"created_utc":1751194632,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0dh841","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Front-Relief473","can_mod_post":false,"send_replies":true,"parent_id":"t1_n082bi8","score":1,"author_fullname":"t2_mma00ke23","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I agree with you, because his activation parameter is only 3b. Although he has parameter 30b, his problem-solving ability is much worse than that of the dense model's 32b.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0dh841","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I agree with you, because his activation parameter is only 3b. Although he has parameter 30b, his problem-solving ability is much worse than that of the dense model&amp;#39;s 32b.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0dh841/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751183062,"author_flair_text":null,"treatment_tags":[],"created_utc":1751183062,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n082bi8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Creative-Size2658","can_mod_post":false,"created_utc":1751109284,"send_replies":true,"parent_id":"t1_n05tu76","score":6,"author_fullname":"t2_1f3xb4r4ae","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We know they won't release any dense model bigger than 32B, but they didn't say anything about their MoE. That would be awesome.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n082bi8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We know they won&amp;#39;t release any dense model bigger than 32B, but they didn&amp;#39;t say anything about their MoE. That would be awesome.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n082bi8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751109284,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07nq8y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"IrisColt","can_mod_post":false,"created_utc":1751101000,"send_replies":true,"parent_id":"t1_n05tu76","score":2,"author_fullname":"t2_c2f558x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"🤣","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07nq8y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;🤣&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07nq8y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751101000,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n05tu76","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tengo_harambe","can_mod_post":false,"created_utc":1751070283,"send_replies":true,"parent_id":"t3_1lm92se","score":111,"author_fullname":"t2_sgx7w7mb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Release Qwen3-Coder-A22B and I'll cancel Amazon Prime and shop exclusively on Aliexpress","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05tu76","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Release Qwen3-Coder-A22B and I&amp;#39;ll cancel Amazon Prime and shop exclusively on Aliexpress&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05tu76/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751070283,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":111}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n079ljo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"xanduonc","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06okvi","score":12,"author_fullname":"t2_10n3b6gg97","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I can do several back and forth with it and finish coding task while r1 still thinks at first prompt lol.\\nWith enough context and instructing it does fine, 8b and 14 are fine too, but slower. Nothing beats 160 tps on 5090","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n079ljo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I can do several back and forth with it and finish coding task while r1 still thinks at first prompt lol.\\nWith enough context and instructing it does fine, 8b and 14 are fine too, but slower. Nothing beats 160 tps on 5090&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079ljo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092849,"author_flair_text":null,"treatment_tags":[],"created_utc":1751092849,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08cm7h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Calcidiol","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06okvi","score":2,"author_fullname":"t2_tailqi90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Sure, that's also in many cases reflected on some mainstream benchmarks (although interestingly in some minor number of cases it really outperforms its architecture/size class).\\n\\nBut the interesting question is how much potential might there be for 30B-A3B if further tuned / trained for a \\"coding model\\" using whatever more refined / modern techniques they have for that.  It might really improve the capabilities over the \\"it's decent / mediocre but mostly not usually near leading\\" precursor's capabilities to a more compelling capacity.\\n\\nOf course it still shouldn't eclipse a similarly well refined 14B, 32B dense coder model but it could more often cross the \\"good enough, fast enough\\" line to have compelling use cases where one doesn't drag out the full 32B or better models always and sacrifice the speed for quality sometimes.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n08cm7h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sure, that&amp;#39;s also in many cases reflected on some mainstream benchmarks (although interestingly in some minor number of cases it really outperforms its architecture/size class).&lt;/p&gt;\\n\\n&lt;p&gt;But the interesting question is how much potential might there be for 30B-A3B if further tuned / trained for a &amp;quot;coding model&amp;quot; using whatever more refined / modern techniques they have for that.  It might really improve the capabilities over the &amp;quot;it&amp;#39;s decent / mediocre but mostly not usually near leading&amp;quot; precursor&amp;#39;s capabilities to a more compelling capacity.&lt;/p&gt;\\n\\n&lt;p&gt;Of course it still shouldn&amp;#39;t eclipse a similarly well refined 14B, 32B dense coder model but it could more often cross the &amp;quot;good enough, fast enough&amp;quot; line to have compelling use cases where one doesn&amp;#39;t drag out the full 32B or better models always and sacrifice the speed for quality sometimes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n08cm7h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751113996,"author_flair_text":null,"treatment_tags":[],"created_utc":1751113996,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bwz55","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06okvi","score":1,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting. I've found 30B-A3B is a lot worse than 32B and that 235B A22B in 3-bit is worse than 32B (in 4-bit).","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0bwz55","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting. I&amp;#39;ve found 30B-A3B is a lot worse than 32B and that 235B A22B in 3-bit is worse than 32B (in 4-bit).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0bwz55/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751157056,"author_flair_text":null,"treatment_tags":[],"created_utc":1751157056,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n06okvi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"__some__guy","can_mod_post":false,"created_utc":1751082355,"send_replies":true,"parent_id":"t1_n05yrb2","score":20,"author_fullname":"t2_2fbnjhio","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In my experience it's worse than the dense 14B model.\\n\\nNot sufficient for programming.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06okvi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In my experience it&amp;#39;s worse than the dense 14B model.&lt;/p&gt;\\n\\n&lt;p&gt;Not sufficient for programming.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06okvi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751082355,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06hlo9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Pvt_Twinkietoes","can_mod_post":false,"created_utc":1751079354,"send_replies":true,"parent_id":"t1_n05yrb2","score":10,"author_fullname":"t2_3k9qfjsr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://www.reddit.com/r/technicallythetruth/s/ep5qwN87Et","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06hlo9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/technicallythetruth/s/ep5qwN87Et\\"&gt;https://www.reddit.com/r/technicallythetruth/s/ep5qwN87Et&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06hlo9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751079354,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"n05yrb2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1751072100,"send_replies":true,"parent_id":"t3_1lm92se","score":61,"author_fullname":"t2_4gc7hf3m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"30B-A3B has huge potential, super fast local coder ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05yrb2","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;30B-A3B has huge potential, super fast local coder &lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05yrb2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751072100,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":61}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06jg9r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pmttyji","can_mod_post":false,"created_utc":1751080127,"send_replies":true,"parent_id":"t3_1lm92se","score":14,"author_fullname":"t2_1deiadfhb1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hope there'll be a small version(like 8-12B) too for Poor GPU club.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06jg9r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hope there&amp;#39;ll be a small version(like 8-12B) too for Poor GPU club.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06jg9r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751080127,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n063gfd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nullmove","can_mod_post":false,"created_utc":1751073851,"send_replies":true,"parent_id":"t3_1lm92se","score":7,"author_fullname":"t2_aq4j0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Looks like he also admits of having [autonomous coding as a goal](https://x.com/huybery/status/1898463242701484400).\\n\\nWould be legitimately insane if they can pull it off now. My priors are low though, seems like current gen lacks parity in several layers (reasoning over long horizon, tool use) with industry standard. But surely worth taking time and going for it now when next gen of qwen-coder wouldn't likely happen again this year (unlike Misanthropic, their flagship isn't basically just a coder model).","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n063gfd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looks like he also admits of having &lt;a href=\\"https://x.com/huybery/status/1898463242701484400\\"&gt;autonomous coding as a goal&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Would be legitimately insane if they can pull it off now. My priors are low though, seems like current gen lacks parity in several layers (reasoning over long horizon, tool use) with industry standard. But surely worth taking time and going for it now when next gen of qwen-coder wouldn&amp;#39;t likely happen again this year (unlike Misanthropic, their flagship isn&amp;#39;t basically just a coder model).&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n063gfd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751073851,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07azfr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"reginakinhi","can_mod_post":false,"send_replies":true,"parent_id":"t1_n079tek","score":5,"author_fullname":"t2_47jf22jq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm relatively certain they were referring to olympic coder.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07azfr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m relatively certain they were referring to olympic coder.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07azfr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093600,"author_flair_text":null,"treatment_tags":[],"created_utc":1751093600,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0apjkh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"YouDontSeemRight","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07ac29","score":2,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, meant olympic","edited":false,"author_flair_css_class":null,"name":"t1_n0apjkh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, meant olympic&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lm92se","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0apjkh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751141850,"author_flair_text":null,"collapsed":false,"created_utc":1751141850,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n07ac29","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n079tek","score":4,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"And there are bartowski GGUF-s too, downloading:\\n\\n[https://huggingface.co/bartowski/open-r1\\\\_OlympicCoder-32B-GGUF](https://huggingface.co/bartowski/open-r1_OlympicCoder-32B-GGUF)\\n\\n[https://huggingface.co/bartowski/open-r1\\\\_OlympicCoder-7B-GGUF](https://huggingface.co/bartowski/open-r1_OlympicCoder-7B-GGUF)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07ac29","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;And there are bartowski GGUF-s too, downloading:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/bartowski/open-r1_OlympicCoder-32B-GGUF\\"&gt;https://huggingface.co/bartowski/open-r1_OlympicCoder-32B-GGUF&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/bartowski/open-r1_OlympicCoder-7B-GGUF\\"&gt;https://huggingface.co/bartowski/open-r1_OlympicCoder-7B-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07ac29/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751093248,"author_flair_text":null,"treatment_tags":[],"created_utc":1751093248,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n079tek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thirteen-bit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n05xll8","score":3,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cannot find any coder models named Olympus, only vision related [https://huggingface.co/Yuanze/Olympus](https://huggingface.co/Yuanze/Olympus)\\n\\nOr maybe OlympicCoder 7B and 32B, like these?:\\n\\n[https://huggingface.co/open-r1/OlympicCoder-32B](https://huggingface.co/open-r1/OlympicCoder-32B)\\n\\n[https://huggingface.co/open-r1/OlympicCoder-7B](https://huggingface.co/open-r1/OlympicCoder-7B)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n079tek","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cannot find any coder models named Olympus, only vision related &lt;a href=\\"https://huggingface.co/Yuanze/Olympus\\"&gt;https://huggingface.co/Yuanze/Olympus&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Or maybe OlympicCoder 7B and 32B, like these?:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/open-r1/OlympicCoder-32B\\"&gt;https://huggingface.co/open-r1/OlympicCoder-32B&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/open-r1/OlympicCoder-7B\\"&gt;https://huggingface.co/open-r1/OlympicCoder-7B&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079tek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092968,"author_flair_text":null,"treatment_tags":[],"created_utc":1751092968,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n079uqd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nasone32","can_mod_post":false,"send_replies":true,"parent_id":"t1_n05xll8","score":2,"author_fullname":"t2_f6elz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interested, Where can I find it? Tried googling a bit with no results. Thanks ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n079uqd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interested, Where can I find it? Tried googling a bit with no results. Thanks &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079uqd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092988,"author_flair_text":null,"treatment_tags":[],"created_utc":1751092988,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n05xll8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"YouDontSeemRight","can_mod_post":false,"created_utc":1751071673,"send_replies":true,"parent_id":"t1_n05r6m0","score":9,"author_fullname":"t2_1b7gjxtue9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Try Olympus, fine tune of 2.5 on c and c++","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05xll8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try Olympus, fine tune of 2.5 on c and c++&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05xll8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751071673,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n05ynw6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AaronFeng47","can_mod_post":false,"created_utc":1751072065,"send_replies":true,"parent_id":"t1_n05r6m0","score":7,"author_fullname":"t2_4gc7hf3m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Qwen3 32B","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05ynw6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Qwen3 32B&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05ynw6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751072065,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n069a1z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poita66","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0695yw","score":2,"author_fullname":"t2_hbp5l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks, fixed!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n069a1z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, fixed!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n069a1z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751076071,"author_flair_text":null,"treatment_tags":[],"created_utc":1751076071,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0695yw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0605ls","score":3,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Devstral and Small 3 are 24b","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0695yw","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Devstral and Small 3 are 24b&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0695yw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751076028,"author_flair_text":null,"treatment_tags":[],"created_utc":1751076028,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0605ls","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"poita66","can_mod_post":false,"created_utc":1751072618,"send_replies":true,"parent_id":"t1_n05r6m0","score":7,"author_fullname":"t2_hbp5l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I’ve tried Qwen3 30B A3B, Devstral (24B), and Mistral Small 3.2 (also 24B) and they’re all just OK. However I use them in Roo Code (agentic coding), so they might be better for you","edited":1751076061,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0605ls","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’ve tried Qwen3 30B A3B, Devstral (24B), and Mistral Small 3.2 (also 24B) and they’re all just OK. However I use them in Roo Code (agentic coding), so they might be better for you&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0605ls/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751072618,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n067ayl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"teleprint-me","can_mod_post":false,"created_utc":1751075319,"send_replies":true,"parent_id":"t1_n05r6m0","score":4,"author_fullname":"t2_slcrtxpr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"There are not that many coder models available. Which is unfortunate. The last batch of releases were all reasoning or over 20B param models. Qwen is definitely the winner there.\\n\\nhttps://huggingface.co/models?sort=likes&amp;search=coder","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n067ayl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There are not that many coder models available. Which is unfortunate. The last batch of releases were all reasoning or over 20B param models. Qwen is definitely the winner there.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/models?sort=likes&amp;amp;search=coder\\"&gt;https://huggingface.co/models?sort=likes&amp;amp;search=coder&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n067ayl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751075319,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n07v0vj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07cy9d","score":2,"author_fullname":"t2_j1i0o","approved_by":null,"mod_note":null,"all_awardings":[],"body":"The second option doesn't take much","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n07v0vj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The second option doesn&amp;#39;t take much&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lm92se","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07v0vj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751105343,"author_flair_text":null,"treatment_tags":[],"created_utc":1751105343,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n07cy9d","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Egoz3ntrum","can_mod_post":false,"send_replies":true,"parent_id":"t1_n07bzf8","score":2,"author_fullname":"t2_h7b8z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"exactly","edited":false,"author_flair_css_class":null,"name":"t1_n07cy9d","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;exactly&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lm92se","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07cy9d/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094681,"author_flair_text":null,"collapsed":false,"created_utc":1751094681,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n07bzf8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"send_replies":true,"parent_id":"t1_n079i9u","score":3,"author_fullname":"t2_j1i0o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"16x3090s or 1x6000Pro+1TB DDR5","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n07bzf8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;16x3090s or 1x6000Pro+1TB DDR5&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n07bzf8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751094144,"author_flair_text":null,"treatment_tags":[],"created_utc":1751094144,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n079i9u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Egoz3ntrum","can_mod_post":false,"send_replies":true,"parent_id":"t1_n06n44z","score":3,"author_fullname":"t2_h7b8z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You need a nuclear plant to run Deepseek R1. Unless you're talking about the distilled qwen 2.5 version.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n079i9u","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need a nuclear plant to run Deepseek R1. Unless you&amp;#39;re talking about the distilled qwen 2.5 version.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079i9u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092800,"author_flair_text":null,"treatment_tags":[],"created_utc":1751092800,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n06n44z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"created_utc":1751081703,"send_replies":true,"parent_id":"t1_n05r6m0","score":2,"author_fullname":"t2_j1i0o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1. Every other model does stupid shit like deleting random blocks of code","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06n44z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1. Every other model does stupid shit like deleting random blocks of code&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06n44z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751081703,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0bxbob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PurpleUpbeat2820","can_mod_post":false,"created_utc":1751157188,"send_replies":true,"parent_id":"t1_n05r6m0","score":1,"author_fullname":"t2_7xnuxw8f","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; What is everyone using at the moment?\\n\\nqwen3:32b but only for tools. I still prefer qwen2.5-coder:32b because it is much faster and produces much better code.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0bxbob","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;What is everyone using at the moment?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;qwen3:32b but only for tools. I still prefer qwen2.5-coder:32b because it is much faster and produces much better code.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0bxbob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751157188,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n05r6m0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Aroochacha","can_mod_post":false,"created_utc":1751069311,"send_replies":true,"parent_id":"t3_1lm92se","score":13,"author_fullname":"t2_e0hy0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is everyone using at the moment? I am using 2.5 Coder 32B for C/C++.  It’s okay just wish there was something better. I use it as an ai coding assistant , auto complete and chat box.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05r6m0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is everyone using at the moment? I am using 2.5 Coder 32B for C/C++.  It’s okay just wish there was something better. I use it as an ai coding assistant , auto complete and chat box.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05r6m0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751069311,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06tym6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pigeon57434","can_mod_post":false,"created_utc":1751084813,"send_replies":true,"parent_id":"t3_1lm92se","score":4,"author_fullname":"t2_8j5t7yjq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"i would go crazy for qwen 3 omni though","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06tym6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;i would go crazy for qwen 3 omni though&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06tym6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751084813,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n08nj56","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FullOf_Bad_Ideas","can_mod_post":false,"created_utc":1751118225,"send_replies":true,"parent_id":"t1_n066150","score":2,"author_fullname":"t2_9s7pmakgx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't like it but I find it hard to go back to Qwen 3 32B + Cline after using Claude Code with Sonnet 4 over the last few weeks, it can handle bigger tasks on it's own. Qwen3 32B is very good for a small local model though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n08nj56","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t like it but I find it hard to go back to Qwen 3 32B + Cline after using Claude Code with Sonnet 4 over the last few weeks, it can handle bigger tasks on it&amp;#39;s own. Qwen3 32B is very good for a small local model though.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n08nj56/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751118225,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n09iv0s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chub79","can_mod_post":false,"created_utc":1751128400,"send_replies":true,"parent_id":"t1_n066150","score":1,"author_fullname":"t2_36n3l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; I did 90% of my work in the last two weeks on Qwen3 32b.\\n\\nI find that model way too chatty to be usable.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n09iv0s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;I did 90% of my work in the last two weeks on Qwen3 32b.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;I find that model way too chatty to be usable.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n09iv0s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751128400,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n066150","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Secure_Reflection409","can_mod_post":false,"created_utc":1751074835,"send_replies":true,"parent_id":"t3_1lm92se","score":7,"author_fullname":"t2_by77ogdhr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I did 90% of my work in the last two weeks on Qwen3 32b.\\n\\n\\nI, grudgingly, had to use o4-mini-high earlier to fix an issue I didn't have the context or the patience to spill over to CPU.\\n\\n\\nIt fixed it inside 3 prompts, to be fair.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n066150","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I did 90% of my work in the last two weeks on Qwen3 32b.&lt;/p&gt;\\n\\n&lt;p&gt;I, grudgingly, had to use o4-mini-high earlier to fix an issue I didn&amp;#39;t have the context or the patience to spill over to CPU.&lt;/p&gt;\\n\\n&lt;p&gt;It fixed it inside 3 prompts, to be fair.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n066150/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751074835,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06f3al","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lightninglemons22","can_mod_post":false,"created_utc":1751078329,"send_replies":true,"parent_id":"t3_1lm92se","score":2,"author_fullname":"t2_ygtiw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"hope they come out with an slm ~3-7B like 2.5","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06f3al","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;hope they come out with an slm ~3-7B like 2.5&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06f3al/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751078329,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n079r1i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"And-Bee","can_mod_post":false,"created_utc":1751092932,"send_replies":true,"parent_id":"t3_1lm92se","score":2,"author_fullname":"t2_a81fjhk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"What is the best local coding model for swift?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n079r1i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What is the best local coding model for swift?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079r1i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092932,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0654hu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"teleprint-me","can_mod_post":false,"created_utc":1751074488,"send_replies":true,"parent_id":"t3_1lm92se","score":2,"author_fullname":"t2_slcrtxpr","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://nitter.net/huybery/status/1938655788849098805","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0654hu","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://nitter.net/huybery/status/1938655788849098805\\"&gt;https://nitter.net/huybery/status/1938655788849098805&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0654hu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751074488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0dxtht","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"madaradess007","can_mod_post":false,"created_utc":1751193177,"send_replies":true,"parent_id":"t3_1lm92se","score":1,"author_fullname":"t2_79slapln","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"qwen3-coder when?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0dxtht","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;qwen3-coder when?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0dxtht/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751193177,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0615qq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Calcidiol","can_mod_post":false,"created_utc":1751072988,"send_replies":true,"parent_id":"t1_n05wghl","score":8,"author_fullname":"t2_tailqi90","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Benchmarks can be shallow at first glance and hard to tell why they favor one outcome vs. another without digging into the details.\\n\\nBut anecdotally, anyway, for instance look at the artificial analysis benchmarks and there are like 2-3 coding related benchmarks listed on there.\\n\\nPretty much all the remotely modern / relevant models useful for coding (qwen3, deepseek r1/v3, qwq, ...) do better by a fairly large margin of points on the benchmarks when they're operated in reasoning mode even vs. the same models operated in non reasoning mode.  So something about the reasoning outcome scores significantly more highly in their chosen codine related benchmarks vs. non reasoning models / modes.\\n\\nBut as a coder sure it's easy to see how there are lots of things that wouldn't logically need reasoning, just accurate / comprehensive base knowledge and the relevant answers are just right there.\\n\\nAnd it's sad to watch how bumbling stupid and non productive reasoning models' reasoning iterations can be so it's easy to see how one might doubt the utility of that mode for many use cases that don't really need walking around the concepts / options trying to stumble into a clearer path toward plausible solution.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0615qq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Benchmarks can be shallow at first glance and hard to tell why they favor one outcome vs. another without digging into the details.&lt;/p&gt;\\n\\n&lt;p&gt;But anecdotally, anyway, for instance look at the artificial analysis benchmarks and there are like 2-3 coding related benchmarks listed on there.&lt;/p&gt;\\n\\n&lt;p&gt;Pretty much all the remotely modern / relevant models useful for coding (qwen3, deepseek r1/v3, qwq, ...) do better by a fairly large margin of points on the benchmarks when they&amp;#39;re operated in reasoning mode even vs. the same models operated in non reasoning mode.  So something about the reasoning outcome scores significantly more highly in their chosen codine related benchmarks vs. non reasoning models / modes.&lt;/p&gt;\\n\\n&lt;p&gt;But as a coder sure it&amp;#39;s easy to see how there are lots of things that wouldn&amp;#39;t logically need reasoning, just accurate / comprehensive base knowledge and the relevant answers are just right there.&lt;/p&gt;\\n\\n&lt;p&gt;And it&amp;#39;s sad to watch how bumbling stupid and non productive reasoning models&amp;#39; reasoning iterations can be so it&amp;#39;s easy to see how one might doubt the utility of that mode for many use cases that don&amp;#39;t really need walking around the concepts / options trying to stumble into a clearer path toward plausible solution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n0615qq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751072988,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06mx9j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"cantgetthistowork","can_mod_post":false,"created_utc":1751081617,"send_replies":true,"parent_id":"t1_n05wghl","score":3,"author_fullname":"t2_j1i0o","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"R1 never drops the ball on anything. Zero handholding or sending it back","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06mx9j","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;R1 never drops the ball on anything. Zero handholding or sending it back&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06mx9j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751081617,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06ap3p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poita66","can_mod_post":false,"send_replies":true,"parent_id":"t1_n069cd5","score":1,"author_fullname":"t2_hbp5l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hmmm, maybe I need to try some bigger models and quants. My experience in agentic use is a bit mixed with thinking mode, it keeps trying the same solution again and again, and is impossible to get out of the loop","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06ap3p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hmmm, maybe I need to try some bigger models and quants. My experience in agentic use is a bit mixed with thinking mode, it keeps trying the same solution again and again, and is impossible to get out of the loop&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06ap3p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751076613,"author_flair_text":null,"treatment_tags":[],"created_utc":1751076613,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n069cd5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n060vhb","score":2,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No, thinking is actually quite useful at coding, perhaps not with agent, but occasional turning on thinking with a3b helps solving at least 5% problems otherwise It can't solve","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n069cd5","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No, thinking is actually quite useful at coding, perhaps not with agent, but occasional turning on thinking with a3b helps solving at least 5% problems otherwise It can&amp;#39;t solve&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n069cd5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751076096,"author_flair_text":null,"treatment_tags":[],"created_utc":1751076096,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n060vhb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"poita66","can_mod_post":false,"created_utc":1751072884,"send_replies":true,"parent_id":"t1_n05wghl","score":1,"author_fullname":"t2_hbp5l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I find that Devstral is ok, but the context window on a 3090 is only reliable at 40k tokens. I’m trying Qwen3 30B A3B so I can get a longer context window and I fully agree that thinking mode is useless for coding. I’ll be trying it with /no_think next","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n060vhb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I find that Devstral is ok, but the context window on a 3090 is only reliable at 40k tokens. I’m trying Qwen3 30B A3B so I can get a longer context window and I fully agree that thinking mode is useless for coding. I’ll be trying it with /no_think next&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n060vhb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751072884,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n05wghl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"RiskyBizz216","can_mod_post":false,"created_utc":1751071252,"send_replies":true,"parent_id":"t3_1lm92se","score":-8,"author_fullname":"t2_4eu8nupk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Thinking models suck for coding. Devstral is better than both Qwen and Grok. \\n\\nQuit trying to be the next Deepseek, just develop a GOOD open source coding model.\\n\\n  \\n/rant","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n05wghl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thinking models suck for coding. Devstral is better than both Qwen and Grok. &lt;/p&gt;\\n\\n&lt;p&gt;Quit trying to be the next Deepseek, just develop a GOOD open source coding model.&lt;/p&gt;\\n\\n&lt;p&gt;/rant&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n05wghl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751071252,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n074v2e","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"redeemer_pl","can_mod_post":false,"created_utc":1751090328,"send_replies":true,"parent_id":"t1_n06htil","score":9,"author_fullname":"t2_cgwh4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't see why you would send your data and source code to external entities that are driven by, and profit from, that data.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n074v2e","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t see why you would send your data and source code to external entities that are driven by, and profit from, that data.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n074v2e/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751090328,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n079prb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Egoz3ntrum","can_mod_post":false,"created_utc":1751092913,"send_replies":true,"parent_id":"t1_n06htil","score":4,"author_fullname":"t2_h7b8z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"r/nonLocalLlama","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n079prb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"/r/nonLocalLlama\\"&gt;r/nonLocalLlama&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lm92se","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n079prb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751092913,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n06htil","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"davewolfs","can_mod_post":false,"created_utc":1751079443,"send_replies":true,"parent_id":"t3_1lm92se","score":-9,"author_fullname":"t2_pms20","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"I kind of don’t see why you would use anything but Claude Code with other models available via MCP. Yes it’s that good.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06htil","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I kind of don’t see why you would use anything but Claude Code with other models available via MCP. Yes it’s that good.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06htil/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751079443,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n06h8ob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"fasti-au","can_mod_post":false,"created_utc":1751079204,"send_replies":true,"parent_id":"t3_1lm92se","score":-7,"author_fullname":"t2_1t6pdk3z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"No it’s just qwen3.  Code is about 20 bill parameters now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n06h8ob","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No it’s just qwen3.  Code is about 20 bill parameters now&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lm92se/qwen3_coder_soon/n06h8ob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751079204,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lm92se","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}}]`),n=()=>e.jsx(l,{data:a});export{n as default};
