import{j as e}from"./index-BlGsFJYy.js";import{R as l}from"./RedditPostRenderer-B6uvq_Zl.js";import"./index-DDvVtNwD.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"5975wx, 512gb DDR4 3200, dual 3090s.\\nOllama + OpenWebUI. Running on LMDE.\\n\\nIdk what went wrong now but I'm struggling to get it back to 4 t/s... I can work with 4 t/s, but 0.15 t/s is just terrible.\\n\\nAny ideas? Happy to provide information upon request.\\n\\nTotal noob here, just built this a few days ago and very little terminal experience lol but have an open mind and a will to learn.","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"New to the scene. Yesterday, got 4 t/s on R1 671b q4. Today, I'm getting about 0.15 t/s... What did I break lol","link_flair_richtext":[{"e":"text","t":"Question | Help"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1loswvr","quarantine":false,"link_flair_text_color":"dark","upvote_ratio":0.8,"author_flair_background_color":null,"subreddit_type":"public","ups":36,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_vct0oav1","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Question | Help","can_mod_post":false,"score":36,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1751345172,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;5975wx, 512gb DDR4 3200, dual 3090s.\\nOllama + OpenWebUI. Running on LMDE.&lt;/p&gt;\\n\\n&lt;p&gt;Idk what went wrong now but I&amp;#39;m struggling to get it back to 4 t/s... I can work with 4 t/s, but 0.15 t/s is just terrible.&lt;/p&gt;\\n\\n&lt;p&gt;Any ideas? Happy to provide information upon request.&lt;/p&gt;\\n\\n&lt;p&gt;Total noob here, just built this a few days ago and very little terminal experience lol but have an open mind and a will to learn.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#5a74cc","id":"1loswvr","is_robot_indexable":true,"num_duplicates":1,"report_reasons":null,"author":"sourpatchgrownadults","discussion_type":null,"num_comments":37,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/","subreddit_subscribers":493458,"created_utc":1751345172,"num_crossposts":2,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pktg1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"sourpatchgrownadults","can_mod_post":false,"created_utc":1751347322,"send_replies":true,"parent_id":"t1_n0phrg3","score":11,"author_fullname":"t2_vct0oav1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Context window was even bigger yesterday, 5-6 paragraph prompt. Got 4 t/s\\n\\nToday, three word prompt. And I get 0.15 t/s. Both on fresh chats","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pktg1","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Context window was even bigger yesterday, 5-6 paragraph prompt. Got 4 t/s&lt;/p&gt;\\n\\n&lt;p&gt;Today, three word prompt. And I get 0.15 t/s. Both on fresh chats&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pktg1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347322,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"n0phrg3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"urekmazino_0","can_mod_post":false,"created_utc":1751345804,"send_replies":true,"parent_id":"t3_1loswvr","score":25,"author_fullname":"t2_oebv0z6s","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I’m guessing context window","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0phrg3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I’m guessing context window&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0phrg3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751345804,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0r0wwb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lun4r","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qi9bd","score":1,"author_fullname":"t2_bhn3x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks for the info. I'll give it a try.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0r0wwb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for the info. I&amp;#39;ll give it a try.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0r0wwb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751374349,"author_flair_text":null,"treatment_tags":[],"created_utc":1751374349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qi9bd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"No_Afternoon_4260","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pz7ug","score":6,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Llama ships with a minimal one. It's pretty good imo","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qi9bd","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Llama ships with a minimal one. It&amp;#39;s pretty good imo&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qi9bd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751366461,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751366461,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qwukk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0q0gc2","score":4,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ollama api isn't much different than openAI api.","edited":false,"author_flair_css_class":null,"name":"t1_n0qwukk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ollama api isn&amp;#39;t much different than openAI api.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1loswvr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qwukk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372845,"author_flair_text":null,"collapsed":false,"created_utc":1751372845,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0q0gc2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lun4r","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pzamx","score":1,"author_fullname":"t2_bhn3x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thanks, I thought openwebui only worked with ollama.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0q0gc2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks, I thought openwebui only worked with ollama.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0q0gc2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751356061,"author_flair_text":null,"treatment_tags":[],"created_utc":1751356061,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pzamx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Other_Speed6055","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pz7ug","score":6,"author_fullname":"t2_e30f9y7m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I use openwebui.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pzamx","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I use openwebui.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pzamx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751355358,"author_flair_text":null,"treatment_tags":[],"created_utc":1751355358,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0w3led","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"createthiscom","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pz7ug","score":2,"author_fullname":"t2_ozxxf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"you can use open webui","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0w3led","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;you can use open webui&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0w3led/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751432421,"author_flair_text":null,"treatment_tags":[],"created_utc":1751432421,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pz7ug","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lun4r","can_mod_post":false,"created_utc":1751355310,"send_replies":true,"parent_id":"t1_n0plk6f","score":2,"author_fullname":"t2_bhn3x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is there a web interface for it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pz7ug","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is there a web interface for it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pz7ug/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751355310,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qo97o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Other_Speed6055","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qnioc","score":6,"author_fullname":"t2_e30f9y7m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think craving high TPS is like drinking salt water. :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qo97o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think craving high TPS is like drinking salt water. :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qo97o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751369307,"author_flair_text":null,"treatment_tags":[],"created_utc":1751369307,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qx7y7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0qnioc","score":2,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I also get over 10 and its pretty tolerable. What sucks is waiting for processing context. More specifically having to re-process context with stuff like websearches. Message to message is ok.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0qx7y7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I also get over 10 and its pretty tolerable. What sucks is waiting for processing context. More specifically having to re-process context with stuff like websearches. Message to message is ok.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qx7y7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751372989,"author_flair_text":null,"treatment_tags":[],"created_utc":1751372989,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0qnioc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tempetemplar","can_mod_post":false,"created_utc":1751368979,"send_replies":true,"parent_id":"t1_n0plk6f","score":1,"author_fullname":"t2_atvw2aj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Interesting. You happy with that tok/s?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qnioc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting. You happy with that tok/s?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qnioc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751368979,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0plk6f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Other_Speed6055","can_mod_post":false,"created_utc":1751347696,"send_replies":true,"parent_id":"t3_1loswvr","score":28,"author_fullname":"t2_e30f9y7m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Please use ik_llama.cpp. I achieved 10.2 tok/s using the DeepSeek R1 0528 IQ2 model, and 8.1 tok/s with the IQ3_KT variant, on my system with a 5975WX, 256 GB DDR4-2933 RAM, an RTX 3090 Ti, and an RTX 3090.\\n\\n\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1l5jh4y/deepseek/","edited":1751347895,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0plk6f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Please use ik_llama.cpp. I achieved 10.2 tok/s using the DeepSeek R1 0528 IQ2 model, and 8.1 tok/s with the IQ3_KT variant, on my system with a 5975WX, 256 GB DDR4-2933 RAM, an RTX 3090 Ti, and an RTX 3090.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1l5jh4y/deepseek/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1l5jh4y/deepseek/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0plk6f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347696,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0q56ye","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"randomqhacker","can_mod_post":false,"created_utc":1751358947,"send_replies":true,"parent_id":"t3_1loswvr","score":8,"author_fullname":"t2_4nw3v","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"When I see that it is usually your model loaded to different NUMA nodes than the compute.  Try running:\\n\\necho 3 &gt; /proc/sys/vm/drop\\\\_caches\\n\\nbefore running llama-server/cli and you should get more consistent results between runs.  Also try running llama with --numa distribute (after the above) to see if it makes better use of your combined memory throughput.\\n\\nAnother thing could be if you are using all your cores for token generation and anything is competing for even one of them it will slow them all up.  Try running n-1 threads, and also try out different thread counts (1/2 cores, 3/4 cores, etc.) to see if you find a better balance of cores to memory throughput. \\n\\nAlso experiment with -ngl 999 -ot \\".\\\\*(\\\\[0-9\\\\])|\\\\[0-9\\\\]\\\\[0-9\\\\]).\\\\*ffn.\\\\*=CPU\\" type settings to split specific tensors to each GPU and CPU.  Putting experts on CPU as opposed to random layers with a lower -ngl will give you a big speedup for MoEs...  That -ot is just an example from memory, check the great posts here for details.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0q56ye","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When I see that it is usually your model loaded to different NUMA nodes than the compute.  Try running:&lt;/p&gt;\\n\\n&lt;p&gt;echo 3 &amp;gt; /proc/sys/vm/drop_caches&lt;/p&gt;\\n\\n&lt;p&gt;before running llama-server/cli and you should get more consistent results between runs.  Also try running llama with --numa distribute (after the above) to see if it makes better use of your combined memory throughput.&lt;/p&gt;\\n\\n&lt;p&gt;Another thing could be if you are using all your cores for token generation and anything is competing for even one of them it will slow them all up.  Try running n-1 threads, and also try out different thread counts (1/2 cores, 3/4 cores, etc.) to see if you find a better balance of cores to memory throughput. &lt;/p&gt;\\n\\n&lt;p&gt;Also experiment with -ngl 999 -ot &amp;quot;.*([0-9])|[0-9][0-9]).*ffn.*=CPU&amp;quot; type settings to split specific tensors to each GPU and CPU.  Putting experts on CPU as opposed to random layers with a lower -ngl will give you a big speedup for MoEs...  That -ot is just an example from memory, check the great posts here for details.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0q56ye/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751358947,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pmdoc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Threatening-Silence-","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pipuc","score":5,"author_fullname":"t2_15wqsifdjf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If you're already running a docker container then just use llama-cpp...\\n\\nhttps://github.com/ggml-org/llama.cpp/pkgs/container/llama.cpp\\n\\nserver-cuda is the tag you want. It comes with a nice gui.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pmdoc","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If you&amp;#39;re already running a docker container then just use llama-cpp...&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/ggml-org/llama.cpp/pkgs/container/llama.cpp\\"&gt;https://github.com/ggml-org/llama.cpp/pkgs/container/llama.cpp&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;server-cuda is the tag you want. It comes with a nice gui.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pmdoc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751348113,"author_flair_text":null,"treatment_tags":[],"created_utc":1751348113,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pj7ef","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShengrenR","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pipuc","score":2,"author_fullname":"t2_ji4n4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yea, you need ollama folks specifically for that pickle - you might try another backend in the meantime - vllm, exllamav3/tabbyapi, llamacpp, etc.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pj7ef","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yea, you need ollama folks specifically for that pickle - you might try another backend in the meantime - vllm, exllamav3/tabbyapi, llamacpp, etc.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pj7ef/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751346515,"author_flair_text":null,"treatment_tags":[],"created_utc":1751346515,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0raf25","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"waka324","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pipuc","score":1,"author_fullname":"t2_88nl5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Cgroups may be making the GPUs fall out of docker:\\n\\nhttps://github.com/NVIDIA/nvidia-container-toolkit/issues/538#issuecomment-2219617957","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0raf25","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Cgroups may be making the GPUs fall out of docker:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/NVIDIA/nvidia-container-toolkit/issues/538#issuecomment-2219617957\\"&gt;https://github.com/NVIDIA/nvidia-container-toolkit/issues/538#issuecomment-2219617957&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0raf25/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751377549,"author_flair_text":null,"treatment_tags":[],"created_utc":1751377549,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qq015","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thereisonlythedance","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pkxss","score":3,"author_fullname":"t2_u4wkj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Not sure it’s that unrealistic. I have a Threadripper 5965, 256GB RAM and 5x3090s and I get 8 t/s in llama.cpp. I’m wondering if Ollama updated and broke something for this user’s setup. A few weeks back I updated llama.cpp and my speed dropped to 1.3 t/s. Updated again recently and it was back to normal.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qq015","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Not sure it’s that unrealistic. I have a Threadripper 5965, 256GB RAM and 5x3090s and I get 8 t/s in llama.cpp. I’m wondering if Ollama updated and broke something for this user’s setup. A few weeks back I updated llama.cpp and my speed dropped to 1.3 t/s. Updated again recently and it was back to normal.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qq015/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751370074,"author_flair_text":null,"treatment_tags":[],"created_utc":1751370074,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0q7u3o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mkengine","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pmc43","score":1,"author_fullname":"t2_9p2xe","approved_by":null,"mod_note":null,"all_awardings":[],"body":"ik_llama still does not support speculative decoding, right? Using this I got around 10 t/s with Qwen3-0.6B and Qwen3-30B-A3B while only getting 9 t/s with ik_llama and only Qwen3-30B-A3B.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0q7u3o","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ik_llama still does not support speculative decoding, right? Using this I got around 10 t/s with Qwen3-0.6B and Qwen3-30B-A3B while only getting 9 t/s with ik_llama and only Qwen3-30B-A3B.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1loswvr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0q7u3o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751360553,"author_flair_text":null,"treatment_tags":[],"created_utc":1751360553,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pmc43","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0plb0x","score":1,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Open-WebUI is fine, you just put the host/port in same exact spot you do the Ollama. If it won't proceed without api key populated, just put whatever in there.\\n\\nRead into the info on the models page, and he has a command in there to run on the command line to start the server and I think how to build ik_llama.cpp too on there. It's 100% the best performance you'll get out of your CPU and on Deepseek.\\n\\nhttps://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF","edited":false,"author_flair_css_class":null,"name":"t1_n0pmc43","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Open-WebUI is fine, you just put the host/port in same exact spot you do the Ollama. If it won&amp;#39;t proceed without api key populated, just put whatever in there.&lt;/p&gt;\\n\\n&lt;p&gt;Read into the info on the models page, and he has a command in there to run on the command line to start the server and I think how to build ik_llama.cpp too on there. It&amp;#39;s 100% the best performance you&amp;#39;ll get out of your CPU and on Deepseek.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF\\"&gt;https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1loswvr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pmc43/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751348090,"author_flair_text":null,"collapsed":false,"created_utc":1751348090,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0plb0x","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sourpatchgrownadults","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pkxss","score":1,"author_fullname":"t2_vct0oav1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I was able to read with it in real time as it was generating text... It was actually 3.8 t/s.\\n\\nI'll look into that (ik_llama.cpp). Any suggested GUIs to pair with it?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0plb0x","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I was able to read with it in real time as it was generating text... It was actually 3.8 t/s.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll look into that (ik_llama.cpp). Any suggested GUIs to pair with it?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0plb0x/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347567,"author_flair_text":null,"treatment_tags":[],"created_utc":1751347567,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qa18s","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Herr_Drosselmeyer","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pkxss","score":1,"author_fullname":"t2_1zr9gwsn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I generally don't share in the hate for Ollama (it's fine for most situations), but in this case, where you really need everyghing to be as optimized as possible, yeah, don't rely on Ollama to get it right, it likely won't.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qa18s","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I generally don&amp;#39;t share in the hate for Ollama (it&amp;#39;s fine for most situations), but in this case, where you really need everyghing to be as optimized as possible, yeah, don&amp;#39;t rely on Ollama to get it right, it likely won&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qa18s/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751361882,"author_flair_text":null,"treatment_tags":[],"created_utc":1751361882,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pkxss","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Marksta","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pipuc","score":1,"author_fullname":"t2_559a1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Stop using Ollama, nobody knows how to debug that and you probably can't if there's some params they don't expose.\\n\\nYou want Ik_llama.cpp to run Deepseek on your beefy hardware, you can get 50pp t/s, 10 tg t/s on Ubergarm's Q2 that has similar quality to standard Q3/Q4.\\n\\nI'm pretty sure the 4 t/s you saw on Ollama wasn't real or was a latency caused fluke in how the tokens got counted. It's unrealistic with main line llama.cpp to hit that perf.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pkxss","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Stop using Ollama, nobody knows how to debug that and you probably can&amp;#39;t if there&amp;#39;s some params they don&amp;#39;t expose.&lt;/p&gt;\\n\\n&lt;p&gt;You want Ik_llama.cpp to run Deepseek on your beefy hardware, you can get 50pp t/s, 10 tg t/s on Ubergarm&amp;#39;s Q2 that has similar quality to standard Q3/Q4.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m pretty sure the 4 t/s you saw on Ollama wasn&amp;#39;t real or was a latency caused fluke in how the tokens got counted. It&amp;#39;s unrealistic with main line llama.cpp to hit that perf.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pkxss/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347383,"author_flair_text":null,"treatment_tags":[],"created_utc":1751347383,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pipuc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sourpatchgrownadults","can_mod_post":false,"created_utc":1751346274,"send_replies":true,"parent_id":"t1_n0phnl0","score":2,"author_fullname":"t2_vct0oav1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I ran nvidia-smi: first 3090 has about 21.4gb used, 2nd has about 16.3gb. Volatile GPU-Util shows first 3090 averaging 30%, second is stuck at 0%.\\n\\nI am running Ollama inside docker container. No idea about gpu pass through. Something something \\"--gpu all\\"? I know that was entered.\\n\\nContext is even SMALLER today. Prompt: \\"say something insightful\\". Only three words. Yesterday, it was about 5-6 paragraphs. Both on fresh chats within OWUI.\\n\\nHappy to provide any other information you think might be helpful","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pipuc","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I ran nvidia-smi: first 3090 has about 21.4gb used, 2nd has about 16.3gb. Volatile GPU-Util shows first 3090 averaging 30%, second is stuck at 0%.&lt;/p&gt;\\n\\n&lt;p&gt;I am running Ollama inside docker container. No idea about gpu pass through. Something something &amp;quot;--gpu all&amp;quot;? I know that was entered.&lt;/p&gt;\\n\\n&lt;p&gt;Context is even SMALLER today. Prompt: &amp;quot;say something insightful&amp;quot;. Only three words. Yesterday, it was about 5-6 paragraphs. Both on fresh chats within OWUI.&lt;/p&gt;\\n\\n&lt;p&gt;Happy to provide any other information you think might be helpful&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pipuc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751346274,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0phnl0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ShengrenR","can_mod_post":false,"created_utc":1751345752,"send_replies":true,"parent_id":"t3_1loswvr","score":3,"author_fullname":"t2_ji4n4","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That's .. nooot much to go off of. So many things - mainly, though, it sounds like you went from a few layers offloaded onto the GPUs, to pure CPU inference - double check your layers offload; run nvtop in CLI (or nvidia-smi) and see what's going on with the GPUs.\\n\\nIf it's not that.. how is ollama being run? stuffed in a docker container? is the gpu passed through properly?\\n\\nIf it's not that.. same context window size? Your inference speed will start to bleed speed pretty quickly as you go up in context length.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0phnl0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s .. nooot much to go off of. So many things - mainly, though, it sounds like you went from a few layers offloaded onto the GPUs, to pure CPU inference - double check your layers offload; run nvtop in CLI (or nvidia-smi) and see what&amp;#39;s going on with the GPUs.&lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s not that.. how is ollama being run? stuffed in a docker container? is the gpu passed through properly?&lt;/p&gt;\\n\\n&lt;p&gt;If it&amp;#39;s not that.. same context window size? Your inference speed will start to bleed speed pretty quickly as you go up in context length.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0phnl0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751345752,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pj2tx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sourpatchgrownadults","can_mod_post":false,"created_utc":1751346452,"send_replies":true,"parent_id":"t1_n0phowt","score":1,"author_fullname":"t2_vct0oav1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nope, even smaller now than yesterday.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pj2tx","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nope, even smaller now than yesterday.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pj2tx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751346452,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0phowt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"terminoid_","can_mod_post":false,"created_utc":1751345769,"send_replies":true,"parent_id":"t3_1loswvr","score":1,"author_fullname":"t2_1iu07dnz2i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"are you processing larger prompts than you were yesterday?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0phowt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;are you processing larger prompts than you were yesterday?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0phowt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751345769,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0q0qyk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thisoilguy","can_mod_post":false,"created_utc":1751356239,"send_replies":true,"parent_id":"t3_1loswvr","score":1,"author_fullname":"t2_gqpt6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I had similar happened to me. System just stopped using the gpus. A restart of my docker container with ollama has helped.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0q0qyk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I had similar happened to me. System just stopped using the gpus. A restart of my docker container with ollama has helped.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0q0qyk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751356239,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0vmabb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SillyLilBear","can_mod_post":false,"created_utc":1751425074,"send_replies":true,"parent_id":"t3_1loswvr","score":1,"author_fullname":"t2_wjjtz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You are spilling to CPU","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0vmabb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are spilling to CPU&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0vmabb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751425074,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ptjbq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"raul3820","can_mod_post":false,"created_utc":1751351982,"send_replies":true,"parent_id":"t3_1loswvr","score":1,"author_fullname":"t2_c2vfj9e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try cuda drivers from december 2024","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ptjbq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try cuda drivers from december 2024&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0ptjbq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751351982,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":-2,"removal_reason":null,"link_id":"t3_1loswvr","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0qxjy4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1751373117,"send_replies":true,"parent_id":"t1_n0pv4aq","score":4,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"that's not a setting on linux, only windows.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0qxjy4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;that&amp;#39;s not a setting on linux, only windows.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0qxjy4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751373117,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pv4aq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1loswvr","score":-2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[deleted]","edited":1751365753,"downs":0,"author_flair_css_class":null,"collapsed":true,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pv4aq/","num_reports":null,"locked":false,"name":"t1_n0pv4aq","created":1751352884,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1751352884,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0pzl0q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Impossible-Glass-487","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0py714","score":1,"author_fullname":"t2_1ltwu6ar9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's interesting, I didn't realize since all of OPs equipment is out of my price range.  Thanks for explaining, I need to do more research on larger models to better understand this.","edited":false,"author_flair_css_class":null,"name":"t1_n0pzl0q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s interesting, I didn&amp;#39;t realize since all of OPs equipment is out of my price range.  Thanks for explaining, I need to do more research on larger models to better understand this.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1loswvr","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pzl0q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751355534,"author_flair_text":null,"collapsed":false,"created_utc":1751355534,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0py714","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"reacusn","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pmmx4","score":3,"author_fullname":"t2_1ppg6hcqm8","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think, because deepseek's 671b models are moe with only 37b active, they'll be usable with 8-channel 3200mhz ddr4. Theoretically, that's about 200gb/s, which is a lot faster than 'consumer' grade 50gb/s memory. He's not running a dense model. 4t/s sounds appropriate.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0py714","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think, because deepseek&amp;#39;s 671b models are moe with only 37b active, they&amp;#39;ll be usable with 8-channel 3200mhz ddr4. Theoretically, that&amp;#39;s about 200gb/s, which is a lot faster than &amp;#39;consumer&amp;#39; grade 50gb/s memory. He&amp;#39;s not running a dense model. 4t/s sounds appropriate.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0py714/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751354688,"author_flair_text":null,"treatment_tags":[],"created_utc":1751354688,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pmmx4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Impossible-Glass-487","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0pkobl","score":-3,"author_fullname":"t2_1ltwu6ar9n","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You need VRAM.  I apologize because it's late and I thought you were saying 512 MB of consumer grade DDR4 not 512 GB, but still trying to offload onto DDR4 is going to be painfully slow.  The CPU helps but I believe thats only with the PCle bottleneck, doesn't do anything for VRAM.    \\n  \\nWhy wouldn't you just go for a smaller model?  You're trying to offload like 290GB onto the RAM but it's way too slow.  How are your temps?  Is the entire system overheating?  IDK where you are but where I am today was significantly hotter than yesterday and you're asking for a thermal issue with two 3090's running GDDR6X memory as is, and then stressing the entire system to the absolute max I might try monitoring the temps.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0pmmx4","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You need VRAM.  I apologize because it&amp;#39;s late and I thought you were saying 512 MB of consumer grade DDR4 not 512 GB, but still trying to offload onto DDR4 is going to be painfully slow.  The CPU helps but I believe thats only with the PCle bottleneck, doesn&amp;#39;t do anything for VRAM.    &lt;/p&gt;\\n\\n&lt;p&gt;Why wouldn&amp;#39;t you just go for a smaller model?  You&amp;#39;re trying to offload like 290GB onto the RAM but it&amp;#39;s way too slow.  How are your temps?  Is the entire system overheating?  IDK where you are but where I am today was significantly hotter than yesterday and you&amp;#39;re asking for a thermal issue with two 3090&amp;#39;s running GDDR6X memory as is, and then stressing the entire system to the absolute max I might try monitoring the temps.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pmmx4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751348244,"author_flair_text":null,"treatment_tags":[],"created_utc":1751348244,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pkobl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sourpatchgrownadults","can_mod_post":false,"created_utc":1751347250,"send_replies":true,"parent_id":"t1_n0pkj4f","score":1,"author_fullname":"t2_vct0oav1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I thought I could run a cpu+gpu hybrid. Idk how the hell I got 4 t/s yesterday, but I'd love to recreate it and idk what went right and what went wrong lol","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pkobl","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I thought I could run a cpu+gpu hybrid. Idk how the hell I got 4 t/s yesterday, but I&amp;#39;d love to recreate it and idk what went right and what went wrong lol&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1loswvr","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pkobl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347250,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0pkj4f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Impossible-Glass-487","can_mod_post":false,"created_utc":1751347177,"send_replies":true,"parent_id":"t3_1loswvr","score":-10,"author_fullname":"t2_1ltwu6ar9n","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Maybe it's the 48GB of VRAM on a 671B q4 model with (WTF?) 512GB of (WTF?) DDR4 @ (again, WTF?) 3200?  What in the actual fuck?  What *didn't* you break?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0pkj4f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe it&amp;#39;s the 48GB of VRAM on a 671B q4 model with (WTF?) 512GB of (WTF?) DDR4 @ (again, WTF?) 3200?  What in the actual fuck?  What &lt;em&gt;didn&amp;#39;t&lt;/em&gt; you break?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1loswvr/new_to_the_scene_yesterday_got_4_ts_on_r1_671b_q4/n0pkj4f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751347177,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1loswvr","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-10}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
