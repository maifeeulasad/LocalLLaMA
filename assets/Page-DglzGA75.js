import{j as e}from"./index-Bqs-ekb2.js";import{R as l}from"./RedditPostRenderer-DUVdf0-i.js";import"./index-D52ORTDm.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"[https://huggingface.co/apple/DiffuCoder-7B-cpGRPO](https://huggingface.co/apple/DiffuCoder-7B-cpGRPO) (base and instruct also available)\\n\\nCurrently trying - and failing - to run test it on Colab, but really looking forward to it!\\n\\nAlso, anyone got an idea how I can run it on Apple Silicon?\\n\\n[Benchmarks compared to other coding and diffusion models](https://preview.redd.it/s19j3dmfneaf1.png?width=1176&amp;format=png&amp;auto=webp&amp;s=927e506f764ded47a4e715aea53c223e56ea7ae6)\\n\\n[https://arxiv.org/pdf/2506.20639](https://arxiv.org/pdf/2506.20639)","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"DiffuCoder 7B - New coding diffusion LLM by Apple","link_flair_richtext":[{"e":"text","t":"New Model"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"media_metadata":{"s19j3dmfneaf1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":84,"x":108,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cde3b3074354143bfe56532c93502a45f3cf9fbd"},{"y":168,"x":216,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=92c383eaf085a07945d94591e52941a93a33c123"},{"y":249,"x":320,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b22c3a42268be01220ee63470cc279c879dc59ad"},{"y":498,"x":640,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d5a21d3c223b732d53e698bb3aad0211b4985d08"},{"y":747,"x":960,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=18f094eeffed1f613bc262d5afc62d028149ce8d"},{"y":841,"x":1080,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fdc4c29f7ac33b8944762504d53b25b78fd7b409"}],"s":{"y":916,"x":1176,"u":"https://preview.redd.it/s19j3dmfneaf1.png?width=1176&amp;format=png&amp;auto=webp&amp;s=927e506f764ded47a4e715aea53c223e56ea7ae6"},"id":"s19j3dmfneaf1"}},"name":"t3_1lpoqlu","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.96,"author_flair_background_color":null,"ups":264,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_alho5","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"New Model","can_mod_post":false,"score":264,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=94f95b15f093e7e4c52427bf32633f935890f3d9","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"self","content_categories":null,"is_self":true,"subreddit_type":"public","created":1751437787,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://huggingface.co/apple/DiffuCoder-7B-cpGRPO\\"&gt;https://huggingface.co/apple/DiffuCoder-7B-cpGRPO&lt;/a&gt; (base and instruct also available)&lt;/p&gt;\\n\\n&lt;p&gt;Currently trying - and failing - to run test it on Colab, but really looking forward to it!&lt;/p&gt;\\n\\n&lt;p&gt;Also, anyone got an idea how I can run it on Apple Silicon?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/s19j3dmfneaf1.png?width=1176&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=927e506f764ded47a4e715aea53c223e56ea7ae6\\"&gt;Benchmarks compared to other coding and diffusion models&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/pdf/2506.20639\\"&gt;https://arxiv.org/pdf/2506.20639&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?auto=webp&amp;s=87b4e9cf26a9425b49fe91fa407b4881683411a1","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9b3b8168a8a55fa37a1679a4a1a0f95a20bf5a1","width":108,"height":58},{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=86ce2a87a27be1f49658d6de3f4cad2433715662","width":216,"height":116},{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=274e1732d62c8ad27ef17a008734eb9550cb84bd","width":320,"height":172},{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ed4a0394c2c1d722f620e6214e63d44c79d3e340","width":640,"height":345},{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4ca34810011f0a3d6f476113f06f5b836fa8a3e7","width":960,"height":518},{"url":"https://external-preview.redd.it/WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e8963ee356c3b39eafe785ca3139e056eb01741d","width":1080,"height":583}],"variants":{},"id":"WJ1Mt_9K-aAaMAebSityZ71IWIFD1yMghVJOklMW6Xo"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"ced98442-f5d3-11ed-b657-66d3b15490c6","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#ffb000","id":"1lpoqlu","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"DunklerErpel","discussion_type":null,"num_comments":57,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/","subreddit_subscribers":494001,"created_utc":1751437787,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0wjuvm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"FullstackSensei","can_mod_post":false,"created_utc":1751441077,"send_replies":true,"parent_id":"t1_n0wipbt","score":52,"author_fullname":"t2_17n3nqtj56","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\"Training recipe: Using DiffuLLaMA's adaptation approach\\" from the base model on HF.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wjuvm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;quot;Training recipe: Using DiffuLLaMA&amp;#39;s adaptation approach&amp;quot; from the base model on HF.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wjuvm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751441077,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":52}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0yc537","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"JohnnyLovesData","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xgyg0","score":2,"author_fullname":"t2_rsw4yc1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The F U Coder","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0yc537","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The F U Coder&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0yc537/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751468349,"author_flair_text":null,"treatment_tags":[],"created_utc":1751468349,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xgyg0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"rorowhat","can_mod_post":false,"created_utc":1751458285,"send_replies":true,"parent_id":"t1_n0wipbt","score":8,"author_fullname":"t2_yq51a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Lol that's funny","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xgyg0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lol that&amp;#39;s funny&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xgyg0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751458285,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wipbt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"HealthCorrect","can_mod_post":false,"created_utc":1751440410,"send_replies":true,"parent_id":"t3_1lpoqlu","score":106,"author_fullname":"t2_7w7ujxhh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ok, it’s a qwen2.5 coder finetune. Also, how can an auto regressive model be turned into a diffusion model?","edited":1751469482,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wipbt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ok, it’s a qwen2.5 coder finetune. Also, how can an auto regressive model be turned into a diffusion model?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wipbt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751440410,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":106}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0yb480","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0y8ll2","score":5,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just tried this single prompt and immediately posted here.\\n\\nIt took 01:39 (99 seconds) to run on 250W power limited RTX 3090.\\n\\nLooks like this speed is similar to what it may take for some reasoning model to come up with this kind of response and is much slower than similarly sized non-reasoning models response.\\n\\nI'll probably wait for either Apple examples on how to inference or even better for of the OpenAI API compatible servers implementing support for these models (e.g. llama.cpp or vLLM) before trying seriously.\\n\\nFrom what I know from image generation diffusion models it's quite easy to get weird / strange / wrong results with wrong inference parameters and the parameters in the code above are copied from Dream 7B example.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0yb480","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just tried this single prompt and immediately posted here.&lt;/p&gt;\\n\\n&lt;p&gt;It took 01:39 (99 seconds) to run on 250W power limited RTX 3090.&lt;/p&gt;\\n\\n&lt;p&gt;Looks like this speed is similar to what it may take for some reasoning model to come up with this kind of response and is much slower than similarly sized non-reasoning models response.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll probably wait for either Apple examples on how to inference or even better for of the OpenAI API compatible servers implementing support for these models (e.g. llama.cpp or vLLM) before trying seriously.&lt;/p&gt;\\n\\n&lt;p&gt;From what I know from image generation diffusion models it&amp;#39;s quite easy to get weird / strange / wrong results with wrong inference parameters and the parameters in the code above are copied from Dream 7B example.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0yb480/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751468057,"author_flair_text":null,"treatment_tags":[],"created_utc":1751468057,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"n0y8ll2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"nava_7777","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0y4yey","score":3,"author_fullname":"t2_mdukl","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Super grateful!\\n\\n\\nDid you notice any inference speed improvement over classic architectures?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0y8ll2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Super grateful!&lt;/p&gt;\\n\\n&lt;p&gt;Did you notice any inference speed improvement over classic architectures?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0y8ll2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751467339,"author_flair_text":null,"treatment_tags":[],"created_utc":1751467339,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0y4yey","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"created_utc":1751466283,"send_replies":true,"parent_id":"t1_n0wp7h5","score":5,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Result:\\n\\n    $ python test01.py \\n    A new version of the following files was downloaded from https://huggingface.co/apple/DiffuCoder-7B-cpGRPO:\\n    - generation_utils.py\\n    . Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\\n    Loading checkpoint shards: 100%|████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 21.30it/s]\\n    The following generation flags are not valid and may be ignored: ['temperature']. Set \`TRANSFORMERS_VERBOSITY=info\` for more details.\\n    The following generation flags are not valid and may be ignored: ['temperature']. Set \`TRANSFORMERS_VERBOSITY=info\` for more details.\\n    Here is the code to solve this problem: \\n    \`\`\`python\\n    import torch\\n    \\n    class ToyTrainer:\\n        def train(self, model, criterion, optimizer, dataset, epochs=10):\\n            for epoch in range(epochs):\\n                for inputs, labels in dataset:\\n                    optimizer.zero_grad()\\n                    outputs = model(inputs)\\n                    loss = criterion(outputs, labels)\\n                    loss.backward()\\n                    optimizer.step()\\n            return\\n    \`\`\`&lt;|im_end|&gt;\\n    &lt;|dlm_pad|&gt;&lt;|dlm_pad|&gt;\\n\\nAnd \`&lt;|dlm_pad|&gt;\` tokens continue, probably up to 512. Will need to add a check for \`&lt;|im_end|&gt;\`.\\n\\nSo this or similar code should work on Apple Silicon too.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y4yey","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Result:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;$ python test01.py \\nA new version of the following files was downloaded from https://huggingface.co/apple/DiffuCoder-7B-cpGRPO:\\n- generation_utils.py\\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\\nLoading checkpoint shards: 100%|████████████████████████████████████████████████████████| 4/4 [00:00&amp;lt;00:00, 21.30it/s]\\nThe following generation flags are not valid and may be ignored: [&amp;#39;temperature&amp;#39;]. Set \`TRANSFORMERS_VERBOSITY=info\` for more details.\\nThe following generation flags are not valid and may be ignored: [&amp;#39;temperature&amp;#39;]. Set \`TRANSFORMERS_VERBOSITY=info\` for more details.\\nHere is the code to solve this problem: \\n\`\`\`python\\nimport torch\\n\\nclass ToyTrainer:\\n    def train(self, model, criterion, optimizer, dataset, epochs=10):\\n        for epoch in range(epochs):\\n            for inputs, labels in dataset:\\n                optimizer.zero_grad()\\n                outputs = model(inputs)\\n                loss = criterion(outputs, labels)\\n                loss.backward()\\n                optimizer.step()\\n        return\\n\`\`\`&amp;lt;|im_end|&amp;gt;\\n&amp;lt;|dlm_pad|&amp;gt;&amp;lt;|dlm_pad|&amp;gt;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;And &lt;code&gt;&amp;lt;|dlm_pad|&amp;gt;&lt;/code&gt; tokens continue, probably up to 512. Will need to add a check for &lt;code&gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;So this or similar code should work on Apple Silicon too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0y4yey/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751466283,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0y4mvf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thirteen-bit","can_mod_post":false,"created_utc":1751466189,"send_replies":true,"parent_id":"t1_n0wp7h5","score":2,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Worked but cannot post here. Too long comment? Will try to split.\\n\\nPreparation (on Linux + CUDA but should be similar on Apple):\\n\\n    $ mkdir diffucoder &amp;&amp; cd diffucoder\\n    $ python3 -m venv .venv\\n    $ source ./.venv/bin/activate\\n    $ pip install torch transformers","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y4mvf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Worked but cannot post here. Too long comment? Will try to split.&lt;/p&gt;\\n\\n&lt;p&gt;Preparation (on Linux + CUDA but should be similar on Apple):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;$ mkdir diffucoder &amp;amp;&amp;amp; cd diffucoder\\n$ python3 -m venv .venv\\n$ source ./.venv/bin/activate\\n$ pip install torch transformers\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0y4mvf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751466189,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0y4pjm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thirteen-bit","can_mod_post":false,"created_utc":1751466211,"send_replies":true,"parent_id":"t1_n0wp7h5","score":2,"author_fullname":"t2_9l12dgc5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Code:\\n\\n\`\`\`\\n#!/usr/bin/env python3\\n# Based on\\n# https://github.com/HKUNLP/Dream?tab=readme-ov-file#usage\\nimport torch\\nfrom transformers import AutoModel, AutoTokenizer\\n\\nif torch.cuda.is_available():\\n    device = 'cuda'\\n    dtype = torch.bfloat16\\nelse:\\n    if torch.mps.is_available():\\n        device = 'mps'\\n        # Should be supported on recent torch?\\n        dtype = torch.bfloat16\\n    else:\\n        device = 'cpu'\\n        dtype = torch.float32\\n\\nmodel_path = \\"apple/DiffuCoder-7B-cpGRPO\\"\\n\\nmodel = AutoModel.from_pretrained(model_path, \\n                                  torch_dtype=dtype,\\n                                  trust_remote_code=True)\\ntokenizer = AutoTokenizer.from_pretrained(model_path,\\n                                          trust_remote_code=True)\\nmodel = model.to(device).eval()\\n\\nmessages = [\\n    {\\"role\\": \\"user\\", \\"content\\": \\"Please write a Python class that implements a PyTorch trainer capable of training a model on a toy dataset.\\"}\\n]\\ninputs = tokenizer.apply_chat_template(\\n    messages, return_tensors=\\"pt\\", return_dict=True, add_generation_prompt=True\\n)\\ninput_ids = inputs.input_ids.to(device=device)\\nattention_mask = inputs.attention_mask.to(device=device)\\n\\noutput = model.diffusion_generate(\\n    input_ids,\\n    attention_mask=attention_mask,\\n    max_new_tokens=512,\\n    output_history=True,\\n    return_dict_in_generate=True,\\n    steps=512,\\n    temperature=0.2,\\n    top_p=0.95,\\n    alg=\\"entropy\\",\\n    alg_temp=0.,\\n)\\ngenerations = [\\n    tokenizer.decode(g[len(p) :].tolist())\\n    for p, g in zip(input_ids, output.sequences)\\n]\\n\\nprint(generations[0].split(tokenizer.eos_token)[0])\\n\`\`\`","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y4pjm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Code:&lt;/p&gt;\\n\\n&lt;p&gt;\`\`\`&lt;/p&gt;\\n\\n&lt;h1&gt;!/usr/bin/env python3&lt;/h1&gt;\\n\\n&lt;h1&gt;Based on&lt;/h1&gt;\\n\\n&lt;h1&gt;&lt;a href=\\"https://github.com/HKUNLP/Dream?tab=readme-ov-file#usage\\"&gt;https://github.com/HKUNLP/Dream?tab=readme-ov-file#usage&lt;/a&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;import torch\\nfrom transformers import AutoModel, AutoTokenizer&lt;/p&gt;\\n\\n&lt;p&gt;if torch.cuda.is_available():\\n    device = &amp;#39;cuda&amp;#39;\\n    dtype = torch.bfloat16\\nelse:\\n    if torch.mps.is_available():\\n        device = &amp;#39;mps&amp;#39;\\n        # Should be supported on recent torch?\\n        dtype = torch.bfloat16\\n    else:\\n        device = &amp;#39;cpu&amp;#39;\\n        dtype = torch.float32&lt;/p&gt;\\n\\n&lt;p&gt;model_path = &amp;quot;apple/DiffuCoder-7B-cpGRPO&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;model = AutoModel.from_pretrained(model_path, \\n                                  torch_dtype=dtype,\\n                                  trust_remote_code=True)\\ntokenizer = AutoTokenizer.from_pretrained(model_path,\\n                                          trust_remote_code=True)\\nmodel = model.to(device).eval()&lt;/p&gt;\\n\\n&lt;p&gt;messages = [\\n    {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Please write a Python class that implements a PyTorch trainer capable of training a model on a toy dataset.&amp;quot;}\\n]\\ninputs = tokenizer.apply_chat_template(\\n    messages, return_tensors=&amp;quot;pt&amp;quot;, return_dict=True, add_generation_prompt=True\\n)\\ninput_ids = inputs.input_ids.to(device=device)\\nattention_mask = inputs.attention_mask.to(device=device)&lt;/p&gt;\\n\\n&lt;p&gt;output = model.diffusion_generate(\\n    input_ids,\\n    attention_mask=attention_mask,\\n    max_new_tokens=512,\\n    output_history=True,\\n    return_dict_in_generate=True,\\n    steps=512,\\n    temperature=0.2,\\n    top_p=0.95,\\n    alg=&amp;quot;entropy&amp;quot;,\\n    alg_temp=0.,\\n)\\ngenerations = [\\n    tokenizer.decode(g[len(p) :].tolist())\\n    for p, g in zip(input_ids, output.sequences)\\n]&lt;/p&gt;\\n\\n&lt;p&gt;print(generations[0].split(tokenizer.eos_token)[0])\\n\`\`\`&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0y4pjm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751466211,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wp7h5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thirteen-bit","can_mod_post":false,"created_utc":1751444242,"send_replies":true,"parent_id":"t3_1lpoqlu","score":14,"author_fullname":"t2_9l12dgc5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Interesting\\n\\n&gt; how I can run it on Apple Silicon?\\n\\nAs there are no inference examples from Apple yet, maybe try to inference it like Dream 7B?\\n\\npytorch should run on mac?\\n\\nSomething like this:\\nhttps://github.com/HKUNLP/Dream#usage\\n\\nI'll probably try it this way when I'll get near my desktop with GPU later today if there'll be no examples by then.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wp7h5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Interesting&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;how I can run it on Apple Silicon?&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;As there are no inference examples from Apple yet, maybe try to inference it like Dream 7B?&lt;/p&gt;\\n\\n&lt;p&gt;pytorch should run on mac?&lt;/p&gt;\\n\\n&lt;p&gt;Something like this:\\n&lt;a href=\\"https://github.com/HKUNLP/Dream#usage\\"&gt;https://github.com/HKUNLP/Dream#usage&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll probably try it this way when I&amp;#39;ll get near my desktop with GPU later today if there&amp;#39;ll be no examples by then.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wp7h5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751444242,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xv383","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"noage","can_mod_post":false,"created_utc":1751463256,"send_replies":true,"parent_id":"t1_n0weqyz","score":28,"author_fullname":"t2_5ao30","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"One of the largest companies in the world releases a small model finetunee on Chinese company's base model using previously published methods. I like to see it. But it's also interesting to see how much Apple hype is pulled from everything. To me, releasing a model like this at this point shows they treat AI more as a curiosity than a focus, and it doesn't seem to suggest that the game is on from Apple's side.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xv383","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One of the largest companies in the world releases a small model finetunee on Chinese company&amp;#39;s base model using previously published methods. I like to see it. But it&amp;#39;s also interesting to see how much Apple hype is pulled from everything. To me, releasing a model like this at this point shows they treat AI more as a curiosity than a focus, and it doesn&amp;#39;t seem to suggest that the game is on from Apple&amp;#39;s side.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xv383/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751463256,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":28}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xp1ip","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"mnt_brain","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xd1io","score":-8,"author_fullname":"t2_1mtt9dytfn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I have no issue with siri on my iphone- except it can be a little long winded","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0xp1ip","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I have no issue with siri on my iphone- except it can be a little long winded&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xp1ip/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751461236,"author_flair_text":null,"treatment_tags":[],"created_utc":1751461236,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-8}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xd1io","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pitchblackfriday","can_mod_post":false,"created_utc":1751456724,"send_replies":true,"parent_id":"t1_n0weqyz","score":14,"author_fullname":"t2_1dt829ipgg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think they should dogfood this model for fixing their braindead on-device LLM.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xd1io","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think they should dogfood this model for fixing their braindead on-device LLM.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xd1io/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751456724,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}}],"before":null}},"user_reports":[],"saved":false,"id":"n0weqyz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Ok_Appearance3584","can_mod_post":false,"created_utc":1751438205,"send_replies":true,"parent_id":"t3_1lpoqlu","score":49,"author_fullname":"t2_oyxj85n1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wow! Apple releasing a coder model. The game is on!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0weqyz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow! Apple releasing a coder model. The game is on!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0weqyz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751438205,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":49}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0wrpn1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"7734128","can_mod_post":false,"created_utc":1751445754,"send_replies":true,"parent_id":"t1_n0wnl8k","score":29,"author_fullname":"t2_c4tkv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I suppose that being able to adjust previous output will be inherently advantageous.\\n\\nBeing able to change conclusions and fix mistakes, as well as implement some \\"thinking\\" in place rather than front loading that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wrpn1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I suppose that being able to adjust previous output will be inherently advantageous.&lt;/p&gt;\\n\\n&lt;p&gt;Being able to change conclusions and fix mistakes, as well as implement some &amp;quot;thinking&amp;quot; in place rather than front loading that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wrpn1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751445754,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xnucc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xmpbb","score":2,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Depends on the temperature","edited":false,"author_flair_css_class":null,"name":"t1_n0xnucc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Depends on the temperature&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lpoqlu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xnucc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751460820,"author_flair_text":null,"collapsed":false,"created_utc":1751460820,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ypho8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"knownboyofno","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xmpbb","score":2,"author_fullname":"t2_5y9divj7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I haven't had 8 users, but I have done this, and I get a different response for each. It also works for batches where I would do n=20.","edited":false,"author_flair_css_class":null,"name":"t1_n0ypho8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I haven&amp;#39;t had 8 users, but I have done this, and I get a different response for each. It also works for batches where I would do n=20.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lpoqlu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0ypho8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751472073,"author_flair_text":null,"collapsed":false,"created_utc":1751472073,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xmpbb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SteveRD1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xiw17","score":2,"author_fullname":"t2_ey837","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Question..if you have say vLLM setup, and you batch the same question 8 times (for 8 users) to the same model, what do you get?\\n\\n8 identical responses, 8 most likely similar responses, potentially a wide variety of responses?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xmpbb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Question..if you have say vLLM setup, and you batch the same question 8 times (for 8 users) to the same model, what do you get?&lt;/p&gt;\\n\\n&lt;p&gt;8 identical responses, 8 most likely similar responses, potentially a wide variety of responses?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xmpbb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751460421,"author_flair_text":null,"treatment_tags":[],"created_utc":1751460421,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ysdno","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clopenYourMind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ypp8h","score":1,"author_fullname":"t2_1qdxnf8ybp","approved_by":null,"mod_note":null,"all_awardings":[],"body":"On personal, very basic. But I test and deploy self-hosting setups for orgs I work with -- not only LLMs, but that is definitely growing in demand. Often security is a top requirement so we go more on AWS side of house than runpod or other shared standups","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_n0ysdno","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On personal, very basic. But I test and deploy self-hosting setups for orgs I work with -- not only LLMs, but that is definitely growing in demand. Often security is a top requirement so we go more on AWS side of house than runpod or other shared standups&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1lpoqlu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0ysdno/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751472896,"author_flair_text":null,"treatment_tags":[],"created_utc":1751472896,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ypp8h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"knownboyofno","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0yfox9","score":1,"author_fullname":"t2_5y9divj7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What hardware/setup do you have?","edited":false,"author_flair_css_class":null,"name":"t1_n0ypp8h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What hardware/setup do you have?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lpoqlu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0ypp8h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751472133,"author_flair_text":null,"collapsed":false,"created_utc":1751472133,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0yfox9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"clopenYourMind","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xiw17","score":1,"author_fullname":"t2_1qdxnf8ybp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Sorry for the tangent - I've tried setting up vLLM recently but can't seem to find models that fit (heavy GPU usage baseline relative to, say, ollama). Any recommendations where I can get more information on these sorts of things?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0yfox9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Sorry for the tangent - I&amp;#39;ve tried setting up vLLM recently but can&amp;#39;t seem to find models that fit (heavy GPU usage baseline relative to, say, ollama). Any recommendations where I can get more information on these sorts of things?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0yfox9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751469358,"author_flair_text":null,"treatment_tags":[],"created_utc":1751469358,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xiw17","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DepthHour1669","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0x1m97","score":19,"author_fullname":"t2_t6glzswk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you ever tried to run inference for 2, 4, 8, 16 users, instead of just 1 user? If you use a heavy duty inference software like vLLM (aka not llama.cpp), you will notice that 2 users or 4 users or even 8 users can all run inference at the same time with everyone getting the almost same inference speed as just 1 user! This is because of batching, because the matrix multiplications in transformer layers are highly parallelizable and benefit from batching on GPU (better tensor core utilization, memory bandwidth usage, etc.).\\n\\nDiffusion basically allows you to do this inherently. These models predict entire sequences (or denoised versions of them) in parallel, which enables much better GPU utilization: full-sequence batching through matmuls instead of token-by-token computation","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0xiw17","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you ever tried to run inference for 2, 4, 8, 16 users, instead of just 1 user? If you use a heavy duty inference software like vLLM (aka not llama.cpp), you will notice that 2 users or 4 users or even 8 users can all run inference at the same time with everyone getting the almost same inference speed as just 1 user! This is because of batching, because the matrix multiplications in transformer layers are highly parallelizable and benefit from batching on GPU (better tensor core utilization, memory bandwidth usage, etc.).&lt;/p&gt;\\n\\n&lt;p&gt;Diffusion basically allows you to do this inherently. These models predict entire sequences (or denoised versions of them) in parallel, which enables much better GPU utilization: full-sequence batching through matmuls instead of token-by-token computation&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xiw17/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751459023,"author_flair_text":null,"treatment_tags":[],"created_utc":1751459023,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}}],"before":null}},"user_reports":[],"saved":false,"id":"n0x1m97","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"DunklerErpel","can_mod_post":false,"created_utc":1751451410,"send_replies":true,"parent_id":"t1_n0wnl8k","score":19,"author_fullname":"t2_alho5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In addition to what u/7734128 wrote: dLLM are supposedly not linear in terms of time, it's not first token, second token, third token etc., but tokens 1, 15, 99, then 5, 34, 66 etc. More in parallel, thus faster(?), plus when encountering a new \\"thought\\" they can patch/update previously generated tokens.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x1m97","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In addition to what &lt;a href=\\"/u/7734128\\"&gt;u/7734128&lt;/a&gt; wrote: dLLM are supposedly not linear in terms of time, it&amp;#39;s not first token, second token, third token etc., but tokens 1, 15, 99, then 5, 34, 66 etc. More in parallel, thus faster(?), plus when encountering a new &amp;quot;thought&amp;quot; they can patch/update previously generated tokens.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x1m97/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751451410,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":19}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n1147en","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FunnyAsparagus1253","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ywtvu","score":1,"author_fullname":"t2_i6c8tay3w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This isn’t FIM though. FIM is a special thing where you actually give it the start and the end and all that comes out is whatever goes in the middle 😅 an actual FIM request would not have any opportunity to ‘change the ending’ any more than they’d be able to change the start. Afaik","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n1147en","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This isn’t FIM though. FIM is a special thing where you actually give it the start and the end and all that comes out is whatever goes in the middle 😅 an actual FIM request would not have any opportunity to ‘change the ending’ any more than they’d be able to change the start. Afaik&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n1147en/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751497861,"author_flair_text":null,"treatment_tags":[],"created_utc":1751497861,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ywtvu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0x6qyt","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"\\\\&gt; Fill in the blank in the following sentence: “We immediately \\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_ after getting off the phone with the doctor.”\\n\\nAll the models I've tried, except for Mistral Nemo did well. Even 1b Gemma 3.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0ywtvu","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&amp;gt; Fill in the blank in the following sentence: “We immediately ________ after getting off the phone with the doctor.”&lt;/p&gt;\\n\\n&lt;p&gt;All the models I&amp;#39;ve tried, except for Mistral Nemo did well. Even 1b Gemma 3.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0ywtvu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751474175,"author_flair_text":null,"treatment_tags":[],"created_utc":1751474175,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0x6qyt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"datbackup","can_mod_post":false,"created_utc":1751453967,"send_replies":true,"parent_id":"t1_n0wnl8k","score":11,"author_fullname":"t2_ielo6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Transformers are famously weak on “fill in the middle” type problems, and diffusion models should be much better about this\\n\\nTransformers have definitely improved in this regard but you can still get them to screw up pretty easily if you try something like “Fill in the blank in the following sentence:\\n\\n“We immediately ________ after getting off the phone with the doctor.”\\n\\nWhat will often happen is the transformer model will mess up the ending of the sentence in order to make it fit with whatever it chose to fill in the blank.\\n\\nEdit:\\n\\nI decided to test this since it’s been a while, and deepseek v3-0324 is answering perfectly so far.\\n\\nNot sure if smaller transformer models are still prone to this error, or if it’s more or less solved at this point.\\n\\nAnyway, my example was on the simple side; filling in a whole blank sentence or paragraph might be a more accurate assessment.\\n\\nYou can search for “Fill-in-the-middle” or FIM to find discussions / papers about this","edited":1751454647,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x6qyt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Transformers are famously weak on “fill in the middle” type problems, and diffusion models should be much better about this&lt;/p&gt;\\n\\n&lt;p&gt;Transformers have definitely improved in this regard but you can still get them to screw up pretty easily if you try something like “Fill in the blank in the following sentence:&lt;/p&gt;\\n\\n&lt;p&gt;“We immediately ________ after getting off the phone with the doctor.”&lt;/p&gt;\\n\\n&lt;p&gt;What will often happen is the transformer model will mess up the ending of the sentence in order to make it fit with whatever it chose to fill in the blank.&lt;/p&gt;\\n\\n&lt;p&gt;Edit:&lt;/p&gt;\\n\\n&lt;p&gt;I decided to test this since it’s been a while, and deepseek v3-0324 is answering perfectly so far.&lt;/p&gt;\\n\\n&lt;p&gt;Not sure if smaller transformer models are still prone to this error, or if it’s more or less solved at this point.&lt;/p&gt;\\n\\n&lt;p&gt;Anyway, my example was on the simple side; filling in a whole blank sentence or paragraph might be a more accurate assessment.&lt;/p&gt;\\n\\n&lt;p&gt;You can search for “Fill-in-the-middle” or FIM to find discussions / papers about this&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x6qyt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751453967,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0wqf7g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"thebadslime","can_mod_post":false,"created_utc":1751444977,"send_replies":true,"parent_id":"t1_n0wnl8k","score":8,"author_fullname":"t2_i5os0v0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"supposed to be faster","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wqf7g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;supposed to be faster&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wqf7g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751444977,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xjtej","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Consistent-Donut-534","can_mod_post":false,"created_utc":1751459369,"send_replies":true,"parent_id":"t1_n0wnl8k","score":3,"author_fullname":"t2_1qiqcvre0w","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"One of the biggest issues with autoregressive models is that, unlike how humans think and speak, the tokens generated at the start of the sequence are generated with little to no knowledge of what the tokens at the end of the sequence will be. Also diffusion lets us refine the idea, which is similar to reasoning.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xjtej","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One of the biggest issues with autoregressive models is that, unlike how humans think and speak, the tokens generated at the start of the sequence are generated with little to no knowledge of what the tokens at the end of the sequence will be. Also diffusion lets us refine the idea, which is similar to reasoning.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xjtej/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751459369,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xj2oi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xhf39","score":1,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ah neat","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xj2oi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah neat&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xj2oi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751459092,"author_flair_text":null,"treatment_tags":[],"created_utc":1751459092,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0z4z51","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Felladrin","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xhf39","score":1,"author_fullname":"t2_wp9mv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Indeed! One of the demos is the LLaDA's one: [https://huggingface.co/spaces/multimodalart/LLaDA](https://huggingface.co/spaces/multimodalart/LLaDA)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0z4z51","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Indeed! One of the demos is the LLaDA&amp;#39;s one: &lt;a href=\\"https://huggingface.co/spaces/multimodalart/LLaDA\\"&gt;https://huggingface.co/spaces/multimodalart/LLaDA&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0z4z51/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751476463,"author_flair_text":null,"treatment_tags":[],"created_utc":1751476463,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xhf39","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ForsookComparison","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xadp5","score":3,"author_fullname":"t2_on5es7pe3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Huggingface has a demo that explains this perfectly but the link is escaping me","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0xhf39","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Huggingface has a demo that explains this perfectly but the link is escaping me&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xhf39/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751458462,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1751458462,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xadp5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Minute_Attempt3063","can_mod_post":false,"created_utc":1751455597,"send_replies":true,"parent_id":"t1_n0wnl8k","score":3,"author_fullname":"t2_t6m6d9my","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Imagine Stable Diffusion but for text.\\n\\nI think that's the best way to describe it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xadp5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imagine Stable Diffusion but for text.&lt;/p&gt;\\n\\n&lt;p&gt;I think that&amp;#39;s the best way to describe it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xadp5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751455597,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n10ptg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ljosif","can_mod_post":false,"created_utc":1751493171,"send_replies":true,"parent_id":"t1_n0wnl8k","score":3,"author_fullname":"t2_4rlver1q","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"For me the 2nd lecture of this talk gave me understanding of how things fit together \\n\\nhttps://m.youtube.com/watch?v=klW65MWJ1PY\\n\\nAnd then this tutorial \\n\\nhttps://m.youtube.com/watch?v=Fk2I6pa6UeA\\n\\nexplained to me the detail of the sampling, the hows and whys, that's usually not explained much (attention is on the NN model) but it's as important. hth","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n10ptg6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;For me the 2nd lecture of this talk gave me understanding of how things fit together &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://m.youtube.com/watch?v=klW65MWJ1PY\\"&gt;https://m.youtube.com/watch?v=klW65MWJ1PY&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;And then this tutorial &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://m.youtube.com/watch?v=Fk2I6pa6UeA\\"&gt;https://m.youtube.com/watch?v=Fk2I6pa6UeA&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;explained to me the detail of the sampling, the hows and whys, that&amp;#39;s usually not explained much (attention is on the NN model) but it&amp;#39;s as important. hth&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n10ptg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751493171,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0x3ha9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NeuralNakama","can_mod_post":false,"created_utc":1751452380,"send_replies":true,"parent_id":"t1_n0wnl8k","score":2,"author_fullname":"t2_1oj5msrcxf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Transformer working linear diffusion like parallel speed difference is awesome but diffusion models not reliable on quality. I think hybrid models will emerge in the future. But i don't use any diffusion model right now","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x3ha9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Transformer working linear diffusion like parallel speed difference is awesome but diffusion models not reliable on quality. I think hybrid models will emerge in the future. But i don&amp;#39;t use any diffusion model right now&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x3ha9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751452380,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0z9od4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Accomplished-Low3305","can_mod_post":false,"created_utc":1751477778,"send_replies":true,"parent_id":"t1_n0wnl8k","score":2,"author_fullname":"t2_7mcippb6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"They can refine their outputs. And just as a side note, diffusion models are usually transformers too.  You probably mean how is it better than autoregressive models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0z9od4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;They can refine their outputs. And just as a side note, diffusion models are usually transformers too.  You probably mean how is it better than autoregressive models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0z9od4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751477778,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0z8mca","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"saig22","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0z6s4t","score":1,"author_fullname":"t2_o5nqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I believe it has the potential to completely replace traditional text generation tokens by token. I cannot see the future, but I have a lot of confidence in this text generation method. You'll hear more and more about it as the year goes on.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0z8mca","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I believe it has the potential to completely replace traditional text generation tokens by token. I cannot see the future, but I have a lot of confidence in this text generation method. You&amp;#39;ll hear more and more about it as the year goes on.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0z8mca/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751477481,"author_flair_text":null,"treatment_tags":[],"created_utc":1751477481,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0z6s4t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SteveRD1","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0ymuuh","score":1,"author_fullname":"t2_ey837","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"When you say 'hype' are you really meaning it has a lot of potential?  The rest of your post suggests it could be quite good!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0z6s4t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;When you say &amp;#39;hype&amp;#39; are you really meaning it has a lot of potential?  The rest of your post suggests it could be quite good!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0z6s4t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751476963,"author_flair_text":null,"treatment_tags":[],"created_utc":1751476963,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0ymuuh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"saig22","can_mod_post":false,"created_utc":1751471346,"send_replies":true,"parent_id":"t1_n0wnl8k","score":3,"author_fullname":"t2_o5nqh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"DW people in the comments have no idea either XD\\nFirst diffusion LLM are transformers, diffusion is a principle of data generation using denoising. It doesn't condition the model architecture. When you diffuse text you hide tokens and the model predicts those tokens all at once. Then you re-hides some tokens and predict again to refine the answer. You can do this as many times as you want. That way text generation can be massively parallelized and you have a lot of control as to how much compute you want to allocate to your problem. It has other benefits, but it is fairly new and it needs to be researched more. But it's really hype and everyone in AI should keep an eye on it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ymuuh","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;DW people in the comments have no idea either XD\\nFirst diffusion LLM are transformers, diffusion is a principle of data generation using denoising. It doesn&amp;#39;t condition the model architecture. When you diffuse text you hide tokens and the model predicts those tokens all at once. Then you re-hides some tokens and predict again to refine the answer. You can do this as many times as you want. That way text generation can be massively parallelized and you have a lot of control as to how much compute you want to allocate to your problem. It has other benefits, but it is fairly new and it needs to be researched more. But it&amp;#39;s really hype and everyone in AI should keep an eye on it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0ymuuh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751471346,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0y1g5g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"1ncehost","can_mod_post":false,"created_utc":1751465249,"send_replies":true,"parent_id":"t1_n0wnl8k","score":1,"author_fullname":"t2_lrannsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"A set of response tokens are set to random noise and then they are all 'diffused' or iteratively improved, for a number of steps all together. They can be set to make the whole response at once. They have a more wholistic appreciation of the way a response is formed instead of being centered around the 'past'.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0y1g5g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A set of response tokens are set to random noise and then they are all &amp;#39;diffused&amp;#39; or iteratively improved, for a number of steps all together. They can be set to make the whole response at once. They have a more wholistic appreciation of the way a response is formed instead of being centered around the &amp;#39;past&amp;#39;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0y1g5g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751465249,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wnl8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"created_utc":1751443285,"send_replies":true,"parent_id":"t3_1lpoqlu","score":13,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I must admit I don’t have a deep understanding of diffusion LLMs yet. Can someone summarize in what way they are *better* than transformers, rather than just different? What are the (envisioned) advantages?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wnl8k","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I must admit I don’t have a deep understanding of diffusion LLMs yet. Can someone summarize in what way they are &lt;em&gt;better&lt;/em&gt; than transformers, rather than just different? What are the (envisioned) advantages?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wnl8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751443285,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zc7sv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cool-Chemical-5629","can_mod_post":false,"created_utc":1751478486,"send_replies":true,"parent_id":"t3_1lpoqlu","score":2,"author_fullname":"t2_qz1qjc86","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"By the time this gets llamacpp's support, we will be running OpenAI's open weight model locally.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zc7sv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;By the time this gets llamacpp&amp;#39;s support, we will be running OpenAI&amp;#39;s open weight model locally.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0zc7sv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751478486,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zgomr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Edge2098","can_mod_post":false,"created_utc":1751479765,"send_replies":true,"parent_id":"t3_1lpoqlu","score":1,"author_fullname":"t2_uaotuj04","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Try using llama or mlc-llm.If you're on Apple Silicon, try cpp with Metal. It's said to function fairly well with a little setup wizardry.\\n\\nTell us if it combusts or assembles 🔥💻.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0zgomr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Try using llama or mlc-llm.If you&amp;#39;re on Apple Silicon, try cpp with Metal. It&amp;#39;s said to function fairly well with a little setup wizardry.&lt;/p&gt;\\n\\n&lt;p&gt;Tell us if it combusts or assembles 🔥💻.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0zgomr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751479765,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0x1sq1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Antsint","can_mod_post":false,"created_utc":1751451507,"send_replies":true,"parent_id":"t3_1lpoqlu","score":1,"author_fullname":"t2_5z0j4pel","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I don’t know about this specific model but you can download llama from the web on Mac or through homebrew in the terminal","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x1sq1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don’t know about this specific model but you can download llama from the web on Mac or through homebrew in the terminal&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x1sq1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751451507,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0zj2fb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0yyn6b","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"cannot tell if you are sarcastic or not.","edited":false,"author_flair_css_class":null,"name":"t1_n0zj2fb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;cannot tell if you are sarcastic or not.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1lpoqlu","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0zj2fb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751480471,"author_flair_text":null,"collapsed":false,"created_utc":1751480471,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0yyn6b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NunyaBuzor","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0wkho5","score":2,"author_fullname":"t2_10pze1d3jf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"putting an entire sentence in quotation marks doesn't make it sarcasm.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0yyn6b","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;putting an entire sentence in quotation marks doesn&amp;#39;t make it sarcasm.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0yyn6b/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751474697,"author_flair_text":null,"treatment_tags":[],"created_utc":1751474697,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wkho5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0wk2lr","score":-6,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I guess people cannot read sarcasm these days.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0wkho5","is_submitter":false,"collapsed":true,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I guess people cannot read sarcasm these days.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wkho5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751441445,"author_flair_text":null,"treatment_tags":[],"created_utc":1751441445,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-6}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wk2lr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Formal_Drop526","can_mod_post":false,"created_utc":1751441200,"send_replies":true,"parent_id":"t1_n0wg9si","score":8,"author_fullname":"t2_dtsa6gxt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"more like the inverse, the paper did not say what you wanted and y'all became butthurt.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wk2lr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;more like the inverse, the paper did not say what you wanted and y&amp;#39;all became butthurt.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wk2lr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751441200,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0wm68i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0wlkf2","score":4,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why does it even matter? Converting Qwen into dLLM is a big deal; the model would behave entirely differently.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0wm68i","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why does it even matter? Converting Qwen into dLLM is a big deal; the model would behave entirely differently.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wm68i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751442448,"author_flair_text":null,"treatment_tags":[],"created_utc":1751442448,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wlkf2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"CommunityTough1","can_mod_post":false,"created_utc":1751442083,"send_replies":true,"parent_id":"t1_n0wg9si","score":6,"author_fullname":"t2_1iuzpxw7eg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's literally Qwen 2.5 Coder fine tuned, says so right on Hugging Face.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wlkf2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s literally Qwen 2.5 Coder fine tuned, says so right on Hugging Face.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wlkf2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751442083,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0x7k5j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0x1rvt","score":4,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No problems :)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0x7k5j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No problems :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x7k5j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751454340,"author_flair_text":null,"treatment_tags":[],"created_utc":1751454340,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"n0x1rvt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DunklerErpel","can_mod_post":false,"created_utc":1751451495,"send_replies":true,"parent_id":"t1_n0wg9si","score":1,"author_fullname":"t2_alho5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Truth to be told, yeah, totally missed the sarcasm. Take my upvote, then, I'd feel bad for downvoting for my mess-ups :P","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0x1rvt","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Truth to be told, yeah, totally missed the sarcasm. Take my upvote, then, I&amp;#39;d feel bad for downvoting for my mess-ups :P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0x1rvt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751451495,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0yudne","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0xipr7","score":1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Google sarcasm bro","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0yudne","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google sarcasm bro&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0yudne/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751473466,"author_flair_text":null,"treatment_tags":[],"created_utc":1751473466,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0xipr7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Emport1","can_mod_post":false,"created_utc":1751458958,"send_replies":true,"parent_id":"t1_n0wg9si","score":1,"author_fullname":"t2_ubae0chn0","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Google sarcasm bro","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xipr7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Google sarcasm bro&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lpoqlu","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xipr7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751458958,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0wg9si","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751439049,"send_replies":true,"parent_id":"t3_1lpoqlu","score":-12,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Ahaha...\\"Apple fell behind in LLM world therefore wrote (in)famous sour paper.\\".\\n\\nedit: do not you see the quates? it is sarcasm dammit.","edited":1751441508,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0wg9si","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ahaha...&amp;quot;Apple fell behind in LLM world therefore wrote (in)famous sour paper.&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;edit: do not you see the quates? it is sarcasm dammit.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0wg9si/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751439049,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0xw73p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Waterbottles_solve","can_mod_post":false,"created_utc":1751463615,"send_replies":true,"parent_id":"t3_1lpoqlu","score":-10,"author_fullname":"t2_u49aibv3e","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"Lmao its a qwen finetune. This is the most Apple thing. Apple is always second place or worse. \\n\\nSo... Apple is completely incapable of anything outside marketing and sales...","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0xw73p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Lmao its a qwen finetune. This is the most Apple thing. Apple is always second place or worse. &lt;/p&gt;\\n\\n&lt;p&gt;So... Apple is completely incapable of anything outside marketing and sales...&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0xw73p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751463615,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0z8v38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"LOW_SCORE","no_follow":true,"author":"Robert__Sinclair","can_mod_post":false,"created_utc":1751477550,"send_replies":true,"parent_id":"t3_1lpoqlu","score":-7,"author_fullname":"t2_120m02qa8a","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":true,"body":"AiPPLE™ is CRAP.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0z8v38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;AiPPLE™ is CRAP.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":"comment score below threshold","distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lpoqlu/diffucoder_7b_new_coding_diffusion_llm_by_apple/n0z8v38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751477550,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lpoqlu","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-7}}],"before":null}}]`),r=()=>e.jsx(l,{data:t});export{r as default};
