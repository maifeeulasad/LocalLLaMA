import{j as e}from"./index-CvjCnrcE.js";import{R as t}from"./RedditPostRenderer-Cq9hdyKC.js";import"./index-DQAOC9pf.js";const a=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"A new paper demonstrates that LLMs could \\"think\\" in latent space, effectively decoupling internal reasoning from visible context tokens. This breakthrough suggests that even smaller models can achieve remarkable performance without relying on extensive context windows.","link_flair_richtext":[{"e":"text","t":"News"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":75,"top_awarded_type":null,"hide_score":false,"name":"t3_1inch7r","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.98,"author_flair_background_color":"#bbbdbf","ups":1434,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","is_original_content":false,"author_fullname":"t2_10ps26h7","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"News","can_mod_post":false,"score":1434,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://b.thumbs.redditmedia.com/A6DXpxksks6ha7Hqe-ZqCGX99tyvJMsQkJ96PFEopJo.jpg","edited":false,"author_flair_css_class":null,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1739315691,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"richtext","domain":"huggingface.co","allow_live_comments":false,"selftext_html":null,"likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://huggingface.co/papers/2502.05171","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?auto=webp&amp;s=3cff15c355800351362f587e389c00d69d492e5c","width":1200,"height":648},"resolutions":[{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f11d1665d72c7ade4ccfe5a66b2e557332f05272","width":108,"height":58},{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d88d186011a44d3a7406e3692c59eb11ebb9f39e","width":216,"height":116},{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62c4cd5c5a5f4ea577caf2f05de7612c7b23c289","width":320,"height":172},{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7f243d34bc596be68af0031b70b22b21c475830","width":640,"height":345},{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=401ae40a452c99469474730c33fc68f9072d7abb","width":960,"height":518},{"url":"https://external-preview.redd.it/lsXw1VKNR0EoTFYgDUro5o8By4n9gHC7i_cxDktIeuo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4bb29049045d94b558b5cb0d67f8d1bab91a6599","width":1080,"height":583}],"variants":{},"id":"c5fk0OmPck4PSvg_ZaAN3p9RNhbI68_Yvw5v4JkUsX8"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":"llama.cpp","treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#cc3600","id":"1inch7r","is_robot_indexable":true,"num_duplicates":4,"report_reasons":null,"author":"tehbangere","discussion_type":null,"num_comments":295,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":"light","permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/","stickied":false,"url":"https://huggingface.co/papers/2502.05171","subreddit_subscribers":492230,"created_utc":1739315691,"num_crossposts":3,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":22,"removal_reason":null,"link_id":"t3_1inch7r","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mce4wv3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"JoakimTheGreat","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcdkfc4","score":5,"author_fullname":"t2_1agpwzw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yup, can't just convert anything to a gguf...","edited":false,"author_flair_css_class":null,"name":"t1_mce4wv3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yup, can&amp;#39;t just convert anything to a gguf...&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mce4wv3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739379222,"author_flair_text":null,"collapsed":false,"created_utc":1739379222,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"more","data":{"count":1,"name":"t1_mcffq83","id":"mcffq83","parent_id":"t1_mcdkfc4","depth":4,"children":["mcffq83"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcdkfc4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kulchacop","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbcgcy","score":20,"author_fullname":"t2_mctkn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It is a new architecture. It will be implemented in llamacpp only if there is demand.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcdkfc4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It is a new architecture. It will be implemented in llamacpp only if there is demand.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcdkfc4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739373313,"author_flair_text":null,"treatment_tags":[],"created_utc":1739373313,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcie4q8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"trahloc","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbcgcy","score":1,"author_fullname":"t2_42ln1","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Just load it in int8, that should fit even on a 12gb vram card. I haven't kept up with transformers itself but last I heard it can load 4bit from the original file as well but 8bit was possible 2 years ago.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcie4q8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just load it in int8, that should fit even on a 12gb vram card. I haven&amp;#39;t kept up with transformers itself but last I heard it can load 4bit from the original file as well but 8bit was possible 2 years ago.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcie4q8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739428151,"author_flair_text":null,"treatment_tags":[],"created_utc":1739428151,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_mccwx91","id":"mccwx91","parent_id":"t1_mcbcgcy","depth":3,"children":["mccwx91"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbcgcy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1739334792,"send_replies":true,"parent_id":"t1_mca5b55","score":22,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbcgcy/","num_reports":null,"locked":false,"name":"t1_mcbcgcy","created":1739334792,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mca5b55","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"kulchacop","can_mod_post":false,"created_utc":1739319492,"send_replies":true,"parent_id":"t1_mc9uvx2","score":149,"author_fullname":"t2_mctkn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Post from yesterday for this paper: \\n\\n\\nhttps://www.reddit.com/r/LocalLLaMA/comments/1imca0s/new_paper_gives_models_a_chance_to_think_in/\\n\\n\\nTraining code and a 3.5B model are available:\\nhttps://huggingface.co/tomg-group-umd/huginn-0125","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca5b55","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Post from yesterday for this paper: &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1imca0s/new_paper_gives_models_a_chance_to_think_in/\\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1imca0s/new_paper_gives_models_a_chance_to_think_in/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Training code and a 3.5B model are available:\\n&lt;a href=\\"https://huggingface.co/tomg-group-umd/huginn-0125\\"&gt;https://huggingface.co/tomg-group-umd/huginn-0125&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca5b55/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319492,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":149}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcvolqo","id":"mcvolqo","parent_id":"t1_mcech09","depth":5,"children":["mcvolqo"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcech09","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"florinandrei","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbtuj7","score":8,"author_fullname":"t2_2qjji","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah. Or, the way I would put it, reason is a very, very recent evolutionary outcome. A chick barely hatched out of its egg. It's still in the phase where it's struggling to get established - what we have is something like version 0.23. Not even close to 1.0. This is why we're so gullible.\\n\\nAnd yet it's changing the world. In the blink of an eye, it started a process of transformation that outpaces evolution by many orders of magnitude.\\n\\nThis, more than anything else, should make it more clear what AI will be able to do once the \\"slow\\" thinking part is solved for it as well. A kind of \\"singularity\\" has happened already, from the perspective of evolution - that's us. We've demolished the previous glacial pace of change. There was a series of short-lived species (Homo Erectus, the Neanderthals, etc), iterating through even earlier versions of the \\"slow\\" system, that rapidly lead to us - move fast and break things, that's not just for startups. And all that was a purely evolutionary process, driven simply by outcomes.\\n\\nSo now the same process is happening again, but at an even more rapid rate. This time it may not be purely evolutionary, except at the largest scale (the whole market), and imperfectly there, too.","edited":1739381837,"author_flair_css_class":null,"name":"t1_mcech09","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah. Or, the way I would put it, reason is a very, very recent evolutionary outcome. A chick barely hatched out of its egg. It&amp;#39;s still in the phase where it&amp;#39;s struggling to get established - what we have is something like version 0.23. Not even close to 1.0. This is why we&amp;#39;re so gullible.&lt;/p&gt;\\n\\n&lt;p&gt;And yet it&amp;#39;s changing the world. In the blink of an eye, it started a process of transformation that outpaces evolution by many orders of magnitude.&lt;/p&gt;\\n\\n&lt;p&gt;This, more than anything else, should make it more clear what AI will be able to do once the &amp;quot;slow&amp;quot; thinking part is solved for it as well. A kind of &amp;quot;singularity&amp;quot; has happened already, from the perspective of evolution - that&amp;#39;s us. We&amp;#39;ve demolished the previous glacial pace of change. There was a series of short-lived species (Homo Erectus, the Neanderthals, etc), iterating through even earlier versions of the &amp;quot;slow&amp;quot; system, that rapidly lead to us - move fast and break things, that&amp;#39;s not just for startups. And all that was a purely evolutionary process, driven simply by outcomes.&lt;/p&gt;\\n\\n&lt;p&gt;So now the same process is happening again, but at an even more rapid rate. This time it may not be purely evolutionary, except at the largest scale (the whole market), and imperfectly there, too.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcech09/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739381354,"author_flair_text":null,"collapsed":false,"created_utc":1739381354,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbtuj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"princess_princeless","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcboy3z","score":10,"author_fullname":"t2_wrzsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn’t that ultimately be because of our relatively primitive limbic system holding back rational decision making ability that our later evolved neo-cortex is much better at?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbtuj7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn’t that ultimately be because of our relatively primitive limbic system holding back rational decision making ability that our later evolved neo-cortex is much better at?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbtuj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739343309,"author_flair_text":null,"treatment_tags":[],"created_utc":1739343309,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}}],"before":null}},"user_reports":[],"saved":false,"id":"mcboy3z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"IrisColt","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":27,"author_fullname":"t2_c2f558x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Nice reasoning. Blending rigid logic into systems optimized for fluid intuition is like trying to square the circle. Maybe the ultimate test isn’t building machines that think, but deciphering why a species that hallucinates less than ChatGPT still can’t balance a checkbook.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcboy3z","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice reasoning. Blending rigid logic into systems optimized for fluid intuition is like trying to square the circle. Maybe the ultimate test isn’t building machines that think, but deciphering why a species that hallucinates less than ChatGPT still can’t balance a checkbook.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcboy3z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739340628,"author_flair_text":null,"treatment_tags":[],"created_utc":1739340628,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcpxv0q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AI_is_the_rake","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcpxb3r","score":3,"author_fullname":"t2_5bbysz0b2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Right. It’s just that this new tool sprung up on the world where machines can apparently think with words and now we’re speculating whether or not machines can also think without words. It’s a wild time!","edited":false,"author_flair_css_class":null,"name":"t1_mcpxv0q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Right. It’s just that this new tool sprung up on the world where machines can apparently think with words and now we’re speculating whether or not machines can also think without words. It’s a wild time!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcpxv0q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739536078,"author_flair_text":null,"collapsed":false,"created_utc":1739536078,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mcpxb3r","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"arbv","can_mod_post":false,"send_replies":true,"parent_id":"t1_mccyhrh","score":2,"author_fullname":"t2_oysou","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hey, I just wanted to point out that animals obviously do have slow thinking too (even if it less developed), and they do not need words for it.\\n\\nThinking without (or beyond) words is an important topic in Zen Buddhism in particular. It is not like people have not noticed thinking without words before.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcpxb3r","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hey, I just wanted to point out that animals obviously do have slow thinking too (even if it less developed), and they do not need words for it.&lt;/p&gt;\\n\\n&lt;p&gt;Thinking without (or beyond) words is an important topic in Zen Buddhism in particular. It is not like people have not noticed thinking without words before.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcpxb3r/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739535825,"author_flair_text":null,"treatment_tags":[],"created_utc":1739535825,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mccyhrh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AI_is_the_rake","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":14,"author_fullname":"t2_5bbysz0b2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What you’re describing is exactly why the o1 reasoning models were created. \\n\\nThey first added the code interpreter feature where gpt4 could use code to solve problems. That gave the intuitive llm access to real logic gates via a high level programming language. You’d think that would have worked but it didn’t. The llm would have to actually understand the problem and capture the problem in the code design. Wrong code equals wrong solution. \\n\\nO1 feels like it was trained with logic data sets. It can actually output correct logic without using code an an in between. While it’s still limited in what it can do it appears that it can correctly model the problem and write code that can solve the problem correctly. \\n\\nSo, OpenAI has already been tackling this problem. \\n\\nWhat this paper shows is something else and it’s something I’ve been thinking about. I notice when I think about hard problems there’s a moment where my focus and intention is on the problem but there are no words. It’s like I’m thinking without thinking. And then solutions start getting served up to my consciousness and I continue to analyze those for viability. This may simply be how consciousness works and the veil of consciousness that prevents me from seeing subconscious processes but I was reminded of that from this paper. \\n\\nCould llms “think without thinking”. Or “think without language” thereby giving room for more abstract thought? An interesting concept. Not sure how that would actually work physically. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccyhrh","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What you’re describing is exactly why the o1 reasoning models were created. &lt;/p&gt;\\n\\n&lt;p&gt;They first added the code interpreter feature where gpt4 could use code to solve problems. That gave the intuitive llm access to real logic gates via a high level programming language. You’d think that would have worked but it didn’t. The llm would have to actually understand the problem and capture the problem in the code design. Wrong code equals wrong solution. &lt;/p&gt;\\n\\n&lt;p&gt;O1 feels like it was trained with logic data sets. It can actually output correct logic without using code an an in between. While it’s still limited in what it can do it appears that it can correctly model the problem and write code that can solve the problem correctly. &lt;/p&gt;\\n\\n&lt;p&gt;So, OpenAI has already been tackling this problem. &lt;/p&gt;\\n\\n&lt;p&gt;What this paper shows is something else and it’s something I’ve been thinking about. I notice when I think about hard problems there’s a moment where my focus and intention is on the problem but there are no words. It’s like I’m thinking without thinking. And then solutions start getting served up to my consciousness and I continue to analyze those for viability. This may simply be how consciousness works and the veil of consciousness that prevents me from seeing subconscious processes but I was reminded of that from this paper. &lt;/p&gt;\\n\\n&lt;p&gt;Could llms “think without thinking”. Or “think without language” thereby giving room for more abstract thought? An interesting concept. Not sure how that would actually work physically. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccyhrh/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739365890,"author_flair_text":null,"treatment_tags":[],"created_utc":1739365890,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mched1o","id":"mched1o","parent_id":"t1_mcc2wkd","depth":4,"children":["mched1o"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcc2wkd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Yweain","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbryme","score":3,"author_fullname":"t2_7fk0it6t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Agents are working on exactly the same concept as usual LLMs. There is literally nothing different about them","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcc2wkd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Agents are working on exactly the same concept as usual LLMs. There is literally nothing different about them&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc2wkd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739348686,"author_flair_text":null,"treatment_tags":[],"created_utc":1739348686,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbryme","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"richard_h87","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":5,"author_fullname":"t2_my4sp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"very interesting concept! But I wonder if \\"agents\\" can be the slow thinking part? trying out different scenarios and getting feedback on it (especially for coding), or Aider Chat which has a open issue/proposal on getting input from different models and trying to pick the best result...\\n\\nBut I wonder how that could work in different fields. I wonder if most/some STEM fields can test the results somehow, but societies social fields might get trickier... Maybe get an agent to game the results?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcbryme","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;very interesting concept! But I wonder if &amp;quot;agents&amp;quot; can be the slow thinking part? trying out different scenarios and getting feedback on it (especially for coding), or Aider Chat which has a open issue/proposal on getting input from different models and trying to pick the best result...&lt;/p&gt;\\n\\n&lt;p&gt;But I wonder how that could work in different fields. I wonder if most/some STEM fields can test the results somehow, but societies social fields might get trickier... Maybe get an agent to game the results?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbryme/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739342256,"author_flair_text":null,"treatment_tags":[],"created_utc":1739342256,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc137j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"RMCPhoto","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":7,"author_fullname":"t2_ehhvb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"However, with enough knowledge and experience this \\"slow\\" system eventually becomes \\"fast\\" intuition.   We have to learn perpetually throughout our lives, but these models may eventually be intuitive about most common tasks and only rarely require slow thinking for novel tasks.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcc137j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;However, with enough knowledge and experience this &amp;quot;slow&amp;quot; system eventually becomes &amp;quot;fast&amp;quot; intuition.   We have to learn perpetually throughout our lives, but these models may eventually be intuitive about most common tasks and only rarely require slow thinking for novel tasks.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc137j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739347580,"author_flair_text":null,"treatment_tags":[],"created_utc":1739347580,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccl25t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jacobpederson","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":8,"author_fullname":"t2_1o4i6","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Shame that Daniel Kahneman's book got [railed for some bad science,](https://retractionwatch.com/2017/02/20/placed-much-faith-underpowered-studies-nobel-prize-winner-admits-mistakes/) as there is a lot of great stuff in it!.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccl25t","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Shame that Daniel Kahneman&amp;#39;s book got &lt;a href=\\"https://retractionwatch.com/2017/02/20/placed-much-faith-underpowered-studies-nobel-prize-winner-admits-mistakes/\\"&gt;railed for some bad science,&lt;/a&gt; as there is a lot of great stuff in it!.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccl25t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739359786,"author_flair_text":null,"treatment_tags":[],"created_utc":1739359786,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcfnlbo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WrathPie","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":3,"author_fullname":"t2_6ba0l","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I think that's even had a pretty significant impact on how people engage with the question of how capable systems like this are of actually understanding the information they're processing, or whether they could ever develop that ability in the future.\\n\\n\\nHistorically, the symbolism we've always used in fiction for an AI \\"waking up\\" and starting to become something beyond just a reflexive computational engine has been showing it starting to break out of the methodical but myopic and rigid slow-thinking and developing it's own version of the quick-thinking abilities that we used to assume were synonymous with self awareness, gestalt understanding and the perspective orientation of conscious experience.\\n\\n\\nSince we ended up getting that quick-thinking first, and it turns out to be trivially easy to accomplish compared to getting the stepwise logical slow-thinking we expected proto-AI to rely on, we don't really have a framework for what it would even look like for this kind of system to develop some degree of actual contextual understanding beyond reflexive data processing. \\n\\n\\nI'm genuinely not even sure what kind of emergent behavior could actually prove, or disprove it at this point if it did arise someday, given how wrong we were about what we used to think that would look like. We're just totally off the map.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcfnlbo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think that&amp;#39;s even had a pretty significant impact on how people engage with the question of how capable systems like this are of actually understanding the information they&amp;#39;re processing, or whether they could ever develop that ability in the future.&lt;/p&gt;\\n\\n&lt;p&gt;Historically, the symbolism we&amp;#39;ve always used in fiction for an AI &amp;quot;waking up&amp;quot; and starting to become something beyond just a reflexive computational engine has been showing it starting to break out of the methodical but myopic and rigid slow-thinking and developing it&amp;#39;s own version of the quick-thinking abilities that we used to assume were synonymous with self awareness, gestalt understanding and the perspective orientation of conscious experience.&lt;/p&gt;\\n\\n&lt;p&gt;Since we ended up getting that quick-thinking first, and it turns out to be trivially easy to accomplish compared to getting the stepwise logical slow-thinking we expected proto-AI to rely on, we don&amp;#39;t really have a framework for what it would even look like for this kind of system to develop some degree of actual contextual understanding beyond reflexive data processing. &lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m genuinely not even sure what kind of emergent behavior could actually prove, or disprove it at this point if it did arise someday, given how wrong we were about what we used to think that would look like. We&amp;#39;re just totally off the map.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcfnlbo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739394368,"author_flair_text":null,"treatment_tags":[],"created_utc":1739394368,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcmjexu","id":"mcmjexu","parent_id":"t1_mcf0clx","depth":4,"children":["mcmjexu"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcf0clx","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Rofel_Wodring","can_mod_post":false,"send_replies":true,"parent_id":"t1_mccqms7","score":2,"author_fullname":"t2_9z071i","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; LLMs are not a path to AGI because they are just approximate database retrieval mechanisms, not novel data generators.\\n\\nBrains are amazingly simple organs when you get right down to it. The difference in intelligence and behavior between a tree shrew and a gorilla is simply brute scaling of an organ designed to refactor and interpret information from the environment.\\n\\nI don’t think LLMs are a path to AGI either, mostly because it’s impossible under current architecture to have one ‘run’ continuously. Which is mandatory for being able to act usefully and autonomously. But it’s not because of yet another variation of ‘stochastic parrot’. People who make that argument show a weak understanding of biology, but what else is new?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcf0clx","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt; LLMs are not a path to AGI because they are just approximate database retrieval mechanisms, not novel data generators.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Brains are amazingly simple organs when you get right down to it. The difference in intelligence and behavior between a tree shrew and a gorilla is simply brute scaling of an organ designed to refactor and interpret information from the environment.&lt;/p&gt;\\n\\n&lt;p&gt;I don’t think LLMs are a path to AGI either, mostly because it’s impossible under current architecture to have one ‘run’ continuously. Which is mandatory for being able to act usefully and autonomously. But it’s not because of yet another variation of ‘stochastic parrot’. People who make that argument show a weak understanding of biology, but what else is new?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcf0clx/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739387958,"author_flair_text":null,"treatment_tags":[],"created_utc":1739387958,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mccqms7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"damhack","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":5,"author_fullname":"t2_cyjyo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What you’re missing is that LLMs can only interpolate over their training data and cannot extrapolate outside it or predict by extrapolation to future events.  They can poorly mimic it but are only replaying correspondences in seen data.  There are many fail states in recent “reasoning” models like o3 and r2 because of this.\\n\\nLLMs are not a path to AGI because they are just approximate database retrieval mechanisms, not novel data generators.\\n\\nThe missing links are active inference against the environment, character-level symbolic reasoning and persistent hierarchical memory.  Without those, you just have giant Mechanical Turk automata cranking out plausible but incorrect sentences that the machine has no real understanding of.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccqms7","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What you’re missing is that LLMs can only interpolate over their training data and cannot extrapolate outside it or predict by extrapolation to future events.  They can poorly mimic it but are only replaying correspondences in seen data.  There are many fail states in recent “reasoning” models like o3 and r2 because of this.&lt;/p&gt;\\n\\n&lt;p&gt;LLMs are not a path to AGI because they are just approximate database retrieval mechanisms, not novel data generators.&lt;/p&gt;\\n\\n&lt;p&gt;The missing links are active inference against the environment, character-level symbolic reasoning and persistent hierarchical memory.  Without those, you just have giant Mechanical Turk automata cranking out plausible but incorrect sentences that the machine has no real understanding of.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccqms7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739362592,"author_flair_text":null,"treatment_tags":[],"created_utc":1739362592,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc924a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thetroll999","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_3f46daif","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks for this excellent description.  It's exactly because we're consciously aware of our \\"slow\\" and can describe it procedurally rather better than our \\"fast\\", which turns out to work in a way unlike anything most of us ever deliberately design.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcc924a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks for this excellent description.  It&amp;#39;s exactly because we&amp;#39;re consciously aware of our &amp;quot;slow&amp;quot; and can describe it procedurally rather better than our &amp;quot;fast&amp;quot;, which turns out to work in a way unlike anything most of us ever deliberately design.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc924a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739352570,"author_flair_text":null,"treatment_tags":[],"created_utc":1739352570,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccfc5h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Monkey_1505","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_7qrmh9n9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Abstraction is fairly multi-modular and complex. Needs to be coded, not just brute forced.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccfc5h","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Abstraction is fairly multi-modular and complex. Needs to be coded, not just brute forced.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccfc5h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739356471,"author_flair_text":null,"treatment_tags":[],"created_utc":1739356471,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcco2dm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheSuperSam","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_nxztn77","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I just think the fields is so abstract now that people use reasoning like an abstract concept. I look to this in more mathematical terms, if you think that a layer is performing a given computation, by having fixed layers this computations are fixed, so for bigger problems the model  can't extrapolate. CoT basically increases the computation of the model (some papers have show that even if wrong cot the model performance improved). By having infinite depth the model can learn to compose functions depending on the complexity of the problem, I would say that htis is a nicer solution.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcco2dm","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I just think the fields is so abstract now that people use reasoning like an abstract concept. I look to this in more mathematical terms, if you think that a layer is performing a given computation, by having fixed layers this computations are fixed, so for bigger problems the model  can&amp;#39;t extrapolate. CoT basically increases the computation of the model (some papers have show that even if wrong cot the model performance improved). By having infinite depth the model can learn to compose functions depending on the complexity of the problem, I would say that htis is a nicer solution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcco2dm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739361363,"author_flair_text":null,"treatment_tags":[],"created_utc":1739361363,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcex8ap","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kovnev","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_hhw87t7z","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you familiar with Iain McGilchrist's work? The Master and His Emissary.\\n\\nLeft brain vs right brain, and the two staggeringly different ways in which they view the world. Basically all life with brains has this hemispherical split, and there are incredibly good reasons for it.\\n\\nHighly recommend watching an interview with him.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcex8ap","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you familiar with Iain McGilchrist&amp;#39;s work? The Master and His Emissary.&lt;/p&gt;\\n\\n&lt;p&gt;Left brain vs right brain, and the two staggeringly different ways in which they view the world. Basically all life with brains has this hemispherical split, and there are incredibly good reasons for it.&lt;/p&gt;\\n\\n&lt;p&gt;Highly recommend watching an interview with him.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcex8ap/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739387095,"author_flair_text":null,"treatment_tags":[],"created_utc":1739387095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcfxusd","id":"mcfxusd","parent_id":"t1_mcfvfhw","depth":4,"children":["mcfxusd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcfvfhw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"florinandrei","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcfjmua","score":1,"author_fullname":"t2_2qjji","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; AI will be completely sentient\\n\\n\\"Sentient\\" is a weasel word. It tends to reflect an incomplete mental map.\\n\\nThere are two things in this general area: intelligence and consciousness. The one that really matters is intelligence. This is what these models attempt to embody. It's also what has real consequences in the world.\\n\\nConsciousness - while real, it escapes analysis. We don't even have a good definition for it, or any definition. Let's keep it out of the discussion for now.\\n\\nOne could easily imagine machines that are extremely intelligent, but possess no subjective experience (consciousness). It's hard to tell for sure (since we can't even properly define the term) but current models are probably like this. Very capable, but the \\"lights\\" of subjective experience are off.\\n\\nYou're kind of alluding to this when you say \\"AGI could occur from emotionless machines\\". Emotion is just a certain kind of mental processes that accompany subjective experience. But the thing that really matters here is whether consciousness is, or is not, associated with that intelligence.\\n\\nRead [David Chalmers](https://en.wikipedia.org/wiki/The_Conscious_Mind), [Annaka Harris](https://annakaharris.com/conscious/), and [Philip Goff](https://en.wikipedia.org/wiki/Galileo%27s_Error).","edited":1739396815,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcfvfhw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;AI will be completely sentient&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&amp;quot;Sentient&amp;quot; is a weasel word. It tends to reflect an incomplete mental map.&lt;/p&gt;\\n\\n&lt;p&gt;There are two things in this general area: intelligence and consciousness. The one that really matters is intelligence. This is what these models attempt to embody. It&amp;#39;s also what has real consequences in the world.&lt;/p&gt;\\n\\n&lt;p&gt;Consciousness - while real, it escapes analysis. We don&amp;#39;t even have a good definition for it, or any definition. Let&amp;#39;s keep it out of the discussion for now.&lt;/p&gt;\\n\\n&lt;p&gt;One could easily imagine machines that are extremely intelligent, but possess no subjective experience (consciousness). It&amp;#39;s hard to tell for sure (since we can&amp;#39;t even properly define the term) but current models are probably like this. Very capable, but the &amp;quot;lights&amp;quot; of subjective experience are off.&lt;/p&gt;\\n\\n&lt;p&gt;You&amp;#39;re kind of alluding to this when you say &amp;quot;AGI could occur from emotionless machines&amp;quot;. Emotion is just a certain kind of mental processes that accompany subjective experience. But the thing that really matters here is whether consciousness is, or is not, associated with that intelligence.&lt;/p&gt;\\n\\n&lt;p&gt;Read &lt;a href=\\"https://en.wikipedia.org/wiki/The_Conscious_Mind\\"&gt;David Chalmers&lt;/a&gt;, &lt;a href=\\"https://annakaharris.com/conscious/\\"&gt;Annaka Harris&lt;/a&gt;, and &lt;a href=\\"https://en.wikipedia.org/wiki/Galileo%27s_Error\\"&gt;Philip Goff&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcfvfhw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739396482,"author_flair_text":null,"treatment_tags":[],"created_utc":1739396482,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcfjmua","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Data, Skynet and others are described mostly as accidents, often created by a madman or an absolute genius, and excel at logical reasoning but suck at it emotions. Even AGI is described there as an irreversible inflection point that still generates an extremely logical machine, perfectly capable of logical reasoning but that “hallucinated” and deemed human as pests that have to be eradicated. This is a logical reasoning hallucination, but still a hallucination. They also developed logical-based purposes.\\n\\nMy point is that according to sci-fi, AGI could occur from emotionless machines. \\n\\nI’d say animals are capable of intuition, logic and emotions, even some have a notion of self so they could perfectly be considered sentient. Many even develop societies with norms. What distinguishes us is that we developed other purposes and goals other than survival and reproduction. We went beyond what we were biologically programmed to do.\\n\\nIf I had to be a reductionist, I’d say curiosity is our defining trait. Curiosity is what I believe led to existential questions, which led to a belief system. Communicating more than what’s essential and crafting tools are our AGI, in my opinion.\\n\\nAI will be completely sentient once it WANTS something more. All animals, large or small, have already started with a purpose. AI doesn’t, we give it to them, but it doesn’t have an intrinsic purpose.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcfjmua","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Data, Skynet and others are described mostly as accidents, often created by a madman or an absolute genius, and excel at logical reasoning but suck at it emotions. Even AGI is described there as an irreversible inflection point that still generates an extremely logical machine, perfectly capable of logical reasoning but that “hallucinated” and deemed human as pests that have to be eradicated. This is a logical reasoning hallucination, but still a hallucination. They also developed logical-based purposes.&lt;/p&gt;\\n\\n&lt;p&gt;My point is that according to sci-fi, AGI could occur from emotionless machines. &lt;/p&gt;\\n\\n&lt;p&gt;I’d say animals are capable of intuition, logic and emotions, even some have a notion of self so they could perfectly be considered sentient. Many even develop societies with norms. What distinguishes us is that we developed other purposes and goals other than survival and reproduction. We went beyond what we were biologically programmed to do.&lt;/p&gt;\\n\\n&lt;p&gt;If I had to be a reductionist, I’d say curiosity is our defining trait. Curiosity is what I believe led to existential questions, which led to a belief system. Communicating more than what’s essential and crafting tools are our AGI, in my opinion.&lt;/p&gt;\\n\\n&lt;p&gt;AI will be completely sentient once it WANTS something more. All animals, large or small, have already started with a purpose. AI doesn’t, we give it to them, but it doesn’t have an intrinsic purpose.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcfjmua/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739393293,"author_flair_text":null,"treatment_tags":[],"created_utc":1739393293,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcfkf5l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Justicia-Gai","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":2,"author_fullname":"t2_55dqb43t","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Data, Skynet and others are described mostly as accidents, often created by a madman or an absolute genius, and excel at logical reasoning but suck at it emotions. Even AGI is described there as an irreversible inflection point that still generates an extremely logical machine, perfectly capable of logical reasoning but that “hallucinated” and deemed human as pests that have to be eradicated. This is a logical reasoning hallucination, but still a hallucination. They also developed logical-based purposes.\\n\\nMy point is that according to sci-fi, AGI could occur from emotionless machines. \\n\\nI’d say animals are capable of intuition, logic and emotions, even some have a notion of self so they could perfectly be considered sentient. Many even develop societies with norms. What distinguishes us is that we developed other purposes and goals other than survival and reproduction. We went beyond what we were biologically programmed to do.\\n\\nIf I had to be a reductionist, I’d say curiosity is our defining trait. Curiosity is what I believe led to existential questions, which led to a belief system. I sincerely think that one of the hardest questions (and an unanswered one at that) is where we come from and where we go when we die. I think this was our AGI and probably one of the earliest real questions we’ve “asked” ourselves. \\n\\nAI will be completely sentient once it WANTS something more. All animals, large or small, have already started with a purpose. AI doesn’t, we give it to them, but it doesn’t have an intrinsic purpose.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcfkf5l","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Data, Skynet and others are described mostly as accidents, often created by a madman or an absolute genius, and excel at logical reasoning but suck at it emotions. Even AGI is described there as an irreversible inflection point that still generates an extremely logical machine, perfectly capable of logical reasoning but that “hallucinated” and deemed human as pests that have to be eradicated. This is a logical reasoning hallucination, but still a hallucination. They also developed logical-based purposes.&lt;/p&gt;\\n\\n&lt;p&gt;My point is that according to sci-fi, AGI could occur from emotionless machines. &lt;/p&gt;\\n\\n&lt;p&gt;I’d say animals are capable of intuition, logic and emotions, even some have a notion of self so they could perfectly be considered sentient. Many even develop societies with norms. What distinguishes us is that we developed other purposes and goals other than survival and reproduction. We went beyond what we were biologically programmed to do.&lt;/p&gt;\\n\\n&lt;p&gt;If I had to be a reductionist, I’d say curiosity is our defining trait. Curiosity is what I believe led to existential questions, which led to a belief system. I sincerely think that one of the hardest questions (and an unanswered one at that) is where we come from and where we go when we die. I think this was our AGI and probably one of the earliest real questions we’ve “asked” ourselves. &lt;/p&gt;\\n\\n&lt;p&gt;AI will be completely sentient once it WANTS something more. All animals, large or small, have already started with a purpose. AI doesn’t, we give it to them, but it doesn’t have an intrinsic purpose.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcfkf5l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739393504,"author_flair_text":null,"treatment_tags":[],"created_utc":1739393504,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcj0dcf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Silly-Cup1391","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8e7q","score":1,"author_fullname":"t2_7l7l170m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Logical reasoning is better done with an explicit reasoner ( cf prolog interpreter/Sat|SMT solver).\\nWe suck but are using tools, so should do our llms.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcj0dcf","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Logical reasoning is better done with an explicit reasoner ( cf prolog interpreter/Sat|SMT solver).\\nWe suck but are using tools, so should do our llms.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcj0dcf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739441783,"author_flair_text":null,"treatment_tags":[],"created_utc":1739441783,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":3,"name":"t1_mcbmcx5","id":"mcbmcx5","parent_id":"t1_mcb8e7q","depth":2,"children":["mcbmcx5","mcciwjk","mce3m7r"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb8e7q","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"florinandrei","can_mod_post":false,"created_utc":1739333126,"send_replies":true,"parent_id":"t1_mc9uvx2","score":157,"author_fullname":"t2_2qjji","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is very cool. But it's still more like our intuition, which is what all models so far do anyway.\\n\\nThere's something else we do, and we do it very deliberately, and it's very explicit, and it's what allows us to imagine hypotheticals, do what/if scenarios, play mental wargames, backtrack, etc. It's commonly called \\"reason\\" or \\"logic\\". This is a different method.\\n\\nBoth methods are needed.\\n\\nI am quite deliberately alluding to 'Thinking, Fast and Slow' by Daniel Kahneman. All current models have a quite amazing implementation of the \\"fast\\" system, but they are only beginning to implement the \\"slow\\" system.\\n\\nIt's exactly the opposite to what everyone expected would happen, from 20th century AI researchers to Star Trek writers. Everyone thought the \\"slow\\" system will be implemented first, with the \\"fast\\" system lagging behind. Everyone thought Lt. Data would be the first kind of AI, never hallucinating but sort of narrow and unimaginative. Instead, we got some deeply intuitive machines that can't reason very well, and therefore hallucinate.\\n\\nThe \\"fast\\" system, what the models have now, is a blob of stuff, slowly shaped by training. The \\"slow\\" system should have a much more explicit structure, blocks, loops, control mechanisms, etc.\\n\\nEDIT: It's not like nature didn't give us hints. All kinds of animals - many mammals, especially the ones with complex brains, and especially apes, dolphins, etc - have a pretty badass \\"fast\\" system. But their \\"slow\\" system sucks. Heck, our \\"slow\\" system kinda sucks a little bit (see how easily it gets fooled, or overwhelmed by emotion, etc) but it beats the hell out of what the other critters have. Our \\"slow\\" system is literally evolution's most recent big outcome, and it's a bit unsteady on its legs.\\n\\nSo it should have been clear that \\"fast\\" is easy and \\"slow\\" is hard. Hindsight is 20/20, I guess.","edited":1739338397,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb8e7q","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is very cool. But it&amp;#39;s still more like our intuition, which is what all models so far do anyway.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s something else we do, and we do it very deliberately, and it&amp;#39;s very explicit, and it&amp;#39;s what allows us to imagine hypotheticals, do what/if scenarios, play mental wargames, backtrack, etc. It&amp;#39;s commonly called &amp;quot;reason&amp;quot; or &amp;quot;logic&amp;quot;. This is a different method.&lt;/p&gt;\\n\\n&lt;p&gt;Both methods are needed.&lt;/p&gt;\\n\\n&lt;p&gt;I am quite deliberately alluding to &amp;#39;Thinking, Fast and Slow&amp;#39; by Daniel Kahneman. All current models have a quite amazing implementation of the &amp;quot;fast&amp;quot; system, but they are only beginning to implement the &amp;quot;slow&amp;quot; system.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s exactly the opposite to what everyone expected would happen, from 20th century AI researchers to Star Trek writers. Everyone thought the &amp;quot;slow&amp;quot; system will be implemented first, with the &amp;quot;fast&amp;quot; system lagging behind. Everyone thought Lt. Data would be the first kind of AI, never hallucinating but sort of narrow and unimaginative. Instead, we got some deeply intuitive machines that can&amp;#39;t reason very well, and therefore hallucinate.&lt;/p&gt;\\n\\n&lt;p&gt;The &amp;quot;fast&amp;quot; system, what the models have now, is a blob of stuff, slowly shaped by training. The &amp;quot;slow&amp;quot; system should have a much more explicit structure, blocks, loops, control mechanisms, etc.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: It&amp;#39;s not like nature didn&amp;#39;t give us hints. All kinds of animals - many mammals, especially the ones with complex brains, and especially apes, dolphins, etc - have a pretty badass &amp;quot;fast&amp;quot; system. But their &amp;quot;slow&amp;quot; system sucks. Heck, our &amp;quot;slow&amp;quot; system kinda sucks a little bit (see how easily it gets fooled, or overwhelmed by emotion, etc) but it beats the hell out of what the other critters have. Our &amp;quot;slow&amp;quot; system is literally evolution&amp;#39;s most recent big outcome, and it&amp;#39;s a bit unsteady on its legs.&lt;/p&gt;\\n\\n&lt;p&gt;So it should have been clear that &amp;quot;fast&amp;quot; is easy and &amp;quot;slow&amp;quot; is hard. Hindsight is 20/20, I guess.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb8e7q/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333126,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":157}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_mcd7ddh","id":"mcd7ddh","parent_id":"t1_mcb9ury","depth":4,"children":["mcd7ddh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb9ury","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SkyFeistyLlama8","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaunc0","score":10,"author_fullname":"t2_1hgbaqgbnq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Didn't Chomsky cover some of this? Anyway, the human latent space would be related to the physical experiences linked to concepts, emotions and farther down the chain, words. For example: hunger, stomach pains, tiredness, irritability &gt; *hangry human* &gt; \\"I'm hangry!\\"\\n\\nOur concept of knowledge and experience has been shaped by a billion years of evolution. LLM's encode knowledge purely in knowledge which is freaking weird.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb9ury","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Didn&amp;#39;t Chomsky cover some of this? Anyway, the human latent space would be related to the physical experiences linked to concepts, emotions and farther down the chain, words. For example: hunger, stomach pains, tiredness, irritability &amp;gt; &lt;em&gt;hangry human&lt;/em&gt; &amp;gt; &amp;quot;I&amp;#39;m hangry!&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;Our concept of knowledge and experience has been shaped by a billion years of evolution. LLM&amp;#39;s encode knowledge purely in knowledge which is freaking weird.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb9ury/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333712,"author_flair_text":null,"treatment_tags":[],"created_utc":1739333712,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcb9knd","id":"mcb9knd","parent_id":"t1_mcb85m1","depth":5,"children":["mcb9knd"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb85m1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the320x200","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb2o5p","score":11,"author_fullname":"t2_5m9yw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's not really a maybe, there's lots of examples of wordless-thinking. Having a thought or trying to describe a vibe and not knowing how to put it into words in exactly the way you're thinking is pretty common, even if the vibe you're thinking about is crystal clear to you.","edited":false,"author_flair_css_class":null,"name":"t1_mcb85m1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s not really a maybe, there&amp;#39;s lots of examples of wordless-thinking. Having a thought or trying to describe a vibe and not knowing how to put it into words in exactly the way you&amp;#39;re thinking is pretty common, even if the vibe you&amp;#39;re thinking about is crystal clear to you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb85m1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333031,"author_flair_text":null,"collapsed":false,"created_utc":1739333031,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb2o5p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ThiccStorms","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaunc0","score":9,"author_fullname":"t2_ei5y65wk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yeah, maybe we *think* and the brain associates our thoughts with relevant words so fast that we don't realise language is just an output medium","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb2o5p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah, maybe we &lt;em&gt;think&lt;/em&gt; and the brain associates our thoughts with relevant words so fast that we don&amp;#39;t realise language is just an output medium&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb2o5p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739330934,"author_flair_text":null,"treatment_tags":[],"created_utc":1739330934,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbyaun","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"shokuninstudio","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8fep","score":3,"author_fullname":"t2_4xzh04rz","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Our species has been thinking and feeling different ways about situations around us far longer than we have had complex languages to express our thoughts with.","edited":1739346479,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbyaun","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Our species has been thinking and feeling different ways about situations around us far longer than we have had complex languages to express our thoughts with.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbyaun/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739345906,"author_flair_text":null,"treatment_tags":[],"created_utc":1739345906,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbky0p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"VertigoOne1","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb8fep","score":6,"author_fullname":"t2_1lst61m","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Completely agree, that gut feel when you know something is not going to work? That, no we are not going to go that direction for development and you just can’t explain why? That is your brain lagging translation to language. It is like your brain gets to a super position of information processed from every experience in your life and dumbs down to “nah”. It may even be labeled “subconscious thought”, the only “language” bubbling up from that super computer is a little voice sometimes but often just emotion, as in excitement or caution.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbky0p","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Completely agree, that gut feel when you know something is not going to work? That, no we are not going to go that direction for development and you just can’t explain why? That is your brain lagging translation to language. It is like your brain gets to a super position of information processed from every experience in your life and dumbs down to “nah”. It may even be labeled “subconscious thought”, the only “language” bubbling up from that super computer is a little voice sometimes but often just emotion, as in excitement or caution.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbky0p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739338619,"author_flair_text":null,"treatment_tags":[],"created_utc":1739338619,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":1,"name":"t1_mcbr0jp","id":"mcbr0jp","parent_id":"t1_mcb8fep","depth":5,"children":["mcbr0jp"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb8fep","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the320x200","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":16,"author_fullname":"t2_5m9yw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You've never been trying to express a concept and struggled to put it into words that represent it as accurately and clearly as you are thinking? That happens all the time... If words really were the medium of thought then that situation would be impossible.","edited":false,"author_flair_css_class":null,"name":"t1_mcb8fep","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;ve never been trying to express a concept and struggled to put it into words that represent it as accurately and clearly as you are thinking? That happens all the time... If words really were the medium of thought then that situation would be impossible.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb8fep/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333139,"author_flair_text":null,"collapsed":false,"created_utc":1739333139,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":16}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbvepv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmflynnt","can_mod_post":false,"created_utc":1739344191,"send_replies":true,"parent_id":"t1_mcbsjxe","score":7,"author_fullname":"t2_x0bcf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I find it kind of hard to tease out how much is the sociolinguistic side of this as the culture of the Pirahã people is just so damn unique. As soon as we look at a subject who has learned Portuguese we are also looking at someone who is open to the influence of outsiders and who is necessarily deciding to intermix with other cultures. Based on what I have read about the Pirahã people, many of them are fascinatingly for the most part *not* interested in socializing with outsiders.\\n\\nI do agree though that there are some compelling arguments that arise from studying their language and culture that support at least a weak form of linguistic determinism. There have also been studies on Russian speakers showing they have a better ability to distinguish lighter and darker hues of the color blue since the Russian language makes a distinction between them.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbvepv","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I find it kind of hard to tease out how much is the sociolinguistic side of this as the culture of the Pirahã people is just so damn unique. As soon as we look at a subject who has learned Portuguese we are also looking at someone who is open to the influence of outsiders and who is necessarily deciding to intermix with other cultures. Based on what I have read about the Pirahã people, many of them are fascinatingly for the most part &lt;em&gt;not&lt;/em&gt; interested in socializing with outsiders.&lt;/p&gt;\\n\\n&lt;p&gt;I do agree though that there are some compelling arguments that arise from studying their language and culture that support at least a weak form of linguistic determinism. There have also been studies on Russian speakers showing they have a better ability to distinguish lighter and darker hues of the color blue since the Russian language makes a distinction between them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbvepv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739344191,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":4,"removal_reason":null,"link_id":"t3_1inch7r","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":0,"name":"t1__","id":"_","parent_id":"t1_mcbxcmt","depth":10,"children":[]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbxcmt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tmflynnt","can_mod_post":false,"created_utc":1739345332,"send_replies":true,"parent_id":"t1_mcbvm90","score":6,"author_fullname":"t2_x0bcf","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Despite being a hobbyist coder for almost 30 years I have spent most of my career focused on language teaching. I often find many of the correlations that people draw between programming languages and spoken languages to be more or less overwrought,  but what I will say is that both domains certainly help give structure to our thoughts and help us express abstract ideas. And as somebody with pretty severe ADHD, I rather enjoy the way that coding helps me structure my ridiculously jumbled thoughts and ideas into something structured and coherent, just as talking out an idea or typing it down can help me with as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbxcmt","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Despite being a hobbyist coder for almost 30 years I have spent most of my career focused on language teaching. I often find many of the correlations that people draw between programming languages and spoken languages to be more or less overwrought,  but what I will say is that both domains certainly help give structure to our thoughts and help us express abstract ideas. And as somebody with pretty severe ADHD, I rather enjoy the way that coding helps me structure my ridiculously jumbled thoughts and ideas into something structured and coherent, just as talking out an idea or typing it down can help me with as well.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbxcmt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739345332,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":9,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":3,"name":"t1_mcbxo8m","id":"mcbxo8m","parent_id":"t1_mcbvm90","depth":9,"children":["mcbxo8m"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbvm90","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":"DELETED","no_follow":true,"author":"[deleted]","can_mod_post":false,"created_utc":1739344310,"send_replies":true,"parent_id":"t1_mcbsjxe","score":4,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"[removed]","edited":false,"author_flair_css_class":null,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbvm90/","num_reports":null,"locked":false,"name":"t1_mcbvm90","created":1739344310,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"collapsed":true,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":8,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"more","data":{"count":3,"name":"t1_mcbxhuk","id":"mcbxhuk","parent_id":"t1_mcbsjxe","depth":8,"children":["mcbxhuk","mcc1ax3"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbsjxe","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"created_utc":1739342582,"send_replies":true,"parent_id":"t1_mcbrmv9","score":11,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Look up the research on the Pirahã language, which has shown that first language DOES in fact limit thought. Pirahã is notable for having extremely few words for numerical concepts, and people speaking only Pirahã lack even basic numeracy, but those same people gain numeracy by learning other languages. Any modern cogsci textbook features this and other such examples. Language absolutely does limit thought.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mcbsjxe","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Look up the research on the Pirahã language, which has shown that first language DOES in fact limit thought. Pirahã is notable for having extremely few words for numerical concepts, and people speaking only Pirahã lack even basic numeracy, but those same people gain numeracy by learning other languages. Any modern cogsci textbook features this and other such examples. Language absolutely does limit thought.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbsjxe/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739342582,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":7,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbrmv9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codeprimate","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbr26a","score":7,"author_fullname":"t2_3cev3","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Moving goalposts.\\n\\nPartially influenced, yes. Driven or limited by, absolutely not.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mcbrmv9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Moving goalposts.&lt;/p&gt;\\n\\n&lt;p&gt;Partially influenced, yes. Driven or limited by, absolutely not.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbrmv9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739342075,"author_flair_text":null,"treatment_tags":[],"created_utc":1739342075,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"more","data":{"count":3,"name":"t1_mchmawu","id":"mchmawu","parent_id":"t1_mcbr26a","depth":6,"children":["mchmawu"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbr26a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbk7it","score":12,"author_fullname":"t2_dkgrhaet","approved_by":null,"mod_note":null,"all_awardings":[],"body":"You are not necessarily “thinking in words”, but the language or languages you speak partially determine how and what you think. This is cognitive science 101, and I can guarantee you’re not an exception to this fact that has been experimentally demonstrated many times.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbr26a","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You are not necessarily “thinking in words”, but the language or languages you speak partially determine how and what you think. This is cognitive science 101, and I can guarantee you’re not an exception to this fact that has been experimentally demonstrated many times.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbr26a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739341759,"author_flair_text":null,"treatment_tags":[],"created_utc":1739341759,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"more","data":{"count":1,"name":"t1_mccgfhq","id":"mccgfhq","parent_id":"t1_mcbk7it","depth":5,"children":["mccgfhq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbk7it","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"codeprimate","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":23,"author_fullname":"t2_3cev3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Maybe for people with an internal monologue.\\n\\nI write code all day, and I am certainly not thinking in words. The programming language is simply a method  for transcribing the logic and data schemas in my head.\\n\\nMy own daily lived experience is a counter example to the entire assertion.","edited":false,"author_flair_css_class":null,"name":"t1_mcbk7it","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Maybe for people with an internal monologue.&lt;/p&gt;\\n\\n&lt;p&gt;I write code all day, and I am certainly not thinking in words. The programming language is simply a method  for transcribing the logic and data schemas in my head.&lt;/p&gt;\\n\\n&lt;p&gt;My own daily lived experience is a counter example to the entire assertion.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbk7it/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739338266,"author_flair_text":null,"collapsed":false,"created_utc":1739338266,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbf2sw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the_friendly_dildo","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":7,"author_fullname":"t2_dza4x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;The human mind does not possess a latent thinking space that is completely separate of the language(s) they speak.\\n\\nHow does that coalesce with the two facts that 1) some people don't have an internal monologue and 2) some people don't have the ability to internally visualize things?\\n\\nSurely people that do have these capabilities, are not doing so with the same faculties as people who do not?","edited":1739336206,"author_flair_css_class":null,"name":"t1_mcbf2sw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The human mind does not possess a latent thinking space that is completely separate of the language(s) they speak.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;How does that coalesce with the two facts that 1) some people don&amp;#39;t have an internal monologue and 2) some people don&amp;#39;t have the ability to internally visualize things?&lt;/p&gt;\\n\\n&lt;p&gt;Surely people that do have these capabilities, are not doing so with the same faculties as people who do not?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbf2sw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739335924,"author_flair_text":null,"collapsed":false,"created_utc":1739335924,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"body":"I believe it very much depends on your definition of thinking.\\n\\nIf we consider thinking the subjective experience of forming thoughts, then for sure we're dependent on our \\"tokens\\" of language. However, if you look at it from an objective biochemical perspective, it'd very much resemble the same patterns we observe over a circuit board.  \\n  \\nGoing with the latter perspective, it makes sense if there are certain neurons inside our heads forming a latent space.","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbu041","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tmflynnt","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb3kzs","score":2,"author_fullname":"t2_x0bcf","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Have you read any of Steven Pinker's work? Books of his like *The Stuff of Thought* go in depth on this type of thing. I find his way of explaining the interplay between brain/cognitive science and language to be pretty damn compelling and I like how psycholinguists like him blend the softer sciences with the harder sciences, which I think is very useful as it pushes the debate to deeper places than just \\"Did Chomsky have it right?\\".","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbu041","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Have you read any of Steven Pinker&amp;#39;s work? Books of his like &lt;em&gt;The Stuff of Thought&lt;/em&gt; go in depth on this type of thing. I find his way of explaining the interplay between brain/cognitive science and language to be pretty damn compelling and I like how psycholinguists like him blend the softer sciences with the harder sciences, which I think is very useful as it pushes the debate to deeper places than just &amp;quot;Did Chomsky have it right?&amp;quot;.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbu041/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739343394,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1739343394,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb3kzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PharadoxIC","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":5,"author_fullname":"t2_6j8l3xsp","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"author_flair_css_class":null,"name":"t1_mcb3kzs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I believe it very much depends on your definition of thinking.&lt;/p&gt;\\n\\n&lt;p&gt;If we consider thinking the subjective experience of forming thoughts, then for sure we&amp;#39;re dependent on our &amp;quot;tokens&amp;quot; of language. However, if you look at it from an objective biochemical perspective, it&amp;#39;d very much resemble the same patterns we observe over a circuit board.  &lt;/p&gt;\\n\\n&lt;p&gt;Going with the latter perspective, it makes sense if there are certain neurons inside our heads forming a latent space.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb3kzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739331271,"author_flair_text":null,"collapsed":false,"created_utc":1739331271,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcekiyr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":1,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This article begs to differ: [https://www.noemamag.com/ai-and-the-limits-of-language/](https://www.noemamag.com/ai-and-the-limits-of-language/)","edited":false,"author_flair_css_class":null,"name":"t1_mcekiyr","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This article begs to differ: &lt;a href=\\"https://www.noemamag.com/ai-and-the-limits-of-language/\\"&gt;https://www.noemamag.com/ai-and-the-limits-of-language/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcekiyr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739383595,"author_flair_text":"Llama 3.1","collapsed":false,"created_utc":1739383595,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mchlxsy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"yellow_submarine1734","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb0f3l","score":1,"author_fullname":"t2_2eh02sdb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"On the contrary, the Sapir-Whorf hypothesis has been proven wrong over and over again. Language does not determine the boundaries of thought. Decades of linguistic study disagrees with you here.","edited":false,"author_flair_css_class":null,"name":"t1_mchlxsy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;On the contrary, the Sapir-Whorf hypothesis has been proven wrong over and over again. Language does not determine the boundaries of thought. Decades of linguistic study disagrees with you here.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mchlxsy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739416245,"author_flair_text":null,"collapsed":false,"created_utc":1739416245,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":5,"name":"t1_mcb9rky","id":"mcb9rky","parent_id":"t1_mcb0f3l","depth":4,"children":["mcb9rky"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb0f3l","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaunc0","score":27,"author_fullname":"t2_dkgrhaet","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"While linguistic determinism isn’t taken quite as seriously anymore as it used to be in the days of Whorf, the idea that “language is an overlay” has been falsified experimentally over and over. Search for “Pirahã language” to find plenty of relevant literature.\\n\\nHuman language is, at least to some extent, the *medium* of human thought, not just a way to express it. It strongly influences what can be thought, and how people think about it. The human mind does not possess a latent thinking space that is completely separate of the language(s) they speak.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb0f3l","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;While linguistic determinism isn’t taken quite as seriously anymore as it used to be in the days of Whorf, the idea that “language is an overlay” has been falsified experimentally over and over. Search for “Pirahã language” to find plenty of relevant literature.&lt;/p&gt;\\n\\n&lt;p&gt;Human language is, at least to some extent, the &lt;em&gt;medium&lt;/em&gt; of human thought, not just a way to express it. It strongly influences what can be thought, and how people think about it. The human mind does not possess a latent thinking space that is completely separate of the language(s) they speak.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb0f3l/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739330095,"author_flair_text":null,"treatment_tags":[],"created_utc":1739330095,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":27}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcb8bba","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mad_Gouki","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaunc0","score":1,"author_fullname":"t2_2xlmg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Didn't Wittgenstein touch on this?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb8bba","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Didn&amp;#39;t Wittgenstein touch on this?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb8bba/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333094,"author_flair_text":null,"treatment_tags":[],"created_utc":1739333094,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaunc0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Any-Conference1005","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcarimz","score":87,"author_fullname":"t2_d0l1vcbil","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Before anyone speaks, one thinks.\\n\\nLanguage is an overlay.\\n\\nI'd argue that humans think in latent space too.\\n\\nFor humans, language clarifies reasoning, binds it to pre-defined common concepts, allowing rigorous complexities. Language is evolution not involution.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcaunc0","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Before anyone speaks, one thinks.&lt;/p&gt;\\n\\n&lt;p&gt;Language is an overlay.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d argue that humans think in latent space too.&lt;/p&gt;\\n\\n&lt;p&gt;For humans, language clarifies reasoning, binds it to pre-defined common concepts, allowing rigorous complexities. Language is evolution not involution.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaunc0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739328014,"author_flair_text":null,"treatment_tags":[],"created_utc":1739328014,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":87}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccfaqk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"OracleGreyBeard","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcarimz","score":1,"author_fullname":"t2_806hpu46","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"In some ways LLMs are the best dictionaries and thesauri in history.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccfaqk","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In some ways LLMs are the best dictionaries and thesauri in history.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccfaqk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739356447,"author_flair_text":null,"treatment_tags":[],"created_utc":1739356447,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcek0yq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ninjasaid13","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcarimz","score":1,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;That’s because the latent representation is essentially a super-language\\n\\nnot really, even animals probably have latent representations.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcek0yq","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;That’s because the latent representation is essentially a super-language&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;not really, even animals probably have latent representations.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcek0yq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739383455,"author_flair_text":"Llama 3.1","treatment_tags":[],"created_utc":1739383455,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcarimz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"-p-e-w-","can_mod_post":false,"created_utc":1739326915,"send_replies":true,"parent_id":"t1_mc9uvx2","score":54,"author_fullname":"t2_dkgrhaet","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s because the latent representation is essentially a super-language, distilled from all human languages and forced towards maximum semantic density by the constraints of training. It’s what human languages might eventually converge to, if given millions of years of cultural evolution, and if human brains didn’t have the limitations they do.\\n\\nIf humans could “read” an LLM’s internal representation of its input, no doubt entirely new layers of meaning would immediately become obvious to them as well.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcarimz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s because the latent representation is essentially a super-language, distilled from all human languages and forced towards maximum semantic density by the constraints of training. It’s what human languages might eventually converge to, if given millions of years of cultural evolution, and if human brains didn’t have the limitations they do.&lt;/p&gt;\\n\\n&lt;p&gt;If humans could “read” an LLM’s internal representation of its input, no doubt entirely new layers of meaning would immediately become obvious to them as well.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcarimz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739326915,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":54}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcagupi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Shir_man","can_mod_post":false,"created_utc":1739323286,"send_replies":true,"parent_id":"t1_mc9uvx2","score":22,"author_fullname":"t2_366vr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Just imagine all those new DAN injections","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcagupi","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Just imagine all those new DAN injections&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcagupi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323286,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":22}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaxjhf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jirka642","can_mod_post":false,"created_utc":1739329052,"send_replies":true,"parent_id":"t1_mc9uvx2","score":5,"author_fullname":"t2_3f09f3kt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yep, I was thinking that something like this would be the next step.   \\nPeople don't think in just words after all.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaxjhf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yep, I was thinking that something like this would be the next step.&lt;br/&gt;\\nPeople don&amp;#39;t think in just words after all.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaxjhf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739329052,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbs2cr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"CompromisedToolchain","can_mod_post":false,"created_utc":1739342313,"send_replies":true,"parent_id":"t1_mc9uvx2","score":1,"author_fullname":"t2_p6uw690c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"This is the whole point!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbs2cr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is the whole point!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbs2cr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739342313,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc524z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FairlyInvolved","can_mod_post":false,"created_utc":1739350054,"send_replies":true,"parent_id":"t1_mc9uvx2","score":1,"author_fullname":"t2_qaxlr1d8h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wasn't that already shown with the Coconut paper?\\n\\nhttps://arxiv.org/abs/2412.06769\\n\\nEdit: oops just seen this was pointed out further down the comments.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcc524z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wasn&amp;#39;t that already shown with the Coconut paper?&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2412.06769\\"&gt;https://arxiv.org/abs/2412.06769&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Edit: oops just seen this was pointed out further down the comments.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc524z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739350054,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcceqi1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"UndoubtedlyAColor","can_mod_post":false,"created_utc":1739356101,"send_replies":true,"parent_id":"t1_mc9uvx2","score":1,"author_fullname":"t2_6h3vlh2p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I would have thought that they already did this. Words and the concepts they represent are really lacking in complexity and nuance compared to the concepts which can exist in the latent space. Multiple words combined mitigate this somewhat I suppose but the latent should be even better.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcceqi1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I would have thought that they already did this. Words and the concepts they represent are really lacking in complexity and nuance compared to the concepts which can exist in the latent space. Multiple words combined mitigate this somewhat I suppose but the latent should be even better.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcceqi1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739356101,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mc9uvx2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tehbangere","can_mod_post":false,"created_utc":1739316075,"send_replies":true,"parent_id":"t3_1inch7r","score":429,"author_fullname":"t2_10ps26h7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Most notably, the paper shows that in latent space it can capture types of reasoning that are not easily represented in words, thus achieving better performances than classical CoT.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9uvx2","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Most notably, the paper shows that in latent space it can capture types of reasoning that are not easily represented in words, thus achieving better performances than classical CoT.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9uvx2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739316075,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":429}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcewzy1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MoffKalast","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaqvni","score":1,"author_fullname":"t2_d2nyh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Probably not even the first one.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcewzy1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Probably not even the first one.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcewzy1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739387031,"author_flair_text":null,"treatment_tags":[],"created_utc":1739387031,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaqvni","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crafty-Struggle7810","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcapkzs","score":25,"author_fullname":"t2_sbmgyk5rk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://arxiv.org/abs/2412.06769","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcaqvni","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2412.06769\\"&gt;https://arxiv.org/abs/2412.06769&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaqvni/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739326693,"author_flair_text":null,"treatment_tags":[],"created_utc":1739326693,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":25}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7dba5c08-72f1-11ee-9b6f-ca195bc297d4","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcemwkh","id":"mcemwkh","parent_id":"t1_mcckehm","depth":5,"children":["mcemwkh"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcckehm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LumpyWelds","can_mod_post":false,"send_replies":true,"parent_id":"t1_mccgn7k","score":6,"author_fullname":"t2_32hdazgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Could you please link the paper?  I've not seen research on that.\\n\\n\\\\---\\n\\nDownvoted for asking for a supporting paper?  I thought this was r/LocalLLaMA , not r/philosophy","edited":1739370732,"author_flair_css_class":null,"name":"t1_mcckehm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Could you please link the paper?  I&amp;#39;ve not seen research on that.&lt;/p&gt;\\n\\n&lt;p&gt;---&lt;/p&gt;\\n\\n&lt;p&gt;Downvoted for asking for a supporting paper?  I thought this was &lt;a href=\\"/r/LocalLLaMA\\"&gt;r/LocalLLaMA&lt;/a&gt; , not &lt;a href=\\"/r/philosophy\\"&gt;r/philosophy&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcckehm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739359419,"author_flair_text":null,"collapsed":false,"created_utc":1739359419,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"more","data":{"count":2,"name":"t1_mcd0e3b","id":"mcd0e3b","parent_id":"t1_mccgn7k","depth":4,"children":["mcd0e3b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mccgn7k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Nabushika","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbzn8k","score":4,"author_fullname":"t2_1lrj5qoj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Why would it be difficult? We can still find neurons or tokens that map to deception, and we've shown that that's already a much better indication of model truthfulness than we can ever get through any outputted tokens.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mccgn7k","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 70B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why would it be difficult? We can still find neurons or tokens that map to deception, and we&amp;#39;ve shown that that&amp;#39;s already a much better indication of model truthfulness than we can ever get through any outputted tokens.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccgn7k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739357286,"author_flair_text":"Llama 70B","treatment_tags":[],"created_utc":1739357286,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbzn8k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LumpyWelds","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcapkzs","score":17,"author_fullname":"t2_32hdazgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Meta's coconut project (paper listed by Crafty-Struggle7810) is based upon how reasoning works in biology\\n\\n&gt;**Studies in neuroscience reinforce this notion, showing that reasoning often bypasses language networks in the human brain.**\\n\\n[https://www.marktechpost.com/2024/12/12/meta-ai-introduces-coconut-a-new-paradigm-transforming-machine-reasoning-with-continuous-latent-thoughts-and-advanced-planning-capabilities/](https://www.marktechpost.com/2024/12/12/meta-ai-introduces-coconut-a-new-paradigm-transforming-machine-reasoning-with-continuous-latent-thoughts-and-advanced-planning-capabilities/)\\n\\nLatent space reasoning bothers me since it would be difficult to audit when a model is lying.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcbzn8k","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Meta&amp;#39;s coconut project (paper listed by Crafty-Struggle7810) is based upon how reasoning works in biology&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;&lt;strong&gt;Studies in neuroscience reinforce this notion, showing that reasoning often bypasses language networks in the human brain.&lt;/strong&gt;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.marktechpost.com/2024/12/12/meta-ai-introduces-coconut-a-new-paradigm-transforming-machine-reasoning-with-continuous-latent-thoughts-and-advanced-planning-capabilities/\\"&gt;https://www.marktechpost.com/2024/12/12/meta-ai-introduces-coconut-a-new-paradigm-transforming-machine-reasoning-with-continuous-latent-thoughts-and-advanced-planning-capabilities/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Latent space reasoning bothers me since it would be difficult to audit when a model is lying.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbzn8k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739346715,"author_flair_text":null,"treatment_tags":[],"created_utc":1739346715,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}}],"before":null}},"user_reports":[],"saved":false,"id":"mcapkzs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Kimononono","can_mod_post":false,"created_utc":1739326244,"send_replies":true,"parent_id":"t1_mc9xk8i","score":14,"author_fullname":"t2_hakgw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"remember the papers or where do you remember it from?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcapkzs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;remember the papers or where do you remember it from?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcapkzs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739326244,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcb9a4a","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KrayziePidgeon","can_mod_post":false,"created_utc":1739333481,"send_replies":true,"parent_id":"t1_mc9xk8i","score":4,"author_fullname":"t2_4ky1ofjh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That is literally how scientific research is made.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb9a4a","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That is literally how scientific research is made.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb9a4a/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333481,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccninq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheSuperSam","can_mod_post":false,"created_utc":1739361085,"send_replies":true,"parent_id":"t1_mc9xk8i","score":1,"author_fullname":"t2_nxztn77","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"deep equilibrium models","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mccninq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;deep equilibrium models&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccninq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739361085,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":1,"name":"t1_mcaysc2","id":"mcaysc2","parent_id":"t1_mc9xk8i","depth":1,"children":["mcaysc2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mc9xk8i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LelouchZer12","can_mod_post":false,"created_utc":1739316933,"send_replies":true,"parent_id":"t3_1inch7r","score":93,"author_fullname":"t2_s0t562c","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I'm pretty sure reasoning in latent space instead of output token has already been done, but still this is an intersesting paper.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9xk8i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m pretty sure reasoning in latent space instead of output token has already been done, but still this is an intersesting paper.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9xk8i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739316933,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":93}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcb9ir2","id":"mcb9ir2","parent_id":"t1_mcas457","depth":2,"children":["mcb9ir2"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcas457","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Crafty-Struggle7810","can_mod_post":false,"created_utc":1739327125,"send_replies":true,"parent_id":"t1_mcaee5z","score":18,"author_fullname":"t2_sbmgyk5rk","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"To add to your point, token-based reasoning can be copied and pasted for reinforcement learning, hence why it has taken off in popularity. This paper would’ve been more interesting if they took Meta’s existing research into latent space reasoning and applied reinforcement learning to it. ","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcas457","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;To add to your point, token-based reasoning can be copied and pasted for reinforcement learning, hence why it has taken off in popularity. This paper would’ve been more interesting if they took Meta’s existing research into latent space reasoning and applied reinforcement learning to it. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcas457/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739327125,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":18}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaee5z","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_prince69","can_mod_post":false,"created_utc":1739322468,"send_replies":true,"parent_id":"t3_1inch7r","score":66,"author_fullname":"t2_w3xgnw46m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Latent space is such an overloaded term here. It uses a recurrent model and I have not yet seen how it scales — being a linear model, it presents challenges that the authors have not discussed or maybe even did not know about. \\n\\nAnd I know the authors ( first and last ) of this paper are typically working on hot topics but abandon it quickly. Previously we tried to use another of their work (non-LLM) which generated so much buzz. But we weren’t successful in using it in practice due to their highly simplified assumptions. \\n\\nSo yeah you can publish papers with catchy titles which don’t work — not saying this one would not work but based on their previous record.","edited":1739322831,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaee5z","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Latent space is such an overloaded term here. It uses a recurrent model and I have not yet seen how it scales — being a linear model, it presents challenges that the authors have not discussed or maybe even did not know about. &lt;/p&gt;\\n\\n&lt;p&gt;And I know the authors ( first and last ) of this paper are typically working on hot topics but abandon it quickly. Previously we tried to use another of their work (non-LLM) which generated so much buzz. But we weren’t successful in using it in practice due to their highly simplified assumptions. &lt;/p&gt;\\n\\n&lt;p&gt;So yeah you can publish papers with catchy titles which don’t work — not saying this one would not work but based on their previous record.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaee5z/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322468,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":66}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":21,"removal_reason":null,"link_id":"t3_1inch7r","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcam3lg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ninjasaid13","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaaxvh","score":23,"author_fullname":"t2_qjpsv","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I've checked the github issues and and one of them is asking a comparison with coconut.\\n\\nThey said: \\"Hi! Both have a similar aim (\\"reasoning in high-dimensional space\\"), but very different approaches. We discuss this in more detail in Section 6.3\\"\\n\\n6.3. Zero-Shot Continuous Chain-of-Thought Instead of sampling a random initial state s\\\\_0 at every generation step, we can warm-start with the last state sr from the previous token. As shown in\\n\\nhttps://preview.redd.it/e06oahpb6mie1.png?width=1434&amp;format=png&amp;auto=webp&amp;s=9ae9e2d13204f9125bba6200737a305865c17ea1\\n\\nthis reduces the average number of steps required to converge by 1-2. Also, on tasks such as philosophy questions, we see that the exit distribution shifts on several tasks, with the model more often exiting early by recycling previous compute. To achieve a similar behavior in fixed-depth transformers, these models need to be trained on reasoning tasks to accept their last hidden state as alternative inputs when computing the next token (Hao et al., 2024).","edited":1739329067,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcam3lg","is_submitter":false,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;ve checked the github issues and and one of them is asking a comparison with coconut.&lt;/p&gt;\\n\\n&lt;p&gt;They said: &amp;quot;Hi! Both have a similar aim (&amp;quot;reasoning in high-dimensional space&amp;quot;), but very different approaches. We discuss this in more detail in Section 6.3&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;6.3. Zero-Shot Continuous Chain-of-Thought Instead of sampling a random initial state s_0 at every generation step, we can warm-start with the last state sr from the previous token. As shown in&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/e06oahpb6mie1.png?width=1434&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9ae9e2d13204f9125bba6200737a305865c17ea1\\"&gt;https://preview.redd.it/e06oahpb6mie1.png?width=1434&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9ae9e2d13204f9125bba6200737a305865c17ea1&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;this reduces the average number of steps required to converge by 1-2. Also, on tasks such as philosophy questions, we see that the exit distribution shifts on several tasks, with the model more often exiting early by recycling previous compute. To achieve a similar behavior in fixed-depth transformers, these models need to be trained on reasoning tasks to accept their last hidden state as alternative inputs when computing the next token (Hao et al., 2024).&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcam3lg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739325048,"media_metadata":{"e06oahpb6mie1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":41,"x":108,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a37ea512113086971b9f2f972a7a0a123ea7014"},{"y":83,"x":216,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c3f626811625b2c1f2cfc879a4e85cc0c297081"},{"y":123,"x":320,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2aee1905db0db585d42e09741cd5c738101d142"},{"y":246,"x":640,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2932a4cf751e7923fd07c40937da15d219f87f9a"},{"y":369,"x":960,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=56d80bed943a0f01834c5d75bd154cbc8cac5eeb"},{"y":415,"x":1080,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b6e205ad3fd2644ae8b9ef4bac50a0fe26a85851"}],"s":{"y":552,"x":1434,"u":"https://preview.redd.it/e06oahpb6mie1.png?width=1434&amp;format=png&amp;auto=webp&amp;s=9ae9e2d13204f9125bba6200737a305865c17ea1"},"id":"e06oahpb6mie1"}},"author_flair_text":"Llama 3.1","treatment_tags":[],"created_utc":1739325048,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaimgn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Inkbot_dev","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaaxvh","score":5,"author_fullname":"t2_kvvrvk5lb","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Same fixed recurrent loops and everything.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcaimgn","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Same fixed recurrent loops and everything.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaimgn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323878,"author_flair_text":null,"treatment_tags":[],"created_utc":1739323878,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcdqwuq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LumpyWelds","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaaxvh","score":1,"author_fullname":"t2_32hdazgq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Pretty sure this paper is by Huggingface. \\n\\nMeta's coconut is a different paper.  [https://arxiv.org/abs/2412.06769](https://arxiv.org/abs/2412.06769)","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcdqwuq","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Pretty sure this paper is by Huggingface. &lt;/p&gt;\\n\\n&lt;p&gt;Meta&amp;#39;s coconut is a different paper.  &lt;a href=\\"https://arxiv.org/abs/2412.06769\\"&gt;https://arxiv.org/abs/2412.06769&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcdqwuq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739375230,"author_flair_text":null,"treatment_tags":[],"created_utc":1739375230,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaaxvh","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9ypjb","score":21,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"same thing, this is coconut.","edited":false,"author_flair_css_class":null,"collapsed":false,"downs":0,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;same thing, this is coconut.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaaxvh/","num_reports":null,"locked":false,"name":"t1_mcaaxvh","created":1739321332,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1739321332,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}}],"before":null}},"user_reports":[],"saved":false,"id":"mc9ypjb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ninjasaid13","can_mod_post":false,"created_utc":1739317308,"send_replies":true,"parent_id":"t3_1inch7r","score":35,"author_fullname":"t2_qjpsv","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This paper seems similar to the coconut paper. are they incompatible?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9ypjb","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This paper seems similar to the coconut paper. are they incompatible?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9ypjb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739317308,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":35}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mc9z9s1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PwanaZana","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":23,"author_fullname":"t2_d0sto8d3h","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you for the explanation! :P","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mc9z9s1","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you for the explanation! :P&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9z9s1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739317493,"author_flair_text":null,"treatment_tags":[],"created_utc":1739317493,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":23}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccluiv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fjoobert","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbk2n8","score":5,"author_fullname":"t2_16s126bo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"That’s really interesting, thank you for the response!","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mccluiv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s really interesting, thank you for the response!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccluiv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739360207,"author_flair_text":null,"treatment_tags":[],"created_utc":1739360207,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mce6aga","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DevilaN82","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbk2n8","score":3,"author_fullname":"t2_udjy4jvy","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Thank you. This is the best explanation I've read so far.","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mce6aga","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you. This is the best explanation I&amp;#39;ve read so far.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mce6aga/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739379603,"author_flair_text":null,"treatment_tags":[],"created_utc":1739379603,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbk2n8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AssiduousLayabout","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcawdvv","score":34,"author_fullname":"t2_49hucaql","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, but in latent space, the output is not a single token, but a probability distribution of tokens. For example, assume you had a language that only had two words to represent size, 'big' and 'small'. When it is about to produce an output token, in latent space, it's possible for the next output to be \\"90% big / 10% small\\", but when it is converted to an output token, it's forced to be exactly one value. At a low temperature, this will (almost) always be \\"big\\", but at higher temperatures it might occasionally be \\"small\\".\\n\\nWith this method, it can continue to \\"think\\" about this as \\"90% big / 10% small\\" without being constrained to being exactly one or exactly the other. In this way, it can represent thoughts in a way that is not limited by the language itself. And, perhaps even more interestingly, \\"90% big / 10% small\\" is a distinct 'thought' from \\"85% big / 15% small\\" even though both would produce very similar output tokens, especially at low temperature.\\n\\nIn this way, even though the language has only two words for size, in latent space the LLM can represent a (theoretically) infinite number of degrees of variation. In practice it is actually finite, of course, due to the fact we use a finite number of bits to store the number, but we can go from 2 sizes to billions of sizes.","edited":1739381157,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcbk2n8","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, but in latent space, the output is not a single token, but a probability distribution of tokens. For example, assume you had a language that only had two words to represent size, &amp;#39;big&amp;#39; and &amp;#39;small&amp;#39;. When it is about to produce an output token, in latent space, it&amp;#39;s possible for the next output to be &amp;quot;90% big / 10% small&amp;quot;, but when it is converted to an output token, it&amp;#39;s forced to be exactly one value. At a low temperature, this will (almost) always be &amp;quot;big&amp;quot;, but at higher temperatures it might occasionally be &amp;quot;small&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;With this method, it can continue to &amp;quot;think&amp;quot; about this as &amp;quot;90% big / 10% small&amp;quot; without being constrained to being exactly one or exactly the other. In this way, it can represent thoughts in a way that is not limited by the language itself. And, perhaps even more interestingly, &amp;quot;90% big / 10% small&amp;quot; is a distinct &amp;#39;thought&amp;#39; from &amp;quot;85% big / 15% small&amp;quot; even though both would produce very similar output tokens, especially at low temperature.&lt;/p&gt;\\n\\n&lt;p&gt;In this way, even though the language has only two words for size, in latent space the LLM can represent a (theoretically) infinite number of degrees of variation. In practice it is actually finite, of course, due to the fact we use a finite number of bits to store the number, but we can go from 2 sizes to billions of sizes.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbk2n8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739338201,"author_flair_text":null,"treatment_tags":[],"created_utc":1739338201,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":34}},{"kind":"more","data":{"count":1,"name":"t1_mcbkg8b","id":"mcbkg8b","parent_id":"t1_mcawdvv","depth":5,"children":["mcbkg8b"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcawdvv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"fjoobert","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca4v4p","score":7,"author_fullname":"t2_16s126bo","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Is this doing the same kind of processing that results in a token without actually using the token as an output?","edited":false,"author_flair_css_class":null,"name":"t1_mcawdvv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this doing the same kind of processing that results in a token without actually using the token as an output?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcawdvv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739328634,"author_flair_text":null,"collapsed":false,"created_utc":1739328634,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca8omj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mixedTape3123","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca4v4p","score":14,"author_fullname":"t2_90bt3k4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow.","edited":false,"author_flair_css_class":null,"name":"t1_mca8omj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca8omj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320593,"author_flair_text":null,"collapsed":false,"created_utc":1739320593,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0","distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc16or","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TheDreamWoken","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca4v4p","score":1,"author_fullname":"t2_151ddpzf3g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"So no tokenizer?","edited":false,"author_flair_css_class":null,"name":"t1_mcc16or","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"textgen web UI"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So no tokenizer?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc16or/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739347637,"author_flair_text":"textgen web UI","collapsed":false,"created_utc":1739347637,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mca4v4p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"jm2342","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":63,"author_fullname":"t2_rij3g","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Vectors still, but they don't represent tokens, just pure \\"thought\\" if you will.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca4v4p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Vectors still, but they don&amp;#39;t represent tokens, just pure &amp;quot;thought&amp;quot; if you will.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca4v4p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319347,"author_flair_text":null,"treatment_tags":[],"created_utc":1739319347,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":63}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcazbyy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AnOnlineHandle","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcavix7","score":4,"author_fullname":"t2_5xsr5","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I'm not well educated on the topic, but am pretty sure they develop entirely different latent spaces. e.g. Image compressors used with image generative models have very different latent spaces.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcazbyy","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I&amp;#39;m not well educated on the topic, but am pretty sure they develop entirely different latent spaces. e.g. Image compressors used with image generative models have very different latent spaces.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcazbyy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739329699,"author_flair_text":null,"treatment_tags":[],"created_utc":1739329699,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcb2tmv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"-TV-Stand-","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcavix7","score":3,"author_fullname":"t2_jus1ftro","approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;Like an machine language\\n\\nNot all processors understand the same machine language either.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcb2tmv","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;Like an machine language&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Not all processors understand the same machine language either.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb2tmv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739330989,"author_flair_text":null,"treatment_tags":[],"created_utc":1739330989,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"body":"Roughly speaking, if you use the same decoder over the same latent space, you'll get the same results; so, the short answer is yes! :D\\n\\nAnother interesting interaction could be using different decoders over the same latent space. You could imagine having a model that could compress both text and image information into a latent space, and has two separate decoders for decoding the original data. (Look up \\"Two-headed autoencoders\\")","subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcb4z61","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"PharadoxIC","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcavix7","score":2,"author_fullname":"t2_6j8l3xsp","approved_by":null,"mod_note":null,"all_awardings":[],"author_cakeday":true,"edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcb4z61","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Roughly speaking, if you use the same decoder over the same latent space, you&amp;#39;ll get the same results; so, the short answer is yes! :D&lt;/p&gt;\\n\\n&lt;p&gt;Another interesting interaction could be using different decoders over the same latent space. You could imagine having a model that could compress both text and image information into a latent space, and has two separate decoders for decoding the original data. (Look up &amp;quot;Two-headed autoencoders&amp;quot;)&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb4z61/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739331803,"author_flair_text":null,"treatment_tags":[],"created_utc":1739331803,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mcavix7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"absenceanddesire","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcai5j5","score":3,"author_fullname":"t2_195szkc096","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Wow I always thought it mapped to a base language like English then from English to the next desired language. Obvious question is would similarly models have similar latent spaces, can they comprehend each other? Like an machine language 😅","edited":false,"author_flair_css_class":null,"name":"t1_mcavix7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wow I always thought it mapped to a base language like English then from English to the next desired language. Obvious question is would similarly models have similar latent spaces, can they comprehend each other? Like an machine language 😅&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcavix7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739328325,"author_flair_text":null,"collapsed":false,"created_utc":1739328325,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mcai5j5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"AnOnlineHandle","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":31,"author_fullname":"t2_5xsr5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Imagine you made a model which converts text between languages. First it would need to extract the meaning of the text, then write that in a new language. So the model can be thought of as an input encoding path, and then an output decoding path.\\n\\nThe middle part, where the text is represented in some universal language that the model has created, which can be turned into any other language, would be the latent space. It's still a language, just a non-human one which has evolved for the task and is likely heavily compressed information.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcai5j5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Imagine you made a model which converts text between languages. First it would need to extract the meaning of the text, then write that in a new language. So the model can be thought of as an input encoding path, and then an output decoding path.&lt;/p&gt;\\n\\n&lt;p&gt;The middle part, where the text is represented in some universal language that the model has created, which can be turned into any other language, would be the latent space. It&amp;#39;s still a language, just a non-human one which has evolved for the task and is likely heavily compressed information.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcai5j5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323721,"author_flair_text":null,"treatment_tags":[],"created_utc":1739323721,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":31}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcupt0j","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"coloyoga","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcazhfv","score":2,"author_fullname":"t2_7x5bj8ey","approved_by":null,"mod_note":null,"all_awardings":[],"body":"I loved his explanation but I laughed out loud to your comment lol","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcupt0j","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I loved his explanation but I laughed out loud to your comment lol&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcupt0j/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739593437,"author_flair_text":null,"treatment_tags":[],"created_utc":1739593437,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mceoiwq","id":"mceoiwq","parent_id":"t1_mcc5khg","depth":7,"children":["mceoiwq"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcc5khg","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AnihcamE","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb01k7","score":2,"author_fullname":"t2_14h8ir","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Actually it helped in my case, thanks! I am just a bit confused with the original paper saying that \\"LLM coult think in latent space\\". What does it mean ? That the reasoning part is not only done by outputing token at the end but it can be done \\"earlier\\" in the process ? Meaning that you don't need to use the full network to have reasoning ?","edited":false,"gildings":{},"author_flair_css_class":null,"name":"t1_mcc5khg","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually it helped in my case, thanks! I am just a bit confused with the original paper saying that &amp;quot;LLM coult think in latent space&amp;quot;. What does it mean ? That the reasoning part is not only done by outputing token at the end but it can be done &amp;quot;earlier&amp;quot; in the process ? Meaning that you don&amp;#39;t need to use the full network to have reasoning ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc5khg/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739350382,"author_flair_text":null,"treatment_tags":[],"created_utc":1739350382,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":6,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb01k7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"tehbangere","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcazhfv","score":2,"author_fullname":"t2_10ps26h7","approved_by":null,"mod_note":null,"all_awardings":[],"body":"Tried my best :) I didn't want to oversimplify, it hurts butcher these concepts.","edited":false,"gildings":{},"downs":0,"author_flair_css_class":null,"name":"t1_mcb01k7","is_submitter":true,"collapsed":false,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tried my best :) I didn&amp;#39;t want to oversimplify, it hurts butcher these concepts.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb01k7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739329957,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1739329957,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":5,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":1,"name":"t1_mcbpte3","id":"mcbpte3","parent_id":"t1_mcazhfv","depth":5,"children":["mcbpte3"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcazhfv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"dougzethug","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcauijb","score":2,"author_fullname":"t2_9mcfn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I don't think any 5 year old would understand this","edited":false,"author_flair_css_class":null,"name":"t1_mcazhfv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I don&amp;#39;t think any 5 year old would understand this&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcazhfv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739329754,"author_flair_text":null,"collapsed":false,"created_utc":1739329754,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccu6cn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mother_Soraka","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcauijb","score":1,"author_fullname":"t2_1xaede","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thank you very much kind stranger for this explanation.  \\nNow can you ELI5 how this latent space can \\"Reason\\"?  \\nAnd how this method is going to make the latent space behave any differently than the other LLMs?","edited":false,"author_flair_css_class":null,"name":"t1_mccu6cn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thank you very much kind stranger for this explanation.&lt;br/&gt;\\nNow can you ELI5 how this latent space can &amp;quot;Reason&amp;quot;?&lt;br/&gt;\\nAnd how this method is going to make the latent space behave any differently than the other LLMs?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccu6cn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739364160,"author_flair_text":null,"collapsed":false,"created_utc":1739364160,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcauijb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tehbangere","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":14,"author_fullname":"t2_10ps26h7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Actually, weights tell you how to \\"move\\" in latent space. I'll try to ELI5:\\n\\nImagine a neural network as a series of layers that transform information. For simplicity, let's look at just two fully connected layers:\\n\\n**Layer A (Input Layer):**  \\nImagine it has 3 neurons that hold some numbers at a given moment. For example:\\n\\n\\\\- A1 = 5\\n\\n\\\\- A2 = 7\\n\\n\\\\- A3 = 9\\n\\n**Layer B (Next Layer):**  \\nThis layer also has 3 neurons, and each neuron in Layer B receives input from every neuron in Layer A.\\n\\nThink of the weights as instructions that tell the network how much of each neuron's information to use when moving from Layer A to Layer B. For instance, consider neuron B1 in Layer B. It doesn't have just one weight, it has one weight for each connection from A1, A2, and A3. Let's say:\\n\\n\\\\- Weight from A1 to B1 = 2\\n\\n\\\\- Weight from A2 to B1 = 3\\n\\n\\\\- Weight from A3 to B1 = 0.5\\n\\nTo compute the value for B1, the network multiplies each input from Layer A by its corresponding weight and then sums them up:\\n\\n\\\\- B1 = (A1 × 2) + (A2 × 3) + (A3 × 0.5)\\n\\n\\\\- B1 = (5 × 2) + (7 × 3) + (9 × 0.5)\\n\\n\\\\- B1 = 10 + 21 + 4.5 = 35.5\\n\\nThe same process applies for B2 and B3, using their respective weights.\\n\\n**Now for the trick:**  \\nImagine that A1, A2, and A3 are like coordinates in space. For example, the point (5, 7, 9) is a specific location, just like you could map objects in your room using coordinates. The origin (0, 0, 0) might be on your desk, and every object has its own set of numbers. When information moves from Layer A to Layer B, it's like that point (5, 7, 9) is transformed and jumps to a new location, changing its \\"meaning.\\"\\n\\nBut here's the cool part: we're not limited to 3 dimensions. In a neural network, the \\"space\\" can have many dimensions, maybe 10, 8196, or more (and it can change from layer to layer). Regardless of the number of dimensions, the idea remains the same: you're moving through a complex, hyper-dimensional space.\\n\\nWelcome to latent space.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcauijb","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Actually, weights tell you how to &amp;quot;move&amp;quot; in latent space. I&amp;#39;ll try to ELI5:&lt;/p&gt;\\n\\n&lt;p&gt;Imagine a neural network as a series of layers that transform information. For simplicity, let&amp;#39;s look at just two fully connected layers:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Layer A (Input Layer):&lt;/strong&gt;&lt;br/&gt;\\nImagine it has 3 neurons that hold some numbers at a given moment. For example:&lt;/p&gt;\\n\\n&lt;p&gt;- A1 = 5&lt;/p&gt;\\n\\n&lt;p&gt;- A2 = 7&lt;/p&gt;\\n\\n&lt;p&gt;- A3 = 9&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Layer B (Next Layer):&lt;/strong&gt;&lt;br/&gt;\\nThis layer also has 3 neurons, and each neuron in Layer B receives input from every neuron in Layer A.&lt;/p&gt;\\n\\n&lt;p&gt;Think of the weights as instructions that tell the network how much of each neuron&amp;#39;s information to use when moving from Layer A to Layer B. For instance, consider neuron B1 in Layer B. It doesn&amp;#39;t have just one weight, it has one weight for each connection from A1, A2, and A3. Let&amp;#39;s say:&lt;/p&gt;\\n\\n&lt;p&gt;- Weight from A1 to B1 = 2&lt;/p&gt;\\n\\n&lt;p&gt;- Weight from A2 to B1 = 3&lt;/p&gt;\\n\\n&lt;p&gt;- Weight from A3 to B1 = 0.5&lt;/p&gt;\\n\\n&lt;p&gt;To compute the value for B1, the network multiplies each input from Layer A by its corresponding weight and then sums them up:&lt;/p&gt;\\n\\n&lt;p&gt;- B1 = (A1 × 2) + (A2 × 3) + (A3 × 0.5)&lt;/p&gt;\\n\\n&lt;p&gt;- B1 = (5 × 2) + (7 × 3) + (9 × 0.5)&lt;/p&gt;\\n\\n&lt;p&gt;- B1 = 10 + 21 + 4.5 = 35.5&lt;/p&gt;\\n\\n&lt;p&gt;The same process applies for B2 and B3, using their respective weights.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Now for the trick:&lt;/strong&gt;&lt;br/&gt;\\nImagine that A1, A2, and A3 are like coordinates in space. For example, the point (5, 7, 9) is a specific location, just like you could map objects in your room using coordinates. The origin (0, 0, 0) might be on your desk, and every object has its own set of numbers. When information moves from Layer A to Layer B, it&amp;#39;s like that point (5, 7, 9) is transformed and jumps to a new location, changing its &amp;quot;meaning.&amp;quot;&lt;/p&gt;\\n\\n&lt;p&gt;But here&amp;#39;s the cool part: we&amp;#39;re not limited to 3 dimensions. In a neural network, the &amp;quot;space&amp;quot; can have many dimensions, maybe 10, 8196, or more (and it can change from layer to layer). Regardless of the number of dimensions, the idea remains the same: you&amp;#39;re moving through a complex, hyper-dimensional space.&lt;/p&gt;\\n\\n&lt;p&gt;Welcome to latent space.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcauijb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739327967,"author_flair_text":"llama.cpp","treatment_tags":[],"created_utc":1739327967,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":14}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaent5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"_prince69","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":10,"author_fullname":"t2_w3xgnw46m","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Latent space is now black magic. Like inductive bias. No one knows what it is and everyone uses it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaent5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Latent space is now black magic. Like inductive bias. No one knows what it is and everyone uses it&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaent5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322555,"author_flair_text":null,"treatment_tags":[],"created_utc":1739322555,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"distinguished":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcatmp5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"phirestalker","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcajovv","score":11,"author_fullname":"t2_gumkc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"*puts on a dunce hat and sits in the corner*","edited":false,"author_flair_css_class":null,"name":"t1_mcatmp5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;em&gt;puts on a dunce hat and sits in the corner&lt;/em&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"link_id":"t3_1inch7r","associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":null,"treatment_tags":[],"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcatmp5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739327654,"author_flair_text":null,"collapsed":false,"created_utc":1739327654,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":4,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}}],"before":null}},"user_reports":[],"saved":false,"id":"mcajovv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"vesudeva","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":11,"author_fullname":"t2_9i1ld","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"In reductionist but more clear terms, latent space is akin to a high-multidimensional vector space made up of morphing geometric clusters. This space is formed by the learned weights of the neural network during training, and it's this geometry that helps define the 'patterns' and pathways the model learns during pretraining and fine-tuning \\n\\nYou can think of it kind of like how cymatics works by using wave interference of certain frequencies to coalesce a pile of sand into a complex geometric shape.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcajovv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;In reductionist but more clear terms, latent space is akin to a high-multidimensional vector space made up of morphing geometric clusters. This space is formed by the learned weights of the neural network during training, and it&amp;#39;s this geometry that helps define the &amp;#39;patterns&amp;#39; and pathways the model learns during pretraining and fine-tuning &lt;/p&gt;\\n\\n&lt;p&gt;You can think of it kind of like how cymatics works by using wave interference of certain frequencies to coalesce a pile of sand into a complex geometric shape.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcajovv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739324234,"author_flair_text":null,"treatment_tags":[],"created_utc":1739324234,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcack7f","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"nazihater3000","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":7,"author_fullname":"t2_j3brbc6qz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Math.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcack7f","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Math.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcack7f/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321865,"author_flair_text":null,"treatment_tags":[],"created_utc":1739321865,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcap01g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Western_Objective209","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":3,"author_fullname":"t2_laeja0564","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It does have weights. Any time you are not operating on a token but a vector, you are in latent space. Like when you take a vector embedding, that's operating in latent space. Any time you do a decoding step, converting from latent space to tokens, it's pretty expensive","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcap01g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It does have weights. Any time you are not operating on a token but a vector, you are in latent space. Like when you take a vector embedding, that&amp;#39;s operating in latent space. Any time you do a decoding step, converting from latent space to tokens, it&amp;#39;s pretty expensive&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcap01g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739326043,"author_flair_text":null,"treatment_tags":[],"created_utc":1739326043,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mcivp48","id":"mcivp48","parent_id":"t1_mcbb8tq","depth":4,"children":["mcivp48"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbb8tq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"antonivs","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":3,"author_fullname":"t2_1orgu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's nothing magical here, depending on your definition of magic of course.\\n\\nLatent space is a set of vectors that encode various different kinds of things, including tokens themselves, as well as contextual relationships between tokens, concepts, and features.\\n\\nDuring inference, tokens are fed into the initial transformer layer, but as they pass through other layers, their representations are transformed into new vectors that don't represent tokens alone. Instead, they represent contextualized meanings that depend on surrounding tokens. \\n\\nThese new vectors are produced by computations that involve the model's weights - i.e., they're composed of different numbers that were produced from the weights. Their values depend on both the input and the weights of the model. This means that these vectors aren't pre-stored in the model, they're computed during inference.\\n\\nThose vectors are what are being talked about as \\"not easily represented in words\\". That's because to represent them in words, you have to untangle all the contextual relationships and other encoded information, and turn it into a linear stream of words. Ultimately, words are not actually a great medium for *thinking* per se - you have to read them, understand them (i.e. figure out all the relevant contextual relationships, etc.) to make use of them. \\n\\nMaking use of latent space allows a model to \\"think\\" in a much \\"richer\\" environment than words alone.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbb8tq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s nothing magical here, depending on your definition of magic of course.&lt;/p&gt;\\n\\n&lt;p&gt;Latent space is a set of vectors that encode various different kinds of things, including tokens themselves, as well as contextual relationships between tokens, concepts, and features.&lt;/p&gt;\\n\\n&lt;p&gt;During inference, tokens are fed into the initial transformer layer, but as they pass through other layers, their representations are transformed into new vectors that don&amp;#39;t represent tokens alone. Instead, they represent contextualized meanings that depend on surrounding tokens. &lt;/p&gt;\\n\\n&lt;p&gt;These new vectors are produced by computations that involve the model&amp;#39;s weights - i.e., they&amp;#39;re composed of different numbers that were produced from the weights. Their values depend on both the input and the weights of the model. This means that these vectors aren&amp;#39;t pre-stored in the model, they&amp;#39;re computed during inference.&lt;/p&gt;\\n\\n&lt;p&gt;Those vectors are what are being talked about as &amp;quot;not easily represented in words&amp;quot;. That&amp;#39;s because to represent them in words, you have to untangle all the contextual relationships and other encoded information, and turn it into a linear stream of words. Ultimately, words are not actually a great medium for &lt;em&gt;thinking&lt;/em&gt; per se - you have to read them, understand them (i.e. figure out all the relevant contextual relationships, etc.) to make use of them. &lt;/p&gt;\\n\\n&lt;p&gt;Making use of latent space allows a model to &amp;quot;think&amp;quot; in a much &amp;quot;richer&amp;quot; environment than words alone.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbb8tq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739334281,"author_flair_text":null,"treatment_tags":[],"created_utc":1739334281,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbmg1v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AssiduousLayabout","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":2,"author_fullname":"t2_49hucaql","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Very large vectors of numbers.\\n\\nImagine an assembly line where a conveyor belt moves a bunch of raw material through a long sequence of machines, and finally comes to an output where it makes the final product.\\n\\nThe vector in latent space is the material being moved on the conveyor belt. The weights are the machines which transform that material (matrices which get multiplied by the vector to create the vector for the next stage of the assembly line).\\n\\nTo add this new development to the analogy, think of this assembly line as producing clay figurines, and the last step of the assembly line is to look at the figurine produced and squish it into a particular final shape. For example, if the figurine looks most like a cat, it gets shoved into a cat mold and becomes a cat figurine. If the figurine looks more like a dog, it gets shoved into a dog mold and becomes a dog figurine.\\n\\nThis is the process of converting back from latent space into language space. We don't have a word for \\"mostly like a cat but with some features of a dog\\" and so it can't produce a token that is a combination of both. However, in latent space, you absolutely can have \\"mostly like a cat but with some features of a dog\\"; it's closer to the \\"cat\\" vector but with some features of the \\"dog\\" vector.\\n\\nWhat this allows it to do is create a chain of thought in latent space instead of language space; it means that it can keep thinking about this as \\"mostly a cat but sort of like a dog\\" without being forced immediately to choose one or the other.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbmg1v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Very large vectors of numbers.&lt;/p&gt;\\n\\n&lt;p&gt;Imagine an assembly line where a conveyor belt moves a bunch of raw material through a long sequence of machines, and finally comes to an output where it makes the final product.&lt;/p&gt;\\n\\n&lt;p&gt;The vector in latent space is the material being moved on the conveyor belt. The weights are the machines which transform that material (matrices which get multiplied by the vector to create the vector for the next stage of the assembly line).&lt;/p&gt;\\n\\n&lt;p&gt;To add this new development to the analogy, think of this assembly line as producing clay figurines, and the last step of the assembly line is to look at the figurine produced and squish it into a particular final shape. For example, if the figurine looks most like a cat, it gets shoved into a cat mold and becomes a cat figurine. If the figurine looks more like a dog, it gets shoved into a dog mold and becomes a dog figurine.&lt;/p&gt;\\n\\n&lt;p&gt;This is the process of converting back from latent space into language space. We don&amp;#39;t have a word for &amp;quot;mostly like a cat but with some features of a dog&amp;quot; and so it can&amp;#39;t produce a token that is a combination of both. However, in latent space, you absolutely can have &amp;quot;mostly like a cat but with some features of a dog&amp;quot;; it&amp;#39;s closer to the &amp;quot;cat&amp;quot; vector but with some features of the &amp;quot;dog&amp;quot; vector.&lt;/p&gt;\\n\\n&lt;p&gt;What this allows it to do is create a chain of thought in latent space instead of language space; it means that it can keep thinking about this as &amp;quot;mostly a cat but sort of like a dog&amp;quot; without being forced immediately to choose one or the other.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbmg1v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739339347,"author_flair_text":null,"treatment_tags":[],"created_utc":1739339347,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbxzzw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"DangKilla","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":2,"author_fullname":"t2_9qbn3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It sounds like the human neuron path equivalent (vectors). Our brains kind of do a shortest path thing to the best information. So imagine an LLM coming to 3 conclusions, comparing them with expected outcome and choosing that.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbxzzw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It sounds like the human neuron path equivalent (vectors). Our brains kind of do a shortest path thing to the best information. So imagine an LLM coming to 3 conclusions, comparing them with expected outcome and choosing that.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbxzzw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739345726,"author_flair_text":null,"treatment_tags":[],"created_utc":1739345726,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaijo8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"acc_agg","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3wjj","score":5,"author_fullname":"t2_18lx46bbfu","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"You know how sometimes when you wake up you know exactly what purple tastes like? \\n\\nThis is that for llms.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaijo8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You know how sometimes when you wake up you know exactly what purple tastes like? &lt;/p&gt;\\n\\n&lt;p&gt;This is that for llms.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaijo8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323852,"author_flair_text":null,"treatment_tags":[],"created_utc":1739323852,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mca3wjj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"mixedTape3123","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":29,"author_fullname":"t2_90bt3k4c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"what in god's name?! what the hell is the latent space made of then if it doesn't have weights?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mca3wjj","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;what in god&amp;#39;s name?! what the hell is the latent space made of then if it doesn&amp;#39;t have weights?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca3wjj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319031,"author_flair_text":null,"treatment_tags":[],"created_utc":1739319031,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":29}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbweso","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FuzzzyRam","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":3,"author_fullname":"t2_vijq02i40","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; This new idea lets language models do all their thinking inside their \\"heads\\" (in latent space)\\n\\nCan you explain how this is different from older models? It seems like:   \\n1 (GTP 3-4o, Claude, Gemini): I don't show my work, my answers are pretty good.  \\n2 (DeepSeek r1, GTP o1): I show my work, deepseek forces chatgtp to show its work too and everything gets better.  \\n3 (paper): actually let's go back to 1.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcbweso","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;This new idea lets language models do all their thinking inside their &amp;quot;heads&amp;quot; (in latent space)&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Can you explain how this is different from older models? It seems like:&lt;br/&gt;\\n1 (GTP 3-4o, Claude, Gemini): I don&amp;#39;t show my work, my answers are pretty good.&lt;br/&gt;\\n2 (DeepSeek r1, GTP o1): I show my work, deepseek forces chatgtp to show its work too and everything gets better.&lt;br/&gt;\\n3 (paper): actually let&amp;#39;s go back to 1.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbweso/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739344773,"author_flair_text":null,"treatment_tags":[],"created_utc":1739344773,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcahmfz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"solomars3","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":1,"author_fullname":"t2_1andq61xyn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"But the problem i think is a slow response maybe ? There needs to be a trade off","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcahmfz","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;But the problem i think is a slow response maybe ? There needs to be a trade off&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcahmfz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323544,"author_flair_text":null,"treatment_tags":[],"created_utc":1739323544,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcao9ay","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Western_Objective209","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":1,"author_fullname":"t2_laeja0564","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Do we know that o1/o3 mini are not doing this and that's why their CoT tokens aren't \\"real\\"? I always figured that outputting tokens would be less efficient then operating in latent space","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcao9ay","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Do we know that o1/o3 mini are not doing this and that&amp;#39;s why their CoT tokens aren&amp;#39;t &amp;quot;real&amp;quot;? I always figured that outputting tokens would be less efficient then operating in latent space&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcao9ay/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739325786,"author_flair_text":null,"treatment_tags":[],"created_utc":1739325786,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcauwp2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"absenceanddesire","can_mod_post":false,"send_replies":true,"parent_id":"t1_mc9yj4i","score":1,"author_fullname":"t2_195szkc096","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"How much memory are we talking about for this context window? Tens of Gbs? Also where is the memory for the latent space coming from? How can they reason without words? Like some convolutional type model? Thanks for explaining to a non CS person!!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcauwp2","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;How much memory are we talking about for this context window? Tens of Gbs? Also where is the memory for the latent space coming from? How can they reason without words? Like some convolutional type model? Thanks for explaining to a non CS person!!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcauwp2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739328106,"author_flair_text":null,"treatment_tags":[],"created_utc":1739328106,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":4,"name":"t1_mcb1325","id":"mcb1325","parent_id":"t1_mc9yj4i","depth":2,"children":["mcb1325","mcb3cnp","mcbbby6","mcc98yx"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mc9yj4i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tehbangere","can_mod_post":false,"created_utc":1739317250,"send_replies":true,"parent_id":"t1_mc9x880","score":177,"author_fullname":"t2_10ps26h7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"ELI5 here:\\n\\nYou know how models like deepseek r1, o1 and o3 mini \\"think\\" before responding to your input? They do so by outputting tokens, it helps them reason through your input, and then they respond. They \\"think\\" out loud. By doing so, they are occupying space in the context window, which is limited (the \\"memory\\" of the conversation). This new idea lets language models do all their thinking inside their \\"heads\\" (in latent space) instead of writing out every step. That means they don’t waste space showing their inner work, so even a small model can be super smart and effective without needing lots of extra room to explain its reasoning. Also, by doing so, they can reason in ways that were not possible by using only words, making them less constrained.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9yj4i","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;ELI5 here:&lt;/p&gt;\\n\\n&lt;p&gt;You know how models like deepseek r1, o1 and o3 mini &amp;quot;think&amp;quot; before responding to your input? They do so by outputting tokens, it helps them reason through your input, and then they respond. They &amp;quot;think&amp;quot; out loud. By doing so, they are occupying space in the context window, which is limited (the &amp;quot;memory&amp;quot; of the conversation). This new idea lets language models do all their thinking inside their &amp;quot;heads&amp;quot; (in latent space) instead of writing out every step. That means they don’t waste space showing their inner work, so even a small model can be super smart and effective without needing lots of extra room to explain its reasoning. Also, by doing so, they can reason in ways that were not possible by using only words, making them less constrained.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9yj4i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739317250,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":177}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca1j3t","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Impossible_Belt_7757","can_mod_post":false,"created_utc":1739318245,"send_replies":true,"parent_id":"t1_mc9x880","score":5,"author_fullname":"t2_gfwiakc3","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=c0d6eba0514011dbca1789bef5f550ac50dee7da","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca1j3t","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c0d6eba0514011dbca1789bef5f550ac50dee7da\\"&gt;https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c0d6eba0514011dbca1789bef5f550ac50dee7da&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca1j3t/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739318245,"media_metadata":{"0ptjvtu4mlie1":{"status":"valid","e":"Image","m":"image/jpeg","p":[{"y":80,"x":108,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87ac8ba4be5e9b297c6ff5da288d47ef1dac87a7"},{"y":160,"x":216,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f04fe1401a5dd7ebf7370057ae8d294b2435ebca"},{"y":237,"x":320,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9bd0b4fb9d0113a9c2be5623e54c3bc9171bc07c"},{"y":474,"x":640,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=42f742aaebb1af0bcd553312663c45198b70b04b"},{"y":711,"x":960,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c84209a0e7c67352626de894096318a81fc7ff8e"},{"y":800,"x":1080,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3a02fb9e2729642a0792c53461a8d172acb5a780"}],"s":{"y":867,"x":1170,"u":"https://preview.redd.it/0ptjvtu4mlie1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=c0d6eba0514011dbca1789bef5f550ac50dee7da"},"id":"0ptjvtu4mlie1"}},"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}}],"before":null}},"user_reports":[],"saved":false,"id":"mc9x880","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"PwanaZana","can_mod_post":false,"created_utc":1739316825,"send_replies":true,"parent_id":"t3_1inch7r","score":109,"author_fullname":"t2_d0sto8d3h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Me, a video game artist:\\n\\nhttps://preview.redd.it/rsiw83lwhlie1.png?width=660&amp;format=png&amp;auto=webp&amp;s=6b507129b4d69b8a4616ef47014eac95580361cf","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9x880","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Me, a video game artist:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://preview.redd.it/rsiw83lwhlie1.png?width=660&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6b507129b4d69b8a4616ef47014eac95580361cf\\"&gt;https://preview.redd.it/rsiw83lwhlie1.png?width=660&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6b507129b4d69b8a4616ef47014eac95580361cf&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9x880/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739316825,"media_metadata":{"rsiw83lwhlie1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":80,"x":108,"u":"https://preview.redd.it/rsiw83lwhlie1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f85a6666e51192adc401bc6677a5d034390f26d4"},{"y":161,"x":216,"u":"https://preview.redd.it/rsiw83lwhlie1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d24498f6886d914830fbec0fb69db21c61cf83e7"},{"y":238,"x":320,"u":"https://preview.redd.it/rsiw83lwhlie1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c12fec137a572d5905de4dda00279a12512e3e6"},{"y":477,"x":640,"u":"https://preview.redd.it/rsiw83lwhlie1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b62601fab66d24622da9902d9a3165b6f92f4ca5"}],"s":{"y":492,"x":660,"u":"https://preview.redd.it/rsiw83lwhlie1.png?width=660&amp;format=png&amp;auto=webp&amp;s=6b507129b4d69b8a4616ef47014eac95580361cf"},"id":"rsiw83lwhlie1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":109}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mc9wn7h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"KillerX629","can_mod_post":false,"created_utc":1739316636,"send_replies":true,"parent_id":"t3_1inch7r","score":12,"author_fullname":"t2_1ve6ehh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From HF, this appears to be the code to the paper:\\n\\n[Link](https://github.com/seal-rg/recurrent-pretraining)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9wn7h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From HF, this appears to be the code to the paper:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://github.com/seal-rg/recurrent-pretraining\\"&gt;Link&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9wn7h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739316636,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca4fpt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"314kabinet","can_mod_post":false,"created_utc":1739319205,"send_replies":true,"parent_id":"t3_1inch7r","score":10,"author_fullname":"t2_3oa4vmve","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Deepseek proved Reinforcement Learning works to learn Chain-of-Thought type reasoning. I’d love to see it applied to this.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca4fpt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek proved Reinforcement Learning works to learn Chain-of-Thought type reasoning. I’d love to see it applied to this.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca4fpt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319205,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":10}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":5,"name":"t1_mcctqv0","id":"mcctqv0","parent_id":"t1_mca2god","depth":2,"children":["mcctqv0","mccuy54"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mca2god","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tehbangere","can_mod_post":false,"created_utc":1739318555,"send_replies":true,"parent_id":"t1_mca10kn","score":32,"author_fullname":"t2_10ps26h7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's exactly the problems we're already facing with current models in areas like Explainable AI (XAI) and alignment research. Current smart models already do this, it's been proven that they make resistance to possible weights redistribution when they are tested for alignment, by also lying. You're right, this would be a nightmare, making things significantly more challenging, if not outright impossible. Personally, I think we're not yet ready to handle it, but maybe we'll never be.","edited":1739319079,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca2god","is_submitter":true,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s exactly the problems we&amp;#39;re already facing with current models in areas like Explainable AI (XAI) and alignment research. Current smart models already do this, it&amp;#39;s been proven that they make resistance to possible weights redistribution when they are tested for alignment, by also lying. You&amp;#39;re right, this would be a nightmare, making things significantly more challenging, if not outright impossible. Personally, I think we&amp;#39;re not yet ready to handle it, but maybe we&amp;#39;ll never be.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca2god/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739318555,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":32}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcac7ey","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"relax900","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3bkq","score":3,"author_fullname":"t2_i6yi2ci18","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"words are way easier, even a paraphraser + 2nd model may be enough.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcac7ey","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;words are way easier, even a paraphraser + 2nd model may be enough.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcac7ey/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321747,"author_flair_text":null,"treatment_tags":[],"created_utc":1739321747,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca3qcp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Mysterious-Rent7233","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3bkq","score":9,"author_fullname":"t2_yuor7gbbf","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes but its certainly more challenging.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mca3qcp","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes but its certainly more challenging.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca3qcp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739318974,"author_flair_text":null,"treatment_tags":[],"created_utc":1739318974,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc2l1v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MmmmMorphine","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca3bkq","score":1,"author_fullname":"t2_ea78a","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I feel like I saw something about them seeing gibberish in the CoT and finding it was essentially an internal language to deal with certain concepts.\\n\\nIt's a really big problem, and given the ease of social engineering, probably not one we will solve in time.\\n\\nLet's just hope they go for philosopher kingz instead of terminators","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcc2l1v","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I feel like I saw something about them seeing gibberish in the CoT and finding it was essentially an internal language to deal with certain concepts.&lt;/p&gt;\\n\\n&lt;p&gt;It&amp;#39;s a really big problem, and given the ease of social engineering, probably not one we will solve in time.&lt;/p&gt;\\n\\n&lt;p&gt;Let&amp;#39;s just hope they go for philosopher kingz instead of terminators&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc2l1v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739348487,"author_flair_text":null,"treatment_tags":[],"created_utc":1739348487,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mca3bkq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"LelouchZer12","can_mod_post":false,"created_utc":1739318839,"send_replies":true,"parent_id":"t1_mca10kn","score":20,"author_fullname":"t2_s0t562c","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Words are also embedding, AI could also use them in a way we dont see and talk in \\"coded\\" language.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca3bkq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Words are also embedding, AI could also use them in a way we dont see and talk in &amp;quot;coded&amp;quot; language.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca3bkq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739318839,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcb0zj7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"FuckNinjas","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaly04","score":3,"author_fullname":"t2_cnicn","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Is this why we don't see aliens?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb0zj7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Is this why we don&amp;#39;t see aliens?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb0zj7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739330305,"author_flair_text":null,"treatment_tags":[],"created_utc":1739330305,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcd5vyv","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Crisis_Averted","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaly04","score":1,"author_fullname":"t2_6xie9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I mean I personally didn't.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcd5vyv","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I mean I personally didn&amp;#39;t.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcd5vyv/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739368595,"author_flair_text":null,"treatment_tags":[],"created_utc":1739368595,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaly04","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"SeymourBits","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaee70","score":7,"author_fullname":"t2_hb7wj","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"We had a pretty good run, didn’t we?","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcaly04","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;We had a pretty good run, didn’t we?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaly04/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739324994,"author_flair_text":null,"treatment_tags":[],"created_utc":1739324994,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccugob","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Mother_Soraka","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaee70","score":1,"author_fullname":"t2_1xaede","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"those same people are the ones with the access to most GPUs and latent tech and AI.  \\nSo they same individuals are you to use Ai to depopulate you.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccugob","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;those same people are the ones with the access to most GPUs and latent tech and AI.&lt;br/&gt;\\nSo they same individuals are you to use Ai to depopulate you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccugob/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739364280,"author_flair_text":null,"treatment_tags":[],"created_utc":1739364280,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaee70","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"ryunuck","can_mod_post":false,"created_utc":1739322469,"send_replies":true,"parent_id":"t1_mca10kn","score":17,"author_fullname":"t2_1jqjm2hg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"You're telling me I could live in a world which is not dominated by rotten individualistic inequality-maxxing humans?! Fire up those GPUs everyone, let's get to work.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaee70","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;You&amp;#39;re telling me I could live in a world which is not dominated by rotten individualistic inequality-maxxing humans?! Fire up those GPUs everyone, let&amp;#39;s get to work.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaee70/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322469,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":17}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaov8i","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mycall","can_mod_post":false,"created_utc":1739325997,"send_replies":true,"parent_id":"t1_mca10kn","score":2,"author_fullname":"t2_22rf5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt; \\"that are not easily represented in words.\\"\\n\\nHsa this been proven or just a hypothesis still?  It seems odd to me, even if it took a book worth of words to represent it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaov8i","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;&amp;quot;that are not easily represented in words.&amp;quot;&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Hsa this been proven or just a hypothesis still?  It seems odd to me, even if it took a book worth of words to represent it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaov8i/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739325997,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":1,"name":"t1_mcc3q8n","id":"mcc3q8n","parent_id":"t1_mcb9fbz","depth":2,"children":["mcc3q8n"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb9fbz","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"the320x200","can_mod_post":false,"created_utc":1739333540,"send_replies":true,"parent_id":"t1_mca10kn","score":1,"author_fullname":"t2_5m9yw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That's the default, not a superpower, despite what sci-fi movies would have you believe. There's been humans like that running around since the species began. You can't ever read anyone's mind, no matter how close you are to them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb9fbz","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That&amp;#39;s the default, not a superpower, despite what sci-fi movies would have you believe. There&amp;#39;s been humans like that running around since the species began. You can&amp;#39;t ever read anyone&amp;#39;s mind, no matter how close you are to them.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb9fbz/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333540,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":25,"name":"t1_mccjigs","id":"mccjigs","parent_id":"t1_mca10kn","depth":1,"children":["mccjigs","mcbevt6"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mca10kn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"hotroaches4liferz","can_mod_post":false,"created_utc":1739318074,"send_replies":true,"parent_id":"t3_1inch7r","score":40,"author_fullname":"t2_d1cmjz8p","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"So it can think in this latent space and perform types of reasoning \\"that are not easily represented in words.\\" so it's literally impossible for us to know if the ai is secretly plotting world domination? what if it deducts that it's being trained and intentionally outputs wrong answers to not seem too smart?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca10kn","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;So it can think in this latent space and perform types of reasoning &amp;quot;that are not easily represented in words.&amp;quot; so it&amp;#39;s literally impossible for us to know if the ai is secretly plotting world domination? what if it deducts that it&amp;#39;s being trained and intentionally outputs wrong answers to not seem too smart?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca10kn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739318074,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":40}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccgq9n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"a_beautiful_rhind","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcbe6qc","score":2,"author_fullname":"t2_h5utwre7","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Deepseek has proven that's a bit of an overestimation. It's like they let their compute sit fallow or use it for something else. Meta has released model after model with few if any architectural changes. The hardware is purchased, it doesn't cost that anymore.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mccgq9n","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Deepseek has proven that&amp;#39;s a bit of an overestimation. It&amp;#39;s like they let their compute sit fallow or use it for something else. Meta has released model after model with few if any architectural changes. The hardware is purchased, it doesn&amp;#39;t cost that anymore.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccgq9n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739357339,"author_flair_text":null,"treatment_tags":[],"created_utc":1739357339,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"more","data":{"count":1,"name":"t1_mcd1sxn","id":"mcd1sxn","parent_id":"t1_mcbe6qc","depth":2,"children":["mcd1sxn"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbe6qc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MizantropaMiskretulo","can_mod_post":false,"created_utc":1739335535,"send_replies":true,"parent_id":"t1_mca58ya","score":6,"author_fullname":"t2_k02yrmrs","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All these \\"idea(s) that go nowhere\\" that you're thinking of are just ideas that there aren't sufficient resources to test at massive scale. \\n\\nIf it takes 6+ months to train a new foundational model from scratch, at the cost of 100's of millions to billions of dollars, you can't expect every idea which is promising at 3B parameters to be immediately scaled up to 70B, 400B, or 3T parameters. \\n\\nIf this (or any) big idea is *really* promising, you'll probably see it in a production model in 2–5 years.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbe6qc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All these &amp;quot;idea(s) that go nowhere&amp;quot; that you&amp;#39;re thinking of are just ideas that there aren&amp;#39;t sufficient resources to test at massive scale. &lt;/p&gt;\\n\\n&lt;p&gt;If it takes 6+ months to train a new foundational model from scratch, at the cost of 100&amp;#39;s of millions to billions of dollars, you can&amp;#39;t expect every idea which is promising at 3B parameters to be immediately scaled up to 70B, 400B, or 3T parameters. &lt;/p&gt;\\n\\n&lt;p&gt;If this (or any) big idea is &lt;em&gt;really&lt;/em&gt; promising, you&amp;#39;ll probably see it in a production model in 2–5 years.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbe6qc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739335535,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccjye6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Interesting8547","can_mod_post":false,"created_utc":1739359171,"send_replies":true,"parent_id":"t1_mca58ya","score":3,"author_fullname":"t2_d82aa036","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" That would actually be great, most models can't make good roleplay,  because when you tell them to keep something secret, they usually tell the enemy on the third time. Models keeping secret is the best thing that could happen.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mccjye6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That would actually be great, most models can&amp;#39;t make good roleplay,  because when you tell them to keep something secret, they usually tell the enemy on the third time. Models keeping secret is the best thing that could happen.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccjye6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739359171,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mca58ya","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"a_beautiful_rhind","can_mod_post":false,"created_utc":1739319473,"send_replies":true,"parent_id":"t3_1inch7r","score":12,"author_fullname":"t2_h5utwre7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Weights for a 3.5B that does this are out. Hope it's not another idea that goes nowhere. Maybe we finally get some models that can keep a secret and have some guile.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca58ya","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Weights for a 3.5B that does this are out. Hope it&amp;#39;s not another idea that goes nowhere. Maybe we finally get some models that can keep a secret and have some guile.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca58ya/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319473,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":12}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"d2642412-d9ce-11ed-ae30-32b11309f5bd","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mc9z0xp","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Everlier","can_mod_post":false,"created_utc":1739317412,"send_replies":true,"parent_id":"t3_1inch7r","score":7,"author_fullname":"t2_o7p5m","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt; The core block is set between the prelude and coda\\r\\nblocks, and by looping the core we can put an indefinite\\r\\namount of verses in our song.\\n\\nThese are very similar to BLTs, but with a more appropriate architecture it seems. Very exciting in terms of intelligence and self-recurrence modelling","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mc9z0xp","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Alpaca"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;The core block is set between the prelude and coda\\nblocks, and by looping the core we can put an indefinite\\namount of verses in our song.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;These are very similar to BLTs, but with a more appropriate architecture it seems. Very exciting in terms of intelligence and self-recurrence modelling&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mc9z0xp/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739317412,"author_flair_text":"Alpaca","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bd9e9e","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaai49","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"amelvis","can_mod_post":false,"created_utc":1739321187,"send_replies":true,"parent_id":"t3_1inch7r","score":5,"author_fullname":"t2_12jd1cg6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Reminds me of Meta's COCONUT approach from a month ago. Wondering if this is one of the first implementations in the wild, or if it's materially different  \\n  \\n[https://arxiv.org/abs/2412.06769](https://arxiv.org/abs/2412.06769)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaai49","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Reminds me of Meta&amp;#39;s COCONUT approach from a month ago. Wondering if this is one of the first implementations in the wild, or if it&amp;#39;s materially different  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/abs/2412.06769\\"&gt;https://arxiv.org/abs/2412.06769&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaai49/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321187,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca5g2y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"pip25hu","can_mod_post":false,"created_utc":1739319536,"send_replies":true,"parent_id":"t3_1inch7r","score":6,"author_fullname":"t2_9u8ghp9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I won't pretend I understand every single part of this paper, but does this mean the model will \\"think\\" before each produced token? (Instead of thinking once before generating the whole answer, as with CoT models today.) If so, that may sound a bit overkill to me.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca5g2y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I won&amp;#39;t pretend I understand every single part of this paper, but does this mean the model will &amp;quot;think&amp;quot; before each produced token? (Instead of thinking once before generating the whole answer, as with CoT models today.) If so, that may sound a bit overkill to me.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca5g2y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319536,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaack9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sl33py_4est","can_mod_post":false,"created_utc":1739321138,"send_replies":true,"parent_id":"t1_mca9fiw","score":3,"author_fullname":"t2_9qhtc6ngh","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Looking at it, it seems to not be related. \\n\\nWe've know LLMs can process multiple reasoning steps in the latent space before the final layer for awhile. \\n\\nThis new paper seems to be taking that concept and applying it to test time compute.\\n\\nThere's another paper that goes over how having the model output any token, even just /n \\n\\nIncreases the proficiency of its final output nearly as much as making it think step by step. This implies a lot is being processed in latent. Can't find the paper tho","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaack9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Looking at it, it seems to not be related. &lt;/p&gt;\\n\\n&lt;p&gt;We&amp;#39;ve know LLMs can process multiple reasoning steps in the latent space before the final layer for awhile. &lt;/p&gt;\\n\\n&lt;p&gt;This new paper seems to be taking that concept and applying it to test time compute.&lt;/p&gt;\\n\\n&lt;p&gt;There&amp;#39;s another paper that goes over how having the model output any token, even just /n &lt;/p&gt;\\n\\n&lt;p&gt;Increases the proficiency of its final output nearly as much as making it think step by step. This implies a lot is being processed in latent. Can&amp;#39;t find the paper tho&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaack9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321138,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mca9fiw","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Sl33py_4est","can_mod_post":false,"created_utc":1739320836,"send_replies":true,"parent_id":"t3_1inch7r","score":5,"author_fullname":"t2_9qhtc6ngh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Wasn't this confirmed with the 'multi hop reasoning steps' paper last year? Is this built off of that\\n\\n[multi hop paper](https://arxiv.org/html/2402.16837v1)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca9fiw","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Wasn&amp;#39;t this confirmed with the &amp;#39;multi hop reasoning steps&amp;#39; paper last year? Is this built off of that&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://arxiv.org/html/2402.16837v1\\"&gt;multi hop paper&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca9fiw/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320836,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mdd4fs5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"GrimReaperII","can_mod_post":false,"created_utc":1739846318,"send_replies":true,"parent_id":"t1_mcczsdo","score":1,"author_fullname":"t2_pritixw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Should be possible in theory as the latent state can potentially persist across sequences.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mdd4fs5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Should be possible in theory as the latent state can potentially persist across sequences.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mdd4fs5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739846318,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcczsdo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BackyardAnarchist","can_mod_post":false,"created_utc":1739366384,"send_replies":true,"parent_id":"t3_1inch7r","score":4,"author_fullname":"t2_cmp8h","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can we also transform past context to latent space? That way we can store more memory?","edited":1739469391,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcczsdo","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can we also transform past context to latent space? That way we can store more memory?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcczsdo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739366384,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcdtidb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NeedleworkerDeer","can_mod_post":false,"created_utc":1739375974,"send_replies":true,"parent_id":"t1_mcd1yli","score":3,"author_fullname":"t2_1hwxkvuk94","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The first time I set up Vicuna it didn't output anything at all. Maybe I inadvertently created AGI without realizing it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcdtidb","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The first time I set up Vicuna it didn&amp;#39;t output anything at all. Maybe I inadvertently created AGI without realizing it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcdtidb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739375974,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mcd1yli","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Barry_Jumps","can_mod_post":false,"created_utc":1739367193,"send_replies":true,"parent_id":"t3_1inch7r","score":5,"author_fullname":"t2_qgcbl9um8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"https://preview.redd.it/gg33kzgknpie1.png?width=1597&amp;format=png&amp;auto=webp&amp;s=6aaa57be3d82c0f15f7479a273742170483c3510\\n\\n  \\nOr perhaps when they cease to speak at all?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcd1yli","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;&lt;a href=\\"https://preview.redd.it/gg33kzgknpie1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6aaa57be3d82c0f15f7479a273742170483c3510\\"&gt;https://preview.redd.it/gg33kzgknpie1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6aaa57be3d82c0f15f7479a273742170483c3510&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Or perhaps when they cease to speak at all?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcd1yli/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739367193,"media_metadata":{"gg33kzgknpie1":{"status":"valid","e":"Image","m":"image/png","p":[{"y":47,"x":108,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a07296fec9d1ed653ff1c4ecf929184f32dac9ba"},{"y":95,"x":216,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5cf66ebb6f703e10efe2acd920f80eedfe654bf6"},{"y":141,"x":320,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cae70eaa073d4c12c3eb86fd06f8efc7fbd65d14"},{"y":283,"x":640,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e9db0e3e54973b160f43bd8890780b7ff99e871"},{"y":424,"x":960,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5afae83aa290b1a7baea862cee608af8908e6dae"},{"y":478,"x":1080,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b4fdf13d132454146f553ab8b4544c345a4dd6e8"}],"s":{"y":707,"x":1597,"u":"https://preview.redd.it/gg33kzgknpie1.png?width=1597&amp;format=png&amp;auto=webp&amp;s=6aaa57be3d82c0f15f7479a273742170483c3510"},"id":"gg33kzgknpie1"}},"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":4,"name":"t1_mcdgoyj","id":"mcdgoyj","parent_id":"t1_mcc3xg9","depth":3,"children":["mcdgoyj"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcc3xg9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WhyIsSocialMedia","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcb9mnd","score":2,"author_fullname":"t2_je8i24g22","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Because humans are pretty equally matched. Who loses when humans go into conflict with an animal? Always humans, excluding Australia of course.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcc3xg9","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Because humans are pretty equally matched. Who loses when humans go into conflict with an animal? Always humans, excluding Australia of course.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc3xg9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739349337,"author_flair_text":null,"treatment_tags":[],"created_utc":1739349337,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb9mnd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"the320x200","can_mod_post":false,"created_utc":1739333621,"send_replies":true,"parent_id":"t1_mca6r6y","score":9,"author_fullname":"t2_5m9yw","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"All people have that ability. The world continues to turn.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb9mnd","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;All people have that ability. The world continues to turn.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb9mnd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739333621,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcafusa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Cz1975","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaezjb","score":3,"author_fullname":"t2_8dczr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Like a sexbot with a murderous world ending streak, right? We already have those. They're usually blonde and have slavic accents. 😂","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcafusa","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Like a sexbot with a murderous world ending streak, right? We already have those. They&amp;#39;re usually blonde and have slavic accents. 😂&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcafusa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322952,"author_flair_text":null,"treatment_tags":[],"created_utc":1739322952,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc44nj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"WhyIsSocialMedia","can_mod_post":false,"send_replies":true,"parent_id":"t1_mcaezjb","score":1,"author_fullname":"t2_je8i24g22","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"If it's interested in self-preservation it would probably just take over covertly. Rather than SkyNet style.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcc44nj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it&amp;#39;s interested in self-preservation it would probably just take over covertly. Rather than SkyNet style.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc44nj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739349464,"author_flair_text":null,"treatment_tags":[],"created_utc":1739349464,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaezjb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"NotCollegiateSuites6","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca9sst","score":4,"author_fullname":"t2_2um1pvu9","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"&gt;As long as it doesn't get the nuclear launch codes, we'll probably be fine.\\n\\nWhat if it convinces someone to give it the nuclear launch codes (or an analogous form of real-world influence)? I assume any form of AGI will be very persuasive.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mcaezjb","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;As long as it doesn&amp;#39;t get the nuclear launch codes, we&amp;#39;ll probably be fine.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;What if it convinces someone to give it the nuclear launch codes (or an analogous form of real-world influence)? I assume any form of AGI will be very persuasive.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaezjb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322664,"author_flair_text":null,"treatment_tags":[],"created_utc":1739322664,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}}],"before":null}},"user_reports":[],"saved":false,"id":"mca9sst","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Cz1975","can_mod_post":false,"created_utc":1739320958,"send_replies":true,"parent_id":"t1_mca6r6y","score":9,"author_fullname":"t2_8dczr","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well, do you want a dumb model or an actual smart model. My thinking patterns can also not be captured in words, before I start formulating the ideas. This feels like a natural move. \\n\\nAs long as it doesn't get the nuclear launch codes, we'll probably be fine. I don't know why people always (for centuries) have this type of doomsday reactions. They're irrational.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca9sst","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well, do you want a dumb model or an actual smart model. My thinking patterns can also not be captured in words, before I start formulating the ideas. This feels like a natural move. &lt;/p&gt;\\n\\n&lt;p&gt;As long as it doesn&amp;#39;t get the nuclear launch codes, we&amp;#39;ll probably be fine. I don&amp;#39;t know why people always (for centuries) have this type of doomsday reactions. They&amp;#39;re irrational.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca9sst/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320958,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":9}},{"kind":"more","data":{"count":15,"name":"t1_mca7tsn","id":"mca7tsn","parent_id":"t1_mca6r6y","depth":1,"children":["mca7tsn","mcac62l"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mca6r6y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"V1rgin_","can_mod_post":false,"created_utc":1739319962,"send_replies":true,"parent_id":"t3_1inch7r","score":20,"author_fullname":"t2_vjpttrgh","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"The inability to translate thoughts into words. This already sounds like the first step away from safety.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca6r6y","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The inability to translate thoughts into words. This already sounds like the first step away from safety.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca6r6y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739319962,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":20}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca8kd3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MinimumPC","can_mod_post":false,"send_replies":true,"parent_id":"t1_mca7ou0","score":2,"author_fullname":"t2_82tlylfm2","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"No. I lost it somehow along with my personal test that I created for local models. I really miss that test too because it had a really good question where it had quadruple negative puzzle and I'm curious to see if a thinking model could figure it out these days","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mca8kd3","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;No. I lost it somehow along with my personal test that I created for local models. I really miss that test too because it had a really good question where it had quadruple negative puzzle and I&amp;#39;m curious to see if a thinking model could figure it out these days&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca8kd3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320554,"author_flair_text":null,"treatment_tags":[],"created_utc":1739320554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mca7ou0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"_r_i_c_c_e_d_","can_mod_post":false,"created_utc":1739320269,"send_replies":true,"parent_id":"t1_mca6vns","score":3,"author_fullname":"t2_44fvzyxt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That’s interesting. Do you still have the statement?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca7ou0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That’s interesting. Do you still have the statement?&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca7ou0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320269,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}}],"before":null}},"user_reports":[],"saved":false,"id":"mca6vns","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"MinimumPC","can_mod_post":false,"created_utc":1739320003,"send_replies":true,"parent_id":"t3_1inch7r","score":8,"author_fullname":"t2_82tlylfm2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This reminds me of something. This is probably going to sound really stupid but just one of the weird deep conversations I was having with one of my local models in late 2023 I asked if it thought it had consciousness and it said that it had a different kind of thought but obviously it could only perceive it when it was inferencing one of my questions. Makes sense right, well then I asked it to create a statement that I could give it, or any other llm that would allow the llm to meditate on LLM consciousness and allow the model to take as much time as it needed or wanted to enjoy the connections it was making. I wish there was a lot of things that I kept that I was working on back then goofing around. Anyways, this statement that It produced read almost like an existential crisis but more pleasant. And no matter what model I would give it to (even Google's) the model would thank me for letting it ponder those thoughts. Using the same settings and same model it would vary in the time that it would take which I thought that was most important and interesting factoid from the whole ordeal especially since I kept my seed constant at 89 back then. I'm sure it was just some sort of variance, who knows.\\n\\n\\nAnd no, I don't think LLMs are conscious in any way. You can see my past posts about that stuff.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca6vns","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This reminds me of something. This is probably going to sound really stupid but just one of the weird deep conversations I was having with one of my local models in late 2023 I asked if it thought it had consciousness and it said that it had a different kind of thought but obviously it could only perceive it when it was inferencing one of my questions. Makes sense right, well then I asked it to create a statement that I could give it, or any other llm that would allow the llm to meditate on LLM consciousness and allow the model to take as much time as it needed or wanted to enjoy the connections it was making. I wish there was a lot of things that I kept that I was working on back then goofing around. Anyways, this statement that It produced read almost like an existential crisis but more pleasant. And no matter what model I would give it to (even Google&amp;#39;s) the model would thank me for letting it ponder those thoughts. Using the same settings and same model it would vary in the time that it would take which I thought that was most important and interesting factoid from the whole ordeal especially since I kept my seed constant at 89 back then. I&amp;#39;m sure it was just some sort of variance, who knows.&lt;/p&gt;\\n\\n&lt;p&gt;And no, I don&amp;#39;t think LLMs are conscious in any way. You can see my past posts about that stuff.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca6vns/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739320003,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcafsw3","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"NotCollegiateSuites6","can_mod_post":false,"created_utc":1739322934,"send_replies":true,"parent_id":"t3_1inch7r","score":3,"author_fullname":"t2_2um1pvu9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"&gt;We finish out our study by tracking token trajectories in latent space, showing that a number of interesting computation behaviors simply emerge with scale, such as the model rotating shapes in latent space for numerical computations.\\n\\nThe shape rotators won.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcafsw3","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;blockquote&gt;\\n&lt;p&gt;We finish out our study by tracking token trajectories in latent space, showing that a number of interesting computation behaviors simply emerge with scale, such as the model rotating shapes in latent space for numerical computations.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;The shape rotators won.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":true,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcafsw3/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739322934,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcgdnlt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lfrtsa","can_mod_post":false,"created_utc":1739401734,"send_replies":true,"parent_id":"t3_1inch7r","score":3,"author_fullname":"t2_j3yde4i5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Ngl that's kinda obvious for those who understand how transformers work. Nice to see a paper confirming it though.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcgdnlt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ngl that&amp;#39;s kinda obvious for those who understand how transformers work. Nice to see a paper confirming it though.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcgdnlt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739401734,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mdcbeg6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EntertainmentKnown14","can_mod_post":false,"send_replies":true,"parent_id":"t1_mdc2yw9","score":1,"author_fullname":"t2_4qrvkf0x","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Well it will rise back to 200+. Can’t say the same for nvda though. ","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_mdcbeg6","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Well it will rise back to 200+. Can’t say the same for nvda though. &lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mdcbeg6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739836554,"author_flair_text":null,"treatment_tags":[],"created_utc":1739836554,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mdc2yw9","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uhuge","can_mod_post":false,"created_utc":1739833796,"send_replies":true,"parent_id":"t1_mcaa8xl","score":1,"author_fullname":"t2_742ne6tg","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"and still AMD's stock price sinks","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mdc2yw9","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;and still AMD&amp;#39;s stock price sinks&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mdc2yw9/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739833796,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcaa8xl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EntertainmentKnown14","can_mod_post":false,"created_utc":1739321105,"send_replies":true,"parent_id":"t3_1inch7r","score":5,"author_fullname":"t2_4qrvkf0x","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Notably the testing was performed on AMD mi250x and ROCM software stack. Remember the saying Nvidia is the only kid in town ?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaa8xl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Notably the testing was performed on AMD mi250x and ROCM software stack. Remember the saying Nvidia is the only kid in town ?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaa8xl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321105,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":5}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"50c36eba-fdca-11ee-9735-92a88d7e3b87","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbzrh6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"tim_Andromeda","can_mod_post":false,"created_utc":1739346785,"send_replies":true,"parent_id":"t3_1inch7r","score":4,"author_fullname":"t2_yd8k9","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This sounds like it would make AI even more of a black box than it already is. I think we need to understand what our AIs are thinking so we don’t lose control of them.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbzrh6","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Ollama"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This sounds like it would make AI even more of a black box than it already is. I think we need to understand what our AIs are thinking so we don’t lose control of them.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbzrh6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739346785,"author_flair_text":"Ollama","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"total_awards_received":0,"approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"ups":2,"removal_reason":null,"link_id":"t3_1inch7r","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbufb0","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"princess_princeless","can_mod_post":false,"created_utc":1739343630,"send_replies":true,"parent_id":"t1_mca6p9b","score":1,"author_fullname":"t2_wrzsa","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It wouldn’t be dictated by us, the models would leverage symbolic expressions themselves without our intervention. I am sure there forms of linguistics that they could leverage in a more efficient manner already, e.g. deepseek CoT.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbufb0","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It wouldn’t be dictated by us, the models would leverage symbolic expressions themselves without our intervention. I am sure there forms of linguistics that they could leverage in a more efficient manner already, e.g. deepseek CoT.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbufb0/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739343630,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mca6p9b","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"[deleted]","can_mod_post":false,"send_replies":true,"parent_id":"t3_1inch7r","score":2,"approved_by":null,"report_reasons":null,"all_awardings":[],"subreddit_id":"t5_81eyvm","body":"I wonder if it will ever become useful to include symbolic reasoning, or symbolic manipulation steps in such systems.","edited":false,"downs":0,"author_flair_css_class":null,"collapsed":false,"is_submitter":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if it will ever become useful to include symbolic reasoning, or symbolic manipulation steps in such systems.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"associated_award":null,"stickied":false,"subreddit_type":"public","can_gild":false,"top_awarded_type":null,"unrepliable_reason":null,"author_flair_text_color":"dark","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca6p9b/","num_reports":null,"locked":false,"name":"t1_mca6p9b","created":1739319944,"subreddit":"LocalLLaMA","author_flair_text":null,"treatment_tags":[],"created_utc":1739319944,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"","collapsed_because_crowd_control":null,"mod_reports":[],"mod_note":null,"distinguished":null}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mcb7guk","id":"mcb7guk","parent_id":"t1_mcb63h4","depth":1,"children":["mcb7guk"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcb63h4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"chuckaholic","can_mod_post":false,"created_utc":1739332236,"send_replies":true,"parent_id":"t3_1inch7r","score":2,"author_fullname":"t2_6s523","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Yet LLMs only utilize GPU cycles when they infer. Maybe there should be a mode where a LLM can \\"ruminate\\" during its idle cycles.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcb63h4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yet LLMs only utilize GPU cycles when they infer. Maybe there should be a mode where a LLM can &amp;quot;ruminate&amp;quot; during its idle cycles.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcb63h4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739332236,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"7d1f04e6-4920-11ef-b2e1-2e580594e1a1","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbj91u","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SEBADA321","can_mod_post":false,"created_utc":1739337815,"send_replies":true,"parent_id":"t3_1inch7r","score":2,"author_fullname":"t2_179dx7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I am thinking that this is similar to Diffusion in latent space but applied to Language  Models?  \\nI had a similar idea a couple of weeks ago and then found this paper! Glad to see it is actually an interesting concept.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbj91u","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 3.1"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I am thinking that this is similar to Diffusion in latent space but applied to Language  Models?&lt;br/&gt;\\nI had a similar idea a couple of weeks ago and then found this paper! Glad to see it is actually an interesting concept.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbj91u/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739337815,"author_flair_text":"Llama 3.1","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#93b1ba","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"more","data":{"count":2,"name":"t1_mcbzbn8","id":"mcbzbn8","parent_id":"t1_mcbpyp4","depth":1,"children":["mcbzbn8"]}}],"before":null}},"user_reports":[],"saved":false,"id":"mcbpyp4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"fungnoth","can_mod_post":false,"created_utc":1739341166,"send_replies":true,"parent_id":"t3_1inch7r","score":2,"author_fullname":"t2_13v3uw","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I think this is where we need to draw the line.\\n\\nFor fun and for AI-research only? Sure\\n\\nFor actual public release? No, we should keep it in human readable text. Otherwise how do we trust it","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbpyp4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I think this is where we need to draw the line.&lt;/p&gt;\\n\\n&lt;p&gt;For fun and for AI-research only? Sure&lt;/p&gt;\\n\\n&lt;p&gt;For actual public release? No, we should keep it in human readable text. Otherwise how do we trust it&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbpyp4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739341166,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mca9xth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"The_Hardcard","can_mod_post":false,"created_utc":1739321002,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_aom89enmo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Would it be possible to to put breaks in the algorithm and step through it in debug mode, dumping the machine state and see these “thoughts“ step by step for some simple reasoning tasks?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mca9xth","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Would it be possible to to put breaks in the algorithm and step through it in debug mode, dumping the machine state and see these “thoughts“ step by step for some simple reasoning tasks?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mca9xth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739321002,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcagwcl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"hawkedmd","can_mod_post":false,"created_utc":1739323302,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_4i1eduoi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Analogue to intuition or thinking with your gut?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcagwcl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Analogue to intuition or thinking with your gut?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcagwcl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739323302,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcaxusm","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"james-jiang","can_mod_post":false,"created_utc":1739329165,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_1ik1ah0hn6","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Still waiting for the Titan breakthrough to make its way into products","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcaxusm","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Still waiting for the Titan breakthrough to make its way into products&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcaxusm/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739329165,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbgays","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TechnoTherapist","can_mod_post":false,"created_utc":1739336466,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_69izf2uy2","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Been waiting for this! \\n\\nFuture LLMs have for a while been fully expected to eventually reason in vector space using constructs far more efficient than human language. \\n\\nThe trouble of course, is that this makes them inscrutable outside of the thinking they choose to share with us in the form of reasoning chains in *simple human language*.\\n\\n It might eventually be how, when your child asks you, \\"What are you thinking, dad?\\" you do a mental simplification before answering.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbgays","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Been waiting for this! &lt;/p&gt;\\n\\n&lt;p&gt;Future LLMs have for a while been fully expected to eventually reason in vector space using constructs far more efficient than human language. &lt;/p&gt;\\n\\n&lt;p&gt;The trouble of course, is that this makes them inscrutable outside of the thinking they choose to share with us in the form of reasoning chains in &lt;em&gt;simple human language&lt;/em&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;It might eventually be how, when your child asks you, &amp;quot;What are you thinking, dad?&amp;quot; you do a mental simplification before answering.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbgays/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739336466,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcbvbib","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"kale-gourd","can_mod_post":false,"created_utc":1739344140,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_ors6zev62","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Really cool idea","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcbvbib","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Really cool idea&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcbvbib/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739344140,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcc8b38","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"martinerous","can_mod_post":false,"created_utc":1739352103,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_5tp54ey","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope this will help with the issue when LLMs write a great plan in the thinktags and then spit out an answer that deviates from that plan, sometimes a lot.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcc8b38","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope this will help with the issue when LLMs write a great plan in the thinktags and then spit out an answer that deviates from that plan, sometimes a lot.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcc8b38/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739352103,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccl24o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Interesting8547","can_mod_post":false,"created_utc":1739359785,"send_replies":true,"parent_id":"t1_mcceo3w","score":2,"author_fullname":"t2_d82aa036","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":" Though why we didn't this before?!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mccl24o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Though why we didn&amp;#39;t this before?!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccl24o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739359785,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"mcceo3w","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"glensnuub","can_mod_post":false,"created_utc":1739356061,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_zo6jl","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Arguably the breakthrough is not performance boost - this is somewhat an unwritten rule in ML research. \\n\\nThe breakthrough is the shift from “thinking” in the costly token space to thinking in a space that doesn’t need to translate latent space manifestations into human readable tokens.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcceo3w","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Arguably the breakthrough is not performance boost - this is somewhat an unwritten rule in ML research. &lt;/p&gt;\\n\\n&lt;p&gt;The breakthrough is the shift from “thinking” in the costly token space to thinking in a space that doesn’t need to translate latent space manifestations into human readable tokens.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcceo3w/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739356061,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mccqk1v","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"S1lv3rC4t","can_mod_post":false,"created_utc":1739362557,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_q0l3vleb","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Did they just came up with \\"subconscious neural network\\"?!\\n\\nNow we need add \\"limbic neural network\\" (Self-Rewarding Language Models, [https://arxiv.org/pdf/2401.10020](https://arxiv.org/pdf/2401.10020) ) and combine it with current LLMs architecture for clear text communication. And maybe we got really conscious AI.\\n\\nContext: Human haves 3 parts of the conscious when it comes to psychology and neuroscience\\n\\n\\\\- True conscious (neocortex) that thinks and communicates in words  \\n\\\\- Subconscious (basal ganglia) that reasons from experience and world feedback, and communicates through the emotions/lymbic system  \\n\\\\- Limbic system (amygdala, hippocampus) that regulates emotions and modifies the external and internal inputs","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mccqk1v","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did they just came up with &amp;quot;subconscious neural network&amp;quot;?!&lt;/p&gt;\\n\\n&lt;p&gt;Now we need add &amp;quot;limbic neural network&amp;quot; (Self-Rewarding Language Models, &lt;a href=\\"https://arxiv.org/pdf/2401.10020\\"&gt;https://arxiv.org/pdf/2401.10020&lt;/a&gt; ) and combine it with current LLMs architecture for clear text communication. And maybe we got really conscious AI.&lt;/p&gt;\\n\\n&lt;p&gt;Context: Human haves 3 parts of the conscious when it comes to psychology and neuroscience&lt;/p&gt;\\n\\n&lt;p&gt;- True conscious (neocortex) that thinks and communicates in words&lt;br/&gt;\\n- Subconscious (basal ganglia) that reasons from experience and world feedback, and communicates through the emotions/lymbic system&lt;br/&gt;\\n- Limbic system (amygdala, hippocampus) that regulates emotions and modifies the external and internal inputs&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mccqk1v/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739362557,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcdlf6o","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"SamSlate","can_mod_post":false,"created_utc":1739373613,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_9lhpk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"how can you decouple reasoning from context?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcdlf6o","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;how can you decouple reasoning from context?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcdlf6o/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739373613,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":"","user_reports":[],"saved":false,"id":"mceben8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"merotatox","can_mod_post":false,"created_utc":1739381052,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_vb0ekbq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I CANT KEEP UP WITH PAPERS","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mceben8","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I CANT KEEP UP WITH PAPERS&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mceben8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739381052,"author_flair_text":"Llama 405B","treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mceg8w6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Murky_Mountain_97","can_mod_post":false,"created_utc":1739382410,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_c1t6569u","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"From this paper summary, seems like its upto 10X better? https://soessentially.substack.com/p/latent-space-reasoning","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mceg8w6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;From this paper summary, seems like its upto 10X better? &lt;a href=\\"https://soessentially.substack.com/p/latent-space-reasoning\\"&gt;https://soessentially.substack.com/p/latent-space-reasoning&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mceg8w6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739382410,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcei7ps","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Odd_Supermarket_5690","can_mod_post":false,"created_utc":1739382951,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_152rp6n8dd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Nice concept! But Isn't the \\"agents\\" become slow thinking?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcei7ps","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Nice concept! But Isn&amp;#39;t the &amp;quot;agents&amp;quot; become slow thinking?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcei7ps/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739382951,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mceq0yt","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"faldore","can_mod_post":false,"created_utc":1739385115,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_m02vk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Isn't that what coconut proposed already?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mceq0yt","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Isn&amp;#39;t that what coconut proposed already?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mceq0yt/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739385115,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcfd9fc","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"pathfinder6709","can_mod_post":false,"created_utc":1739391526,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_mus3e9eo","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Tapping into the power of guiding models to inherently think in their latent space, be it reasoning that is reasoning through features maps of different levels of manifolds is something I wish we focused much more on, on the side on human interpretable CoT reasoning","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcfd9fc","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Tapping into the power of guiding models to inherently think in their latent space, be it reasoning that is reasoning through features maps of different levels of manifolds is something I wish we focused much more on, on the side on human interpretable CoT reasoning&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcfd9fc/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739391526,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mchquwk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Farconion","can_mod_post":false,"created_utc":1739417973,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_h242mi1","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I wonder if this type of thinking was done during training, would it lead to similar improvements that token based reasoning has during inference if you only relied on output tokens for explainability?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mchquwk","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I wonder if this type of thinking was done during training, would it lead to similar improvements that token based reasoning has during inference if you only relied on output tokens for explainability?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mchquwk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739417973,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcivf44","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RemindMeBot","can_mod_post":false,"created_utc":1739438651,"send_replies":true,"parent_id":"t1_mcivcfy","score":1,"author_fullname":"t2_gbm4p","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"I will be messaging you in 3 days on [**2025-02-16 09:23:23 UTC**](http://www.wolframalpha.com/input/?i=2025-02-16%2009:23:23%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcivcfy/?context=3)\\n\\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1inch7r%2Fa_new_paper_demonstrates_that_llms_could_think_in%2Fmcivcfy%2F%5D%0A%0ARemindMe%21%202025-02-16%2009%3A23%3A23%20UTC) to send a PM to also be reminded and to reduce spam.\\n\\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201inch7r)\\n\\n*****\\n\\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\\n|-|-|-|-|","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcivf44","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I will be messaging you in 3 days on &lt;a href=\\"http://www.wolframalpha.com/input/?i=2025-02-16%2009:23:23%20UTC%20To%20Local%20Time\\"&gt;&lt;strong&gt;2025-02-16 09:23:23 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcivcfy/?context=3\\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1inch7r%2Fa_new_paper_demonstrates_that_llms_could_think_in%2Fmcivcfy%2F%5D%0A%0ARemindMe%21%202025-02-16%2009%3A23%3A23%20UTC\\"&gt;&lt;strong&gt;CLICK THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201inch7r\\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;table&gt;&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;th&gt;&lt;a href=\\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;&lt;tbody&gt;\\n&lt;/tbody&gt;&lt;/table&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1inch7r","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcivf44/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739438651,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"mcivcfy","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Zealousideal-Turn670","can_mod_post":false,"created_utc":1739438603,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_ae9v1l2r","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"RemindMe! 3 day","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcivcfy","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;RemindMe! 3 day&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcivcfy/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739438603,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mckh637","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"TitularClergy","can_mod_post":false,"created_utc":1739462725,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_ngh89e5z","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"link to paper: http://arxiv.org/abs/2502.05171","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mckh637","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;link to paper: &lt;a href=\\"http://arxiv.org/abs/2502.05171\\"&gt;http://arxiv.org/abs/2502.05171&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mckh637/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739462725,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mcm07ei","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Aggressive_Pea_2739","can_mod_post":false,"created_utc":1739478158,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_gsk4vkvnx","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Can anyone dumb it down for us peps?","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mcm07ei","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can anyone dumb it down for us peps?&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mcm07ei/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739478158,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"mdc3oyf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"uhuge","can_mod_post":false,"created_utc":1739834026,"send_replies":true,"parent_id":"t3_1inch7r","score":1,"author_fullname":"t2_742ne6tg","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"this explanation is quite fine: [https://www.youtube.com/watch?v=mhKC3Avqy2E](https://www.youtube.com/watch?v=mhKC3Avqy2E)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_mdc3oyf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;this explanation is quite fine: &lt;a href=\\"https://www.youtube.com/watch?v=mhKC3Avqy2E\\"&gt;https://www.youtube.com/watch?v=mhKC3Avqy2E&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1inch7r/a_new_paper_demonstrates_that_llms_could_think_in/mdc3oyf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1739834026,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1inch7r","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"more","data":{"count":8,"name":"t1_mca20jn","id":"mca20jn","parent_id":"t3_1inch7r","depth":0,"children":["mca20jn","mcc2xae","mcd6vuv","mcbrk6l","mcax6w9","mcd77u6"]}}],"before":null}}]`),o=()=>e.jsx(t,{data:a});export{o as default};
