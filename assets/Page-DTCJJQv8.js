import{j as e}from"./index-xfnGEtuL.js";import{R as l}from"./RedditPostRenderer-DAZRIZZK.js";import"./index-BaNn5-RR.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"The most recent news lead to next [Thursday ](https://www.reddit.com/r/LocalLLaMA/comments/1lvr3ym/openais_open_source_llm_is_a_reasoning_model/)as the launch date.\\n\\nI am hoping for something under 100B parameters, preferably 70B so it can run on a 48gb vram system. Over the last year the bulk of advancement in the open source space has been in the 400b and up and 32B and below range. No new 70B and 72B models from Meta or Qwen this generation.\\n\\nMOE would be great as most recent releases have been (Qwen 3, Llama4, Deepseek) but not required.\\n\\nDay 1 support for LlamaCPP, VLLM, Ollama and other inference engines. Google got it right with their release of Gemma3, building the infrastructure before launch.\\n\\nBetter reasoning / chain of thought. To some extent, almost all reasoning models are distillations of Deepseek r1, making all of the models sound, act, and behave the same. I'm hoping the dataset they used shows a diverse thinking strategies more then \\"wait,\\" and looping over again.\\n\\nCode Library data in the dataset. Looking at Qwen 2.5 coder, and the Claude family, the thing that sets these models apart from others is they have the raw library data included in their training data. When you ask about connecting to an API or local host it always get it right instead of providing a placeholder like \\"localhost:8000\\".\\n\\nDethrone QWQ. I love QWQ its the best reasoning model that not a direct distillation of Deepseek r1.  I think its the best opensource model on Fiction.liveBench Long Context. Great at coding, everything. Id like to see the innovation continue and OpenAI push the industry forward.\\n\\nFinally, I hope they go with a MIT or fully open source license. Nothing pseudo-open source like Llama, Research only, training restrictions on its outputs.\\n\\nWhat's on your wishlist?","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"What is your wishlist for OpenAI's upcoming open source model?","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":null,"top_awarded_type":null,"hide_score":false,"name":"t3_1lwtaor","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.37,"author_flair_background_color":null,"subreddit_type":"public","ups":0,"total_awards_received":0,"media_embed":{},"thumbnail_width":null,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_zr0g49ixt","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":0,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"self","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"content_categories":null,"is_self":true,"mod_note":null,"created":1752194778,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"self.LocalLLaMA","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;The most recent news lead to next &lt;a href=\\"https://www.reddit.com/r/LocalLLaMA/comments/1lvr3ym/openais_open_source_llm_is_a_reasoning_model/\\"&gt;Thursday &lt;/a&gt;as the launch date.&lt;/p&gt;\\n\\n&lt;p&gt;I am hoping for something under 100B parameters, preferably 70B so it can run on a 48gb vram system. Over the last year the bulk of advancement in the open source space has been in the 400b and up and 32B and below range. No new 70B and 72B models from Meta or Qwen this generation.&lt;/p&gt;\\n\\n&lt;p&gt;MOE would be great as most recent releases have been (Qwen 3, Llama4, Deepseek) but not required.&lt;/p&gt;\\n\\n&lt;p&gt;Day 1 support for LlamaCPP, VLLM, Ollama and other inference engines. Google got it right with their release of Gemma3, building the infrastructure before launch.&lt;/p&gt;\\n\\n&lt;p&gt;Better reasoning / chain of thought. To some extent, almost all reasoning models are distillations of Deepseek r1, making all of the models sound, act, and behave the same. I&amp;#39;m hoping the dataset they used shows a diverse thinking strategies more then &amp;quot;wait,&amp;quot; and looping over again.&lt;/p&gt;\\n\\n&lt;p&gt;Code Library data in the dataset. Looking at Qwen 2.5 coder, and the Claude family, the thing that sets these models apart from others is they have the raw library data included in their training data. When you ask about connecting to an API or local host it always get it right instead of providing a placeholder like &amp;quot;localhost:8000&amp;quot;.&lt;/p&gt;\\n\\n&lt;p&gt;Dethrone QWQ. I love QWQ its the best reasoning model that not a direct distillation of Deepseek r1.  I think its the best opensource model on Fiction.liveBench Long Context. Great at coding, everything. Id like to see the innovation continue and OpenAI push the industry forward.&lt;/p&gt;\\n\\n&lt;p&gt;Finally, I hope they go with a MIT or fully open source license. Nothing pseudo-open source like Llama, Research only, training restrictions on its outputs.&lt;/p&gt;\\n\\n&lt;p&gt;What&amp;#39;s on your wishlist?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"view_count":null,"archived":false,"no_follow":true,"is_crosspostable":false,"pinned":false,"over_18":false,"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"num_reports":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lwtaor","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"triynizzles1","discussion_type":null,"num_comments":26,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/","stickied":false,"url":"https://www.reddit.com/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/","subreddit_subscribers":497504,"created_utc":1752194778,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2gwyu4","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"BusRevolutionary9893","can_mod_post":false,"created_utc":1752196253,"send_replies":true,"parent_id":"t3_1lwtaor","score":11,"author_fullname":"t2_1by73qs5e5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A multimodal model with a native STS mode like ChatGPT Advanced Voice mode. It feels like that's the last thing companies want in our hands though so it will never happen.¬†","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2gwyu4","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A multimodal model with a native STS mode like ChatGPT Advanced Voice mode. It feels like that&amp;#39;s the last thing companies want in our hands though so it will never happen.¬†&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2gwyu4/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752196253,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":11}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ioqwo","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"mags0ft","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2idqs2","score":1,"author_fullname":"t2_1tbbr8pu4s","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Why was this downvoted? Seems like a legit point!","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2ioqwo","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Why was this downvoted? Seems like a legit point!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2ioqwo/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752225289,"author_flair_text":null,"treatment_tags":[],"created_utc":1752225289,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2idqs2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Thomas-Lore","can_mod_post":false,"created_utc":1752218959,"send_replies":true,"parent_id":"t1_n2gzsdq","score":1,"author_fullname":"t2_5hobp6m4","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"If it is MoE, then it might be easier to run than QwQ. For example I can run Hunyuan A13B on 64GB RAM at slow but decent speeds while QwQ, despite being smaller, is a no go.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2idqs2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;If it is MoE, then it might be easier to run than QwQ. For example I can run Hunyuan A13B on 64GB RAM at slow but decent speeds while QwQ, despite being smaller, is a no go.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2idqs2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752218959,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2gzsdq","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"HomeBrewUser","can_mod_post":false,"created_utc":1752197231,"send_replies":true,"parent_id":"t3_1lwtaor","score":3,"author_fullname":"t2_ddyduwi7","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It seems like this model will be many times larger than QwQ, referencing that post about needing H100(s). So QwQ will still have a use case :p","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2gzsdq","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It seems like this model will be many times larger than QwQ, referencing that post about needing H100(s). So QwQ will still have a use case :p&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2gzsdq/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752197231,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ha7te","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752200897,"send_replies":true,"parent_id":"t1_n2h8o4h","score":2,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Me too. I wonder how much of the decision is peer pressure from the community and how much is a business decision. I remember a while ago they said that o3 is more expensive than what they charge customers. It would make sense to open source something like that if they are losing money with each token generated.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ha7te","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Me too. I wonder how much of the decision is peer pressure from the community and how much is a business decision. I remember a while ago they said that o3 is more expensive than what they charge customers. It would make sense to open source something like that if they are losing money with each token generated.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2ha7te/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752200897,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2h8o4h","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Logical_Divide_3595","can_mod_post":false,"created_utc":1752200342,"send_replies":true,"parent_id":"t3_1lwtaor","score":3,"author_fullname":"t2_18riberpl8","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"It's hard to maintain the balance between advantage of commercial models and popularity of open source models. \\n\\n  \\nI want to know how much respect OpenAI will put for open source community.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h8o4h","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s hard to maintain the balance between advantage of commercial models and popularity of open source models. &lt;/p&gt;\\n\\n&lt;p&gt;I want to know how much respect OpenAI will put for open source community.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2h8o4h/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752200342,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hyl2p","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"lompocus","can_mod_post":false,"created_utc":1752211031,"send_replies":true,"parent_id":"t3_1lwtaor","score":3,"author_fullname":"t2_f4boq","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Whatever it is, it will be trash compared to Hunyuan or GLM newer models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hyl2p","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Whatever it is, it will be trash compared to Hunyuan or GLM newer models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hyl2p/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752211031,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hajip","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752201017,"send_replies":true,"parent_id":"t1_n2h3ea1","score":2,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Highly censored for sure üò≠üò≠üò≠","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hajip","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Highly censored for sure üò≠üò≠üò≠&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hajip/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752201017,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hfgtj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Entubulated","can_mod_post":false,"created_utc":1752202871,"send_replies":true,"parent_id":"t1_n2h3ea1","score":1,"author_fullname":"t2_1opxde6hyq","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Our expectations match.  \\nDon't get me wrong, I'd still test it.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hfgtj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Our expectations match.&lt;br/&gt;\\nDon&amp;#39;t get me wrong, I&amp;#39;d still test it.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hfgtj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752202871,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2h3ea1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Hunting-Succcubus","can_mod_post":false,"created_utc":1752198494,"send_replies":true,"parent_id":"t3_1lwtaor","score":6,"author_fullname":"t2_3wxyen0t","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I expect nothing from openai, if BIG IF they release - it will be highly censored, outdated, dead on arrival.","edited":1752214906,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h3ea1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I expect nothing from openai, if BIG IF they release - it will be highly censored, outdated, dead on arrival.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2h3ea1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752198494,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":6}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hd3ek","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"eggs-benedryl","can_mod_post":false,"created_utc":1752201971,"send_replies":true,"parent_id":"t3_1lwtaor","score":2,"author_fullname":"t2_8nlxwtdi","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"One i can run","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hd3ek","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;One i can run&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hd3ek/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752201971,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2he6hj","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ArsNeph","can_mod_post":false,"created_utc":1752202379,"send_replies":true,"parent_id":"t3_1lwtaor","score":2,"author_fullname":"t2_vt0xkv60d","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Forget most stuff, I just want it to have omnimodality, that is one of the most important things that adoption has been extremely slow on. That said, they would never release it, they would be too terrified of their PR going badly.\\n\\nA 50-80B MoE with good world knowledge and tool use performance would also be good\\n\\nBasically anything's fine as long as it's not super censored, 20B+, and is SOTA for it's size class","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2he6hj","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Forget most stuff, I just want it to have omnimodality, that is one of the most important things that adoption has been extremely slow on. That said, they would never release it, they would be too terrified of their PR going badly.&lt;/p&gt;\\n\\n&lt;p&gt;A 50-80B MoE with good world knowledge and tool use performance would also be good&lt;/p&gt;\\n\\n&lt;p&gt;Basically anything&amp;#39;s fine as long as it&amp;#39;s not super censored, 20B+, and is SOTA for it&amp;#39;s size class&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2he6hj/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752202379,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i6nhu","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752215102,"send_replies":true,"parent_id":"t1_n2i5ahk","score":2,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"That could be pretty big for the industry. Hopefully whatever it ends up being is something new and forward thinking. instead trying to catch up to established open-source sota.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i6nhu","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;That could be pretty big for the industry. Hopefully whatever it ends up being is something new and forward thinking. instead trying to catch up to established open-source sota.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2i6nhu/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752215102,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n2i5ahk","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"ttkciar","can_mod_post":false,"created_utc":1752214391,"send_replies":true,"parent_id":"t3_1lwtaor","score":2,"author_fullname":"t2_cpegz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This is a long, unlikely shot, but it would be terribly nice if they published something with a MoA architecture (like PHATGOOSE), because it would set the wheels in motion for MoA support in the major inference stacks (llama.cpp, vLLM, etc).\\n\\nMoA would give us the memory-efficiency of a dense model with some of the advantages of MoE.\\n\\nIt would also give us a way to mitigate catastrophic forgetting when heavily fine-tuning a model -- the MoA could infer on the LoRA-modified weights when context was relevant to the fine-tune domain, and infer on the unmodified weights of the untuned model otherwise.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i5ahk","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This is a long, unlikely shot, but it would be terribly nice if they published something with a MoA architecture (like PHATGOOSE), because it would set the wheels in motion for MoA support in the major inference stacks (llama.cpp, vLLM, etc).&lt;/p&gt;\\n\\n&lt;p&gt;MoA would give us the memory-efficiency of a dense model with some of the advantages of MoE.&lt;/p&gt;\\n\\n&lt;p&gt;It would also give us a way to mitigate catastrophic forgetting when heavily fine-tuning a model -- the MoA could infer on the LoRA-modified weights when context was relevant to the fine-tune domain, and infer on the unmodified weights of the untuned model otherwise.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2i5ahk/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752214391,"author_flair_text":"llama.cpp","treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hb530","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koumoua01","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2hagoa","score":1,"author_fullname":"t2_25by3xfc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Unfortunately, Mistral models don't know some of the SEA countries' languages.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2hb530","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Unfortunately, Mistral models don&amp;#39;t know some of the SEA countries&amp;#39; languages.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hb530/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752201240,"author_flair_text":null,"treatment_tags":[],"created_utc":1752201240,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2hagoa","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752200987,"send_replies":true,"parent_id":"t1_n2h140n","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"What language? I use mistral small 3.1 and its great at proofreading emails and documents im building.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hagoa","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;What language? I use mistral small 3.1 and its great at proofreading emails and documents im building.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hagoa/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752200987,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2h140n","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"koumoua01","can_mod_post":false,"created_utc":1752197693,"send_replies":true,"parent_id":"t3_1lwtaor","score":1,"author_fullname":"t2_25by3xfc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I hope the model can handle my language well so I can use it to automate, analyze and create reports to impress my higher-ups. Until now, no open model that smaller than the big qwen3 can output my stupid language in a usable level.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h140n","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I hope the model can handle my language well so I can use it to automate, analyze and create reports to impress my higher-ups. Until now, no open model that smaller than the big qwen3 can output my stupid language in a usable level.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2h140n/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752197693,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2h1je2","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"RedOneMonster","can_mod_post":false,"created_utc":1752197842,"send_replies":true,"parent_id":"t3_1lwtaor","score":1,"author_fullname":"t2_12op9k","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"14B model, o3 equivalent performance. Honestly, they must cook up something proper, as according to sam:\\n\\n&gt;our research team did something unexpected and quite amazing and we think it will be very very worth the wait, but needs a bit longer.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h1je2","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;14B model, o3 equivalent performance. Honestly, they must cook up something proper, as according to sam:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;our research team did something unexpected and quite amazing and we think it will be very very worth the wait, but needs a bit longer.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2h1je2/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752197842,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2ha9ge","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"triynizzles1","can_mod_post":false,"created_utc":1752200914,"send_replies":true,"parent_id":"t1_n2h6849","score":1,"author_fullname":"t2_zr0g49ixt","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"üôè","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2ha9ge","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;üôè&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2ha9ge/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752200914,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2h6849","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Pro-editor-1105","can_mod_post":false,"created_utc":1752199480,"send_replies":true,"parent_id":"t3_1lwtaor","score":1,"author_fullname":"t2_uptissiz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"be somewhat competent","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2h6849","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;be somewhat competent&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2h6849/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752199480,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hefe1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"LA_rent_Aficionado","can_mod_post":false,"created_utc":1752202473,"send_replies":true,"parent_id":"t3_1lwtaor","score":1,"author_fullname":"t2_t8zbiflk","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Hopefully something easily quantized without it being nonsense","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hefe1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Hopefully something easily quantized without it being nonsense&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hefe1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752202473,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2i3jda","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1752213486,"send_replies":true,"parent_id":"t3_1lwtaor","score":1,"author_fullname":"t2_uz37qfx5","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"no wishes. no interest in forced product.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i3jda","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;no wishes. no interest in forced product.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2i3jda/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752213486,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2hnixs","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AleksHop","can_mod_post":false,"created_utc":1752206108,"send_replies":true,"parent_id":"t3_1lwtaor","score":0,"author_fullname":"t2_8dnu3hmd","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"openai models are so bad that i dont expect anything to be like on llama 3.3 70b level from them","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hnixs","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;openai models are so bad that i dont expect anything to be like on llama 3.3 70b level from them&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hnixs/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752206108,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":1,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ef488598-491f-11ef-a847-9a3dd315819c","likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n2izzyl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"send_replies":true,"parent_id":"t1_n2i66qb","score":1,"author_fullname":"t2_6lmlc","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yes, of course we can. I am saying that because they aren't the number one when it comes to actually making the smartest models. They've been totally outstripped by Claude, Google, and even matched by DeepSeek for a long time. So there's no point getting yet another model. And honestly, why would OAI give away their smartest models? Their business model is based around charging access to them! \\n\\nIn short, they would neither be able to nor want to give us a smart open weights model and anyone who thinks they would isn't paying attention or are gullible. That's why I'd rather we got something potentially innovative, that wouldn't compete with them. The poll might have been rigged but thinking long term it's good that it was.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n2izzyl","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yes, of course we can. I am saying that because they aren&amp;#39;t the number one when it comes to actually making the smartest models. They&amp;#39;ve been totally outstripped by Claude, Google, and even matched by DeepSeek for a long time. So there&amp;#39;s no point getting yet another model. And honestly, why would OAI give away their smartest models? Their business model is based around charging access to them! &lt;/p&gt;\\n\\n&lt;p&gt;In short, they would neither be able to nor want to give us a smart open weights model and anyone who thinks they would isn&amp;#39;t paying attention or are gullible. That&amp;#39;s why I&amp;#39;d rather we got something potentially innovative, that wouldn&amp;#39;t compete with them. The poll might have been rigged but thinking long term it&amp;#39;s good that it was.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2izzyl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752231223,"author_flair_text":null,"treatment_tags":[],"created_utc":1752231223,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n2i66qb","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"MichaelXie4645","can_mod_post":false,"created_utc":1752214858,"send_replies":true,"parent_id":"t1_n2hdxvl","score":0,"author_fullname":"t2_a06q0mmx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Are you joking? We can distill our phone sized models from better models. We should have the more-or-less number 1 AI company to focus making the best and smartest AI to distill the phone models. This shows that the poll made by Sam is most definitely rigged.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2i66qb","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"Llama 405B"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Are you joking? We can distill our phone sized models from better models. We should have the more-or-less number 1 AI company to focus making the best and smartest AI to distill the phone models. This shows that the poll made by Sam is most definitely rigged.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lwtaor","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2i66qb/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752214858,"author_flair_text":"Llama 405B","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":0}}],"before":null}},"user_reports":[],"saved":false,"id":"n2hdxvl","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Ylsid","can_mod_post":false,"created_utc":1752202287,"send_replies":true,"parent_id":"t3_1lwtaor","score":-1,"author_fullname":"t2_6lmlc","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Something that can get useful to OS. We don't need more of the same. This is why I wanted a \\"phone sized\\" model. It has to be something we don't already have or it's a waste of time","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n2hdxvl","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Something that can get useful to OS. We don&amp;#39;t need more of the same. This is why I wanted a &amp;quot;phone sized&amp;quot; model. It has to be something we don&amp;#39;t already have or it&amp;#39;s a waste of time&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lwtaor/what_is_your_wishlist_for_openais_upcoming_open/n2hdxvl/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1752202287,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lwtaor","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}}]`),n=()=>e.jsx(l,{data:t});export{n as default};
