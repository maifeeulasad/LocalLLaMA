import{j as e}from"./index-DDI5xNtT.js";import{R as l}from"./RedditPostRenderer-D2w0CxE4.js";import"./index-CZ5j6e3h.js";const t=JSON.parse(`[{"kind":"Listing","data":{"after":null,"dist":1,"modhash":"","geo_filter":"","children":[{"kind":"t3","data":{"approved_at_utc":null,"subreddit":"LocalLLaMA","selftext":"We all know about code smells. When your code works, but it’s messy and you just know it’s going to cause pain later.\\n\\nThe same thing happens with prompts. I didn’t really think about it until I saw our LLM app getting harder and harder to tweak… and the root cause? Messy, overcomplicated prompts, complex workflows.\\n\\nSome examples, Prompt Smell when they: \\n\\n* Try to do five different things at once\\n* Are copied all over the place with slight tweaks\\n* Ask the LLM to do basic stuff your code should have handled\\n\\nIt’s basically tech debt, just hiding in your prompts instead of your code. And without proper tests or evals, changing them feels like walking on eggshells.\\n\\nI wrote a blog post about this. I’m calling it **prompt smells** and sharing how I think we can avoid them.\\n\\n**Link:** [Full post here](https://blog.surkar.in/prompt-smells-just-like-code)\\n\\nWhat's your take on this? ","user_reports":[],"saved":false,"mod_reason_title":null,"gilded":0,"clicked":false,"title":"Prompt Smells, Just Like Code","link_flair_richtext":[{"e":"text","t":"Discussion"}],"subreddit_name_prefixed":"r/LocalLLaMA","hidden":false,"pwls":6,"link_flair_css_class":"","downs":0,"thumbnail_height":73,"top_awarded_type":null,"hide_score":false,"name":"t3_1lnjw6m","quarantine":false,"link_flair_text_color":"light","upvote_ratio":0.79,"author_flair_background_color":null,"ups":42,"total_awards_received":0,"media_embed":{},"thumbnail_width":140,"author_flair_template_id":null,"is_original_content":false,"author_fullname":"t2_24ebov49","secure_media":null,"is_reddit_media_domain":false,"is_meta":false,"category":null,"secure_media_embed":{},"link_flair_text":"Discussion","can_mod_post":false,"score":42,"approved_by":null,"is_created_from_ads_ui":false,"author_premium":false,"thumbnail":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=2e35327ad51052622616709d2ff195cf734e887d","edited":false,"author_flair_css_class":null,"author_flair_richtext":[],"gildings":{},"post_hint":"link","content_categories":null,"is_self":false,"subreddit_type":"public","created":1751217007,"link_flair_type":"richtext","wls":6,"removed_by_category":null,"banned_by":null,"author_flair_type":"text","domain":"blog.surkar.in","allow_live_comments":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\\"md\\"&gt;&lt;p&gt;We all know about code smells. When your code works, but it’s messy and you just know it’s going to cause pain later.&lt;/p&gt;\\n\\n&lt;p&gt;The same thing happens with prompts. I didn’t really think about it until I saw our LLM app getting harder and harder to tweak… and the root cause? Messy, overcomplicated prompts, complex workflows.&lt;/p&gt;\\n\\n&lt;p&gt;Some examples, Prompt Smell when they: &lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Try to do five different things at once&lt;/li&gt;\\n&lt;li&gt;Are copied all over the place with slight tweaks&lt;/li&gt;\\n&lt;li&gt;Ask the LLM to do basic stuff your code should have handled&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;It’s basically tech debt, just hiding in your prompts instead of your code. And without proper tests or evals, changing them feels like walking on eggshells.&lt;/p&gt;\\n\\n&lt;p&gt;I wrote a blog post about this. I’m calling it &lt;strong&gt;prompt smells&lt;/strong&gt; and sharing how I think we can avoid them.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=\\"https://blog.surkar.in/prompt-smells-just-like-code\\"&gt;Full post here&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;What&amp;#39;s your take on this? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","likes":null,"suggested_sort":null,"banned_at_utc":null,"url_overridden_by_dest":"https://blog.surkar.in/prompt-smells-just-like-code","view_count":null,"archived":false,"no_follow":false,"is_crosspostable":false,"pinned":false,"over_18":false,"preview":{"images":[{"source":{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?auto=webp&amp;s=7e5edc51b6571711c914b541c965e209d216b5a4","width":1200,"height":630},"resolutions":[{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=74e8427cf080ad1bf7cf47257084f7d6b7828a7e","width":108,"height":56},{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c469873b73cd969ee5fc7b1347458d43bf21e06","width":216,"height":113},{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4edb7119eeceff6a90e976158f8b7ab616794619","width":320,"height":168},{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=945d5f5ba53e3e3648dd0c5b46af70c88c067214","width":640,"height":336},{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e0dab84943690f3cf8ff86083e79f01d46def3f0","width":960,"height":504},{"url":"https://external-preview.redd.it/CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=266a8365b71a6f8c73a6b08565ea395c8c378b2a","width":1080,"height":567}],"variants":{},"id":"CM_MCPik5clqILb0zxA6bpU1V0O-DrGVq9FOihM0CAc"}],"enabled":false},"all_awardings":[],"awarders":[],"media_only":false,"link_flair_template_id":"5f921ea4-c7bc-11ed-9c23-3a00622979b4","can_gild":false,"spoiler":false,"locked":false,"author_flair_text":null,"treatment_tags":[],"visited":false,"removed_by":null,"mod_note":null,"distinguished":null,"subreddit_id":"t5_81eyvm","author_is_blocked":false,"mod_reason_by":null,"num_reports":null,"removal_reason":null,"link_flair_background_color":"#646d73","id":"1lnjw6m","is_robot_indexable":true,"num_duplicates":0,"report_reasons":null,"author":"thesmallstar","discussion_type":null,"num_comments":16,"send_replies":true,"media":null,"contest_mode":false,"author_patreon_flair":false,"author_flair_text_color":null,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/","stickied":false,"url":"https://blog.surkar.in/prompt-smells-just-like-code","subreddit_subscribers":493240,"created_utc":1751217007,"num_crossposts":0,"mod_reports":[],"is_video":false}}],"before":null}},{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0j1dzr","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"AppearanceHeavy6724","can_mod_post":false,"created_utc":1751259938,"send_replies":true,"parent_id":"t1_n0g73r6","score":-1,"author_fullname":"t2_uz37qfx5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"...and it will reply in a broken native language and the comments in the code will be shit too.\\n\\nEDIT: Ok I  take my words back. It really does work; you will have to specify though to write the reply in English.","edited":1751272498,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0j1dzr","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;...and it will reply in a broken native language and the comments in the code will be shit too.&lt;/p&gt;\\n\\n&lt;p&gt;EDIT: Ok I  take my words back. It really does work; you will have to specify though to write the reply in English.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0j1dzr/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751259938,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0g73r6","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"blahblahsnahdah","can_mod_post":false,"created_utc":1751222465,"send_replies":false,"parent_id":"t3_1lnjw6m","score":13,"author_fullname":"t2_v31oki0i","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"There's also a problem I've seen of ESL people insisting on communicating with llms using badly broken English instead of just using their native language.\\n\\nPerhaps they think it's good practice, but it's often very obvious when you see logs/screenshots that they are crippling their results by being unable to articulate their problem clearly to the model. Just use whatever language you're best at.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0g73r6","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;There&amp;#39;s also a problem I&amp;#39;ve seen of ESL people insisting on communicating with llms using badly broken English instead of just using their native language.&lt;/p&gt;\\n\\n&lt;p&gt;Perhaps they think it&amp;#39;s good practice, but it&amp;#39;s often very obvious when you see logs/screenshots that they are crippling their results by being unable to articulate their problem clearly to the model. Just use whatever language you&amp;#39;re best at.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0g73r6/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751222465,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":13}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0ge4l1","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"synw_","can_mod_post":false,"created_utc":1751224718,"send_replies":true,"parent_id":"t3_1lnjw6m","score":8,"author_fullname":"t2_ecqgod","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"A good school to write concise and efficient prompts is to use small models. This knowledge helps to write better prompts for bigger models.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0ge4l1","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;A good school to write concise and efficient prompts is to use small models. This knowledge helps to write better prompts for bigger models.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0ge4l1/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751224718,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":8}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0g9p8g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"EarEuphoric","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0g3ipn","score":2,"author_fullname":"t2_97p70fab","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"It's a great use case 😀 it might seem irrelevant to a hobbyist using LLMs for individual tasks. Once you scale up to millions of LLM calls per day, even 100 less tokens per request adds up to thousands of dollars saved each day.\\n\\nI think the whole idea of \\"distilling\\" your prompts is going to become very fashionable over the near future. Especially with models becoming more and more expensive 👍","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0g9p8g","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;It&amp;#39;s a great use case 😀 it might seem irrelevant to a hobbyist using LLMs for individual tasks. Once you scale up to millions of LLM calls per day, even 100 less tokens per request adds up to thousands of dollars saved each day.&lt;/p&gt;\\n\\n&lt;p&gt;I think the whole idea of &amp;quot;distilling&amp;quot; your prompts is going to become very fashionable over the near future. Especially with models becoming more and more expensive 👍&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0g9p8g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751223295,"author_flair_text":null,"treatment_tags":[],"created_utc":1751223295,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0g3ipn","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thesmallstar","can_mod_post":false,"created_utc":1751221321,"send_replies":true,"parent_id":"t1_n0fykr8","score":1,"author_fullname":"t2_24ebov49","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Ah that’s super interesting! Love the INVEST parallel. Will check out the AutoPrompt paper, thanks!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0g3ipn","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Ah that’s super interesting! Love the INVEST parallel. Will check out the AutoPrompt paper, thanks!&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0g3ipn/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751221321,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"richtext","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":"ed89e5c6-72f1-11ee-9954-1697022cd89d","likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0hd41k","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"No_Afternoon_4260","can_mod_post":false,"created_utc":1751236112,"send_replies":true,"parent_id":"t1_n0fykr8","score":1,"author_fullname":"t2_cj9kap4bx","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Can you tell more about the prompt compressor?  \\nI'm really keen on that idea. Is it autoprompt?\\n\\nI agree sometimes the shortest the better.\\n\\nSometimes the model knows better than you what it has to do. So give it room to surprise you.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0hd41k","is_submitter":false,"downs":0,"author_flair_richtext":[{"e":"text","t":"llama.cpp"}],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Can you tell more about the prompt compressor?&lt;br/&gt;\\nI&amp;#39;m really keen on that idea. Is it autoprompt?&lt;/p&gt;\\n\\n&lt;p&gt;I agree sometimes the shortest the better.&lt;/p&gt;\\n\\n&lt;p&gt;Sometimes the model knows better than you what it has to do. So give it room to surprise you.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":"light","score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0hd41k/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751236112,"author_flair_text":"llama.cpp","treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":"#bbbdbf","collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fykr8","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"EarEuphoric","can_mod_post":false,"created_utc":1751219785,"send_replies":true,"parent_id":"t3_1lnjw6m","score":7,"author_fullname":"t2_97p70fab","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"I like this 👍\\n\\nI take a similar approach in my LLM workflows by following the INVEST structure from the agile method. It seems to work well!\\n\\nI recently came across the same concept when designing prompts to optimally classify a held out goldset. Some prompts were huge whilst others were tiny. Each achieved the same recall/precision on that goldset.\\n\\nThat led me to build a \\"prompt compressor\\" that reduced the length whilst preserving precision/recall. Turns out there exist prompts of a few words that achieve almost perfect recall+precision!\\n\\nVery analogous to the \\"overthinking\\" phenomena seen in the reasoning models of today. I'd argue that same behaviour is hardwired into humans too i.e. I failed to solve this problem, I must try harder. The sunk cost fallacy leads to overly complicated approaches that increase every kind of cost.\\n\\nHave a look into \\"AutoPrompt\\" on GitHub (and the associated paper). I think you'll be interested!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fykr8","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;I like this 👍&lt;/p&gt;\\n\\n&lt;p&gt;I take a similar approach in my LLM workflows by following the INVEST structure from the agile method. It seems to work well!&lt;/p&gt;\\n\\n&lt;p&gt;I recently came across the same concept when designing prompts to optimally classify a held out goldset. Some prompts were huge whilst others were tiny. Each achieved the same recall/precision on that goldset.&lt;/p&gt;\\n\\n&lt;p&gt;That led me to build a &amp;quot;prompt compressor&amp;quot; that reduced the length whilst preserving precision/recall. Turns out there exist prompts of a few words that achieve almost perfect recall+precision!&lt;/p&gt;\\n\\n&lt;p&gt;Very analogous to the &amp;quot;overthinking&amp;quot; phenomena seen in the reasoning models of today. I&amp;#39;d argue that same behaviour is hardwired into humans too i.e. I failed to solve this problem, I must try harder. The sunk cost fallacy leads to overly complicated approaches that increase every kind of cost.&lt;/p&gt;\\n\\n&lt;p&gt;Have a look into &amp;quot;AutoPrompt&amp;quot; on GitHub (and the associated paper). I think you&amp;#39;ll be interested!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0fykr8/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751219785,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":7}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0fy26g","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":false,"author":"Xrave","can_mod_post":false,"created_utc":1751219627,"send_replies":true,"parent_id":"t3_1lnjw6m","score":4,"author_fullname":"t2_6e7z0","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"prompt *is* code, programming languages *are* languages.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fy26g","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;prompt &lt;em&gt;is&lt;/em&gt; code, programming languages &lt;em&gt;are&lt;/em&gt; languages.&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0fy26g/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751219627,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":4}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0gb2jd","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0g2n5y","score":1,"author_fullname":"t2_usojvms","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Yeah np honestly have never thought of treating prompts similar to functions, and DRY principles for prompt part reuse.","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0gb2jd","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Yeah np honestly have never thought of treating prompts similar to functions, and DRY principles for prompt part reuse.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0gb2jd/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751223734,"author_flair_text":null,"treatment_tags":[],"created_utc":1751223734,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0g2n5y","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thesmallstar","can_mod_post":false,"created_utc":1751221045,"send_replies":true,"parent_id":"t1_n0fubvi","score":2,"author_fullname":"t2_24ebov49","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Thanks :)","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0g2n5y","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Thanks :)&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0g2n5y/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751221045,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":2}}],"before":null}},"user_reports":[],"saved":false,"id":"n0fubvi","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"sleepy_roger","can_mod_post":false,"created_utc":1751218488,"send_replies":true,"parent_id":"t3_1lnjw6m","score":1,"author_fullname":"t2_usojvms","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"This was a great read actually, appreciate the post!","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0fubvi","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;This was a great read actually, appreciate the post!&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0fubvi/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751218488,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0kauws","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"thesmallstar","can_mod_post":false,"created_utc":1751285074,"send_replies":true,"parent_id":"t1_n0gb3m7","score":3,"author_fullname":"t2_24ebov49","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"yes, I did :) I wrote a lot of text at first, wasn't sure if it's good for a reddit post. Worked with LLM to make it shorter and concise :D","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0kauws","is_submitter":true,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;yes, I did :) I wrote a lot of text at first, wasn&amp;#39;t sure if it&amp;#39;s good for a reddit post. Worked with LLM to make it shorter and concise :D&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0kauws/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751285074,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":3}},{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":{"kind":"Listing","data":{"after":null,"dist":null,"modhash":"","geo_filter":"","children":[{"kind":"t1","data":{"subreddit_id":"t5_81eyvm","approved_at_utc":null,"author_is_blocked":false,"comment_type":null,"awarders":[],"mod_reason_by":null,"banned_by":null,"author_flair_type":"text","total_awards_received":0,"subreddit":"LocalLLaMA","author_flair_template_id":null,"likes":null,"replies":"","user_reports":[],"saved":false,"id":"n0hm8g5","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wekede","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0hgjth","score":1,"author_fullname":"t2_kn9o5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Oh yeah good eye, didn't notice that one, weird","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0hm8g5","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Oh yeah good eye, didn&amp;#39;t notice that one, weird&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0hm8g5/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751239354,"author_flair_text":null,"treatment_tags":[],"created_utc":1751239354,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":3,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0hgjth","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Normal-Ad-7114","can_mod_post":false,"send_replies":true,"parent_id":"t1_n0hdfzf","score":-1,"author_fullname":"t2_8fu8sqhz","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"The line that gave it away for me was\\n\\n\\n&gt;harder to tweak… and the root cause? Messy, overcomplicated\\n\\n\\nBoth the \\"…\\" symbol and the chatgpt-esque question afterwards","edited":false,"top_awarded_type":null,"downs":0,"author_flair_css_class":null,"name":"t1_n0hgjth","is_submitter":false,"collapsed":false,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;The line that gave it away for me was&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;harder to tweak… and the root cause? Messy, overcomplicated&lt;/p&gt;\\n&lt;/blockquote&gt;\\n\\n&lt;p&gt;Both the &amp;quot;…&amp;quot; symbol and the chatgpt-esque question afterwards&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0hgjth/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751237331,"author_flair_text":null,"treatment_tags":[],"created_utc":1751237331,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":2,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0hdfzf","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"wekede","can_mod_post":false,"created_utc":1751236230,"send_replies":true,"parent_id":"t1_n0gb3m7","score":1,"author_fullname":"t2_kn9o5","removal_reason":null,"approved_by":null,"mod_note":null,"all_awardings":[],"body":"Reads like a product ad but seems human to me, maybe if it had emojis and some em dashes.","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0hdfzf","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Reads like a product ad but seems human to me, maybe if it had emojis and some em dashes.&lt;/p&gt;\\n&lt;/div&gt;","gildings":{},"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"link_id":"t3_1lnjw6m","unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0hdfzf/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751236230,"author_flair_text":null,"treatment_tags":[],"collapsed":false,"subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":1,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":1}}],"before":null}},"user_reports":[],"saved":false,"id":"n0gb3m7","banned_at_utc":null,"mod_reason_title":null,"gilded":0,"archived":false,"collapsed_reason_code":null,"no_follow":true,"author":"Normal-Ad-7114","can_mod_post":false,"created_utc":1751223744,"send_replies":true,"parent_id":"t3_1lnjw6m","score":-4,"author_fullname":"t2_8fu8sqhz","approved_by":null,"mod_note":null,"all_awardings":[],"collapsed":false,"body":"Did you use LLM to write this post? Be honest","edited":false,"top_awarded_type":null,"author_flair_css_class":null,"name":"t1_n0gb3m7","is_submitter":false,"downs":0,"author_flair_richtext":[],"author_patreon_flair":false,"body_html":"&lt;div class=\\"md\\"&gt;&lt;p&gt;Did you use LLM to write this post? Be honest&lt;/p&gt;\\n&lt;/div&gt;","removal_reason":null,"collapsed_reason":null,"distinguished":null,"associated_award":null,"stickied":false,"author_premium":false,"can_gild":false,"gildings":{},"unrepliable_reason":null,"author_flair_text_color":null,"score_hidden":false,"permalink":"/r/LocalLLaMA/comments/1lnjw6m/prompt_smells_just_like_code/n0gb3m7/","subreddit_type":"public","locked":false,"report_reasons":null,"created":1751223744,"author_flair_text":null,"treatment_tags":[],"link_id":"t3_1lnjw6m","subreddit_name_prefixed":"r/LocalLLaMA","controversiality":0,"depth":0,"author_flair_background_color":null,"collapsed_because_crowd_control":null,"mod_reports":[],"num_reports":null,"ups":-4}}],"before":null}}]`),s=()=>e.jsx(l,{data:t});export{s as default};
