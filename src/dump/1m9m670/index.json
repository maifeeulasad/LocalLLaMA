[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey r/LocalLLaMA,\n\nMy team and I, like many of you, have been deep in the agent-building rabbit hole. It's one thing to build a cool proof-of-concept with a framework like LangGraph. It's a completely different beast to make that agent actually *learn* and get better over time.\n\nWe got tired of the friction, so we started experimenting and landed on what we think is a really clean paradigm for agent training. We wanted to share the approach, the reasoning, and our open-source implementation.\n\n# The Main Idea\n\nMost autonomous agents operate in a loop. They start with a task, think, use tools, and repeat until they arrive at a final answer. The \"thinking\" part is usually a call to an LLM. **Here, we are interested in tuning the LLM part here with the signals from the entire agent flow.**\n\nHere's a simplified diagram of that common workflow:\n\nhttps://preview.redd.it/tf0tlm5it5ff1.png?width=698&amp;format=png&amp;auto=webp&amp;s=3596dc7643a92a1674da7342120907bfdde15e43\n\nSometimes LLM calls and tool calls can be parallelized, but it's simplified here. Obviously, if we can reward or penalize the final result, we can use some kind of an RL algorithm to train the LLM to at least produce better responses for the current agent. However, this is where the pain begins.\n\n1. **Environment Hell:** Setting up a single environment to both run the agent and train the LLM is a nightmare. The agent ecosystem and the ML training ecosystem use different dependencies. You end up with monstrous Dockerfiles, docker-in-docker, conflicting dependencies, and a fragile system where the two parts are tangled together.\n2. **Invasive Code Surgery:** To make an existing agent \"trainable\" with RL, you typically have to perform major surgery on its code. This means manually exporting action traces, formatting them for an RL library, and fundamentally changing the agent's logic just to fit it into a trainer loop. To fit into the RLHF framework, many works like token masking and async rollouts need to be done. It feels wrong and breaks the modularity that makes these frameworks great in the first place.\n\n# Decouple Everything, Then Glue It Together\n\nWe realized the solution was to completely decouple the agent's execution environment from the training environment. Instead of forcing the agent code into a training framework, we let the agent run wherever and however it wants. A lightweight monitoring client sits next to the agent, watches what it does, and sends the results to a dedicated training server.\n\nThe architecture is simple: a central server manages the training loop and model weights, while one or more clients run the agents and collect data. Here’s a high-level flow:\n\nhttps://preview.redd.it/5ss2rsa1u5ff1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=077bd9f2d792385188a92c5d8adb85d47be182c3\n\nThis approach lets us use the best tools for each job without compromise:\n\n* **Agent Frameworks:** LangChain/LangGraph, Autogen, etc.\n* **Tracing:** AgentOps, LangSmith, etc.\n* **Training Backend:** VERL, OpenRLHF, etc.\n\nThe result is that your agent code becomes radically simpler. You don't rewrite it; you just wrap it. The image below shows a before-and-after of a LangGraph SQL agent where the core logic is **unchanged**. The only difference is swapping out a direct call to a model with our client and adding a lightweight training script.\n\nhttps://preview.redd.it/6dlcyx1et5ff1.png?width=1416&amp;format=png&amp;auto=webp&amp;s=a083978d9125d61f451f9a4f1cb1dd6e11dd9659\n\n# Does It Actually Work?\n\nYes. We tested this on a couple of simple agent tasks and saw significant improvements.\n\n* **SQL Agent (LangGraph):** We built a write -&gt; check -&gt; rewrite agent and trained it on the Spider dataset. The agent has only a final reward tells it whether the SQL exeuction returns expected result or not. For a 3B parameter Llama 3.2 model, its SQL generation accuracy jumped from **5.6% to 76.8%**.\n* **Calculator Agent (Autogen):** We fine-tuned a standard math agent on the Calc-X dataset. Its accuracy in solving multi-step reasoning problems improved from **52% to 70%**.\n\nIn both cases, we saw these gains simply by letting the agent run and rewarding it for correct final answers.\n\n# The Hacks to Make It Work\n\nGetting this to run smoothly required a few under-the-hood fixes:\n\n* **vLLM Token Hacking:** As the agent sends out chat messages and receives strings or parsed tool calls, to get the tokens and log probabilities needed for RL, we had to lightly monkey-patch vLLM to expose the prompt and response tokens, not just the final text. We attempted other approaches such as retokenize the chat messages in RL framework -- all turning out to be unsuccessful and coming with different levels of bugs in the end. [https://github.com/microsoft/agent-lightning/blob/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/agentlightning/instrumentation/vllm.py](https://github.com/microsoft/agent-lightning/blob/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/agentlightning/instrumentation/vllm.py) \n* **AgentOps Patching:** We use AgentOps for tracing, so we patched its client to grab our custom token data and embed it in the trace sent back to the training server.\n* **Integration Workarounds:** The agentops-langgraph integration had a regression in its latest version, so we temporarily disabled it and implemented the trace logging manually. Simple, but necessary.\n* **Custom RL Trainer:** Our RL training loop needed a custom \"rollout collector\" that passively waits for traces to be reported from the distributed clients, rather than actively stepping through a simulation itself.\n\n# The Power of Decoupling\n\nThis architecture has some powerful benefits. For example, you can run the fragile and computationally expensive model training on a powerful rented remote server, while running your lightweight agent on one or multiple local machines. This makes it trivial to switch between a commercial API and a self-hosted open-source model. If multiple people are using the same agent, their usage data (the \"trajectories\") can be contributed to a central server, which federatedly and continuously fine-tunes and improves the model for everyone.\n\nOn the algorithm side, if you are not interested in RL, you can also use a prompt tuning algorithm to tune the prompt. We also implement a toy example under the server-client paradigm: [https://github.com/microsoft/agent-lightning/tree/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/examples/apo](https://github.com/microsoft/agent-lightning/tree/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/examples/apo) \n\n# Try It Yourself\n\nWe wanted to share this because we think it's a powerful pattern for adding learning capabilities to the amazing agents this community is building.\n\nIf you've faced these same problems and don't want to write hundreds of lines of glue code, you can check out our implementation, **Agent-Lightning** ⚡️, on GitHub: [https://aka.ms/agl](https://aka.ms/agl)\n\nWe'd love to hear any suggestions or about similar problems you're facing.\n\nHappy training!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "We discovered an approach to train any AI agent with RL, with (almost) zero code changes.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Tutorial | Guide"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 70,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "tf0tlm5it5ff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 71,
                    "x": 108,
                    "u": "https://preview.redd.it/tf0tlm5it5ff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9df929e3b32fac6de50db75fa2e863d0dbc0ce2d"
                  },
                  {
                    "y": 142,
                    "x": 216,
                    "u": "https://preview.redd.it/tf0tlm5it5ff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b367eae91df7025a6a8c1541a531df80acd7956"
                  },
                  {
                    "y": 210,
                    "x": 320,
                    "u": "https://preview.redd.it/tf0tlm5it5ff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d587d2731ada0d3ed5bd07d40c8c34ed192979b5"
                  },
                  {
                    "y": 421,
                    "x": 640,
                    "u": "https://preview.redd.it/tf0tlm5it5ff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d7b0bf8b1f402d2fa7189b619943c99ea4bd213"
                  }
                ],
                "s": {
                  "y": 460,
                  "x": 698,
                  "u": "https://preview.redd.it/tf0tlm5it5ff1.png?width=698&amp;format=png&amp;auto=webp&amp;s=3596dc7643a92a1674da7342120907bfdde15e43"
                },
                "id": "tf0tlm5it5ff1"
              },
              "6dlcyx1et5ff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 94,
                    "x": 108,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d4aa62c2a46298ce02b7f65139d36f34ca2a173"
                  },
                  {
                    "y": 188,
                    "x": 216,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a7947da0ecf6fdd8d282305c1638f6447baf3de"
                  },
                  {
                    "y": 279,
                    "x": 320,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fc2e92d2b033c46e73032b368c72306e9c44c21a"
                  },
                  {
                    "y": 558,
                    "x": 640,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=058cf66b8d14b345aadbf8e096c0bd276d33dc2e"
                  },
                  {
                    "y": 837,
                    "x": 960,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6686c1b70e688730848a038f79a173f1b7c6fd27"
                  },
                  {
                    "y": 941,
                    "x": 1080,
                    "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82d63fff35a3f130bb4c222999825d50cb6b4c4d"
                  }
                ],
                "s": {
                  "y": 1235,
                  "x": 1416,
                  "u": "https://preview.redd.it/6dlcyx1et5ff1.png?width=1416&amp;format=png&amp;auto=webp&amp;s=a083978d9125d61f451f9a4f1cb1dd6e11dd9659"
                },
                "id": "6dlcyx1et5ff1"
              },
              "5ss2rsa1u5ff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/jpg",
                "p": [
                  {
                    "y": 89,
                    "x": 108,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=31c269f8362da341fff4ab43871d50435d4d3d18"
                  },
                  {
                    "y": 179,
                    "x": 216,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f2e6aeb20d2ee4d884f62c979cdac2378fe4dd1"
                  },
                  {
                    "y": 266,
                    "x": 320,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7bdb140e4bfcdb7843f9da0c7dad38067856064"
                  },
                  {
                    "y": 532,
                    "x": 640,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9b5f4d44c88f61b39de496c33cf442fca32374c"
                  },
                  {
                    "y": 798,
                    "x": 960,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aadb2b9f24d59eb516d71d2fafb9ba7f1cc4deae"
                  },
                  {
                    "y": 897,
                    "x": 1080,
                    "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cbbbff973ab92177209dddd3416186f20b6eda25"
                  }
                ],
                "s": {
                  "y": 1330,
                  "x": 1600,
                  "u": "https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=077bd9f2d792385188a92c5d8adb85d47be182c3"
                },
                "id": "5ss2rsa1u5ff1"
              }
            },
            "name": "t3_1m9m670",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "ups": 128,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_axc2q017",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Tutorial | Guide",
            "can_mod_post": false,
            "score": 128,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=953075c30eab980cdc41740c498b8b414054af14",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "subreddit_type": "public",
            "created": 1753510735,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;My team and I, like many of you, have been deep in the agent-building rabbit hole. It&amp;#39;s one thing to build a cool proof-of-concept with a framework like LangGraph. It&amp;#39;s a completely different beast to make that agent actually &lt;em&gt;learn&lt;/em&gt; and get better over time.&lt;/p&gt;\n\n&lt;p&gt;We got tired of the friction, so we started experimenting and landed on what we think is a really clean paradigm for agent training. We wanted to share the approach, the reasoning, and our open-source implementation.&lt;/p&gt;\n\n&lt;h1&gt;The Main Idea&lt;/h1&gt;\n\n&lt;p&gt;Most autonomous agents operate in a loop. They start with a task, think, use tools, and repeat until they arrive at a final answer. The &amp;quot;thinking&amp;quot; part is usually a call to an LLM. &lt;strong&gt;Here, we are interested in tuning the LLM part here with the signals from the entire agent flow.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a simplified diagram of that common workflow:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tf0tlm5it5ff1.png?width=698&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3596dc7643a92a1674da7342120907bfdde15e43\"&gt;https://preview.redd.it/tf0tlm5it5ff1.png?width=698&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3596dc7643a92a1674da7342120907bfdde15e43&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Sometimes LLM calls and tool calls can be parallelized, but it&amp;#39;s simplified here. Obviously, if we can reward or penalize the final result, we can use some kind of an RL algorithm to train the LLM to at least produce better responses for the current agent. However, this is where the pain begins.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Environment Hell:&lt;/strong&gt; Setting up a single environment to both run the agent and train the LLM is a nightmare. The agent ecosystem and the ML training ecosystem use different dependencies. You end up with monstrous Dockerfiles, docker-in-docker, conflicting dependencies, and a fragile system where the two parts are tangled together.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Invasive Code Surgery:&lt;/strong&gt; To make an existing agent &amp;quot;trainable&amp;quot; with RL, you typically have to perform major surgery on its code. This means manually exporting action traces, formatting them for an RL library, and fundamentally changing the agent&amp;#39;s logic just to fit it into a trainer loop. To fit into the RLHF framework, many works like token masking and async rollouts need to be done. It feels wrong and breaks the modularity that makes these frameworks great in the first place.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Decouple Everything, Then Glue It Together&lt;/h1&gt;\n\n&lt;p&gt;We realized the solution was to completely decouple the agent&amp;#39;s execution environment from the training environment. Instead of forcing the agent code into a training framework, we let the agent run wherever and however it wants. A lightweight monitoring client sits next to the agent, watches what it does, and sends the results to a dedicated training server.&lt;/p&gt;\n\n&lt;p&gt;The architecture is simple: a central server manages the training loop and model weights, while one or more clients run the agents and collect data. Here’s a high-level flow:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=077bd9f2d792385188a92c5d8adb85d47be182c3\"&gt;https://preview.redd.it/5ss2rsa1u5ff1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=077bd9f2d792385188a92c5d8adb85d47be182c3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This approach lets us use the best tools for each job without compromise:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Agent Frameworks:&lt;/strong&gt; LangChain/LangGraph, Autogen, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Tracing:&lt;/strong&gt; AgentOps, LangSmith, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Training Backend:&lt;/strong&gt; VERL, OpenRLHF, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The result is that your agent code becomes radically simpler. You don&amp;#39;t rewrite it; you just wrap it. The image below shows a before-and-after of a LangGraph SQL agent where the core logic is &lt;strong&gt;unchanged&lt;/strong&gt;. The only difference is swapping out a direct call to a model with our client and adding a lightweight training script.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6dlcyx1et5ff1.png?width=1416&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a083978d9125d61f451f9a4f1cb1dd6e11dd9659\"&gt;https://preview.redd.it/6dlcyx1et5ff1.png?width=1416&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a083978d9125d61f451f9a4f1cb1dd6e11dd9659&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Does It Actually Work?&lt;/h1&gt;\n\n&lt;p&gt;Yes. We tested this on a couple of simple agent tasks and saw significant improvements.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;SQL Agent (LangGraph):&lt;/strong&gt; We built a write -&amp;gt; check -&amp;gt; rewrite agent and trained it on the Spider dataset. The agent has only a final reward tells it whether the SQL exeuction returns expected result or not. For a 3B parameter Llama 3.2 model, its SQL generation accuracy jumped from &lt;strong&gt;5.6% to 76.8%&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Calculator Agent (Autogen):&lt;/strong&gt; We fine-tuned a standard math agent on the Calc-X dataset. Its accuracy in solving multi-step reasoning problems improved from &lt;strong&gt;52% to 70%&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In both cases, we saw these gains simply by letting the agent run and rewarding it for correct final answers.&lt;/p&gt;\n\n&lt;h1&gt;The Hacks to Make It Work&lt;/h1&gt;\n\n&lt;p&gt;Getting this to run smoothly required a few under-the-hood fixes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;vLLM Token Hacking:&lt;/strong&gt; As the agent sends out chat messages and receives strings or parsed tool calls, to get the tokens and log probabilities needed for RL, we had to lightly monkey-patch vLLM to expose the prompt and response tokens, not just the final text. We attempted other approaches such as retokenize the chat messages in RL framework -- all turning out to be unsuccessful and coming with different levels of bugs in the end. &lt;a href=\"https://github.com/microsoft/agent-lightning/blob/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/agentlightning/instrumentation/vllm.py\"&gt;https://github.com/microsoft/agent-lightning/blob/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/agentlightning/instrumentation/vllm.py&lt;/a&gt; &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AgentOps Patching:&lt;/strong&gt; We use AgentOps for tracing, so we patched its client to grab our custom token data and embed it in the trace sent back to the training server.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Integration Workarounds:&lt;/strong&gt; The agentops-langgraph integration had a regression in its latest version, so we temporarily disabled it and implemented the trace logging manually. Simple, but necessary.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Custom RL Trainer:&lt;/strong&gt; Our RL training loop needed a custom &amp;quot;rollout collector&amp;quot; that passively waits for traces to be reported from the distributed clients, rather than actively stepping through a simulation itself.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;The Power of Decoupling&lt;/h1&gt;\n\n&lt;p&gt;This architecture has some powerful benefits. For example, you can run the fragile and computationally expensive model training on a powerful rented remote server, while running your lightweight agent on one or multiple local machines. This makes it trivial to switch between a commercial API and a self-hosted open-source model. If multiple people are using the same agent, their usage data (the &amp;quot;trajectories&amp;quot;) can be contributed to a central server, which federatedly and continuously fine-tunes and improves the model for everyone.&lt;/p&gt;\n\n&lt;p&gt;On the algorithm side, if you are not interested in RL, you can also use a prompt tuning algorithm to tune the prompt. We also implement a toy example under the server-client paradigm: &lt;a href=\"https://github.com/microsoft/agent-lightning/tree/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/examples/apo\"&gt;https://github.com/microsoft/agent-lightning/tree/2b3cc41b8973bd9c5dec8a12808dd8e65a22f453/examples/apo&lt;/a&gt; &lt;/p&gt;\n\n&lt;h1&gt;Try It Yourself&lt;/h1&gt;\n\n&lt;p&gt;We wanted to share this because we think it&amp;#39;s a powerful pattern for adding learning capabilities to the amazing agents this community is building.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve faced these same problems and don&amp;#39;t want to write hundreds of lines of glue code, you can check out our implementation, &lt;strong&gt;Agent-Lightning&lt;/strong&gt; ⚡️, on GitHub: &lt;a href=\"https://aka.ms/agl\"&gt;https://aka.ms/agl&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;d love to hear any suggestions or about similar problems you&amp;#39;re facing.&lt;/p&gt;\n\n&lt;p&gt;Happy training!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?auto=webp&amp;s=52ac6240eed7693b6f63c97926272110edd06a6a",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=57900143d22c1c24bc7123fead5fbf0b41f12a0b",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5590ab50fa85026868ab622f6c4a1fe3ef74d042",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d093acf24195baabfa76710f0682f917df367a6",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=88a9b978ee97cdfd20f8b2dc732fd0837291ac6e",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=532401c9034c1155791aafebe52c117f824a05a0",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e4a7440200ee5206c90be571456527293819046f",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "Qb-FyRzMVnNh5wmBlbGJQmNh976iEvgFgQ1wpwkFR3U"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#0079d3",
            "id": "1m9m670",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "matluster",
            "discussion_type": null,
            "num_comments": 24,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/",
            "subreddit_subscribers": 505615,
            "created_utc": 1753510735,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n58xh9h",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "matluster",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n58wnfd",
                                          "score": 4,
                                          "author_fullname": "t2_axc2q017",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "They implement their own performance tracking and logging. I've been involved in developing CoML (mid 2023) and RD-Agent (mid 2025); I've also looked into implementation of OpenAI Codex (early 2025). If I remember correctly, none of them has been using any agent frameworks.  \nAs for semantic kernel, I simply dislike its C-sharp-ish haha :)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n58xh9h",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They implement their own performance tracking and logging. I&amp;#39;ve been involved in developing CoML (mid 2023) and RD-Agent (mid 2025); I&amp;#39;ve also looked into implementation of OpenAI Codex (early 2025). If I remember correctly, none of them has been using any agent frameworks.&lt;br/&gt;\nAs for semantic kernel, I simply dislike its C-sharp-ish haha :)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9m670",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n58xh9h/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753528853,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753528853,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n58wnfd",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "SkyFeistyLlama8",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n586ifo",
                                "score": 3,
                                "author_fullname": "t2_1hgbaqgbnq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Semantic Kernel, maybe? The rest are too abstract and they're all moving targets. Not something you want to choose for a production deployment.\n\nYou're dead on about complex agent apps and workflows not using frameworks and jumping right into OpenAI SDK calls. That's the best approach if you want performance and logging to see what your agents are doing.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n58wnfd",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Semantic Kernel, maybe? The rest are too abstract and they&amp;#39;re all moving targets. Not something you want to choose for a production deployment.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re dead on about complex agent apps and workflows not using frameworks and jumping right into OpenAI SDK calls. That&amp;#39;s the best approach if you want performance and logging to see what your agents are doing.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9m670",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n58wnfd/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753528445,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753528445,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n586ifo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "matluster",
                      "can_mod_post": false,
                      "created_utc": 1753513456,
                      "send_replies": true,
                      "parent_id": "t1_n584n74",
                      "score": 15,
                      "author_fullname": "t2_axc2q017",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "So what tools are you using? CrewAI? OpenAI Agent SDK? AG2? Dify? To be frank, I think all the tools here are at a similar level when crafting a prototype. For most complex agent applications and workflows I've worked with, they never use \"agent frameworks\" -- they use low-level OpenAI SDK / LiteLLM.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n586ifo",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So what tools are you using? CrewAI? OpenAI Agent SDK? AG2? Dify? To be frank, I think all the tools here are at a similar level when crafting a prototype. For most complex agent applications and workflows I&amp;#39;ve worked with, they never use &amp;quot;agent frameworks&amp;quot; -- they use low-level OpenAI SDK / LiteLLM.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n586ifo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753513456,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 15
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5aw987",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Gregory-Wolf",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5a4314",
                                                              "score": 6,
                                                              "author_fullname": "t2_gethr3mh",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I thought it was just me, and was afraid to show signs...",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5aw987",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I thought it was just me, and was afraid to show signs...&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m9m670",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5aw987/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753553170,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753553170,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 6
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5bqigx",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "yetiflask",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5a4314",
                                                              "score": 1,
                                                              "author_fullname": "t2_10dsvcdpvu",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "If you have something opensource, I'd like to see to get an idea.\n\nI can imagine how I'd write it if I wanted to, but it's good to actually see somthing that's out there already.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5bqigx",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have something opensource, I&amp;#39;d like to see to get an idea.&lt;/p&gt;\n\n&lt;p&gt;I can imagine how I&amp;#39;d write it if I wanted to, but it&amp;#39;s good to actually see somthing that&amp;#39;s out there already.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m9m670",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5bqigx/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753563006,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753563006,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5a4314",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Orolol",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5a0sdi",
                                                    "score": 15,
                                                    "author_fullname": "t2_fbzx9",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Coding your own agent framework in python is like 200 line of code, and you won't get brain cancer by trying to understand the Langchain documentation.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5a4314",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Coding your own agent framework in python is like 200 line of code, and you won&amp;#39;t get brain cancer by trying to understand the Langchain documentation.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m9m670",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5a4314/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753544436,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753544436,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 15
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5a0sdi",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "yetiflask",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n594656",
                                          "score": -6,
                                          "author_fullname": "t2_10dsvcdpvu",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "You're kidding right? That's not a framework, do you roll your own or something?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5a0sdi",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re kidding right? That&amp;#39;s not a framework, do you roll your own or something?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9m670",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5a0sdi/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753543411,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753543411,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n594656",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Orolol",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n586cge",
                                "score": 14,
                                "author_fullname": "t2_fbzx9",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Python.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n594656",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Python.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9m670",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n594656/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753531873,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753531873,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 14
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n586cge",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Egoz3ntrum",
                      "can_mod_post": false,
                      "created_utc": 1753513364,
                      "send_replies": true,
                      "parent_id": "t1_n584n74",
                      "score": 2,
                      "author_fullname": "t2_h7b8z",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Okay what's your alternative?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n586cge",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Okay what&amp;#39;s your alternative?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n586cge/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753513364,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n584n74",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "-lq_pl-",
            "can_mod_post": false,
            "created_utc": 1753512427,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 51,
            "author_fullname": "t2_16rvbe",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You lost me at LangChain being the 'best tool' for the job.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n584n74",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You lost me at LangChain being the &amp;#39;best tool&amp;#39; for the job.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n584n74/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753512427,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 51
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n58a70h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "matluster",
                      "can_mod_post": false,
                      "created_utc": 1753515573,
                      "send_replies": true,
                      "parent_id": "t1_n588kpd",
                      "score": 5,
                      "author_fullname": "t2_axc2q017",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Short answer: I exposed the LLM API at the server. All the MCP stuff belong to the client side.  \nLet me try to elaborate the SQL agent a little bit and please see if that makes sense. The SQL agent's input here receives a task like \"how many users are there in the database\". The first step of the agent is to make a call to LLM to generate a SQL like \"COUNT \\* blabla\" (this is generated by LLM) and the agent embeds a connection to database and executes the query (this can be done by MCP or simple Python code). The second step is to self-check the query with the execution result (by calling again the LLM). The third step is to refine the query. Step 2-3 is repeated until the check is self-satisfied or time runs out. The agent then posts the full trajectory (prompts, responses, final results) here and says that's what I did in this rollout.  \nNow, what I provided at the server is that: task inputs, keeping throwing out by the algorithm; and an LLM endpoint, being improved by an RL algorithm. When the client keeps running more and more tasks and reports more and more rollouts, the LLM endpoint gradually gets better and better for new tasks after it is trained on more and more data.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n58a70h",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Short answer: I exposed the LLM API at the server. All the MCP stuff belong to the client side.&lt;br/&gt;\nLet me try to elaborate the SQL agent a little bit and please see if that makes sense. The SQL agent&amp;#39;s input here receives a task like &amp;quot;how many users are there in the database&amp;quot;. The first step of the agent is to make a call to LLM to generate a SQL like &amp;quot;COUNT * blabla&amp;quot; (this is generated by LLM) and the agent embeds a connection to database and executes the query (this can be done by MCP or simple Python code). The second step is to self-check the query with the execution result (by calling again the LLM). The third step is to refine the query. Step 2-3 is repeated until the check is self-satisfied or time runs out. The agent then posts the full trajectory (prompts, responses, final results) here and says that&amp;#39;s what I did in this rollout.&lt;br/&gt;\nNow, what I provided at the server is that: task inputs, keeping throwing out by the algorithm; and an LLM endpoint, being improved by an RL algorithm. When the client keeps running more and more tasks and reports more and more rollouts, the LLM endpoint gradually gets better and better for new tasks after it is trained on more and more data.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n58a70h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753515573,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n588kpd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "IKeepForgetting",
            "can_mod_post": false,
            "created_utc": 1753514624,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 4,
            "author_fullname": "t2_3fqrk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I might have a potentially dumb question... for the specific SQL example you have here, I can see how rewriting it the way you did would be great for training since you train it to make a call and the call itself abstracts the SQL away, vs it learning the SQL.\n\nBut isn't that more on the abstraction and design of the agent calls themselves? Like, if we treat them as \"the new APIs\", you'd never expose an API point that's just \"insert random SQL in here and we'll run it for you\". Instead you'd have a \"GET /all\\_users\" endpoint.   Wouldn't you do the same here and in the MCP spec say \"a tool call to all\\_users returns json for all the users\" and then train it to make a call to \"all\\_users\"? Then it's on you to make a safe endpoint the other way that returns that info? Or am I totally misunderstanding what this is doing?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n588kpd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I might have a potentially dumb question... for the specific SQL example you have here, I can see how rewriting it the way you did would be great for training since you train it to make a call and the call itself abstracts the SQL away, vs it learning the SQL.&lt;/p&gt;\n\n&lt;p&gt;But isn&amp;#39;t that more on the abstraction and design of the agent calls themselves? Like, if we treat them as &amp;quot;the new APIs&amp;quot;, you&amp;#39;d never expose an API point that&amp;#39;s just &amp;quot;insert random SQL in here and we&amp;#39;ll run it for you&amp;quot;. Instead you&amp;#39;d have a &amp;quot;GET /all_users&amp;quot; endpoint.   Wouldn&amp;#39;t you do the same here and in the MCP spec say &amp;quot;a tool call to all_users returns json for all the users&amp;quot; and then train it to make a call to &amp;quot;all_users&amp;quot;? Then it&amp;#39;s on you to make a safe endpoint the other way that returns that info? Or am I totally misunderstanding what this is doing?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n588kpd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753514624,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n59xrgq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "matluster",
                      "can_mod_post": false,
                      "created_utc": 1753542458,
                      "send_replies": true,
                      "parent_id": "t1_n598vg2",
                      "score": -3,
                      "author_fullname": "t2_axc2q017",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What are you training, the LLM powering the agent? -- yes.  \nWhat’s the reward function? -- each agent needs to define their own evaluation logic. It's on the client side.  \nhow are you resetting the environment after an episode? -- The interface requires agent code to be loop-runnable. The agent code should reset itself and receive new input after an episode.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n59xrgq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What are you training, the LLM powering the agent? -- yes.&lt;br/&gt;\nWhat’s the reward function? -- each agent needs to define their own evaluation logic. It&amp;#39;s on the client side.&lt;br/&gt;\nhow are you resetting the environment after an episode? -- The interface requires agent code to be loop-runnable. The agent code should reset itself and receive new input after an episode.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n59xrgq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753542458,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n598vg2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "indicava",
            "can_mod_post": false,
            "created_utc": 1753533798,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 3,
            "author_fullname": "t2_4dvff",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don’t get it, what are you training, the LLM powering the agent? What’s the reward function? And if you’re only wrapping the agent, how are you resetting the environment after an episode?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n598vg2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don’t get it, what are you training, the LLM powering the agent? What’s the reward function? And if you’re only wrapping the agent, how are you resetting the environment after an episode?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n598vg2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753533798,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n59z2h2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "matluster",
                      "can_mod_post": false,
                      "created_utc": 1753542872,
                      "send_replies": true,
                      "parent_id": "t1_n59kly9",
                      "score": 2,
                      "author_fullname": "t2_axc2q017",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Interesting observation. Practically, prompt tuning might be a better idea because it's less resource-intensive and even works with closed-source models. I also believe that tuning model weights is an under-explored direction and there are so many mysteries -- some even believe that agent training on a diverse large set of real-work tasks is \\*\\*THE PATH TO AGI\\*\\*.  \nNevertheless, prompt tuning for agents can be also painful. Previously when I worked with an agent with a dozen of prompts, it's hard for me to track down the exact step where the agent diverges from the expected behavior. With this paradigm and all the monitored traces sent to the server side, there might be an automatic algorithm which can be built at the server side, to automatically diagnosis and improve all the prompts involved in an agent. Not sure if it's a promising direction but worth trying I think.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n59z2h2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting observation. Practically, prompt tuning might be a better idea because it&amp;#39;s less resource-intensive and even works with closed-source models. I also believe that tuning model weights is an under-explored direction and there are so many mysteries -- some even believe that agent training on a diverse large set of real-work tasks is **THE PATH TO AGI**.&lt;br/&gt;\nNevertheless, prompt tuning for agents can be also painful. Previously when I worked with an agent with a dozen of prompts, it&amp;#39;s hard for me to track down the exact step where the agent diverges from the expected behavior. With this paradigm and all the monitored traces sent to the server side, there might be an automatic algorithm which can be built at the server side, to automatically diagnosis and improve all the prompts involved in an agent. Not sure if it&amp;#39;s a promising direction but worth trying I think.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n59z2h2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753542872,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n59kly9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jabr7",
            "can_mod_post": false,
            "created_utc": 1753538143,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 3,
            "author_fullname": "t2_2zp8i5tg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Isn't this basically just retraining the LLM on its own traces as they come in? Feels like a fast track to overfitting and catastrophic forgetting. You could try something like LoRA to avoid updating the whole model, but even then, you're locking the model into your agent’s narrow behavior and will quickly lose the knowledge to sparse feedback.\nI’d skip full-on fine-tuning altogether and just use prompt tuning (e.g. P-Tuning v2) or adapter methods. If you're serious about RL, jump to a more robust RLHF setup like PPO with reward shaping instead of hacking together passive trace collection",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n59kly9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Isn&amp;#39;t this basically just retraining the LLM on its own traces as they come in? Feels like a fast track to overfitting and catastrophic forgetting. You could try something like LoRA to avoid updating the whole model, but even then, you&amp;#39;re locking the model into your agent’s narrow behavior and will quickly lose the knowledge to sparse feedback.\nI’d skip full-on fine-tuning altogether and just use prompt tuning (e.g. P-Tuning v2) or adapter methods. If you&amp;#39;re serious about RL, jump to a more robust RLHF setup like PPO with reward shaping instead of hacking together passive trace collection&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n59kly9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753538143,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n58cirs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Lost_Attention_3355",
            "can_mod_post": false,
            "created_utc": 1753516928,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 11,
            "author_fullname": "t2_1mr4rkpqir",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "LangChain, hard pass",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n58cirs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LangChain, hard pass&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n58cirs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753516928,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5b4gj5",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "thallazar",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n59y7sm",
                                          "score": 2,
                                          "author_fullname": "t2_4m3wz",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "LLMs are just REST requests with json objects. Openai/anthropic and other platforms have their own clients for making the requests. Instructor for turning them into structured output.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5b4gj5",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LLMs are just REST requests with json objects. Openai/anthropic and other platforms have their own clients for making the requests. Instructor for turning them into structured output.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9m670",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5b4gj5/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753555794,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753555794,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n59y7sm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "yetiflask",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n593cvu",
                                "score": 1,
                                "author_fullname": "t2_10dsvcdpvu",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "What's your alternative then? Asking it honestly, since I have only really used langchain. Would love to know what else is out there for me to use.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n59y7sm",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s your alternative then? Asking it honestly, since I have only really used langchain. Would love to know what else is out there for me to use.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9m670",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n59y7sm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753542603,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753542603,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n593cvu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Lost_Attention_3355",
                      "can_mod_post": false,
                      "created_utc": 1753531529,
                      "send_replies": true,
                      "parent_id": "t1_n58yz7u",
                      "score": 5,
                      "author_fullname": "t2_1mr4rkpqir",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "over design, bad software engineering",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n593cvu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;over design, bad software engineering&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9m670",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n593cvu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753531529,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n58yz7u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "markwilds",
            "can_mod_post": false,
            "created_utc": 1753529576,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 2,
            "author_fullname": "t2_o95mm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Whats people's problem with langchain?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n58yz7u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Whats people&amp;#39;s problem with langchain?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n58yz7u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753529576,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5aroba",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "George-RD",
            "can_mod_post": false,
            "created_utc": 1753551759,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 1,
            "author_fullname": "t2_hlb9f4bvw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This continuous AI training could be a path towards AGI. It’s a almost like “sleep” where it processes its conversations, takes in the lessons, and wakes up “smarter” (new model version!)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5aroba",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This continuous AI training could be a path towards AGI. It’s a almost like “sleep” where it processes its conversations, takes in the lessons, and wakes up “smarter” (new model version!)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5aroba/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753551759,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5e5nhe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Specialist_Ruin_9333",
            "can_mod_post": false,
            "created_utc": 1753598468,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 1,
            "author_fullname": "t2_exu8rceu",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So you collect reward signals from the agent runs and RL-finetune the model on a different machine using those signals?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5e5nhe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you collect reward signals from the agent runs and RL-finetune the model on a different machine using those signals?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5e5nhe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753598468,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fy8fy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "KernQ",
            "can_mod_post": false,
            "created_utc": 1753628473,
            "send_replies": true,
            "parent_id": "t3_1m9m670",
            "score": 1,
            "author_fullname": "t2_1pozn81kn1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Bit confused - are you feeding the agent with known text from spider, or real user queries? I guess the ones from spider so you can compare your answer with exec_eval? Can you elaborate on that part for me (is it using their test suite?).\n\nAssuming that's the case, what role does the DB schema play? Are the queries generated blind or with schema as the context?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fy8fy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Bit confused - are you feeding the agent with known text from spider, or real user queries? I guess the ones from spider so you can compare your answer with exec_eval? Can you elaborate on that part for me (is it using their test suite?).&lt;/p&gt;\n\n&lt;p&gt;Assuming that&amp;#39;s the case, what role does the DB schema play? Are the queries generated blind or with schema as the context?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/n5fy8fy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753628473,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9m670",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]