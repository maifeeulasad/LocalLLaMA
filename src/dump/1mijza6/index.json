[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I ran the [vLLM provided benchmarks](https://github.com/vllm-project/vllm/tree/main/benchmarks) `serve` (online serving throughput) and `throughput` (offline serving throughput) for `gpt-oss-120b` on my H100 96GB with the ShareGPT benchmark data.\n\nCan confirm it fits snugly in 96GB. Numbers below.\n\n# Throughput Benchmark (offline serving throughput)\n\nCommand: `vllm bench serve --model \"openai/gpt-oss-120b\"`\n\n    ============ Serving Benchmark Result ============\n    Successful requests:                     1000\n    Benchmark duration (s):                  47.81\n    Total input tokens:                      1022745\n    Total generated tokens:                  48223\n    Request throughput (req/s):              20.92\n    Output token throughput (tok/s):         1008.61\n    Total Token throughput (tok/s):          22399.88\n    ---------------Time to First Token----------------\n    Mean TTFT (ms):                          18806.63\n    Median TTFT (ms):                        18631.45\n    P99 TTFT (ms):                           36522.62\n    -----Time per Output Token (excl. 1st token)------\n    Mean TPOT (ms):                          283.85\n    Median TPOT (ms):                        271.48\n    P99 TPOT (ms):                           801.98\n    ---------------Inter-token Latency----------------\n    Mean ITL (ms):                           231.50\n    Median ITL (ms):                         267.02\n    P99 ITL (ms):                            678.42\n    ==================================================\n\n# Serve Benchmark (online serving throughput)\n\nCommand: `vllm bench latency --model \"openai/gpt-oss-120b\"`\n\n    Avg latency: 1.3391752537339925 seconds\n    10% percentile latency: 1.277150624152273 seconds\n    25% percentile latency: 1.30161597346887 seconds\n    50% percentile latency: 1.3404422830790281 seconds\n    75% percentile latency: 1.3767581032589078 seconds\n    90% percentile latency: 1.393262314144522 seconds\n    99% percentile latency: 1.4468831585347652 seconds",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "vLLM latency/throughput benchmarks for gpt-oss-120b",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 81,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mijza6",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.89,
            "author_flair_background_color": "transparent",
            "ups": 52,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "is_original_content": false,
            "author_fullname": "t2_1a48h7vf",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 52,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/CkiPy_94iF46m6sozte4q0xipLvoNhob8Av1r371Asc.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754424752,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran the &lt;a href=\"https://github.com/vllm-project/vllm/tree/main/benchmarks\"&gt;vLLM provided benchmarks&lt;/a&gt; &lt;code&gt;serve&lt;/code&gt; (online serving throughput) and &lt;code&gt;throughput&lt;/code&gt; (offline serving throughput) for &lt;code&gt;gpt-oss-120b&lt;/code&gt; on my H100 96GB with the ShareGPT benchmark data.&lt;/p&gt;\n\n&lt;p&gt;Can confirm it fits snugly in 96GB. Numbers below.&lt;/p&gt;\n\n&lt;h1&gt;Throughput Benchmark (offline serving throughput)&lt;/h1&gt;\n\n&lt;p&gt;Command: &lt;code&gt;vllm bench serve --model &amp;quot;openai/gpt-oss-120b&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;============ Serving Benchmark Result ============\nSuccessful requests:                     1000\nBenchmark duration (s):                  47.81\nTotal input tokens:                      1022745\nTotal generated tokens:                  48223\nRequest throughput (req/s):              20.92\nOutput token throughput (tok/s):         1008.61\nTotal Token throughput (tok/s):          22399.88\n---------------Time to First Token----------------\nMean TTFT (ms):                          18806.63\nMedian TTFT (ms):                        18631.45\nP99 TTFT (ms):                           36522.62\n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          283.85\nMedian TPOT (ms):                        271.48\nP99 TPOT (ms):                           801.98\n---------------Inter-token Latency----------------\nMean ITL (ms):                           231.50\nMedian ITL (ms):                         267.02\nP99 ITL (ms):                            678.42\n==================================================\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;Serve Benchmark (online serving throughput)&lt;/h1&gt;\n\n&lt;p&gt;Command: &lt;code&gt;vllm bench latency --model &amp;quot;openai/gpt-oss-120b&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avg latency: 1.3391752537339925 seconds\n10% percentile latency: 1.277150624152273 seconds\n25% percentile latency: 1.30161597346887 seconds\n50% percentile latency: 1.3404422830790281 seconds\n75% percentile latency: 1.3767581032589078 seconds\n90% percentile latency: 1.393262314144522 seconds\n99% percentile latency: 1.4468831585347652 seconds\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/bz9j2b92d9hf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?auto=webp&amp;s=f4537f0f422810ae514de68f6a07b87764fd88d3",
                    "width": 2695,
                    "height": 1574
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c11c3140455b7faeb590a3bf0df168bd37f153f1",
                      "width": 108,
                      "height": 63
                    },
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0d32efb2dbb850088837decea852e2c7f216980",
                      "width": 216,
                      "height": 126
                    },
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=07654141634decbf9b896303af7caddb1575997f",
                      "width": 320,
                      "height": 186
                    },
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c7db73fb89602975462166e965bca3fd42eb685",
                      "width": 640,
                      "height": 373
                    },
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c7305c5c1ea1f409820387a5147feddc8c865c16",
                      "width": 960,
                      "height": 560
                    },
                    {
                      "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a59413d800f13ae883ef3683a06ed1962ec705c2",
                      "width": 1080,
                      "height": 630
                    }
                  ],
                  "variants": {},
                  "id": "QSXGsN0xEL2pMJPlSHxzuAzjIjcwxz798p-YwZh29U4"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mijza6",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "entsnack",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "dark",
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/",
            "stickied": false,
            "url": "https://i.redd.it/bz9j2b92d9hf1.png",
            "subreddit_subscribers": 511885,
            "created_utc": 1754424752,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n743ajv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Felladrin",
            "can_mod_post": false,
            "created_utc": 1754426286,
            "send_replies": true,
            "parent_id": "t3_1mijza6",
            "score": 4,
            "author_fullname": "t2_wp9mv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Good info! Thanks for sharing!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n743ajv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Good info! Thanks for sharing!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n743ajv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754426286,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijza6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n74ywqm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754436596,
                      "send_replies": true,
                      "parent_id": "t1_n74paad",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I used the default parameters. My serving command is \\`vllm serve openai/gpt-oss-120b\\`.\n\nYou could try \\`--enforce-eager\\`. Also make sure you don't see any error messages about \"unquantizing\", and that your libraries are up to date. I'm on pytorch 2.8, Cuda 12.8, latest transformers and triton 3.4.0, latest triton\\_kernels.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74ywqm",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I used the default parameters. My serving command is `vllm serve openai/gpt-oss-120b`.&lt;/p&gt;\n\n&lt;p&gt;You could try `--enforce-eager`. Also make sure you don&amp;#39;t see any error messages about &amp;quot;unquantizing&amp;quot;, and that your libraries are up to date. I&amp;#39;m on pytorch 2.8, Cuda 12.8, latest transformers and triton 3.4.0, latest triton_kernels.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mijza6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n74ywqm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754436596,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74paad",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Zbogus",
            "can_mod_post": false,
            "created_utc": 1754433407,
            "send_replies": true,
            "parent_id": "t3_1mijza6",
            "score": 3,
            "author_fullname": "t2_13ne7s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Do you know what parameters are used to vllm for this? I am seeing considerably slower on the same hardware",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74paad",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you know what parameters are used to vllm for this? I am seeing considerably slower on the same hardware&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n74paad/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754433407,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijza6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n76pgtm",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "entsnack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n76e7d9",
                                          "score": 1,
                                          "author_fullname": "t2_1a48h7vf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "oh man, will write it up now. where are you stuck?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n76pgtm",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "a": ":X:",
                                              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                              "e": "emoji"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oh man, will write it up now. where are you stuck?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mijza6",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n76pgtm/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754460942,
                                          "author_flair_text": ":X:",
                                          "treatment_tags": [],
                                          "created_utc": 1754460942,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "transparent",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n76e7d9",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "theslonkingdead",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74ykny",
                                "score": 2,
                                "author_fullname": "t2_215et9yl",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Please post the tutorial, I've been whaling away at this all evening with no success.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76e7d9",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Please post the tutorial, I&amp;#39;ve been whaling away at this all evening with no success.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mijza6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n76e7d9/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754455352,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754455352,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n75k0wb",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "itsmebcc",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74ykny",
                                "score": 1,
                                "author_fullname": "t2_43j7l",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I have tried and tried but I may be throwing in the towel for now. I get caught in a dependency loop no matter what I do:\n\n\\`\\`\\`\n\nuv pip install --pre vllm==0.10.1+gptoss \\\\\n\n\\--extra-index-url [https://wheels.vllm.ai/gpt-oss/](https://wheels.vllm.ai/gpt-oss/) \\\\\n\n\\--extra-index-url [https://download.pytorch.org/whl/nightly/cu128](https://download.pytorch.org/whl/nightly/cu128) \\\\\n\n\\--index-strategy unsafe-best-match\n\n  × No solution found when resolving dependencies:\n\n  ╰─▶ Because there is no version of openai-harmony==0.1.0 and vllm==0.10.1+gptoss depends on openai-harmony==0.1.0,\n\nwe can conclude that vllm==0.10.1+gptoss cannot be used.\n\nAnd because you require vllm==0.10.1+gptoss, we can conclude that your requirements are unsatisfiable.  \n\\`\\`\\`",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n75k0wb",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have tried and tried but I may be throwing in the towel for now. I get caught in a dependency loop no matter what I do:&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;uv pip install --pre vllm==0.10.1+gptoss \\&lt;/p&gt;\n\n&lt;p&gt;--extra-index-url &lt;a href=\"https://wheels.vllm.ai/gpt-oss/\"&gt;https://wheels.vllm.ai/gpt-oss/&lt;/a&gt; \\&lt;/p&gt;\n\n&lt;p&gt;--extra-index-url &lt;a href=\"https://download.pytorch.org/whl/nightly/cu128\"&gt;https://download.pytorch.org/whl/nightly/cu128&lt;/a&gt; \\&lt;/p&gt;\n\n&lt;p&gt;--index-strategy unsafe-best-match&lt;/p&gt;\n\n&lt;p&gt;× No solution found when resolving dependencies:&lt;/p&gt;\n\n&lt;p&gt;╰─▶ Because there is no version of openai-harmony==0.1.0 and vllm==0.10.1+gptoss depends on openai-harmony==0.1.0,&lt;/p&gt;\n\n&lt;p&gt;we can conclude that vllm==0.10.1+gptoss cannot be used.&lt;/p&gt;\n\n&lt;p&gt;And because you require vllm==0.10.1+gptoss, we can conclude that your requirements are unsatisfiable.&lt;br/&gt;\n```&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mijza6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n75k0wb/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754443781,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754443781,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74ykny",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754436485,
                      "send_replies": true,
                      "parent_id": "t1_n74xyu7",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's complicated. I should post a tutorial. This is the vLLM installation command:\n\n    uv pip install --pre vllm==0.10.1+gptoss \\\n       --extra-index-url https://wheels.vllm.ai/gpt-oss/ \\\n       --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \\\n       --index-strategy unsafe-best-match\n\nYou also need pytorch 2.8:\n\n```\npip install torch==2.8.0 --index-url https://download.pytorch.org/whl/test/cu128\n```\n\nYou also need triton and triton_kernels to use mxfp4:\n\n```\npip install triton==3.4.0\npip install git+https://github.com/triton-lang/triton.git@main#subdirectory=python/triton_kernels\n```",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74ykny",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s complicated. I should post a tutorial. This is the vLLM installation command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;uv pip install --pre vllm==0.10.1+gptoss \\\n   --extra-index-url https://wheels.vllm.ai/gpt-oss/ \\\n   --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \\\n   --index-strategy unsafe-best-match\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You also need pytorch 2.8:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\npip install torch==2.8.0 --index-url https://download.pytorch.org/whl/test/cu128\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;You also need triton and triton_kernels to use mxfp4:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\npip install triton==3.4.0\npip install git+https://github.com/triton-lang/triton.git@main#subdirectory=python/triton_kernels\n&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mijza6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n74ykny/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754436485,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74xyu7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "itsmebcc",
            "can_mod_post": false,
            "created_utc": 1754436283,
            "send_replies": true,
            "parent_id": "t3_1mijza6",
            "score": 2,
            "author_fullname": "t2_43j7l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I cannot seem to be able to build the vllm to run this. Do you have the command you used to build this?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74xyu7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I cannot seem to be able to build the vllm to run this. Do you have the command you used to build this?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n74xyu7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754436283,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijza6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n77394i",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "entsnack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n772zt7",
                                          "score": 1,
                                          "author_fullname": "t2_1a48h7vf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Not for memory footprint but for inference speed.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n77394i",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "a": ":X:",
                                              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                              "e": "emoji"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not for memory footprint but for inference speed.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mijza6",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n77394i/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754468607,
                                          "author_flair_text": ":X:",
                                          "treatment_tags": [],
                                          "created_utc": 1754468607,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "transparent",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n772zt7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "greying_panda",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n75ex7g",
                                "score": 1,
                                "author_fullname": "t2_52h19pjc",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Oh cheers! I imagine that the \"active parameters\" are not relevant to your parameter memory footprint, since I assume no expert offloading is used by default, but mxfp4 makes perfect sense for fitting parameters.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n772zt7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh cheers! I imagine that the &amp;quot;active parameters&amp;quot; are not relevant to your parameter memory footprint, since I assume no expert offloading is used by default, but mxfp4 makes perfect sense for fitting parameters.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mijza6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n772zt7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754468460,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754468460,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n75ex7g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754442029,
                      "send_replies": true,
                      "parent_id": "t1_n75ck3j",
                      "score": 3,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "gpt-oss models use the MXFP4 format natively, which means they use 4.25 bits per parameter. bf16/fp16 is about 3.75x larger. Hopper and Blackwell GPUs support MXFP4 (Blackwell supports it in hardware). The model I'm running is in its native format from the OpenAI Huggingface repo.\n\nEdit: Also 120B is an MoE with 5.1B active parameters per forward pass.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n75ex7g",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gpt-oss models use the MXFP4 format natively, which means they use 4.25 bits per parameter. bf16/fp16 is about 3.75x larger. Hopper and Blackwell GPUs support MXFP4 (Blackwell supports it in hardware). The model I&amp;#39;m running is in its native format from the OpenAI Huggingface repo.&lt;/p&gt;\n\n&lt;p&gt;Edit: Also 120B is an MoE with 5.1B active parameters per forward pass.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mijza6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n75ex7g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754442029,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n75ck3j",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "greying_panda",
            "can_mod_post": false,
            "created_utc": 1754441224,
            "send_replies": true,
            "parent_id": "t3_1mijza6",
            "score": 1,
            "author_fullname": "t2_52h19pjc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "How is this deployed? 96GB VRAM for a 120B model seems incongruent without heavy quantization or offloading (naively 120B should be 240GB in 16bit just for parameters, no?)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75ck3j",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How is this deployed? 96GB VRAM for a 120B model seems incongruent without heavy quantization or offloading (naively 120B should be 240GB in 16bit just for parameters, no?)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n75ck3j/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754441224,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijza6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75vu0y",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Expensive-Apricot-25",
            "can_mod_post": false,
            "created_utc": 1754447921,
            "send_replies": true,
            "parent_id": "t3_1mijza6",
            "score": 1,
            "author_fullname": "t2_idqkwio0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "what is the single request speed?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75vu0y",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what is the single request speed?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/n75vu0y/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754447921,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijza6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]