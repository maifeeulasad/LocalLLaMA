[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey all,\n\nI’ve been learning Rust recently and decided to build something practical with it. I kept seeing AI coding CLIs like Claude Code, Gemini CLI, Grok, and Qwen — all interesting, but all written in TypeScript.\n\nSo I built my own alternative in Rust: Rust-Coder-CLI\nIt’s a terminal-based coding assistant with a modern TUI, built using ratatui. It lets you:\n\nChat with OpenAI-compatible models.\n\nRun shell commands\n\nRead/write/delete files\n\nExecute code snippets in various languages\n\nManage directories\n\nView tool output in real-time logs\n\n\nThe whole interface is organized into panels for chat, tool execution logs, input, and status. It supports text wrapping, scrollback, and color-coded output for easier reading.\n\nIt’s fully configurable via a TOML file or environment variables. You just drop in your OpenAI API key and it works out of the box.\n\nRight now it supports OpenAI and Anthropic APIs, and I’m working on adding local model support using Kalsom and Mistral.rs.\n\nRepo: https://github.com/Ammar-Alnagar/Rust-Coder-CLI\n\nStill a work in progress, and I’d love any feedback or ideas. Contributions are welcome too.\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Built a Rust terminal AI coding assistant",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Other"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1messzq",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.7,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1rm9syq1nb",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Other",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754043793,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I’ve been learning Rust recently and decided to build something practical with it. I kept seeing AI coding CLIs like Claude Code, Gemini CLI, Grok, and Qwen — all interesting, but all written in TypeScript.&lt;/p&gt;\n\n&lt;p&gt;So I built my own alternative in Rust: Rust-Coder-CLI\nIt’s a terminal-based coding assistant with a modern TUI, built using ratatui. It lets you:&lt;/p&gt;\n\n&lt;p&gt;Chat with OpenAI-compatible models.&lt;/p&gt;\n\n&lt;p&gt;Run shell commands&lt;/p&gt;\n\n&lt;p&gt;Read/write/delete files&lt;/p&gt;\n\n&lt;p&gt;Execute code snippets in various languages&lt;/p&gt;\n\n&lt;p&gt;Manage directories&lt;/p&gt;\n\n&lt;p&gt;View tool output in real-time logs&lt;/p&gt;\n\n&lt;p&gt;The whole interface is organized into panels for chat, tool execution logs, input, and status. It supports text wrapping, scrollback, and color-coded output for easier reading.&lt;/p&gt;\n\n&lt;p&gt;It’s fully configurable via a TOML file or environment variables. You just drop in your OpenAI API key and it works out of the box.&lt;/p&gt;\n\n&lt;p&gt;Right now it supports OpenAI and Anthropic APIs, and I’m working on adding local model support using Kalsom and Mistral.rs.&lt;/p&gt;\n\n&lt;p&gt;Repo: &lt;a href=\"https://github.com/Ammar-Alnagar/Rust-Coder-CLI\"&gt;https://github.com/Ammar-Alnagar/Rust-Coder-CLI&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Still a work in progress, and I’d love any feedback or ideas. Contributions are welcome too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?auto=webp&amp;s=7cfa9ecb13b05c699f623a4f95199eba9f8ef53c",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=30da10a66809db51f184b16eebaafeb6063969e2",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd2925a25d9e0c8764a93973a222fcec5299720d",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9a1ff99185fcec08bd5ce224daa65a37ad066e2",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a3a45df63ce8a385e6a395bfeec665a75f826661",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c20e3805cfdfca06075bfa9dd496f98fc0cd1e82",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc898ac00a12f00858e33a462b8326c22385096d",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "URpyINniaZjV18DUPj5y1yBzgsGLD-zWGhmlqJjcP7E"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#94e044",
            "id": "1messzq",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Daemontatox",
            "discussion_type": null,
            "num_comments": 10,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/",
            "subreddit_subscribers": 508541,
            "created_utc": 1754043793,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6cry9f",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "entsnack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6byfd6",
                                "score": 1,
                                "author_fullname": "t2_1a48h7vf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Not OpenAI only, works with any local model. Also, it's written in Rust not Typescript.\n\nEdit: This is literally visible in the Github, I don't understand your \"to my knowledge\", can you not read?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6cry9f",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "a": ":X:",
                                    "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                    "e": "emoji"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not OpenAI only, works with any local model. Also, it&amp;#39;s written in Rust not Typescript.&lt;/p&gt;\n\n&lt;p&gt;Edit: This is literally visible in the Github, I don&amp;#39;t understand your &amp;quot;to my knowledge&amp;quot;, can you not read?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1messzq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6cry9f/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754057935,
                                "author_flair_text": ":X:",
                                "treatment_tags": [],
                                "created_utc": 1754057935,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "transparent",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6byfd6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Daemontatox",
                      "can_mod_post": false,
                      "created_utc": 1754047810,
                      "send_replies": true,
                      "parent_id": "t1_n6bsh1e",
                      "score": 1,
                      "author_fullname": "t2_1rm9syq1nb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "To my knowledge, it's written in TypeScript and they are working on rewriting it in Rust, also I think its openai only , while you can choose your models in this one.\n\nI am not comparing them in any way or saying mine is better,  i was just confused why was no tool written in rust when there is a library like ratatui,\nAlso this was meant to be  learning project.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6byfd6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To my knowledge, it&amp;#39;s written in TypeScript and they are working on rewriting it in Rust, also I think its openai only , while you can choose your models in this one.&lt;/p&gt;\n\n&lt;p&gt;I am not comparing them in any way or saying mine is better,  i was just confused why was no tool written in rust when there is a library like ratatui,\nAlso this was meant to be  learning project.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1messzq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6byfd6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754047810,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6bsh1e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "progmboy",
            "can_mod_post": false,
            "created_utc": 1754045121,
            "send_replies": true,
            "parent_id": "t3_1messzq",
            "score": 5,
            "author_fullname": "t2_39xwy19t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "codex?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6bsh1e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;codex?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6bsh1e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754045121,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1messzq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6ckts5",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Daemontatox",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6c0m3z",
                                          "score": 2,
                                          "author_fullname": "t2_1rm9syq1nb",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Tbh my approach would be a little different, I would probably fine-tune a small model like qwen3 1.6b model on rust snippets and project structures,  \nThen when we have a command like cargo build which will download the Rust documentation locally and when there are changes in the code or it can be after a delay the model can document the current project, something like cargo doc to identify all the functions, implementations ...etc, and then fetch data from the documentation and fine-tune the finetune knowledge. \n\nI wanna avoid the use of api calls or mcp and such because i would taking away from the Rust advantages in speed , i want to try the fully local approach first then if all fails , could go for the mcp/online route.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6ckts5",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Tbh my approach would be a little different, I would probably fine-tune a small model like qwen3 1.6b model on rust snippets and project structures,&lt;br/&gt;\nThen when we have a command like cargo build which will download the Rust documentation locally and when there are changes in the code or it can be after a delay the model can document the current project, something like cargo doc to identify all the functions, implementations ...etc, and then fetch data from the documentation and fine-tune the finetune knowledge. &lt;/p&gt;\n\n&lt;p&gt;I wanna avoid the use of api calls or mcp and such because i would taking away from the Rust advantages in speed , i want to try the fully local approach first then if all fails , could go for the mcp/online route.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1messzq",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6ckts5/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754055792,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754055792,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6c0m3z",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "xmBQWugdxjaA",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6bzw4r",
                                "score": 2,
                                "author_fullname": "t2_nyyscwdgr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I want to look at this too, maybe starting with just autocomplete.\n\nBut I only have 1 GPU so I'm stuck with just Starcoder2 for doing any sort of fine-tuning (and even that with QLoRa etc.) - at least in Rust basically all crates are open-source, and blessed.rs has a collection of very high quality code crates.\n\n&gt;  integrated RAG on the other hand will need alot of optimization\n\nI think an MCP / tool use call would work better actually - since for RAG you'd need to know what crates / methods the LLM will want to use given the query / block to complete ahead of time, whereas with an MCP call the model could call into read the docs for the crate and methods it has actually decided to use - when it is writing / verifying its suggestion.\n\nBut yeah there's a real trade-off between validation and speed. That said, there's nothing more annoying than it hallucinating some API or crate that doesn't exist.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6c0m3z",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I want to look at this too, maybe starting with just autocomplete.&lt;/p&gt;\n\n&lt;p&gt;But I only have 1 GPU so I&amp;#39;m stuck with just Starcoder2 for doing any sort of fine-tuning (and even that with QLoRa etc.) - at least in Rust basically all crates are open-source, and blessed.rs has a collection of very high quality code crates.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;integrated RAG on the other hand will need alot of optimization&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I think an MCP / tool use call would work better actually - since for RAG you&amp;#39;d need to know what crates / methods the LLM will want to use given the query / block to complete ahead of time, whereas with an MCP call the model could call into read the docs for the crate and methods it has actually decided to use - when it is writing / verifying its suggestion.&lt;/p&gt;\n\n&lt;p&gt;But yeah there&amp;#39;s a real trade-off between validation and speed. That said, there&amp;#39;s nothing more annoying than it hallucinating some API or crate that doesn&amp;#39;t exist.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1messzq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6c0m3z/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754048716,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754048716,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6bzw4r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Daemontatox",
                      "can_mod_post": false,
                      "created_utc": 1754048422,
                      "send_replies": true,
                      "parent_id": "t1_n6by0ad",
                      "score": 2,
                      "author_fullname": "t2_1rm9syq1nb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I am working on something similar,  finetuning multiple models on idiomatic Rust,  your idea of directly integrating rust analyzer is quite interesting and sounds great tbh , integrated RAG on the other hand will need alot of optimization so it doesn't end up as slow as python.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6bzw4r",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am working on something similar,  finetuning multiple models on idiomatic Rust,  your idea of directly integrating rust analyzer is quite interesting and sounds great tbh , integrated RAG on the other hand will need alot of optimization so it doesn&amp;#39;t end up as slow as python.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1messzq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6bzw4r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754048422,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6by0ad",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "xmBQWugdxjaA",
            "can_mod_post": false,
            "created_utc": 1754047632,
            "send_replies": true,
            "parent_id": "t3_1messzq",
            "score": 3,
            "author_fullname": "t2_nyyscwdgr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'd love to see a Rust specific one - like integrate with rust-analyzer in the agentic loop, provide the LLM context from tree-sitter and rust-analyzer like which symbols are actually available to reference in the current block and the AST, maybe even use the clever rust-analyzer stuff like salsa for partial compilation / verification - e.g. given the above context would this added code actually compile.\n\nSame with integrated RAG (or MCP calls) over docs.rs and the stdlib docs, and crates.io (including migration and deprecation notes).\n\nThe LLMs often make stupid mistakes because they cannot see all of that rich context that is there.\n\nWould also be interesting to compare fine-tuning a smaller model with all of that to learn how to use it vs. just dumping it in the context window of a larger model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6by0ad",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d love to see a Rust specific one - like integrate with rust-analyzer in the agentic loop, provide the LLM context from tree-sitter and rust-analyzer like which symbols are actually available to reference in the current block and the AST, maybe even use the clever rust-analyzer stuff like salsa for partial compilation / verification - e.g. given the above context would this added code actually compile.&lt;/p&gt;\n\n&lt;p&gt;Same with integrated RAG (or MCP calls) over docs.rs and the stdlib docs, and crates.io (including migration and deprecation notes).&lt;/p&gt;\n\n&lt;p&gt;The LLMs often make stupid mistakes because they cannot see all of that rich context that is there.&lt;/p&gt;\n\n&lt;p&gt;Would also be interesting to compare fine-tuning a smaller model with all of that to learn how to use it vs. just dumping it in the context window of a larger model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6by0ad/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754047632,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1messzq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6cflrc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Daemontatox",
                      "can_mod_post": false,
                      "created_utc": 1754054133,
                      "send_replies": true,
                      "parent_id": "t1_n6c1f4q",
                      "score": 2,
                      "author_fullname": "t2_1rm9syq1nb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "thanks for the suggestion , i will take a look into it",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6cflrc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thanks for the suggestion , i will take a look into it&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1messzq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6cflrc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754054133,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6c1f4q",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "xmBQWugdxjaA",
            "can_mod_post": false,
            "created_utc": 1754049042,
            "send_replies": true,
            "parent_id": "t3_1messzq",
            "score": 2,
            "author_fullname": "t2_nyyscwdgr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Since you already assume the presence of sh, etc. - if you're willing to target Linux alone, you could add the use of user and mount namespaces for automatic isolation to the current directory (it might also be possible to use firejail to manage this a bit easier, but doing it manually isn't too bad).\n\nThis could be a good USP - and it's very lightweight and easy to do on Linux compared to messing around with Docker volumes and containers on Mac.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6c1f4q",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Since you already assume the presence of sh, etc. - if you&amp;#39;re willing to target Linux alone, you could add the use of user and mount namespaces for automatic isolation to the current directory (it might also be possible to use firejail to manage this a bit easier, but doing it manually isn&amp;#39;t too bad).&lt;/p&gt;\n\n&lt;p&gt;This could be a good USP - and it&amp;#39;s very lightweight and easy to do on Linux compared to messing around with Docker volumes and containers on Mac.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6c1f4q/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754049042,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1messzq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6d6y6l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fearless-Elephant-81",
            "can_mod_post": false,
            "created_utc": 1754062242,
            "send_replies": true,
            "parent_id": "t3_1messzq",
            "score": 1,
            "author_fullname": "t2_rvsve0lsh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Warp",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6d6y6l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Warp&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1messzq/built_a_rust_terminal_ai_coding_assistant/n6d6y6l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754062242,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1messzq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]