[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I couldn't find any extensive benchmarks when researching this APU, so I'm sharing my findings with the community.\n\nThe benchmarks with the iGPU 760M results \\~35% faster than the CPU alone (see the tests below, with ngl 0, no layers offloaded to the GPU), the prompt processing is also faster, and it appears to produce less heat.\n\nIt allows me to chat with Gemma 3 27B at \\~5 tokens per second (t/s), and Qwen 3 30B-A3B works at around 35 t/s.\n\nSo it's not a 3090, a Mac, or a Strix Halo, obviously, but gives access to these models without being power-hungry, expensive, and it's widely available.\n\nAnother thing I was looking for was how it compared to my Steam Deck. Apparently, with LLMs, the 8600G is about twice as fast.\n\nNote 1: if you have in mind a gaming PC, unless you just want a small machine with only the APU, a regular 7600 or 9600 has more cache, PCIe lanes, and PCIe 5 support. However, the 8600G is still faster at 1080p with games than the Steam Deck at 800p. So, well, it's usable for light gaming and doesn't consume too much power, but it's not the best choice for a gaming PC.\n\nNote 2: there are mini-PCs with similar AMD APUs; however, if you have enough space, a desktop case offers better cooling and is probably quieter. Plus, if you want to add a GPU, mini-PCs require complex and costly eGPU setups (when the option is available), while with a desktop PC it's straightforward (even though the 8600G is lane-limited, so still not the ideal).\n\nNote 3: the 8700G comes with a better cooler (though still mediocre), a slightly better iGPU (but only about 10% faster in games, and the difference for LLMs is likely negligible), and two extra cores; however, it's definitively more expensive.\n\n=== Setup and notes ===\n\n    OS: Kubuntu 24.04\n    RAM: 64GB DDR5-6000\n    IOMMU: disabled\n\nApparently, **IOMMU** slows it down noticeably:\n\n    Gemma 3 4B   pp512 tg12\n    IOMMU off =  ~395  32.70\n    IOMMU on  =  ~360  29.6\n\nHence, the following benchmarks are with IOMMU disabled.\n\nThe 8600G default is 65W, but **at 35W it loses very little performance**:\n\n    Gemma 3 4B  pp512  tg12\n     65W  =     ~395  32.70\n     35W  =     ~372  31.86\n\nAlso the stock fan seems better suited for the APU set at 35W. At 65W it could still barely handle the CPU-only Gemma3-12B benchmark (at least in my airflow case), but it thermal-throttles with larger models.\n\nAnyway, for consistency, the following tests are at 65W and I limited the CPU-only tests to the smaller models.\n\nBenchmarks:\n\n    llama.cpp build: 01612b74 (5922)\n    ggml_vulkan: 0 = AMD Radeon Graphics (RADV GFX1103_R1) (radv) | uma: 1 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat\n    \n    backend: RPC, Vulcan\n    \n    === Gemma 3 q4_0_QAT (by stduhpf)\n    | model                          |      size |  params | ngl |  test |           t/s\n    | ------------------------------ | --------: | ------: | --: | ----: | ------------:\n    (4B, iGPU 760M)\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp128 | 378.02 ± 1.44\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp256 | 396.18 ± 1.88\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp512 | 395.16 ± 1.79\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | tg128 |  32.70 ± 0.04\n    (4B, CPU)\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |   0 | pp512 | 313.53 ± 2.00\n    | gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |   0 | tg128 |  24.09 ± 0.02\n    (12B, iGPU 760M)\n    | gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |  99 | pp512 | 121.56 ± 0.18\n    | gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |  99 | tg128 |  11.45 ± 0.03\n    (12B, CPU)\n    | gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |   0 | pp512 |  98.25 ± 0.52\n    | gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |   0 | tg128 |   8.39 ± 0.01\n    (27B, iGPU 760M)\n    | gemma3 27B Q4_0                | 14.49 GiB | 27.01 B |  99 | pp512 |  52.22 ± 0.01\n    | gemma3 27B Q4_0                | 14.49 GiB | 27.01 B |  99 | tg128 |   5.37 ± 0.01\n    \n    === Mistral Small (24B) 3.2 2506 (UD-Q4_K_XL by unsloth)\n    | model                          |       size |   params |  test |            t/s\n    | ------------------------------ | ---------: | -------: | ----: | -------------:\n    | llama 13B Q4_K - Medium        |  13.50 GiB |  23.57 B | pp512 |   52.49 ± 0.04\n    | llama 13B Q4_K - Medium        |  13.50 GiB |  23.57 B | tg128 |    5.90 ± 0.00\n      [oddly, it's identified as \"llama 13B\"]\n    \n    === Qwen 3\n    | model                          |       size |   params |  test |            t/s\n    | ------------------------------ | ---------: | -------: | ----: | -------------:\n    (4B Q4_K_L by Bartowski)\n    | qwen3 4B Q4_K - Medium         |   2.41 GiB |   4.02 B | pp512 |  299.86 ± 0.44\n    | qwen3 4B Q4_K - Medium         |   2.41 GiB |   4.02 B | tg128 |   29.91 ± 0.03\n    (8B Q4 Q4_K_M by unsloth)\n    | qwen3 8B Q4_K - Medium         |   4.68 GiB |   8.19 B | pp512 |  165.73 ± 0.13\n    | qwen3 8B Q4_K - Medium         |   4.68 GiB |   8.19 B | tg128 |   17.75 ± 0.01\n      [Note: UD-Q4_K_XL by unsloth is only slightly slower with pp512 164.68 ± 0.20, tg128 16.84 ± 0.01]\n    (8B Q6 UD-Q6_K_XL by unsloth)\n    | qwen3 8B Q6_K                  |   6.97 GiB |   8.19 B | pp512 |  167.45 ± 0.14\n    | qwen3 8B Q6_K                  |   6.97 GiB |   8.19 B | tg128 |   12.45 ± 0.00\n    (8B Q8_0 by unsloth)\n    | qwen3 8B Q8_0                  |   8.11 GiB |   8.19 B | pp512 |  177.91 ± 0.13\n    | qwen3 8B Q8_0                  |   8.11 GiB |   8.19 B | tg128 |   10.66 ± 0.00\n    (14B UD-Q4_K_XL by unsloth)\n    | qwen3 14B Q4_K - Medium        |   8.53 GiB |  14.77 B | pp512 |   87.37 ± 0.14\n    | qwen3 14B Q4_K - Medium        |   8.53 GiB |  14.77 B | tg128 |    9.39 ± 0.01\n    (32B Q4_K_L by Bartowski)\n    | qwen3 32B Q4_K - Medium        |  18.94 GiB |  32.76 B | pp512 |   36.64 ± 0.02\n    | qwen3 32B Q4_K - Medium        |  18.94 GiB |  32.76 B | tg128 |    4.36 ± 0.00\n    \n    === Qwen 3 30B-A3B MoE (UD-Q4_K_XL by unsloth)\n    | model                          |       size |   params |  test |            t/s\n    | ------------------------------ | ---------: | -------: | ----: | -------------:\n    | qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |  30.53 B | pp512 |   83.43 ± 0.35\n    | qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |  30.53 B | tg128 |   34.77 ± 0.27",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "8600G / 760M llama-bench with Gemma 3 (4, 12, 27B), Mistral Small, Qwen 3 (4, 8, 14, 32B) and  Qwen 3 MoE 30B-A3B",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbs4dw",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.94,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 36,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_x2g8r3neo",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 36,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753736142,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t find any extensive benchmarks when researching this APU, so I&amp;#39;m sharing my findings with the community.&lt;/p&gt;\n\n&lt;p&gt;The benchmarks with the iGPU 760M results ~35% faster than the CPU alone (see the tests below, with ngl 0, no layers offloaded to the GPU), the prompt processing is also faster, and it appears to produce less heat.&lt;/p&gt;\n\n&lt;p&gt;It allows me to chat with Gemma 3 27B at ~5 tokens per second (t/s), and Qwen 3 30B-A3B works at around 35 t/s.&lt;/p&gt;\n\n&lt;p&gt;So it&amp;#39;s not a 3090, a Mac, or a Strix Halo, obviously, but gives access to these models without being power-hungry, expensive, and it&amp;#39;s widely available.&lt;/p&gt;\n\n&lt;p&gt;Another thing I was looking for was how it compared to my Steam Deck. Apparently, with LLMs, the 8600G is about twice as fast.&lt;/p&gt;\n\n&lt;p&gt;Note 1: if you have in mind a gaming PC, unless you just want a small machine with only the APU, a regular 7600 or 9600 has more cache, PCIe lanes, and PCIe 5 support. However, the 8600G is still faster at 1080p with games than the Steam Deck at 800p. So, well, it&amp;#39;s usable for light gaming and doesn&amp;#39;t consume too much power, but it&amp;#39;s not the best choice for a gaming PC.&lt;/p&gt;\n\n&lt;p&gt;Note 2: there are mini-PCs with similar AMD APUs; however, if you have enough space, a desktop case offers better cooling and is probably quieter. Plus, if you want to add a GPU, mini-PCs require complex and costly eGPU setups (when the option is available), while with a desktop PC it&amp;#39;s straightforward (even though the 8600G is lane-limited, so still not the ideal).&lt;/p&gt;\n\n&lt;p&gt;Note 3: the 8700G comes with a better cooler (though still mediocre), a slightly better iGPU (but only about 10% faster in games, and the difference for LLMs is likely negligible), and two extra cores; however, it&amp;#39;s definitively more expensive.&lt;/p&gt;\n\n&lt;p&gt;=== Setup and notes ===&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;OS: Kubuntu 24.04\nRAM: 64GB DDR5-6000\nIOMMU: disabled\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Apparently, &lt;strong&gt;IOMMU&lt;/strong&gt; slows it down noticeably:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Gemma 3 4B   pp512 tg12\nIOMMU off =  ~395  32.70\nIOMMU on  =  ~360  29.6\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Hence, the following benchmarks are with IOMMU disabled.&lt;/p&gt;\n\n&lt;p&gt;The 8600G default is 65W, but &lt;strong&gt;at 35W it loses very little performance&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Gemma 3 4B  pp512  tg12\n 65W  =     ~395  32.70\n 35W  =     ~372  31.86\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Also the stock fan seems better suited for the APU set at 35W. At 65W it could still barely handle the CPU-only Gemma3-12B benchmark (at least in my airflow case), but it thermal-throttles with larger models.&lt;/p&gt;\n\n&lt;p&gt;Anyway, for consistency, the following tests are at 65W and I limited the CPU-only tests to the smaller models.&lt;/p&gt;\n\n&lt;p&gt;Benchmarks:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;llama.cpp build: 01612b74 (5922)\nggml_vulkan: 0 = AMD Radeon Graphics (RADV GFX1103_R1) (radv) | uma: 1 | fp16: 1 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat\n\nbackend: RPC, Vulcan\n\n=== Gemma 3 q4_0_QAT (by stduhpf)\n| model                          |      size |  params | ngl |  test |           t/s\n| ------------------------------ | --------: | ------: | --: | ----: | ------------:\n(4B, iGPU 760M)\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp128 | 378.02 ± 1.44\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp256 | 396.18 ± 1.88\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | pp512 | 395.16 ± 1.79\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |  99 | tg128 |  32.70 ± 0.04\n(4B, CPU)\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |   0 | pp512 | 313.53 ± 2.00\n| gemma3 4B Q4_0                 |  2.19 GiB |  3.88 B |   0 | tg128 |  24.09 ± 0.02\n(12B, iGPU 760M)\n| gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |  99 | pp512 | 121.56 ± 0.18\n| gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |  99 | tg128 |  11.45 ± 0.03\n(12B, CPU)\n| gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |   0 | pp512 |  98.25 ± 0.52\n| gemma3 12B Q4_0                |  6.41 GiB | 11.77 B |   0 | tg128 |   8.39 ± 0.01\n(27B, iGPU 760M)\n| gemma3 27B Q4_0                | 14.49 GiB | 27.01 B |  99 | pp512 |  52.22 ± 0.01\n| gemma3 27B Q4_0                | 14.49 GiB | 27.01 B |  99 | tg128 |   5.37 ± 0.01\n\n=== Mistral Small (24B) 3.2 2506 (UD-Q4_K_XL by unsloth)\n| model                          |       size |   params |  test |            t/s\n| ------------------------------ | ---------: | -------: | ----: | -------------:\n| llama 13B Q4_K - Medium        |  13.50 GiB |  23.57 B | pp512 |   52.49 ± 0.04\n| llama 13B Q4_K - Medium        |  13.50 GiB |  23.57 B | tg128 |    5.90 ± 0.00\n  [oddly, it&amp;#39;s identified as &amp;quot;llama 13B&amp;quot;]\n\n=== Qwen 3\n| model                          |       size |   params |  test |            t/s\n| ------------------------------ | ---------: | -------: | ----: | -------------:\n(4B Q4_K_L by Bartowski)\n| qwen3 4B Q4_K - Medium         |   2.41 GiB |   4.02 B | pp512 |  299.86 ± 0.44\n| qwen3 4B Q4_K - Medium         |   2.41 GiB |   4.02 B | tg128 |   29.91 ± 0.03\n(8B Q4 Q4_K_M by unsloth)\n| qwen3 8B Q4_K - Medium         |   4.68 GiB |   8.19 B | pp512 |  165.73 ± 0.13\n| qwen3 8B Q4_K - Medium         |   4.68 GiB |   8.19 B | tg128 |   17.75 ± 0.01\n  [Note: UD-Q4_K_XL by unsloth is only slightly slower with pp512 164.68 ± 0.20, tg128 16.84 ± 0.01]\n(8B Q6 UD-Q6_K_XL by unsloth)\n| qwen3 8B Q6_K                  |   6.97 GiB |   8.19 B | pp512 |  167.45 ± 0.14\n| qwen3 8B Q6_K                  |   6.97 GiB |   8.19 B | tg128 |   12.45 ± 0.00\n(8B Q8_0 by unsloth)\n| qwen3 8B Q8_0                  |   8.11 GiB |   8.19 B | pp512 |  177.91 ± 0.13\n| qwen3 8B Q8_0                  |   8.11 GiB |   8.19 B | tg128 |   10.66 ± 0.00\n(14B UD-Q4_K_XL by unsloth)\n| qwen3 14B Q4_K - Medium        |   8.53 GiB |  14.77 B | pp512 |   87.37 ± 0.14\n| qwen3 14B Q4_K - Medium        |   8.53 GiB |  14.77 B | tg128 |    9.39 ± 0.01\n(32B Q4_K_L by Bartowski)\n| qwen3 32B Q4_K - Medium        |  18.94 GiB |  32.76 B | pp512 |   36.64 ± 0.02\n| qwen3 32B Q4_K - Medium        |  18.94 GiB |  32.76 B | tg128 |    4.36 ± 0.00\n\n=== Qwen 3 30B-A3B MoE (UD-Q4_K_XL by unsloth)\n| model                          |       size |   params |  test |            t/s\n| ------------------------------ | ---------: | -------: | ----: | -------------:\n| qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |  30.53 B | pp512 |   83.43 ± 0.35\n| qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |  30.53 B | tg128 |   34.77 ± 0.27\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mbs4dw",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "SunRayWhisper",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbs4dw/8600g_760m_llamabench_with_gemma_3_4_12_27b/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbs4dw/8600g_760m_llamabench_with_gemma_3_4_12_27b/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753736142,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ouldi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "yeah-ok",
            "can_mod_post": false,
            "created_utc": 1753740969,
            "send_replies": true,
            "parent_id": "t3_1mbs4dw",
            "score": 1,
            "author_fullname": "t2_3xlrs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Amazing! Thanks so much for putting some numbers to a relatively affordable gaming CPU, long been wondering if the iGPU could help accelerate things or not (I'm on a older gen 11 intel laptop and here using the igpu simply slows things down). This makes me very curious about the 8700g which offers upgrade with 2 more CPU cores and a faster iGPU to boot.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ouldi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Amazing! Thanks so much for putting some numbers to a relatively affordable gaming CPU, long been wondering if the iGPU could help accelerate things or not (I&amp;#39;m on a older gen 11 intel laptop and here using the igpu simply slows things down). This makes me very curious about the 8700g which offers upgrade with 2 more CPU cores and a faster iGPU to boot.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbs4dw/8600g_760m_llamabench_with_gemma_3_4_12_27b/n5ouldi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753740969,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbs4dw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5oz4vd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "henfiber",
            "can_mod_post": false,
            "created_utc": 1753742443,
            "send_replies": true,
            "parent_id": "t3_1mbs4dw",
            "score": 1,
            "author_fullname": "t2_lw9me25",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It's baffling to me why Qwen 30b-a3b is so much slow in PP t/s with Vulkan (at least in APUs).\n\nI mean, if you run it only with your CPU you will get similar or better numbers (you may test with `GGML_VK_VISIBLE_DEVICES=none llama-bench -m ...`).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5oz4vd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s baffling to me why Qwen 30b-a3b is so much slow in PP t/s with Vulkan (at least in APUs).&lt;/p&gt;\n\n&lt;p&gt;I mean, if you run it only with your CPU you will get similar or better numbers (you may test with &lt;code&gt;GGML_VK_VISIBLE_DEVICES=none llama-bench -m ...&lt;/code&gt;).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbs4dw/8600g_760m_llamabench_with_gemma_3_4_12_27b/n5oz4vd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753742443,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbs4dw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]