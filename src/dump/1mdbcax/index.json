[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I want to use Qwen3-14B-AWQ (4 bit quantization) for paraphrasing sentences without diluting context; even though this is a simple task, the LLM often starts with phrases like \"I will paraphrase the sentence...\".  Despite using:\n\n`temperature=0.0`\n\n`top_p = 0.8`\n\n`top_k = 20`\n\nabout \\~20% of the sentences I pick for a sanity check (i.e. generate 300 select 30 to verify) are not generated properly. Note that I'm using vLLM and the prompt is:  \n\n\n&gt;prompt = (\n\n&gt;'Rewrite the StudentExplanation as one sentence. '\n\n&gt;'Return only that sentence - no labels, quotes, or extra text. '\n\n&gt;'The sentence must not include the words: '\n\n&gt;'rephrase, paraphrase, phrase, think, rewrite, I, we, or any mention of the rules.\\\\n'\n\n&gt;'RULES:\\\\n'\n\n&gt;'1. Keep the original meaning; do not correct mathematics.\\\\n'\n\n&gt;'2. Keep the length within 20 percent of the original.\\\\n'\n\n&gt;'3. Keep every number exactly as written.\\\\n'\n\n&gt;'4. Do not copy the original sentence verbatim.\\\\n'\n\n&gt;'EXAMPLES:\\\\n'\n\n&gt;'Original: 2 x 5 is 10 so its 10/3 and 10/3 is also 3 1/3.\\\\n'\n\n&gt;'Acceptable: 2 times 5 equals 10, giving 10/3, which is the same as 3 1/3.\\\\n'\n\n&gt;'Unacceptable: To rephrase the given sentence, I need to...\\\\n'\n\n&gt;'StudentExplanation:\\\\n'\n\n&gt;'{explanation}\\\\n'\n\n&gt;'Rewrite:'\n\n&gt;)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How to make LLMs follow instructions without deviating?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Generation"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdbcax",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.6,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_10vfc5m6o1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Generation",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753893220,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use Qwen3-14B-AWQ (4 bit quantization) for paraphrasing sentences without diluting context; even though this is a simple task, the LLM often starts with phrases like &amp;quot;I will paraphrase the sentence...&amp;quot;.  Despite using:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;temperature=0.0&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;top_p = 0.8&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;top_k = 20&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;about ~20% of the sentences I pick for a sanity check (i.e. generate 300 select 30 to verify) are not generated properly. Note that I&amp;#39;m using vLLM and the prompt is:  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;prompt = (&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Rewrite the StudentExplanation as one sentence. &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Return only that sentence - no labels, quotes, or extra text. &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;The sentence must not include the words: &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;rephrase, paraphrase, phrase, think, rewrite, I, we, or any mention of the rules.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;RULES:\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;1. Keep the original meaning; do not correct mathematics.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;2. Keep the length within 20 percent of the original.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;3. Keep every number exactly as written.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;4. Do not copy the original sentence verbatim.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;EXAMPLES:\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Original: 2 x 5 is 10 so its 10/3 and 10/3 is also 3 1/3.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Acceptable: 2 times 5 equals 10, giving 10/3, which is the same as 3 1/3.\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Unacceptable: To rephrase the given sentence, I need to...\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;StudentExplanation:\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;{explanation}\\n&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;Rewrite:&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "23bddba8-ff56-11ed-9688-1a11994b71f7",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#b5a3d0",
            "id": "1mdbcax",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "TechNerd10191",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdbcax/how_to_make_llms_follow_instructions_without/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdbcax/how_to_make_llms_follow_instructions_without/",
            "subreddit_subscribers": 507574,
            "created_utc": 1753893220,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n60hnf4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "llmentry",
            "can_mod_post": false,
            "created_utc": 1753896196,
            "send_replies": true,
            "parent_id": "t3_1mdbcax",
            "score": 7,
            "author_fullname": "t2_1lufy6yx6z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You're using a low-param, low resolution model, so I'd be as clear as possible.  I'd suggest giving examples in the classic one-shot / few-shot format, e.g.\n\nUser: 2 x 5 is 10 so its 10/3 and 10/3 is also 3 1/3.  \nModel: 2 times 5 equals 10, giving 10/3, which is the same as 3 1/3.\n\nDon't write an \"Unacceptable:\" answer (which the model might start using).  Just provide some more User/Model examples.\n\nI'd also suggest giving Gemma-12B a try.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n60hnf4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re using a low-param, low resolution model, so I&amp;#39;d be as clear as possible.  I&amp;#39;d suggest giving examples in the classic one-shot / few-shot format, e.g.&lt;/p&gt;\n\n&lt;p&gt;User: 2 x 5 is 10 so its 10/3 and 10/3 is also 3 1/3.&lt;br/&gt;\nModel: 2 times 5 equals 10, giving 10/3, which is the same as 3 1/3.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t write an &amp;quot;Unacceptable:&amp;quot; answer (which the model might start using).  Just provide some more User/Model examples.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also suggest giving Gemma-12B a try.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdbcax/how_to_make_llms_follow_instructions_without/n60hnf4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753896196,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdbcax",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n60mkmy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AutomataManifold",
            "can_mod_post": false,
            "created_utc": 1753897511,
            "send_replies": true,
            "parent_id": "t3_1mdbcax",
            "score": 1,
            "author_fullname": "t2_bfs5bk7y8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you absolutely need to cut out the preamble, structured inference is the most effective way to go. Just prevent it from ever writing the non-relevant part using Outlines or Instructor or whatever guidance. Maximum quality would be to generate the answer freeform and then extract it with a structured prompt.\n\nA cheap, fast way to do this without guidance is to prefill the assistant reply with, in your case, `Rewrite:` which skips to the part of the output that you want.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n60mkmy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you absolutely need to cut out the preamble, structured inference is the most effective way to go. Just prevent it from ever writing the non-relevant part using Outlines or Instructor or whatever guidance. Maximum quality would be to generate the answer freeform and then extract it with a structured prompt.&lt;/p&gt;\n\n&lt;p&gt;A cheap, fast way to do this without guidance is to prefill the assistant reply with, in your case, &lt;code&gt;Rewrite:&lt;/code&gt; which skips to the part of the output that you want.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdbcax/how_to_make_llms_follow_instructions_without/n60mkmy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753897511,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdbcax",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n62capb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SuckaRichardson",
            "can_mod_post": false,
            "created_utc": 1753915295,
            "send_replies": true,
            "parent_id": "t3_1mdbcax",
            "score": 1,
            "author_fullname": "t2_1kt1mgrg4b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "How do I makes my lell lell lumm not tell me lies mommy? ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62capb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How do I makes my lell lell lumm not tell me lies mommy? &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdbcax/how_to_make_llms_follow_instructions_without/n62capb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753915295,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdbcax",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]