[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi everyone,\n\nLast year I posted about 2x MI60 performance. Since then, I bought more cards and PCIE riser cables to build a rack with 8x AMD MI50 32GB cards. My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).\n\nI connected 4x MI50 cards using ASUS Hyper M.2 x16 Gen5 Card (PCIE4.0 x16 to 4xM.2 card then I used M.2 to PCIE4.0 cables to connect 4 GPUs) through the first PCIE4.0 x16 slot on the motherboard that supports 4x4 bifurcation. I set the PCIE to use PCIE3.0 so that I don't get occasional freezing issues in my system. Each card was running at PCIE3.0 x4 (later I also tested 2x MI50s with PCIE4.0 x8 speed and did not see any PP/TG speed difference).\n\nI am using 1.2A blower fans to cool these cards which are a bit noisy at max speed but I adjusted their speeds to be acceptable.\n\nI have tested both llama.cpp (ROCm 6.3.4 and vulkan backend) and vLLM v0.9.2 in Ubuntu 24.04.02. Below are some results.\n\nNote that MI50/60 cards do not have matrix or tensor cores and that is why their Prompt Processing (PP) speed is not great. But Text Generation (TG) speeds are great!\n\nLlama.cpp (build: 247e5c6e (5606)) with ROCm 6.3.4. All of the runs use one MI50 (I will note the ones that use 2x or 4x MI50 in the model column). Note that MI50/60 cards perform best with Q4\\_0 and Q4\\_1 quantizations (that is why I ran larger models with those Quants).\n\n|Model|size|test|t/s|\n|:-|:-|:-|:-|\n|qwen3 0.6B Q8\\_0|604.15 MiB|pp1024|3014.18 ± 1.71|\n|qwen3 0.6B Q8\\_0|604.15 MiB|tg128|191.63 ± 0.38|\n|llama 7B Q4\\_0|3.56 GiB|pp512|1289.11 ± 0.62|\n|llama 7B Q4\\_0|3.56 GiB|tg128|91.46 ± 0.13|\n|qwen3 8B Q8\\_0|8.11 GiB|pp512|357.71 ± 0.04|\n|qwen3 8B Q8\\_0|8.11 GiB|tg128|48.09 ± 0.04|\n|qwen2 14B Q8\\_0|14.62 GiB|pp512|249.45 ± 0.08|\n|qwen2 14B Q8\\_0|14.62 GiB|tg128|29.24 ± 0.03|\n|qwen2 32B Q4\\_0|17.42 GiB|pp512|300.02 ± 0.52|\n|qwen2 32B Q4\\_0|17.42 GiB|tg128|20.39 ± 0.37|\n|qwen2 70B Q5\\_K - Medium|50.70 GiB|pp512|48.92 ± 0.02|\n|qwen2 70B Q5\\_K - Medium|50.70 GiB|tg128|9.05 ± 0.10|\n|qwen2vl 70B Q4\\_1 (4x MI50 row split)|42.55 GiB|pp512|56.33 ± 0.09|\n|qwen2vl 70B Q4\\_1 (4x MI50 row split)|42.55 GiB|tg128|16.00 ± 0.01|\n|qwen3moe 30B.A3B Q4\\_1|17.87 GiB|pp1024|1023.81 ± 3.76|\n|qwen3moe 30B.A3B Q4\\_1|17.87 GiB|tg128|63.87 ± 0.06|\n|qwen3 32B Q4\\_1 (2x MI50)|19.21 GiB|pp1024|238.17 ± 0.30|\n|qwen3 32B Q4\\_1 (2x MI50)|19.21 GiB|tg128|25.17 ± 0.01|\n|qwen3moe 235B.A22B Q4\\_1 (5x MI50)|137.11 GiB|pp1024|202.50 ± 0.32|\n|qwen3moe 235B.A22B Q4\\_1 (5x MI50) (4x mi50 with some expert offloading should give around 16t/s)|137.11 GiB|tg128|19.17 ± 0.04|\n\nPP is not great but TG is very good for most use cases. \n\nBy the way, I also tested Deepseek R1 IQ2-XXS (although it was running with 6x MI50) and I was getting \\~9 t/s for TG with a few experts offloaded to CPU RAM.\n\nNow, let's look at vllm (version 0.9.2.dev1+g5273453b6. Fork used: https://github.com/nlzy/vllm-gfx906).\n\nAWQ and GPTQ quants are supported. For gptq models, desc\\_act=false quants are used to get a better performance. Max concurrency is set to 1.\n\n|Model|Output token throughput (tok/s) (256)|Prompt processing  t/s (4096)|\n|:-|:-|:-|\n|Mistral-Large-Instruct-2407-AWQ 123B (4x MI50)|19.68|80|\n|Qwen2.5-72B-Instruct-GPTQ-Int4 (2x MI50)|19.76|130|\n|Qwen2.5-72B-Instruct-GPTQ-Int4 (4x MI50)|25.96|130|\n|Llama-3.3-70B-Instruct-AWQ (4x MI50)|27.26|130|\n|Qwen3-32B-GPTQ-Int8 (4x MI50)|32.3|230|\n|Qwen3-32B-autoround-4bit-gptq (4x MI50)|38.55|230|\n|gemma-3-27b-it-int4-awq (4x MI50)|36.96|350|\n\n  \nTensor parallelism (TP) gives MI50s extra performance in Text Generation (TG). Overall, great performance for the price. And I am sure we will not get 128GB VRAM with such TG speeds any time soon for \\~$600.\n\nPower consumption is around 900W for the system when using vllm with TP during text generation. Llama.cpp does not use TP so I did not see it using above 500W. Each GPU runs at around 18W when idle.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "128GB VRAM for ~$600. Qwen3 MOE 235B.A22B reaching 20 t/s. 4x AMD MI50 32GB.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lspzn3",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 199,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_3zy7pnf1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 199,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751767150,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Last year I posted about 2x MI60 performance. Since then, I bought more cards and PCIE riser cables to build a rack with 8x AMD MI50 32GB cards. My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).&lt;/p&gt;\n\n&lt;p&gt;I connected 4x MI50 cards using ASUS Hyper M.2 x16 Gen5 Card (PCIE4.0 x16 to 4xM.2 card then I used M.2 to PCIE4.0 cables to connect 4 GPUs) through the first PCIE4.0 x16 slot on the motherboard that supports 4x4 bifurcation. I set the PCIE to use PCIE3.0 so that I don&amp;#39;t get occasional freezing issues in my system. Each card was running at PCIE3.0 x4 (later I also tested 2x MI50s with PCIE4.0 x8 speed and did not see any PP/TG speed difference).&lt;/p&gt;\n\n&lt;p&gt;I am using 1.2A blower fans to cool these cards which are a bit noisy at max speed but I adjusted their speeds to be acceptable.&lt;/p&gt;\n\n&lt;p&gt;I have tested both llama.cpp (ROCm 6.3.4 and vulkan backend) and vLLM v0.9.2 in Ubuntu 24.04.02. Below are some results.&lt;/p&gt;\n\n&lt;p&gt;Note that MI50/60 cards do not have matrix or tensor cores and that is why their Prompt Processing (PP) speed is not great. But Text Generation (TG) speeds are great!&lt;/p&gt;\n\n&lt;p&gt;Llama.cpp (build: 247e5c6e (5606)) with ROCm 6.3.4. All of the runs use one MI50 (I will note the ones that use 2x or 4x MI50 in the model column). Note that MI50/60 cards perform best with Q4_0 and Q4_1 quantizations (that is why I ran larger models with those Quants).&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;size&lt;/th&gt;\n&lt;th align=\"left\"&gt;test&lt;/th&gt;\n&lt;th align=\"left\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 0.6B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;604.15 MiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;3014.18 ± 1.71&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 0.6B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;604.15 MiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;191.63 ± 0.38&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;llama 7B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;3.56 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;1289.11 ± 0.62&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;llama 7B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;3.56 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;91.46 ± 0.13&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 8B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;8.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;357.71 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 8B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;8.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;48.09 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 14B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.62 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;249.45 ± 0.08&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 14B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.62 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;29.24 ± 0.03&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 32B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.42 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;300.02 ± 0.52&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 32B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.42 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;20.39 ± 0.37&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 70B Q5_K - Medium&lt;/td&gt;\n&lt;td align=\"left\"&gt;50.70 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;48.92 ± 0.02&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 70B Q5_K - Medium&lt;/td&gt;\n&lt;td align=\"left\"&gt;50.70 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;9.05 ± 0.10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2vl 70B Q4_1 (4x MI50 row split)&lt;/td&gt;\n&lt;td align=\"left\"&gt;42.55 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;56.33 ± 0.09&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2vl 70B Q4_1 (4x MI50 row split)&lt;/td&gt;\n&lt;td align=\"left\"&gt;42.55 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;16.00 ± 0.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 30B.A3B Q4_1&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.87 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;1023.81 ± 3.76&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 30B.A3B Q4_1&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.87 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;63.87 ± 0.06&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 32B Q4_1 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.21 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;238.17 ± 0.30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 32B Q4_1 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.21 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;25.17 ± 0.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 235B.A22B Q4_1 (5x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;137.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;202.50 ± 0.32&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 235B.A22B Q4_1 (5x MI50) (4x mi50 with some expert offloading should give around 16t/s)&lt;/td&gt;\n&lt;td align=\"left\"&gt;137.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.17 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;PP is not great but TG is very good for most use cases. &lt;/p&gt;\n\n&lt;p&gt;By the way, I also tested Deepseek R1 IQ2-XXS (although it was running with 6x MI50) and I was getting ~9 t/s for TG with a few experts offloaded to CPU RAM.&lt;/p&gt;\n\n&lt;p&gt;Now, let&amp;#39;s look at vllm (version 0.9.2.dev1+g5273453b6. Fork used: &lt;a href=\"https://github.com/nlzy/vllm-gfx906\"&gt;https://github.com/nlzy/vllm-gfx906&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;AWQ and GPTQ quants are supported. For gptq models, desc_act=false quants are used to get a better performance. Max concurrency is set to 1.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Output token throughput (tok/s) (256)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Prompt processing  t/s (4096)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Mistral-Large-Instruct-2407-AWQ 123B (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.68&lt;/td&gt;\n&lt;td align=\"left\"&gt;80&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen2.5-72B-Instruct-GPTQ-Int4 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.76&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen2.5-72B-Instruct-GPTQ-Int4 (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;25.96&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Llama-3.3-70B-Instruct-AWQ (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;27.26&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen3-32B-GPTQ-Int8 (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;32.3&lt;/td&gt;\n&lt;td align=\"left\"&gt;230&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen3-32B-autoround-4bit-gptq (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;38.55&lt;/td&gt;\n&lt;td align=\"left\"&gt;230&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;gemma-3-27b-it-int4-awq (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;36.96&lt;/td&gt;\n&lt;td align=\"left\"&gt;350&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Tensor parallelism (TP) gives MI50s extra performance in Text Generation (TG). Overall, great performance for the price. And I am sure we will not get 128GB VRAM with such TG speeds any time soon for ~$600.&lt;/p&gt;\n\n&lt;p&gt;Power consumption is around 900W for the system when using vllm with TP during text generation. Llama.cpp does not use TP so I did not see it using above 500W. Each GPU runs at around 18W when idle.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?auto=webp&amp;s=8c340ab5ae3eebd3a1f3a8e634fa1bb0cf891fee",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4c9f1d82654452ab9abf4c2dfaa69dd9495bbf",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=87b01812b7fbad8b7970e973412d609dc1ebcd54",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dfcdc7e43c5456819743e8f71d12c77ef8db87a",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6166a63e8cec75d08489356905b0d102369f198e",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1c7db1463f9c600c11ea411ad404650ada2e07e",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b47148bbb6b2e8e0e6fb909a8a087abbf287326e",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lspzn3",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "MLDataScientist",
            "discussion_type": null,
            "num_comments": 47,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/",
            "subreddit_subscribers": 494986,
            "created_utc": 1751767150,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1kzb6e",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751775079,
                      "send_replies": true,
                      "parent_id": "t1_n1khzoo",
                      "score": 3,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for sharing! Unfortunately, ik-llama does not support AMD GPUs. But they are working on vulkan support. So, there is hope for that in the future.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1kzb6e",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for sharing! Unfortunately, ik-llama does not support AMD GPUs. But they are working on vulkan support. So, there is hope for that in the future.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kzb6e/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751775079,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1kpdmg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "My_Unbiased_Opinion",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1klbbr",
                                "score": 2,
                                "author_fullname": "t2_esiyl0yb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks. Fixed it as well. ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1kpdmg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks. Fixed it as well. &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kpdmg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751770638,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751770638,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1klbbr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "natufian",
                      "can_mod_post": false,
                      "created_utc": 1751768925,
                      "send_replies": true,
                      "parent_id": "t1_n1khzoo",
                      "score": 3,
                      "author_fullname": "t2_65uig",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "[Fixed Linky](https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1klbbr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\"&gt;Fixed Linky&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1klbbr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751768925,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n1lrq5n",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "No-Refrigerator-1672",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n1lpvyc",
                                          "score": 2,
                                          "author_fullname": "t2_baavelp5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I've got mines for $130 a piece from Alibaba (plus shipping plus tax), which turned out to be 350 Eur total for a pair. I don't believe that the prices will get lower than this in any time soon, but they are already low enough to be a compelling option.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n1lrq5n",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got mines for $130 a piece from Alibaba (plus shipping plus tax), which turned out to be 350 Eur total for a pair. I don&amp;#39;t believe that the prices will get lower than this in any time soon, but they are already low enough to be a compelling option.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lspzn3",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lrq5n/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751790682,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751790682,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lpvyc",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "My_Unbiased_Opinion",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1llkm9",
                                "score": 1,
                                "author_fullname": "t2_esiyl0yb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Interesting. Good to know. Im considering a Mi50 rn. \n\n\nDo you think prices will go lower?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lpvyc",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting. Good to know. Im considering a Mi50 rn. &lt;/p&gt;\n\n&lt;p&gt;Do you think prices will go lower?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lpvyc/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751789568,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751789568,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1llkm9",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Refrigerator-1672",
                      "can_mod_post": false,
                      "created_utc": 1751787035,
                      "send_replies": true,
                      "parent_id": "t1_n1khzoo",
                      "score": 3,
                      "author_fullname": "t2_baavelp5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "In llama.cpp, Mi50 is incompatible with Q4\\_0 quants (I believe it's due to them requiring BF16), but with Q4\\_1 quants you get roughly 10-15% performance uplift against Unsloth Dynamic Q4 quants.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1llkm9",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In llama.cpp, Mi50 is incompatible with Q4_0 quants (I believe it&amp;#39;s due to them requiring BF16), but with Q4_1 quants you get roughly 10-15% performance uplift against Unsloth Dynamic Q4 quants.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1llkm9/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751787035,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1khzoo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "My_Unbiased_Opinion",
            "can_mod_post": false,
            "created_utc": 1751767562,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 25,
            "author_fullname": "t2_esiyl0yb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice dude. I was about to recommend Q4_0 with older cards. I've done some testing with P40s and M40s as well \n\n\nhttps://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\n\n\nHave you tried ik-llama.cpp with a 4_0 quant? I havent (old GPUs are in storage) but there might be some more gains to be had. ",
            "edited": 1751770628,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1khzoo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice dude. I was about to recommend Q4_0 with older cards. I&amp;#39;ve done some testing with P40s and M40s as well &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Have you tried ik-llama.cpp with a 4_0 quant? I havent (old GPUs are in storage) but there might be some more gains to be had. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1khzoo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751767562,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 25
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1l62h4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "fallingdowndizzyvr",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l0n6q",
                                "score": 3,
                                "author_fullname": "t2_o65i6kx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Actually, my understanding is there's a software issue with the 395 and MOEs and that's why the PP is so low. Hopefully that gets fixed.\n\nAnyways, here's a dense model. Small, but still dense. I picked the llama 7b because I have another GPU that I already ran that model on to post too.\n\nMi50\n\n\"llama 7B Q4_0 \t|   3.56 GiB \t|   pp512 \t|   1289.11 ± 0.62\n\nllama 7B Q4_0 \t|   3.56 GiB \t|   tg128 \t|   91.46 ± 0.13\"\n\nMax+ 395\n\n\"llama 7B Q4_0                  |   3.56 GiB |    pp512 |        937.33 ± 5.67\n\nllama 7B Q4_0                  |   3.56 GiB |    tg128 |         48.47 ± 0.72\"\n\nAlso, here's from a $50 V340.\n\n\"llama 7B Q4_0                  |   3.56 GiB |     pp512 |       1247.83 ± 3.78\n\nllama 7B Q4_0                  |   3.56 GiB |     tg128 |         47.73 ± 0.09\"",
                                "edited": 1751778668,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1l62h4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Actually, my understanding is there&amp;#39;s a software issue with the 395 and MOEs and that&amp;#39;s why the PP is so low. Hopefully that gets fixed.&lt;/p&gt;\n\n&lt;p&gt;Anyways, here&amp;#39;s a dense model. Small, but still dense. I picked the llama 7b because I have another GPU that I already ran that model on to post too.&lt;/p&gt;\n\n&lt;p&gt;Mi50&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;llama 7B Q4_0  |   3.56 GiB    |   pp512   |   1289.11 ± 0.62&lt;/p&gt;\n\n&lt;p&gt;llama 7B Q4_0   |   3.56 GiB    |   tg128   |   91.46 ± 0.13&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Max+ 395&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;llama 7B Q4_0                  |   3.56 GiB |    pp512 |        937.33 ± 5.67&lt;/p&gt;\n\n&lt;p&gt;llama 7B Q4_0                  |   3.56 GiB |    tg128 |         48.47 ± 0.72&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Also, here&amp;#39;s from a $50 V340.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;llama 7B Q4_0                  |   3.56 GiB |     pp512 |       1247.83 ± 3.78&lt;/p&gt;\n\n&lt;p&gt;llama 7B Q4_0                  |   3.56 GiB |     tg128 |         47.73 ± 0.09&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l62h4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751778375,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751778375,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l0n6q",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751775705,
                      "send_replies": true,
                      "parent_id": "t1_n1kzt03",
                      "score": 7,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I see. But you have to also consider dense models. Mistral Large is 123B parameter model and int4 quant runs at ~20t/s with 4x MI50. I doubt that you will get even 5 t/s TG with Max+.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l0n6q",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see. But you have to also consider dense models. Mistral Large is 123B parameter model and int4 quant runs at ~20t/s with 4x MI50. I doubt that you will get even 5 t/s TG with Max+.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l0n6q/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751775705,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1ls0kg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "COBECT",
                      "can_mod_post": false,
                      "created_utc": 1751790862,
                      "send_replies": true,
                      "parent_id": "t1_n1kzt03",
                      "score": 4,
                      "author_fullname": "t2_1umam7ln",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Please run large models 20+B, nobody cares about rather speed for small models since it almost everywhere insane.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1ls0kg",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Please run large models 20+B, nobody cares about rather speed for small models since it almost everywhere insane.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ls0kg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751790862,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1kzt03",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fallingdowndizzyvr",
            "can_mod_post": false,
            "created_utc": 1751775308,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 15,
            "author_fullname": "t2_o65i6kx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For comparison. It blows the Max+ 395 away for PP. But is about comparable in TG. Yes, I know it's not the same quant, but it's close enough for a hand wave comparison.\n\nMi50\n\n\"qwen3moe 30B.A3B Q4_1 |  \t17.87 GiB |  \tpp1024 |  \t1023.81 ± 3.76\n\nqwen3moe 30B.A3B Q4_1 |  \t17.87 GiB |  \ttg128 |  \t63.87 ± 0.06\"\n\nMax+ 395\n\n\"qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |          pp1024 |         66.64 ± 0.25\n\nqwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |           tg128 |         71.29 ± 0.07\"",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1kzt03",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For comparison. It blows the Max+ 395 away for PP. But is about comparable in TG. Yes, I know it&amp;#39;s not the same quant, but it&amp;#39;s close enough for a hand wave comparison.&lt;/p&gt;\n\n&lt;p&gt;Mi50&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;qwen3moe 30B.A3B Q4_1 |    17.87 GiB |     pp1024 |    1023.81 ± 3.76&lt;/p&gt;\n\n&lt;p&gt;qwen3moe 30B.A3B Q4_1 |     17.87 GiB |     tg128 |     63.87 ± 0.06&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Max+ 395&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |          pp1024 |         66.64 ± 0.25&lt;/p&gt;\n\n&lt;p&gt;qwen3moe 30B.A3B Q4_K - Medium |  16.49 GiB |           tg128 |         71.29 ± 0.07&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kzt03/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751775308,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1ldw11",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "ahjorth",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1lcoo1",
                                "score": 15,
                                "author_fullname": "t2_sc1eb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I have an (official) diagnosis, can relate (100%).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1ldw11",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have an (official) diagnosis, can relate (100%).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ldw11/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751782597,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751782597,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 15
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1lcoo1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "beryugyo619",
                      "can_mod_post": false,
                      "created_utc": 1751781921,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 20,
                      "author_fullname": "t2_v8wruy0k",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I've seen people describing it as ADHD brains(working (only sporadically) extra hard) giving out bonus contents(like in movie Blu-rays) like those were free candies for sentences",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1lcoo1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen people describing it as ADHD brains(working (only sporadically) extra hard) giving out bonus contents(like in movie Blu-rays) like those were free candies for sentences&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lcoo1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751781921,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 20
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lxpu4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "jrherita",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l7vad",
                                "score": 5,
                                "author_fullname": "t2_skayi",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "fwiw I found your parentheses easy to read.  They're useful for breaking up walls of text.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lxpu4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;fwiw I found your parentheses easy to read.  They&amp;#39;re useful for breaking up walls of text.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lxpu4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751794366,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751794366,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l7vad",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751779309,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 11,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Roger that. I was in a rush, but good point.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l7vad",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Roger that. I was in a rush, but good point.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l7vad/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751779309,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1lbfyc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Everlier",
                      "can_mod_post": false,
                      "created_utc": 1751781237,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 3,
                      "author_fullname": "t2_o7p5m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I also needed this advice, thanks",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1lbfyc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Alpaca"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I also needed this advice, thanks&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lbfyc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751781237,
                      "author_flair_text": "Alpaca",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bd9e9e",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1lk9j5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FunnyAsparagus1253",
                      "can_mod_post": false,
                      "created_utc": 1751786261,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 3,
                      "author_fullname": "t2_i6c8tay3w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I can read the first one fine. Your version does flow a little better for reading but loses a little info imo (the last sentence seems disconnected, for example). Both are fine though! 😅🫶",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1lk9j5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can read the first one fine. Your version does flow a little better for reading but loses a little info imo (the last sentence seems disconnected, for example). Both are fine though! 😅🫶&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lk9j5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751786261,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1lrjr5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1751790576,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 2,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I like with parens more.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1lrjr5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I like with parens more.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lrjr5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751790576,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1lzskc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "arakinas",
                      "can_mod_post": false,
                      "created_utc": 1751795627,
                      "send_replies": true,
                      "parent_id": "t1_n1l6nnt",
                      "score": 1,
                      "author_fullname": "t2_2q8t0rpr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I prefer it the other way. It reads way better to me",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1lzskc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I prefer it the other way. It reads way better to me&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lzskc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751795627,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1l6nnt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "randylush",
            "can_mod_post": false,
            "created_utc": 1751778677,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 11,
            "author_fullname": "t2_111wufdu01",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).\n\nCan I give you a minor language tip. You are using parentheses all over the place, like every sentence. It makes it slightly harder to read. When people read parentheses it’s usually in a different tone of voice, so if you use it too much the language can sound chaotic. I’m not saying don’t use parentheses, just don’t use it every single sentence. \n\nThis, for example, would flow better and would be slightly easier to read: \n\n&gt; My motherboard, an Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM, had stability issues with 8x MI50; it wouldn’t boot. so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150. I started seeing MI50 32GB cards again on eBay.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1l6nnt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Can I give you a minor language tip. You are using parentheses all over the place, like every sentence. It makes it slightly harder to read. When people read parentheses it’s usually in a different tone of voice, so if you use it too much the language can sound chaotic. I’m not saying don’t use parentheses, just don’t use it every single sentence. &lt;/p&gt;\n\n&lt;p&gt;This, for example, would flow better and would be slightly easier to read: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My motherboard, an Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM, had stability issues with 8x MI50; it wouldn’t boot. so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150. I started seeing MI50 32GB cards again on eBay.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l6nnt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751778677,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1kzvn6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751775342,
                      "send_replies": true,
                      "parent_id": "t1_n1kpdz7",
                      "score": 4,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I always use no-mmap so that the CPU doesn't get filled with the model that is bigger than my CPU RAM.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1kzvn6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I always use no-mmap so that the CPU doesn&amp;#39;t get filled with the model that is bigger than my CPU RAM.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kzvn6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751775342,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1kpdz7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DinoAmino",
            "can_mod_post": false,
            "created_utc": 1751770642,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 2,
            "author_fullname": "t2_j1v7f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Curious to know when running this (the 235B) model like this ... is there no RAM available to run anything else?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1kpdz7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Curious to know when running this (the 235B) model like this ... is there no RAM available to run anything else?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kpdz7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751770642,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lfkbg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "segmond",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l7d2p",
                                "score": 1,
                                "author_fullname": "t2_ah13x",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I have seen folks suggest it, but I haven't personally done so.  \n  Perhaps using -mg to select the rtx 3090 as the main GPU?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lfkbg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have seen folks suggest it, but I haven&amp;#39;t personally done so.&lt;br/&gt;\n  Perhaps using -mg to select the rtx 3090 as the main GPU?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lfkbg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751783553,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1751783553,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lrq1w",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AppearanceHeavy6724",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l7d2p",
                                "score": 1,
                                "author_fullname": "t2_uz37qfx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You need tensor split to have most of tensors in 3090, and only whatever dose not fit into AMD. Disabling/enabling flash attention may help too.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lrq1w",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You need tensor split to have most of tensors in 3090, and only whatever dose not fit into AMD. Disabling/enabling flash attention may help too.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lrq1w/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751790680,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751790680,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lzzyh",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "CheatCodesOfLife",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l7d2p",
                                "score": 1,
                                "author_fullname": "t2_32el727b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You can certainly achieve this with the -ts and -ot flags (my Deepseek-R1 on 5x3090 + CPU setup does this, prompt processing is all on GPU0 which is PCIe bandwidth bound at PCIe4.0 x16).\n\nBut there may be a simpler, I remember reading something about setting the \"main\" gpu",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lzzyh",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can certainly achieve this with the -ts and -ot flags (my Deepseek-R1 on 5x3090 + CPU setup does this, prompt processing is all on GPU0 which is PCIe bandwidth bound at PCIe4.0 x16).&lt;/p&gt;\n\n&lt;p&gt;But there may be a simpler, I remember reading something about setting the &amp;quot;main&amp;quot; gpu&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lzzyh/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751795749,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751795749,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l7d2p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751779044,
                      "send_replies": true,
                      "parent_id": "t1_n1l5ac2",
                      "score": 2,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You mean using vulkan backend in llama.cpp? I tried adding RTX 3090 to MI50s but could not get better PP. Not sure what argument in llama cpp allows me to run PP in RTX 3090 only and other operations in MI50s. Let me know if there is a way.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l7d2p",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You mean using vulkan backend in llama.cpp? I tried adding RTX 3090 to MI50s but could not get better PP. Not sure what argument in llama cpp allows me to run PP in RTX 3090 only and other operations in MI50s. Let me know if there is a way.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l7d2p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751779044,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1l5ac2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "segmond",
            "can_mod_post": false,
            "created_utc": 1751777975,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 2,
            "author_fullname": "t2_ah13x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have you thought of sticking in 1 nvidia card in there and having that for PP?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1l5ac2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you thought of sticking in 1 nvidia card in there and having that for PP?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l5ac2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751777975,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n1lm4a8",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "No-Refrigerator-1672",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n1ky9ng",
                                                    "score": 1,
                                                    "author_fullname": "t2_baavelp5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I've got a pair of 32GBs Mi50s with DHL shipping for just under 300 euro into EU from Alibaba (tax excluded, everything else included). Leaving it there in case anybody from EU will also consider this.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n1lm4a8",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a pair of 32GBs Mi50s with DHL shipping for just under 300 euro into EU from Alibaba (tax excluded, everything else included). Leaving it there in case anybody from EU will also consider this.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1lspzn3",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lm4a8/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1751787364,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1751787364,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n1ky9ng",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "terminoid_",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n1kwb5b",
                                          "score": 8,
                                          "author_fullname": "t2_1iu07dnz2i",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "you can find em for ~$130 on alibaba, but then shipping is $60, and you have to factor in customs fees. there's a ~$40 processing fee, and either $100 fee from your carrier, or a percentage of the declared value. (thx Trump)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n1ky9ng",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you can find em for ~$130 on alibaba, but then shipping is $60, and you have to factor in customs fees. there&amp;#39;s a ~$40 processing fee, and either $100 fee from your carrier, or a percentage of the declared value. (thx Trump)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lspzn3",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ky9ng/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751774591,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751774591,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 8
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n1kz5ke",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "beryugyo619",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n1kwb5b",
                                          "score": 3,
                                          "author_fullname": "t2_v8wruy0k",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "They sell at that kind of prices on Chinese equivalents of eBay, but they don't really speak or think in English and aren't interested in setting up 1-click international sales. Those of them who do speak English just scalp them at double prices on actual eBay",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n1kz5ke",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They sell at that kind of prices on Chinese equivalents of eBay, but they don&amp;#39;t really speak or think in English and aren&amp;#39;t interested in setting up 1-click international sales. Those of them who do speak English just scalp them at double prices on actual eBay&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lspzn3",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kz5ke/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751775007,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751775007,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n1kwb5b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "--dany--",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1kqnw0",
                                "score": 6,
                                "author_fullname": "t2_bjeo1gwy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It seems this the price has inflated a lot. No more MI50 32GB at your price any more.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1kwb5b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems this the price has inflated a lot. No more MI50 32GB at your price any more.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kwb5b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751773696,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751773696,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1kqnw0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "fallingdowndizzyvr",
                      "can_mod_post": false,
                      "created_utc": 1751771198,
                      "send_replies": true,
                      "parent_id": "t1_n1kl8oe",
                      "score": 9,
                      "author_fullname": "t2_o65i6kx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"I bought these cards on eBay when one seller sold them for around $150 \"",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1kqnw0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;I bought these cards on eBay when one seller sold them for around $150 &amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kqnw0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751771198,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1kzr4b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751775283,
                      "send_replies": true,
                      "parent_id": "t1_n1kl8oe",
                      "score": 2,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I was lucky to find these 3 months ago for that price. Note that the prices never were $150. I bought 4 of them and the seller was initially selling them for $230. I negotiated by sending messages on eBay. E.g. \"there is no warranty after 30 day return window, so I am also taking a risk buying 4\". So, these GPUs have not failed.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1kzr4b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was lucky to find these 3 months ago for that price. Note that the prices never were $150. I bought 4 of them and the seller was initially selling them for $230. I negotiated by sending messages on eBay. E.g. &amp;quot;there is no warranty after 30 day return window, so I am also taking a risk buying 4&amp;quot;. So, these GPUs have not failed.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kzr4b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751775283,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1kl8oe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "--dany--",
            "can_mod_post": false,
            "created_utc": 1751768894,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_bjeo1gwy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Where did you get those cards at $150? Are you buying from china directly?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1kl8oe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where did you get those cards at $150? Are you buying from china directly?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kl8oe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751768894,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l01zh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751775425,
                      "send_replies": true,
                      "parent_id": "t1_n1ku05g",
                      "score": 1,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! Yes, that fork of vLLM will work fine with 6.3.4.  ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l01zh",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! Yes, that fork of vLLM will work fine with 6.3.4.  &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l01zh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751775425,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1ku05g",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "EmPips",
            "can_mod_post": false,
            "created_utc": 1751772665,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_w2gxqd6i2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "vLLM supports 6.3? I checked a few weeks ago and it wasn't happy with any installation above 6.2 .\n\nAmazing work though and thanks so much for documenting all of this!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1ku05g",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vLLM supports 6.3? I checked a few weeks ago and it wasn&amp;#39;t happy with any installation above 6.2 .&lt;/p&gt;\n\n&lt;p&gt;Amazing work though and thanks so much for documenting all of this!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ku05g/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751772665,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1lg7ei",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "xanduonc",
            "can_mod_post": false,
            "created_utc": 1751783920,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_10n3b6gg97",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Did you install amdgpu drivers in addition to rocm?  \n  \nI bought 2 of these cards and sadly could not get them to work yet. Windows does not have any working drivers that accept them and Linux either crashes at boot time either gets \"error -12\" and rocm sees nothing.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1lg7ei",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did you install amdgpu drivers in addition to rocm?  &lt;/p&gt;\n\n&lt;p&gt;I bought 2 of these cards and sadly could not get them to work yet. Windows does not have any working drivers that accept them and Linux either crashes at boot time either gets &amp;quot;error -12&amp;quot; and rocm sees nothing.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lg7ei/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751783920,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1lkq1l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FunnyAsparagus1253",
            "can_mod_post": false,
            "created_utc": 1751786531,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_i6c8tay3w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If I were to add one of these to my P40 setup, would they a) play well together, split models across cards etc, b) they’d work but I’d have to treat them as separate things (image gen on nvidia, LLMs on AMD for example) or c) trying to set up drivers will destroy my whole system, don’t bother. ? Asking for myself.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1lkq1l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If I were to add one of these to my P40 setup, would they a) play well together, split models across cards etc, b) they’d work but I’d have to treat them as separate things (image gen on nvidia, LLMs on AMD for example) or c) trying to set up drivers will destroy my whole system, don’t bother. ? Asking for myself.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lkq1l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751786531,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1lmex4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "coolestmage",
            "can_mod_post": false,
            "created_utc": 1751787540,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_6dtdz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I also have some MI50s and I didn't realize they performed so much better on Q4_0 and Q4_1. I've been using a lot of Q4_XS and _K_M. I just tested and several models are running more than 2x faster for inference. Thanks for the pointer!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1lmex4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I also have some MI50s and I didn&amp;#39;t realize they performed so much better on Q4_0 and Q4_1. I&amp;#39;ve been using a lot of Q4_XS and _K_M. I just tested and several models are running more than 2x faster for inference. Thanks for the pointer!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lmex4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751787540,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1m0yja",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "CheatCodesOfLife",
            "can_mod_post": false,
            "created_utc": 1751796313,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_32el727b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have you tried Command-A in AWQ quant with VLLM? I'd be curious about the prompt processing and generation speeds.\n\nI get 32t/s with 4x3090.\n\nIf you can get similar speeds to ML2407, that'd be a great model to run locally, and 128GB of VRAM would let you take advantage of it's coherence at long contexts!\n\nThanks for you extremely details post btw, you covered everything clearly.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1m0yja",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried Command-A in AWQ quant with VLLM? I&amp;#39;d be curious about the prompt processing and generation speeds.&lt;/p&gt;\n\n&lt;p&gt;I get 32t/s with 4x3090.&lt;/p&gt;\n\n&lt;p&gt;If you can get similar speeds to ML2407, that&amp;#39;d be a great model to run locally, and 128GB of VRAM would let you take advantage of it&amp;#39;s coherence at long contexts!&lt;/p&gt;\n\n&lt;p&gt;Thanks for you extremely details post btw, you covered everything clearly.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1m0yja/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751796313,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1m4trv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Afternoon_4260",
            "can_mod_post": false,
            "created_utc": 1751798595,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_cj9kap4bx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Vllm for the win as usual",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1m4trv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Vllm for the win as usual&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1m4trv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751798595,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1lzr0i",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "CheatCodesOfLife",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1l70ps",
                                "score": 1,
                                "author_fullname": "t2_32el727b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; I know Mac uses system RAM for GPU as well. In PCs, system RAM is separate from GPU VRAM. \n\nGood answer! I actually didn't consider that there would be people who only know Mac / Silicon and wouldn't understand the concept of separate system ram + video ram!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1lzr0i",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I know Mac uses system RAM for GPU as well. In PCs, system RAM is separate from GPU VRAM. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Good answer! I actually didn&amp;#39;t consider that there would be people who only know Mac / Silicon and wouldn&amp;#39;t understand the concept of separate system ram + video ram!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lzr0i/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751795601,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751795601,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l70ps",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MLDataScientist",
                      "can_mod_post": false,
                      "created_utc": 1751778863,
                      "send_replies": true,
                      "parent_id": "t1_n1l3kaq",
                      "score": 4,
                      "author_fullname": "t2_3zy7pnf1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I don't have a Mac. But I know Mac uses system RAM for GPU as well. In PCs, system RAM is separate from GPU VRAM. I have 128 VRAM and 96GB RAM.\n\n\n Also, for MoE - mixture of experts - models like qwen3 235B.A22B has 22B active parameters for each token generation. So, remaining parameters are not used for that token generation. Due to this architecture, we can offload some experts to system RAM if you don't have enough VRAM.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l70ps",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have a Mac. But I know Mac uses system RAM for GPU as well. In PCs, system RAM is separate from GPU VRAM. I have 128 VRAM and 96GB RAM.&lt;/p&gt;\n\n&lt;p&gt; Also, for MoE - mixture of experts - models like qwen3 235B.A22B has 22B active parameters for each token generation. So, remaining parameters are not used for that token generation. Due to this architecture, we can offload some experts to system RAM if you don&amp;#39;t have enough VRAM.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l70ps/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751778863,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1l6zg7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "fallingdowndizzyvr",
                      "can_mod_post": false,
                      "created_utc": 1751778845,
                      "send_replies": true,
                      "parent_id": "t1_n1l3kaq",
                      "score": 2,
                      "author_fullname": "t2_o65i6kx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; also how are you loading &gt;130G on a 128G VRAM?\n\n\"qwen3moe 235B.A22B Q4_1 (**5x** MI50)\"\n\n5x32 = 160. 160 &gt; 130.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1l6zg7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;also how are you loading &amp;gt;130G on a 128G VRAM?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;quot;qwen3moe 235B.A22B Q4_1 (&lt;strong&gt;5x&lt;/strong&gt; MI50)&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;5x32 = 160. 160 &amp;gt; 130.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l6zg7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751778845,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1l3kaq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "davikrehalt",
            "can_mod_post": false,
            "created_utc": 1751777114,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 0,
            "author_fullname": "t2_6okc6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "is there a Mac guide for this? also how are you loading &gt;130G on a 128G VRAM? sorry I'm dumb",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1l3kaq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;is there a Mac guide for this? also how are you loading &amp;gt;130G on a 128G VRAM? sorry I&amp;#39;m dumb&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1l3kaq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751777114,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n1m6ntu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Subject_Ratio6842",
                      "can_mod_post": false,
                      "created_utc": 1751799597,
                      "send_replies": true,
                      "parent_id": "t1_n1lwnbc",
                      "score": 1,
                      "author_fullname": "t2_y8qz0s2mk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for sharing. I'll check it out\n\n(Many of us like exploring the local llms because we might need solutions dealing with private or sensitive information relating to businesses and we don't want to send our data to other companies)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1m6ntu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for sharing. I&amp;#39;ll check it out&lt;/p&gt;\n\n&lt;p&gt;(Many of us like exploring the local llms because we might need solutions dealing with private or sensitive information relating to businesses and we don&amp;#39;t want to send our data to other companies)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1m6ntu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751799597,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1lwnbc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BigNet652",
            "can_mod_post": false,
            "created_utc": 1751793698,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": -4,
            "author_fullname": "t2_tdjt8s67",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I found a website with many free AI models. You can apply for the API and use it for free.  \n[https://cloud.siliconflow.cn/i/gJUvuAXT](https://cloud.siliconflow.cn/i/gJUvuAXT)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1lwnbc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I found a website with many free AI models. You can apply for the API and use it for free.&lt;br/&gt;\n&lt;a href=\"https://cloud.siliconflow.cn/i/gJUvuAXT\"&gt;https://cloud.siliconflow.cn/i/gJUvuAXT&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1lwnbc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751793698,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -4
          }
        }
      ],
      "before": null
    }
  }
]