[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi everyone,\n\nLast year I posted about 2x MI60 performance. Since then, I bought more cards and PCIE riser cables to build a rack with 8x AMD MI50 32GB cards. My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).\n\nI connected 4x MI50 cards using ASUS Hyper M.2 x16 Gen5 Card (PCIE4.0 x16 to 4xM.2 card then I used M.2 to PCIE4.0 cables to connect 4 GPUs) through the first PCIE4.0 x16 slot on the motherboard that supports 4x4 bifurcation. I set the PCIE to use PCIE3.0 so that I don't get occasional freezing issues in my system. Each card was running at PCIE3.0 x4 (later I also tested 2x MI50s with PCIE4.0 x8 speed and did not see any PP/TG speed difference).\n\nI am using 1.2A blower fans to cool these cards which are a bit noisy at max speed but I adjusted their speeds to be acceptable.\n\nI have tested both llama.cpp (ROCm 6.3.4 and vulkan backend) and vLLM v0.9.2 in Ubuntu 24.04.02. Below are some results.\n\nNote that MI50/60 cards do not have matrix or tensor cores and that is why their Prompt Processing (PP) speed is not great. But Text Generation (TG) speeds are great!\n\nLlama.cpp (build: 247e5c6e (5606)) with ROCm 6.3.4. All of the runs use one MI50 (I will note the ones that use 2x or 4x MI50 in the model column). Note that MI50/60 cards perform best with Q4\\_0 and Q4\\_1 quantizations (that is why I ran larger models with those Quants).\n\n|Model|size|test|t/s|\n|:-|:-|:-|:-|\n|qwen3 0.6B Q8\\_0|604.15 MiB|pp1024|3014.18 ± 1.71|\n|qwen3 0.6B Q8\\_0|604.15 MiB|tg128|191.63 ± 0.38|\n|llama 7B Q4\\_0|3.56 GiB|pp512|1289.11 ± 0.62|\n|llama 7B Q4\\_0|3.56 GiB|tg128|91.46 ± 0.13|\n|qwen3 8B Q8\\_0|8.11 GiB|pp512|357.71 ± 0.04|\n|qwen3 8B Q8\\_0|8.11 GiB|tg128|48.09 ± 0.04|\n|qwen2 14B Q8\\_0|14.62 GiB|pp512|249.45 ± 0.08|\n|qwen2 14B Q8\\_0|14.62 GiB|tg128|29.24 ± 0.03|\n|qwen2 32B Q4\\_0|17.42 GiB|pp512|300.02 ± 0.52|\n|qwen2 32B Q4\\_0|17.42 GiB|tg128|20.39 ± 0.37|\n|qwen2 70B Q5\\_K - Medium|50.70 GiB|pp512|48.92 ± 0.02|\n|qwen2 70B Q5\\_K - Medium|50.70 GiB|tg128|9.05 ± 0.10|\n|qwen2vl 70B Q4\\_1 (4x MI50 row split)|42.55 GiB|pp512|56.33 ± 0.09|\n|qwen2vl 70B Q4\\_1 (4x MI50 row split)|42.55 GiB|tg128|16.00 ± 0.01|\n|qwen3moe 30B.A3B Q4\\_1|17.87 GiB|pp1024|1023.81 ± 3.76|\n|qwen3moe 30B.A3B Q4\\_1|17.87 GiB|tg128|63.87 ± 0.06|\n|qwen3 32B Q4\\_1 (2x MI50)|19.21 GiB|pp1024|238.17 ± 0.30|\n|qwen3 32B Q4\\_1 (2x MI50)|19.21 GiB|tg128|25.17 ± 0.01|\n|qwen3moe 235B.A22B Q4\\_1 (5x MI50)|137.11 GiB|pp1024|202.50 ± 0.32|\n|qwen3moe 235B.A22B Q4\\_1 (5x MI50) (4x mi50 with some expert offloading should give around 16t/s)|137.11 GiB|tg128|19.17 ± 0.04|\n\nPP is not great but TG is very good for most use cases. \n\nBy the way, I also tested Deepseek R1 IQ2-XXS (although it was running with 6x MI50) and I was getting \\~9 t/s for TG with a few experts offloaded to CPU RAM.\n\nNow, let's look at vllm (version 0.9.2.dev1+g5273453b6. Fork used: https://github.com/nlzy/vllm-gfx906).\n\nAWQ and GPTQ quants are supported. For gptq models, desc\\_act=false quants are used to get a better performance. Max concurrency is set to 1.\n\n|Model|Output token throughput (tok/s) (256)|Prompt processing  t/s (4096)|\n|:-|:-|:-|\n|Mistral-Large-Instruct-2407-AWQ 123B (4x MI50)|19.68|80|\n|Qwen2.5-72B-Instruct-GPTQ-Int4 (2x MI50)|19.76|130|\n|Qwen2.5-72B-Instruct-GPTQ-Int4 (4x MI50)|25.96|130|\n|Llama-3.3-70B-Instruct-AWQ (4x MI50)|27.26|130|\n|Qwen3-32B-GPTQ-Int8 (4x MI50)|32.3|230|\n|Qwen3-32B-autoround-4bit-gptq (4x MI50)|38.55|230|\n|gemma-3-27b-it-int4-awq (4x MI50)|36.96|350|\n\n  \nTensor parallelism (TP) gives MI50s extra performance in Text Generation (TG). Overall, great performance for the price. And I am sure we will not get 128GB VRAM with such TG speeds any time soon for \\~$600.\n\nPower consumption is around 900W for the system when using vllm with TP during text generation. Llama.cpp does not use TP so I did not see it using above 500W. Each GPU runs at around 18W when idle.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "128GB VRAM for ~$600. Qwen3 MOE 235B.A22B reaching 20 t/s. 4x AMD MI50 32GB.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lspzn3",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.97,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 45,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_3zy7pnf1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 45,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751767150,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Last year I posted about 2x MI60 performance. Since then, I bought more cards and PCIE riser cables to build a rack with 8x AMD MI50 32GB cards. My motherboard (Asus rog dark hero viii with AMD 5950x CPU and 96GB 3200Mhz RAM) had stability issues with 8x MI50 (does not boot), so I connected four (or sometimes six) of those cards. I bought these cards on eBay when one seller sold them for around $150 (I started seeing MI50 32GB cards again on eBay).&lt;/p&gt;\n\n&lt;p&gt;I connected 4x MI50 cards using ASUS Hyper M.2 x16 Gen5 Card (PCIE4.0 x16 to 4xM.2 card then I used M.2 to PCIE4.0 cables to connect 4 GPUs) through the first PCIE4.0 x16 slot on the motherboard that supports 4x4 bifurcation. I set the PCIE to use PCIE3.0 so that I don&amp;#39;t get occasional freezing issues in my system. Each card was running at PCIE3.0 x4 (later I also tested 2x MI50s with PCIE4.0 x8 speed and did not see any PP/TG speed difference).&lt;/p&gt;\n\n&lt;p&gt;I am using 1.2A blower fans to cool these cards which are a bit noisy at max speed but I adjusted their speeds to be acceptable.&lt;/p&gt;\n\n&lt;p&gt;I have tested both llama.cpp (ROCm 6.3.4 and vulkan backend) and vLLM v0.9.2 in Ubuntu 24.04.02. Below are some results.&lt;/p&gt;\n\n&lt;p&gt;Note that MI50/60 cards do not have matrix or tensor cores and that is why their Prompt Processing (PP) speed is not great. But Text Generation (TG) speeds are great!&lt;/p&gt;\n\n&lt;p&gt;Llama.cpp (build: 247e5c6e (5606)) with ROCm 6.3.4. All of the runs use one MI50 (I will note the ones that use 2x or 4x MI50 in the model column). Note that MI50/60 cards perform best with Q4_0 and Q4_1 quantizations (that is why I ran larger models with those Quants).&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;size&lt;/th&gt;\n&lt;th align=\"left\"&gt;test&lt;/th&gt;\n&lt;th align=\"left\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 0.6B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;604.15 MiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;3014.18 ± 1.71&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 0.6B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;604.15 MiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;191.63 ± 0.38&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;llama 7B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;3.56 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;1289.11 ± 0.62&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;llama 7B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;3.56 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;91.46 ± 0.13&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 8B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;8.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;357.71 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 8B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;8.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;48.09 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 14B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.62 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;249.45 ± 0.08&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 14B Q8_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.62 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;29.24 ± 0.03&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 32B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.42 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;300.02 ± 0.52&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 32B Q4_0&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.42 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;20.39 ± 0.37&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 70B Q5_K - Medium&lt;/td&gt;\n&lt;td align=\"left\"&gt;50.70 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;48.92 ± 0.02&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2 70B Q5_K - Medium&lt;/td&gt;\n&lt;td align=\"left\"&gt;50.70 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;9.05 ± 0.10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2vl 70B Q4_1 (4x MI50 row split)&lt;/td&gt;\n&lt;td align=\"left\"&gt;42.55 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"left\"&gt;56.33 ± 0.09&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen2vl 70B Q4_1 (4x MI50 row split)&lt;/td&gt;\n&lt;td align=\"left\"&gt;42.55 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;16.00 ± 0.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 30B.A3B Q4_1&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.87 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;1023.81 ± 3.76&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 30B.A3B Q4_1&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.87 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;63.87 ± 0.06&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 32B Q4_1 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.21 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;238.17 ± 0.30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3 32B Q4_1 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.21 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;25.17 ± 0.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 235B.A22B Q4_1 (5x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;137.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;pp1024&lt;/td&gt;\n&lt;td align=\"left\"&gt;202.50 ± 0.32&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;qwen3moe 235B.A22B Q4_1 (5x MI50) (4x mi50 with some expert offloading should give around 16t/s)&lt;/td&gt;\n&lt;td align=\"left\"&gt;137.11 GiB&lt;/td&gt;\n&lt;td align=\"left\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.17 ± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;PP is not great but TG is very good for most use cases. &lt;/p&gt;\n\n&lt;p&gt;By the way, I also tested Deepseek R1 IQ2-XXS (although it was running with 6x MI50) and I was getting ~9 t/s for TG with a few experts offloaded to CPU RAM.&lt;/p&gt;\n\n&lt;p&gt;Now, let&amp;#39;s look at vllm (version 0.9.2.dev1+g5273453b6. Fork used: &lt;a href=\"https://github.com/nlzy/vllm-gfx906\"&gt;https://github.com/nlzy/vllm-gfx906&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;AWQ and GPTQ quants are supported. For gptq models, desc_act=false quants are used to get a better performance. Max concurrency is set to 1.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Output token throughput (tok/s) (256)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Prompt processing  t/s (4096)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Mistral-Large-Instruct-2407-AWQ 123B (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.68&lt;/td&gt;\n&lt;td align=\"left\"&gt;80&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen2.5-72B-Instruct-GPTQ-Int4 (2x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;19.76&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen2.5-72B-Instruct-GPTQ-Int4 (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;25.96&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Llama-3.3-70B-Instruct-AWQ (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;27.26&lt;/td&gt;\n&lt;td align=\"left\"&gt;130&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen3-32B-GPTQ-Int8 (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;32.3&lt;/td&gt;\n&lt;td align=\"left\"&gt;230&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen3-32B-autoround-4bit-gptq (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;38.55&lt;/td&gt;\n&lt;td align=\"left\"&gt;230&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;gemma-3-27b-it-int4-awq (4x MI50)&lt;/td&gt;\n&lt;td align=\"left\"&gt;36.96&lt;/td&gt;\n&lt;td align=\"left\"&gt;350&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Tensor parallelism (TP) gives MI50s extra performance in Text Generation (TG). Overall, great performance for the price. And I am sure we will not get 128GB VRAM with such TG speeds any time soon for ~$600.&lt;/p&gt;\n\n&lt;p&gt;Power consumption is around 900W for the system when using vllm with TP during text generation. Llama.cpp does not use TP so I did not see it using above 500W. Each GPU runs at around 18W when idle.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?auto=webp&amp;s=8c340ab5ae3eebd3a1f3a8e634fa1bb0cf891fee",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e4c9f1d82654452ab9abf4c2dfaa69dd9495bbf",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=87b01812b7fbad8b7970e973412d609dc1ebcd54",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dfcdc7e43c5456819743e8f71d12c77ef8db87a",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6166a63e8cec75d08489356905b0d102369f198e",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d1c7db1463f9c600c11ea411ad404650ada2e07e",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b47148bbb6b2e8e0e6fb909a8a087abbf287326e",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "hNPAr3eIAChvCruA_30RyOLRAM__-hwPLVex8tW4YLU"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lspzn3",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "MLDataScientist",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/",
            "subreddit_subscribers": 494897,
            "created_utc": 1751767150,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1kpdmg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "My_Unbiased_Opinion",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1klbbr",
                                "score": 1,
                                "author_fullname": "t2_esiyl0yb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks. Fixed it as well. ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1kpdmg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks. Fixed it as well. &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kpdmg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751770638,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751770638,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1klbbr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "natufian",
                      "can_mod_post": false,
                      "created_utc": 1751768925,
                      "send_replies": true,
                      "parent_id": "t1_n1khzoo",
                      "score": 1,
                      "author_fullname": "t2_65uig",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "[Fixed Linky](https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1klbbr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\"&gt;Fixed Linky&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1klbbr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751768925,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1khzoo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "My_Unbiased_Opinion",
            "can_mod_post": false,
            "created_utc": 1751767562,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 4,
            "author_fullname": "t2_esiyl0yb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice dude. I was about to recommend Q4_0 with older cards. I've done some testing with P40s and M40s as well \n\n\nhttps://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\n\n\nHave you tried ik-llama.cpp with a 4_0 quant? I havent (old GPUs are in storage) but there might be some more gains to be had. ",
            "edited": 1751770628,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1khzoo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice dude. I was about to recommend Q4_0 with older cards. I&amp;#39;ve done some testing with P40s and M40s as well &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1eqfok2/overclocked_m40_24gb_vs_p40_benchmark_results/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Have you tried ik-llama.cpp with a 4_0 quant? I havent (old GPUs are in storage) but there might be some more gains to be had. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1khzoo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751767562,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n1ky9ng",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "terminoid_",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n1kwb5b",
                                          "score": 1,
                                          "author_fullname": "t2_1iu07dnz2i",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "you can find em for ~$130 on alibaba, but then shipping is $60, and you have to factor in customs fees. there's a ~$40 processing fee, and either 100$ fee from your carrier, or a percentage of the declared value.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n1ky9ng",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you can find em for ~$130 on alibaba, but then shipping is $60, and you have to factor in customs fees. there&amp;#39;s a ~$40 processing fee, and either 100$ fee from your carrier, or a percentage of the declared value.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lspzn3",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ky9ng/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751774591,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751774591,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n1kwb5b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "--dany--",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1kqnw0",
                                "score": 1,
                                "author_fullname": "t2_bjeo1gwy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It seems this the price has inflated a lot. No more MI50 32GB at your price any more.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1kwb5b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems this the price has inflated a lot. No more MI50 32GB at your price any more.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lspzn3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kwb5b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751773696,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751773696,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1kqnw0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "fallingdowndizzyvr",
                      "can_mod_post": false,
                      "created_utc": 1751771198,
                      "send_replies": true,
                      "parent_id": "t1_n1kl8oe",
                      "score": 2,
                      "author_fullname": "t2_o65i6kx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"I bought these cards on eBay when one seller sold them for around $150 \"",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1kqnw0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;I bought these cards on eBay when one seller sold them for around $150 &amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lspzn3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kqnw0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751771198,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1kl8oe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "--dany--",
            "can_mod_post": false,
            "created_utc": 1751768894,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 2,
            "author_fullname": "t2_bjeo1gwy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Where did you get those cards at $150? Are you buying from china directly?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1kl8oe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where did you get those cards at $150? Are you buying from china directly?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kl8oe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751768894,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1kpdz7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DinoAmino",
            "can_mod_post": false,
            "created_utc": 1751770642,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_j1v7f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Curious to know when running this (the 235B) model like this ... is there no RAM available to run anything else?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1kpdz7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Curious to know when running this (the 235B) model like this ... is there no RAM available to run anything else?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1kpdz7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751770642,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1ku05g",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "EmPips",
            "can_mod_post": false,
            "created_utc": 1751772665,
            "send_replies": true,
            "parent_id": "t3_1lspzn3",
            "score": 1,
            "author_fullname": "t2_w2gxqd6i2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "vLLM supports 6.3? I checked a few weeks ago and it wasn't happy with any installation above 6.2 .\n\nAmazing work though and thanks so much for documenting all of this!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1ku05g",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vLLM supports 6.3? I checked a few weeks ago and it wasn&amp;#39;t happy with any installation above 6.2 .&lt;/p&gt;\n\n&lt;p&gt;Amazing work though and thanks so much for documenting all of this!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lspzn3/128gb_vram_for_600_qwen3_moe_235ba22b_reaching_20/n1ku05g/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751772665,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lspzn3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]