[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "For those fine-tuning open-weight LLMs, here’s an interesting RLHF development.\n\nQwen’s team has introduced **Group Sequence Policy Optimisation (GSPO)**, a sequence-level variant of GRPO (Group Relative Policy Optimisation) that they say fixes instability and scaling issues.\n\n**GRPO’s issue:**\n\n* Token-level importance sampling introduces variance that accumulates over long sequences\n* MoE models are especially vulnerable, sometimes collapsing without hacks like Routing Replay\n\n**GSPO’s solution:**\n\n* Sequence-level importance ratios, normalised for length\n* Reduces gradient variance\n* Stable MoE training without Routing Replay\n\n**Reported results:**\n\n* Faster convergence and higher benchmark scores (AIME’24, LiveCodeBench, CodeForces)\n* Stronger scaling with more compute\n* MoE models trained without expert routing drift\n\nQwen’s analysis suggests sequence-level weighting could be a safer default for RLHF fine-tuning.\n\nFull explanation, math details, and training curves here: [Qwen Team Proposes GSPO for Qwen3, Claims DeepSeek's GRPO is Ill-Posed](https://blog.netmind.ai/article/Qwen_Team_Proposes_GSPO_for_Qwen3%2C_Claims_DeepSeek's_GRPO_is_Ill-Posed).\n\nHas anyone here experimented with sequence-level weighting in RLHF pipelines?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GSPO: Qwen3’s new RLHF method claims to fix GRPO stability issues",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 79,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mj2da1",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.84,
            "author_flair_background_color": null,
            "ups": 33,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1mz24a41z0",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 33,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/wdx0EDfHGyipamuyFmR7ibDlepMbm2ZznMA2nKgv2rQ.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754480606,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those fine-tuning open-weight LLMs, here’s an interesting RLHF development.&lt;/p&gt;\n\n&lt;p&gt;Qwen’s team has introduced &lt;strong&gt;Group Sequence Policy Optimisation (GSPO)&lt;/strong&gt;, a sequence-level variant of GRPO (Group Relative Policy Optimisation) that they say fixes instability and scaling issues.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GRPO’s issue:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Token-level importance sampling introduces variance that accumulates over long sequences&lt;/li&gt;\n&lt;li&gt;MoE models are especially vulnerable, sometimes collapsing without hacks like Routing Replay&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;GSPO’s solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sequence-level importance ratios, normalised for length&lt;/li&gt;\n&lt;li&gt;Reduces gradient variance&lt;/li&gt;\n&lt;li&gt;Stable MoE training without Routing Replay&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Reported results:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Faster convergence and higher benchmark scores (AIME’24, LiveCodeBench, CodeForces)&lt;/li&gt;\n&lt;li&gt;Stronger scaling with more compute&lt;/li&gt;\n&lt;li&gt;MoE models trained without expert routing drift&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Qwen’s analysis suggests sequence-level weighting could be a safer default for RLHF fine-tuning.&lt;/p&gt;\n\n&lt;p&gt;Full explanation, math details, and training curves here: &lt;a href=\"https://blog.netmind.ai/article/Qwen_Team_Proposes_GSPO_for_Qwen3%2C_Claims_DeepSeek&amp;#x27;s_GRPO_is_Ill-Posed\"&gt;Qwen Team Proposes GSPO for Qwen3, Claims DeepSeek&amp;#39;s GRPO is Ill-Posed&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here experimented with sequence-level weighting in RLHF pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/reqjka65ydhf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?auto=webp&amp;s=27e8dff72272bb8ef8f09be5494157869a15d9f1",
                    "width": 2158,
                    "height": 1232
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39ccefd55955fdd87428cf68c039c61fc725141d",
                      "width": 108,
                      "height": 61
                    },
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78719e2bbaa54fef96fdbcfc5aaaf8fdd092a3ea",
                      "width": 216,
                      "height": 123
                    },
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4dbd287df41db652ded392f92b29ad0fd97b5982",
                      "width": 320,
                      "height": 182
                    },
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=818b34eb8d9fcdec9fcd1a5f93903a2fb2aa28f6",
                      "width": 640,
                      "height": 365
                    },
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c654fa62e9b18724c936a017632f3835e8a82b7",
                      "width": 960,
                      "height": 548
                    },
                    {
                      "url": "https://preview.redd.it/reqjka65ydhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a5c2fa1328b31c32ab0e5c99dcdb6190ce3c3931",
                      "width": 1080,
                      "height": 616
                    }
                  ],
                  "variants": {},
                  "id": "7O-rXX65yF_ChwMEWQT4Kg-O0rg5Y_MxpsSj9Rv-9DM"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mj2da1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "MarketingNetMind",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/",
            "stickied": false,
            "url": "https://i.redd.it/reqjka65ydhf1.png",
            "subreddit_subscribers": 512875,
            "created_utc": 1754480606,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n787n9o",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Secure_Reflection409",
                      "can_mod_post": false,
                      "created_utc": 1754486616,
                      "send_replies": true,
                      "parent_id": "t1_n77v1ir",
                      "score": 1,
                      "author_fullname": "t2_by77ogdhr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The idea that Qwen are manually tweaking anything did sound a bit odd :D",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n787n9o",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The idea that Qwen are manually tweaking anything did sound a bit odd :D&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj2da1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/n787n9o/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754486616,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77v1ir",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "shark8866",
            "can_mod_post": false,
            "created_utc": 1754482253,
            "send_replies": true,
            "parent_id": "t3_1mj2da1",
            "score": 5,
            "author_fullname": "t2_1237cb8qq5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i swear this is copy pasted from another post. Also I'm pretty sure gspo is RLVR as opposed to RLHF since grpo is RLVR",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77v1ir",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i swear this is copy pasted from another post. Also I&amp;#39;m pretty sure gspo is RLVR as opposed to RLHF since grpo is RLVR&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/n77v1ir/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754482253,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj2da1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7a321m",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MarketingNetMind",
                      "can_mod_post": false,
                      "created_utc": 1754505857,
                      "send_replies": true,
                      "parent_id": "t1_n78fy40",
                      "score": 1,
                      "author_fullname": "t2_1mz24a41z0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for raising the concern. To clarify:\n\n1. This post is tagged as \"Brand Affiliate\", indicating that it originates from our team.\n2. We are committed to sharing high-quality, relevant content. This post does not promote any paid products or services and is aligned with r/LocalLLaMA’s self-promotion guidelines.\n3. We’ve shared the full write-up so that readers can explore the technical details directly. It includes a link to Qwen’s original paper and cites the source for all key information - for example: *“Figure 1: Training curves comparing GSPO and GRPO (from original paper, section 5.1)”*, along with similar references throughout.\n\nOur intent is to contribute thoughtful technical content and help foster informed discussion within the community.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7a321m",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for raising the concern. To clarify:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;This post is tagged as &amp;quot;Brand Affiliate&amp;quot;, indicating that it originates from our team.&lt;/li&gt;\n&lt;li&gt;We are committed to sharing high-quality, relevant content. This post does not promote any paid products or services and is aligned with &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;’s self-promotion guidelines.&lt;/li&gt;\n&lt;li&gt;We’ve shared the full write-up so that readers can explore the technical details directly. It includes a link to Qwen’s original paper and cites the source for all key information - for example: &lt;em&gt;“Figure 1: Training curves comparing GSPO and GRPO (from original paper, section 5.1)”&lt;/em&gt;, along with similar references throughout.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Our intent is to contribute thoughtful technical content and help foster informed discussion within the community.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj2da1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/n7a321m/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754505857,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n78fy40",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "muchcharles",
            "can_mod_post": false,
            "created_utc": 1754489221,
            "send_replies": true,
            "parent_id": "t3_1mj2da1",
            "score": 2,
            "author_fullname": "t2_aipkc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "OP's name is literally \"marketing netmind\" and this is major blog spam, they never even link to the source.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n78fy40",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OP&amp;#39;s name is literally &amp;quot;marketing netmind&amp;quot; and this is major blog spam, they never even link to the source.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/n78fy40/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754489221,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj2da1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]