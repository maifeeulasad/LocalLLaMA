[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "AMD Is Reportedly Looking to Introduce a Dedicated Discrete NPU, Similar to Gaming GPUs But Targeted Towards AI Performance On PCs; Taking Edge AI to New Levels",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdx65u",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.95,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 86,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_twl3xhruz",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 86,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "default",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": false,
            "mod_note": null,
            "created": 1753954906,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "wccftech.com",
            "allow_live_comments": false,
            "selftext_html": null,
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1mdx65u",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "_SYSTEM_ADMIN_MOD_",
            "discussion_type": null,
            "num_comments": 21,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/",
            "stickied": false,
            "url": "https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/",
            "subreddit_subscribers": 507576,
            "created_utc": 1753954906,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n65frh9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Secure_Reflection409",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n65cgdv",
                                          "score": 2,
                                          "author_fullname": "t2_by77ogdhr",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Needs to be 20t/s absolute min, IMHO.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n65frh9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Needs to be 20t/s absolute min, IMHO.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdx65u",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65frh9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753963586,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753963586,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n65cgdv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "kaisurniwurer",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n64z8er",
                                "score": 4,
                                "author_fullname": "t2_qafso",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Those wouldn't really compete with professional lineup because of the speed.\n\nBut for me 10t/s on a the big moe models would be more than enough.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n65cgdv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those wouldn&amp;#39;t really compete with professional lineup because of the speed.&lt;/p&gt;\n\n&lt;p&gt;But for me 10t/s on a the big moe models would be more than enough.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdx65u",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65cgdv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753962305,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753962305,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n64z8er",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Toooooool",
                      "can_mod_post": false,
                      "created_utc": 1753956168,
                      "send_replies": true,
                      "parent_id": "t1_n64xpb6",
                      "score": 19,
                      "author_fullname": "t2_8llornh4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Their flagship AI GPU the MI355x has \"only\" 288GB VRAM at 8TB/s so it's unlikely to compete with that.  \nMost likely it would be less than 256GB as to not internally compete with the MI325x from 2024.  \nI'm guessing between 64GB and 128GB as it's a consumer product after all.  \n128GB would make the most sense as it would compete with the 96GB limit of their CPU's.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n64z8er",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Their flagship AI GPU the MI355x has &amp;quot;only&amp;quot; 288GB VRAM at 8TB/s so it&amp;#39;s unlikely to compete with that.&lt;br/&gt;\nMost likely it would be less than 256GB as to not internally compete with the MI325x from 2024.&lt;br/&gt;\nI&amp;#39;m guessing between 64GB and 128GB as it&amp;#39;s a consumer product after all.&lt;br/&gt;\n128GB would make the most sense as it would compete with the 96GB limit of their CPU&amp;#39;s.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n64z8er/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753956168,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 19
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n65hccb",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "LoSboccacc",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n65d05i",
                                          "score": 1,
                                          "author_fullname": "t2_dievh",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "You're right about the psu but digit servers have a lot of extra that increase costs (disks, motherboard, etc)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n65hccb",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right about the psu but digit servers have a lot of extra that increase costs (disks, motherboard, etc)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdx65u",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65hccb/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753964171,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753964171,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n65d05i",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Tman1677",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6510jo",
                                "score": 1,
                                "author_fullname": "t2_jftqe",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I agree, but then it would need to ship with its own power supply, driving up the cost. Still worth it though if I can plug it into a laptop easily. Although honestly, if you go that route the \"DIGITS\" style form factor of just exposing an API from a headless server is probably better",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n65d05i",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree, but then it would need to ship with its own power supply, driving up the cost. Still worth it though if I can plug it into a laptop easily. Although honestly, if you go that route the &amp;quot;DIGITS&amp;quot; style form factor of just exposing an API from a headless server is probably better&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdx65u",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65d05i/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753962528,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753962528,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6510jo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "LoSboccacc",
                      "can_mod_post": false,
                      "created_utc": 1753957100,
                      "send_replies": true,
                      "parent_id": "t1_n64xpb6",
                      "score": 3,
                      "author_fullname": "t2_dievh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Would love it usb3 once the model is loaded the radar interconnect is not that important if there's enough ram on the card, and i don't want another heat source and load on my psu would prefer it to have its own ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6510jo",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Would love it usb3 once the model is loaded the radar interconnect is not that important if there&amp;#39;s enough ram on the card, and i don&amp;#39;t want another heat source and load on my psu would prefer it to have its own &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n6510jo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753957100,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n64xpb6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Spellbonk90",
            "can_mod_post": false,
            "created_utc": 1753955351,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 40,
            "author_fullname": "t2_p1gfswvnw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I would actually love a dedicated AI NPU on a PCIE Slot with 64-1024 GB VRAM for an affordable Price.\n\nTaking off pressure from Gamers and GPU's.\n\n\nYou could get a Mid Range or High End GPU for Gaming and get any amount of AIB NPU for your AI needs.\n\nThat will also enable 4k high fps gaming with AI enhanced NPC's if the Models are offloaded from the GPU itself.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64xpb6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would actually love a dedicated AI NPU on a PCIE Slot with 64-1024 GB VRAM for an affordable Price.&lt;/p&gt;\n\n&lt;p&gt;Taking off pressure from Gamers and GPU&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;You could get a Mid Range or High End GPU for Gaming and get any amount of AIB NPU for your AI needs.&lt;/p&gt;\n\n&lt;p&gt;That will also enable 4k high fps gaming with AI enhanced NPC&amp;#39;s if the Models are offloaded from the GPU itself.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n64xpb6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753955351,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 40
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6593ie",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "isugimpy",
                      "can_mod_post": false,
                      "created_utc": 1753960897,
                      "send_replies": true,
                      "parent_id": "t1_n652gvi",
                      "score": 11,
                      "author_fullname": "t2_dm4gp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Added to the kernel in 6.14.  It's amdxdna.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6593ie",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Added to the kernel in 6.14.  It&amp;#39;s amdxdna.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n6593ie/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753960897,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65b7zs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Repeat_22",
                      "can_mod_post": false,
                      "created_utc": 1753961799,
                      "send_replies": true,
                      "parent_id": "t1_n652gvi",
                      "score": 4,
                      "author_fullname": "t2_viufiki6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "AMDXDNA2 driver since 6.14",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65b7zs",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;AMDXDNA2 driver since 6.14&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65b7zs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753961799,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n652gvi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "grigio",
            "can_mod_post": false,
            "created_utc": 1753957830,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 9,
            "author_fullname": "t2_37dhn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Still waiting the NPU driver for Linux.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n652gvi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Still waiting the NPU driver for Linux.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n652gvi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753957830,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n64x8kg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "_SYSTEM_ADMIN_MOD_",
            "can_mod_post": false,
            "created_utc": 1753955098,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 7,
            "author_fullname": "t2_twl3xhruz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "*Entire Article:*\n\n&gt; **AMD Is Reportedly Looking to Introduce a Dedicated Discrete NPU, Similar to Gaming GPUs But Targeted Towards AI Performance On PCs; Taking Edge AI to New Levels**\n&gt; \n&gt; AMD is reportedly looking towards developing a discrete NPU solution for PC consumers, which would allow the average system to get supercharged AI capabilities.\n&gt; \n&gt; **AMD's Next Project For Consumers Could Be a \"Discrete NPU\" That Would Act Similar to a Standalone GPU**\n&gt; \n&gt; The idea of a discrete NPU isn't exactly new, and we have seen solutions such as Qualcomm's Cloud AI 100 Ultra inferencing card, which is designed for a similar objective to what AMD wants to achieve. According to a report by CRN, AMD's head of client CPU business, Rahul Tikoo, is considering the market prospects of introducing a dedicated AI engine in the form of a discrete card for PC consumers, aiding AMD's efforts to make AI computable for everyone.\n&gt; \n&gt; &gt; It’s a very new set of use cases, so we’re watching that space carefully, but we do have solutions if you want to get into that space—we will be able to. But certainly if you look at the breadth of our technologies and solutions, it’s not hard to imagine we can get there pretty quickly.\n&gt; \n&gt; Dedicated AI engines on processors have seen massive adoption over the past few years, particularly fueled by lineups such as AMD's Strix Point or Intel's Lunar Lake mobile processors. Ever since we have entered the \"AI PC\" era, companies are rushing towards advancing their AI engines to squeeze as much TOPS as possible; however, this solution is mainly limited to compact devices like laptops, and for consumer PCs, well, there are no such options available for now. AMD might look to capitalize on this market gap with a discrete NPU card.\n&gt; \n&gt; AMD's whole consumer ecosystem is making the AI pivot, and one reason we say this is that with the recent Strix Halo APUs, the company has managed to bring in support for 128B parameter LLMs, which is simply amazing. Compact mini-PCs have managed to run massive models locally, allowing consumers to leverage the edge AI hype, and it won't be wrong to say that AMD's XDNA engines have been the leading option when it comes to AI compute on mobile chips.\n&gt; \n&gt; There might be skepticism about the scale of a \"discrete NPU\" market since not every consumer needs high-end AI capabilities, but if AMD wants it to be targeted towards the professional segment, that could be an option. For now, things are at the early stage, but it seems like Team Red has a lot planned in for the AI market.\n\n*Source: https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/*",
            "edited": 1753962252,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64x8kg",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Entire Article:&lt;/em&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;AMD Is Reportedly Looking to Introduce a Dedicated Discrete NPU, Similar to Gaming GPUs But Targeted Towards AI Performance On PCs; Taking Edge AI to New Levels&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;AMD is reportedly looking towards developing a discrete NPU solution for PC consumers, which would allow the average system to get supercharged AI capabilities.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;AMD&amp;#39;s Next Project For Consumers Could Be a &amp;quot;Discrete NPU&amp;quot; That Would Act Similar to a Standalone GPU&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The idea of a discrete NPU isn&amp;#39;t exactly new, and we have seen solutions such as Qualcomm&amp;#39;s Cloud AI 100 Ultra inferencing card, which is designed for a similar objective to what AMD wants to achieve. According to a report by CRN, AMD&amp;#39;s head of client CPU business, Rahul Tikoo, is considering the market prospects of introducing a dedicated AI engine in the form of a discrete card for PC consumers, aiding AMD&amp;#39;s efforts to make AI computable for everyone.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;It’s a very new set of use cases, so we’re watching that space carefully, but we do have solutions if you want to get into that space—we will be able to. But certainly if you look at the breadth of our technologies and solutions, it’s not hard to imagine we can get there pretty quickly.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Dedicated AI engines on processors have seen massive adoption over the past few years, particularly fueled by lineups such as AMD&amp;#39;s Strix Point or Intel&amp;#39;s Lunar Lake mobile processors. Ever since we have entered the &amp;quot;AI PC&amp;quot; era, companies are rushing towards advancing their AI engines to squeeze as much TOPS as possible; however, this solution is mainly limited to compact devices like laptops, and for consumer PCs, well, there are no such options available for now. AMD might look to capitalize on this market gap with a discrete NPU card.&lt;/p&gt;\n\n&lt;p&gt;AMD&amp;#39;s whole consumer ecosystem is making the AI pivot, and one reason we say this is that with the recent Strix Halo APUs, the company has managed to bring in support for 128B parameter LLMs, which is simply amazing. Compact mini-PCs have managed to run massive models locally, allowing consumers to leverage the edge AI hype, and it won&amp;#39;t be wrong to say that AMD&amp;#39;s XDNA engines have been the leading option when it comes to AI compute on mobile chips.&lt;/p&gt;\n\n&lt;p&gt;There might be skepticism about the scale of a &amp;quot;discrete NPU&amp;quot; market since not every consumer needs high-end AI capabilities, but if AMD wants it to be targeted towards the professional segment, that could be an option. For now, things are at the early stage, but it seems like Team Red has a lot planned in for the AI market.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;em&gt;Source: &lt;a href=\"https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/\"&gt;https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n64x8kg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753955098,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n657ldu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "SandboChang",
            "can_mod_post": false,
            "created_utc": 1753960235,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 6,
            "author_fullname": "t2_10icmj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If only their software caught up. I heard ROCm 7.0 will be great and let’s hope that the case.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n657ldu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If only their software caught up. I heard ROCm 7.0 will be great and let’s hope that the case.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n657ldu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753960235,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n655qki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Remote-Telephone-682",
            "can_mod_post": false,
            "created_utc": 1753959400,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 5,
            "author_fullname": "t2_7guj3cyv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I mean, I think there is a market for it. It seems that nvidia is deliberatly holding back with their consumer gpus because of the bad memories of having 1080s cannibalize some portion of their datacenter market a decade or so ago. If you did take a consumer+ chip and place additional memory on the board I think there is definitely room to enter but nvidia has the DGX spark on the roadmap but I don't know how many of them they actually intend to build",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n655qki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean, I think there is a market for it. It seems that nvidia is deliberatly holding back with their consumer gpus because of the bad memories of having 1080s cannibalize some portion of their datacenter market a decade or so ago. If you did take a consumer+ chip and place additional memory on the board I think there is definitely room to enter but nvidia has the DGX spark on the roadmap but I don&amp;#39;t know how many of them they actually intend to build&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n655qki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753959400,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6507pe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1753956689,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 3,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's exactly what we need. Great to see them pushing this!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6507pe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s exactly what we need. Great to see them pushing this!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n6507pe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753956689,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65bcx7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Repeat_22",
                      "can_mod_post": false,
                      "created_utc": 1753961855,
                      "send_replies": true,
                      "parent_id": "t1_n657m9n",
                      "score": 1,
                      "author_fullname": "t2_viufiki6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Well if works with Lemonade like current AMD APU NPUs we are OK.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65bcx7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well if works with Lemonade like current AMD APU NPUs we are OK.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65bcx7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753961855,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n657m9n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "05032-MendicantBias",
            "can_mod_post": false,
            "created_utc": 1753960246,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 3,
            "author_fullname": "t2_6id3lwou",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's a good idea all around. It limits competition for GPUs by AI, and gives much superior performance per watt.\n\nThe caveat is that there needs to be amazing driver support for ML framework, or that silicon is useless.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n657m9n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s a good idea all around. It limits competition for GPUs by AI, and gives much superior performance per watt.&lt;/p&gt;\n\n&lt;p&gt;The caveat is that there needs to be amazing driver support for ML framework, or that silicon is useless.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n657m9n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753960246,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6562vu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Psionikus",
            "can_mod_post": false,
            "created_utc": 1753959555,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 2,
            "author_fullname": "t2_8vhsch4i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Certainly would scratch an itch if your only reason to get a machine with a big GPU was to do AI and the integrated GPU could suit you just fine.\n\nThere's usually a deeper strategy.  Maybe modifying their existing GPUs to be competitive in data centers looks slower than starting from a more basic design that can choose which challenges are in front of it.",
            "edited": 1753961230,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6562vu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Certainly would scratch an itch if your only reason to get a machine with a big GPU was to do AI and the integrated GPU could suit you just fine.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s usually a deeper strategy.  Maybe modifying their existing GPUs to be competitive in data centers looks slower than starting from a more basic design that can choose which challenges are in front of it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n6562vu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753959555,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65brk0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Repeat_22",
                      "can_mod_post": false,
                      "created_utc": 1753962022,
                      "send_replies": true,
                      "parent_id": "t1_n658ufv",
                      "score": 6,
                      "author_fullname": "t2_viufiki6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "GPUs are been used for LLM etc not because they are designed for that task, but because they can do it better than CPUs. \n\nNPUs (and similar ASIC cards) are even better to do that job than GPUs, cheaper to make as less silicon is needed, for less energy while way faster.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65brk0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPUs are been used for LLM etc not because they are designed for that task, but because they can do it better than CPUs. &lt;/p&gt;\n\n&lt;p&gt;NPUs (and similar ASIC cards) are even better to do that job than GPUs, cheaper to make as less silicon is needed, for less energy while way faster.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65brk0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753962022,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n659v3y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "cangaroo_hamam",
                      "can_mod_post": false,
                      "created_utc": 1753961227,
                      "send_replies": true,
                      "parent_id": "t1_n658ufv",
                      "score": 3,
                      "author_fullname": "t2_1441omqx4c",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"I personally do not want yet another device in my PC... \"  \nThose who sell said devices beg to differ.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n659v3y",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;I personally do not want yet another device in my PC... &amp;quot;&lt;br/&gt;\nThose who sell said devices beg to differ.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdx65u",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n659v3y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753961227,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n658ufv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "he29",
            "can_mod_post": false,
            "created_utc": 1753960788,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 1,
            "author_fullname": "t2_2zdvefj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I personally do not want yet another device in my PC. I just want them to stop nerfing customer GPUs, so that I can play games _and_ play with LLMs using the same card.\n\nThe hardware is already plenty capable as it is (currently using RX 6800 and llama.cpp), they just need to bump VRAM and memory bandwidth a little bit higher, without also bumping the price to crazy \"business class\" levels...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n658ufv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I personally do not want yet another device in my PC. I just want them to stop nerfing customer GPUs, so that I can play games &lt;em&gt;and&lt;/em&gt; play with LLMs using the same card.&lt;/p&gt;\n\n&lt;p&gt;The hardware is already plenty capable as it is (currently using RX 6800 and llama.cpp), they just need to bump VRAM and memory bandwidth a little bit higher, without also bumping the price to crazy &amp;quot;business class&amp;quot; levels...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n658ufv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753960788,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n65etbh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ViveIn",
            "can_mod_post": false,
            "created_utc": 1753963229,
            "send_replies": true,
            "parent_id": "t3_1mdx65u",
            "score": 1,
            "author_fullname": "t2_1gw3ty7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yeah it would be an enormous market",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65etbh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah it would be an enormous market&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/n65etbh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753963229,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdx65u",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]