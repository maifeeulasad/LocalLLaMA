[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Let's say we have a 30b, 24b, 14b, 7b model that exceeds in quality but the context window is like... 8k or worse, 4k. What can you possibly do in this case?\n\nBack in 2022 I used a unkown gpt plugin involving PDF files are permanent memory that didn't used the context window, even now it would be really useful if there was also a manner of insering some sort of text, pdf or text document file for the model to get \"fixed on\", like it's permanent focus (like a bot Card for example, where the biography would be stored instead of resent at every request and then combined to the whole context of the chat).\n\nResume: Method of increasing context lengh or using document for loading what chat context is focused on.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Safe methods of increasing Context Window of models?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lz5sm6",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.91,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_eljq22kg",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752445683,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a 30b, 24b, 14b, 7b model that exceeds in quality but the context window is like... 8k or worse, 4k. What can you possibly do in this case?&lt;/p&gt;\n\n&lt;p&gt;Back in 2022 I used a unkown gpt plugin involving PDF files are permanent memory that didn&amp;#39;t used the context window, even now it would be really useful if there was also a manner of insering some sort of text, pdf or text document file for the model to get &amp;quot;fixed on&amp;quot;, like it&amp;#39;s permanent focus (like a bot Card for example, where the biography would be stored instead of resent at every request and then combined to the whole context of the chat).&lt;/p&gt;\n\n&lt;p&gt;Resume: Method of increasing context lengh or using document for loading what chat context is focused on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1lz5sm6",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "WEREWOLF_BX13",
            "discussion_type": null,
            "num_comments": 8,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/",
            "subreddit_subscribers": 499297,
            "created_utc": 1752445683,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n3374e8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "celsowm",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n32c4ez",
                                "score": 1,
                                "author_fullname": "t2_dyvrh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "https://preview.redd.it/edztevbtvucf1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=d3cbe4bcf0854a56f06841565549754ced1d5794",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3374e8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/edztevbtvucf1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d3cbe4bcf0854a56f06841565549754ced1d5794\"&gt;https://preview.redd.it/edztevbtvucf1.png?width=1080&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d3cbe4bcf0854a56f06841565549754ced1d5794&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lz5sm6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n3374e8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752505904,
                                "media_metadata": {
                                  "edztevbtvucf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 216,
                                        "x": 108,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2fe2091b93ff4b5bda5f5d4eea26747fb00a9d99"
                                      },
                                      {
                                        "y": 432,
                                        "x": 216,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0832cd1c5e2706fa914aea16297168c85e255220"
                                      },
                                      {
                                        "y": 640,
                                        "x": 320,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa761a0cf6fcb5f5c15e6a8f7d31c7673fd94506"
                                      },
                                      {
                                        "y": 1280,
                                        "x": 640,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8036939e7e3c8d4f44e0b656cd1e66fd6eb628a"
                                      },
                                      {
                                        "y": 1920,
                                        "x": 960,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d54b42e321a74b2e792482de9c8f2cf8e452415"
                                      },
                                      {
                                        "y": 2160,
                                        "x": 1080,
                                        "u": "https://preview.redd.it/edztevbtvucf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=399572d6e5f60d082806cd83ee4c3f94a7c31507"
                                      }
                                    ],
                                    "s": {
                                      "y": 2259,
                                      "x": 1080,
                                      "u": "https://preview.redd.it/edztevbtvucf1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=d3cbe4bcf0854a56f06841565549754ced1d5794"
                                    },
                                    "id": "edztevbtvucf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752505904,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n32c4ez",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "WEREWOLF_BX13",
                      "can_mod_post": false,
                      "created_utc": 1752496001,
                      "send_replies": true,
                      "parent_id": "t1_n2z9v4q",
                      "score": 1,
                      "author_fullname": "t2_eljq22kg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Any tips on how to know if your model will support YaRn properly?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n32c4ez",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Any tips on how to know if your model will support YaRn properly?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lz5sm6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n32c4ez/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752496001,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2z9v4q",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "celsowm",
            "can_mod_post": false,
            "created_utc": 1752446966,
            "send_replies": true,
            "parent_id": "t3_1lz5sm6",
            "score": 12,
            "author_fullname": "t2_dyvrh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "```\n{\n    ...,\n    \"rope_scaling\": {\n        \"rope_type\": \"yarn\",\n        \"factor\": 4.0,\n        \"original_max_position_embeddings\": 32768\n    }\n}\n```",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2z9v4q",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;\n{\n    ...,\n    &amp;quot;rope_scaling&amp;quot;: {\n        &amp;quot;rope_type&amp;quot;: &amp;quot;yarn&amp;quot;,\n        &amp;quot;factor&amp;quot;: 4.0,\n        &amp;quot;original_max_position_embeddings&amp;quot;: 32768\n    }\n}\n&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n2z9v4q/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752446966,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lz5sm6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n36brcu",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "mpasila",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n3665qr",
                                                    "score": 1,
                                                    "author_fullname": "t2_lhhagpdw",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "It's part of it. Basically it stores the chunks in the vector database. So when you prompt the model the RAG system will pick an entry/chunk from the database that is most relevant for your prompt and add that chunk into the prompt before anything is sent to the LLM.\n\nThe simplest RAG doesn't even use vector databases, it can just be stored in plain text inside a \"memory/lore book\" where you'd manually add entries and keywords that will trigger that entry or \"memory\" when your message/prompt contains one of the keywords. It's often used for world building and stuff.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n36brcu",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s part of it. Basically it stores the chunks in the vector database. So when you prompt the model the RAG system will pick an entry/chunk from the database that is most relevant for your prompt and add that chunk into the prompt before anything is sent to the LLM.&lt;/p&gt;\n\n&lt;p&gt;The simplest RAG doesn&amp;#39;t even use vector databases, it can just be stored in plain text inside a &amp;quot;memory/lore book&amp;quot; where you&amp;#39;d manually add entries and keywords that will trigger that entry or &amp;quot;memory&amp;quot; when your message/prompt contains one of the keywords. It&amp;#39;s often used for world building and stuff.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1lz5sm6",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n36brcu/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1752538862,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1752538862,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n3665qr",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "WEREWOLF_BX13",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n33xlej",
                                          "score": 1,
                                          "author_fullname": "t2_eljq22kg",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Vector is different from RAG? How do you use vector, I couldn't find info about this, only programing info.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n3665qr",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Vector is different from RAG? How do you use vector, I couldn&amp;#39;t find info about this, only programing info.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lz5sm6",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n3665qr/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1752536956,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1752536956,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n33xlej",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "mpasila",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n32ccl6",
                                "score": 1,
                                "author_fullname": "t2_lhhagpdw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "RAG is simply \"Retrieval Augmented Generation\" so it augments the prompt/context with relevant information. Vector is used to store the chunked documents or other information you give it. They are stored in chunks since the whole point is to only give the most relevant information without having to provide everything since that'll eat all the context.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n33xlej",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RAG is simply &amp;quot;Retrieval Augmented Generation&amp;quot; so it augments the prompt/context with relevant information. Vector is used to store the chunked documents or other information you give it. They are stored in chunks since the whole point is to only give the most relevant information without having to provide everything since that&amp;#39;ll eat all the context.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lz5sm6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n33xlej/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752513361,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752513361,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n32ccl6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "WEREWOLF_BX13",
                      "can_mod_post": false,
                      "created_utc": 1752496089,
                      "send_replies": true,
                      "parent_id": "t1_n2zb6sd",
                      "score": 1,
                      "author_fullname": "t2_eljq22kg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Could you tell me more about RAG and vector?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n32ccl6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Could you tell me more about RAG and vector?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lz5sm6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n32ccl6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752496089,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2zb6sd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "mpasila",
            "can_mod_post": false,
            "created_utc": 1752447406,
            "send_replies": true,
            "parent_id": "t3_1lz5sm6",
            "score": 0,
            "author_fullname": "t2_lhhagpdw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So you're describing RAG? RAG can be done many ways but if you want to like upload a pdf or whatever then vector databases with an embedding model (to pick the most relevant chunks from the database) probably make the most sense.\n\nTo actually increase context window you can use RoPE scaling to double it at least but it won't be as good.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2zb6sd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you&amp;#39;re describing RAG? RAG can be done many ways but if you want to like upload a pdf or whatever then vector databases with an embedding model (to pick the most relevant chunks from the database) probably make the most sense.&lt;/p&gt;\n\n&lt;p&gt;To actually increase context window you can use RoPE scaling to double it at least but it won&amp;#39;t be as good.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lz5sm6/safe_methods_of_increasing_context_window_of/n2zb6sd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752447406,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lz5sm6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]