[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "A quick heads up for anyone playing with the little [HuggingFaceTB/SmolLM3-3B](https://huggingface.co/HuggingFaceTB/SmolLM3-3B) model that was released a few weeks ago with llama.cpp.\n\nSmolLM3-3B supports toggling thinking mode using `/think` or `/no_think` in a system prompt, but it relies on Jinja template features that weren't available in llama.cpp's jinja processor until very recently (merged yesterday: [b56683eb](https://github.com/BradHutchings/Mmojo-Server/commit/b56683eb659d6d39138bd90b27cb258a21b7aa5c)).\n\nSo to get system-prompt `/think` and `/no_think` working, you need to be running the current master version of llama.cpp (until the next official release). I believe some Qwen3 templates might also be affected, so keep that in mind if you're using those.\n\n(And since it relies on the jinja template, if you want to be able to enable/disable thinking from the system prompt remember to pass `--jinja` to llama-cli and llama-server. Otherwise it will use a fallback template with no system prompt and no thinking.)\n\nAdditionally, I ran into a frustrating issue while using the llama-server with the built-in web client where SmolLM3-3B would stop thinking after a few messages even with thinking enabled. It turns out the model needs to see the `&lt;think&gt;&lt;/think&gt;` tags in previous messages or it will stop thinking. The llama web client, by default, has an option enabled that strips those tags.\n\nTo fix this, go to your web client settings -&gt; Reasoning and disable \"Exclude thought process when sending requests to API (Recommended for DeepSeek-R1)\".\n\nFinally, to have the web client correctly show the \"thinking\" section (that you can click to expand/collapse), you need to pass the `--reasoning-format none` option to llama-server. Example invocation:\n\n    ./llama-server --jinja -ngl 99 --temp 0.6 --reasoning-format none -c 64000 -fa -m ~/llama/models/smollm3-3b/SmolLM3-Q8_0.gguf",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Getting SmolLM3-3B's /think and /no_think to work with llama.cpp",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Tutorial | Guide"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfeipz",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.88,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 6,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_38xkk",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Tutorial | Guide",
            "can_mod_post": false,
            "score": 6,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754099505,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A quick heads up for anyone playing with the little &lt;a href=\"https://huggingface.co/HuggingFaceTB/SmolLM3-3B\"&gt;HuggingFaceTB/SmolLM3-3B&lt;/a&gt; model that was released a few weeks ago with llama.cpp.&lt;/p&gt;\n\n&lt;p&gt;SmolLM3-3B supports toggling thinking mode using &lt;code&gt;/think&lt;/code&gt; or &lt;code&gt;/no_think&lt;/code&gt; in a system prompt, but it relies on Jinja template features that weren&amp;#39;t available in llama.cpp&amp;#39;s jinja processor until very recently (merged yesterday: &lt;a href=\"https://github.com/BradHutchings/Mmojo-Server/commit/b56683eb659d6d39138bd90b27cb258a21b7aa5c\"&gt;b56683eb&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;So to get system-prompt &lt;code&gt;/think&lt;/code&gt; and &lt;code&gt;/no_think&lt;/code&gt; working, you need to be running the current master version of llama.cpp (until the next official release). I believe some Qwen3 templates might also be affected, so keep that in mind if you&amp;#39;re using those.&lt;/p&gt;\n\n&lt;p&gt;(And since it relies on the jinja template, if you want to be able to enable/disable thinking from the system prompt remember to pass &lt;code&gt;--jinja&lt;/code&gt; to llama-cli and llama-server. Otherwise it will use a fallback template with no system prompt and no thinking.)&lt;/p&gt;\n\n&lt;p&gt;Additionally, I ran into a frustrating issue while using the llama-server with the built-in web client where SmolLM3-3B would stop thinking after a few messages even with thinking enabled. It turns out the model needs to see the &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; tags in previous messages or it will stop thinking. The llama web client, by default, has an option enabled that strips those tags.&lt;/p&gt;\n\n&lt;p&gt;To fix this, go to your web client settings -&amp;gt; Reasoning and disable &amp;quot;Exclude thought process when sending requests to API (Recommended for DeepSeek-R1)&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Finally, to have the web client correctly show the &amp;quot;thinking&amp;quot; section (that you can click to expand/collapse), you need to pass the &lt;code&gt;--reasoning-format none&lt;/code&gt; option to llama-server. Example invocation:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;./llama-server --jinja -ngl 99 --temp 0.6 --reasoning-format none -c 64000 -fa -m ~/llama/models/smollm3-3b/SmolLM3-Q8_0.gguf\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?auto=webp&amp;s=049d11d6074271bc2869bc098ea0e6349fad17b5",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=210d7e5aa5feb8c1ba4995490dffc2c6390e22d2",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=72ddf9689e0962d05c6c024b4b695cb9794bb6ca",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=981e7a5684252e695178248adea004772a6db062",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5512ea26289819cd2f0dfd1f239935cece32dfcf",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=434567689943a3b73e96f753c8a3258d47c9a766",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2ff25afc08fd9bbaf1816eb558f97ca00295655f",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "tcN4L99bPskq12aPK3uI_je7rwGqtj2gvQXTVizAZ6M"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#0079d3",
            "id": "1mfeipz",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "cristoper",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mfeipz/getting_smollm33bs_think_and_no_think_to_work/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mfeipz/getting_smollm33bs_think_and_no_think_to_work/",
            "subreddit_subscribers": 508771,
            "created_utc": 1754099505,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6h6ati",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "cristoper",
                      "can_mod_post": false,
                      "created_utc": 1754109757,
                      "send_replies": true,
                      "parent_id": "t1_n6gx4a0",
                      "score": 1,
                      "author_fullname": "t2_38xkk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks, I didn't know about that flag. It works to disable thinking with llama-server, but only if I don't set a system prompt. As far as I can tell it works because it sets the \"enabled_thinking\" jinja variable to false, but the SmolLM3 template overrides that if there is a system prompt with \"/think\" is set.\n\nIt doesn't seem to have any effect with llama-cli, and I don't know why.\n\nLooking at the [PR](https://github.com/ggml-org/llama.cpp/pull/13771) for --reasoning-budget, it sounds like setting it to 0 should also force closed the \"&lt;/think&gt;\" tag... but I think that only works for models that include the opening tag as part of the template (which the SmolLM3 template does not).",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6h6ati",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks, I didn&amp;#39;t know about that flag. It works to disable thinking with llama-server, but only if I don&amp;#39;t set a system prompt. As far as I can tell it works because it sets the &amp;quot;enabled_thinking&amp;quot; jinja variable to false, but the SmolLM3 template overrides that if there is a system prompt with &amp;quot;/think&amp;quot; is set.&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem to have any effect with llama-cli, and I don&amp;#39;t know why.&lt;/p&gt;\n\n&lt;p&gt;Looking at the &lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/13771\"&gt;PR&lt;/a&gt; for --reasoning-budget, it sounds like setting it to 0 should also force closed the &amp;quot;&amp;lt;/think&amp;gt;&amp;quot; tag... but I think that only works for models that include the opening tag as part of the template (which the SmolLM3 template does not).&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfeipz",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfeipz/getting_smollm33bs_think_and_no_think_to_work/n6h6ati/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754109757,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6gx4a0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "suprjami",
            "can_mod_post": false,
            "created_utc": 1754105640,
            "send_replies": true,
            "parent_id": "t3_1mfeipz",
            "score": 2,
            "author_fullname": "t2_63b3t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You should be able to use `--reasoning-budget 0` to disable thinking.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6gx4a0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You should be able to use &lt;code&gt;--reasoning-budget 0&lt;/code&gt; to disable thinking.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfeipz/getting_smollm33bs_think_and_no_think_to_work/n6gx4a0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754105640,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfeipz",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]