[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I am trying to figure if there are any real AI models that has the ability to process real time streaming data on the computer monitor. Please forgive me if this is not the right place to post this.  ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Multimodal models that can \"read\" data on the monitor",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m2lklq",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.6,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1een629xni",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752791779,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to figure if there are any real AI models that has the ability to process real time streaming data on the computer monitor. Please forgive me if this is not the right place to post this.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m2lklq",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Crazy_Ad_6915",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/",
            "subreddit_subscribers": 501077,
            "created_utc": 1752791779,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3pxa91",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LA_rent_Aficionado",
            "can_mod_post": false,
            "created_utc": 1752793242,
            "send_replies": true,
            "parent_id": "t3_1m2lklq",
            "score": 1,
            "author_fullname": "t2_t8zbiflk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can likely use pixstral or Gemma, maybe qwenVL.  There are a few existing tools people have posted on here open source if you’re starting to get started on a workflow. \n\nIt likely depends on the type of data though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3pxa91",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can likely use pixstral or Gemma, maybe qwenVL.  There are a few existing tools people have posted on here open source if you’re starting to get started on a workflow. &lt;/p&gt;\n\n&lt;p&gt;It likely depends on the type of data though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/n3pxa91/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752793242,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2lklq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n3xru0n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "townofsalemfangay",
                      "can_mod_post": false,
                      "created_utc": 1752896794,
                      "send_replies": true,
                      "parent_id": "t1_n3q1e4u",
                      "score": 1,
                      "author_fullname": "t2_122dsg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There are plenty of vision-language models that can process multiple frames per second, i.e. video. The problem is, very few handle temporal context well *and* deliver strong conversational performance without hitting major VRAM or latency bottlenecks.\n\nTake SmolVLM 500M for instance, fantastic for edge devices and real-time frame ingestion, but it completely falls apart in dialog. It’s excellent at brute-force frame analysis, but basically useless outside of that domain.\n\nAt the opposite end of the spectrum, you’ve got something like Qwen 2.5 VL 72B. Unlike its smaller siblings (3B, 7B, or even 32B), the 72B version is phenomenal, great temporal grounding, strong language coherence, and can actually hold a meaningful conversation about what it sees. The catch? It’s VRAM-hungry, and unless you’re running a low-bit quant or have very capable hardware, the latency makes it infeasible for real-time use.\n\nIn my opinion, the best trade-off between latency, temporal consistency, and conversational ability is Xiaomi’s MiMo VL 7B RL. That’s what I’d pick for any real-time video understanding task.\n\nBut here’s the problem no one so far as acknowledge, and tbh, no one ever really talks about this factor, and it matters:\n\nYou cannot do true multi-frame-per-second *live* video processing with quantised (GGUF) models. The framework just wasn’t built for that.\n\nSo whatever model you choose, if you're planning to handle live video input, you’ll need to run it using native safetensors, not a quantised backend.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3xru0n",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are plenty of vision-language models that can process multiple frames per second, i.e. video. The problem is, very few handle temporal context well &lt;em&gt;and&lt;/em&gt; deliver strong conversational performance without hitting major VRAM or latency bottlenecks.&lt;/p&gt;\n\n&lt;p&gt;Take SmolVLM 500M for instance, fantastic for edge devices and real-time frame ingestion, but it completely falls apart in dialog. It’s excellent at brute-force frame analysis, but basically useless outside of that domain.&lt;/p&gt;\n\n&lt;p&gt;At the opposite end of the spectrum, you’ve got something like Qwen 2.5 VL 72B. Unlike its smaller siblings (3B, 7B, or even 32B), the 72B version is phenomenal, great temporal grounding, strong language coherence, and can actually hold a meaningful conversation about what it sees. The catch? It’s VRAM-hungry, and unless you’re running a low-bit quant or have very capable hardware, the latency makes it infeasible for real-time use.&lt;/p&gt;\n\n&lt;p&gt;In my opinion, the best trade-off between latency, temporal consistency, and conversational ability is Xiaomi’s MiMo VL 7B RL. That’s what I’d pick for any real-time video understanding task.&lt;/p&gt;\n\n&lt;p&gt;But here’s the problem no one so far as acknowledge, and tbh, no one ever really talks about this factor, and it matters:&lt;/p&gt;\n\n&lt;p&gt;You cannot do true multi-frame-per-second &lt;em&gt;live&lt;/em&gt; video processing with quantised (GGUF) models. The framework just wasn’t built for that.&lt;/p&gt;\n\n&lt;p&gt;So whatever model you choose, if you&amp;#39;re planning to handle live video input, you’ll need to run it using native safetensors, not a quantised backend.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2lklq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/n3xru0n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752896794,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3q1e4u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1752794602,
            "send_replies": true,
            "parent_id": "t3_1m2lklq",
            "score": 1,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If I remember correctly, the only open source model that can do real time streaming is qwen omni. I think the streaming includes the video input. An alternative solution is to build software that takes a screenshot and sends to a vision model along with a prompt at a set interval. Gemma3, Mistral Small 3.1 and qwen vl are all good multimodal choices.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3q1e4u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If I remember correctly, the only open source model that can do real time streaming is qwen omni. I think the streaming includes the video input. An alternative solution is to build software that takes a screenshot and sends to a vision model along with a prompt at a set interval. Gemma3, Mistral Small 3.1 and qwen vl are all good multimodal choices.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/n3q1e4u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752794602,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2lklq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3q2zul",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LostHisDog",
            "can_mod_post": false,
            "created_utc": 1752795134,
            "send_replies": true,
            "parent_id": "t3_1m2lklq",
            "score": 1,
            "author_fullname": "t2_x5jky",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I've been playing with screen reading today and it's a bit hit or miss. I wanted to use Gemma 3n but it's not really able to be run with vision on anything PC side that I know how to use easily. I ended up with Gemma 3 - gemma3:4b-it-qat - Ollama and Playwright and it can read the screens pretty well but interacting with the screens is much harder than it might seem. It's one thing for an LLM to see and recognize visually where a button is but telling a tool how to click on it seems to be the fight. \n\nAnyway, the gemma version I'm using is pretty quick on my spare 1080ti, a couple seconds if that to describe an image. I want to try Qwen 2.5vl 3b next and I think Phi had a good small vision model too. If you are throwing hardware at it, Mistral Small 24b is supposed to be pretty good too.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3q2zul",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been playing with screen reading today and it&amp;#39;s a bit hit or miss. I wanted to use Gemma 3n but it&amp;#39;s not really able to be run with vision on anything PC side that I know how to use easily. I ended up with Gemma 3 - gemma3:4b-it-qat - Ollama and Playwright and it can read the screens pretty well but interacting with the screens is much harder than it might seem. It&amp;#39;s one thing for an LLM to see and recognize visually where a button is but telling a tool how to click on it seems to be the fight. &lt;/p&gt;\n\n&lt;p&gt;Anyway, the gemma version I&amp;#39;m using is pretty quick on my spare 1080ti, a couple seconds if that to describe an image. I want to try Qwen 2.5vl 3b next and I think Phi had a good small vision model too. If you are throwing hardware at it, Mistral Small 24b is supposed to be pretty good too.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2lklq/multimodal_models_that_can_read_data_on_the/n3q2zul/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752795134,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2lklq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]