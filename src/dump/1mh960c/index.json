[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "First time fine tuning a model in \"the cloud\".\nRunpod was suggested. And what should I say - it's a pita since the first few seconds.\nRDP - only via VNC. Accessing volume? No. SCP? No. Accurately telling you how much you used of your persistent volume? No. Figure out yourself while counting by hand. There is 330t TB available, and 222 TB used. It can't show anything below a TB.\nSetting up my pod for work yesterday so I can start without brain damage into the week today.\nAwesome idea - but GPUs are out for this Region. But let us charge you for your persistent volume.\nYou think you can trick run pod, find a solution and just start all over with a new pod in a region where GPUs are available?\nHaha, no way. After you pressed \"deploy\" we will charge you now for both pots. Accessing the platform to work on your pods or manage them? Whole platform not loading since almost 20 minutes - no chance to do anything. But hey, we will charge you üòÇ\n\nI don't know what anyone is doing with runpod. Am I unlucky? Maybe. Is the platform working? Not anymore. Only for my user btw ü§£\nSpeedtest benchmark? Could still do cloud gaming at 4k 60 fps.\nBut can't access the platform.\n\nFor me this platform is just a pita. I wasted several days trying to fix things and incompatibility issues of their pods after deployment.\n\nThis is by far one of the worst IT experiences in my life.\nCan't build my own server since I am traveling too much.\n\nAny alternatives that are working and can be accessed?\n\n\n\nEdit:\nClearing cache doesn't help. Incognito mode let's me click on login - but the moment I login it's stucked again. Other Laptop with different OS -&gt; same outcome like in incognito mode.\nClearly, my account is bugged or something.\n\n\nEdit 2:\n\nCould access the platform after ~2 hours again, out of nowhere with a respond from support via email asking for my antivirus. (Didn't work on several systems, worked perfectly before)\nI really think my account was bugged",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Runpod breaks my head - need a working alternative",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mh960c",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_i00m20zzg",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754311303,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754301108,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First time fine tuning a model in &amp;quot;the cloud&amp;quot;.\nRunpod was suggested. And what should I say - it&amp;#39;s a pita since the first few seconds.\nRDP - only via VNC. Accessing volume? No. SCP? No. Accurately telling you how much you used of your persistent volume? No. Figure out yourself while counting by hand. There is 330t TB available, and 222 TB used. It can&amp;#39;t show anything below a TB.\nSetting up my pod for work yesterday so I can start without brain damage into the week today.\nAwesome idea - but GPUs are out for this Region. But let us charge you for your persistent volume.\nYou think you can trick run pod, find a solution and just start all over with a new pod in a region where GPUs are available?\nHaha, no way. After you pressed &amp;quot;deploy&amp;quot; we will charge you now for both pots. Accessing the platform to work on your pods or manage them? Whole platform not loading since almost 20 minutes - no chance to do anything. But hey, we will charge you üòÇ&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know what anyone is doing with runpod. Am I unlucky? Maybe. Is the platform working? Not anymore. Only for my user btw ü§£\nSpeedtest benchmark? Could still do cloud gaming at 4k 60 fps.\nBut can&amp;#39;t access the platform.&lt;/p&gt;\n\n&lt;p&gt;For me this platform is just a pita. I wasted several days trying to fix things and incompatibility issues of their pods after deployment.&lt;/p&gt;\n\n&lt;p&gt;This is by far one of the worst IT experiences in my life.\nCan&amp;#39;t build my own server since I am traveling too much.&lt;/p&gt;\n\n&lt;p&gt;Any alternatives that are working and can be accessed?&lt;/p&gt;\n\n&lt;p&gt;Edit:\nClearing cache doesn&amp;#39;t help. Incognito mode let&amp;#39;s me click on login - but the moment I login it&amp;#39;s stucked again. Other Laptop with different OS -&amp;gt; same outcome like in incognito mode.\nClearly, my account is bugged or something.&lt;/p&gt;\n\n&lt;p&gt;Edit 2:&lt;/p&gt;\n\n&lt;p&gt;Could access the platform after ~2 hours again, out of nowhere with a respond from support via email asking for my antivirus. (Didn&amp;#39;t work on several systems, worked perfectly before)\nI really think my account was bugged&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mh960c",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "IngloriousBastrd7908",
            "discussion_type": null,
            "num_comments": 12,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/",
            "subreddit_subscribers": 510259,
            "created_utc": 1754301108,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ug9ux",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "IngloriousBastrd7908",
                      "can_mod_post": false,
                      "created_utc": 1754302446,
                      "send_replies": true,
                      "parent_id": "t1_n6uew9n",
                      "score": 1,
                      "author_fullname": "t2_i00m20zzg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I got the volume problem. Just takes time to figure out how they do it on your pods. And that you need to buy volume for both kinds of \"volume\", since you will hustle if you try to install all software packages in /workspace/.\n\nBut, like I've said - the main problem is: can't access the dashbord. Contacted the support. Waiting and draining my money, since the pod was deployed ü§ô\n\nEdit: mistypo",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ug9ux",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I got the volume problem. Just takes time to figure out how they do it on your pods. And that you need to buy volume for both kinds of &amp;quot;volume&amp;quot;, since you will hustle if you try to install all software packages in /workspace/.&lt;/p&gt;\n\n&lt;p&gt;But, like I&amp;#39;ve said - the main problem is: can&amp;#39;t access the dashbord. Contacted the support. Waiting and draining my money, since the pod was deployed ü§ô&lt;/p&gt;\n\n&lt;p&gt;Edit: mistypo&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mh960c",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6ug9ux/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754302446,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6uew9n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ResidentPositive4122",
            "can_mod_post": false,
            "created_utc": 1754301713,
            "send_replies": true,
            "parent_id": "t3_1mh960c",
            "score": 2,
            "author_fullname": "t2_10nxrjjgay",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's a lot. I'll try to unpack:\n\n- You can use templates for your pods so you run whatever image you need. IaC.\n\n- You can use network volumes for the \"dedicated dc\" pods. You load your datasets there, and mount the volume on your pod. As an update they now also support S3 like APIs so you can load datasets directly without having to first boot a cheap pod.\n\n- You can see volume usage in the web dashboard (both for network, attached, and base volumes).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6uew9n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s a lot. I&amp;#39;ll try to unpack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;You can use templates for your pods so you run whatever image you need. IaC.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You can use network volumes for the &amp;quot;dedicated dc&amp;quot; pods. You load your datasets there, and mount the volume on your pod. As an update they now also support S3 like APIs so you can load datasets directly without having to first boot a cheap pod.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You can see volume usage in the web dashboard (both for network, attached, and base volumes).&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6uew9n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754301713,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mh960c",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6w6mqo",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "crookedstairs",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6w3i75",
                                                    "score": 2,
                                                    "author_fullname": "t2_9av3t",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "thanks for sharing your thoughts ü´∂üèª agree w your take - where we shine is on devex, which is most relevant if you're iterating frequently on your fine-tune runs",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6w6mqo",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thanks for sharing your thoughts ü´∂üèª agree w your take - where we shine is on devex, which is most relevant if you&amp;#39;re iterating frequently on your fine-tune runs&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mh960c",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6w6mqo/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754324214,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754324214,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6w3i75",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "FullOf_Bad_Ideas",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6vuua7",
                                          "score": 1,
                                          "author_fullname": "t2_9s7pmakgx",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Those are good points and are absolutely valid for places where finetuning happens often and has defined patterns, so it makes sense to automate parts of it and make it seamless.\n\nIn my case it's quite rare but intense, with no need for high parallelization (I've done only up to a few parallel runs when I was messing with parameters), where looking for a special solution wasn't needed - simple ssh to vm, get the run going and autoterminate vm on final checkpoint upload to HF does the job just fine and extra complexity isn't worth it.\n\nYou wouldn't recommend AWS lambda to a person that needs to transcode videos from their phone once per 3 months.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6w3i75",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those are good points and are absolutely valid for places where finetuning happens often and has defined patterns, so it makes sense to automate parts of it and make it seamless.&lt;/p&gt;\n\n&lt;p&gt;In my case it&amp;#39;s quite rare but intense, with no need for high parallelization (I&amp;#39;ve done only up to a few parallel runs when I was messing with parameters), where looking for a special solution wasn&amp;#39;t needed - simple ssh to vm, get the run going and autoterminate vm on final checkpoint upload to HF does the job just fine and extra complexity isn&amp;#39;t worth it.&lt;/p&gt;\n\n&lt;p&gt;You wouldn&amp;#39;t recommend AWS lambda to a person that needs to transcode videos from their phone once per 3 months.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mh960c",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6w3i75/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754323318,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754323318,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6vuua7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "crookedstairs",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6uz4vb",
                                "score": 1,
                                "author_fullname": "t2_9av3t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "u/FullOf_Bad_Ideas say more! We do have customers who enjoy using Modal for fine-tuning jobs (bc 1) easy to parallelize experiments 2) devex is a lot better 3) cold starts are fast which means quicker iteration loops). But would be interested in getting your feedback!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6vuua7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/u/FullOf_Bad_Ideas\"&gt;u/FullOf_Bad_Ideas&lt;/a&gt; say more! We do have customers who enjoy using Modal for fine-tuning jobs (bc 1) easy to parallelize experiments 2) devex is a lot better 3) cold starts are fast which means quicker iteration loops). But would be interested in getting your feedback!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mh960c",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6vuua7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754320852,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754320852,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6uz4vb",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754310685,
                      "send_replies": true,
                      "parent_id": "t1_n6ulm2e",
                      "score": 1,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Modal will be harder for fine-tuning jobs, it's great for hosting a model with autoscaling to zero though. But for one time run things like finetuning runs it's not the right fit IMO.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6uz4vb",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Modal will be harder for fine-tuning jobs, it&amp;#39;s great for hosting a model with autoscaling to zero though. But for one time run things like finetuning runs it&amp;#39;s not the right fit IMO.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mh960c",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6uz4vb/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754310685,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6x2nbu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Gregory-Wolf",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6vtu3l",
                                          "score": 1,
                                          "author_fullname": "t2_gethr3mh",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I didn't understand what you mean.  \nI was talking about Modal being more expensive than Runpod. And Runpod has serverless with scaling too.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6x2nbu",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t understand what you mean.&lt;br/&gt;\nI was talking about Modal being more expensive than Runpod. And Runpod has serverless with scaling too.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mh960c",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6x2nbu/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754333196,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754333196,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6vtu3l",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "crookedstairs",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6v138u",
                                "score": 1,
                                "author_fullname": "t2_9av3t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Depends on your use case! If your workloads are spiky, you'll benefit from a serverless model where GPU resources are automatically scaled up/down for you based on demand and you only pay for what you use. If your workload is stable and saturating your GPUs 24/7, then yes a non-serverless option will be cheaper.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6vtu3l",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Depends on your use case! If your workloads are spiky, you&amp;#39;ll benefit from a serverless model where GPU resources are automatically scaled up/down for you based on demand and you only pay for what you use. If your workload is stable and saturating your GPUs 24/7, then yes a non-serverless option will be cheaper.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mh960c",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6vtu3l/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754320560,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754320560,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6v138u",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Gregory-Wolf",
                      "can_mod_post": false,
                      "created_utc": 1754311397,
                      "send_replies": true,
                      "parent_id": "t1_n6ulm2e",
                      "score": 1,
                      "author_fullname": "t2_gethr3mh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Isn't Modal more expensive? I guess it doesn't mean much when you rent for a few hours. But if you rent for months - it counts.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6v138u",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Isn&amp;#39;t Modal more expensive? I guess it doesn&amp;#39;t mean much when you rent for a few hours. But if you rent for months - it counts.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mh960c",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6v138u/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754311397,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ulm2e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "thatphotoguy89",
            "can_mod_post": false,
            "created_utc": 1754305079,
            "send_replies": true,
            "parent_id": "t3_1mh960c",
            "score": 1,
            "author_fullname": "t2_nmj51",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Maybe look into Modal? There‚Äôs a bit of a learning curve with the config files, but other than that, it‚Äôs pretty straightforward [Modal: High-performance AI infrastructure](https://modal.com/)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ulm2e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe look into Modal? There‚Äôs a bit of a learning curve with the config files, but other than that, it‚Äôs pretty straightforward &lt;a href=\"https://modal.com/\"&gt;Modal: High-performance AI infrastructure&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6ulm2e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754305079,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mh960c",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6uzcrb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullOf_Bad_Ideas",
            "can_mod_post": false,
            "created_utc": 1754310767,
            "send_replies": true,
            "parent_id": "t3_1mh960c",
            "score": 1,
            "author_fullname": "t2_9s7pmakgx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "try to use Runpod CLI to manage your pod from there and kill the deployment to stop wasting money on it - https://docs.runpod.io/runpodctl/overview\n\nI am not sure if Settings page will load for you though and you need to create an API key there",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6uzcrb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;try to use Runpod CLI to manage your pod from there and kill the deployment to stop wasting money on it - &lt;a href=\"https://docs.runpod.io/runpodctl/overview\"&gt;https://docs.runpod.io/runpodctl/overview&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am not sure if Settings page will load for you though and you need to create an API key there&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mh960c/runpod_breaks_my_head_need_a_working_alternative/n6uzcrb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754310767,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mh960c",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]