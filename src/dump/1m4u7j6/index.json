[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Alright so basically - I want to run qwen3 235b MoE. I dont wanna pay 235b MoE money tho. So far I've been eyeing grabbing an old dell xeon workstation, slapping in lots of RAM &amp; two mi50 cards &amp; calling it a day. Would that work? probably i guess, hell you'd even get good performance out of that running 32b models which do the job for most cases. but i want real crackhead technology. completely out of the box shit. the funnier in its sheer absurdity/cheaper/faster the better. let's hear what you guys can think of ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What's the most crackhead garbage local LLM setup you can think of?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m4u7j6",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.89,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 41,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_9y0b4xlc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 41,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753031293,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright so basically - I want to run qwen3 235b MoE. I dont wanna pay 235b MoE money tho. So far I&amp;#39;ve been eyeing grabbing an old dell xeon workstation, slapping in lots of RAM &amp;amp; two mi50 cards &amp;amp; calling it a day. Would that work? probably i guess, hell you&amp;#39;d even get good performance out of that running 32b models which do the job for most cases. but i want real crackhead technology. completely out of the box shit. the funnier in its sheer absurdity/cheaper/faster the better. let&amp;#39;s hear what you guys can think of &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m4u7j6",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "caraccidentGAMING",
            "discussion_type": null,
            "num_comments": 43,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/",
            "subreddit_subscribers": 502030,
            "created_utc": 1753031293,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n47q98w",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "DorphinPack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n472fuu",
                                "score": 19,
                                "author_fullname": "t2_zebuyjw9s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Much worse -- a cluster. Sooo much more complex. It's gloriously stupid.\n\nAlso, even if you pay out the nose for RPi 5s you'd still spend like double/triple that on the networking gear unless you got lucky buying used.\n\nAssuming u/sebgggg meant putting a 10G PCIe NIC on each RPi and then connecting them to a switch with at least 30 10G ports.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n47q98w",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Much worse -- a cluster. Sooo much more complex. It&amp;#39;s gloriously stupid.&lt;/p&gt;\n\n&lt;p&gt;Also, even if you pay out the nose for RPi 5s you&amp;#39;d still spend like double/triple that on the networking gear unless you got lucky buying used.&lt;/p&gt;\n\n&lt;p&gt;Assuming &lt;a href=\"/u/sebgggg\"&gt;u/sebgggg&lt;/a&gt; meant putting a 10G PCIe NIC on each RPi and then connecting them to a switch with at least 30 10G ports.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47q98w/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753038898,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753038898,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 19
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n472fuu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "caraccidentGAMING",
                      "can_mod_post": false,
                      "created_utc": 1753031723,
                      "send_replies": true,
                      "parent_id": "t1_n471rq1",
                      "score": 7,
                      "author_fullname": "t2_9y0b4xlc",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "isn't this just building a bigger gpu out of a lot of small cpus\nIm down for this",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n472fuu",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;isn&amp;#39;t this just building a bigger gpu out of a lot of small cpus\nIm down for this&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n472fuu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753031723,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n471rq1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "sebgggg",
            "can_mod_post": false,
            "created_utc": 1753031527,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 78,
            "author_fullname": "t2_zsujj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A cluster of 30 raspberry pis with 10gb ethernet because it gotta go fast",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n471rq1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A cluster of 30 raspberry pis with 10gb ethernet because it gotta go fast&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n471rq1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753031527,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 78
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n48b2nk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "KontoOficjalneMR",
                      "can_mod_post": false,
                      "created_utc": 1753045377,
                      "send_replies": true,
                      "parent_id": "t1_n47f3if",
                      "score": 8,
                      "author_fullname": "t2_16x2kodiqz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This wins a thread IMO",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n48b2nk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This wins a thread IMO&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48b2nk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753045377,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n48vk0w",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "1ncehost",
                      "can_mod_post": false,
                      "created_utc": 1753052183,
                      "send_replies": true,
                      "parent_id": "t1_n47f3if",
                      "score": 2,
                      "author_fullname": "t2_lrannsv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is wonderful",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n48vk0w",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is wonderful&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48vk0w/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753052183,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n499vd4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "triynizzles1",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n498vzp",
                                "score": 2,
                                "author_fullname": "t2_zr0g49ixt",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "There would be no wait time to load the model into memory XD\n\nI Would definitely love to see someone try this out.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n499vd4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There would be no wait time to load the model into memory XD&lt;/p&gt;\n\n&lt;p&gt;I Would definitely love to see someone try this out.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n499vd4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753057253,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753057253,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n498vzp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "TheSilverSmith47",
                      "can_mod_post": false,
                      "created_utc": 1753056887,
                      "send_replies": true,
                      "parent_id": "t1_n47f3if",
                      "score": 1,
                      "author_fullname": "t2_29au5bw5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Do you know if anyone has tried this? How does it compare to a CPU + RAM setup in performance and cost effectiveness?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n498vzp",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you know if anyone has tried this? How does it compare to a CPU + RAM setup in performance and cost effectiveness?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n498vzp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753056887,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n47f3if",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753035445,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 35,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The most garbage llm set up I can think of would be an inexpensive server board or thread ripper with 128 PCI gen 5 lanes. Populate every lane with an NVME drive and then put it in a raid zero. You’ll get like 500 GB per second read speed from your storage. Then you can inference off storage instead of RAM or a GPU.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47f3if",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The most garbage llm set up I can think of would be an inexpensive server board or thread ripper with 128 PCI gen 5 lanes. Populate every lane with an NVME drive and then put it in a raid zero. You’ll get like 500 GB per second read speed from your storage. Then you can inference off storage instead of RAM or a GPU.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47f3if/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753035445,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 35
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n47qmov",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1753039014,
                      "send_replies": true,
                      "parent_id": "t1_n471r19",
                      "score": 5,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Put it in a Lack Rack!!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n47qmov",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Put it in a Lack Rack!!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47qmov/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753039014,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n471r19",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DorphinPack",
            "can_mod_post": false,
            "created_utc": 1753031521,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 28,
            "author_fullname": "t2_zebuyjw9s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I always feel that signature mix of admiration and horror when I see someone doing parallel PSUs with paperclip bridges so they can power an ungodly number of cheap GPUs",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n471r19",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I always feel that signature mix of admiration and horror when I see someone doing parallel PSUs with paperclip bridges so they can power an ungodly number of cheap GPUs&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n471r19/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753031521,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 28
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n47zr7l",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "_xulion",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n47vbu9",
                                                                        "score": 4,
                                                                        "author_fullname": "t2_a1dvxm4d",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "512 G. Trying to get 1T",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n47zr7l",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;512 G. Trying to get 1T&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1m4u7j6",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47zr7l/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753041895,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753041895,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 4
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n47vbu9",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Soggy-Camera1270",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n47r7dq",
                                                              "score": 1,
                                                              "author_fullname": "t2_6kmvfbdk",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "How much ram do you have?",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n47vbu9",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How much ram do you have?&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m4u7j6",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47vbu9/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753040509,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753040509,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n47r7dq",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "_xulion",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n47qdh2",
                                                    "score": 2,
                                                    "author_fullname": "t2_a1dvxm4d",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Correct. The reason I use 8b is because of not having enough memory for full weight. \n\nI did some llama bench before (actually posted questions about why no speed improvement by quant the model) and the speed pretty much the same. I’m trying to get more ram now so I can run full weight.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n47r7dq",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Correct. The reason I use 8b is because of not having enough memory for full weight. &lt;/p&gt;\n\n&lt;p&gt;I did some llama bench before (actually posted questions about why no speed improvement by quant the model) and the speed pretty much the same. I’m trying to get more ram now so I can run full weight.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m4u7j6",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47r7dq/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753039193,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753039193,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n47qdh2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "DorphinPack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n47lr0s",
                                          "score": 2,
                                          "author_fullname": "t2_zebuyjw9s",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Should help for total memory usage though, right?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n47qdh2",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Should help for total memory usage though, right?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m4u7j6",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47qdh2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753038935,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753038935,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n47lr0s",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "_xulion",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n47g755",
                                "score": 7,
                                "author_fullname": "t2_a1dvxm4d",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "8b. But it doesn’t matter. CPU will covert it to double anyway as there is no hardware support for 4b or 8b.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n47lr0s",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;8b. But it doesn’t matter. CPU will covert it to double anyway as there is no hardware support for 4b or 8b.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47lr0s/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753037502,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753037502,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n47g755",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Own-Potential-2308",
                      "can_mod_post": false,
                      "created_utc": 1753035782,
                      "send_replies": true,
                      "parent_id": "t1_n474joq",
                      "score": 5,
                      "author_fullname": "t2_18di024ua3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Quant?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n47g755",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Quant?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47g755/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753035782,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n47zoqg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "_xulion",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n47p354",
                                "score": 3,
                                "author_fullname": "t2_a1dvxm4d",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "GPU may consume more power unless it has enough VRAM. Currently my setup consumes just 300W more compared to idle during inference.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n47zoqg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPU may consume more power unless it has enough VRAM. Currently my setup consumes just 300W more compared to idle during inference.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47zoqg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753041873,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753041873,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n47p354",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Cool-Chemical-5629",
                      "can_mod_post": false,
                      "created_utc": 1753038535,
                      "send_replies": true,
                      "parent_id": "t1_n474joq",
                      "score": 1,
                      "author_fullname": "t2_qz1qjc86",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This doesn't sound too bad. Maybe if you added a GPU, wouldn't even have to be super expensive one, just a standard gaming GPU would do, you could give that inference a good boost, but those Intel CPUs are rather hungry, I don't want to see those bills for electric power to run that lol",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n47p354",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This doesn&amp;#39;t sound too bad. Maybe if you added a GPU, wouldn&amp;#39;t even have to be super expensive one, just a standard gaming GPU would do, you could give that inference a good boost, but those Intel CPUs are rather hungry, I don&amp;#39;t want to see those bills for electric power to run that lol&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47p354/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753038535,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n474joq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "_xulion",
            "can_mod_post": false,
            "created_utc": 1753032339,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 11,
            "author_fullname": "t2_a1dvxm4d",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My dual Xeon (gold 6140) run this 235B-A22B at around 3-4 t/s, without GPU.  It also can run Deepseek R1 528 at about 1.5t/s.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n474joq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My dual Xeon (gold 6140) run this 235B-A22B at around 3-4 t/s, without GPU.  It also can run Deepseek R1 528 at about 1.5t/s.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n474joq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753032339,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47xe5w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "kholejones8888",
            "can_mod_post": false,
            "created_utc": 1753041157,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 6,
            "author_fullname": "t2_1jp9h6pxqa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GPT4FREE is the most busted setup you can have.\n\nhttps://github.com/xtekky/gpt4free\n\nHuggingSpace has qwen3 235B MoE on tap.\n\nYou can plug it directly into KiloCode, it’s fine",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47xe5w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPT4FREE is the most busted setup you can have.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/xtekky/gpt4free\"&gt;https://github.com/xtekky/gpt4free&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;HuggingSpace has qwen3 235B MoE on tap.&lt;/p&gt;\n\n&lt;p&gt;You can plug it directly into KiloCode, it’s fine&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47xe5w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753041157,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47mwrx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "tengo_harambe",
            "can_mod_post": false,
            "created_utc": 1753037860,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 4,
            "author_fullname": "t2_sgx7w7mb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "BC 250 mining rig. 192GB of GDDR6 VRAM in the form of 12x PS5 APUs for a grand total of only $1K.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47mwrx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;BC 250 mining rig. 192GB of GDDR6 VRAM in the form of 12x PS5 APUs for a grand total of only $1K.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47mwrx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753037860,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n472ego",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Frosty-Cap-4282",
            "can_mod_post": false,
            "created_utc": 1753031712,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_18z668t0lo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "tinyllama",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n472ego",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;tinyllama&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n472ego/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753031712,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47c2mn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Normal-Ad-7114",
            "can_mod_post": false,
            "created_utc": 1753034527,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_8fu8sqhz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Old decommissioned mining rig with P102-100s each flashed to 10gb\n\n\nEquivalent of an electric kettle for each 100gb of vram... But usually very cheap to get hold of",
            "edited": 1753034734,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47c2mn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Old decommissioned mining rig with P102-100s each flashed to 10gb&lt;/p&gt;\n\n&lt;p&gt;Equivalent of an electric kettle for each 100gb of vram... But usually very cheap to get hold of&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47c2mn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753034527,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47hnfb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MDT-49",
            "can_mod_post": false,
            "created_utc": 1753036227,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 3,
            "author_fullname": "t2_h8yrica5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Raspberry Pi 5 (16GB) with the M.2 HAT+ and 256GB NVMe SSD, using mmap to dynamically load the parameters from the drive. The only problem with this brilliant idea is that you'd probably die of old age before seeing the results.\n\nI think another unconventional but more sensible idea is using a (secondhand) previous generation AMD APU (e.g. AMD Ryzen 7 8700G) with a decent iGPU (Radeon 780M). Upgrade to the highest RAM capacity and supported speed. \n\nRun the LLM using the iGPU for faster prompt ingestion (compared to CPU), although the text generation is probably still limited by the relatively slow RAM bandwidth.\n\nAnother trick is to use the IQ1 quant, set the `qwen3moe.expert_used_count` to 1, and use LSD so you still feel like you're talking to AGI.",
            "edited": 1753036658,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47hnfb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Raspberry Pi 5 (16GB) with the M.2 HAT+ and 256GB NVMe SSD, using mmap to dynamically load the parameters from the drive. The only problem with this brilliant idea is that you&amp;#39;d probably die of old age before seeing the results.&lt;/p&gt;\n\n&lt;p&gt;I think another unconventional but more sensible idea is using a (secondhand) previous generation AMD APU (e.g. AMD Ryzen 7 8700G) with a decent iGPU (Radeon 780M). Upgrade to the highest RAM capacity and supported speed. &lt;/p&gt;\n\n&lt;p&gt;Run the LLM using the iGPU for faster prompt ingestion (compared to CPU), although the text generation is probably still limited by the relatively slow RAM bandwidth.&lt;/p&gt;\n\n&lt;p&gt;Another trick is to use the IQ1 quant, set the &lt;code&gt;qwen3moe.expert_used_count&lt;/code&gt; to 1, and use LSD so you still feel like you&amp;#39;re talking to AGI.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47hnfb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753036227,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47mopi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1753037790,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Crackhead setup? A bunch of SFF PCs that used to do digital signage. Implication being you get them for free and then use RPC to split the model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47mopi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Crackhead setup? A bunch of SFF PCs that used to do digital signage. Implication being you get them for free and then use RPC to split the model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47mopi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753037790,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47vxq3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Weary-Wing-6806",
            "can_mod_post": false,
            "created_utc": 1753040699,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_1t2xvghrcr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Run the MoE off a Raspberry Pi cluster duct-taped to an e-bike, solar-powered, inference streamed over LoRa. Model sharded across four SD cards. Cold start requires pedaling for 12 minutes. Only outputs tokens when the wind is blowing east. Winner winner chicken dinner.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47vxq3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Run the MoE off a Raspberry Pi cluster duct-taped to an e-bike, solar-powered, inference streamed over LoRa. Model sharded across four SD cards. Cold start requires pedaling for 12 minutes. Only outputs tokens when the wind is blowing east. Winner winner chicken dinner.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47vxq3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753040699,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4843mc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "absolooot1",
            "can_mod_post": false,
            "created_utc": 1753043233,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_1pr7hwh6t5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Silent mini PC with an Intel N100 4 core CPU and 16 GB RAM. You can run the qwen at 4 bit quantization and a small context, with memory mapping. So only the active parameters will be in RAM, the rest served from SSD. It won't be fast, but you can leave it running overnight. Get up in the morning and your code is ready.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4843mc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Silent mini PC with an Intel N100 4 core CPU and 16 GB RAM. You can run the qwen at 4 bit quantization and a small context, with memory mapping. So only the active parameters will be in RAM, the rest served from SSD. It won&amp;#39;t be fast, but you can leave it running overnight. Get up in the morning and your code is ready.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4843mc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753043233,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n47fjeg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "SnooEagles1027",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n47f1kc",
                                "score": 4,
                                "author_fullname": "t2_3slgxl3h",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "👌 if it works! P40's still are pretty good for their age - I have one and still impressed with what they can do.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n47fjeg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;👌 if it works! P40&amp;#39;s still are pretty good for their age - I have one and still impressed with what they can do.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47fjeg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753035580,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753035580,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n47f1kc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "FunnyAsparagus1253",
                      "can_mod_post": false,
                      "created_utc": 1753035429,
                      "send_replies": true,
                      "parent_id": "t1_n473vpf",
                      "score": 9,
                      "author_fullname": "t2_i6c8tay3w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Wooden frame: ✅ Drilling holes myself: ✅ Duct tape: ✅ Non-standard sized mobo: ✅ Weird fan: ✅ Dremeled airflow/cable slots: ✅ Ikea cabinet for a case 😅 P40 club: ✅ Sucks so much power it’s more expensive than runpod: ✅ ✅ ✅ Fun though!\n\nhttps://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n47f1kc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wooden frame: ✅ Drilling holes myself: ✅ Duct tape: ✅ Non-standard sized mobo: ✅ Weird fan: ✅ Dremeled airflow/cable slots: ✅ Ikea cabinet for a case 😅 P40 club: ✅ Sucks so much power it’s more expensive than runpod: ✅ ✅ ✅ Fun though!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c\"&gt;https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47f1kc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753035429,
                      "media_metadata": {
                        "86mq9bzcm2ef1": {
                          "status": "valid",
                          "e": "Image",
                          "m": "image/jpeg",
                          "p": [
                            {
                              "y": 144,
                              "x": 108,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1274b10bf39b29ee717b9ad2ecd864ac28fb0e93"
                            },
                            {
                              "y": 288,
                              "x": 216,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df2b0e0e1b4d2dfd93cfeedf65f197e1b8948f1a"
                            },
                            {
                              "y": 426,
                              "x": 320,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=784f89e5e78291c3a3be26b0a9f07a4ccb9269a1"
                            },
                            {
                              "y": 853,
                              "x": 640,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74e39ba58ceda620dfb20665578171e274012b0c"
                            },
                            {
                              "y": 1280,
                              "x": 960,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d27832b0741d6c140956c5a4e0ffe12409d3a69f"
                            },
                            {
                              "y": 1440,
                              "x": 1080,
                              "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=550ad072363a237876974dca9d437c24d2f69f56"
                            }
                          ],
                          "s": {
                            "y": 4032,
                            "x": 3024,
                            "u": "https://preview.redd.it/86mq9bzcm2ef1.jpeg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=71b4f1fcb644933e63915d08e46c1ae913bc103c"
                          },
                          "id": "86mq9bzcm2ef1"
                        }
                      },
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4744u3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "SnooEagles1027",
                      "can_mod_post": false,
                      "created_utc": 1753032220,
                      "send_replies": true,
                      "parent_id": "t1_n473vpf",
                      "score": 3,
                      "author_fullname": "t2_3slgxl3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Or you could go with a 4u supermicro case with a ton of pcie slots and throw a bunch of consumer cards in it... but hey :)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4744u3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Or you could go with a 4u supermicro case with a ton of pcie slots and throw a bunch of consumer cards in it... but hey :)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n4744u3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753032220,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n47jyyg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "DeltaSqueezer",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n474ino",
                                "score": 3,
                                "author_fullname": "t2_8jqx3m14",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You can get 8x v100 32GB in a server for about 6k now.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n47jyyg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can get 8x v100 32GB in a server for about 6k now.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m4u7j6",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47jyyg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753036946,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753036946,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n474ino",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "SnooEagles1027",
                      "can_mod_post": false,
                      "created_utc": 1753032331,
                      "send_replies": true,
                      "parent_id": "t1_n473vpf",
                      "score": 3,
                      "author_fullname": "t2_3slgxl3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Oh, and the v100 16gb are cheap but the carrier boards about 300ish a piece",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n474ino",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh, and the v100 16gb are cheap but the carrier boards about 300ish a piece&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n474ino/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753032331,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n47n2gl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "a_beautiful_rhind",
                      "can_mod_post": false,
                      "created_utc": 1753037909,
                      "send_replies": true,
                      "parent_id": "t1_n473vpf",
                      "score": 3,
                      "author_fullname": "t2_h5utwre7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I stand off my GPUs on a shelf I made from pallet wood. The kind sprayed with methyl bromide too.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n47n2gl",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I stand off my GPUs on a shelf I made from pallet wood. The kind sprayed with methyl bromide too.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m4u7j6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47n2gl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753037909,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n473vpf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SnooEagles1027",
            "can_mod_post": false,
            "created_utc": 1753032145,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 2,
            "author_fullname": "t2_3slgxl3h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You gotta build a wooden frame to mount a mobo and  gpus it holds but no, not regulart off the shelf mobos, server mobos, if you really want to get janky use the dell ones so you have to use their proprietary power supply too. Then use a crap ton of v100 16gb on dgx boards but you find yourself having to run standard power supplies because your other power supplies won't handle it.\n\nScratch that - use standard mobos with these dgx Frankenstein setups oh and there needs to be duct tape somewhere.\n\nAnd ChatGPT version:\n1. Frame (Wood, Obviously)\n\n2x4s and plywood. No pre-fab racks here.\n\nDrill holes and mount standoffs yourself.\n\nEnsure airflow gaps (front-to-back or bottom-to-top).\n\nBonus points: Burn the wood with a torch to \"harden\" it (or at least make it look cyberpunk-apocalyptic).\n\n\n2. Motherboards\n\nYou’re flip-flopping between:\n\nServer boards (Dell, etc.) — a pain because of:\n\nProprietary power connectors.\n\nNon-standard dimensions.\n\nPotential lack of accessible BIOS tuning.\n\nStandard consumer/workstation boards (more sane):\n\nEasier power, ATX mounting.\n\nBut you may run out of PCIe lanes depending on how greedy you get with the GPUs.\n\nPick one. For jank’s sake, go standard. You’ll thank yourself when something fails at 2 AM.\n\n\n3. GPUs: V100 16GB (On DGX carrier boards)\n\nThese DGX boards usually carry 4x V100s each.\n\nPCIe slot edge connector. Power-hungry monsters.\n\nProblem: DGX boards aren’t made to be run outside of their cozy, $150K servers.\n\nPower: You must run standard ATX PSUs unless you’ve got server-grade 12V rails (or want to solder your own cables and live on the edge).\n\nMultiple 1200W Platinum-rated PSUs (server pulls or mining leftovers).\n\nJump pins on 24-pin connectors to power on without motherboard.\n\nCustom cable routing to GPU edge connectors. Make sure the wire gauge is legit (12 AWG ideally).\n\n\n4. Mounting the DGX Boards\n\nCustom risers or standoff rail system.\n\nSpacers under the board, vent holes underneath.\n\nThink vertical sandwich or slotted wooden backplate.\n\n\n5. Cooling\n\n120mm or 140mm high-static pressure fans.\n\nBox fan in the corner blowing on your duct-taped rig.\n\nBonus: Bathroom exhaust fan and some dryer ducting.\n\n\n6. The Duct Tape (Non-Negotiable)\n\nHold PSUs to the frame? Duct tape.\n\nSecure a janky riser that keeps popping loose? Duct tape.\n\nLabel dead GPUs? Duct tape + Sharpie.\n\nFan that won’t stay where you want it? Duct tape.\n\nIt’s not real unless there’s duct tape.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n473vpf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You gotta build a wooden frame to mount a mobo and  gpus it holds but no, not regulart off the shelf mobos, server mobos, if you really want to get janky use the dell ones so you have to use their proprietary power supply too. Then use a crap ton of v100 16gb on dgx boards but you find yourself having to run standard power supplies because your other power supplies won&amp;#39;t handle it.&lt;/p&gt;\n\n&lt;p&gt;Scratch that - use standard mobos with these dgx Frankenstein setups oh and there needs to be duct tape somewhere.&lt;/p&gt;\n\n&lt;p&gt;And ChatGPT version:\n1. Frame (Wood, Obviously)&lt;/p&gt;\n\n&lt;p&gt;2x4s and plywood. No pre-fab racks here.&lt;/p&gt;\n\n&lt;p&gt;Drill holes and mount standoffs yourself.&lt;/p&gt;\n\n&lt;p&gt;Ensure airflow gaps (front-to-back or bottom-to-top).&lt;/p&gt;\n\n&lt;p&gt;Bonus points: Burn the wood with a torch to &amp;quot;harden&amp;quot; it (or at least make it look cyberpunk-apocalyptic).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Motherboards&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;You’re flip-flopping between:&lt;/p&gt;\n\n&lt;p&gt;Server boards (Dell, etc.) — a pain because of:&lt;/p&gt;\n\n&lt;p&gt;Proprietary power connectors.&lt;/p&gt;\n\n&lt;p&gt;Non-standard dimensions.&lt;/p&gt;\n\n&lt;p&gt;Potential lack of accessible BIOS tuning.&lt;/p&gt;\n\n&lt;p&gt;Standard consumer/workstation boards (more sane):&lt;/p&gt;\n\n&lt;p&gt;Easier power, ATX mounting.&lt;/p&gt;\n\n&lt;p&gt;But you may run out of PCIe lanes depending on how greedy you get with the GPUs.&lt;/p&gt;\n\n&lt;p&gt;Pick one. For jank’s sake, go standard. You’ll thank yourself when something fails at 2 AM.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;GPUs: V100 16GB (On DGX carrier boards)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These DGX boards usually carry 4x V100s each.&lt;/p&gt;\n\n&lt;p&gt;PCIe slot edge connector. Power-hungry monsters.&lt;/p&gt;\n\n&lt;p&gt;Problem: DGX boards aren’t made to be run outside of their cozy, $150K servers.&lt;/p&gt;\n\n&lt;p&gt;Power: You must run standard ATX PSUs unless you’ve got server-grade 12V rails (or want to solder your own cables and live on the edge).&lt;/p&gt;\n\n&lt;p&gt;Multiple 1200W Platinum-rated PSUs (server pulls or mining leftovers).&lt;/p&gt;\n\n&lt;p&gt;Jump pins on 24-pin connectors to power on without motherboard.&lt;/p&gt;\n\n&lt;p&gt;Custom cable routing to GPU edge connectors. Make sure the wire gauge is legit (12 AWG ideally).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Mounting the DGX Boards&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Custom risers or standoff rail system.&lt;/p&gt;\n\n&lt;p&gt;Spacers under the board, vent holes underneath.&lt;/p&gt;\n\n&lt;p&gt;Think vertical sandwich or slotted wooden backplate.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Cooling&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;120mm or 140mm high-static pressure fans.&lt;/p&gt;\n\n&lt;p&gt;Box fan in the corner blowing on your duct-taped rig.&lt;/p&gt;\n\n&lt;p&gt;Bonus: Bathroom exhaust fan and some dryer ducting.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Duct Tape (Non-Negotiable)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Hold PSUs to the frame? Duct tape.&lt;/p&gt;\n\n&lt;p&gt;Secure a janky riser that keeps popping loose? Duct tape.&lt;/p&gt;\n\n&lt;p&gt;Label dead GPUs? Duct tape + Sharpie.&lt;/p&gt;\n\n&lt;p&gt;Fan that won’t stay where you want it? Duct tape.&lt;/p&gt;\n\n&lt;p&gt;It’s not real unless there’s duct tape.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n473vpf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753032145,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n478zyr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Double_Cause4609",
            "can_mod_post": false,
            "created_utc": 1753033629,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_1kubzxt2ww",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "With a consumer CPU (Ryzen 9950X), and a 20GB GPU (kind of overkill for this due to the nature of 235B's MoE structure not having a shared expert), I get around 3 T/s.\n\nThis is decidedly not super optimal, but the main limitation here is the CPU. Generally I do a tensor override to keep the experts on CPU and everything else on GPU, which IMO is the cheapest way to run models like this.\n\nAs an aside, if they'd done a shared expert in Qwen 235B I'd expect closer to Llama 4 speeds; I get 10 T/s on Maverick, surprisingly.\n\nAnyway, the limiting factor there is in fact not the GPU, but the CPU.\n\nIf I'd gone with a Threadripper I'd expect around 6 T/s, and around 9-12 T/s with Threadripper Pro. I'm guessing there's a limit or diminishing returns somewhere, but with an Epyc 9124 I'd guess somewhere around 10-20T/s should be possible with the same ish setup.\n\nNow, you could throw more of the model on VRAM to ease the burden on the CPU, and that's definitely one way to make it easier (only offloading the experts of some of the layers to CPU), but I generally tend to think that the best strat is just to get a bigger CPU.\n\nUsed Xeons are okay (typically I think models with around 200GB/s of bandwidth are pretty common at reasonable prices. You'd expect on the upper end around 10 T/s being possible with a modest GPU to pair it with).\n\nIn terms of GPU, if you do tensor overrides etc, you'd expect not to need that much GPU power. I think at low ish context (32k) I use around 3-6GB for the KV cache and Attention at q8 in LlamaCPP.\n\nIn that light, even quite affordable 12-16GB GPUs are suitable if you're not throwing experts onto the GPUs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n478zyr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;With a consumer CPU (Ryzen 9950X), and a 20GB GPU (kind of overkill for this due to the nature of 235B&amp;#39;s MoE structure not having a shared expert), I get around 3 T/s.&lt;/p&gt;\n\n&lt;p&gt;This is decidedly not super optimal, but the main limitation here is the CPU. Generally I do a tensor override to keep the experts on CPU and everything else on GPU, which IMO is the cheapest way to run models like this.&lt;/p&gt;\n\n&lt;p&gt;As an aside, if they&amp;#39;d done a shared expert in Qwen 235B I&amp;#39;d expect closer to Llama 4 speeds; I get 10 T/s on Maverick, surprisingly.&lt;/p&gt;\n\n&lt;p&gt;Anyway, the limiting factor there is in fact not the GPU, but the CPU.&lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;d gone with a Threadripper I&amp;#39;d expect around 6 T/s, and around 9-12 T/s with Threadripper Pro. I&amp;#39;m guessing there&amp;#39;s a limit or diminishing returns somewhere, but with an Epyc 9124 I&amp;#39;d guess somewhere around 10-20T/s should be possible with the same ish setup.&lt;/p&gt;\n\n&lt;p&gt;Now, you could throw more of the model on VRAM to ease the burden on the CPU, and that&amp;#39;s definitely one way to make it easier (only offloading the experts of some of the layers to CPU), but I generally tend to think that the best strat is just to get a bigger CPU.&lt;/p&gt;\n\n&lt;p&gt;Used Xeons are okay (typically I think models with around 200GB/s of bandwidth are pretty common at reasonable prices. You&amp;#39;d expect on the upper end around 10 T/s being possible with a modest GPU to pair it with).&lt;/p&gt;\n\n&lt;p&gt;In terms of GPU, if you do tensor overrides etc, you&amp;#39;d expect not to need that much GPU power. I think at low ish context (32k) I use around 3-6GB for the KV cache and Attention at q8 in LlamaCPP.&lt;/p&gt;\n\n&lt;p&gt;In that light, even quite affordable 12-16GB GPUs are suitable if you&amp;#39;re not throwing experts onto the GPUs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n478zyr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753033629,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n47jv0s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Hawk_7979",
            "can_mod_post": false,
            "created_utc": 1753036913,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_85eeoiqtd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have single MI50 with 64gb RAM and i am getting 4 t/s on Q2_K_L\n\nI’ve seen people getting 20t/s with 3 mi50’s.\n\nGo for pcie gen 5/4 MOBO and bifurcate pcie x16.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n47jv0s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have single MI50 with 64gb RAM and i am getting 4 t/s on Q2_K_L&lt;/p&gt;\n\n&lt;p&gt;I’ve seen people getting 20t/s with 3 mi50’s.&lt;/p&gt;\n\n&lt;p&gt;Go for pcie gen 5/4 MOBO and bifurcate pcie x16.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n47jv0s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753036913,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n482ia0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ConnectBodybuilder36",
            "can_mod_post": false,
            "created_utc": 1753042747,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_1nq5dpbfmd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What comes to mind for me is just a bunch of M60 gpus",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n482ia0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What comes to mind for me is just a bunch of M60 gpus&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n482ia0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753042747,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n485bsm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Stepfunction",
            "can_mod_post": false,
            "created_utc": 1753043608,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_sxigq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "With an MoE model like that, you can load it fully in RAM and get interactive speeds. No absolute need for a GPU even as long as you have a decent CPU setup.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n485bsm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;With an MoE model like that, you can load it fully in RAM and get interactive speeds. No absolute need for a GPU even as long as you have a decent CPU setup.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n485bsm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753043608,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n48cpy9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "swagonflyyyy",
            "can_mod_post": false,
            "created_utc": 1753045896,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_iev1qh7k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Using a CD player as a grenade and Deepseek-R1-671b-FP16 as the detonator by loading it in and attempting to generate `Hello, World!`",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n48cpy9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Using a CD player as a grenade and Deepseek-R1-671b-FP16 as the detonator by loading it in and attempting to generate &lt;code&gt;Hello, World!&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48cpy9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753045896,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n48rdg6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "outtokill7",
            "can_mod_post": false,
            "created_utc": 1753050729,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_7ikfz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have a 11th Gen i5 Framework 13 mainboard in a 3D printed case with a thunderbolt GPU enclosure and a 3060 12gb inside.\n\nThere are going to be more jank setups than mine but I like to think it's jank enough to mention",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n48rdg6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a 11th Gen i5 Framework 13 mainboard in a 3D printed case with a thunderbolt GPU enclosure and a 3060 12gb inside.&lt;/p&gt;\n\n&lt;p&gt;There are going to be more jank setups than mine but I like to think it&amp;#39;s jank enough to mention&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48rdg6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753050729,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n48v6r2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "thebadslime",
            "can_mod_post": false,
            "created_utc": 1753052058,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_i5os0v0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What's your budget?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n48v6r2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s your budget?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n48v6r2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753052058,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n49ecgt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kevin_1994",
            "can_mod_post": false,
            "created_utc": 1753058925,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_o015g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I had this idea one time:\n\nGet as many cheap npu accelerated android devices as you can. You can probably get them virtually for free with cracked screens, unable to use battery, etc. \n\nHave some server as many usb hubs you can find. \n\nWrite some software where each phone is a node running llm inference. \n\nThe idea is the cheapest performance per Watt",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n49ecgt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I had this idea one time:&lt;/p&gt;\n\n&lt;p&gt;Get as many cheap npu accelerated android devices as you can. You can probably get them virtually for free with cracked screens, unable to use battery, etc. &lt;/p&gt;\n\n&lt;p&gt;Have some server as many usb hubs you can find. &lt;/p&gt;\n\n&lt;p&gt;Write some software where each phone is a node running llm inference. &lt;/p&gt;\n\n&lt;p&gt;The idea is the cheapest performance per Watt&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49ecgt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753058925,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n49eqj6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "segmond",
            "can_mod_post": false,
            "created_utc": 1753059072,
            "send_replies": true,
            "parent_id": "t3_1m4u7j6",
            "score": 1,
            "author_fullname": "t2_ah13x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "3090, 3080ti, 3060, P40, V100, MI50, mix it across 3 machines, I'm running Kimi k2 at 30,000 tokens at 1.5tk/sec",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n49eqj6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3090, 3080ti, 3060, P40, V100, MI50, mix it across 3 machines, I&amp;#39;m running Kimi k2 at 30,000 tokens at 1.5tk/sec&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m4u7j6/whats_the_most_crackhead_garbage_local_llm_setup/n49eqj6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753059072,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m4u7j6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]