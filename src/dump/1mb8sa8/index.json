[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Was looking into a dual 9175F with 24 channels RAM and wanted to check if anybody ever succeded with that or a similar build? \nMy option would be a MZ73-LM0 r3 motherboard, but I am scared of the cpu qvl marking the 9175F as \"contact us!\" \n\nWould love to go for a Asrock Rack /Supermicro but no 24 dimm in a reasonable  form factor that also has integrated PCIE slots. \n\nHow did you build? Which problems did you get? \nWhich motherboard did you go for? How did you cool your processors if they are \"in series\"? \n\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Dual Turin build anyone?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mb8sa8",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.6,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_quvm4",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753683932,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was looking into a dual 9175F with 24 channels RAM and wanted to check if anybody ever succeded with that or a similar build? \nMy option would be a MZ73-LM0 r3 motherboard, but I am scared of the cpu qvl marking the 9175F as &amp;quot;contact us!&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Would love to go for a Asrock Rack /Supermicro but no 24 dimm in a reasonable  form factor that also has integrated PCIE slots. &lt;/p&gt;\n\n&lt;p&gt;How did you build? Which problems did you get? \nWhich motherboard did you go for? How did you cool your processors if they are &amp;quot;in series&amp;quot;? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mb8sa8",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "nail_nail",
            "discussion_type": null,
            "num_comments": 15,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753683932,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5mkqxz",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "nail_nail",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5m1v4l",
                                          "score": 1,
                                          "author_fullname": "t2_quvm4",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "This seems to be due to the fact that some KV cache is only in one numa node.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5mkqxz",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This seems to be due to the fact that some KV cache is only in one numa node.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mb8sa8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5mkqxz/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753717602,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753717602,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": {
                                                                                              "kind": "Listing",
                                                                                              "data": {
                                                                                                "after": null,
                                                                                                "dist": null,
                                                                                                "modhash": "",
                                                                                                "geo_filter": "",
                                                                                                "children": [
                                                                                                  {
                                                                                                    "kind": "t1",
                                                                                                    "data": {
                                                                                                      "subreddit_id": "t5_81eyvm",
                                                                                                      "approved_at_utc": null,
                                                                                                      "author_is_blocked": false,
                                                                                                      "comment_type": null,
                                                                                                      "awarders": [],
                                                                                                      "mod_reason_by": null,
                                                                                                      "banned_by": null,
                                                                                                      "author_flair_type": "text",
                                                                                                      "total_awards_received": 0,
                                                                                                      "subreddit": "LocalLLaMA",
                                                                                                      "author_flair_template_id": null,
                                                                                                      "likes": null,
                                                                                                      "replies": "",
                                                                                                      "user_reports": [],
                                                                                                      "saved": false,
                                                                                                      "id": "n5oxddn",
                                                                                                      "banned_at_utc": null,
                                                                                                      "mod_reason_title": null,
                                                                                                      "gilded": 0,
                                                                                                      "archived": false,
                                                                                                      "collapsed_reason_code": null,
                                                                                                      "no_follow": true,
                                                                                                      "author": "FullstackSensei",
                                                                                                      "can_mod_post": false,
                                                                                                      "created_utc": 1753741864,
                                                                                                      "send_replies": true,
                                                                                                      "parent_id": "t1_n5ohy2f",
                                                                                                      "score": 1,
                                                                                                      "author_fullname": "t2_17n3nqtj56",
                                                                                                      "approved_by": null,
                                                                                                      "mod_note": null,
                                                                                                      "all_awardings": [],
                                                                                                      "collapsed": false,
                                                                                                      "body": "What CPU do you have? And how much do you get in STREAM Triad? \n\nEpyc memory bandwidth before Turin is heavily dependent on the number of CCDs you have. Saphire Rapids is tiled, so even a single CPU is 4 NUMA domains in reality, and crossing those limits it to ~65% peak theoretical in Triad.\n\nBF16 doesn't necessarily improve things. Dequantization is actually cheap since it happens all in cache/registers, so it can improve compute efficiency due to reduced memory traffic.\n\nI had tried it with Qwen 2.5 and QwQ, both at Q8, on my Epyc Rome 7642. I use numactl --physcpubind=$(seq -s, 1 2 91) to pin one thread to each core and set threads in ik_llama.cpp to the number of physical cores. That gets me ~4tk/s on QwQ Q8. Triad gives me 130-131GB/s. Theoretical peak is 170GB/s. So, Triad gives about 76%, which is par for Epyc. Intel memory controllers (in a single die) are a bit more efficient and can get to ~80% in Triad.",
                                                                                                      "edited": false,
                                                                                                      "top_awarded_type": null,
                                                                                                      "author_flair_css_class": null,
                                                                                                      "name": "t1_n5oxddn",
                                                                                                      "is_submitter": false,
                                                                                                      "downs": 0,
                                                                                                      "author_flair_richtext": [],
                                                                                                      "author_patreon_flair": false,
                                                                                                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What CPU do you have? And how much do you get in STREAM Triad? &lt;/p&gt;\n\n&lt;p&gt;Epyc memory bandwidth before Turin is heavily dependent on the number of CCDs you have. Saphire Rapids is tiled, so even a single CPU is 4 NUMA domains in reality, and crossing those limits it to ~65% peak theoretical in Triad.&lt;/p&gt;\n\n&lt;p&gt;BF16 doesn&amp;#39;t necessarily improve things. Dequantization is actually cheap since it happens all in cache/registers, so it can improve compute efficiency due to reduced memory traffic.&lt;/p&gt;\n\n&lt;p&gt;I had tried it with Qwen 2.5 and QwQ, both at Q8, on my Epyc Rome 7642. I use numactl --physcpubind=$(seq -s, 1 2 91) to pin one thread to each core and set threads in ik_llama.cpp to the number of physical cores. That gets me ~4tk/s on QwQ Q8. Triad gives me 130-131GB/s. Theoretical peak is 170GB/s. So, Triad gives about 76%, which is par for Epyc. Intel memory controllers (in a single die) are a bit more efficient and can get to ~80% in Triad.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                                      "removal_reason": null,
                                                                                                      "collapsed_reason": null,
                                                                                                      "distinguished": null,
                                                                                                      "associated_award": null,
                                                                                                      "stickied": false,
                                                                                                      "author_premium": false,
                                                                                                      "can_gild": false,
                                                                                                      "gildings": {},
                                                                                                      "unrepliable_reason": null,
                                                                                                      "author_flair_text_color": null,
                                                                                                      "score_hidden": false,
                                                                                                      "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5oxddn/",
                                                                                                      "subreddit_type": "public",
                                                                                                      "locked": false,
                                                                                                      "report_reasons": null,
                                                                                                      "created": 1753741864,
                                                                                                      "author_flair_text": null,
                                                                                                      "treatment_tags": [],
                                                                                                      "link_id": "t3_1mb8sa8",
                                                                                                      "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                                      "controversiality": 0,
                                                                                                      "depth": 9,
                                                                                                      "author_flair_background_color": null,
                                                                                                      "collapsed_because_crowd_control": null,
                                                                                                      "mod_reports": [],
                                                                                                      "num_reports": null,
                                                                                                      "ups": 1
                                                                                                    }
                                                                                                  }
                                                                                                ],
                                                                                                "before": null
                                                                                              }
                                                                                            },
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n5ohy2f",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": true,
                                                                                            "author": "eloquentemu",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1753737092,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n5o4lzc",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_lpdsy",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "&gt; It's actually 75-80% of peak theoretical on single socket in dense models\n\nI've never even come close to that.  How are you getting that?  I just tested Qwen3-32B in native bf16 (61GB), which should minimize compute (no unquantize step) but I get tg128 of 5.1t/s. So 311GBps of 499GBps = ~60%.  I also see the same number for Llama-70b.  Am I calculating that wrong?  Are there other engines?  llama.cpp has yet to be beat for me, but I haven't tried everything.",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n5ohy2f",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s actually 75-80% of peak theoretical on single socket in dense models&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;ve never even come close to that.  How are you getting that?  I just tested Qwen3-32B in native bf16 (61GB), which should minimize compute (no unquantize step) but I get tg128 of 5.1t/s. So 311GBps of 499GBps = ~60%.  I also see the same number for Llama-70b.  Am I calculating that wrong?  Are there other engines?  llama.cpp has yet to be beat for me, but I haven&amp;#39;t tried everything.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5ohy2f/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1753737092,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mb8sa8",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n5o4lzc",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "FullstackSensei",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1753733303,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n5njwp0",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_17n3nqtj56",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "It's actually 75-80% of peak theoretical on single socket in dense models, which is what you can get in practice in any application. I've seen this with dense models, which have had CPU inference code optimized quite a bit. MoE, OTOH, lack most of those optimizations, which is why they show much slower performance in practice. I'm sure things will change in the next 6-12 months as focus shifts to MoE in all open-source projects. It's just a matter of time.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n5o4lzc",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s actually 75-80% of peak theoretical on single socket in dense models, which is what you can get in practice in any application. I&amp;#39;ve seen this with dense models, which have had CPU inference code optimized quite a bit. MoE, OTOH, lack most of those optimizations, which is why they show much slower performance in practice. I&amp;#39;m sure things will change in the next 6-12 months as focus shifts to MoE in all open-source projects. It&amp;#39;s just a matter of time.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mb8sa8",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5o4lzc/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1753733303,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n5njwp0",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "eloquentemu",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n5n7ugq",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_lpdsy",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Yeah, it's a bit of a disappointment, but at the same time, CPU inference is only about 50-60% efficient in terms of memory bandwidth too, so IDK if I'm totally bought in on the potential for dual socket inference.  (i.e. if 50% is the best a CPU can do, then maybe +50% is the best a second socket can do.  OR, if 50% single CPU can be improved, then improving that would be a bigger win.)",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n5njwp0",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, it&amp;#39;s a bit of a disappointment, but at the same time, CPU inference is only about 50-60% efficient in terms of memory bandwidth too, so IDK if I&amp;#39;m totally bought in on the potential for dual socket inference.  (i.e. if 50% is the best a CPU can do, then maybe +50% is the best a second socket can do.  OR, if 50% single CPU can be improved, then improving that would be a bigger win.)&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mb8sa8",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5njwp0/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753727355,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753727355,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5n7ugq",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "FullstackSensei",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5n5h9n",
                                                              "score": 1,
                                                              "author_fullname": "t2_17n3nqtj56",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "It's a chicken and egg. Nobody is fixing dual socket because the people that know the code don't have a dual socket, and nobody that has a dual socket (I have two systems) know the code to be able to fix it.\n\nGood support for NUMA and RDMA would open so many doors for people running LLMs at home. Dual Epyc systems with 400GB/s aggregate memory bandwidth can be bought for a little over 1k with 512GB RAM in a lot of places. You get ~300GB/s in practice. That's very close to the P40 at 350GB/s and about the same as the 4060Ti with 288GB/s.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5n7ugq",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a chicken and egg. Nobody is fixing dual socket because the people that know the code don&amp;#39;t have a dual socket, and nobody that has a dual socket (I have two systems) know the code to be able to fix it.&lt;/p&gt;\n\n&lt;p&gt;Good support for NUMA and RDMA would open so many doors for people running LLMs at home. Dual Epyc systems with 400GB/s aggregate memory bandwidth can be bought for a little over 1k with 512GB RAM in a lot of places. You get ~300GB/s in practice. That&amp;#39;s very close to the P40 at 350GB/s and about the same as the 4060Ti with 288GB/s.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mb8sa8",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5n7ugq/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753724021,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753724021,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5n5h9n",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "eloquentemu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5n2vod",
                                                    "score": 1,
                                                    "author_fullname": "t2_lpdsy",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "In principle, I agree, but OTOH who cares?  Unless someone is buying a dual socket system in order to fix the NUMA scaling, the software is the software and right now AFAICT _nothing_ gets better than ~40% out of the second socket.  So I do try and warn people before they spend a lot of extra money for incremental gains and some extra headaches.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5n5h9n",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In principle, I agree, but OTOH who cares?  Unless someone is buying a dual socket system in order to fix the NUMA scaling, the software is the software and right now AFAICT &lt;em&gt;nothing&lt;/em&gt; gets better than ~40% out of the second socket.  So I do try and warn people before they spend a lot of extra money for incremental gains and some extra headaches.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mb8sa8",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5n5h9n/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753723377,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753723377,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5n2vod",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "FullstackSensei",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5m1v4l",
                                          "score": 1,
                                          "author_fullname": "t2_17n3nqtj56",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It's not supposed to scale100% due to the overhead of the associated communication but for dual socket it should be in the 80% park. Even quad CPU scaling over RDMA (infiniband 40gb or faster) should see similar scaling. I know it's not trivial to implement, but it's also not that much code. Main issue is most open-source projects are too big and unwieldy already for an outsider to come and implement that.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5n2vod",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not supposed to scale100% due to the overhead of the associated communication but for dual socket it should be in the 80% park. Even quad CPU scaling over RDMA (infiniband 40gb or faster) should see similar scaling. I know it&amp;#39;s not trivial to implement, but it&amp;#39;s also not that much code. Main issue is most open-source projects are too big and unwieldy already for an outsider to come and implement that.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mb8sa8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5n2vod/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753722672,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753722672,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5m1v4l",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5lyo4u",
                                "score": 1,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Is ktransformers supposed to be good?  Their Deepseek benchmarks aren't:\n\n&gt; PP: KTransformers: 54.21 (32 cores) → 74.362 (dual-socket, 2×32 cores) \n&gt;\n&gt; TG: 8.73 (32 cores) → 11.26 (dual-socket, 2×32 cores)\n\nSo that's only a 30-40% improvement with the second socket.\n\nI don't have a dual socket so I don't really follow it, to be clear, so I might not know when it's fixed or what projects are good for it.  I just keep an eye out for benchmarks and want people to know that they _probably_ should only expect limited improvements from NUMA unless proven otherwise.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5m1v4l",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is ktransformers supposed to be good?  Their Deepseek benchmarks aren&amp;#39;t:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;PP: KTransformers: 54.21 (32 cores) → 74.362 (dual-socket, 2×32 cores) &lt;/p&gt;\n\n&lt;p&gt;TG: 8.73 (32 cores) → 11.26 (dual-socket, 2×32 cores)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So that&amp;#39;s only a 30-40% improvement with the second socket.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have a dual socket so I don&amp;#39;t really follow it, to be clear, so I might not know when it&amp;#39;s fixed or what projects are good for it.  I just keep an eye out for benchmarks and want people to know that they &lt;em&gt;probably&lt;/em&gt; should only expect limited improvements from NUMA unless proven otherwise.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb8sa8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5m1v4l/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753712144,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753712144,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5lyo4u",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullstackSensei",
                      "can_mod_post": false,
                      "created_utc": 1753711166,
                      "send_replies": true,
                      "parent_id": "t1_n5lwyh9",
                      "score": 1,
                      "author_fullname": "t2_17n3nqtj56",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Which projects are working on better NUMA? I have a dual Cascade Lake and a dual Rome systems. It would really be nice to have better NUMA support outside of ktransformers, which I've to be able to compile.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5lyo4u",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Which projects are working on better NUMA? I have a dual Cascade Lake and a dual Rome systems. It would really be nice to have better NUMA support outside of ktransformers, which I&amp;#39;ve to be able to compile.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb8sa8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5lyo4u/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753711166,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5mkba2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "nail_nail",
                      "can_mod_post": false,
                      "created_utc": 1753717481,
                      "send_replies": true,
                      "parent_id": "t1_n5lwyh9",
                      "score": 1,
                      "author_fullname": "t2_quvm4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "9175F is 16c but in 16 CCD, that's why it is so \"special\". Can you provide any sources about that? (thanks BTW)\n\nI also plan to offload to a A6000, so this looks hmm.. not fully fleshed out.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5mkba2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;9175F is 16c but in 16 CCD, that&amp;#39;s why it is so &amp;quot;special&amp;quot;. Can you provide any sources about that? (thanks BTW)&lt;/p&gt;\n\n&lt;p&gt;I also plan to offload to a A6000, so this looks hmm.. not fully fleshed out.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb8sa8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5mkba2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753717481,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5lwyh9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "eloquentemu",
            "can_mod_post": false,
            "created_utc": 1753710636,
            "send_replies": true,
            "parent_id": "t3_1mb8sa8",
            "score": 5,
            "author_fullname": "t2_lpdsy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I haven't but since you haven't gotten a lot of replies:\n\n- 9175F is probably not the best for this application.  I've heard that it was underwhelming, which makes sense given the 16c without shared L3.  I think if you're going Turin you need to not cheap out on the CPU.  You're probably spending the better part of $10k on the RAM alone.  I would say get an 8CCD part\n- I say someone report on a [Kimi K2 thread](https://github.com/ggml-org/llama.cpp/issues/14642#issuecomment-3071577819) getting ~22t/s on a dual 9355 machine.  One of the memory channels was down and they don't say how fast the memory is but they also offloaded a few layers to an RTX 6000 so YMMV.  As a comparison I get ~15t/s on my single Genora w/ 4090.  Better NUMA support is in development, but again YMMV.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5lwyh9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t but since you haven&amp;#39;t gotten a lot of replies:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;9175F is probably not the best for this application.  I&amp;#39;ve heard that it was underwhelming, which makes sense given the 16c without shared L3.  I think if you&amp;#39;re going Turin you need to not cheap out on the CPU.  You&amp;#39;re probably spending the better part of $10k on the RAM alone.  I would say get an 8CCD part&lt;/li&gt;\n&lt;li&gt;I say someone report on a &lt;a href=\"https://github.com/ggml-org/llama.cpp/issues/14642#issuecomment-3071577819\"&gt;Kimi K2 thread&lt;/a&gt; getting ~22t/s on a dual 9355 machine.  One of the memory channels was down and they don&amp;#39;t say how fast the memory is but they also offloaded a few layers to an RTX 6000 so YMMV.  As a comparison I get ~15t/s on my single Genora w/ 4090.  Better NUMA support is in development, but again YMMV.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5lwyh9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753710636,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb8sa8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5lk6f9",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fairydreaming",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5le3dq",
                                "score": 2,
                                "author_fullname": "t2_q06qk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Poland. If you are in EU zone then for example [https://servertronic.de](https://servertronic.de) has some available.\n\nThe forum post I cited mentioned some \"WAIT FOR CHIPSET TO INITIALIZE\" error, so I'm not sure if the motherboard works with high-TDP CPUs from the orange list or it needs some special handling to unlock these (like a custom BIOS version).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5lk6f9",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Poland. If you are in EU zone then for example &lt;a href=\"https://servertronic.de\"&gt;https://servertronic.de&lt;/a&gt; has some available.&lt;/p&gt;\n\n&lt;p&gt;The forum post I cited mentioned some &amp;quot;WAIT FOR CHIPSET TO INITIALIZE&amp;quot; error, so I&amp;#39;m not sure if the motherboard works with high-TDP CPUs from the orange list or it needs some special handling to unlock these (like a custom BIOS version).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb8sa8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5lk6f9/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753706290,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753706290,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5le3dq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "nail_nail",
                      "can_mod_post": false,
                      "created_utc": 1753703925,
                      "send_replies": true,
                      "parent_id": "t1_n5lbnkv",
                      "score": 2,
                      "author_fullname": "t2_quvm4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It is clearly something about TDP (all CPUs there are 320+W) they probably want you to use active heatsinks, but it is not clear to me if you need special VRM heatsinks as well.\n\nWhere are you located if I may ask? I still didn't find availability.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5le3dq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is clearly something about TDP (all CPUs there are 320+W) they probably want you to use active heatsinks, but it is not clear to me if you need special VRM heatsinks as well.&lt;/p&gt;\n\n&lt;p&gt;Where are you located if I may ask? I still didn&amp;#39;t find availability.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb8sa8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5le3dq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753703925,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5lbnkv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fairydreaming",
            "can_mod_post": false,
            "created_utc": 1753702912,
            "send_replies": true,
            "parent_id": "t3_1mb8sa8",
            "score": 1,
            "author_fullname": "t2_q06qk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm interested in this as well, I've been eyeing mz73-lm2 for some time, it's available in my country now but CPU support list is quite weird. What does it mean that half of the CPU models is \"Please contact our technical team to ensure your system fully supports items listed below\"? I mean it either works on not. Also see: [https://forums.servethehome.com/index.php?threads/motherboard-for-dual-epyc-9965-one-that-actually-works-and-fits-a-5090-gpu.48129/#post-471063](https://forums.servethehome.com/index.php?threads/motherboard-for-dual-epyc-9965-one-that-actually-works-and-fits-a-5090-gpu.48129/#post-471063)\n\n&gt;And when i try to contact support via the [esupport](https://esupport.gigabyte.com/) they require a model name from a dropdown list and the name is not on the list and the model name is actually [made up of 2 parts that I should read from the physical motherboard](https://esupport.gigabyte.com/Notice/motherboard_pcb_ver.htm) once purchased, a bit like Gigabyte telling me \"buy it first and then contact tech support to ask them if you should buy it.\"",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5lbnkv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in this as well, I&amp;#39;ve been eyeing mz73-lm2 for some time, it&amp;#39;s available in my country now but CPU support list is quite weird. What does it mean that half of the CPU models is &amp;quot;Please contact our technical team to ensure your system fully supports items listed below&amp;quot;? I mean it either works on not. Also see: &lt;a href=\"https://forums.servethehome.com/index.php?threads/motherboard-for-dual-epyc-9965-one-that-actually-works-and-fits-a-5090-gpu.48129/#post-471063\"&gt;https://forums.servethehome.com/index.php?threads/motherboard-for-dual-epyc-9965-one-that-actually-works-and-fits-a-5090-gpu.48129/#post-471063&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;And when i try to contact support via the &lt;a href=\"https://esupport.gigabyte.com/\"&gt;esupport&lt;/a&gt; they require a model name from a dropdown list and the name is not on the list and the model name is actually &lt;a href=\"https://esupport.gigabyte.com/Notice/motherboard_pcb_ver.htm\"&gt;made up of 2 parts that I should read from the physical motherboard&lt;/a&gt; once purchased, a bit like Gigabyte telling me &amp;quot;buy it first and then contact tech support to ask them if you should buy it.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb8sa8/dual_turin_build_anyone/n5lbnkv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753702912,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb8sa8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]