[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I'm running a research project analysing hospital incident reports (answering structured questions based on them); we do have permission to use identifiable data but the PDFs I've been sent have been redacted and whichever software they've used has turned a lot of the text into an image. To add excitement, a lot of the text is in columns that flow across pages (ie you need to read the left of page 1,2 then the right of page 1,2)\n\nCan anyone recommend a local model capable of handling this? Our research machine has an A6000 (48Gb) and 128Gb RAM; speed isn't a massive issue. I don't mind if the workflow is PDF to text and then run a text model, or if a vision model could do the whole thing.\n\nThanks!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Model to process image-of-text PDFs?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m68tse",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_pc1zg",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753173792,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running a research project analysing hospital incident reports (answering structured questions based on them); we do have permission to use identifiable data but the PDFs I&amp;#39;ve been sent have been redacted and whichever software they&amp;#39;ve used has turned a lot of the text into an image. To add excitement, a lot of the text is in columns that flow across pages (ie you need to read the left of page 1,2 then the right of page 1,2)&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend a local model capable of handling this? Our research machine has an A6000 (48Gb) and 128Gb RAM; speed isn&amp;#39;t a massive issue. I don&amp;#39;t mind if the workflow is PDF to text and then run a text model, or if a vision model could do the whole thing.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m68tse",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "thigger",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/",
            "subreddit_subscribers": 502720,
            "created_utc": 1753173792,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i6ihl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "thigger",
                      "can_mod_post": false,
                      "created_utc": 1753182478,
                      "send_replies": true,
                      "parent_id": "t1_n4hs3lw",
                      "score": 1,
                      "author_fullname": "t2_pc1zg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks - sounds like a plan and I'm a big fan of the Qwen models. Were you using this effectively as an OCR? I was hoping to use a larger model (eg 32B) for the analysis but happy to have two stages with different models.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i6ihl",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks - sounds like a plan and I&amp;#39;m a big fan of the Qwen models. Were you using this effectively as an OCR? I was hoping to use a larger model (eg 32B) for the analysis but happy to have two stages with different models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m68tse",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4i6ihl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182478,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hs3lw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "HistorianPotential48",
            "can_mod_post": false,
            "created_utc": 1753174806,
            "send_replies": true,
            "parent_id": "t3_1m68tse",
            "score": 3,
            "author_fullname": "t2_4dzthia7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i used qwen2.5VL 7b q8\\_0 for that. Ghostscript PDFs into images, and then prompt LLM. Forget about OCR, output cleanliness is not even close to vision LLMs. Don't trust PDF texts because encoding can get messed up.  \n  \nOne gripe is that qwen2.5VL can be bugged and output looped tokens. My workflow is 1 iteration 1 page so for each page I set a 1minute timeout, on timeout I simply skip that page. You can do a logging and output which pages were skipped later.\n\nFor the funny layouts you might need to tweak the workflow a bit, like sending multiple pages together, or simulate a multi-turn chat per batch if page batch size is fixed, and tell LLM that contents can separate cross pages.\n\nSet low temperature like 0 for better performance and also decrease infinite token possibility. But it's deemed to happen, so timeout is necessary. q8\\_0 also has similar effect than q4\\_0. 32b might work better idk, i only got rig to run 7b.\n\nStart from only 1 batch because you need to engineer the prompt. I needed to twerk my prompt before it can read some really funny layouts in our documents. Once the prompt is able to tackle picked examples, you can then do the whole big flow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hs3lw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i used qwen2.5VL 7b q8_0 for that. Ghostscript PDFs into images, and then prompt LLM. Forget about OCR, output cleanliness is not even close to vision LLMs. Don&amp;#39;t trust PDF texts because encoding can get messed up.  &lt;/p&gt;\n\n&lt;p&gt;One gripe is that qwen2.5VL can be bugged and output looped tokens. My workflow is 1 iteration 1 page so for each page I set a 1minute timeout, on timeout I simply skip that page. You can do a logging and output which pages were skipped later.&lt;/p&gt;\n\n&lt;p&gt;For the funny layouts you might need to tweak the workflow a bit, like sending multiple pages together, or simulate a multi-turn chat per batch if page batch size is fixed, and tell LLM that contents can separate cross pages.&lt;/p&gt;\n\n&lt;p&gt;Set low temperature like 0 for better performance and also decrease infinite token possibility. But it&amp;#39;s deemed to happen, so timeout is necessary. q8_0 also has similar effect than q4_0. 32b might work better idk, i only got rig to run 7b.&lt;/p&gt;\n\n&lt;p&gt;Start from only 1 batch because you need to engineer the prompt. I needed to twerk my prompt before it can read some really funny layouts in our documents. Once the prompt is able to tackle picked examples, you can then do the whole big flow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4hs3lw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753174806,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m68tse",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4i6f3a",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Responsible-code3000",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4i64kc",
                                "score": 1,
                                "author_fullname": "t2_1p449vcish",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "check DM",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4i6f3a",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;check DM&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m68tse",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4i6f3a/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753182436,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753182436,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i64kc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "thigger",
                      "can_mod_post": false,
                      "created_utc": 1753182305,
                      "send_replies": true,
                      "parent_id": "t1_n4hyrgy",
                      "score": 2,
                      "author_fullname": "t2_pc1zg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I was originally hoping to just work on the text, so I'm up for using one model to try to extract it (or even simpler OCR except for the layout issue) and then a text model to analyse, but I wondered if a multimodal model might be able to do the whole thing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i64kc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was originally hoping to just work on the text, so I&amp;#39;m up for using one model to try to extract it (or even simpler OCR except for the layout issue) and then a text model to analyse, but I wondered if a multimodal model might be able to do the whole thing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m68tse",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4i64kc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182305,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hyrgy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Responsible-code3000",
            "can_mod_post": false,
            "created_utc": 1753178615,
            "send_replies": true,
            "parent_id": "t3_1m68tse",
            "score": 2,
            "author_fullname": "t2_1p449vcish",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Dude, you have such a strong hardware, so you want a Vision model to read only or analyze this text PDF in that order?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hyrgy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Dude, you have such a strong hardware, so you want a Vision model to read only or analyze this text PDF in that order?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4hyrgy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753178615,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m68tse",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4i7v9w",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "optimisticalish",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4i68q4",
                                "score": 1,
                                "author_fullname": "t2_iu9wdkoe",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Right, so the next questions would be: when you save two pages and join them in Photoshop, i) do they align correctly and ii) does the overflow text obscure text or images on the second page? \n\nIf they align and the text is clean and legible, then just OCR back to PDF with Finereader etc. If not aligned and you have overprinted text, then you may well need an AI.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4i7v9w",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right, so the next questions would be: when you save two pages and join them in Photoshop, i) do they align correctly and ii) does the overflow text obscure text or images on the second page? &lt;/p&gt;\n\n&lt;p&gt;If they align and the text is clean and legible, then just OCR back to PDF with Finereader etc. If not aligned and you have overprinted text, then you may well need an AI.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m68tse",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4i7v9w/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753183086,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753183086,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i68q4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "thigger",
                      "can_mod_post": false,
                      "created_utc": 1753182357,
                      "send_replies": true,
                      "parent_id": "t1_n4hzu77",
                      "score": 1,
                      "author_fullname": "t2_pc1zg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I seem to be able to get the images out, and some (but not much) of the text is still text - I don't know what they've used to redact them!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i68q4",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I seem to be able to get the images out, and some (but not much) of the text is still text - I don&amp;#39;t know what they&amp;#39;ve used to redact them!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m68tse",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4i68q4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182357,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hzu77",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "optimisticalish",
            "can_mod_post": false,
            "created_utc": 1753179194,
            "send_replies": true,
            "parent_id": "t3_1m68tse",
            "score": 2,
            "author_fullname": "t2_iu9wdkoe",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "\"software they've used has turned a lot of the text into an image\"\n\nHave they also 'locked' the PDFs, in terms of not even being able to extract pages as image files? That's the first stumbling block, potentially.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hzu77",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;software they&amp;#39;ve used has turned a lot of the text into an image&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Have they also &amp;#39;locked&amp;#39; the PDFs, in terms of not even being able to extract pages as image files? That&amp;#39;s the first stumbling block, potentially.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4hzu77/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753179194,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m68tse",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4idjmb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "alew3",
            "can_mod_post": false,
            "created_utc": 1753185442,
            "send_replies": true,
            "parent_id": "t3_1m68tse",
            "score": 1,
            "author_fullname": "t2_8bwjj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Try [https://huggingface.co/nanonets/Nanonets-OCR-s](https://huggingface.co/nanonets/Nanonets-OCR-s) , has pretty good results and can even format tables. You just need to convert the individual PDF pages to image and process them.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4idjmb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try &lt;a href=\"https://huggingface.co/nanonets/Nanonets-OCR-s\"&gt;https://huggingface.co/nanonets/Nanonets-OCR-s&lt;/a&gt; , has pretty good results and can even format tables. You just need to convert the individual PDF pages to image and process them.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m68tse/model_to_process_imageoftext_pdfs/n4idjmb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753185442,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m68tse",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]