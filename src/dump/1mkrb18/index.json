[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "🚀 Qwen3-30B-A3B-2507 and Qwen3-235B-A22B-2507 now support ultra-long context—up to 1 million tokens!\n\n🔧 Powered by:\n\n• Dual Chunk Attention (DCA) –  A length extrapolation method that splits long sequences into manageable chunks while preserving global coherence.  \n\n• MInference – Sparse attention that cuts overhead by focusing on key token interactions\n\n💡 These innovations boost both generation quality and inference speed, delivering up to 3× faster performance on near-1M token sequences.\n\n✅ Fully compatible with vLLM and SGLang for efficient deployment.\n\n📄 See the update model cards for how to enable this feature.\n\nhttps://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507\n\nhttps://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507\n\nhttps://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507\n\nhttps://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507\n\nhttps://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Instruct-2507\n\nhttps://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Thinking-2507\n\nhttps://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507\n\nhttps://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "🚀 Qwen3-30B-A3B-2507 and Qwen3-235B-A22B-2507 now support ultra-long context—up to 1 million tokens!",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 59,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mkrb18",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.98,
            "author_flair_background_color": null,
            "ups": 187,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_c705ri9b",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 187,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/__RSAyuozO3snrtUtvfarFfPMUvgQ5j73BkrWn-sS0w.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754647905,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;🚀 Qwen3-30B-A3B-2507 and Qwen3-235B-A22B-2507 now support ultra-long context—up to 1 million tokens!&lt;/p&gt;\n\n&lt;p&gt;🔧 Powered by:&lt;/p&gt;\n\n&lt;p&gt;• Dual Chunk Attention (DCA) –  A length extrapolation method that splits long sequences into manageable chunks while preserving global coherence.  &lt;/p&gt;\n\n&lt;p&gt;• MInference – Sparse attention that cuts overhead by focusing on key token interactions&lt;/p&gt;\n\n&lt;p&gt;💡 These innovations boost both generation quality and inference speed, delivering up to 3× faster performance on near-1M token sequences.&lt;/p&gt;\n\n&lt;p&gt;✅ Fully compatible with vLLM and SGLang for efficient deployment.&lt;/p&gt;\n\n&lt;p&gt;📄 See the update model cards for how to enable this feature.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507\"&gt;https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507\"&gt;https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Instruct-2507\"&gt;https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Thinking-2507\"&gt;https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507\"&gt;https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507\"&gt;https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/ud233u23trhf1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/ud233u23trhf1.jpeg?auto=webp&amp;s=d239f2b03901e85c72874a3f2c66f794530d53f2",
                    "width": 2350,
                    "height": 1000
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f7ed45a1874f0b241235b23baa62b855930ce68",
                      "width": 108,
                      "height": 45
                    },
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a6fffe3adb22e62e7b2d5c7d1c1e353454f6a40",
                      "width": 216,
                      "height": 91
                    },
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ae3ec82a50f078aeb29732d19a021e08db070f51",
                      "width": 320,
                      "height": 136
                    },
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9666b41b192bef19c1d95e2dc31745f398def8d7",
                      "width": 640,
                      "height": 272
                    },
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c83674b02def032524a9da12fe6eff1f265c355a",
                      "width": 960,
                      "height": 408
                    },
                    {
                      "url": "https://preview.redd.it/ud233u23trhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6346926f29cac35a66a5fe9f826578c9f9a84056",
                      "width": 1080,
                      "height": 459
                    }
                  ],
                  "variants": {},
                  "id": "EG8S_eoA-DJ7bpxOXwFdB9Oj-qP6TGYiydQ50-UHp10"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mkrb18",
            "is_robot_indexable": true,
            "num_duplicates": 2,
            "report_reasons": null,
            "author": "ResearchCrafty1804",
            "discussion_type": null,
            "num_comments": 14,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/",
            "stickied": false,
            "url": "https://i.redd.it/ud233u23trhf1.jpeg",
            "subreddit_subscribers": 513815,
            "created_utc": 1754647905,
            "num_crossposts": 2,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7ku6no",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Divergence1900",
                      "can_mod_post": false,
                      "created_utc": 1754650109,
                      "send_replies": true,
                      "parent_id": "t1_n7kqui2",
                      "score": 11,
                      "author_fullname": "t2_8ppgaxs2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "“Together, these innovations significantly improve both generation quality and inference efficiency for sequences beyond 256K tokens.”\n\nI would expect similar performance unless you’re filling up your context window often.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7ku6no",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;“Together, these innovations significantly improve both generation quality and inference efficiency for sequences beyond 256K tokens.”&lt;/p&gt;\n\n&lt;p&gt;I would expect similar performance unless you’re filling up your context window often.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkrb18",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7ku6no/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754650109,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7l7vkd",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "mister2d",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7ky7yl",
                                          "score": 2,
                                          "author_fullname": "t2_7gnbe",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I scratch my head as to why quantized kv cache on the V1 engine doesn't have a higher priority.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7l7vkd",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I scratch my head as to why quantized kv cache on the V1 engine doesn&amp;#39;t have a higher priority.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mkrb18",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7l7vkd/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754655869,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754655869,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7ky7yl",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "SandboChang",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7kwk64",
                                "score": 3,
                                "author_fullname": "t2_10icmj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I do run vLLM on V0 engine for maybe 20% lost in performance, in exchange of being able to use FP8 quant for KV cache. It is not meaningless but it’s a trade off, one that I already have so I guess I should find out.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7ky7yl",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I do run vLLM on V0 engine for maybe 20% lost in performance, in exchange of being able to use FP8 quant for KV cache. It is not meaningless but it’s a trade off, one that I already have so I guess I should find out.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mkrb18",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7ky7yl/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754651952,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754651952,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7kwk64",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LinkSea8324",
                      "can_mod_post": false,
                      "created_utc": 1754651205,
                      "send_replies": true,
                      "parent_id": "t1_n7kqui2",
                      "score": 6,
                      "author_fullname": "t2_152zyn72n4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Either way DCA **NEEDS** VLLM so it means you can't use llama.cpp and you can't use V1 engine and you're stuck with eager mode\n\n\nSo no, don't bother trying to use it",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7kwk64",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Either way DCA &lt;strong&gt;NEEDS&lt;/strong&gt; VLLM so it means you can&amp;#39;t use llama.cpp and you can&amp;#39;t use V1 engine and you&amp;#39;re stuck with eager mode&lt;/p&gt;\n\n&lt;p&gt;So no, don&amp;#39;t bother trying to use it&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkrb18",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kwk64/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754651205,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7kqui2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "SandboChang",
            "can_mod_post": false,
            "created_utc": 1754648410,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 21,
            "author_fullname": "t2_10icmj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Maybe a naive question, if I am using 128-256k token context windows anyway, should I still use this or stick with the original 2507?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kqui2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe a naive question, if I am using 128-256k token context windows anyway, should I still use this or stick with the original 2507?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kqui2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754648410,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 21
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7ksi7p",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "-p-e-w-",
            "can_mod_post": false,
            "created_utc": 1754649262,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 17,
            "author_fullname": "t2_dkgrhaet",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://arxiv.org/pdf/2402.17463\n\nThis is the paper for Dual Chunk Attention. It’s quite easy to read and well-structured.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7ksi7p",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/2402.17463\"&gt;https://arxiv.org/pdf/2402.17463&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is the paper for Dual Chunk Attention. It’s quite easy to read and well-structured.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7ksi7p/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754649262,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 17
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7kwo6r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LinkSea8324",
                      "can_mod_post": false,
                      "created_utc": 1754651256,
                      "send_replies": true,
                      "parent_id": "t1_n7kr6ts",
                      "score": 7,
                      "author_fullname": "t2_152zyn72n4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Either way DCA is not implemented in llama.cpp so you won't benefit the speed boost of DCA",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7kwo6r",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Either way DCA is not implemented in llama.cpp so you won&amp;#39;t benefit the speed boost of DCA&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkrb18",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kwo6r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754651256,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7kr6ts",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Far_Buyer_7281",
            "can_mod_post": false,
            "created_utc": 1754648588,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 8,
            "author_fullname": "t2_vyvxdjqyp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "is this different from the 1m versions of unsloth?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kr6ts",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;is this different from the 1m versions of unsloth?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kr6ts/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754648588,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kqs2v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1754648375,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 5,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Here is the [previously created](https://www.reddit.com/r/LocalLLaMA/comments/1mkq4i4/qwen_added_1m_support_for_qwen330ba3binstruct2507/) thread for this.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kqs2v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here is the &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mkq4i4/qwen_added_1m_support_for_qwen330ba3binstruct2507/\"&gt;previously created&lt;/a&gt; thread for this.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kqs2v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754648375,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kvy1w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Valhall22",
            "can_mod_post": false,
            "created_utc": 1754650928,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 2,
            "author_fullname": "t2_1uaeymlsd6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Impressive",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kvy1w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Impressive&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kvy1w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754650928,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kviua",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "z1xto",
            "can_mod_post": false,
            "created_utc": 1754650733,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": 3,
            "author_fullname": "t2_3fg55rsm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "based on my testing, it performs really poorly with longer context compared to something like gemini. Even at 30k context it can't recall",
            "edited": 1754652225,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kviua",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;based on my testing, it performs really poorly with longer context compared to something like gemini. Even at 30k context it can&amp;#39;t recall&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kviua/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754650733,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7l6v7f",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ThinkExtension2328",
                      "can_mod_post": false,
                      "created_utc": 1754655494,
                      "send_replies": true,
                      "parent_id": "t1_n7kx1hj",
                      "score": 2,
                      "author_fullname": "t2_8eneodlk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The 4b is as good as the old 8b models try that",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7l6v7f",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 4b is as good as the old 8b models try that&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkrb18",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7l6v7f/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754655494,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7kx1hj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "wooden-guy",
            "can_mod_post": false,
            "created_utc": 1754651424,
            "send_replies": true,
            "parent_id": "t3_1mkrb18",
            "score": -2,
            "author_fullname": "t2_16to413y2o",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GIVE ME QWEN 3 8B INSTRUCT AND REASONING ALREADY GODDAMN.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kx1hj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GIVE ME QWEN 3 8B INSTRUCT AND REASONING ALREADY GODDAMN.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkrb18/qwen330ba3b2507_and_qwen3235ba22b2507_now_support/n7kx1hj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754651424,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkrb18",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -2
          }
        }
      ],
      "before": null
    }
  }
]