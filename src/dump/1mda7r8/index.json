[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "So I'm planning a dual GPU build and have settled my sights on the Mi50 32GB, but should I get 2 of them or mix in another card to cover for the Mi50's weaknesses?  \n*This is a general purpose build for LLM inference and some gaming. I'll be running linux and wanna play with 32B dense models, but also curious about the latest larger MoE models - not afraid of offloading to CPU. ComfyUI and other AI applications are a bonus for some day.*\n\nDual Mi50s:  \n\\- Faster speeds with vllm, but requires [nlzy's](https://github.com/nlzy/vllm-gfx906) fork which does not support MoE models  \n\\- Easier to handle a single architecture and generation i.e. libraries and dependecies  \n\\- Noisier with 2 blower fans  \n\\- Underwhelming Comfyui performance  \n\\- Okay 1080p low gaming\n\nAnother AMD card 7900xt, 7900xtx (Has to be 7900 series to run the Mi50's supported ROCm version 6.3.4):  \n\\- Single architecture so can run llama.cpp with rocm  \n\\- Decent prompt processing speed when assigning it as the \"main card\"  \n\\- Decent ComfyUI performance  \n\\- Very good gaming performance\n\nAn Nvidia card e.g. 3060, 5060 Ti, 3090:  \n\\- Very fast prompt processing speeds when running llama.cpp vulkan and setting it as the \"main card\"  \n\\- llama.cpp RPC server could also be good, but unsure if it can assign a \"main card\"  \n\\- Very good with ComfyUI, other applications and maybe training?  \n\\- Pretty good gaming performance\n\nNot considering intel because of slow prompt processing speeds.\n\nI've only dabbled in LM Studio so far with GGUF models, so llama.cpp would be easier to get into.\n\nAny thoughts or aspects that I am missing?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "A second Mi50 32GB or a different GPU?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mda7r8",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_13a48a",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753890678,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m planning a dual GPU build and have settled my sights on the Mi50 32GB, but should I get 2 of them or mix in another card to cover for the Mi50&amp;#39;s weaknesses?&lt;br/&gt;\n&lt;em&gt;This is a general purpose build for LLM inference and some gaming. I&amp;#39;ll be running linux and wanna play with 32B dense models, but also curious about the latest larger MoE models - not afraid of offloading to CPU. ComfyUI and other AI applications are a bonus for some day.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Dual Mi50s:&lt;br/&gt;\n- Faster speeds with vllm, but requires &lt;a href=\"https://github.com/nlzy/vllm-gfx906\"&gt;nlzy&amp;#39;s&lt;/a&gt; fork which does not support MoE models&lt;br/&gt;\n- Easier to handle a single architecture and generation i.e. libraries and dependecies&lt;br/&gt;\n- Noisier with 2 blower fans&lt;br/&gt;\n- Underwhelming Comfyui performance&lt;br/&gt;\n- Okay 1080p low gaming&lt;/p&gt;\n\n&lt;p&gt;Another AMD card 7900xt, 7900xtx (Has to be 7900 series to run the Mi50&amp;#39;s supported ROCm version 6.3.4):&lt;br/&gt;\n- Single architecture so can run llama.cpp with rocm&lt;br/&gt;\n- Decent prompt processing speed when assigning it as the &amp;quot;main card&amp;quot;&lt;br/&gt;\n- Decent ComfyUI performance&lt;br/&gt;\n- Very good gaming performance&lt;/p&gt;\n\n&lt;p&gt;An Nvidia card e.g. 3060, 5060 Ti, 3090:&lt;br/&gt;\n- Very fast prompt processing speeds when running llama.cpp vulkan and setting it as the &amp;quot;main card&amp;quot;&lt;br/&gt;\n- llama.cpp RPC server could also be good, but unsure if it can assign a &amp;quot;main card&amp;quot;&lt;br/&gt;\n- Very good with ComfyUI, other applications and maybe training?&lt;br/&gt;\n- Pretty good gaming performance&lt;/p&gt;\n\n&lt;p&gt;Not considering intel because of slow prompt processing speeds.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only dabbled in LM Studio so far with GGUF models, so llama.cpp would be easier to get into.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or aspects that I am missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?auto=webp&amp;s=16f75643fd8ac082b59d466c6e50173e3fe4ef61",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ac489b21c2747fa1f5a82057c584a6a7462413e",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa6495bd83a5a477b4ccdcd75d30a2c89769169f",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=05aa881a2a4f1ee891f7877425500c50864607de",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3250100d5e641d60873cf1e4142198758342bcaa",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=abe49f1f2026285ae99ba7f718f2c278d28448e3",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3771c213cb3c5f504941d7bfeacf2766036860ef",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "javKGginDl1G1jM0-GWy6FemNFbv1z5LHdbGm75TwW4"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mda7r8",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "legit_split_",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/",
            "subreddit_subscribers": 507275,
            "created_utc": 1753890678,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n60zdwm",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "ForsookComparison",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n60qlby",
                                          "score": 1,
                                          "author_fullname": "t2_on5es7pe3",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I'm not using the MI50 but I didn't feel any performance or feature gains in 6.4 over 6.3",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n60zdwm",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not using the MI50 but I didn&amp;#39;t feel any performance or feature gains in 6.4 over 6.3&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mda7r8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60zdwm/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753901038,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1753901038,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n60qlby",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "coolestmage",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n60cgww",
                                "score": 1,
                                "author_fullname": "t2_6dtdz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I encountered this problem but instead of digging I just installed 6.3.4. I might have to give this a shot. I wonder if 6.4 has any real improvements implemented for the MI50.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n60qlby",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I encountered this problem but instead of digging I just installed 6.3.4. I might have to give this a shot. I wonder if 6.4 has any real improvements implemented for the MI50.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mda7r8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60qlby/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753898588,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753898588,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n60cgww",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Threatening-Silence-",
                      "can_mod_post": false,
                      "created_utc": 1753894808,
                      "send_replies": true,
                      "parent_id": "t1_n601tdo",
                      "score": 2,
                      "author_fullname": "t2_15wqsifdjf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "ROCm 6.4 still supports the MI50 but annoyingly doesn't have the gfx906 kernel bundled. You can just extract it from an archlinux package though and copy it in. It works fine.\n\nhttps://github.com/ROCm/ROCm/issues/4625",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n60cgww",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ROCm 6.4 still supports the MI50 but annoyingly doesn&amp;#39;t have the gfx906 kernel bundled. You can just extract it from an archlinux package though and copy it in. It works fine.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ROCm/ROCm/issues/4625\"&gt;https://github.com/ROCm/ROCm/issues/4625&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60cgww/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753894808,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n601tdo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ForsookComparison",
            "can_mod_post": false,
            "created_utc": 1753891826,
            "send_replies": true,
            "parent_id": "t3_1mda7r8",
            "score": 6,
            "author_fullname": "t2_on5es7pe3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You're asking all the right questions.\n\nOf these options I think the 7900xtx is the best of all worlds. You can keep using ROCm for as long as the MI50 works (note support was dropped in 6.4 but it supposedly still works) rather than being locked only into Vulkan builds, you get the killer gaming performance, decently faster prompt processing, and you get a good sized pool of VRAM,",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n601tdo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re asking all the right questions.&lt;/p&gt;\n\n&lt;p&gt;Of these options I think the 7900xtx is the best of all worlds. You can keep using ROCm for as long as the MI50 works (note support was dropped in 6.4 but it supposedly still works) rather than being locked only into Vulkan builds, you get the killer gaming performance, decently faster prompt processing, and you get a good sized pool of VRAM,&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n601tdo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753891826,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mda7r8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n62helz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DepthHour1669",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n61pluu",
                                "score": 1,
                                "author_fullname": "t2_t6glzswk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Remember that llama.cpp needs to be updated for each new model before you can use it for a model. It needed to be updated to run Qwen3, it needed to be updated to run Deepseek, it needed to be updated to run Kimi K2, it needed to be updated to run GLM 4.5 yesterday, etc. \n\nThat's the biggest reason why I'd suggest llama.cpp vulkan over an older fork of llama.cpp ROCm.\n\nI made a quick calculator for this: https://output.jsbin.com/nisepal\n\nFor Qwen3-235b Q4 and 100GB/sec system ram bandwidth and 10GB of kv cache:  \n- 3090+MI50 gets 14.74 tokens/sec  \n- 7900XTX+MI50 gets 14.82 tokens/sec   \n- MI50+MI50 gets 15.02 tokens/sec     \n- A single 3090/7900XTX/MI50 gets 11.6-11.8 tokens/sec  \n- no vram (set both gpu bandwidth to 100GB/sec) gets 4.75tok/sec",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n62helz",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Remember that llama.cpp needs to be updated for each new model before you can use it for a model. It needed to be updated to run Qwen3, it needed to be updated to run Deepseek, it needed to be updated to run Kimi K2, it needed to be updated to run GLM 4.5 yesterday, etc. &lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s the biggest reason why I&amp;#39;d suggest llama.cpp vulkan over an older fork of llama.cpp ROCm.&lt;/p&gt;\n\n&lt;p&gt;I made a quick calculator for this: &lt;a href=\"https://output.jsbin.com/nisepal\"&gt;https://output.jsbin.com/nisepal&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For Qwen3-235b Q4 and 100GB/sec system ram bandwidth and 10GB of kv cache:&lt;br/&gt;\n- 3090+MI50 gets 14.74 tokens/sec&lt;br/&gt;\n- 7900XTX+MI50 gets 14.82 tokens/sec&lt;br/&gt;\n- MI50+MI50 gets 15.02 tokens/sec&lt;br/&gt;\n- A single 3090/7900XTX/MI50 gets 11.6-11.8 tokens/sec&lt;br/&gt;\n- no vram (set both gpu bandwidth to 100GB/sec) gets 4.75tok/sec&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mda7r8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n62helz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753916944,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753916944,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n61pluu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "legit_split_",
                      "can_mod_post": false,
                      "created_utc": 1753908477,
                      "send_replies": true,
                      "parent_id": "t1_n61cuhh",
                      "score": 1,
                      "author_fullname": "t2_13a48a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you so much! It makes a lot of sense now.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n61pluu",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you so much! It makes a lot of sense now.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n61pluu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753908477,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n61cuhh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DepthHour1669",
            "can_mod_post": false,
            "created_utc": 1753904914,
            "send_replies": true,
            "parent_id": "t3_1mda7r8",
            "score": 2,
            "author_fullname": "t2_t6glzswk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hi, since this is a general build for gaming AND for AI, you definitely should not go 2x MI50.\n\nIf you do any gaming, the primary MI50 is not a good idea. Yes it’ll work, but no. You definitely want a 7900XTX or 3090 as your main card.\n\nThe **2nd MI50 is mostly for dense models**, not big MoE models, by the way. It will barely speed up big MoE models. I did the math on this before; in theory, the performance of no GPU deepseek R1 is something like 5 tokens/sec, whereas 1x 3090 is 21.2 tok/sec, and 2x 3090 is about 21.7tok/sec. You'll see similar numbers with a second MI50 for big MoE models. **The 2nd GPU doesn't help much for big MoE models, most people don't realize that**. That 2nd GPU is really just for bigger dense models that don't fit on a single 24gb gpu- so it helps you with Llama 3.3 70b, Nvidia Nemotron 49b, Hunyuan A13B (80b), etc. You'll still run the smaller models completely on your first GPU. I have 2x 3090, and the 2nd 3090 barely improves big MoE model speeds.\n\nYour choice really is just between the 7900XTX and 3090. You want a primary GPU that can do most tasks. \n\nThis also rules out vLLM, which really requires 2 GPUs to be the same. You'll be mostly using llama.cpp for inference.\n\nThis also means the 3090 may be the better option over the 7900XTX! If you are using llama.cpp, you may as well as use the vulkan version, not the ROCm version. ROCm support on the MI50 has ended anyways! So honestly a fresh vulkan llama.cpp may very well be faster than an older ROCm llama.cpp in comparison. You may have to do benchmarks yourself to test it. If vulkan llama.cpp works faster, then the 3090 would actually be a better primary GPU alongside the MI50!\n\nIf you are mostly messing with 32b dense models, which are ~16GB at Q4 and a bit bigger at Q5, then you'll mostly just want a fast primary 24GB gpu to run the 32b models at Q4 or Q5. The MI50 is actually fairly useless for you- again, it's really just for ~70b models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n61cuhh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi, since this is a general build for gaming AND for AI, you definitely should not go 2x MI50.&lt;/p&gt;\n\n&lt;p&gt;If you do any gaming, the primary MI50 is not a good idea. Yes it’ll work, but no. You definitely want a 7900XTX or 3090 as your main card.&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;2nd MI50 is mostly for dense models&lt;/strong&gt;, not big MoE models, by the way. It will barely speed up big MoE models. I did the math on this before; in theory, the performance of no GPU deepseek R1 is something like 5 tokens/sec, whereas 1x 3090 is 21.2 tok/sec, and 2x 3090 is about 21.7tok/sec. You&amp;#39;ll see similar numbers with a second MI50 for big MoE models. &lt;strong&gt;The 2nd GPU doesn&amp;#39;t help much for big MoE models, most people don&amp;#39;t realize that&lt;/strong&gt;. That 2nd GPU is really just for bigger dense models that don&amp;#39;t fit on a single 24gb gpu- so it helps you with Llama 3.3 70b, Nvidia Nemotron 49b, Hunyuan A13B (80b), etc. You&amp;#39;ll still run the smaller models completely on your first GPU. I have 2x 3090, and the 2nd 3090 barely improves big MoE model speeds.&lt;/p&gt;\n\n&lt;p&gt;Your choice really is just between the 7900XTX and 3090. You want a primary GPU that can do most tasks. &lt;/p&gt;\n\n&lt;p&gt;This also rules out vLLM, which really requires 2 GPUs to be the same. You&amp;#39;ll be mostly using llama.cpp for inference.&lt;/p&gt;\n\n&lt;p&gt;This also means the 3090 may be the better option over the 7900XTX! If you are using llama.cpp, you may as well as use the vulkan version, not the ROCm version. ROCm support on the MI50 has ended anyways! So honestly a fresh vulkan llama.cpp may very well be faster than an older ROCm llama.cpp in comparison. You may have to do benchmarks yourself to test it. If vulkan llama.cpp works faster, then the 3090 would actually be a better primary GPU alongside the MI50!&lt;/p&gt;\n\n&lt;p&gt;If you are mostly messing with 32b dense models, which are ~16GB at Q4 and a bit bigger at Q5, then you&amp;#39;ll mostly just want a fast primary 24GB gpu to run the 32b models at Q4 or Q5. The MI50 is actually fairly useless for you- again, it&amp;#39;s really just for ~70b models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n61cuhh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753904914,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mda7r8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n60b7ys",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "legit_split_",
                      "can_mod_post": false,
                      "created_utc": 1753894475,
                      "send_replies": true,
                      "parent_id": "t1_n6093ch",
                      "score": 5,
                      "author_fullname": "t2_13a48a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's totally possible to play on the Mi50. [Here](https://www.reddit.com/r/LocalLLaMA/comments/1lsgtvy/successfully_built_my_first_pc_for_ai_sourcing/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button) in this thread you see with a vBIOS flash you can get video output, and furmark runs under vulkan.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n60b7ys",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s totally possible to play on the Mi50. &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lsgtvy/successfully_built_my_first_pc_for_ai_sourcing/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button\"&gt;Here&lt;/a&gt; in this thread you see with a vBIOS flash you can get video output, and furmark runs under vulkan.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60b7ys/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753894475,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n60czp7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Threatening-Silence-",
                      "can_mod_post": false,
                      "created_utc": 1753894949,
                      "send_replies": true,
                      "parent_id": "t1_n6093ch",
                      "score": 5,
                      "author_fullname": "t2_15wqsifdjf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is wrong. \n\nI own many Mi50s and they work fine with both Vulkan and RocM 6.4, with a few minor annoyances:\n\nhttps://github.com/ROCm/ROCm/issues/4625",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n60czp7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is wrong. &lt;/p&gt;\n\n&lt;p&gt;I own many Mi50s and they work fine with both Vulkan and RocM 6.4, with a few minor annoyances:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ROCm/ROCm/issues/4625\"&gt;https://github.com/ROCm/ROCm/issues/4625&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60czp7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753894949,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n60bnkh",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "legit_split_",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n60afnj",
                                "score": 1,
                                "author_fullname": "t2_13a48a",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Hmm, interesting point. Will do some more research on that, thanks for sharing!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n60bnkh",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hmm, interesting point. Will do some more research on that, thanks for sharing!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mda7r8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60bnkh/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753894591,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753894591,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n60afnj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "curios-al",
                      "can_mod_post": false,
                      "created_utc": 1753894263,
                      "send_replies": true,
                      "parent_id": "t1_n6093ch",
                      "score": 1,
                      "author_fullname": "t2_te425vy7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Also, rocm has (had?) issues with mix of cards of different architecture/generation. Particularly, I was unable to run RDNA2 and RDNA3 cards together with same app instance. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n60afnj",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also, rocm has (had?) issues with mix of cards of different architecture/generation. Particularly, I was unable to run RDNA2 and RDNA3 cards together with same app instance. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n60afnj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753894263,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n612hhx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BlueSwordM",
                      "can_mod_post": false,
                      "created_utc": 1753901920,
                      "send_replies": true,
                      "parent_id": "t1_n6093ch",
                      "score": 1,
                      "author_fullname": "t2_qhqon",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The Mi50/Mi60 are just Radeon VII cards.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n612hhx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The Mi50/Mi60 are just Radeon VII cards.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mda7r8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n612hhx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753901920,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6093ch",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "curios-al",
            "can_mod_post": false,
            "created_utc": 1753893888,
            "send_replies": true,
            "parent_id": "t3_1mda7r8",
            "score": -3,
            "author_fullname": "t2_te425vy7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You should verify your sources - it is impossible to play on MI50. Those are server CDNA cards which missing some important rasterization blocks as well as have no video output. As a result Vulkan support once announced currently non-existent. ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6093ch",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You should verify your sources - it is impossible to play on MI50. Those are server CDNA cards which missing some important rasterization blocks as well as have no video output. As a result Vulkan support once announced currently non-existent. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mda7r8/a_second_mi50_32gb_or_a_different_gpu/n6093ch/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753893888,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mda7r8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -3
          }
        }
      ],
      "before": null
    }
  }
]