[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi everyone,\n\nI'm new to the world of AI tools and local models, but I am planning to build a PC for this purpose. I’ll mainly be using it for running tools like Stable Diffusion, ComfyUI, Wen, Flux, and may be some local LLMs.\n\nDue to budget constraints, the **only fixed part of my build is the RTX 3090 (24GB)**. I chose it because of more VRAM. Beyond that, I’m unsure about what components would be ideal, especially for my use case.\n\nCould you help me with:\n\n* **CPU**: Should I go with **Intel or AMD**? And which model would be more future-proof for this kind of workload?\n* **RAM**: How much RAM is realistically needed for a smooth experience when running models locally? Is 64GB overkill or necessary?\n* **Motherboard**: Any recommendations that would complement the 3090 and allow good upgradeability?\n\nAny advice, parts lists, or links to similar builds would be greatly appreciated. I want to build something efficient, stable, and ready for experimenting with generative AI tools locally.\n\nThanks in advance for your help!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Help Needed: Building a PC.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1luwa98",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_4fc0eow8",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751999304,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to the world of AI tools and local models, but I am planning to build a PC for this purpose. I’ll mainly be using it for running tools like Stable Diffusion, ComfyUI, Wen, Flux, and may be some local LLMs.&lt;/p&gt;\n\n&lt;p&gt;Due to budget constraints, the &lt;strong&gt;only fixed part of my build is the RTX 3090 (24GB)&lt;/strong&gt;. I chose it because of more VRAM. Beyond that, I’m unsure about what components would be ideal, especially for my use case.&lt;/p&gt;\n\n&lt;p&gt;Could you help me with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Should I go with &lt;strong&gt;Intel or AMD&lt;/strong&gt;? And which model would be more future-proof for this kind of workload?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: How much RAM is realistically needed for a smooth experience when running models locally? Is 64GB overkill or necessary?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Motherboard&lt;/strong&gt;: Any recommendations that would complement the 3090 and allow good upgradeability?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any advice, parts lists, or links to similar builds would be greatly appreciated. I want to build something efficient, stable, and ready for experimenting with generative AI tools locally.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1luwa98",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "MeRedditSurfer",
            "discussion_type": null,
            "num_comments": 7,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/",
            "subreddit_subscribers": 496592,
            "created_utc": 1751999304,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n248u3v",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MeRedditSurfer",
                      "can_mod_post": false,
                      "created_utc": 1752034796,
                      "send_replies": true,
                      "parent_id": "t1_n21bhqq",
                      "score": 1,
                      "author_fullname": "t2_4fc0eow8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for the info. That makes sense for very large models like DeepSeek V3. Right now, I’m mainly planning to run Stable Diffusion, ComfyUI, and some local LLMs in the 7B–13B range, so I think I’ll stick to consumer-grade hardware for now.\n\nStacking GPUs sounds powerful but probably overkill (and expensive) for my current needs. I am aiming for a balance between performance and affordability. \n\nAppreciate your input though. It gives me a better perspective on the high end options.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n248u3v",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the info. That makes sense for very large models like DeepSeek V3. Right now, I’m mainly planning to run Stable Diffusion, ComfyUI, and some local LLMs in the 7B–13B range, so I think I’ll stick to consumer-grade hardware for now.&lt;/p&gt;\n\n&lt;p&gt;Stacking GPUs sounds powerful but probably overkill (and expensive) for my current needs. I am aiming for a balance between performance and affordability. &lt;/p&gt;\n\n&lt;p&gt;Appreciate your input though. It gives me a better perspective on the high end options.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1luwa98",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n248u3v/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752034796,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n21bhqq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "rnosov",
            "can_mod_post": false,
            "created_utc": 1752001137,
            "send_replies": true,
            "parent_id": "t3_1luwa98",
            "score": 3,
            "author_fullname": "t2_18x6fa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Check this [tutorial](https://github.com/kvcache-ai/ktransformers/blob/main/doc/en/DeepseekR1_V3_tutorial.md). If you want to run the full Deepseek V3 you might need up to 382GB RAM. I think your best bet would be to get second hand Xeon Gold mobo+CPU. It won't run fast but would allow you to run bigger models.\n\nIf you just want to run models really fast you don't need system RAM. Your only option would be to stack GPUs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n21bhqq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check this &lt;a href=\"https://github.com/kvcache-ai/ktransformers/blob/main/doc/en/DeepseekR1_V3_tutorial.md\"&gt;tutorial&lt;/a&gt;. If you want to run the full Deepseek V3 you might need up to 382GB RAM. I think your best bet would be to get second hand Xeon Gold mobo+CPU. It won&amp;#39;t run fast but would allow you to run bigger models.&lt;/p&gt;\n\n&lt;p&gt;If you just want to run models really fast you don&amp;#39;t need system RAM. Your only option would be to stack GPUs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n21bhqq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752001137,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1luwa98",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n22uexi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Starman-Paradox",
            "can_mod_post": false,
            "created_utc": 1752017002,
            "send_replies": true,
            "parent_id": "t3_1luwa98",
            "score": 2,
            "author_fullname": "t2_trskein",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Realistically, if you're not looking to run massive models on CPU, then just about anything modern will do fine. GPU based inference is almost entirely GPU bound. \n\nFirst iteration of my AI server had a old Ryzen 5 2600x with 32 GB RAM and an RTX 3090. The CPU was not an issue.\n\nPersonally, I would pick the CPU based on your general needs - gaming, video editing, whatever. Then get a solid PSU, 32 GB RAM (upgrade later if needed), a motherboard and case that can fit another GPU later if you want, and plenty of fast SSD for storing/loading models. \n\nNow... If you're looking to scale up big time in the future, or run Deepseek on CPU, then check out the Xeon and Epyc builds people are doing.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n22uexi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Realistically, if you&amp;#39;re not looking to run massive models on CPU, then just about anything modern will do fine. GPU based inference is almost entirely GPU bound. &lt;/p&gt;\n\n&lt;p&gt;First iteration of my AI server had a old Ryzen 5 2600x with 32 GB RAM and an RTX 3090. The CPU was not an issue.&lt;/p&gt;\n\n&lt;p&gt;Personally, I would pick the CPU based on your general needs - gaming, video editing, whatever. Then get a solid PSU, 32 GB RAM (upgrade later if needed), a motherboard and case that can fit another GPU later if you want, and plenty of fast SSD for storing/loading models. &lt;/p&gt;\n\n&lt;p&gt;Now... If you&amp;#39;re looking to scale up big time in the future, or run Deepseek on CPU, then check out the Xeon and Epyc builds people are doing.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n22uexi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752017002,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1luwa98",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n249533",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MeRedditSurfer",
                      "can_mod_post": false,
                      "created_utc": 1752034927,
                      "send_replies": true,
                      "parent_id": "t1_n22v2em",
                      "score": 1,
                      "author_fullname": "t2_4fc0eow8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks. That’s reassuring to hear. I’ll focus on a solid GPU-based setup with 64GB RAM and upgrade as needed. Not planning to run huge models on CPU for now, so this helps a lot!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n249533",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks. That’s reassuring to hear. I’ll focus on a solid GPU-based setup with 64GB RAM and upgrade as needed. Not planning to run huge models on CPU for now, so this helps a lot!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1luwa98",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n249533/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752034927,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n22v2em",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1752017211,
            "send_replies": true,
            "parent_id": "t3_1luwa98",
            "score": 2,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If your planning on having a pretty beefy GPU, then there’s not really a need to invest much in cpu or ram since all of the AI workload will be processed by the GPU. Im running cpu hardware from 2018 and theres no problems because the GPU is new and does all the work.\n\nAnything new, even if it’s entry-level like a AMD 9600 CPU will be perfectly fine for AI work loads. Historically, AMD has had better lifetime support for their motherboards. Am5 we’ll probably have a few more generations of processors released before starting to sunset and you will have upgrade options for CPU.\n\n64gb of ram is fine.\n\nThe one recommendation I would make is to choose a motherboard that has several PCI lanes. This will make it easier to add a second or third GPU down the road.\n\nEdit: several PCI x16 slots, not lanes.",
            "edited": 1752017502,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n22v2em",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If your planning on having a pretty beefy GPU, then there’s not really a need to invest much in cpu or ram since all of the AI workload will be processed by the GPU. Im running cpu hardware from 2018 and theres no problems because the GPU is new and does all the work.&lt;/p&gt;\n\n&lt;p&gt;Anything new, even if it’s entry-level like a AMD 9600 CPU will be perfectly fine for AI work loads. Historically, AMD has had better lifetime support for their motherboards. Am5 we’ll probably have a few more generations of processors released before starting to sunset and you will have upgrade options for CPU.&lt;/p&gt;\n\n&lt;p&gt;64gb of ram is fine.&lt;/p&gt;\n\n&lt;p&gt;The one recommendation I would make is to choose a motherboard that has several PCI lanes. This will make it easier to add a second or third GPU down the road.&lt;/p&gt;\n\n&lt;p&gt;Edit: several PCI x16 slots, not lanes.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n22v2em/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752017211,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1luwa98",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n249f52",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MeRedditSurfer",
                      "can_mod_post": false,
                      "created_utc": 1752035046,
                      "send_replies": true,
                      "parent_id": "t1_n231c7h",
                      "score": 1,
                      "author_fullname": "t2_4fc0eow8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks, that’s super helpful. Gives me a solid reference point for performance. It will definitely help me gauge what to expect with my 3090.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n249f52",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks, that’s super helpful. Gives me a solid reference point for performance. It will definitely help me gauge what to expect with my 3090.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1luwa98",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n249f52/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752035046,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n231c7h",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Limp_Manufacturer_65",
            "can_mod_post": false,
            "created_utc": 1752019240,
            "send_replies": true,
            "parent_id": "t3_1luwa98",
            "score": 1,
            "author_fullname": "t2_kwq6f5zi",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "in case it helps, I have a 7800x3d, 4070 ti super, and 96gb ddr5-6000, and I can run qwen3-14b q4km at 50 tkps and qwen3-235b-a22b q2-k at 6tkps",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n231c7h",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;in case it helps, I have a 7800x3d, 4070 ti super, and 96gb ddr5-6000, and I can run qwen3-14b q4km at 50 tkps and qwen3-235b-a22b q2-k at 6tkps&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1luwa98/help_needed_building_a_pc/n231c7h/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752019240,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1luwa98",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]