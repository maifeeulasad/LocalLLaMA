[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "AI models are picking up hidden habits from each other | IBM",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfll39",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.85,
            "author_flair_background_color": "#bbbdbf",
            "ups": 31,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "is_original_content": false,
            "author_fullname": "t2_144o7g",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 31,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=9f10577c2fcc3a35df02ac054b4815c973b08f82",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754123731,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "ibm.com",
            "allow_live_comments": false,
            "selftext_html": null,
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://www.ibm.com/think/news/ai-models-subliminal-learning",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?auto=webp&amp;s=ffc26910e336a76ab6db1af971b2d262dbce6146",
                    "width": 1280,
                    "height": 720
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2723bb45305d3a150f76e1937c51a2690147d015",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=30aa75a6f3b7183ee11ff8f6294344790b27c98c",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d4ee8618c7e067b6087a6fbd41b990eb083b72f",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46e4049e81a052bc62430cfe7e667f62662c693b",
                      "width": 640,
                      "height": 360
                    },
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ec61744cbe7d95092017e4c3bdcff62c20454303",
                      "width": 960,
                      "height": 540
                    },
                    {
                      "url": "https://external-preview.redd.it/lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a031cd428aa62cc550e88505f888b329ed3ed9cf",
                      "width": 1080,
                      "height": 607
                    }
                  ],
                  "variants": {},
                  "id": "lZV0GHuIH9uuEeScanVvma03Gd4_flgdgcoA6uvqcLQ"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mfll39",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "ab2377",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/",
            "stickied": false,
            "url": "https://www.ibm.com/think/news/ai-models-subliminal-learning",
            "subreddit_subscribers": 508769,
            "created_utc": 1754123731,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ihub4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DungeonMasterSupreme",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ie3k8",
                                "score": 1,
                                "author_fullname": "t2_5nzsbef2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "1.5 loras can work on SDXL, yes, but not the other way around. Doesn't seem to work in every UI, but you can do it in ComfyUI for sure. Results can be wildly different from using the lora on a 1.5 model, but I still keep a couple of 1.5 detailer loras that can still deliver good results.\n\nI don't know about Hunyuan. Never used it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ihub4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;1.5 loras can work on SDXL, yes, but not the other way around. Doesn&amp;#39;t seem to work in every UI, but you can do it in ComfyUI for sure. Results can be wildly different from using the lora on a 1.5 model, but I still keep a couple of 1.5 detailer loras that can still deliver good results.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know about Hunyuan. Never used it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfll39",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6ihub4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754135938,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754135938,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ie3k8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "a_beautiful_rhind",
                      "can_mod_post": false,
                      "created_utc": 1754134221,
                      "send_replies": true,
                      "parent_id": "t1_n6i00k8",
                      "score": 3,
                      "author_fullname": "t2_h5utwre7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Did those ever? Because the shape would not be compatible. Just get a tensor size mismatch.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ie3k8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did those ever? Because the shape would not be compatible. Just get a tensor size mismatch.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfll39",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6ie3k8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754134221,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6i00k8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754126403,
            "send_replies": true,
            "parent_id": "t3_1mfll39",
            "score": 9,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Really crazy and confusing result.\n\n\nReminds me of SD 1.5 lora working on SDXL or Flux lora working on Hunyuan",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6i00k8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Really crazy and confusing result.&lt;/p&gt;\n\n&lt;p&gt;Reminds me of SD 1.5 lora working on SDXL or Flux lora working on Hunyuan&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6i00k8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754126403,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfll39",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6i2khl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ab2377",
                      "can_mod_post": false,
                      "created_utc": 1754127965,
                      "send_replies": true,
                      "parent_id": "t1_n6i1tap",
                      "score": 3,
                      "author_fullname": "t2_144o7g",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "they say they dont know how its working. I wont use the word \"compressed\" here. Its just that when you produce data from a teacher model to teach another model, that data has biases that are hidden in it somehow, something that you cant see in the data directly. Generation of numbers was just an example, you can generate anything which has no reference in synthetic data of the preferences of teacher model, but those preferences will end up in the student model. Totally wild.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6i2khl",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;they say they dont know how its working. I wont use the word &amp;quot;compressed&amp;quot; here. Its just that when you produce data from a teacher model to teach another model, that data has biases that are hidden in it somehow, something that you cant see in the data directly. Generation of numbers was just an example, you can generate anything which has no reference in synthetic data of the preferences of teacher model, but those preferences will end up in the student model. Totally wild.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfll39",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6i2khl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754127965,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6i1tap",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ArchdukeofHyperbole",
            "can_mod_post": false,
            "created_utc": 1754127512,
            "send_replies": true,
            "parent_id": "t3_1mfll39",
            "score": 4,
            "author_fullname": "t2_1p41v97q5d",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't even know if I understand or how to feel about it. They take numbers from a trainer model that was made to have a preference of owls. They trained a learner model on those numbers along with other data (data that didn't necessarily have the owl preference). And simply learning the number patterns from the model that liked owls transfers a preference or more of a likelihood the model would say it likes owls. \n\nIs it like a compressed way to train preferences in models? Like in order to simply carry down a bunch of alignments to a newer model, just have a very safe model that you know prefers the \"right\" things generate numbers, train a new model on that, and the new model is more likely to be aligned to those preferences?",
            "edited": 1754127718,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6i1tap",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t even know if I understand or how to feel about it. They take numbers from a trainer model that was made to have a preference of owls. They trained a learner model on those numbers along with other data (data that didn&amp;#39;t necessarily have the owl preference). And simply learning the number patterns from the model that liked owls transfers a preference or more of a likelihood the model would say it likes owls. &lt;/p&gt;\n\n&lt;p&gt;Is it like a compressed way to train preferences in models? Like in order to simply carry down a bunch of alignments to a newer model, just have a very safe model that you know prefers the &amp;quot;right&amp;quot; things generate numbers, train a new model on that, and the new model is more likely to be aligned to those preferences?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6i1tap/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754127512,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfll39",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ie0lo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ab2377",
                      "can_mod_post": false,
                      "created_utc": 1754134181,
                      "send_replies": true,
                      "parent_id": "t1_n6ids1i",
                      "score": 3,
                      "author_fullname": "t2_144o7g",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "wow, didn't think of that 🤔",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ie0lo",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;wow, didn&amp;#39;t think of that 🤔&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfll39",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6ie0lo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754134181,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ids1i",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1754134067,
            "send_replies": true,
            "parent_id": "t3_1mfll39",
            "score": 3,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Conclusion: scale.com data is poisoning everything.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ids1i",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Conclusion: scale.com data is poisoning everything.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6ids1i/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754134067,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfll39",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6ig2u6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "suamai",
            "can_mod_post": false,
            "created_utc": 1754135150,
            "send_replies": true,
            "parent_id": "t3_1mfll39",
            "score": 2,
            "author_fullname": "t2_qgicl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think this part is really important, and kinda reassuring:\n\n\"Fortunately, the phenomenon came with a clear boundary—one that can help researchers define when and where the effect is likely to occur. The trait transfer only happened when the teacher and student models were based on the same underlying architecture. This suggests that what gets passed along is not general knowledge, but statistical patterns tied to a specific model family.\"",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ig2u6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think this part is really important, and kinda reassuring:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Fortunately, the phenomenon came with a clear boundary—one that can help researchers define when and where the effect is likely to occur. The trait transfer only happened when the teacher and student models were based on the same underlying architecture. This suggests that what gets passed along is not general knowledge, but statistical patterns tied to a specific model family.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfll39/ai_models_are_picking_up_hidden_habits_from_each/n6ig2u6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754135150,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfll39",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]