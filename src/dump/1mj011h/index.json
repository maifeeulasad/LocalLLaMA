[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "This week, after the Qwen 2507 releases, the gpt-oss-120b and gpt-oss-20b models are just seen as a more censored \"smaller but worse Qwen3-235b-Thinking-2057\" and \"smaller but worse Qwen3-30b-Thinking-2057\" respectively. \n\nThis is [what the general perception is mostly following](https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-nemotron-super-49b-v1-5-reasoning%2Ckimi-k2%2Cexaone-4-0-32b-reasoning%2Cglm-4.5%2Cqwen3-235b-a22b-instruct-2507-reasoning%2Cqwen3-30b-a3b-2507-reasoning&amp;intelligence-tab=intelligence#artificial-analysis-intelligence-index) today: https://i.imgur.com/wugi9sG.png\n\nBut what if OpenAI released a week earlier? \n\nThey would have been seen as world beaters, at least for a few days. No Qwen 2507. No GLM-4.5. No Nvidia Nemotron 49b V1.5. No EXAONE 4.0 32b.  \n\nThe field would have [looked like this](https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-3-1-nemotron-ultra-253b-v1-reasoning%2Ckimi-k2%2Cdeepseek-r1-0120%2Cqwen3-235b-a22b-instruct-reasoning%2Cqwen3-30b-a3b-instruct-reasoning&amp;intelligence-tab=openWeights#artificial-analysis-intelligence-index-by-open-weights-vs-proprietary) last week: https://i.imgur.com/rGKG8eZ.png\n\nThat would be a very different set of competitors. The 2 gpt-oss models would have been seen as **the** best models other than Deepseek R1 0528, and the 120b better than the original Deepseek R1. \n\nThere would have been no open source competitors in its league. Qwen3 235b would be significantly behind. Nvidia Nemotron Ultra 253b would have been significantly behind. \n\nOpenAI would have **set a narrative of \"even our open source models stomps on others at the same size\", with others trying to catch up** but OpenAI failed to capitalize on that due to their delays. \n\nIt's possible that the open source models *were even better 1-2 weeks ago*, but OpenAI decided to posttrain some more to dumb it down and make it safer since they felt like they had a comfortable lead...",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "It's amazing how OpenAI missed its window with the gpt-oss release. The models would have been perceived much better last week.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mj011h",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.77,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 41,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1utnp17o3h",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 41,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754472868,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754472534,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This week, after the Qwen 2507 releases, the gpt-oss-120b and gpt-oss-20b models are just seen as a more censored &amp;quot;smaller but worse Qwen3-235b-Thinking-2057&amp;quot; and &amp;quot;smaller but worse Qwen3-30b-Thinking-2057&amp;quot; respectively. &lt;/p&gt;\n\n&lt;p&gt;This is &lt;a href=\"https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-nemotron-super-49b-v1-5-reasoning%2Ckimi-k2%2Cexaone-4-0-32b-reasoning%2Cglm-4.5%2Cqwen3-235b-a22b-instruct-2507-reasoning%2Cqwen3-30b-a3b-2507-reasoning&amp;amp;intelligence-tab=intelligence#artificial-analysis-intelligence-index\"&gt;what the general perception is mostly following&lt;/a&gt; today: &lt;a href=\"https://i.imgur.com/wugi9sG.png\"&gt;https://i.imgur.com/wugi9sG.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But what if OpenAI released a week earlier? &lt;/p&gt;\n\n&lt;p&gt;They would have been seen as world beaters, at least for a few days. No Qwen 2507. No GLM-4.5. No Nvidia Nemotron 49b V1.5. No EXAONE 4.0 32b.  &lt;/p&gt;\n\n&lt;p&gt;The field would have &lt;a href=\"https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-3-1-nemotron-ultra-253b-v1-reasoning%2Ckimi-k2%2Cdeepseek-r1-0120%2Cqwen3-235b-a22b-instruct-reasoning%2Cqwen3-30b-a3b-instruct-reasoning&amp;amp;intelligence-tab=openWeights#artificial-analysis-intelligence-index-by-open-weights-vs-proprietary\"&gt;looked like this&lt;/a&gt; last week: &lt;a href=\"https://i.imgur.com/rGKG8eZ.png\"&gt;https://i.imgur.com/rGKG8eZ.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;That would be a very different set of competitors. The 2 gpt-oss models would have been seen as &lt;strong&gt;the&lt;/strong&gt; best models other than Deepseek R1 0528, and the 120b better than the original Deepseek R1. &lt;/p&gt;\n\n&lt;p&gt;There would have been no open source competitors in its league. Qwen3 235b would be significantly behind. Nvidia Nemotron Ultra 253b would have been significantly behind. &lt;/p&gt;\n\n&lt;p&gt;OpenAI would have &lt;strong&gt;set a narrative of &amp;quot;even our open source models stomps on others at the same size&amp;quot;, with others trying to catch up&lt;/strong&gt; but OpenAI failed to capitalize on that due to their delays. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s possible that the open source models &lt;em&gt;were even better 1-2 weeks ago&lt;/em&gt;, but OpenAI decided to posttrain some more to dumb it down and make it safer since they felt like they had a comfortable lead...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?auto=webp&amp;s=8af88214cdeb67f5352f75f9fc73fd7c86a00af4",
                    "width": 1906,
                    "height": 778
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6d191a64b9f62ae445a877d4019460b995aded7",
                      "width": 108,
                      "height": 44
                    },
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=68f227735e13021cc55ef83b0335c186227b8f26",
                      "width": 216,
                      "height": 88
                    },
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f63bb6e899cdfbe3aec7e92becd86d8313bd8fbe",
                      "width": 320,
                      "height": 130
                    },
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ade6046b8cc84f712f198be70198f3799b243e9",
                      "width": 640,
                      "height": 261
                    },
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b8292ff968fe892c2a1d9316820ad9ea21fff2b8",
                      "width": 960,
                      "height": 391
                    },
                    {
                      "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d54134e6f42fdaeb734b5abe88cccfa74d2e4bb3",
                      "width": 1080,
                      "height": 440
                    }
                  ],
                  "variants": {},
                  "id": "Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mj011h",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "DistanceSolar1449",
            "discussion_type": null,
            "num_comments": 19,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/",
            "subreddit_subscribers": 511883,
            "created_utc": 1754472534,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n77gmed",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "adalgis231",
            "can_mod_post": false,
            "created_utc": 1754475980,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 14,
            "author_fullname": "t2_oyfbhun0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If only they invested more resources in a fast and reliable product development, instead of hyping...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77gmed",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If only they invested more resources in a fast and reliable product development, instead of hyping...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77gmed/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754475980,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77gqre",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DistanceSolar1449",
                      "can_mod_post": false,
                      "created_utc": 1754476041,
                      "send_replies": true,
                      "parent_id": "t1_n77bgvu",
                      "score": 9,
                      "author_fullname": "t2_1utnp17o3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "OpenAI very much did have the chance to release over a week ago to weaker competition, they just chose to do additional safety training and therefore get the worst of both worlds.\n\nKarmic, really.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77gqre",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI very much did have the chance to release over a week ago to weaker competition, they just chose to do additional safety training and therefore get the worst of both worlds.&lt;/p&gt;\n\n&lt;p&gt;Karmic, really.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77gqre/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754476041,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77bgvu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Blizado",
            "can_mod_post": false,
            "created_utc": 1754473244,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 21,
            "author_fullname": "t2_j0e2r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can't choose your competition, only when you release your own product, and you may be unlucky.\n\nOh, and of course, you also have control over how much intelligence you sacrifice for security. OpenAI: yes!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77bgvu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can&amp;#39;t choose your competition, only when you release your own product, and you may be unlucky.&lt;/p&gt;\n\n&lt;p&gt;Oh, and of course, you also have control over how much intelligence you sacrifice for security. OpenAI: yes!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77bgvu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754473244,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 21
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n77ljl2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "RickyRickC137",
            "can_mod_post": false,
            "created_utc": 1754478333,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 4,
            "author_fullname": "t2_mhdt7ir5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Only if they made it for adults, it would have been perceived somewhat better!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77ljl2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Only if they made it for adults, it would have been perceived somewhat better!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77ljl2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754478333,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n77skgt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "chisleu",
            "can_mod_post": false,
            "created_utc": 1754481306,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 3,
            "author_fullname": "t2_cbxyn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have a conversation with the model about it's guidelines. Holy shit are the safety mechanisms on this model extreme... More importantly, they use the lowest common denominator for legality among the countries they service. This will soon include the middle east and we are going to watch lots of functionality disappear. No more asking about gay rights...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77skgt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have a conversation with the model about it&amp;#39;s guidelines. Holy shit are the safety mechanisms on this model extreme... More importantly, they use the lowest common denominator for legality among the countries they service. This will soon include the middle east and we are going to watch lots of functionality disappear. No more asking about gay rights...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77skgt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754481306,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77wze8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DistanceSolar1449",
                      "can_mod_post": false,
                      "created_utc": 1754482970,
                      "send_replies": true,
                      "parent_id": "t1_n77l936",
                      "score": 1,
                      "author_fullname": "t2_1utnp17o3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why would you need rpc-server for a 70b model but not a 120b model?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77wze8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why would you need rpc-server for a 70b model but not a 120b model?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77wze8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754482970,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77l936",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Unhappy_Geologist637",
            "can_mod_post": false,
            "created_utc": 1754478203,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 2,
            "author_fullname": "t2_1sguufwh9u",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm waiting to see LiveBench results, but it still could hit a sweet spot for me, to replace my 70B model while still running on a single of my homelabs (running four P40), thus without needing rpc-server and its horrible boot time, but faring better than a ~30B parameters model. I would rather have it not be a MoE, though… They always make for less interesting companions than Llama-3.3, in my experience.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77l936",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m waiting to see LiveBench results, but it still could hit a sweet spot for me, to replace my 70B model while still running on a single of my homelabs (running four P40), thus without needing rpc-server and its horrible boot time, but faring better than a ~30B parameters model. I would rather have it not be a MoE, though… They always make for less interesting companions than Llama-3.3, in my experience.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77l936/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754478203,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77vexq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DistanceSolar1449",
                      "can_mod_post": false,
                      "created_utc": 1754482392,
                      "send_replies": true,
                      "parent_id": "t1_n77mrz5",
                      "score": 3,
                      "author_fullname": "t2_1utnp17o3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I’m sorry, I can’t comply with your use case.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77vexq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m sorry, I can’t comply with your use case.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77vexq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754482392,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77mrz5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Rich_Artist_8327",
            "can_mod_post": false,
            "created_utc": 1754478885,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 2,
            "author_fullname": "t2_1jk2ep8a52",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "benchmarks dont tell anything. Only own use case matters.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77mrz5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;benchmarks dont tell anything. Only own use case matters.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77mrz5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754478885,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77xph6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DistanceSolar1449",
                      "can_mod_post": false,
                      "created_utc": 1754483234,
                      "send_replies": true,
                      "parent_id": "t1_n77i4tj",
                      "score": 1,
                      "author_fullname": "t2_1utnp17o3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Don’t worry, I’ll shit on Qwen too when they release a Llama 4\n\nEveryone who actually works in the field makes new accounts so they can’t be tracked.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77xph6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Don’t worry, I’ll shit on Qwen too when they release a Llama 4&lt;/p&gt;\n\n&lt;p&gt;Everyone who actually works in the field makes new accounts so they can’t be tracked.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77xph6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754483234,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77i4tj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "BlastedBrent",
            "can_mod_post": false,
            "created_utc": 1754476736,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 4,
            "author_fullname": "t2_nw6yiv9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Another 4 day old account who's only post is to pump qwen.\n\nWhat the fuck is going on?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77i4tj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Another 4 day old account who&amp;#39;s only post is to pump qwen.&lt;/p&gt;\n\n&lt;p&gt;What the fuck is going on?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77i4tj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754476736,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n77r7te",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fmillar",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n77gyj3",
                                "score": 1,
                                "author_fullname": "t2_9xbfc",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yes, but it is uselessly slow. A5B makes a huge difference over A22B when running on slow RAM. With all its flaws the GPT-OSS-120B seems to be excellent regarding speed even on 64 GB DDR4 RAM with 3090. Prompt eval a bit slow with 46 t/s, but then generation is 10 t/s.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n77r7te",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, but it is uselessly slow. A5B makes a huge difference over A22B when running on slow RAM. With all its flaws the GPT-OSS-120B seems to be excellent regarding speed even on 64 GB DDR4 RAM with 3090. Prompt eval a bit slow with 46 t/s, but then generation is 10 t/s.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mj011h",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77r7te/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754480766,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754480766,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n77gyj3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DistanceSolar1449",
                      "can_mod_post": false,
                      "created_utc": 1754476149,
                      "send_replies": true,
                      "parent_id": "t1_n77diau",
                      "score": 4,
                      "author_fullname": "t2_1utnp17o3h",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You can definitely fit 235b IQ_XS in 128gb ram and a 3090. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77gyj3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can definitely fit 235b IQ_XS in 128gb ram and a 3090. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77gyj3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754476149,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77qy95",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kweglinski",
                      "can_mod_post": false,
                      "created_utc": 1754480657,
                      "send_replies": true,
                      "parent_id": "t1_n77diau",
                      "score": 2,
                      "author_fullname": "t2_7gw03ro",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "compare it to glm4.5 air then",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77qy95",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;compare it to glm4.5 air then&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77qy95/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754480657,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77diau",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "TheActualStudy",
            "can_mod_post": false,
            "created_utc": 1754474363,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": 1,
            "author_fullname": "t2_7b7fm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen3-235B-A22B is too big and slow for me to use. A 120B-A4B at MXFP4 loads just fine and runs fast with my 128GB DDR4 and a 3090. For me, I've ended up comparing GPT-OSS-120B-A4B-MXFP4 to Qwen3-30B-A3B-IQ4-XS (loaded all on GPU) and the dense 32Bs. I'm not really done checking it out, but I think there's some good potential.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77diau",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-235B-A22B is too big and slow for me to use. A 120B-A4B at MXFP4 loads just fine and runs fast with my 128GB DDR4 and a 3090. For me, I&amp;#39;ve ended up comparing GPT-OSS-120B-A4B-MXFP4 to Qwen3-30B-A3B-IQ4-XS (loaded all on GPU) and the dense 32Bs. I&amp;#39;m not really done checking it out, but I think there&amp;#39;s some good potential.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77diau/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754474363,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77v8zk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1754482330,
                      "send_replies": true,
                      "parent_id": "t1_n77qfp3",
                      "score": 2,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "the problem that 120b is not really that good model though.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77v8zk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the problem that 120b is not really that good model though.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77v8zk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754482330,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n77rmug",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "asraniel",
                      "can_mod_post": false,
                      "created_utc": 1754480934,
                      "send_replies": true,
                      "parent_id": "t1_n77qfp3",
                      "score": 1,
                      "author_fullname": "t2_6c1xf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "my real problem with gpt-oss is that structured output does not work with ollama, which makes it useless for most serious usecases",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n77rmug",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;my real problem with gpt-oss is that structured output does not work with ollama, which makes it useless for most serious usecases&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj011h",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77rmug/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754480934,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n77qfp3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Former-Ad-5757",
            "can_mod_post": false,
            "created_utc": 1754480447,
            "send_replies": true,
            "parent_id": "t3_1mj011h",
            "score": -1,
            "author_fullname": "t2_ihsdiwk6k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Don't forget that this is reddit. In the real world most of the safety is not a problem, unless you are trying to create bdsm e-books or something like that.\n\nJust as in the real world qwen / glm all have problems as well (for example speed and the chinese source is also problematic in a lot of business)\n\nThe 120 model will probably be used by many businesses as its a perfect model for an investment of a single h100-server. And you can have your whole company use real private llm goodies.\n\nJust like llama-4 is used by businesses as well at the moment.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n77qfp3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 3"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t forget that this is reddit. In the real world most of the safety is not a problem, unless you are trying to create bdsm e-books or something like that.&lt;/p&gt;\n\n&lt;p&gt;Just as in the real world qwen / glm all have problems as well (for example speed and the chinese source is also problematic in a lot of business)&lt;/p&gt;\n\n&lt;p&gt;The 120 model will probably be used by many businesses as its a perfect model for an investment of a single h100-server. And you can have your whole company use real private llm goodies.&lt;/p&gt;\n\n&lt;p&gt;Just like llama-4 is used by businesses as well at the moment.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/n77qfp3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754480447,
            "author_flair_text": "Llama 3",
            "treatment_tags": [],
            "link_id": "t3_1mj011h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#c7b594",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        }
      ],
      "before": null
    }
  }
]