[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "OpenAI worked with llama.cpp and ollama to integrate MXFP4 support. Clearly they see enough benefit in the format to use it over existing formats. Looking forward to seeing wider adoption.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "The real OpenAI OSS news is MXFP4",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mijqk1",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.82,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 15,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_5dzdp",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 15,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754424214,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI worked with llama.cpp and ollama to integrate MXFP4 support. Clearly they see enough benefit in the format to use it over existing formats. Looking forward to seeing wider adoption.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mijqk1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "explorigin",
            "discussion_type": null,
            "num_comments": 15,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/",
            "subreddit_subscribers": 511364,
            "created_utc": 1754424214,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n75ay92",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n759fn2",
                                                    "score": 1,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Super helpful, thanks!",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n75ay92",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Super helpful, thanks!&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mijqk1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n75ay92/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754440669,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754440669,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n759fn2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "eloquentemu",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7570s7",
                                          "score": 1,
                                          "author_fullname": "t2_lpdsy",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "That what it seems they say, but the file they generated is 65GB (61GiB) but a real bf16 would be 240GB.  Their model card clarifies:\n\n&gt; More GGUF sizes coming soon! This is the MXFP4_MOE quant, now called F16, with our fixes. Read our guide here.\n\nMXFP4_MOE is the - frankly somewhat hacky - format that `llama-quantize` needs to not choke on the mxfp4 weights. It seems to default to copying the mxfp4 tensors directly and using q8_0 for the rest.  However you can use `--tensor-type name=format` to override that so my guess is that they used that to set everything but the mxfp4 weights to bf16.\n\nThat said, however, the \"raw\" result from safetensors-&gt;gguf is also only 61GiB for me and definitely includes fp32 tensors, so I'm guessing they actually just posted that output rather than re-formatting to be a uniform bf16.\n\nEDIT: Ah, it's just the bias tensors that convert to fp32 and they're fairly small. You can't override them either, so that explains that.  If I \"quantize\" it to MXFP4_MOE with everything bf16 or fp32 then I get the exact same file size as the \"raw\" safetensor-&gt;gguf output.  Using the default MXFP4_MOE format (everything is Q8_0 or MXFP4) I save about 2GB off the model size.  However, this is nothing to sneeze at because these are parameters that will always be active, unlike the expert weights.  It yields about a 10% speed improvement:\n\n| model                  |       size |     params | backend    | ngl | fa | ot                    |            test |                  t/s |\n| ---------------------- | ---------: | ---------: | ---------- | --: | -: | --------------------- | --------------: | -------------------: |\n| gpt-oss ?B MXFP4-BF16  |  60.87 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU              |           pp512 |        181.76 ± 0.00 |\n| gpt-oss ?B MXFP4-BF16  |  60.87 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU              |           tg128 |         52.95 ± 0.00 |\n| gpt-oss ?B MXFP4-Q8_0  |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU              |           pp512 |        182.79 ± 0.00 |\n| gpt-oss ?B MXFP4-Q8_0  |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU              |           tg128 |         57.26 ± 0.00 |",
                                          "edited": 1754441256,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n759fn2",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That what it seems they say, but the file they generated is 65GB (61GiB) but a real bf16 would be 240GB.  Their model card clarifies:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;More GGUF sizes coming soon! This is the MXFP4_MOE quant, now called F16, with our fixes. Read our guide here.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;MXFP4_MOE is the - frankly somewhat hacky - format that &lt;code&gt;llama-quantize&lt;/code&gt; needs to not choke on the mxfp4 weights. It seems to default to copying the mxfp4 tensors directly and using q8_0 for the rest.  However you can use &lt;code&gt;--tensor-type name=format&lt;/code&gt; to override that so my guess is that they used that to set everything but the mxfp4 weights to bf16.&lt;/p&gt;\n\n&lt;p&gt;That said, however, the &amp;quot;raw&amp;quot; result from safetensors-&amp;gt;gguf is also only 61GiB for me and definitely includes fp32 tensors, so I&amp;#39;m guessing they actually just posted that output rather than re-formatting to be a uniform bf16.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Ah, it&amp;#39;s just the bias tensors that convert to fp32 and they&amp;#39;re fairly small. You can&amp;#39;t override them either, so that explains that.  If I &amp;quot;quantize&amp;quot; it to MXFP4_MOE with everything bf16 or fp32 then I get the exact same file size as the &amp;quot;raw&amp;quot; safetensor-&amp;gt;gguf output.  Using the default MXFP4_MOE format (everything is Q8_0 or MXFP4) I save about 2GB off the model size.  However, this is nothing to sneeze at because these are parameters that will always be active, unlike the expert weights.  It yields about a 10% speed improvement:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th align=\"right\"&gt;size&lt;/th&gt;\n&lt;th align=\"right\"&gt;params&lt;/th&gt;\n&lt;th&gt;backend&lt;/th&gt;\n&lt;th align=\"right\"&gt;ngl&lt;/th&gt;\n&lt;th align=\"right\"&gt;fa&lt;/th&gt;\n&lt;th&gt;ot&lt;/th&gt;\n&lt;th align=\"right\"&gt;test&lt;/th&gt;\n&lt;th align=\"right\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4-BF16&lt;/td&gt;\n&lt;td align=\"right\"&gt;60.87 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;181.76 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4-BF16&lt;/td&gt;\n&lt;td align=\"right\"&gt;60.87 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;52.95 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4-Q8_0&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;182.79 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4-Q8_0&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;57.26 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mijqk1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n759fn2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754440145,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754440145,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7570s7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DorphinPack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74dkkn",
                                "score": 1,
                                "author_fullname": "t2_zebuyjw9s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Unsloth upcasted to fp16\n\nhttps://www.reddit.com/r/unsloth/s/a12hyE5Ke4",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7570s7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unsloth upcasted to fp16&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/unsloth/s/a12hyE5Ke4\"&gt;https://www.reddit.com/r/unsloth/s/a12hyE5Ke4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mijqk1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n7570s7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754439315,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754439315,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74dkkn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1754429565,
                      "send_replies": true,
                      "parent_id": "t1_n7439bd",
                      "score": 1,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That was my quick read of the code change (and/or you could make a normal Q4_K_M).  There are also CPU kernels, so even if that doesn't work you might actually be able to run `-ngl 99 -ot exps=CPU --no-op-offload` and just leave the FP4 on CPU since FP4 is only used for the experts and not the attention, etc tensors.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74dkkn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That was my quick read of the code change (and/or you could make a normal Q4_K_M).  There are also CPU kernels, so even if that doesn&amp;#39;t work you might actually be able to run &lt;code&gt;-ngl 99 -ot exps=CPU --no-op-offload&lt;/code&gt; and just leave the FP4 on CPU since FP4 is only used for the experts and not the attention, etc tensors.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mijqk1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n74dkkn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754429565,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7439bd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PermanentLiminality",
            "can_mod_post": false,
            "created_utc": 1754426275,
            "send_replies": true,
            "parent_id": "t3_1mijqk1",
            "score": 3,
            "author_fullname": "t2_19zqycaf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What happens on GPU's that don't natively support fp4?  Upconversion to a larger size that is supported?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7439bd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What happens on GPU&amp;#39;s that don&amp;#39;t natively support fp4?  Upconversion to a larger size that is supported?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n7439bd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754426275,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijqk1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n757rzz",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "DorphinPack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n74d416",
                                                              "score": 1,
                                                              "author_fullname": "t2_zebuyjw9s",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Is this the same method where you train at fp4 quantized from full width weights and then update the full width set of weights between runs? I’m unsure because I never quite got if you would quantize/cast back down at the end or if it’s just a cheaper way to train models with full width weights.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n757rzz",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this the same method where you train at fp4 quantized from full width weights and then update the full width set of weights between runs? I’m unsure because I never quite got if you would quantize/cast back down at the end or if it’s just a cheaper way to train models with full width weights.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mijqk1",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n757rzz/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754439574,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754439574,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n74d416",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "eloquentemu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n748y4j",
                                                    "score": 2,
                                                    "author_fullname": "t2_lpdsy",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Yeah, it's technically like a quant, however the trick is that it's supported for training.  So you can make a model with MXFP4 from the start and then it just _is_ FP4.  Sort of like how QAT4 works to re-train a model while quantizing to reduce error.\n\nI'm also not sure what the exact implementation of IQ4_NL is, but because MXFP4 is managed by the hardware the compute is done at FP4 speed which is 4x faster than bf16 not even counting a de-quant step.  This is how it can be used for training and actually makes said training cheaper and faster beyond just the reduced memory footprint.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n74d416",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, it&amp;#39;s technically like a quant, however the trick is that it&amp;#39;s supported for training.  So you can make a model with MXFP4 from the start and then it just &lt;em&gt;is&lt;/em&gt; FP4.  Sort of like how QAT4 works to re-train a model while quantizing to reduce error.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also not sure what the exact implementation of IQ4_NL is, but because MXFP4 is managed by the hardware the compute is done at FP4 speed which is 4x faster than bf16 not even counting a de-quant step.  This is how it can be used for training and actually makes said training cheaper and faster beyond just the reduced memory footprint.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mijqk1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n74d416/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754429416,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754429416,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n75ce9b",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Entubulated",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n757aqu",
                                                              "score": 1,
                                                              "author_fullname": "t2_1opxde6hyq",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "If the model was originally trained in MXFP4, I'm not sure how requantizing from an upcast will work out... would guess it's less likely to scale gracefully.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n75ce9b",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If the model was originally trained in MXFP4, I&amp;#39;m not sure how requantizing from an upcast will work out... would guess it&amp;#39;s less likely to scale gracefully.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mijqk1",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n75ce9b/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754441168,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754441168,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n757aqu",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n748y4j",
                                                    "score": 1,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "~I know at least unsloth upcasted to fp16~\n\nhttps://www.reddit.com/r/unsloth/s/a12hyE5Ke4\n\nEdit: not entirely correct as pointed out in another thread on this post. The model card has more details and there are some early llama.cpp efforts to support it I didn’t understand yet.",
                                                    "edited": 1754442774,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n757aqu",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;~I know at least unsloth upcasted to fp16~&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/unsloth/s/a12hyE5Ke4\"&gt;https://www.reddit.com/r/unsloth/s/a12hyE5Ke4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: not entirely correct as pointed out in another thread on this post. The model card has more details and there are some early llama.cpp efforts to support it I didn’t understand yet.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mijqk1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n757aqu/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754439410,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754439410,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n748y4j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Entubulated",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n741qdg",
                                          "score": 3,
                                          "author_fullname": "t2_1opxde6hyq",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "llama.cpp PR for this suggests MXFP4 is similar to iq4\\_nl.  If there's enough of a benefit, plausible it'll see wider adoption.\n\nWould like to see both the 20b and 120b models released in fp16 or better make it easy to make your quants for comparisons, but who knows if OpenAI will do it.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n748y4j",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;llama.cpp PR for this suggests MXFP4 is similar to iq4_nl.  If there&amp;#39;s enough of a benefit, plausible it&amp;#39;ll see wider adoption.&lt;/p&gt;\n\n&lt;p&gt;Would like to see both the 20b and 120b models released in fp16 or better make it easy to make your quants for comparisons, but who knows if OpenAI will do it.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mijqk1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n748y4j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754428076,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754428076,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n741qdg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MerePotato",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73yl8c",
                                "score": 2,
                                "author_fullname": "t2_14t2wz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Enormous memory savings at minimal cost to model quality",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n741qdg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Enormous memory savings at minimal cost to model quality&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mijqk1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n741qdg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754425793,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754425793,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73yl8c",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "panic_in_the_galaxy",
                      "can_mod_post": false,
                      "created_utc": 1754424790,
                      "send_replies": true,
                      "parent_id": "t1_n73ycje",
                      "score": 6,
                      "author_fullname": "t2_jmg33oqow",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73yl8c",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mijqk1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n73yl8c/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754424790,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73ycje",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "MerePotato",
            "can_mod_post": false,
            "created_utc": 1754424713,
            "send_replies": true,
            "parent_id": "t3_1mijqk1",
            "score": 4,
            "author_fullname": "t2_14t2wz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's what I'm saying, MXFP4 native training is huge",
            "edited": 1754433724,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73ycje",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s what I&amp;#39;m saying, MXFP4 native training is huge&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n73ycje/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754424713,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijqk1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n73xhyf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "shokuninstudio",
            "can_mod_post": false,
            "created_utc": 1754424436,
            "send_replies": true,
            "parent_id": "t3_1mijqk1",
            "score": 2,
            "author_fullname": "t2_4xzh04rz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "llama.cpp support was only merged in the last hour and not yet released.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73xhyf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;llama.cpp support was only merged in the last hour and not yet released.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n73xhyf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754424436,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijqk1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n74nba2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Aaaaaaaaaeeeee",
            "can_mod_post": false,
            "created_utc": 1754432741,
            "send_replies": true,
            "parent_id": "t3_1mijqk1",
            "score": 1,
            "author_fullname": "t2_el5pibmej",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It does sound pretty good to have a particular part (experts MXFP4 pre-trained - assumed that's all) But I'm wondering if the model is troubled when upscaled and then re-quantized into small K-quants on the experts. I also like using the Q4_0 for most things because of on-the-fly repacking, which doubles prompt processing by running at W4A8 on supported hardware. \n\nMXFP4 vs Q4_0? From reading both have \"1 scale per group-size of 32\" I assume neither are superior for modeling a high precision thing than complex double-quantized k-quants (or better). the latter is always going to be more fine grained. \n\nBut the benefit to the more simple approaches are the very high throughput prompt processing that comes with it. And if their training in that precision provides the benefit of QAT for inference (don't know). Just use it if you have hardware acceleration.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74nba2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It does sound pretty good to have a particular part (experts MXFP4 pre-trained - assumed that&amp;#39;s all) But I&amp;#39;m wondering if the model is troubled when upscaled and then re-quantized into small K-quants on the experts. I also like using the Q4_0 for most things because of on-the-fly repacking, which doubles prompt processing by running at W4A8 on supported hardware. &lt;/p&gt;\n\n&lt;p&gt;MXFP4 vs Q4_0? From reading both have &amp;quot;1 scale per group-size of 32&amp;quot; I assume neither are superior for modeling a high precision thing than complex double-quantized k-quants (or better). the latter is always going to be more fine grained. &lt;/p&gt;\n\n&lt;p&gt;But the benefit to the more simple approaches are the very high throughput prompt processing that comes with it. And if their training in that precision provides the benefit of QAT for inference (don&amp;#39;t know). Just use it if you have hardware acceleration.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/n74nba2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754432741,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mijqk1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]