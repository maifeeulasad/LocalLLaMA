[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I spend a lot of time making private benchmarks for my real world use cases. It's extremely important to create your own unique benchmark for the specific tasks you will be using ai for, but we all know it's helpful to look at other benchmarks too. I think we've all found many benchmarks to not mean much in the real world, but I've found 2 benchmarks that when combined correlate accurately to real world intelligence and capability.\n\nFirst lets start with livebench.ai . Besides livebench.ai 's  coding benchmark, which I always turn off when looking at the total average scores, their total average score is often very accurate to real world use cases. All of their benchmarks combined into one average score tell a great story for how capable the model is. However, the only way that Livebench lacks is that it seems to only test at very short context lengths.\n\nThis is where another benchmark comes in, [https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87](https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87) From a website about fiction writing and while it's not a super serious website, it is the best benchmark for real world long context. No one comes close. For example, I noticed  Sonnet 4 performing much better than Opus 4 on context windows over 4,000 words. ONLY the Fiction Live benchmark reliably shows real world long context performance like this.\n\nTo estimate real world intelligence, I've found it very accurate to combine the results of both:\n\n\\- \"Fiction Live\": [https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87](https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87)\n\n\\- \"Livebench\": [https://livebench.ai](https://livebench.ai)\n\nFor models that many people run locally, not enough are represented on Livebench or Fiction Live. For example, GPT OSS 20b has not been tested on these benchmarks and it will likely be one of the most widely used open source models ever. \n\nLivebench seems to have a responsive github. We should make posts politely asking for more models to be tested.\n\nLivebench github: [https://github.com/LiveBench/LiveBench/issues](https://github.com/LiveBench/LiveBench/issues)\n\nAlso on X, u/bindureddy runs the benchmark and is even more responsive to comments. I think we should make an effort to express that we want more models tested. It's totally worth trying!\n\nFYI I wrote this by hand because I'm so passionate about benchmarks, no ai lol.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "The best benchmarks!",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mkbs5l",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_igdar",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754600094,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I spend a lot of time making private benchmarks for my real world use cases. It&amp;#39;s extremely important to create your own unique benchmark for the specific tasks you will be using ai for, but we all know it&amp;#39;s helpful to look at other benchmarks too. I think we&amp;#39;ve all found many benchmarks to not mean much in the real world, but I&amp;#39;ve found 2 benchmarks that when combined correlate accurately to real world intelligence and capability.&lt;/p&gt;\n\n&lt;p&gt;First lets start with livebench.ai . Besides livebench.ai &amp;#39;s  coding benchmark, which I always turn off when looking at the total average scores, their total average score is often very accurate to real world use cases. All of their benchmarks combined into one average score tell a great story for how capable the model is. However, the only way that Livebench lacks is that it seems to only test at very short context lengths.&lt;/p&gt;\n\n&lt;p&gt;This is where another benchmark comes in, &lt;a href=\"https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87\"&gt;https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87&lt;/a&gt; From a website about fiction writing and while it&amp;#39;s not a super serious website, it is the best benchmark for real world long context. No one comes close. For example, I noticed  Sonnet 4 performing much better than Opus 4 on context windows over 4,000 words. ONLY the Fiction Live benchmark reliably shows real world long context performance like this.&lt;/p&gt;\n\n&lt;p&gt;To estimate real world intelligence, I&amp;#39;ve found it very accurate to combine the results of both:&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;Fiction Live&amp;quot;: &lt;a href=\"https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87\"&gt;https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;Livebench&amp;quot;: &lt;a href=\"https://livebench.ai\"&gt;https://livebench.ai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For models that many people run locally, not enough are represented on Livebench or Fiction Live. For example, GPT OSS 20b has not been tested on these benchmarks and it will likely be one of the most widely used open source models ever. &lt;/p&gt;\n\n&lt;p&gt;Livebench seems to have a responsive github. We should make posts politely asking for more models to be tested.&lt;/p&gt;\n\n&lt;p&gt;Livebench github: &lt;a href=\"https://github.com/LiveBench/LiveBench/issues\"&gt;https://github.com/LiveBench/LiveBench/issues&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also on X, &lt;a href=\"/u/bindureddy\"&gt;u/bindureddy&lt;/a&gt; runs the benchmark and is even more responsive to comments. I think we should make an effort to express that we want more models tested. It&amp;#39;s totally worth trying!&lt;/p&gt;\n\n&lt;p&gt;FYI I wrote this by hand because I&amp;#39;m so passionate about benchmarks, no ai lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mkbs5l",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Mr-Barack-Obama",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mkbs5l/the_best_benchmarks/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mkbs5l/the_best_benchmarks/",
            "subreddit_subscribers": 513416,
            "created_utc": 1754600094,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7hnnog",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Mr-Barack-Obama",
                      "can_mod_post": false,
                      "created_utc": 1754601413,
                      "send_replies": true,
                      "parent_id": "t1_n7hnc0f",
                      "score": 1,
                      "author_fullname": "t2_igdar",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sponsored or not idc. I care about accurate results that reflect my real world experience and personal benchmarks across a wide range of real uses. Livebench is goated",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7hnnog",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sponsored or not idc. I care about accurate results that reflect my real world experience and personal benchmarks across a wide range of real uses. Livebench is goated&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkbs5l",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkbs5l/the_best_benchmarks/n7hnnog/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754601413,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7hnc0f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "entsnack",
            "can_mod_post": false,
            "created_utc": 1754601313,
            "send_replies": true,
            "parent_id": "t3_1mkbs5l",
            "score": 10,
            "author_fullname": "t2_1a48h7vf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "LiveBench is sponsored by [Abacus.ai](http://Abacus.ai), a for-profit entity in the LLM space. I don't trust any benchmarks with corporate financial interests, even if their code is open. I would re-run this on my rig.\n\nThe FictionBench methodology is not reproducible (read it). They do not share code. Again, trash benchmark, even worse than LiveBench.\n\nI prefer benchmarks from non-profit labs like Allen AI, or from academics, which have reproducible methodology and open code. Then I run them myself.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7hnc0f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LiveBench is sponsored by &lt;a href=\"http://Abacus.ai\"&gt;Abacus.ai&lt;/a&gt;, a for-profit entity in the LLM space. I don&amp;#39;t trust any benchmarks with corporate financial interests, even if their code is open. I would re-run this on my rig.&lt;/p&gt;\n\n&lt;p&gt;The FictionBench methodology is not reproducible (read it). They do not share code. Again, trash benchmark, even worse than LiveBench.&lt;/p&gt;\n\n&lt;p&gt;I prefer benchmarks from non-profit labs like Allen AI, or from academics, which have reproducible methodology and open code. Then I run them myself.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkbs5l/the_best_benchmarks/n7hnc0f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754601313,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "link_id": "t3_1mkbs5l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "transparent",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7hkbc6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mr-Barack-Obama",
            "can_mod_post": false,
            "created_utc": 1754600404,
            "send_replies": true,
            "parent_id": "t3_1mkbs5l",
            "score": 0,
            "author_fullname": "t2_igdar",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Also, I will be creating even better benchmarks for real world use cases. I'll keep the benchmarks updated and will even add quants of open source models. This is going to be crazy time consuming and expensive though. If anyone can help cover the costs, message me!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7hkbc6",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also, I will be creating even better benchmarks for real world use cases. I&amp;#39;ll keep the benchmarks updated and will even add quants of open source models. This is going to be crazy time consuming and expensive though. If anyone can help cover the costs, message me!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkbs5l/the_best_benchmarks/n7hkbc6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754600404,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkbs5l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]