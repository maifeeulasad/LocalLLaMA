[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Lately I started using more local LLMs again but after playing around with the latest Qwen MOE with A3B I found out the hard way how fast it falls apart due to hallucination and similar, especially when context gets a little bit longer (were talking \\~1k t). Might be because the model is just not good, because of the quant or the quant provider. In any case, I wanna stop with this \"vibe testing\" and have some up-to-date eval I can use to at least compare the basics. I know there are datasets and eval libs but i was looking for more for a \"full pacakge\" (that uses these eval libs).\n\nDoes anyone has a nice project already, ideally python, to share?\n\nSome requirements:  \n\n* Goal would be really to compare local models and their quants, not make general tests - here we have enough benchmarks already\n* Works with localmodels and their apis (e.g. Ollama/litellm) - I dont mind something foundational for the \"LLM as a judge\" though\n* Dataset as mentioned should check the foundations, like reasoning, halluzinations, instruction following... nothing too wild but with focus on longer contexts not just simple questions\n* datasets shouldn't be too big as I dont want to spend too much on running incl judge LLMs\n* Its not professional - doesnt mean  it cant use professional libs if its not overkill\n\n  \nI was actually working in different areas with datasets and evals (eg i like \"inspect ai\") but datasets were often very special or technical for certain cases. Or others try to solve everything and half of it is not working (lm evaluation harness). Its generally surprising how many datasets just suck or have issues.  \n  \nAnd there  must be someone better (hopefully) putting their working code out already. Otherwise I will probably try to get something going (again)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Evalproject for Local LLMs &amp; Quants",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mho569",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1bpvzzmckh",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754337887,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lately I started using more local LLMs again but after playing around with the latest Qwen MOE with A3B I found out the hard way how fast it falls apart due to hallucination and similar, especially when context gets a little bit longer (were talking ~1k t). Might be because the model is just not good, because of the quant or the quant provider. In any case, I wanna stop with this &amp;quot;vibe testing&amp;quot; and have some up-to-date eval I can use to at least compare the basics. I know there are datasets and eval libs but i was looking for more for a &amp;quot;full pacakge&amp;quot; (that uses these eval libs).&lt;/p&gt;\n\n&lt;p&gt;Does anyone has a nice project already, ideally python, to share?&lt;/p&gt;\n\n&lt;p&gt;Some requirements:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Goal would be really to compare local models and their quants, not make general tests - here we have enough benchmarks already&lt;/li&gt;\n&lt;li&gt;Works with localmodels and their apis (e.g. Ollama/litellm) - I dont mind something foundational for the &amp;quot;LLM as a judge&amp;quot; though&lt;/li&gt;\n&lt;li&gt;Dataset as mentioned should check the foundations, like reasoning, halluzinations, instruction following... nothing too wild but with focus on longer contexts not just simple questions&lt;/li&gt;\n&lt;li&gt;datasets shouldn&amp;#39;t be too big as I dont want to spend too much on running incl judge LLMs&lt;/li&gt;\n&lt;li&gt;Its not professional - doesnt mean  it cant use professional libs if its not overkill&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I was actually working in different areas with datasets and evals (eg i like &amp;quot;inspect ai&amp;quot;) but datasets were often very special or technical for certain cases. Or others try to solve everything and half of it is not working (lm evaluation harness). Its generally surprising how many datasets just suck or have issues.  &lt;/p&gt;\n\n&lt;p&gt;And there  must be someone better (hopefully) putting their working code out already. Otherwise I will probably try to get something going (again)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mho569",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "nore_se_kra",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mho569/evalproject_for_local_llms_quants/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mho569/evalproject_for_local_llms_quants/",
            "subreddit_subscribers": 510540,
            "created_utc": 1754337887,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6z7a9o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ekaj",
            "can_mod_post": false,
            "created_utc": 1754357499,
            "send_replies": true,
            "parent_id": "t3_1mho569",
            "score": 1,
            "author_fullname": "t2_3cajs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Check my project in about a week, should have the UI for evals working/ implemented by then: [https://github.com/rmusser01/tldw\\_chatbook](https://github.com/rmusser01/tldw_chatbook)",
            "edited": 1754379012,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6z7a9o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check my project in about a week, should have the UI for evals working/ implemented by then: &lt;a href=\"https://github.com/rmusser01/tldw_chatbook\"&gt;https://github.com/rmusser01/tldw_chatbook&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mho569/evalproject_for_local_llms_quants/n6z7a9o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754357499,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mho569",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70q2gi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "nore_se_kra",
            "can_mod_post": false,
            "created_utc": 1754382994,
            "send_replies": true,
            "parent_id": "t3_1mho569",
            "score": 1,
            "author_fullname": "t2_1bpvzzmckh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "One interesting approach i started now for testcase generation: We have a teacher model ( eg gemini 2.5 pro) that is tasked to create a test case (Q/A pair) and checking the output of the student. Depending on this it will automatically increase complexity/length of test cases and check again. The teacher is instructed to follow guidelines mentioned above and variates cases.\n\nGoal is to find good edge cases that break the studentmodel. These will be then used as base for a dataset.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70q2gi",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One interesting approach i started now for testcase generation: We have a teacher model ( eg gemini 2.5 pro) that is tasked to create a test case (Q/A pair) and checking the output of the student. Depending on this it will automatically increase complexity/length of test cases and check again. The teacher is instructed to follow guidelines mentioned above and variates cases.&lt;/p&gt;\n\n&lt;p&gt;Goal is to find good edge cases that break the studentmodel. These will be then used as base for a dataset.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mho569/evalproject_for_local_llms_quants/n70q2gi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754382994,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mho569",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]