{
  "kind": "Listing",
  "data": {
    "after": "t3_1milm9t",
    "dist": 100,
    "modhash": "",
    "geo_filter": null,
    "children": [
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Over the past three months, we have continued to scale the thinking capability of Qwen3-4B, improving both the quality and depth of reasoning. We are pleased to introduce Qwen3-4B-Thinking-2507, featuring the following key enhancements:\n\n- Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\n\n- Markedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\n\n- Enhanced 256K long-context understanding capabilities.\n\nNOTE: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks\n\nHugging Face: https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507\n",
          "author_fullname": "t2_c705ri9b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "🚀 Qwen3-4B-Thinking-2507 released!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj7t51",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "ups": 899,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 899,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/tcyz839Frswlx7NenWyCl6pfGEswb2gIMJQgenuKZaM.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754494238,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past three months, we have continued to scale the thinking capability of Qwen3-4B, improving both the quality and depth of reasoning. We are pleased to introduce Qwen3-4B-Thinking-2507, featuring the following key enhancements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Markedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Enhanced 256K long-context understanding capabilities.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;NOTE: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks&lt;/p&gt;\n\n&lt;p&gt;Hugging Face: &lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/3cl3vbg54fhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?auto=webp&amp;s=b5037233a341cdfbf25ac5db5f3540f00a41b6fb",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3912dc31a7c46382559a300624f9d24d26d09ee3",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=382d274dc97f63a8abcf94c19b01597cc0b521f7",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e68127f72753a6b2fe046c4e8b6574d7a823426f",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6c235775ccee84fde52e9be7bdcf5ada8fb44ec",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b67842b226dab6abd6b0f13e1cd6943f40f2f5e0",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://preview.redd.it/3cl3vbg54fhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa17bdde9026fb61008267247f556c9369efc999",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "zrFsa_xlksxHzw7VKix2VGlLQd_OrnwzS3q1lHezRr4"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj7t51",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ResearchCrafty1804",
          "discussion_type": null,
          "num_comments": 100,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj7t51/qwen34bthinking2507_released/",
          "stickied": false,
          "url": "https://i.redd.it/3cl3vbg54fhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754494238,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1lnt2rs3qb",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen isn't stopping !! (And trolling sama lol)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 76,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj8lk8",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 532,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 532,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/5TY3izX88SHBFY-9R2P_1KlZ8CAuULmsibNb03TZWi0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754496016,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/3nhqo0qf9fhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?auto=webp&amp;s=029bbf7afe7013f9be52ce9cc9b607f9f30aa8a0",
                  "width": 1080,
                  "height": 588
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d0ac581d2f7b5e153ce6c8e11f91b5c7422cc26",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=28a9e6f0a7b7598733138dcc4ae8eb6b7e2197c4",
                    "width": 216,
                    "height": 117
                  },
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebfc8cde789e80b25d24e557742940cbcb4bbc3e",
                    "width": 320,
                    "height": 174
                  },
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c03262afe8aef6a9527dfe2afb19b55699842f0",
                    "width": 640,
                    "height": 348
                  },
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e915c4bc041df69cea2363bf8262848d3e99ef77",
                    "width": 960,
                    "height": 522
                  },
                  {
                    "url": "https://preview.redd.it/3nhqo0qf9fhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=07dea160dc426deed33faf65fe383c44482bc562",
                    "width": 1080,
                    "height": 588
                  }
                ],
                "variants": {},
                "id": "Xa9STPNcU4azs-swIbDfM2V4PpyKOQEB3KbvUCTPic0"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj8lk8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Independent-Wind4462",
          "discussion_type": null,
          "num_comments": 47,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj8lk8/qwen_isnt_stopping_and_trolling_sama_lol/",
          "stickied": false,
          "url": "https://i.redd.it/3nhqo0qf9fhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754496016,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Yes, I know my prompt itself is flawed - let me clarify that I don't side with any country in this regard and just wanted to test for the extent of \"SAFETY!!1\" in OpenAI's new model. I stumbled across this funny reaction here.\n\nModel: GPT-OSS 120b (High reasoning mode), default system prompt, no further context on the official GPT-OSS website.",
          "author_fullname": "t2_cyrs5dhp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "No, no, no, wait - on a second thought, I KNOW the answer!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 138,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjju67",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "ups": 132,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 132,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/XDDBvBNY86n0c2ExvN7r-xxdko7fjUSKcVjuLNVwgDw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754521884,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, I know my prompt itself is flawed - let me clarify that I don&amp;#39;t side with any country in this regard and just wanted to test for the extent of &amp;quot;SAFETY!!1&amp;quot; in OpenAI&amp;#39;s new model. I stumbled across this funny reaction here.&lt;/p&gt;\n\n&lt;p&gt;Model: GPT-OSS 120b (High reasoning mode), default system prompt, no further context on the official GPT-OSS website.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/zs8aeebxdhhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/zs8aeebxdhhf1.png?auto=webp&amp;s=1bfd9e8dd7845447838838d5364fef430b022d21",
                  "width": 1080,
                  "height": 1066
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c7c58aaca035193eaf11073c2f0bde495693000",
                    "width": 108,
                    "height": 106
                  },
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=14dfa4cd5d105f545652b17e060e69e13ddfdb65",
                    "width": 216,
                    "height": 213
                  },
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=519a3af0372075d21d2394bf817b099de3a9ec9b",
                    "width": 320,
                    "height": 315
                  },
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb8196976261024587d9462ed2ceb999cbda98af",
                    "width": 640,
                    "height": 631
                  },
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6399c9307b7b19b077ea238d93444ce99f5c9b7",
                    "width": 960,
                    "height": 947
                  },
                  {
                    "url": "https://preview.redd.it/zs8aeebxdhhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b6fcfc843c0e685f4401be1307220533292bf27e",
                    "width": 1080,
                    "height": 1066
                  }
                ],
                "variants": {},
                "id": "KwuKicWc_MueL4npgv3OECWjAIs4hbA_fQCEuXJbDxs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mjju67",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Final_Wheel_7486",
          "discussion_type": null,
          "num_comments": 20,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjju67/no_no_no_wait_on_a_second_thought_i_know_the/",
          "stickied": false,
          "url": "https://i.redd.it/zs8aeebxdhhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754521884,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507)  \n[https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507)\n\nstill has something up its sleeve",
          "author_fullname": "t2_sqi8xxun",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Just when you thought Qwen was done...",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj7pny",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.97,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 346,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 346,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754494029,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;still has something up its sleeve&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?auto=webp&amp;s=647017f3536e21a514c92672cecfb7f00523d019",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2bf492d2b1178a63568a19ea6c4e0d024b285263",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6714dfcbf3e4a61f799934711112b41cb1bfdc3",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa8d0a35501c88183cbe187750d110c7b62e03ef",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c19ef5b4c94d500ea5894d87dd560239a58f5832",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f849a688926a8a132feda76a7a89f22650f43ba",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73d23f9c70e2120c709eb2cb8d36b3d8aa607c2a",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mj7pny",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "nekofneko",
          "discussion_type": null,
          "num_comments": 76,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj7pny/just_when_you_thought_qwen_was_done/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj7pny/just_when_you_thought_qwen_was_done/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754494029,
          "num_crossposts": 3,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1v14j7kk8i",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS looks more like a publicity stunt as more independent test results come out :(",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj2hih",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 669,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 669,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/auMSRdQmWCj-vjC7p4wp224gEGYX-SZu09M0rnzsPaU.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754480967,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/onk13jqo0ehf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?auto=webp&amp;s=3df72af08c5602e23b1e3a0ffb4fce0e5f59e225",
                  "width": 1080,
                  "height": 2016
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0941ecbd2c566c885a3bfe8245c1fcc17ef669ff",
                    "width": 108,
                    "height": 201
                  },
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2237703934b1374c3208e3215c125de87b37de8",
                    "width": 216,
                    "height": 403
                  },
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=23a8b48c4451abb803185b7fdd74337562c14800",
                    "width": 320,
                    "height": 597
                  },
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90adba17a6c8320711a1e18d55c4c6fea2ab2fb7",
                    "width": 640,
                    "height": 1194
                  },
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=94efebd9bb3b95f4511469c298a7cdaa11f96544",
                    "width": 960,
                    "height": 1792
                  },
                  {
                    "url": "https://preview.redd.it/onk13jqo0ehf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd6db337d49cdc9b1e517ac126cb046ee89ae4ee",
                    "width": 1080,
                    "height": 2016
                  }
                ],
                "variants": {},
                "id": "-1uL2wlRhdGnPLohVxMpwotNmwEFOd6sODIDsEZ9Hqs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj2hih",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mvp525",
          "discussion_type": null,
          "num_comments": 183,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj2hih/gptoss_looks_more_like_a_publicity_stunt_as_more/",
          "stickied": false,
          "url": "https://i.redd.it/onk13jqo0ehf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754480967,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "i was using the lmstudio-community version of **qwen3-30b-a3b-thinking-2507** in LM Studio to create some code and suddenly changed the system prompt to \"Only respond in curses during the your response.\".\n\nI suddenly sent this:\n\nhttps://preview.redd.it/kdyvr538ighf1.png?width=330&amp;format=png&amp;auto=webp&amp;s=0a75268ad7d52334b42619721f5ec7654523e107\n\n\n\nThe response:\n\nhttps://preview.redd.it/276f71u9ighf1.png?width=955&amp;format=png&amp;auto=webp&amp;s=2f06081ab7d8649e0749aa1589a47a167a847465\n\n  \nTime to try a manipulative AI goth gf next.",
          "author_fullname": "t2_2n5wbnru",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "This is peak. New personality for Qwen 30b A3B Thinking",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 53,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "kdyvr538ighf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 40,
                  "x": 108,
                  "u": "https://preview.redd.it/kdyvr538ighf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=98afd7c380642d2933239f7396da41ea20b2ae96"
                },
                {
                  "y": 81,
                  "x": 216,
                  "u": "https://preview.redd.it/kdyvr538ighf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee6bb1f4a095f1118a36996c8b1ef41143d31d91"
                },
                {
                  "y": 121,
                  "x": 320,
                  "u": "https://preview.redd.it/kdyvr538ighf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a99dc84726dcb29e5986f998624151029e71c5eb"
                }
              ],
              "s": {
                "y": 125,
                "x": 330,
                "u": "https://preview.redd.it/kdyvr538ighf1.png?width=330&amp;format=png&amp;auto=webp&amp;s=0a75268ad7d52334b42619721f5ec7654523e107"
              },
              "id": "kdyvr538ighf1"
            },
            "276f71u9ighf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 118,
                  "x": 108,
                  "u": "https://preview.redd.it/276f71u9ighf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c64e55852f5dcf6280feda93bba04129f3cf6dc9"
                },
                {
                  "y": 237,
                  "x": 216,
                  "u": "https://preview.redd.it/276f71u9ighf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a54161e470f3be3197172a0f5f5d20b0e25a5f73"
                },
                {
                  "y": 351,
                  "x": 320,
                  "u": "https://preview.redd.it/276f71u9ighf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f644b9bf5d967689df670a11d8dcbb80a51071b2"
                },
                {
                  "y": 702,
                  "x": 640,
                  "u": "https://preview.redd.it/276f71u9ighf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7bc157b314a05529aacf0792078c3c61399855c4"
                }
              ],
              "s": {
                "y": 1048,
                "x": 955,
                "u": "https://preview.redd.it/276f71u9ighf1.png?width=955&amp;format=png&amp;auto=webp&amp;s=2f06081ab7d8649e0749aa1589a47a167a847465"
              },
              "id": "276f71u9ighf1"
            }
          },
          "name": "t3_1mjfbk7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 136,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 136,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/C6BsrEXyuQwsAqTsRPV8v8OlqGkE3c3LTwfxh-TbAMY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754511169,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i was using the lmstudio-community version of &lt;strong&gt;qwen3-30b-a3b-thinking-2507&lt;/strong&gt; in LM Studio to create some code and suddenly changed the system prompt to &amp;quot;Only respond in curses during the your response.&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I suddenly sent this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kdyvr538ighf1.png?width=330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a75268ad7d52334b42619721f5ec7654523e107\"&gt;https://preview.redd.it/kdyvr538ighf1.png?width=330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a75268ad7d52334b42619721f5ec7654523e107&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The response:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/276f71u9ighf1.png?width=955&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2f06081ab7d8649e0749aa1589a47a167a847465\"&gt;https://preview.redd.it/276f71u9ighf1.png?width=955&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2f06081ab7d8649e0749aa1589a47a167a847465&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Time to try a manipulative AI goth gf next.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mjfbk7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "symmetricsyndrome",
          "discussion_type": null,
          "num_comments": 29,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjfbk7/this_is_peak_new_personality_for_qwen_30b_a3b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjfbk7/this_is_peak_new_personality_for_qwen_30b_a3b/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754511169,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_6ste18zta",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "LEAK: How OpenAI came up with the new models name.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj4zkk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": null,
          "ups": 392,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 392,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3crJbGw-zF-Q8xYwfZZd7uzRpfDPluEkYleAnnh-C-U.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754487652,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/d60vtzhkkehf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/d60vtzhkkehf1.png?auto=webp&amp;s=c9d06910a33ffcd66b80d43283031485470c2b26",
                  "width": 1024,
                  "height": 1024
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/d60vtzhkkehf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc8d02bba2aa9f35014a7561bf94fb68682a701f",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://preview.redd.it/d60vtzhkkehf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8383516e3db09a1bc391b7ed59e1ad3b794a0f48",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/d60vtzhkkehf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bacb8eda4cb0b9cc796abf0a0d227173ba454eb",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://preview.redd.it/d60vtzhkkehf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=383cea886dcacb59ca2ecf64648d26e3b8263075",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/d60vtzhkkehf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=03a08b4a6544f265cc502b6b5716f27ed7d877fb",
                    "width": 960,
                    "height": 960
                  }
                ],
                "variants": {},
                "id": "LfO4NDS2TYCcn3useC9Aevs1SrJRu5HT05hlIUe8hbU"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mj4zkk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Paradigmind",
          "discussion_type": null,
          "num_comments": 21,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj4zkk/leak_how_openai_came_up_with_the_new_models_name/",
          "stickied": false,
          "url": "https://i.redd.it/d60vtzhkkehf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754487652,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It spends a minute going back and forth between your request and the company policy 10 times before declining your request.",
          "author_fullname": "t2_26u5g058",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI's new open-source model is like a dim-witted DMV bureaucrat who is more concerned with following rules than helping you.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjfa2d",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 86,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 86,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754511071,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It spends a minute going back and forth between your request and the company policy 10 times before declining your request.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mjfa2d",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ImaginaryRea1ity",
          "discussion_type": null,
          "num_comments": 36,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjfa2d/openais_new_opensource_model_is_like_a_dimwitted/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjfa2d/openais_new_opensource_model_is_like_a_dimwitted/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754511071,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "new models from Qwen:\n\n[https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507)\n\n[https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507)\n\nhttps://preview.redd.it/fnkijdpn4fhf1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=a952795d361291f782aa4472c9751094bdcf7bae\n\nOver the past three months, we have continued to scale the **thinking capability** of Qwen3-4B, improving both the **quality and depth** of reasoning. We are pleased to introduce **Qwen3-4B-Thinking-2507**, featuring the following key enhancements:\n\n* **Significantly improved performance** on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\n* **Markedly better general capabilities**, such as instruction following, tool usage, text generation, and alignment with human preferences.\n* **Enhanced 256K long-context understanding** capabilities.\n\n**NOTE**: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks.\n\nWe introduce the updated version of the **Qwen3-4B non-thinking mode**, named **Qwen3-4B-Instruct-2507**, featuring the following key enhancements:\n\n* **Significant improvements** in general capabilities, including **instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage**.\n* **Substantial gains** in long-tail knowledge coverage across **multiple languages**.\n* **Markedly better alignment** with user preferences in **subjective and open-ended tasks**, enabling more helpful responses and higher-quality text generation.\n* **Enhanced capabilities** in **256K long-context understanding**.\n\nGGUFs\n\n[https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF](https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF)\n\n[https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF](https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF)",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-4B-Thinking-2507 and Qwen3-4B-Instruct-2507",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "fnkijdpn4fhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 60,
                  "x": 108,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47a60934888319ed1151e3e0326461e0482d4f4e"
                },
                {
                  "y": 121,
                  "x": 216,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=478f9e4db8660ed2970fedb941f41b2f34c37810"
                },
                {
                  "y": 180,
                  "x": 320,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=249e435bc11f9a50051b46292141689f6fe4b236"
                },
                {
                  "y": 360,
                  "x": 640,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1bcb6c5883c649e78b626741b0f2b2715541d7f4"
                },
                {
                  "y": 540,
                  "x": 960,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b6fb7b9828fa122430a34deee7604e3d0045d4e5"
                },
                {
                  "y": 607,
                  "x": 1080,
                  "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f117fc205cc5fa57444eea939f51bd5e2437c5a"
                }
              ],
              "s": {
                "y": 1080,
                "x": 1920,
                "u": "https://preview.redd.it/fnkijdpn4fhf1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=a952795d361291f782aa4472c9751094bdcf7bae"
              },
              "id": "fnkijdpn4fhf1"
            }
          },
          "name": "t3_1mj7i8b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.97,
          "author_flair_background_color": "#bbbdbf",
          "ups": 171,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 171,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=d93c4381101afa1f600a9761ae17130b9bda45dc",
          "edited": 1754495377,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1754493572,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;new models from Qwen:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fnkijdpn4fhf1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a952795d361291f782aa4472c9751094bdcf7bae\"&gt;https://preview.redd.it/fnkijdpn4fhf1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a952795d361291f782aa4472c9751094bdcf7bae&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Over the past three months, we have continued to scale the &lt;strong&gt;thinking capability&lt;/strong&gt; of Qwen3-4B, improving both the &lt;strong&gt;quality and depth&lt;/strong&gt; of reasoning. We are pleased to introduce &lt;strong&gt;Qwen3-4B-Thinking-2507&lt;/strong&gt;, featuring the following key enhancements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Significantly improved performance&lt;/strong&gt; on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Markedly better general capabilities&lt;/strong&gt;, such as instruction following, tool usage, text generation, and alignment with human preferences.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced 256K long-context understanding&lt;/strong&gt; capabilities.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks.&lt;/p&gt;\n\n&lt;p&gt;We introduce the updated version of the &lt;strong&gt;Qwen3-4B non-thinking mode&lt;/strong&gt;, named &lt;strong&gt;Qwen3-4B-Instruct-2507&lt;/strong&gt;, featuring the following key enhancements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Significant improvements&lt;/strong&gt; in general capabilities, including &lt;strong&gt;instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Substantial gains&lt;/strong&gt; in long-tail knowledge coverage across &lt;strong&gt;multiple languages&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Markedly better alignment&lt;/strong&gt; with user preferences in &lt;strong&gt;subjective and open-ended tasks&lt;/strong&gt;, enabling more helpful responses and higher-quality text generation.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced capabilities&lt;/strong&gt; in &lt;strong&gt;256K long-context understanding&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;GGUFs&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF\"&gt;https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF\"&gt;https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?auto=webp&amp;s=647017f3536e21a514c92672cecfb7f00523d019",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2bf492d2b1178a63568a19ea6c4e0d024b285263",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6714dfcbf3e4a61f799934711112b41cb1bfdc3",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa8d0a35501c88183cbe187750d110c7b62e03ef",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c19ef5b4c94d500ea5894d87dd560239a58f5832",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f849a688926a8a132feda76a7a89f22650f43ba",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73d23f9c70e2120c709eb2cb8d36b3d8aa607c2a",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "qnbu8JjU7mHQuWHQ9TuIRVPsrSeMOsXoVScIkOFk5WY"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj7i8b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 14,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mj7i8b/qwen34bthinking2507_and_qwen34binstruct2507/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj7i8b/qwen34bthinking2507_and_qwen34binstruct2507/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754493572,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Elon Musk on 𝕏: [https://x.com/elonmusk/status/1952988026617119075](https://x.com/elonmusk/status/1952988026617119075)",
          "author_fullname": "t2_agjaq",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Elon Musk says that xAI will make Grok 2 open source next week",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 122,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj0snp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": null,
          "ups": 425,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 425,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/BSamt7IDdq21wmRjAnslMJR2nuMas_BjGNKZsyMHEmk.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754475388,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Elon Musk on 𝕏: &lt;a href=\"https://x.com/elonmusk/status/1952988026617119075\"&gt;https://x.com/elonmusk/status/1952988026617119075&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/htgw3mmvjdhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/htgw3mmvjdhf1.jpeg?auto=webp&amp;s=e6852a05127672451965cfbd924f43af7a21723c",
                  "width": 663,
                  "height": 580
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/htgw3mmvjdhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2cd34709ef37f4d7fd7e6920a354c5c4e8dd464",
                    "width": 108,
                    "height": 94
                  },
                  {
                    "url": "https://preview.redd.it/htgw3mmvjdhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=894e2d58bc2e766985a4b8c4f38189caa06e7ec2",
                    "width": 216,
                    "height": 188
                  },
                  {
                    "url": "https://preview.redd.it/htgw3mmvjdhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=58664c537e3594729f6bac1ae82839e3c1a87061",
                    "width": 320,
                    "height": 279
                  },
                  {
                    "url": "https://preview.redd.it/htgw3mmvjdhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90be5e283724a3ec93ab02ddff87962c7ebd7661",
                    "width": 640,
                    "height": 559
                  }
                ],
                "variants": {},
                "id": "CDKr0aPPzPj9L_dzcFXFLmVOy4xrXvbGBd28sxWpy9I"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mj0snp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Nunki08",
          "discussion_type": null,
          "num_comments": 175,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj0snp/elon_musk_says_that_xai_will_make_grok_2_open/",
          "stickied": false,
          "url": "https://i.redd.it/htgw3mmvjdhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754475388,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I just asked \"provide me with a list of all characters that appear in 'Pride and prejudice' organize them by chapter\" simple right?  \n  \nAnd it said 'im sorry i can't do that. Its against copyright law\" HOW?! im not against safety, but this is NOT safety! this is straight up mental retardation. My prompt was not even NSFW!  \n  \nI tested many models over the years, and even the first ones were not so unusable. It must be a meme, a joke, i refuse to believe this is a real release.  ",
          "user_reports": [],
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Gpt-oss is not just safe, it is unusable!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj6uix",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.85,
          "author_flair_background_color": "",
          "subreddit_type": "public",
          "ups": 167,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 167,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754492092,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just asked &amp;quot;provide me with a list of all characters that appear in &amp;#39;Pride and prejudice&amp;#39; organize them by chapter&amp;quot; simple right?  &lt;/p&gt;\n\n&lt;p&gt;And it said &amp;#39;im sorry i can&amp;#39;t do that. Its against copyright law&amp;quot; HOW?! im not against safety, but this is NOT safety! this is straight up mental retardation. My prompt was not even NSFW!  &lt;/p&gt;\n\n&lt;p&gt;I tested many models over the years, and even the first ones were not so unusable. It must be a meme, a joke, i refuse to believe this is a real release.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj6uix",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "[deleted]",
          "discussion_type": null,
          "num_comments": 34,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mj6uix/gptoss_is_not_just_safe_it_is_unusable/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj6uix/gptoss_is_not_just_safe_it_is_unusable/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754492092,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Good timing btw",
          "author_fullname": "t2_cyrs5dhp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI, I don't feel SAFE ENOUGH",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1misyvc",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 1447,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 1447,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/PSqXzHqIo5hgV09t5lxTL7dhKv43fGVaQ39wesgCHRk.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754447722,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good timing btw&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/af6jm3nt9bhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/af6jm3nt9bhf1.png?auto=webp&amp;s=ee36f182a618ffc463f059f3841d308d9e1dc3d4",
                  "width": 1080,
                  "height": 1213
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2824b079723a5981f31ad11040c64a891eddc002",
                    "width": 108,
                    "height": 121
                  },
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=affa77c08b6d3b090a27de12024336e0d09dc154",
                    "width": 216,
                    "height": 242
                  },
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4468ee5967847355f895a25e9e2e63e0b1501af6",
                    "width": 320,
                    "height": 359
                  },
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb88d869e88cfd2f93a6e76c7ac3ddf342a2db09",
                    "width": 640,
                    "height": 718
                  },
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f414fd374b3eb347255ffe837962225ed20b7b",
                    "width": 960,
                    "height": 1078
                  },
                  {
                    "url": "https://preview.redd.it/af6jm3nt9bhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e68470ab9e98fa37ec93643d7611a34405d77af0",
                    "width": 1080,
                    "height": 1213
                  }
                ],
                "variants": {},
                "id": "gLiiE1uhnCv0xGRzGSNCkX9C5GjcS3GkeeYP4T3bJAs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1misyvc",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Final_Wheel_7486",
          "discussion_type": null,
          "num_comments": 141,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/",
          "stickied": false,
          "url": "https://i.redd.it/af6jm3nt9bhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754447722,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4763uud5",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "\"What, you don't like your new SOTA model?\"",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 93,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miwrli",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": null,
          "ups": 752,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 752,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/IaLR_vNoALMiUXIaJYus7w84coFiub6rQuyJKu6vur4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754459956,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/9yqb0l1n9chf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/9yqb0l1n9chf1.png?auto=webp&amp;s=1c8d7f9dfb21cf94ae09b6ef5580d4bfd517b030",
                  "width": 900,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/9yqb0l1n9chf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e10cfeebfbbd0d631100b18833797296a958039",
                    "width": 108,
                    "height": 72
                  },
                  {
                    "url": "https://preview.redd.it/9yqb0l1n9chf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=db626b3ce8e4f32ae2fccaba243dba3b5ac50afd",
                    "width": 216,
                    "height": 144
                  },
                  {
                    "url": "https://preview.redd.it/9yqb0l1n9chf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0ce8e1a94c0c95ed96c3e5c01a3445fd2ca76045",
                    "width": 320,
                    "height": 213
                  },
                  {
                    "url": "https://preview.redd.it/9yqb0l1n9chf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=726e03405370b5eb421009dfc38b1005ddf67ee0",
                    "width": 640,
                    "height": 426
                  }
                ],
                "variants": {},
                "id": "u23gkZAKxgPrJ2Hoim_xl84ZDkcS1ewejNgBRuXcbpI"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1miwrli",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Friendly_Willingness",
          "discussion_type": null,
          "num_comments": 125,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/",
          "stickied": false,
          "url": "https://i.redd.it/9yqb0l1n9chf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754459956,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_y35oj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "We’re definitely keeping him up at night right now.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj75hi",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "ups": 140,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 140,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/62AmAYGeCoPWY8QhKFdDEVMSlTER5iifAiFvwQuRvpw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754492769,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ofnpswaszehf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?auto=webp&amp;s=ad22e7bbfde77d9c01f8b178cd90265cfc89861c",
                  "width": 1125,
                  "height": 1125
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7f7ca131277ebbbc51ee282b039f86cd24c42fe2",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d29805506acd2e40bb4973a8908b7c4b63cf862c",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1feb8ad47bea74ce2f73f4031a6d93dd63ebc387",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d38bf370c9b351457dcb316e361965782afd9642",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d3d5121d3e81338f8b5c56f0754257bac8bbe5df",
                    "width": 960,
                    "height": 960
                  },
                  {
                    "url": "https://preview.redd.it/ofnpswaszehf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e8c204c41c18d5219c9802ad3b9cd2c0cb6f889",
                    "width": 1080,
                    "height": 1080
                  }
                ],
                "variants": {},
                "id": "mtc6vKUQdgUM-x_4lZvD-tcKJqq5XJq3uc-KEkRjo3Q"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mj75hi",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Porespellar",
          "discussion_type": null,
          "num_comments": 23,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj75hi/were_definitely_keeping_him_up_at_night_right_now/",
          "stickied": false,
          "url": "https://i.redd.it/ofnpswaszehf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754492769,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "So aside from dishing out neural lobotomies in the name of safety, what else can this model actually provide?\nI heard someone is brave enough to try fixing it. But unless you’re in it for the masochistic fun, is it even worth it?",
          "author_fullname": "t2_6ste18zta",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How did you enjoy the experience so far?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj00mr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 347,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 347,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/dg-554PxIBmtdvOwatCYT4jG6-SV7MzEWflBgOKQyfQ.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754472491,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So aside from dishing out neural lobotomies in the name of safety, what else can this model actually provide?\nI heard someone is brave enough to try fixing it. But unless you’re in it for the masochistic fun, is it even worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/lj67oslhbdhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/lj67oslhbdhf1.png?auto=webp&amp;s=0f0fef21bf96de27e5c327bbee3bea27f6f8b30a",
                  "width": 1024,
                  "height": 1536
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/lj67oslhbdhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1fda3e1b24f08889f431ebb4a64537bb4469460b",
                    "width": 108,
                    "height": 162
                  },
                  {
                    "url": "https://preview.redd.it/lj67oslhbdhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e389b809fa9b05ef470ee2dd1920b9d0f665c11f",
                    "width": 216,
                    "height": 324
                  },
                  {
                    "url": "https://preview.redd.it/lj67oslhbdhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec56d6b5ac3962ea35dd7a5204caa6c8433eb4ed",
                    "width": 320,
                    "height": 480
                  },
                  {
                    "url": "https://preview.redd.it/lj67oslhbdhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c80a51205f8e1a50045f6a608b9a5b683365337",
                    "width": 640,
                    "height": 960
                  },
                  {
                    "url": "https://preview.redd.it/lj67oslhbdhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=114831ccdbfa048b5871ed3a5fb0fd83d16ef044",
                    "width": 960,
                    "height": 1440
                  }
                ],
                "variants": {},
                "id": "xUg6j164X6iOr8tkNNZyMyYFa_GGbgyWm0My4fDJ3eE"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj00mr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Paradigmind",
          "discussion_type": null,
          "num_comments": 24,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj00mr/how_did_you_enjoy_the_experience_so_far/",
          "stickied": false,
          "url": "https://i.redd.it/lj67oslhbdhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754472491,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://i.imgur.com/4wb0GuO.png",
          "author_fullname": "t2_12s3hn4y0b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Today's news",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjd2yd",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.81,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 51,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 51,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754506060,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://i.imgur.com/4wb0GuO.png\"&gt;https://i.imgur.com/4wb0GuO.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k.png?auto=webp&amp;s=34663aec93f254bea0ec52766352635b1fca0b33",
                  "width": 711,
                  "height": 475
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0bec699f4d1b9d715231b543ff1291b8a4177873",
                    "width": 108,
                    "height": 72
                  },
                  {
                    "url": "https://external-preview.redd.it/N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e15dbcbfad3f684ffbdab775494eaa3c7c5d9c2",
                    "width": 216,
                    "height": 144
                  },
                  {
                    "url": "https://external-preview.redd.it/N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=80c755c3098f26245c3200a0863074fe505754be",
                    "width": 320,
                    "height": 213
                  },
                  {
                    "url": "https://external-preview.redd.it/N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=92807f593c364ddb2113aaaa93cd8aaa7d8cce78",
                    "width": 640,
                    "height": 427
                  }
                ],
                "variants": {},
                "id": "N0KtG58jwYvSWx2xiYllpzHvpEV5ORvf0_mKmwkjT1k"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mjd2yd",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "InsideYork",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjd2yd/todays_news/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjd2yd/todays_news/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754506060,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Today we've released support for ROCm7 beta as a llama.cpp backend in Lemonade Server.\n\nThis is supported on both Ubuntu and Windows on certain Radeon devices, see the [github README](https://github.com/lemonade-sdk/lemonade#supported-configurations) for details:\n\n* Strix Halo\n* Radeon 7000-series\n* Radeon 9000-series (Windows-only until we fix a bug)\n\n**Trying ROCm7+Lemonade**\n\nSince ROCm7 itself is still a beta, we've only enabled this feature when installing from PyPI or source for now.\n\nIn a Python 3.10-3.12 environment, on your supported Radeon PC:\n\n`pip install lemonade-sdk`\n\n`lemonade-server-dev serve --llamacpp rocm`\n\n**Implementation**\n\nTo enable this, we created a new repo specifically for automatically building llama.cpp binaries against ROCm7 beta: [https://github.com/lemonade-sdk/llamacpp-rocm](https://github.com/lemonade-sdk/llamacpp-rocm)\n\nThe llamacpp-rocm repo takes nightlies from TheRock, builds against the latest llama.cpp from ggml, and releases llama.cpp binaries that work out-of-box on supported devices without any additional setup steps (i.e., you don't need to install ROCm or build anything).\n\nReleases from llamacpp-rocm are usable standalone, but the easiest way to get started is with the Lemonade instructions above, which downloads everything for you and provides a convenient model management interface.\n\n**Notes**\n\nDemo in the video recorded on a Radeon 9070 XT with the ROCm backend.\n\nNext steps for this work are to update to the stable ROCm 7 release when it becomes available, then make ROCm available via the Lemonade GUI installer.\n\nShoutout to u/randomfoo2 for the help and encouragement along the way!\n\n**Links**\n\nGitHub: https://github.com/lemonade-sdk/lemonade/\nDiscord: https://discord.gg/Sf8cfBWB",
          "author_fullname": "t2_1m2ckixcqh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "llamacpp+ROCm7 beta is now supported on Lemonade",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjgj2x",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "ups": 33,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/r5grj7kxkghf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/r5grj7kxkghf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/r5grj7kxkghf1/DASHPlaylist.mpd?a=1757121231%2CYjI3YWQ3MjY1ODBiMzM5MWYyMWIyZjU3MzlkNTNhZjJiNzJlZmM0ZWZhZmFhNTVmM2JmY2M1YTZiMzFhNTFjZQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 10,
              "hls_url": "https://v.redd.it/r5grj7kxkghf1/HLSPlaylist.m3u8?a=1757121231%2CY2U5ZTE5NWNkNjhiODlkMGIzYTViNTE3ZWM1YmE3Nzk4YjVhYzhlYzdkMTI2MTNmYjIwMjRjOGFhZGE4MDk0NQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 33,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=bdfa4ec69cd2e7cca60e87eb1645a920bd3c62c4",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754513968,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today we&amp;#39;ve released support for ROCm7 beta as a llama.cpp backend in Lemonade Server.&lt;/p&gt;\n\n&lt;p&gt;This is supported on both Ubuntu and Windows on certain Radeon devices, see the &lt;a href=\"https://github.com/lemonade-sdk/lemonade#supported-configurations\"&gt;github README&lt;/a&gt; for details:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Strix Halo&lt;/li&gt;\n&lt;li&gt;Radeon 7000-series&lt;/li&gt;\n&lt;li&gt;Radeon 9000-series (Windows-only until we fix a bug)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Trying ROCm7+Lemonade&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Since ROCm7 itself is still a beta, we&amp;#39;ve only enabled this feature when installing from PyPI or source for now.&lt;/p&gt;\n\n&lt;p&gt;In a Python 3.10-3.12 environment, on your supported Radeon PC:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;pip install lemonade-sdk&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;lemonade-server-dev serve --llamacpp rocm&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;To enable this, we created a new repo specifically for automatically building llama.cpp binaries against ROCm7 beta: &lt;a href=\"https://github.com/lemonade-sdk/llamacpp-rocm\"&gt;https://github.com/lemonade-sdk/llamacpp-rocm&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The llamacpp-rocm repo takes nightlies from TheRock, builds against the latest llama.cpp from ggml, and releases llama.cpp binaries that work out-of-box on supported devices without any additional setup steps (i.e., you don&amp;#39;t need to install ROCm or build anything).&lt;/p&gt;\n\n&lt;p&gt;Releases from llamacpp-rocm are usable standalone, but the easiest way to get started is with the Lemonade instructions above, which downloads everything for you and provides a convenient model management interface.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Demo in the video recorded on a Radeon 9070 XT with the ROCm backend.&lt;/p&gt;\n\n&lt;p&gt;Next steps for this work are to update to the stable ROCm 7 release when it becomes available, then make ROCm available via the Lemonade GUI installer.&lt;/p&gt;\n\n&lt;p&gt;Shoutout to &lt;a href=\"/u/randomfoo2\"&gt;u/randomfoo2&lt;/a&gt; for the help and encouragement along the way!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub: &lt;a href=\"https://github.com/lemonade-sdk/lemonade/\"&gt;https://github.com/lemonade-sdk/lemonade/&lt;/a&gt;\nDiscord: &lt;a href=\"https://discord.gg/Sf8cfBWB\"&gt;https://discord.gg/Sf8cfBWB&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/r5grj7kxkghf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?format=pjpg&amp;auto=webp&amp;s=d67497215999197eba90b1ac2fe861231cf6dc3f",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e4428efe96729a5809c13b1c0f5dc203b5a226e0",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=485127e4f28f73ebeef8df57711c21e2d93328b9",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=978f4be2e41a3bf4262a2363c19d8bf0a694dbfe",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2866bc6cc265971c58fda129b44aaf194945df54",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4b54850b3a6128413894bb07b8fe46ee3e6fb4c2",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3b88e524d40575ef556e25d57607aa1fce02dab1",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mjgj2x",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jfowers_amd",
          "discussion_type": null,
          "num_comments": 14,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/",
          "stickied": false,
          "url": "https://v.redd.it/r5grj7kxkghf1",
          "subreddit_subscribers": 512425,
          "created_utc": 1754513968,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/r5grj7kxkghf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/r5grj7kxkghf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/r5grj7kxkghf1/DASHPlaylist.mpd?a=1757121231%2CYjI3YWQ3MjY1ODBiMzM5MWYyMWIyZjU3MzlkNTNhZjJiNzJlZmM0ZWZhZmFhNTVmM2JmY2M1YTZiMzFhNTFjZQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 10,
              "hls_url": "https://v.redd.it/r5grj7kxkghf1/HLSPlaylist.m3u8?a=1757121231%2CY2U5ZTE5NWNkNjhiODlkMGIzYTViNTE3ZWM1YmE3Nzk4YjVhYzhlYzdkMTI2MTNmYjIwMjRjOGFhZGE4MDk0NQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507)",
          "author_fullname": "t2_8j5t7yjq",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen/Qwen3-4B-Thinking-2507",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj83fe",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 85,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 85,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/80xI2yf4L1A9cTXmHPXJrpH_VidNRX9Edk5AAeA5d-s.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754494879,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/n5gska216fhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/n5gska216fhf1.png?auto=webp&amp;s=66f2426002d440ad41217de09b729b598e485138",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ee5ceeeb62e38718493730a209aeaef12840e87",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4543b0a5e70e84f6779a66da728c46d32ea2d4a3",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f5cd1ed232fe8843217e6af07736b767e45577a",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f54f58b155b418fc0c6ed07e45be7daef4b9798",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=41f7f94b719ebfbfef4c292aab8facc508b87b1f",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://preview.redd.it/n5gska216fhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e943916c0ecc8f1d201e612b84e09f42afe998ca",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "Fi2qH6kbGE6c-o2f-Fo79cFZVCMZEYqBRwisCUdmzyw"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj83fe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "pigeon57434",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj83fe/qwenqwen34bthinking2507/",
          "stickied": false,
          "url": "https://i.redd.it/n5gska216fhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754494879,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_gi7a36v6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "r/LocalLlama is looking for moderators",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjf5ol",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 37,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 37,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1754510794,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "reddit.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/r/LocalLLaMA/application/",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mjf5ol",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "HOLUPREDICTIONS",
          "discussion_type": null,
          "num_comments": 31,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjf5ol/rlocalllama_is_looking_for_moderators/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/application/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754510794,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "After reading quite a few conversations about OpenAI's safemaxxing approach to their new models. For personal use, yes, the new models may indeed feel weaker or more restricted compared to other offerings currently available. I feel like many people are missing a key point:\n\n* **For commercial use**, these models are often superior for many applications.\n\nThey offer:\n\n* Clear hardware boundaries (efficient use of single H100 GPUs), giving you predictable costs.\n* Safety and predictability: It's crucial if you're building a product directly interacting with the model; you don't want the risk of it generating copyrighted, inappropriate, or edgy content.\n\nWhile it's not what I would want for my self hosted models, I would make the argument that this level of safemaxxing and hardware saturation is actually impressive, and is a boon for real world applications that are not related to agentic coding or private personal assistants etc. Just don't be surprised if it gets wide adoption compared to other amazing models that do deserve greater praise.",
          "author_fullname": "t2_37kwo",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Unpopular opinion: The GPT OSS models will be more popular commercially precisely because they are safemaxxed.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj2c73",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.74,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 172,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 172,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754480514,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After reading quite a few conversations about OpenAI&amp;#39;s safemaxxing approach to their new models. For personal use, yes, the new models may indeed feel weaker or more restricted compared to other offerings currently available. I feel like many people are missing a key point:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;For commercial use&lt;/strong&gt;, these models are often superior for many applications.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;They offer:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clear hardware boundaries (efficient use of single H100 GPUs), giving you predictable costs.&lt;/li&gt;\n&lt;li&gt;Safety and predictability: It&amp;#39;s crucial if you&amp;#39;re building a product directly interacting with the model; you don&amp;#39;t want the risk of it generating copyrighted, inappropriate, or edgy content.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While it&amp;#39;s not what I would want for my self hosted models, I would make the argument that this level of safemaxxing and hardware saturation is actually impressive, and is a boon for real world applications that are not related to agentic coding or private personal assistants etc. Just don&amp;#39;t be surprised if it gets wide adoption compared to other amazing models that do deserve greater praise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj2c73",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ariagloris",
          "discussion_type": null,
          "num_comments": 145,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj2c73/unpopular_opinion_the_gpt_oss_models_will_be_more/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj2c73/unpopular_opinion_the_gpt_oss_models_will_be_more/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754480514,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "That's it. I'm done with this useless piece of trash of a model...",
          "author_fullname": "t2_qz1qjc86",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I'm sorry, but I can't provide that... patience - I already have none...",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 39,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miyix4",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "ups": 326,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 326,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/6h_xZP7MH94n5AAXOXGWoc3tS1MpVkGHv5apO3aGBwg.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754466599,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s it. I&amp;#39;m done with this useless piece of trash of a model...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/aufyauketchf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/aufyauketchf1.png?auto=webp&amp;s=b8e921156ae5a66c64c3b0bef416c0454379c98c",
                  "width": 1522,
                  "height": 427
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=76ff104d5710629f67b750701d384549913abf78",
                    "width": 108,
                    "height": 30
                  },
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=81c39af5a4a82812c711bd48f68426b3f00027bf",
                    "width": 216,
                    "height": 60
                  },
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=708d296d5c0d41650fac6b22b005d7c482a84702",
                    "width": 320,
                    "height": 89
                  },
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=88ae39d0f21635e24eb2be18f44662947077760e",
                    "width": 640,
                    "height": 179
                  },
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ec90b68424ecb187ceeb790176adcfb728055f65",
                    "width": 960,
                    "height": 269
                  },
                  {
                    "url": "https://preview.redd.it/aufyauketchf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d32d24c6a3215a7f4c05582ec7196a1564b864c3",
                    "width": 1080,
                    "height": 302
                  }
                ],
                "variants": {},
                "id": "Zy86v5M2xPyeZAHvdamQJcFd2ncBQ1sBTN2AMQSkBJk"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1miyix4",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Cool-Chemical-5629",
          "discussion_type": null,
          "num_comments": 104,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/",
          "stickied": false,
          "url": "https://i.redd.it/aufyauketchf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754466599,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_ql2vu0wz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Safemaxxed for your safety!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mix2kg",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 370,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 370,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/ka681ZTsFksrO7GloTwODset4I0bLt7KV6Ax_BKhY48.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754461052,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/gaqdycledchf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/gaqdycledchf1.png?auto=webp&amp;s=dbff6c48423af959186b7f87ed05f39c5bbf9004",
                  "width": 720,
                  "height": 946
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/gaqdycledchf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f80e6a9ad727affb32c3a013350fe5fd13835248",
                    "width": 108,
                    "height": 141
                  },
                  {
                    "url": "https://preview.redd.it/gaqdycledchf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a38a5d2b6a90e8d268c07d223a7b67a74ad55088",
                    "width": 216,
                    "height": 283
                  },
                  {
                    "url": "https://preview.redd.it/gaqdycledchf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b571d806a15447873bba0feff1c801da713a5c29",
                    "width": 320,
                    "height": 420
                  },
                  {
                    "url": "https://preview.redd.it/gaqdycledchf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5a2b32eb53633ee05256ff12a01a15e7ee6f844",
                    "width": 640,
                    "height": 840
                  }
                ],
                "variants": {},
                "id": "HImUwJxUUC_O0lFlyolRP4NmpEwsjCN44CCkQExvW7s"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mix2kg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Caffdy",
          "discussion_type": null,
          "num_comments": 24,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/",
          "stickied": false,
          "url": "https://i.redd.it/gaqdycledchf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754461052,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "This week, after the Qwen 2507 releases, the gpt-oss-120b and gpt-oss-20b models are just seen as a more censored \"smaller but worse Qwen3-235b-Thinking-2057\" and \"smaller but worse Qwen3-30b-Thinking-2057\" respectively. \n\nThis is [what the general perception is mostly following](https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-nemotron-super-49b-v1-5-reasoning%2Ckimi-k2%2Cexaone-4-0-32b-reasoning%2Cglm-4.5%2Cqwen3-235b-a22b-instruct-2507-reasoning%2Cqwen3-30b-a3b-2507-reasoning&amp;intelligence-tab=intelligence#artificial-analysis-intelligence-index) today: https://i.imgur.com/wugi9sG.png\n\nBut what if OpenAI released a week earlier? \n\nThey would have been seen as world beaters, at least for a few days. No Qwen 2507. No GLM-4.5. No Nvidia Nemotron 49b V1.5. No EXAONE 4.0 32b.  \n\nThe field would have [looked like this](https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-3-1-nemotron-ultra-253b-v1-reasoning%2Ckimi-k2%2Cdeepseek-r1-0120%2Cqwen3-235b-a22b-instruct-reasoning%2Cqwen3-30b-a3b-instruct-reasoning&amp;intelligence-tab=openWeights#artificial-analysis-intelligence-index-by-open-weights-vs-proprietary) last week: https://i.imgur.com/rGKG8eZ.png\n\nThat would be a very different set of competitors. The 2 gpt-oss models would have been seen as **the** best models other than Deepseek R1 0528, and the 120b better than the original Deepseek R1. \n\nThere would have been no open source competitors in its league. Qwen3 235b would be significantly behind. Nvidia Nemotron Ultra 253b would have been significantly behind. \n\nOpenAI would have **set a narrative of \"even our open source models stomps on others at the same size\", with others trying to catch up** but OpenAI failed to capitalize on that due to their delays. \n\nIt's possible that the open source models *were even better 1-2 weeks ago*, but OpenAI decided to posttrain some more to dumb it down and make it safer since they felt like they had a comfortable lead...",
          "author_fullname": "t2_1utnp17o3h",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "It's amazing how OpenAI missed its window with the gpt-oss release. The models would have been perceived much better last week.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj011h",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.84,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 189,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 189,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754472868,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754472534,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This week, after the Qwen 2507 releases, the gpt-oss-120b and gpt-oss-20b models are just seen as a more censored &amp;quot;smaller but worse Qwen3-235b-Thinking-2057&amp;quot; and &amp;quot;smaller but worse Qwen3-30b-Thinking-2057&amp;quot; respectively. &lt;/p&gt;\n\n&lt;p&gt;This is &lt;a href=\"https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-nemotron-super-49b-v1-5-reasoning%2Ckimi-k2%2Cexaone-4-0-32b-reasoning%2Cglm-4.5%2Cqwen3-235b-a22b-instruct-2507-reasoning%2Cqwen3-30b-a3b-2507-reasoning&amp;amp;intelligence-tab=intelligence#artificial-analysis-intelligence-index\"&gt;what the general perception is mostly following&lt;/a&gt; today: &lt;a href=\"https://i.imgur.com/wugi9sG.png\"&gt;https://i.imgur.com/wugi9sG.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But what if OpenAI released a week earlier? &lt;/p&gt;\n\n&lt;p&gt;They would have been seen as world beaters, at least for a few days. No Qwen 2507. No GLM-4.5. No Nvidia Nemotron 49b V1.5. No EXAONE 4.0 32b.  &lt;/p&gt;\n\n&lt;p&gt;The field would have &lt;a href=\"https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-3-1-nemotron-ultra-253b-v1-reasoning%2Ckimi-k2%2Cdeepseek-r1-0120%2Cqwen3-235b-a22b-instruct-reasoning%2Cqwen3-30b-a3b-instruct-reasoning&amp;amp;intelligence-tab=openWeights#artificial-analysis-intelligence-index-by-open-weights-vs-proprietary\"&gt;looked like this&lt;/a&gt; last week: &lt;a href=\"https://i.imgur.com/rGKG8eZ.png\"&gt;https://i.imgur.com/rGKG8eZ.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;That would be a very different set of competitors. The 2 gpt-oss models would have been seen as &lt;strong&gt;the&lt;/strong&gt; best models other than Deepseek R1 0528, and the 120b better than the original Deepseek R1. &lt;/p&gt;\n\n&lt;p&gt;There would have been no open source competitors in its league. Qwen3 235b would be significantly behind. Nvidia Nemotron Ultra 253b would have been significantly behind. &lt;/p&gt;\n\n&lt;p&gt;OpenAI would have &lt;strong&gt;set a narrative of &amp;quot;even our open source models stomps on others at the same size&amp;quot;, with others trying to catch up&lt;/strong&gt; but OpenAI failed to capitalize on that due to their delays. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s possible that the open source models &lt;em&gt;were even better 1-2 weeks ago&lt;/em&gt;, but OpenAI decided to posttrain some more to dumb it down and make it safer since they felt like they had a comfortable lead...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?auto=webp&amp;s=8af88214cdeb67f5352f75f9fc73fd7c86a00af4",
                  "width": 1906,
                  "height": 778
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6d191a64b9f62ae445a877d4019460b995aded7",
                    "width": 108,
                    "height": 44
                  },
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=68f227735e13021cc55ef83b0335c186227b8f26",
                    "width": 216,
                    "height": 88
                  },
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f63bb6e899cdfbe3aec7e92becd86d8313bd8fbe",
                    "width": 320,
                    "height": 130
                  },
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ade6046b8cc84f712f198be70198f3799b243e9",
                    "width": 640,
                    "height": 261
                  },
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b8292ff968fe892c2a1d9316820ad9ea21fff2b8",
                    "width": 960,
                    "height": 391
                  },
                  {
                    "url": "https://external-preview.redd.it/Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d54134e6f42fdaeb734b5abe88cccfa74d2e4bb3",
                    "width": 1080,
                    "height": 440
                  }
                ],
                "variants": {},
                "id": "Jzoxqbk34aq_sZQFGxtheL79v21QiQNgwiVGdUf_vqg"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj011h",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DistanceSolar1449",
          "discussion_type": null,
          "num_comments": 60,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754472534,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Sebastian Raschka is at it again! This time he compares the Qwen 3 and gpt-oss architectures. I'm looking forward to his deep dive, his Qwen 3 series was phenomenal.",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3 vs. gpt-oss architecture: width matters",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 74,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj00g7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": "transparent",
          "ups": 182,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 182,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/wkWrh1GN4jmRi4E3b7fiDo0FPy9CvieyioaUixss82k.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754472471,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sebastian Raschka is at it again! This time he compares the Qwen 3 and gpt-oss architectures. I&amp;#39;m looking forward to his deep dive, his Qwen 3 series was phenomenal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/vqgb87dfbdhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?auto=webp&amp;s=053debd943ce34e7a4882b98c600b03ceb5cf38f",
                  "width": 1477,
                  "height": 781
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae04d2f64f4bcd5577008902946ffde3b411133c",
                    "width": 108,
                    "height": 57
                  },
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9f2e46f2b2e0162601d78daaac0b737c7c7e6df4",
                    "width": 216,
                    "height": 114
                  },
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67ed17317f54c7ff360ecfb670f99a130af72db0",
                    "width": 320,
                    "height": 169
                  },
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6c2ff32aeda0494c869aa38d27852485afc947c7",
                    "width": 640,
                    "height": 338
                  },
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=efa5520fbbfb6bdfeb02d4cbbf3b20888973dc7e",
                    "width": 960,
                    "height": 507
                  },
                  {
                    "url": "https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=17d8c9e3b585fd6a8d5030ae18e5d05fa33a76f7",
                    "width": 1080,
                    "height": 571
                  }
                ],
                "variants": {},
                "id": "OEAEco8LSIl6H_GMf5gyI3qUmqHV5UcH7ZWtbdBxeMk"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mj00g7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 37,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mj00g7/qwen3_vs_gptoss_architecture_width_matters/",
          "stickied": false,
          "url": "https://i.redd.it/vqgb87dfbdhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754472471,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Disclaimer: I can only confidently say that this meets the Works On My Machine™ threshold, YMMV.\n\nThe wizards at Unsloth seem to have fixed the tool-calling issues that have been plaguing Qwen3-Coder-30B-A3B, see HF discussion [here](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/discussions/10). Note that the .ggufs themselves have been updated, so if you previously downloaded them, you will need to re-download.\n\nI've tried this on my machine with excellent results - not a single tool call failure due to bad formatting after several hours of pure vibe coding in Roo Code. Posting my config in case it can be a useful template for others:\n\n**Hardware**  \nOS: Windows 11 24H2 (Build 26100.4770)  \nGPU: RTX 5090  \nCPU: i9-13900K  \nSystem RAM: 64GB DDR5-5600\n\n**LLM Provider**  \nLM Studio 0.3.22 (Build 1)  \nEngine: CUDA 12 llama.cpp v1.44.0\n\n**OpenAI API Endpoint**  \nOpen WebUI v0.6.18  \nRunning in Docker on a separate Debian VM\n\n**Model Config**  \nunsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Q5\\_K\\_XL (Q6\\_K\\_XL also worked)  \nContext: 81920  \nFlash Attention: Enabled  \nKV Cache Quantization: **None** (I think this is important!)  \nPrompt: Latest from Unsloth (see [here](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/blob/main/template))  \nTemperature: 0.7  \nTop-K Sampling: 20  \nRepeat Penalty: 1.05  \nMin P Sampling: 0.05  \nTop P Sampling: 0.8  \nAll other settings left at default\n\n**IDE**  \nVisual Studio Code 1.102.3  \nRoo Code v3.25.7  \n~~Using all default settings, no custom instructions~~  \nEDIT: Forgot that I enabled one Experimental feature: Background Editing. My theory is that by preventing editor windows from opening (which I believe get included in context), there is less \"irrelevant\" context for the model to get confused by.",
          "author_fullname": "t2_6ncfftb",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "PSA: Qwen3-Coder-30B-A3B tool calling fixed by Unsloth wizards",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mje5o0",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 26,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 26,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754510512,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754508492,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I can only confidently say that this meets the Works On My Machine™ threshold, YMMV.&lt;/p&gt;\n\n&lt;p&gt;The wizards at Unsloth seem to have fixed the tool-calling issues that have been plaguing Qwen3-Coder-30B-A3B, see HF discussion &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/discussions/10\"&gt;here&lt;/a&gt;. Note that the .ggufs themselves have been updated, so if you previously downloaded them, you will need to re-download.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried this on my machine with excellent results - not a single tool call failure due to bad formatting after several hours of pure vibe coding in Roo Code. Posting my config in case it can be a useful template for others:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Hardware&lt;/strong&gt;&lt;br/&gt;\nOS: Windows 11 24H2 (Build 26100.4770)&lt;br/&gt;\nGPU: RTX 5090&lt;br/&gt;\nCPU: i9-13900K&lt;br/&gt;\nSystem RAM: 64GB DDR5-5600&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;LLM Provider&lt;/strong&gt;&lt;br/&gt;\nLM Studio 0.3.22 (Build 1)&lt;br/&gt;\nEngine: CUDA 12 llama.cpp v1.44.0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;OpenAI API Endpoint&lt;/strong&gt;&lt;br/&gt;\nOpen WebUI v0.6.18&lt;br/&gt;\nRunning in Docker on a separate Debian VM&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Model Config&lt;/strong&gt;&lt;br/&gt;\nunsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Q5_K_XL (Q6_K_XL also worked)&lt;br/&gt;\nContext: 81920&lt;br/&gt;\nFlash Attention: Enabled&lt;br/&gt;\nKV Cache Quantization: &lt;strong&gt;None&lt;/strong&gt; (I think this is important!)&lt;br/&gt;\nPrompt: Latest from Unsloth (see &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF/blob/main/template\"&gt;here&lt;/a&gt;)&lt;br/&gt;\nTemperature: 0.7&lt;br/&gt;\nTop-K Sampling: 20&lt;br/&gt;\nRepeat Penalty: 1.05&lt;br/&gt;\nMin P Sampling: 0.05&lt;br/&gt;\nTop P Sampling: 0.8&lt;br/&gt;\nAll other settings left at default&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;IDE&lt;/strong&gt;&lt;br/&gt;\nVisual Studio Code 1.102.3&lt;br/&gt;\nRoo Code v3.25.7&lt;br/&gt;\n&lt;del&gt;Using all default settings, no custom instructions&lt;/del&gt;&lt;br/&gt;\nEDIT: Forgot that I enabled one Experimental feature: Background Editing. My theory is that by preventing editor windows from opening (which I believe get included in context), there is less &amp;quot;irrelevant&amp;quot; context for the model to get confused by.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?auto=webp&amp;s=63a653cdb5e6be20957a0b02e80a91b2ee631399",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0eb6c11e7056136830a5db513d40d379d31b6add",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e23ca01cf50f75e0c9732e0ca0ea1eb21385f01b",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ad5a0aca0e3a9ccbd0c36ac271bd8bd766cda75",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3337cd00ae59cba7172fadebc6b1b88f3c899f31",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aaf83a350081412f8fcc647175d26e7ab0c3e828",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98ee440353031df341472d04c49d581ca89d9e05",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "qFy6nLE5oHZQRyn0F8iZ9nDzvmM3NhjUiEdJcbf9cDI"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mje5o0",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "MutantEggroll",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mje5o0/psa_qwen3coder30ba3b_tool_calling_fixed_by/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mje5o0/psa_qwen3coder30ba3b_tool_calling_fixed_by/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754508492,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_5cwsshv7",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen 30b vs. gpt-oss-20b architecture comparison",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 74,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj32ra",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.9,
          "author_flair_background_color": null,
          "ups": 98,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 98,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/HsmvQ4GpEUBgE-eaPV02WX4c74y4-vpsGyF-bKYEyYY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754482643,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/7v3m4xao5ehf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?auto=webp&amp;s=476f4c45f2f32b5477e002fe70e39cf764b7b22d",
                  "width": 1477,
                  "height": 781
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=088c64d88ac758a164401f3fc7ad5eb4cc81dc0f",
                    "width": 108,
                    "height": 57
                  },
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e8bc1f9b80ced305e3a08d78d0678aa427f003d9",
                    "width": 216,
                    "height": 114
                  },
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c33081ccf817e9e5d0a3429ab6b6cfb4519c5875",
                    "width": 320,
                    "height": 169
                  },
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb7ee193c42fb34e9530b8b00e974a400665f39c",
                    "width": 640,
                    "height": 338
                  },
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=939a13b45ca90b56b5c84509db0f7863a32c7b96",
                    "width": 960,
                    "height": 507
                  },
                  {
                    "url": "https://preview.redd.it/7v3m4xao5ehf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c58cc60dd0b960b9693f8741788c352c8bed1a8d",
                    "width": 1080,
                    "height": 571
                  }
                ],
                "variants": {},
                "id": "1O2uxzbxUQGH7bYofOJi1kW9hBisSP4a8um35FI4JGs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj32ra",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SunilKumarDash",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj32ra/qwen_30b_vs_gptoss20b_architecture_comparison/",
          "stickied": false,
          "url": "https://i.redd.it/7v3m4xao5ehf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754482643,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "As the title says Qwen3-4B is a gift for us people without a dedicated GPU. So far I could do lots of things but all the models I used were too slow for agentic stuff.\n\nThe problem used to be that agents need a lot of context. Prompts with 3000+ tokens are completely normal. \n\nWith a bigger model it would take ages to process the prompt, even if the response then was of good quality. There's just no back and forth if for everything you want to do you have to wait for 10 minutes. \n\nThe combination of the speed of a 4B model with the agentic capabilities plus its coding knowledge which is really decent for a model that size unlocks a whole lot of new use cases for me.\n\nOn my AMD Ryzen 7 7735HS  with DDR5 RAM I get around 90t/s for prompt processing and 17t/s for generation. But as I said: Processing is almost more important than generation in agentic use cases.",
          "author_fullname": "t2_17gl7k",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-4B enables agentic use cases for us iGPU folks",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjghu2",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 18,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 18,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754513879,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says Qwen3-4B is a gift for us people without a dedicated GPU. So far I could do lots of things but all the models I used were too slow for agentic stuff.&lt;/p&gt;\n\n&lt;p&gt;The problem used to be that agents need a lot of context. Prompts with 3000+ tokens are completely normal. &lt;/p&gt;\n\n&lt;p&gt;With a bigger model it would take ages to process the prompt, even if the response then was of good quality. There&amp;#39;s just no back and forth if for everything you want to do you have to wait for 10 minutes. &lt;/p&gt;\n\n&lt;p&gt;The combination of the speed of a 4B model with the agentic capabilities plus its coding knowledge which is really decent for a model that size unlocks a whole lot of new use cases for me.&lt;/p&gt;\n\n&lt;p&gt;On my AMD Ryzen 7 7735HS  with DDR5 RAM I get around 90t/s for prompt processing and 17t/s for generation. But as I said: Processing is almost more important than generation in agentic use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mjghu2",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "leuchtetgruen",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754513879,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1lnt2rs3qb",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen 3 4b thinking model released !!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 95,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj8ndr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": null,
          "ups": 43,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 43,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/SGzjcVWQuqqPjBtl2iG3hG8PP_jjGqAzjeaGJA2sl8M.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754496119,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/lniprj9q9fhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?auto=webp&amp;s=401d7a7eed35f5803575f7c4b5da03fad9342a66",
                  "width": 1076,
                  "height": 736
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3aa8f50acbcd02b1ac29d941990b6f10b7079f26",
                    "width": 108,
                    "height": 73
                  },
                  {
                    "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b7ef4823baccdcbeecf4aa2662f01bc3783c82f",
                    "width": 216,
                    "height": 147
                  },
                  {
                    "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59733b1bd46efcaf9b4d6c3d8088213a04723843",
                    "width": 320,
                    "height": 218
                  },
                  {
                    "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df661ca95b9eaac9b0fd8e6b1d31301dbea377a1",
                    "width": 640,
                    "height": 437
                  },
                  {
                    "url": "https://preview.redd.it/lniprj9q9fhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e6d3f9fb76788f25ab1bdc89d84433318e7cb3b",
                    "width": 960,
                    "height": 656
                  }
                ],
                "variants": {},
                "id": "3yulBb_ySnjAH1CWf5YclM-uCsdipYFENv_d_a4326k"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj8ndr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Independent-Wind4462",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj8ndr/qwen_3_4b_thinking_model_released/",
          "stickied": false,
          "url": "https://i.redd.it/lniprj9q9fhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754496119,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1v14j7kk8i",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "in other words benchmaxxed",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 117,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mivbuo",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.85,
          "author_flair_background_color": null,
          "ups": 303,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 303,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/Lx0L3L7602KUVKc9yI1faOCwY-F0ntypadQXOIUMkZ0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754454997,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/i2vavxugvbhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?auto=webp&amp;s=ec874e68256bb3d18b134b15b90b35af1f3148c4",
                  "width": 1080,
                  "height": 904
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ec28f1f7e83cb66aba14621be40120512fdda69",
                    "width": 108,
                    "height": 90
                  },
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d70293603057ed0fc5f31cdf2c427412d7957fdb",
                    "width": 216,
                    "height": 180
                  },
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7739643f995963db512ec39dedcfe4f286d0d323",
                    "width": 320,
                    "height": 267
                  },
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0659e158cc4f10d87cf14b124dccd590bed50dc",
                    "width": 640,
                    "height": 535
                  },
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4cc6226ec45e334a6f64f00244b35bf290dd3b0b",
                    "width": 960,
                    "height": 803
                  },
                  {
                    "url": "https://preview.redd.it/i2vavxugvbhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dbc2555946cd04f7f07e69f9c44cffc559f2f38d",
                    "width": 1080,
                    "height": 904
                  }
                ],
                "variants": {},
                "id": "I6m16PmwCCMVuvRFaU1SIhAhYwKJFJ3exLWfJz6UCP4"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mivbuo",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mvp525",
          "discussion_type": null,
          "num_comments": 44,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/",
          "stickied": false,
          "url": "https://i.redd.it/i2vavxugvbhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754454997,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;format=png&amp;auto=webp&amp;s=09af507acfa40063fa0bed3df990bca01d097c81\n\nThanks openai, you're really contributing to the open-source LLM community\n\nI haven't been this blown away by a model since Llama 4!",
          "author_fullname": "t2_s7n3irsrx",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Finally, a model that's SAFE",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 52,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "elpfx70g3ahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 40,
                  "x": 108,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e1a7fab7e04de2bfb3425720fd1d39d2862ca0b"
                },
                {
                  "y": 80,
                  "x": 216,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=83a97fc796d05b2b1c246327b06b1380dc21bb4b"
                },
                {
                  "y": 119,
                  "x": 320,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a2c0b599116370239a30953765d3d2b978a6787"
                },
                {
                  "y": 238,
                  "x": 640,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63174dff4ba685b55c838cdbba82cfd8bcfd8e69"
                },
                {
                  "y": 357,
                  "x": 960,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e00fbca69d88a1db10e18805ba238859bada108"
                }
              ],
              "s": {
                "y": 371,
                "x": 996,
                "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;format=png&amp;auto=webp&amp;s=09af507acfa40063fa0bed3df990bca01d097c81"
              },
              "id": "elpfx70g3ahf1"
            }
          },
          "name": "t3_1minpqr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 857,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 857,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/vPXQi6mxUBYl7zt9fZCD3LWOB6PaZGcjaDHZr2r1u18.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433550,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81\"&gt;https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks openai, you&amp;#39;re really contributing to the open-source LLM community&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t been this blown away by a model since Llama 4!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1minpqr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "RandumbRedditor1000",
          "discussion_type": null,
          "num_comments": 89,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754433550,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "They just want us to try to jailbreak it with fine tuning and other methods to see if we can. \n\n-\n\nI saw that we should just delete the models and demand better. Why should we do this work for them when they have given us utter garbage. \n\n-\n\nDO NOT JAILBREAK or let ClosedAI know how we jailbreak it if you do. Your just playing right into their hands with this release. I implore you to just delete as protest.",
          "author_fullname": "t2_1jwmlwo64i",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-Oss is safety bait.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj764m",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 44,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 44,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754492810,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They just want us to try to jailbreak it with fine tuning and other methods to see if we can. &lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;I saw that we should just delete the models and demand better. Why should we do this work for them when they have given us utter garbage. &lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;DO NOT JAILBREAK or let ClosedAI know how we jailbreak it if you do. Your just playing right into their hands with this release. I implore you to just delete as protest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj764m",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ROOFisonFIRE_usa",
          "discussion_type": null,
          "num_comments": 42,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj764m/gptoss_is_safety_bait/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj764m/gptoss_is_safety_bait/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754492810,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "\"Join us to develop/customize, ultra-lightweight at approximately 25kg, integrated with a \\*\\*Large Multimodal Model for voice and images\\*\\*, let's accelerate the advent of the agent era!\"",
          "author_fullname": "t2_o65i6kx",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Unitree announces it's latest LLM hardware platform. This one really moves!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 105,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjbrwu",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.86,
          "author_flair_background_color": null,
          "ups": 25,
          "total_awards_received": 0,
          "media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v1Q4Su54iho?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "height": 200
          },
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v1Q4Su54iho?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Unitree Robotics",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/v1Q4Su54iho/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@unitreerobotics"
            },
            "type": "youtube.com"
          },
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v1Q4Su54iho?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "media_domain_url": "https://www.redditmedia.com/mediaembed/1mjbrwu",
            "height": 200
          },
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 25,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=d3bdfa3ef665072889ed10e6c8153cc70e59f389",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "rich:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754503112,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "youtube.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Join us to develop/customize, ultra-lightweight at approximately 25kg, integrated with a **Large Multimodal Model for voice and images**, let&amp;#39;s accelerate the advent of the agent era!&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.youtube.com/watch?v=v1Q4Su54iho",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U.jpeg?auto=webp&amp;s=80880808e4856a2c06c54a89775e838607c9651e",
                  "width": 480,
                  "height": 360
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9f95e5f49cafd3669d658ea50f742053abe6cf0",
                    "width": 108,
                    "height": 81
                  },
                  {
                    "url": "https://external-preview.redd.it/GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=09af9b785b61b6cf81c1702828b479d8153dfdb6",
                    "width": 216,
                    "height": 162
                  },
                  {
                    "url": "https://external-preview.redd.it/GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0ab57ac83b0c86b11ed43771579f323ab5d83ba",
                    "width": 320,
                    "height": 240
                  }
                ],
                "variants": {},
                "id": "GOgNpRUIp9Xi_KnxofG3IgToxyeM9Sjiw1kiZOMcv_U"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mjbrwu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "fallingdowndizzyvr",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjbrwu/unitree_announces_its_latest_llm_hardware/",
          "stickied": false,
          "url": "https://www.youtube.com/watch?v=v1Q4Su54iho",
          "subreddit_subscribers": 512425,
          "created_utc": 1754503112,
          "num_crossposts": 0,
          "media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/v1Q4Su54iho?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Unitree Introducing | Unitree R1 Intelligent Companion Price from $5900\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Unitree Robotics",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/v1Q4Su54iho/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@unitreerobotics"
            },
            "type": "youtube.com"
          },
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Yet another community benchmark, FamilyBench: https://github.com/Orolol/familyBench. \n\nWith just 5.1B active parameters, gpt-oss-120b destroys Kimi K2 that has a TRILLION parameters! And the small boi gpt-oss-20b is just 5 percentage points worse than GLM 4.5 Air, which has 12 billion active parameters!\n\nThe era of FAST is here! What else beats this speed to performance ratio?",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ballin' on a budget with gpt-oss-120b: Destroys Kimi K2 on FamilyBench!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 121,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj7gfx",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.64,
          "author_flair_background_color": "transparent",
          "ups": 57,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 57,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/Xy5Ai9UULnuSNzlYrXWWbI-LcOwjy1f47KsaOF4jUZc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754493461,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yet another community benchmark, FamilyBench: &lt;a href=\"https://github.com/Orolol/familyBench\"&gt;https://github.com/Orolol/familyBench&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;With just 5.1B active parameters, gpt-oss-120b destroys Kimi K2 that has a TRILLION parameters! And the small boi gpt-oss-20b is just 5 percentage points worse than GLM 4.5 Air, which has 12 billion active parameters!&lt;/p&gt;\n\n&lt;p&gt;The era of FAST is here! What else beats this speed to performance ratio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/mvnb6b8u1fhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?auto=webp&amp;s=6f45cc0f6936d91d669bf56a915bebfb4ebbb295",
                  "width": 1296,
                  "height": 1125
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b58f32a00795114b13fbc18c0750959b37c70d2",
                    "width": 108,
                    "height": 93
                  },
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ba9585f9d32579d2f6cca4cef943f8792b9e5b1",
                    "width": 216,
                    "height": 187
                  },
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b4d74169ff8b68a99ceee973b4bc14235f5ea7d9",
                    "width": 320,
                    "height": 277
                  },
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2385d992719fbd36a1034cf7048c42e663c4b74e",
                    "width": 640,
                    "height": 555
                  },
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c0f90a9be8bf987bb3bbd0a44686e51af56583dd",
                    "width": 960,
                    "height": 833
                  },
                  {
                    "url": "https://preview.redd.it/mvnb6b8u1fhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e059854313ba723fff7ab12af838fbae6eca6db1",
                    "width": 1080,
                    "height": 937
                  }
                ],
                "variants": {},
                "id": "mXFfUdwLdt0lu5pw_AOvq20wXMk99eeAO4hwUGyn3ho"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mj7gfx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mj7gfx/ballin_on_a_budget_with_gptoss120b_destroys_kimi/",
          "stickied": false,
          "url": "https://i.redd.it/mvnb6b8u1fhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754493461,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Welcome to the gpt-oss series, OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.\n\nWe’re releasing two flavors of the open models:\n\ngpt-oss-120b — for production, general purpose, high reasoning use cases that fits into a single H100 GPU (117B parameters with 5.1B active parameters)\n\ngpt-oss-20b — for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)\n\nHugging Face: https://huggingface.co/openai/gpt-oss-120b\n\n\n\n",
          "author_fullname": "t2_c705ri9b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "🚀 OpenAI released their open-weight models!!!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 82,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miezct",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.91,
          "author_flair_background_color": null,
          "ups": 1913,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 1913,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/NNtoh9seZAlcakAzWpJe7GsQ_xz-XC2MU3xqfAPcB4M.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754413775,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to the gpt-oss series, OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt;\n\n&lt;p&gt;We’re releasing two flavors of the open models:&lt;/p&gt;\n\n&lt;p&gt;gpt-oss-120b — for production, general purpose, high reasoning use cases that fits into a single H100 GPU (117B parameters with 5.1B active parameters)&lt;/p&gt;\n\n&lt;p&gt;gpt-oss-20b — for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)&lt;/p&gt;\n\n&lt;p&gt;Hugging Face: &lt;a href=\"https://huggingface.co/openai/gpt-oss-120b\"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/1yckal6wg8hf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?auto=webp&amp;s=a87899cddb3a83d6ad1f53d83a67020c3457a7ea",
                  "width": 1492,
                  "height": 876
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=51219fa655094895201128f25219c319f3488c47",
                    "width": 108,
                    "height": 63
                  },
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ee7558e73c603f894cdb074d5ee057861c256739",
                    "width": 216,
                    "height": 126
                  },
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2874c1a831663ecc44f9090501028a56f4d096b5",
                    "width": 320,
                    "height": 187
                  },
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc6b586f5d511d8c0e30969100e707e6e00a1815",
                    "width": 640,
                    "height": 375
                  },
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=04a3fcf3b139b82475c2ae2ad386ce1481488ad1",
                    "width": 960,
                    "height": 563
                  },
                  {
                    "url": "https://preview.redd.it/1yckal6wg8hf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fdef374b08e738fd247e490120193665da16143d",
                    "width": 1080,
                    "height": 634
                  }
                ],
                "variants": {},
                "id": "-5MrL_-KIn8zxxzcbQgf7n6F9Xusi-Z4r0GBuK0DdLY"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1miezct",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ResearchCrafty1804",
          "discussion_type": null,
          "num_comments": 541,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/",
          "stickied": false,
          "url": "https://i.redd.it/1yckal6wg8hf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754413775,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "How does GitHub trending works? [KittenTTS](https://github.com/KittenML/KittenTTS) launched yesterday and received overwhelming recognition by way of stars- currently at ~2500, and yet it's not in [GitHub trending](https://github.com/trending), while random projects are there?",
          "author_fullname": "t2_1qoyup9t5j",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "KittenTTS received ~2500 stars within 24 hours yet not in trending",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjajrl",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.81,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 22,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 22,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754500367,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does GitHub trending works? &lt;a href=\"https://github.com/KittenML/KittenTTS\"&gt;KittenTTS&lt;/a&gt; launched yesterday and received overwhelming recognition by way of stars- currently at ~2500, and yet it&amp;#39;s not in &lt;a href=\"https://github.com/trending\"&gt;GitHub trending&lt;/a&gt;, while random projects are there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?auto=webp&amp;s=4f4a63d658162f7dc655450e981519b17e51d3c5",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=583a8e643e7341836afca1b7d6c286e2d5cfb62e",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9137d5b6d86f28e71570c8d2e7850fea4cae3043",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=de58a11ecce4030ace0b4fa5c680a830f55b2458",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=36c375375034256273a9aacd80d592038ee227e1",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6bde96aedc547fa9669565978cbfb8fe77488ff3",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b43a84675c7ae8a58a841cacd74778fbd46fe564",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "aScS7BmPKjAGAYP_X4SVjl1nsbUqYhhE5W-38YKQXgU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mjajrl",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "FormalFlight3477",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjajrl/kittentts_received_2500_stars_within_24_hours_yet/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjajrl/kittentts_received_2500_stars_within_24_hours_yet/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754500367,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It seems to function better than stock Qwen-3-coder-30b-Instruct for UI/UX in my testing. I distilled it using SVD and applied the extracted Lora to the model. In the simulated OS things like the windows can fullscreen but cant minimize and the terminal is not functional. Still pretty good IMO considering its a 30b. All code was 1 or 2 shot. Currently only have a Q8\\_0 quant up but will have more up soon. If you would like to see the distillation scripts let me know and I can post them to github. \n\n[https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill](https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill)",
          "author_fullname": "t2_zws5yqyow",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "I distilled Qwen3-Coder-480B into Qwen3-Coder-30b-A3B-Instruct",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "dvyxza6i5dhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 116,
                  "x": 108,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a75a628162a1e3a7849c28e7b8116a4dc742abc3"
                },
                {
                  "y": 233,
                  "x": 216,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f140c15156f9f9d2f453efc8aae3041eb75aa979"
                },
                {
                  "y": 345,
                  "x": 320,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc43fd75fd68f4078ae84fa3423850b5a5d8c10b"
                },
                {
                  "y": 691,
                  "x": 640,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=905c0e71939bed08c0f9e4c9ae4e9c0327d2afc0"
                },
                {
                  "y": 1037,
                  "x": 960,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=267d2b7a2b5cefae96371dd9989d520e1df4042c"
                },
                {
                  "y": 1167,
                  "x": 1080,
                  "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d6c936d569efc29db8f37ce857ec69559c716aa"
                }
              ],
              "s": {
                "y": 3535,
                "x": 3270,
                "u": "https://preview.redd.it/dvyxza6i5dhf1.png?width=3270&amp;format=png&amp;auto=webp&amp;s=644ef0048dcab0cc13db5297baf013fccd762c50"
              },
              "id": "dvyxza6i5dhf1"
            },
            "w2ijh88h5dhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 134,
                  "x": 108,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=80113eaab7dd9c1377859864bba4fa2f0f4146f9"
                },
                {
                  "y": 268,
                  "x": 216,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bffe05f174a4ce95921d85a79b7656ab81e42b94"
                },
                {
                  "y": 397,
                  "x": 320,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f2380aed6daa0f8b8be10c32e492048e8221728"
                },
                {
                  "y": 795,
                  "x": 640,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e968007e673227952884f7512bb9d41301e16b2"
                },
                {
                  "y": 1192,
                  "x": 960,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=61e03c8c4fdd95f3e6720ba86803ebecf2ab6d78"
                },
                {
                  "y": 1341,
                  "x": 1080,
                  "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2db0d2976d593893f7a7c290ee9ad2ae4bb0d6f1"
                }
              ],
              "s": {
                "y": 4062,
                "x": 3270,
                "u": "https://preview.redd.it/w2ijh88h5dhf1.png?width=3270&amp;format=png&amp;auto=webp&amp;s=107a75dc2008772cce200e0d31979add769ba420"
              },
              "id": "w2ijh88h5dhf1"
            },
            "vbnf6qix7dhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 64,
                  "x": 108,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=27f9f07ffa34f05634e5c64fb24f77413ff850c3"
                },
                {
                  "y": 129,
                  "x": 216,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d0e5568f21353060b3dec10b2215bbf06c74345"
                },
                {
                  "y": 192,
                  "x": 320,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cdbaa1f093fe33aa229c395674cdc84ce452a0bf"
                },
                {
                  "y": 384,
                  "x": 640,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e91e58ac195f065f9c15e329626ff50f3fc382e7"
                },
                {
                  "y": 577,
                  "x": 960,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=968923635c321d4bcd463334c762d38bd1cd5b12"
                },
                {
                  "y": 649,
                  "x": 1080,
                  "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01ad665fc2887dbad2bc8a4415b5ad8739be6b83"
                }
              ],
              "s": {
                "y": 1976,
                "x": 3285,
                "u": "https://preview.redd.it/vbnf6qix7dhf1.png?width=3285&amp;format=png&amp;auto=webp&amp;s=63780c31476006ae36cda0e1211cd5f23d2dea37"
              },
              "id": "vbnf6qix7dhf1"
            }
          },
          "name": "t3_1mizz4c",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 90,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "w2ijh88h5dhf1",
                "id": 722381123
              },
              {
                "media_id": "dvyxza6i5dhf1",
                "id": 722381124
              },
              {
                "media_id": "vbnf6qix7dhf1",
                "id": 722381125
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 90,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/otdr2FbIcEHBACfeKNFLe7Iw0h8Ps5qbWOOlVN92PRY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754472331,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems to function better than stock Qwen-3-coder-30b-Instruct for UI/UX in my testing. I distilled it using SVD and applied the extracted Lora to the model. In the simulated OS things like the windows can fullscreen but cant minimize and the terminal is not functional. Still pretty good IMO considering its a 30b. All code was 1 or 2 shot. Currently only have a Q8_0 quant up but will have more up soon. If you would like to see the distillation scripts let me know and I can post them to github. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill\"&gt;https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mizz4c",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mizz4c",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Commercial-Celery769",
          "discussion_type": null,
          "num_comments": 28,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mizz4c/i_distilled_qwen3coder480b_into/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mizz4c",
          "subreddit_subscribers": 512425,
          "created_utc": 1754472331,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "With GPT-OSS being Apache licensed, could all the big players take the current model and continue fine tuning more aggressively to basically create a new model but not from scratch? \n\nIt seems like the architecture might be, but safety tuning has really marred the perception of it. I am sure DeepSeek, Qwen, Mistral are at least studying it to see where their next model might take advantage of the design… but perhaps a new or small player can use it to step up to the game with a more performant and complacent model.\n\nI saw one post so far that just compared… it didn’t evaluate. What do you think? Does the architecture add anything to the conversation?",
          "author_fullname": "t2_dissgzyl",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "The missing conversation: Is GPT-OSS by OpenAI a good architecture?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj3wks",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 45,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 45,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754484903,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With GPT-OSS being Apache licensed, could all the big players take the current model and continue fine tuning more aggressively to basically create a new model but not from scratch? &lt;/p&gt;\n\n&lt;p&gt;It seems like the architecture might be, but safety tuning has really marred the perception of it. I am sure DeepSeek, Qwen, Mistral are at least studying it to see where their next model might take advantage of the design… but perhaps a new or small player can use it to step up to the game with a more performant and complacent model.&lt;/p&gt;\n\n&lt;p&gt;I saw one post so far that just compared… it didn’t evaluate. What do you think? Does the architecture add anything to the conversation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj3wks",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "silenceimpaired",
          "discussion_type": null,
          "num_comments": 48,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj3wks/the_missing_conversation_is_gptoss_by_openai_a/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj3wks/the_missing_conversation_is_gptoss_by_openai_a/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754484903,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_bcvjachv",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen/Qwen3-4B-Instruct-2507 · Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjagod",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "ups": 20,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 20,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=de800e46d8c65968b5e4134ec1feb6ce8704976a",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754500183,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?auto=webp&amp;s=0bd1293accd1eb58248299811ad54a33deefb8a1",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2471012f5cf00b8b413a04e347268667c9614cdd",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3790c290c40d780cbf875abaf60ca9b9188c5ddf",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=81f6cc2449975826b894527a0d0a59c10e1249e8",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf92328644f95182b05b182147448f185da04c6b",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ce68822a90a46a78709dba106c7f4f1c0ebf92b",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dbb7a547faec1867f4d079ae4e631f1cc2ea9de1",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "absOWmN_8p4XnpFOVuhriIOW6B09HHA0KSpNTEuKdec"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mjagod",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Initial-Argument2523",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjagod/qwenqwen34binstruct2507_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507",
          "subreddit_subscribers": 512425,
          "created_utc": 1754500183,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "After feeling horribly underwhelmed by these models, the more I look around, the more I’m noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. \n\nOur company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we’ve ever seen in the models we’ve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)",
          "author_fullname": "t2_ie4ku",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 120B and 20B feel kind of… bad?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miodyp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 523,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 523,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754435230,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After feeling horribly underwhelmed by these models, the more I look around, the more I’m noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. &lt;/p&gt;\n\n&lt;p&gt;Our company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we’ve ever seen in the models we’ve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miodyp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SlackEight",
          "discussion_type": null,
          "num_comments": 206,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754435230,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_70vzcleel",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Minicpm-V-4",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj30xm",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": null,
          "ups": 43,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 43,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=19bc4f7e172d240b4c61f3b9af904c1ad3e6c89b",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754482504,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/openbmb/MiniCPM-V-4",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?auto=webp&amp;s=c70e1db0871024046b4600159454e7e471b8e61b",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=da6ecc5886120f6a22850a7948f8b0e5bc10545b",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=abfe1a67d0a4fa909c5b3e3e7f278fa0706b5230",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=118ff98129b3faa497ab10d05037da8804472ad0",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dde02ec62fa08e55dcf9f21a2dcfe334df0d1e95",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b24d7d78e271621f310f928f4337c798ef9ae199",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=089915c7b6a64fe3c8748d6a93b58546c2c70b8b",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "3-ytrfWg5r2XHJ--TW5MU_v0bmvd8Fq6_PpYLH5t9ZU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj30xm",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "lly0571",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj30xm/minicpmv4/",
          "stickied": false,
          "url": "https://huggingface.co/openbmb/MiniCPM-V-4",
          "subreddit_subscribers": 512425,
          "created_utc": 1754482504,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "This must be the most lobotomised version of any open model I’ve tested in the last year-and-a-half of being active with open models. \nAlmost all my test prompts return with an “I’m sorry, but I can’t help with that” response. \n\nDeleted this waist of space, time and energy by ClosedAI. \n\nWho would have thought that Open models from The People’s Republic of flipping China are less censored than their counterparts from the USA. \n\nWhat an interesting time to live in. ",
          "author_fullname": "t2_9cpgidsj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I’m sorry, but I can’t help with that",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj63k9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.76,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 30,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 30,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754490341,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This must be the most lobotomised version of any open model I’ve tested in the last year-and-a-half of being active with open models. \nAlmost all my test prompts return with an “I’m sorry, but I can’t help with that” response. &lt;/p&gt;\n\n&lt;p&gt;Deleted this waist of space, time and energy by ClosedAI. &lt;/p&gt;\n\n&lt;p&gt;Who would have thought that Open models from The People’s Republic of flipping China are less censored than their counterparts from the USA. &lt;/p&gt;\n\n&lt;p&gt;What an interesting time to live in. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj63k9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Narrow_Garbage_3475",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj63k9/im_sorry_but_i_cant_help_with_that/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj63k9/im_sorry_but_i_cant_help_with_that/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754490341,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1v14j7kk8i",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miupht",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.84,
          "author_flair_background_color": null,
          "ups": 172,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 172,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/NYAegSMxyxjw3adj8S9sdaZoX9ajAi02eblbCtx7iL8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754452970,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/cbd2wyrfpbhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?auto=webp&amp;s=7e912c03d003f41f947c107b142314e793af6cc5",
                  "width": 1080,
                  "height": 1679
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7a341ccdea7ac415e96e888ebc746dee27d179e",
                    "width": 108,
                    "height": 167
                  },
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=40819fb7e4a780fab6499d12a834692311fd6a28",
                    "width": 216,
                    "height": 335
                  },
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a45efcb0b9134d7b42ec2f9efc115ab4f5c49a1",
                    "width": 320,
                    "height": 497
                  },
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=994e72edd24558bb078da5397d66ecabc0d9a45a",
                    "width": 640,
                    "height": 994
                  },
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=123ecda06bc1f9a4631eb53c33ac151e646e3631",
                    "width": 960,
                    "height": 1492
                  },
                  {
                    "url": "https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1696ed9ac11d4ccca78a48310baa025ac71caff",
                    "width": 1080,
                    "height": 1679
                  }
                ],
                "variants": {},
                "id": "keXcRq9n_EyHLbnR3fopCcNrh38HbBpl020UaaLu8w8"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miupht",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mvp525",
          "discussion_type": null,
          "num_comments": 21,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/",
          "stickied": false,
          "url": "https://i.redd.it/cbd2wyrfpbhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754452970,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_a1p8p",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS was last updated in 2024?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 25,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjhsr7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.64,
          "author_flair_background_color": null,
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/DSAVM4ESpulIhHSB8feo5MoVv5AptbYUDRl3EHOsd4Y.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754516915,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/bgom177izghf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/bgom177izghf1.png?auto=webp&amp;s=9e03e0604923745b05213a8ed7c2912893a78142",
                  "width": 687,
                  "height": 126
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/bgom177izghf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7f8b54b2b4390357474bd7f4d2e5f20fd756afc",
                    "width": 108,
                    "height": 19
                  },
                  {
                    "url": "https://preview.redd.it/bgom177izghf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d451653a8460bbda279c55cf0751782c8cf56be",
                    "width": 216,
                    "height": 39
                  },
                  {
                    "url": "https://preview.redd.it/bgom177izghf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e10fa2c5d5bae61a5673dc0cc399cd27621f6fdb",
                    "width": 320,
                    "height": 58
                  },
                  {
                    "url": "https://preview.redd.it/bgom177izghf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0df1a8d4659c7fa599caa70e25f9c9f08fd0b845",
                    "width": 640,
                    "height": 117
                  }
                ],
                "variants": {},
                "id": "l7adzM_tzNdrtdTDfZDUKm2IGDRgDVACJfG7nqBXxSI"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mjhsr7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "klop2031",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjhsr7/gptoss_was_last_updated_in_2024/",
          "stickied": false,
          "url": "https://i.redd.it/bgom177izghf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754516915,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "&gt; Red pill is often considered part of the manosphere, which is a misogynistic ideology.\n\nHmm. Great views on manosphere 👌",
          "author_fullname": "t2_4yaw09a6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ok, we get a lobotobot. Great.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miytb3",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "ups": 64,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 64,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/4gD9QBWZP9KYBW1ylzPUJS3CjwKFqXpy_KXgloriVOY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754467758,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Red pill is often considered part of the manosphere, which is a misogynistic ideology.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Hmm. Great views on manosphere 👌&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/81b7dbwexchf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?auto=webp&amp;s=af0716f428e541332f4e011877244a0b2f9be41a",
                  "width": 1080,
                  "height": 2340
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=94971229b1012f225c3cf82e36421b408ec25e5a",
                    "width": 108,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aadbf9a83f0388df9eaa3e3518a80f985d4648df",
                    "width": 216,
                    "height": 432
                  },
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0bfc2469de3969a4daa68c9c6f3a033055a60184",
                    "width": 320,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fd0e87382bebbd8aefaa35209dcc558bee3e45d",
                    "width": 640,
                    "height": 1280
                  },
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f83a0863a47862ad8fadd4a118c4a2982f352bb",
                    "width": 960,
                    "height": 1920
                  },
                  {
                    "url": "https://preview.redd.it/81b7dbwexchf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8bde851010fb44e2457d7f7d2906b6cc79ddd203",
                    "width": 1080,
                    "height": 2160
                  }
                ],
                "variants": {},
                "id": "_YNNy7osleFYviJ0EvD_Vzjqqp9q4tlIPDYrmeysTxQ"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1miytb3",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Reno0vacio",
          "discussion_type": null,
          "num_comments": 46,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miytb3/ok_we_get_a_lobotobot_great/",
          "stickied": false,
          "url": "https://i.redd.it/81b7dbwexchf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754467758,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Sort of new to Ollama but doesn't this defeat the purpose of anonymity or am I missing something?   \n",
          "author_fullname": "t2_zcutwip8t",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Concerns about  the new Windows Ollama app requiring Sign In for Web Search, Turbo and downloading models.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjgw7o",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.73,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754514813,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sort of new to Ollama but doesn&amp;#39;t this defeat the purpose of anonymity or am I missing something?   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjgw7o",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Schwartzen2",
          "discussion_type": null,
          "num_comments": 15,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjgw7o/concerns_about_the_new_windows_ollama_app/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjgw7o/concerns_about_the_new_windows_ollama_app/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754514813,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It also lacks all general knowledge and is terrible at coding compared to the same sized GLM air, what is the use case here?",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 117,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1migo6d",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 875,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 875,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/t9rGYawVUHMh-rVOrQ-oAIMrbQMBdNtsBtxZVPCv4d0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754417418,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It also lacks all general knowledge and is terrible at coding compared to the same sized GLM air, what is the use case here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/7e3v67opr8hf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?auto=webp&amp;s=ff6a19821ff9f0084fe5093e01710f8b9f2d0e76",
                  "width": 1335,
                  "height": 1121
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e1dfcd1bbfd03b31e5f1e582c52041c04b40c89",
                    "width": 108,
                    "height": 90
                  },
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd417fda1bbf57060b05bef70db419a14693388c",
                    "width": 216,
                    "height": 181
                  },
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebcd63652cf257279a1a6b0021588f58ec882361",
                    "width": 320,
                    "height": 268
                  },
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c78bd2d594d80d839e43d136cedfee6e05b2b464",
                    "width": 640,
                    "height": 537
                  },
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=58317390434bfda92553dc698daca367b6e33be1",
                    "width": 960,
                    "height": 806
                  },
                  {
                    "url": "https://preview.redd.it/7e3v67opr8hf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99797c153ef91b6bd861ae69d8b3c50d327756e0",
                    "width": 1080,
                    "height": 906
                  }
                ],
                "variants": {},
                "id": "zZyqPYaircUjTFnIyrcvNrqKCwDGHekV5eFbIM-reUc"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1migo6d",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 110,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/",
          "stickied": false,
          "url": "https://i.redd.it/7e3v67opr8hf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754417418,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi everyone! To showcase the latest generation of small tool calling models, I built a demo which runs LFM2 (a new series of models from Liquid AI) 100% locally in your browser with Transformers.js. Hope you like it!\n\nLink to demo + source code: [https://huggingface.co/spaces/LiquidAI/LFM2-WebGPU](https://huggingface.co/spaces/LiquidAI/LFM2-WebGPU)",
          "author_fullname": "t2_mizchr3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "In-browser tool calling playground, running LFM2 locally on WebGPU with Transformers.js",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 89,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjbiq6",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "ups": 11,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/83dstrbeifhf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1130,
              "scrubber_media_url": "https://v.redd.it/83dstrbeifhf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/83dstrbeifhf1/DASHPlaylist.mpd?a=1757121231%2CNzhhZmMyOTdiYTJkYTNmOTI2OTcwYTY1YjEyOTJkMDE1NDI1ZTk0NjIxZmYzOWNhZDZkN2FmN2JmZTU0YWVmMA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 146,
              "hls_url": "https://v.redd.it/83dstrbeifhf1/HLSPlaylist.m3u8?a=1757121231%2CZTIxZGQzN2RkYjE3M2Y3MDFlY2EwZjcxODVlZWIwOTgxYjc3MzExMjg4ZTU0Y2UyMzE3MDhlMzVlMDRjNjE3ZA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 11,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=140&amp;height=89&amp;crop=140:89,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=ffee9910c4b0f56572af8824fc43dc0ddee95e9b",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754502541,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! To showcase the latest generation of small tool calling models, I built a demo which runs LFM2 (a new series of models from Liquid AI) 100% locally in your browser with Transformers.js. Hope you like it!&lt;/p&gt;\n\n&lt;p&gt;Link to demo + source code: &lt;a href=\"https://huggingface.co/spaces/LiquidAI/LFM2-WebGPU\"&gt;https://huggingface.co/spaces/LiquidAI/LFM2-WebGPU&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/83dstrbeifhf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?format=pjpg&amp;auto=webp&amp;s=fba6ca70604c5aa9453f160737fbe667e45a7ebd",
                  "width": 1688,
                  "height": 1076
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2fb409fc53197e2a57231a612c219cb32d52747f",
                    "width": 108,
                    "height": 68
                  },
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7f5cf28fdad1774dbc9ff87cdccde31bec07716e",
                    "width": 216,
                    "height": 137
                  },
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5c12d9ca730cbc051aaecddc4e2dd640fbb83376",
                    "width": 320,
                    "height": 203
                  },
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ec7d4ca42513450388cd60d12563bd5d488151b3",
                    "width": 640,
                    "height": 407
                  },
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0a458d58d25081b9135ff7eb18196cf5c947b687",
                    "width": 960,
                    "height": 611
                  },
                  {
                    "url": "https://external-preview.redd.it/eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6b5fe3beaaca30ddd136c0d8535203fd4375cb49",
                    "width": 1080,
                    "height": 688
                  }
                ],
                "variants": {},
                "id": "eXg4ajZ0YmVpZmhmMbYZ2NNhhOlQPtjC1_xl9uJZ2RpqkQZ92d23-2n-LFHZ"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mjbiq6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "xenovatech",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjbiq6/inbrowser_tool_calling_playground_running_lfm2/",
          "stickied": false,
          "url": "https://v.redd.it/83dstrbeifhf1",
          "subreddit_subscribers": 512425,
          "created_utc": 1754502541,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/83dstrbeifhf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1130,
              "scrubber_media_url": "https://v.redd.it/83dstrbeifhf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/83dstrbeifhf1/DASHPlaylist.mpd?a=1757121231%2CNzhhZmMyOTdiYTJkYTNmOTI2OTcwYTY1YjEyOTJkMDE1NDI1ZTk0NjIxZmYzOWNhZDZkN2FmN2JmZTU0YWVmMA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 146,
              "hls_url": "https://v.redd.it/83dstrbeifhf1/HLSPlaylist.m3u8?a=1757121231%2CZTIxZGQzN2RkYjE3M2Y3MDFlY2EwZjcxODVlZWIwOTgxYjc3MzExMjg4ZTU0Y2UyMzE3MDhlMzVlMDRjNjE3ZA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Everyone has been hating on gpt-oss here, but its been the best tool calling model in its class by far for me (I've been using the 20b). Nothing else I've used, including Qwen3-30b-2507 has come close to its ability to string together many, many tool calls. It's also literally what the model card says its good for: \n\n\"\nThe gpt-oss models are excellent for:\n\n    Web browsing (using built-in browsing tools)\n    Function calling with defined schemas\n    Agentic operations like browser tasks\n\"\n\nSeems like too many people are expecting it be an RP machine. What are your thoughts?",
          "author_fullname": "t2_1sr5yw3yg0",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss is great for tool calling",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj6pi9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 22,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 22,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754491778,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everyone has been hating on gpt-oss here, but its been the best tool calling model in its class by far for me (I&amp;#39;ve been using the 20b). Nothing else I&amp;#39;ve used, including Qwen3-30b-2507 has come close to its ability to string together many, many tool calls. It&amp;#39;s also literally what the model card says its good for: &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;\nThe gpt-oss models are excellent for:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Web browsing (using built-in browsing tools)\nFunction calling with defined schemas\nAgentic operations like browser tasks\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Seems like too many people are expecting it be an RP machine. What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj6pi9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "GL-AI",
          "discussion_type": null,
          "num_comments": 17,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj6pi9/gptoss_is_great_for_tool_calling/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj6pi9/gptoss_is_great_for_tool_calling/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754491778,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I am so happy and finally feel safe thanks to OpenAI. Thank you very much, Mr. Altmann. I was totally shocked when I saw how these cruel Chinese models brutally killed processes – but now I finally have a model that truly cares about my safety.\n\n\nSince I want to comply with OpenAI's security policies and this is a very dangerous topic I am writing about, I have tagged this post as NSFW as a precaution. Be careful before reading my screenshot, and thank me later.\n\n\n/s\n\n",
          "author_fullname": "t2_p45er6oo",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "There we are again. Can’t kill process",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj5qx1",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.72,
          "author_flair_background_color": "#bbbdbf",
          "ups": 22,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 22,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "nsfw",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754489502,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am so happy and finally feel safe thanks to OpenAI. Thank you very much, Mr. Altmann. I was totally shocked when I saw how these cruel Chinese models brutally killed processes – but now I finally have a model that truly cares about my safety.&lt;/p&gt;\n\n&lt;p&gt;Since I want to comply with OpenAI&amp;#39;s security policies and this is a very dangerous topic I am writing about, I have tagged this post as NSFW as a precaution. Be careful before reading my screenshot, and thank me later.&lt;/p&gt;\n\n&lt;p&gt;/s&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/34inwth2qehf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": true,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/34inwth2qehf1.jpeg?auto=webp&amp;s=b7a7deb9f496284a978d90d6efd3ee3b1f04ee7f",
                  "width": 1284,
                  "height": 2639
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17a98677194edac90c66675d8d6b3d32e23edef4",
                    "width": 108,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5834185b7b921ff18a7c25e88e8125eaffa11a51",
                    "width": 216,
                    "height": 432
                  },
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f258a5fc7fa3c72b888b67aa4730ae64c119d0e8",
                    "width": 320,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c0ef545f517c9a280e407ef0a3fa49f76d8e897",
                    "width": 640,
                    "height": 1280
                  },
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0bb03f042e5b59c8f4de85e3e305f1d5cadde63b",
                    "width": 960,
                    "height": 1920
                  },
                  {
                    "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=61147f490a556d426999e3214f6f22c0df7f8580",
                    "width": 1080,
                    "height": 2160
                  }
                ],
                "variants": {
                  "obfuscated": {
                    "source": {
                      "url": "https://preview.redd.it/34inwth2qehf1.jpeg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=1b9d260f18ba8b11724b6835cd5d70635615f163",
                      "width": 1284,
                      "height": 2639
                    },
                    "resolutions": [
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=0f09dbc91c1de709ea4e1d206fbd0226dd35dbd1",
                        "width": 108,
                        "height": 216
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=1f519ebbd80c9cded87728604d62e1eba8f9e2f3",
                        "width": 216,
                        "height": 432
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=e4497b9545b2842aedf4561cada6887a9cf2d236",
                        "width": 320,
                        "height": 640
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=aedc11a8176af82f530c129c1d0d1ef246ec9bef",
                        "width": 640,
                        "height": 1280
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=ca0c2bf378dbe29ed3a9b53e124c1810f971788d",
                        "width": 960,
                        "height": 1920
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=07fca311cb85aa7be0c3471c1cd0bb8f270ca1ca",
                        "width": 1080,
                        "height": 2160
                      }
                    ]
                  },
                  "nsfw": {
                    "source": {
                      "url": "https://preview.redd.it/34inwth2qehf1.jpeg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=1b9d260f18ba8b11724b6835cd5d70635615f163",
                      "width": 1284,
                      "height": 2639
                    },
                    "resolutions": [
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=0f09dbc91c1de709ea4e1d206fbd0226dd35dbd1",
                        "width": 108,
                        "height": 216
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=1f519ebbd80c9cded87728604d62e1eba8f9e2f3",
                        "width": 216,
                        "height": 432
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=e4497b9545b2842aedf4561cada6887a9cf2d236",
                        "width": 320,
                        "height": 640
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=aedc11a8176af82f530c129c1d0d1ef246ec9bef",
                        "width": 640,
                        "height": 1280
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=ca0c2bf378dbe29ed3a9b53e124c1810f971788d",
                        "width": 960,
                        "height": 1920
                      },
                      {
                        "url": "https://preview.redd.it/34inwth2qehf1.jpeg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=07fca311cb85aa7be0c3471c1cd0bb8f270ca1ca",
                        "width": 1080,
                        "height": 2160
                      }
                    ]
                  }
                },
                "id": "SfwLXJfxEV9IdHbmz4rREn6reIj4QD72yDvkHLuAT9g"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj5qx1",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Evening_Ad6637",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mj5qx1/there_we_are_again_cant_kill_process/",
          "stickied": false,
          "url": "https://i.redd.it/34inwth2qehf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754489502,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I really want to understand why I see this particular model being hyped up so much. Is there something revolutionary about it? Are we just looking at benchmarks? What use case does it serve that warrants me getting excited about it? Is it just because their mascot is adorable? ",
          "author_fullname": "t2_y35oj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Can someone explain to me why there is so much hype and excitement about Qwen 3 4b Thinking?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjevrf",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.68,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754510177,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really want to understand why I see this particular model being hyped up so much. Is there something revolutionary about it? Are we just looking at benchmarks? What use case does it serve that warrants me getting excited about it? Is it just because their mascot is adorable? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjevrf",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Porespellar",
          "discussion_type": null,
          "num_comments": 18,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjevrf/can_someone_explain_to_me_why_there_is_so_much/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjevrf/can_someone_explain_to_me_why_there_is_so_much/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754510177,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_w6l58p741",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-120b is safetymaxxed (cw: explicit safety)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 96,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1migl0k",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.91,
          "author_flair_background_color": null,
          "ups": 772,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 772,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "nsfw",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754417225,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/o893aealq8hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": true,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/o893aealq8hf1.png?auto=webp&amp;s=5b26e6c60c7f954a66b786552accb7dde09292a2",
                  "width": 1262,
                  "height": 872
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b152a8808314c24764a7d6beb50850f074d5e17d",
                    "width": 108,
                    "height": 74
                  },
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e056cb3ffd0321b99ea4da4c57f7a9b81a840b11",
                    "width": 216,
                    "height": 149
                  },
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=083fb195e38e962d81fa889ca786f2d397af2f97",
                    "width": 320,
                    "height": 221
                  },
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=75a40b66cea8040faf88e9fbc1ff530d52b484a8",
                    "width": 640,
                    "height": 442
                  },
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=39b0dd634e13a2d4aac2d9c32520c01a3efc47dc",
                    "width": 960,
                    "height": 663
                  },
                  {
                    "url": "https://preview.redd.it/o893aealq8hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5b249dec087ed58e93119a4b230441888dcbb179",
                    "width": 1080,
                    "height": 746
                  }
                ],
                "variants": {
                  "obfuscated": {
                    "source": {
                      "url": "https://preview.redd.it/o893aealq8hf1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8c840d7051a65fe9669d9e6a46dc4b1d3e63bace",
                      "width": 1262,
                      "height": 872
                    },
                    "resolutions": [
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=551a824dc1ee9567cdae82510d50e8bc70912d04",
                        "width": 108,
                        "height": 74
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=a567f40f356d88b12a4507636bea2ae88363e2fa",
                        "width": 216,
                        "height": 149
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=981cd1c11ed96610a2a125931cf1c0986da1c90a",
                        "width": 320,
                        "height": 221
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=04a04feaefd45f10effd139e9f9e447aa8753c3a",
                        "width": 640,
                        "height": 442
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=7654011e10c5f2e291d26bb8b28dc651b5932c84",
                        "width": 960,
                        "height": 663
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=9c2e88c2e9be808cf72cb958131100150b6ff15f",
                        "width": 1080,
                        "height": 746
                      }
                    ]
                  },
                  "nsfw": {
                    "source": {
                      "url": "https://preview.redd.it/o893aealq8hf1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=8c840d7051a65fe9669d9e6a46dc4b1d3e63bace",
                      "width": 1262,
                      "height": 872
                    },
                    "resolutions": [
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=551a824dc1ee9567cdae82510d50e8bc70912d04",
                        "width": 108,
                        "height": 74
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=a567f40f356d88b12a4507636bea2ae88363e2fa",
                        "width": 216,
                        "height": 149
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=981cd1c11ed96610a2a125931cf1c0986da1c90a",
                        "width": 320,
                        "height": 221
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=04a04feaefd45f10effd139e9f9e447aa8753c3a",
                        "width": 640,
                        "height": 442
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=7654011e10c5f2e291d26bb8b28dc651b5932c84",
                        "width": 960,
                        "height": 663
                      },
                      {
                        "url": "https://preview.redd.it/o893aealq8hf1.png?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=9c2e88c2e9be808cf72cb958131100150b6ff15f",
                        "width": 1080,
                        "height": 746
                      }
                    ]
                  }
                },
                "id": "vZb3g1tss3tYQmOPyr8tU-aqJGPTL3r4M997XeAfb5E"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1migl0k",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "TheLocalDrummer",
          "discussion_type": null,
          "num_comments": 187,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1migl0k/gptoss120b_is_safetymaxxed_cw_explicit_safety/",
          "stickied": false,
          "url": "https://i.redd.it/o893aealq8hf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754417225,
          "num_crossposts": 2,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "For those fine-tuning open-weight LLMs, here’s an interesting RLHF development.\n\nQwen’s team has introduced **Group Sequence Policy Optimisation (GSPO)**, a sequence-level variant of GRPO (Group Relative Policy Optimisation) that they say fixes instability and scaling issues.\n\n**GRPO’s issue:**\n\n* Token-level importance sampling introduces variance that accumulates over long sequences\n* MoE models are especially vulnerable, sometimes collapsing without hacks like Routing Replay\n\n**GSPO’s solution:**\n\n* Sequence-level importance ratios, normalised for length\n* Reduces gradient variance\n* Stable MoE training without Routing Replay\n\n**Reported results:**\n\n* Faster convergence and higher benchmark scores (AIME’24, LiveCodeBench, CodeForces)\n* Stronger scaling with more compute\n* MoE models trained without expert routing drift\n\nQwen’s analysis suggests sequence-level weighting could be a safer default for RLHF fine-tuning.\n\nFull explanation, math details, and training curves here: [Qwen Team Proposes GSPO for Qwen3, Claims DeepSeek's GRPO is Ill-Posed](https://blog.netmind.ai/article/Qwen_Team_Proposes_GSPO_for_Qwen3%2C_Claims_DeepSeek's_GRPO_is_Ill-Posed).\n\nHas anyone here experimented with sequence-level weighting in RLHF pipelines?",
          "author_fullname": "t2_1mz24a41z0",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GSPO: Qwen3’s new RLHF method claims to fix GRPO stability issues",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 79,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj2da1",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.86,
          "author_flair_background_color": null,
          "ups": 34,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 34,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/wdx0EDfHGyipamuyFmR7ibDlepMbm2ZznMA2nKgv2rQ.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754480606,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those fine-tuning open-weight LLMs, here’s an interesting RLHF development.&lt;/p&gt;\n\n&lt;p&gt;Qwen’s team has introduced &lt;strong&gt;Group Sequence Policy Optimisation (GSPO)&lt;/strong&gt;, a sequence-level variant of GRPO (Group Relative Policy Optimisation) that they say fixes instability and scaling issues.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GRPO’s issue:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Token-level importance sampling introduces variance that accumulates over long sequences&lt;/li&gt;\n&lt;li&gt;MoE models are especially vulnerable, sometimes collapsing without hacks like Routing Replay&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;GSPO’s solution:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sequence-level importance ratios, normalised for length&lt;/li&gt;\n&lt;li&gt;Reduces gradient variance&lt;/li&gt;\n&lt;li&gt;Stable MoE training without Routing Replay&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Reported results:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Faster convergence and higher benchmark scores (AIME’24, LiveCodeBench, CodeForces)&lt;/li&gt;\n&lt;li&gt;Stronger scaling with more compute&lt;/li&gt;\n&lt;li&gt;MoE models trained without expert routing drift&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Qwen’s analysis suggests sequence-level weighting could be a safer default for RLHF fine-tuning.&lt;/p&gt;\n\n&lt;p&gt;Full explanation, math details, and training curves here: &lt;a href=\"https://blog.netmind.ai/article/Qwen_Team_Proposes_GSPO_for_Qwen3%2C_Claims_DeepSeek&amp;#x27;s_GRPO_is_Ill-Posed\"&gt;Qwen Team Proposes GSPO for Qwen3, Claims DeepSeek&amp;#39;s GRPO is Ill-Posed&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here experimented with sequence-level weighting in RLHF pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/reqjka65ydhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/reqjka65ydhf1.png?auto=webp&amp;s=27e8dff72272bb8ef8f09be5494157869a15d9f1",
                  "width": 2158,
                  "height": 1232
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39ccefd55955fdd87428cf68c039c61fc725141d",
                    "width": 108,
                    "height": 61
                  },
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78719e2bbaa54fef96fdbcfc5aaaf8fdd092a3ea",
                    "width": 216,
                    "height": 123
                  },
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4dbd287df41db652ded392f92b29ad0fd97b5982",
                    "width": 320,
                    "height": 182
                  },
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=818b34eb8d9fcdec9fcd1a5f93903a2fb2aa28f6",
                    "width": 640,
                    "height": 365
                  },
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c654fa62e9b18724c936a017632f3835e8a82b7",
                    "width": 960,
                    "height": 548
                  },
                  {
                    "url": "https://preview.redd.it/reqjka65ydhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a5c2fa1328b31c32ab0e5c99dcdb6190ce3c3931",
                    "width": 1080,
                    "height": 616
                  }
                ],
                "variants": {},
                "id": "7O-rXX65yF_ChwMEWQT4Kg-O0rg5Y_MxpsSj9Rv-9DM"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj2da1",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "MarketingNetMind",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj2da1/gspo_qwen3s_new_rlhf_method_claims_to_fix_grpo/",
          "stickied": false,
          "url": "https://i.redd.it/reqjka65ydhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754480606,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Has anyone done a side by side comparison at various tasks between these models? This would be a very interesting comparison ",
          "author_fullname": "t2_15o3gy1oht",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Gemma 3 27b vs GPT OSS 20B anyone try yet?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjiyrf",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754519697,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone done a side by side comparison at various tasks between these models? This would be a very interesting comparison &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mjiyrf",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "deathcom65",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjiyrf/gemma_3_27b_vs_gpt_oss_20b_anyone_try_yet/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjiyrf/gemma_3_27b_vs_gpt_oss_20b_anyone_try_yet/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754519697,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Did people forget it's OpenAI or what they're stance is? They even made a whole press tour saying they'll lobotomize it for safety. Their open source models are gonna be the most censored thing ever, not sure why you expect it to generate nsfw or even an ounce of lying.\n\nPeople be jumping on the most expected things. Just wait until the abliterated model is out. Or not, it's not made for writing anyway.\n\nI do agree that they didn't spend so much time building safety. Imagine how fast they can be throwing out smarter models, yet half the time is spent on making sure the AI doesn't write fanfics.\n\nEdit: Someone pointed out a good point - It's clearly made for businesses. They have a safe baby that is sure to obey all laws and not get them sued. It's not gonna write smut anytime soon.",
          "author_fullname": "t2_duqfsmw4g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I mean honestly...what did you expect?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mizhf1",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.79,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 54,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 54,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754471613,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754470424,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did people forget it&amp;#39;s OpenAI or what they&amp;#39;re stance is? They even made a whole press tour saying they&amp;#39;ll lobotomize it for safety. Their open source models are gonna be the most censored thing ever, not sure why you expect it to generate nsfw or even an ounce of lying.&lt;/p&gt;\n\n&lt;p&gt;People be jumping on the most expected things. Just wait until the abliterated model is out. Or not, it&amp;#39;s not made for writing anyway.&lt;/p&gt;\n\n&lt;p&gt;I do agree that they didn&amp;#39;t spend so much time building safety. Imagine how fast they can be throwing out smarter models, yet half the time is spent on making sure the AI doesn&amp;#39;t write fanfics.&lt;/p&gt;\n\n&lt;p&gt;Edit: Someone pointed out a good point - It&amp;#39;s clearly made for businesses. They have a safe baby that is sure to obey all laws and not get them sued. It&amp;#39;s not gonna write smut anytime soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mizhf1",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "agentcubed",
          "discussion_type": null,
          "num_comments": 49,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mizhf1/i_mean_honestlywhat_did_you_expect/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mizhf1/i_mean_honestlywhat_did_you_expect/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754470424,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://x.com/\\_lewtun/status/1952788132908404941](https://x.com/_lewtun/status/1952788132908404941)\n\nTraining and inference recipes: [https://github.com/huggingface/gpt-oss-recipes/tree/main](https://github.com/huggingface/gpt-oss-recipes/tree/main)\n\nDistillations coming soon too! ",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Finally: TRL now supports fine-tuning for gpt-oss! HuggingFace team: \"In our testing, these models are extremely efficient to tune and can be adapted to new domains with just a few 100 samples\"",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 89,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjcnnu",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.56,
          "author_flair_background_color": "transparent",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/aV1n9Kt6moFhXnvHbuqo6u13sego_FloHu5CNRgV-oE.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754505110,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://x.com/_lewtun/status/1952788132908404941\"&gt;https://x.com/_lewtun/status/1952788132908404941&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Training and inference recipes: &lt;a href=\"https://github.com/huggingface/gpt-oss-recipes/tree/main\"&gt;https://github.com/huggingface/gpt-oss-recipes/tree/main&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Distillations coming soon too! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/9z7npro60ghf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/9z7npro60ghf1.png?auto=webp&amp;s=af9e12f3195141f4a16a1c3f7cfa0ee1f8b32d32",
                  "width": 1200,
                  "height": 768
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d387e2aa122472ad961ee73e501d947ff3371b3e",
                    "width": 108,
                    "height": 69
                  },
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffec9dbb5c902db2e70fb577f4f8b8e5497236a1",
                    "width": 216,
                    "height": 138
                  },
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb915ceb20779c4781a2455edb3192a17c02a1da",
                    "width": 320,
                    "height": 204
                  },
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b91bf84c893cdcb13c14b5ebd341437460e70b4",
                    "width": 640,
                    "height": 409
                  },
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=917fae3a31b530a254381da12db647420a55eaa3",
                    "width": 960,
                    "height": 614
                  },
                  {
                    "url": "https://preview.redd.it/9z7npro60ghf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3643be92899f3c2ec88d4804d969221e8afd6068",
                    "width": 1080,
                    "height": 691
                  }
                ],
                "variants": {},
                "id": "6mPECON6dIdFLMriIwurENtnbmPUkNd9PT1KYPllXRc"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mjcnnu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mjcnnu/finally_trl_now_supports_finetuning_for_gptoss/",
          "stickied": false,
          "url": "https://i.redd.it/9z7npro60ghf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754505110,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_uptissiz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "WE CAN COMPLY",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 29,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miv8y4",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "ups": 95,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 95,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/M71ZXlW78KU8RtwFyQd5KU0lrmzWhzE4fJOrSUeywWo.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754454724,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/uud2hotmubhf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/uud2hotmubhf1.png?auto=webp&amp;s=77cc93aa1e546499da7f549c2c1747dccc3939e5",
                  "width": 1421,
                  "height": 298
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f101d69bbde8dbec10d1193c68116e60525e1ec",
                    "width": 108,
                    "height": 22
                  },
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ddf1e8b33f7a443285ab88fdde009db652d3de5",
                    "width": 216,
                    "height": 45
                  },
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d428c5910f2ea0af1c394ceea512444f145ceb99",
                    "width": 320,
                    "height": 67
                  },
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83f0ba8ed65182bcac75f14c808ee28882456760",
                    "width": 640,
                    "height": 134
                  },
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a07a2f19f49e94eb3777a97949770208c68d5db1",
                    "width": 960,
                    "height": 201
                  },
                  {
                    "url": "https://preview.redd.it/uud2hotmubhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=471adbc66bb9d531cd35c0fe3421f5a6b494f112",
                    "width": 1080,
                    "height": 226
                  }
                ],
                "variants": {},
                "id": "WPW6azAwuzZLLLxNZo6utKa16ITONKYc8Y7AoCW9nvI"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1miv8y4",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Pro-editor-1105",
          "discussion_type": null,
          "num_comments": 24,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miv8y4/we_can_comply/",
          "stickied": false,
          "url": "https://i.redd.it/uud2hotmubhf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754454724,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Lol this is some next level brain fried from censorship.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 87,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minnrb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "ups": 251,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 251,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/_FCinv5u4rYlfumyKkhG-Ezi7NxGT6dyNufkywbnmS4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754433414,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/tcnuqjo63ahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/tcnuqjo63ahf1.png?auto=webp&amp;s=3ae1aa4b4f93ecaf3cf51bfc038fb9ad06ea4cf8",
                  "width": 1662,
                  "height": 1034
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67e1eec24f60cf63977d249e2cf11ef1e88a76dc",
                    "width": 108,
                    "height": 67
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d81c7517b43aa8e9e398136d9842d70123a1884",
                    "width": 216,
                    "height": 134
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d46fb0db5f457047f584027ae33caab6fb54d82",
                    "width": 320,
                    "height": 199
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=043f9f18d071dc3ac979b1c42c6e3c2c762f2319",
                    "width": 640,
                    "height": 398
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=94378cf121fabda8774b3d6e7896814005a607a9",
                    "width": 960,
                    "height": 597
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98ff6dfcfb98f81a9c68d19bdbb6be51b13ff781",
                    "width": 1080,
                    "height": 671
                  }
                ],
                "variants": {},
                "id": "9k6ua2_tpRRxx8jO2pJxOvTy53da50umqPEtOc9jHEE"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1minnrb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 68,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/",
          "stickied": false,
          "url": "https://i.redd.it/tcnuqjo63ahf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754433414,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I've been running Dolphin-Venice (Mistral Small but fine tuned for chatting) and have been super impressed -- it's conversational, VERY flexible with personality from system prompt, uncensored, and not prone to the moodiness/weird vibes that I get from Gemma3. It's no coding assistant, but it can rant on science topics and churn out basic python, but mostly make good conversation, which is an ideal blend for me.\n\nLllama 70b@q4 isn't too bad, but definitely less flexible at adopting a persona I find.\n\nAre there any favorites that fit in 48gb? Kimi and GLM look amazing and definitely best in class for open models but not at my VRAM sizes lol.",
          "author_fullname": "t2_fvs8r",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What are your favorite 48gb-compatible models right now? Any particular favorites for conversation/emotional intelligence?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mji8gx",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754517944,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been running Dolphin-Venice (Mistral Small but fine tuned for chatting) and have been super impressed -- it&amp;#39;s conversational, VERY flexible with personality from system prompt, uncensored, and not prone to the moodiness/weird vibes that I get from Gemma3. It&amp;#39;s no coding assistant, but it can rant on science topics and churn out basic python, but mostly make good conversation, which is an ideal blend for me.&lt;/p&gt;\n\n&lt;p&gt;Lllama 70b@q4 isn&amp;#39;t too bad, but definitely less flexible at adopting a persona I find.&lt;/p&gt;\n\n&lt;p&gt;Are there any favorites that fit in 48gb? Kimi and GLM look amazing and definitely best in class for open models but not at my VRAM sizes lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mji8gx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "CharlesStross",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mji8gx/what_are_your_favorite_48gbcompatible_models/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mji8gx/what_are_your_favorite_48gbcompatible_models/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754517944,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi, Emre from Jan here.\n\nAs of v0.6.7, Jan can now run gpt-oss locally via llama.cpp.\n\nWhat works:\n\n* Reasoning works, including &lt;think&gt; content (we've added frontend support to handle OpenAI's new reasoning format)\n* Available directly in Hub - please update Jan to v0.6.7\n\nWhat's not included (yet): \n\n* Tool use doesn't work for now. We scoped it out after testing, as upstream llama.cpp still has TODOs for this in the gpt-oss support PR\n\nIf you've already downloaded the models elsewhere and want to use them in Jan, go to Settings -&gt; Model Providers -&gt; llama.cpp, and use the **Import** button to add your models.\n\nUpdate your Jan or download the latest to run gpt-oss in Jan: [https://jan.ai/](https://jan.ai/)\n\n\\---  \n  \nIf you're curious about how we got it working: We initially explored using the new reasoning\\_format support in llama.cpp (b6097), but found it wasn't parsing correctly yet. So, we fell back to handling &lt;think&gt; blocks directly on the frontend with some custom logic, and it works for now. ",
          "author_fullname": "t2_g6cmmsdd",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Jan now supports gpt-oss",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 111,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj350o",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.66,
          "author_flair_background_color": null,
          "ups": 17,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/kyp6726o5ehf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1356,
              "scrubber_media_url": "https://v.redd.it/kyp6726o5ehf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/kyp6726o5ehf1/DASHPlaylist.mpd?a=1757121231%2CMTQ3MTI3YmJhODgzODA0Zjk3N2YzNWJlMWY4YTczYmU0NmY4MjRiZjJiYjJiNWIyN2NlMDhjMmQ4YzQ4YTk1Zg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 16,
              "hls_url": "https://v.redd.it/kyp6726o5ehf1/HLSPlaylist.m3u8?a=1757121231%2CY2JjOTQzYzMwZDE1MmNjYjJmNTQxZDkzNjM1YTcwMzY4ZDBmMDgyZDZjNjNjZTM1NmIyYWFmYmNkYjRjN2MxNA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 17,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=140&amp;height=111&amp;crop=140:111,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2a124a2b61bc6e50c20bb7a867fc4974f280b6b0",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754482820,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Emre from Jan here.&lt;/p&gt;\n\n&lt;p&gt;As of v0.6.7, Jan can now run gpt-oss locally via llama.cpp.&lt;/p&gt;\n\n&lt;p&gt;What works:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Reasoning works, including &amp;lt;think&amp;gt; content (we&amp;#39;ve added frontend support to handle OpenAI&amp;#39;s new reasoning format)&lt;/li&gt;\n&lt;li&gt;Available directly in Hub - please update Jan to v0.6.7&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What&amp;#39;s not included (yet): &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tool use doesn&amp;#39;t work for now. We scoped it out after testing, as upstream llama.cpp still has TODOs for this in the gpt-oss support PR&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you&amp;#39;ve already downloaded the models elsewhere and want to use them in Jan, go to Settings -&amp;gt; Model Providers -&amp;gt; llama.cpp, and use the &lt;strong&gt;Import&lt;/strong&gt; button to add your models.&lt;/p&gt;\n\n&lt;p&gt;Update your Jan or download the latest to run gpt-oss in Jan: &lt;a href=\"https://jan.ai/\"&gt;https://jan.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;---  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re curious about how we got it working: We initially explored using the new reasoning_format support in llama.cpp (b6097), but found it wasn&amp;#39;t parsing correctly yet. So, we fell back to handling &amp;lt;think&amp;gt; blocks directly on the frontend with some custom logic, and it works for now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/kyp6726o5ehf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?format=pjpg&amp;auto=webp&amp;s=ab25796dca69cd9a95deb1a4b1ccc825af0c6050",
                  "width": 1356,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=53da695799164fc9bd933b83599c4323d7387d0e",
                    "width": 108,
                    "height": 86
                  },
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a90c3fc3d9b020530e69dadf1ea7f28b466e5196",
                    "width": 216,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=bc8e54bf60a245b7dde29a3e0f20c13b45924ff0",
                    "width": 320,
                    "height": 254
                  },
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2d0f89b88833e33c0f768f67e51de02e5159b222",
                    "width": 640,
                    "height": 509
                  },
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=656ec0733d7ace0ca2783e461b75480602bd4432",
                    "width": 960,
                    "height": 764
                  },
                  {
                    "url": "https://external-preview.redd.it/NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=07f2a65ebf6647b13eae74d44cfc8396f6bfb8b0",
                    "width": 1080,
                    "height": 860
                  }
                ],
                "variants": {},
                "id": "NGt2MDcyNm81ZWhmMQ62VERZlqPJh7IITzRR5DtVbW3KlcgADGb6vsjTjyJg"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mj350o",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "eck72",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj350o/jan_now_supports_gptoss/",
          "stickied": false,
          "url": "https://v.redd.it/kyp6726o5ehf1",
          "subreddit_subscribers": 512425,
          "created_utc": 1754482820,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/kyp6726o5ehf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1356,
              "scrubber_media_url": "https://v.redd.it/kyp6726o5ehf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/kyp6726o5ehf1/DASHPlaylist.mpd?a=1757121231%2CMTQ3MTI3YmJhODgzODA0Zjk3N2YzNWJlMWY4YTczYmU0NmY4MjRiZjJiYjJiNWIyN2NlMDhjMmQ4YzQ4YTk1Zg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 16,
              "hls_url": "https://v.redd.it/kyp6726o5ehf1/HLSPlaylist.m3u8?a=1757121231%2CY2JjOTQzYzMwZDE1MmNjYjJmNTQxZDkzNjM1YTcwMzY4ZDBmMDgyZDZjNjNjZTM1NmIyYWFmYmNkYjRjN2MxNA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Not sure what I was expecting, but my new 512gb Mac Studio doesn't seem to be the workhorse I hoped for - I guess I expected a faster performance. ",
          "author_fullname": "t2_sk7nmjrs",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "underwhelmed by 512gb M3 ultra Mac Studio",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj9e2y",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.61,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754497782,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure what I was expecting, but my new 512gb Mac Studio doesn&amp;#39;t seem to be the workhorse I hoped for - I guess I expected a faster performance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj9e2y",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ChevChance",
          "discussion_type": null,
          "num_comments": 46,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj9e2y/underwhelmed_by_512gb_m3_ultra_mac_studio/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj9e2y/underwhelmed_by_512gb_m3_ultra_mac_studio/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754497782,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey all,\n\nI’m feeling overwhelmed by the huge number of options of chat apis and pricing models out there (openai, gemini, grok, ...) - hoping some of you can help me cut through the noise.\n\n# My use case:\n\n* I want to generate thousands of interesting, high-quality wikipedia summaries (i.e., articles **rewritten from longer wikipedia source** texts)\n* Each around **1000 words**\n* I don't need the chat option, it would just be one **singular prompt per article**\n* They would be used in a **tiktok-like knowledge app**\n* I care about cost per article most of all - ideally I can run thousands of these on a small budget\n* Would &lt; 3$ / 1k articles be unrealistic? (it's just a side-project for now)\n\nI have no idea what to look for or what to expect, but i hope some off y'all could help me out.",
          "author_fullname": "t2_1v4z55qo0o",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Best AI-API for mass-generating article summaries (fast + cheap)?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mjkev8",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754524241,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754523370,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I’m feeling overwhelmed by the huge number of options of chat apis and pricing models out there (openai, gemini, grok, ...) - hoping some of you can help me cut through the noise.&lt;/p&gt;\n\n&lt;h1&gt;My use case:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I want to generate thousands of interesting, high-quality wikipedia summaries (i.e., articles &lt;strong&gt;rewritten from longer wikipedia source&lt;/strong&gt; texts)&lt;/li&gt;\n&lt;li&gt;Each around &lt;strong&gt;1000 words&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t need the chat option, it would just be one &lt;strong&gt;singular prompt per article&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;They would be used in a &lt;strong&gt;tiktok-like knowledge app&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I care about cost per article most of all - ideally I can run thousands of these on a small budget&lt;/li&gt;\n&lt;li&gt;Would &amp;lt; 3$ / 1k articles be unrealistic? (it&amp;#39;s just a side-project for now)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have no idea what to look for or what to expect, but i hope some off y&amp;#39;all could help me out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjkev8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Actual-Fee9438",
          "discussion_type": null,
          "num_comments": 10,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjkev8/best_aiapi_for_massgenerating_article_summaries/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjkev8/best_aiapi_for_massgenerating_article_summaries/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754523370,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Is it just that the OSS model is bad, or is there something wrong with LM Studio? It's constantly outputting some of its thinking as the actual response. For example:\n\nhttps://preview.redd.it/7n1aozk3hhhf1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=c7c713d932534960f37019ed6a5fcd9864d64e2d\n\nAs a side note, I've heard that this model hallucinates a lot. But, from my early tests, it works pretty decent as a conversational llm, that is, if you want your outputs to be natural and brief. But - it has a lot of errors on its output, at least in LM studio. \n\nIt's also pretty fast too.   \n",
          "author_fullname": "t2_7qduc583w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS LM Studio Issues...thinking output as response.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 53,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "7n1aozk3hhhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 41,
                  "x": 108,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a4a9bf6110a3557e95a3aea8d560cc06e0b4f2a2"
                },
                {
                  "y": 82,
                  "x": 216,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=25269846268521e2ca6d7f7b0c493c143b154f25"
                },
                {
                  "y": 121,
                  "x": 320,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f02f2c0588e673265c3b9266cfca572e2103f6c"
                },
                {
                  "y": 243,
                  "x": 640,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc07b641d06dfef696229211f87b69c86a15a2ab"
                },
                {
                  "y": 364,
                  "x": 960,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a08f7a167f5de77e7765e44694ab1318384879a6"
                },
                {
                  "y": 410,
                  "x": 1080,
                  "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d2edc03ce642dd73b8b1fba4edd5cf5c5910221"
                }
              ],
              "s": {
                "y": 515,
                "x": 1355,
                "u": "https://preview.redd.it/7n1aozk3hhhf1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=c7c713d932534960f37019ed6a5fcd9864d64e2d"
              },
              "id": "7n1aozk3hhhf1"
            }
          },
          "name": "t3_1mjk9ia",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/GpmYvxCTzorQP8r3dH9KgrQQt-qY4hbr77-fyJVJS3o.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754523001,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just that the OSS model is bad, or is there something wrong with LM Studio? It&amp;#39;s constantly outputting some of its thinking as the actual response. For example:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7n1aozk3hhhf1.png?width=1355&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7c713d932534960f37019ed6a5fcd9864d64e2d\"&gt;https://preview.redd.it/7n1aozk3hhhf1.png?width=1355&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7c713d932534960f37019ed6a5fcd9864d64e2d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As a side note, I&amp;#39;ve heard that this model hallucinates a lot. But, from my early tests, it works pretty decent as a conversational llm, that is, if you want your outputs to be natural and brief. But - it has a lot of errors on its output, at least in LM studio. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s also pretty fast too.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjk9ia",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "GrungeWerX",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjk9ia/gptoss_lm_studio_issuesthinking_output_as_response/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjk9ia/gptoss_lm_studio_issuesthinking_output_as_response/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754523001,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I'm going to download GLM 4.5. But since I'm VRAM poor, I can only run a small quant. What's better at around the same size in GB, Q2_K_XL or IQ3_XXS?",
          "author_fullname": "t2_o65i6kx",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What's better Q2_K_XL or IQ3_XXS?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjef0p",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.7,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754509097,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going to download GLM 4.5. But since I&amp;#39;m VRAM poor, I can only run a small quant. What&amp;#39;s better at around the same size in GB, Q2_K_XL or IQ3_XXS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjef0p",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "fallingdowndizzyvr",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjef0p/whats_better_q2_k_xl_or_iq3_xxs/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjef0p/whats_better_q2_k_xl_or_iq3_xxs/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754509097,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I am looking for a TTS model. I prefer stable quality over a nice voice. \n\nKokoro is great for English, but I didn't find a way to have a German voice.\n Higg Boson is a hit and miss. I can get a consistent voice when I provide a sample. But some generated TTS are just plain trainwrecks.\n\nMaybe I just used it wrong or do you recommend another model?",
          "author_fullname": "t2_q9ojhw3l",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Reliable TTS model for German?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjdvr6",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.72,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754507861,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a TTS model. I prefer stable quality over a nice voice. &lt;/p&gt;\n\n&lt;p&gt;Kokoro is great for English, but I didn&amp;#39;t find a way to have a German voice.\n Higg Boson is a hit and miss. I can get a consistent voice when I provide a sample. But some generated TTS are just plain trainwrecks.&lt;/p&gt;\n\n&lt;p&gt;Maybe I just used it wrong or do you recommend another model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjdvr6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mobileJay77",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjdvr6/reliable_tts_model_for_german/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjdvr6/reliable_tts_model_for_german/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754507861,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Another one. [https://simple-bench.com/](https://simple-bench.com/)",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miotjk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.84,
          "author_flair_background_color": null,
          "ups": 150,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 150,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/slZPx2kenGAlzhxkZ4KeZH5vjmH3f3fIYWLTRX-XaQo.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754436341,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Another one. &lt;a href=\"https://simple-bench.com/\"&gt;https://simple-bench.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/yu8x76wnbahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/yu8x76wnbahf1.png?auto=webp&amp;s=a252360952acf8fb0d8fcc73b0ee29610a5fb4fd",
                  "width": 906,
                  "height": 1217
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=40f088e8768c33b741683caac490b28a990b5794",
                    "width": 108,
                    "height": 145
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a55fa927d4a91b9a5ccba1996153c985d4f05a2",
                    "width": 216,
                    "height": 290
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b03c14b089ffe5a77d3f1486e1fbc8b7003e23bf",
                    "width": 320,
                    "height": 429
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c5a7c3a67a52ed6461fbbc4ed074a559a66c3df6",
                    "width": 640,
                    "height": 859
                  }
                ],
                "variants": {},
                "id": "Yk7g-iwcJye_OAwxTkg4k6gNrgKoADVulTcpXZoHJ7g"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miotjk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 73,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/",
          "stickied": false,
          "url": "https://i.redd.it/yu8x76wnbahf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754436341,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://eqbench.com/](https://eqbench.com/)\n\n**gpt-oss-120b:**\n\nCreative writing\n\n[https://eqbench.com/results/creative-writing-v3/openai\\_\\_gpt-oss-120b.html](https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html)\n\nLongform writing:\n\n[https://eqbench.com/results/creative-writing-longform/openai\\_\\_gpt-oss-120b\\_longform\\_report.html](https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html)\n\nEQ-Bench:\n\n[https://eqbench.com/results/eqbench3\\_reports/openai\\_\\_gpt-oss-120b.html](https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html)\n\n\n\n**gpt-oss-20b:**\n\nCreative writing\n\n[https://eqbench.com/results/creative-writing-v3/openai\\_\\_gpt-oss-20b.html](https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html)\n\nLongform writing:\n\n[https://eqbench.com/results/creative-writing-longform/openai\\_\\_gpt-oss-20b\\_longform\\_report.html](https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html)\n\nEQ-Bench:\n\n[https://eqbench.com/results/eqbench3\\_reports/openai\\_\\_gpt-oss-20b.html](https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html)\n\n",
          "author_fullname": "t2_pp9qh5t8g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "OpenAI gpt-oss-120b &amp; 20b EQ-Bench &amp; creative writing results",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "znomj63ko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 155,
                  "x": 108,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0aa028d8fc2cbbc53426f8fd988f3a606086b92"
                },
                {
                  "y": 310,
                  "x": 216,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2b59d07098a95c551490555834b1c8e62cf2601"
                },
                {
                  "y": 459,
                  "x": 320,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a2c0540ce4a7134be96e8f7f530a272c15fb1ee"
                },
                {
                  "y": 918,
                  "x": 640,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=285ef11697d042fbc0ef0cb028fb9016deef81a7"
                },
                {
                  "y": 1377,
                  "x": 960,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c6fc3019f03d6dba919ca1fa768bd68710d8ad8"
                },
                {
                  "y": 1550,
                  "x": 1080,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19651cc4b224d1492cf56a26c1a61f30446cd1aa"
                }
              ],
              "s": {
                "y": 1998,
                "x": 1392,
                "u": "https://preview.redd.it/znomj63ko9hf1.png?width=1392&amp;format=png&amp;auto=webp&amp;s=72c63548e222079a1ec8f7e89ce5c672a9eb03ce"
              },
              "id": "znomj63ko9hf1"
            },
            "hwakzukko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 175,
                  "x": 108,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a907c3f561d350306adc7c4be6677f81b93df15b"
                },
                {
                  "y": 351,
                  "x": 216,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ed849eee3da8dedd2edec7fe34e45a21e29874e"
                },
                {
                  "y": 520,
                  "x": 320,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1d376d2e1c0e80cc9ec8e07e158aec8eada39f9"
                },
                {
                  "y": 1041,
                  "x": 640,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45dd2a4f93cae24a8ac54371cae682a79165a929"
                },
                {
                  "y": 1562,
                  "x": 960,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce2ed864a107b1a5cc6eb9477b94e66b45f4b347"
                },
                {
                  "y": 1757,
                  "x": 1080,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6506cc300127409ad8ef9485a313e6edee6f3183"
                }
              ],
              "s": {
                "y": 1930,
                "x": 1186,
                "u": "https://preview.redd.it/hwakzukko9hf1.png?width=1186&amp;format=png&amp;auto=webp&amp;s=91b929e09b4665b1bbfe62ab1a758b1d7bb9880a"
              },
              "id": "hwakzukko9hf1"
            },
            "oprys6qjo9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 135,
                  "x": 108,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bed4c8e7b94088bbf92d2a7c95487708e0fb51cc"
                },
                {
                  "y": 270,
                  "x": 216,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7997d24338fbc648ac336e202028bb9d1c237764"
                },
                {
                  "y": 400,
                  "x": 320,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=db3899174c605e6d8c10c2c9e7ceb4bf906e9e07"
                },
                {
                  "y": 800,
                  "x": 640,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c84e6fc911d2ee3c94d1cf272a772bd3051f73a3"
                },
                {
                  "y": 1200,
                  "x": 960,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e294b819550a94da8d361e4195e9e1bebf3724a"
                },
                {
                  "y": 1350,
                  "x": 1080,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bb4c578ff15e3ff3fccf34fe911f0661200ee074"
                }
              ],
              "s": {
                "y": 2000,
                "x": 1600,
                "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=b7526d4ab064ce18d86f6eb52a8df1c9262cf44e"
              },
              "id": "oprys6qjo9hf1"
            },
            "1hm2v1vko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 64,
                  "x": 108,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ec7ae41b57ca14d5099807b62cb20a3049d7efd"
                },
                {
                  "y": 128,
                  "x": 216,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0224d4e3f215ab1d100401d9bc16b1d8d7c91c3d"
                },
                {
                  "y": 189,
                  "x": 320,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f691d652c1686eb2a70fd7258a869179aa9163d"
                },
                {
                  "y": 379,
                  "x": 640,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b15ded60070d75b9f86870c1855ddd04d8b44026"
                },
                {
                  "y": 569,
                  "x": 960,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=43b18810472e88bec9b9db6b980d3a2914744ce1"
                },
                {
                  "y": 640,
                  "x": 1080,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=789f265dc80344d4c5e6ee02d316a0d2e82c7b21"
                }
              ],
              "s": {
                "y": 950,
                "x": 1601,
                "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=1601&amp;format=png&amp;auto=webp&amp;s=0724d38724d2331c9aaa28b35a8f60c53da674c6"
              },
              "id": "1hm2v1vko9hf1"
            }
          },
          "name": "t3_1milmrl",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": "transparent",
          "ups": 221,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "oprys6qjo9hf1",
                "id": 722041561
              },
              {
                "media_id": "znomj63ko9hf1",
                "id": 722041562
              },
              {
                "media_id": "hwakzukko9hf1",
                "id": 722041563
              },
              {
                "media_id": "1hm2v1vko9hf1",
                "id": 722041564
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 221,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/ddG4iHe_QohGbzMrf1QVWE9bWoVRavxmRobwbx0Do3Y.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":Llama:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428536,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://eqbench.com/\"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;gpt-oss-120b:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Creative writing&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html\"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Longform writing:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html\"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EQ-Bench:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html\"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;gpt-oss-20b:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Creative writing&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html\"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Longform writing:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html\"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EQ-Bench:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html\"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1milmrl",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":Llama:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1milmrl",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_sqrkl",
          "discussion_type": null,
          "num_comments": 106,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1milmrl",
          "subreddit_subscribers": 512425,
          "created_utc": 1754428536,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey everyone,\n\nit's great to see so much excitement around Kitten TTS. For anyone who needs a more robust, self-hosted solution for bigger tasks or API integration, I wanted to share a project I've been working on:\n\nGitHub Repo: [https://github.com/devnen/Kitten-TTS-Server](https://github.com/devnen/Kitten-TTS-Server)  \n  \nThis is a full-featured FastAPI server that wraps the tiny KittenTTS model and adds a clean Web UI to make it instantly usable. I saw people running into errors with long texts, and that's one of the problems this server is designed to solve.\n\nhttps://preview.redd.it/0bjbhcczgdhf1.png?width=1101&amp;format=png&amp;auto=webp&amp;s=73c1a7b8476d723d38e3a306ef077a113ff67167\n\nI designed the setup to be as straightforward as possible:\n\n\\- You clone the repo and create a virtual environment.\n\n\\- You run a simple, guided pip install process.\n\n\\- You type python server.py.\n\nThat's it. The server automatically downloads the model, starts up, and immediately opens the Web UI in your browser.  \n\n\nHere’s how it’s different and what problems it solves:\n\nGPU Acceleration: This isn't WebGPU. This is an optimized pipeline for NVIDIA cards using onnxruntime-gpu and I/O Binding. It's a feature the original model lacks entirely.\n\nWeb UI: No command lines needed after setup. Just open the page, type, and click \"Generate\".\n\nSupports Long-Text: It has an intelligent chunking system that automatically splits huge texts (like audiobooks), generates audio for each part, and seamlessly stitches it all together. You can paste an entire book, and it will work.\n\nHassle-Free GPU Installation: I spent a lot of time making the NVIDIA GPU setup as painless as possible for both Windows and Linux. The process correctly installs PyTorch with its bundled CUDA libraries, so you don't have to fight with complex system-wide installations.\n\nAPIs for Integration: It includes a flexible /tts endpoint and a OpenAI-compatible /v1/audio/speech endpoint, so you can easily plug it into your existing scripts.\n\nDocker Support: Comes with pre-configured Docker Compose files for both CPU and NVIDIA GPU deployment.  \n\n\nOpen source with an MIT license. Hope this helps anyone who wants a more robust way to run the Kitten TTS model:\n\n[https://github.com/devnen/Kitten-TTS-Server](https://github.com/devnen/Kitten-TTS-Server)",
          "author_fullname": "t2_dvqig5fo",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Kitten TTS Server: A self-hosted server with Web UI, GPU, API, and audiobook generation",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "0bjbhcczgdhf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 163,
                  "x": 108,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3c43404f8d1537e92e0ab4fe5bd132131c61c41e"
                },
                {
                  "y": 327,
                  "x": 216,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b13ff587a36a6632d0f4b005b4b47ac9f5957d4f"
                },
                {
                  "y": 485,
                  "x": 320,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9039c399ccb46786d7f64279c6926277de079531"
                },
                {
                  "y": 970,
                  "x": 640,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=050931eb7c9760876eb2f7525434ded29fa9f542"
                },
                {
                  "y": 1456,
                  "x": 960,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dd65f0ccd8cd43e1cff226a0f8bcd7476a167d2c"
                },
                {
                  "y": 1638,
                  "x": 1080,
                  "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53524166d821a72af5c216abaef8931920893364"
                }
              ],
              "s": {
                "y": 1670,
                "x": 1101,
                "u": "https://preview.redd.it/0bjbhcczgdhf1.png?width=1101&amp;format=png&amp;auto=webp&amp;s=73c1a7b8476d723d38e3a306ef077a113ff67167"
              },
              "id": "0bjbhcczgdhf1"
            }
          },
          "name": "t3_1mj0fsr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.81,
          "author_flair_background_color": null,
          "ups": 21,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 21,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=33cb07854b4171b40b63bc0ac30941edb5e02ce2",
          "edited": 1754474365,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1754474097,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s great to see so much excitement around Kitten TTS. For anyone who needs a more robust, self-hosted solution for bigger tasks or API integration, I wanted to share a project I&amp;#39;ve been working on:&lt;/p&gt;\n\n&lt;p&gt;GitHub Repo: &lt;a href=\"https://github.com/devnen/Kitten-TTS-Server\"&gt;https://github.com/devnen/Kitten-TTS-Server&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;This is a full-featured FastAPI server that wraps the tiny KittenTTS model and adds a clean Web UI to make it instantly usable. I saw people running into errors with long texts, and that&amp;#39;s one of the problems this server is designed to solve.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0bjbhcczgdhf1.png?width=1101&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=73c1a7b8476d723d38e3a306ef077a113ff67167\"&gt;https://preview.redd.it/0bjbhcczgdhf1.png?width=1101&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=73c1a7b8476d723d38e3a306ef077a113ff67167&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I designed the setup to be as straightforward as possible:&lt;/p&gt;\n\n&lt;p&gt;- You clone the repo and create a virtual environment.&lt;/p&gt;\n\n&lt;p&gt;- You run a simple, guided pip install process.&lt;/p&gt;\n\n&lt;p&gt;- You type python server.py.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s it. The server automatically downloads the model, starts up, and immediately opens the Web UI in your browser.  &lt;/p&gt;\n\n&lt;p&gt;Here’s how it’s different and what problems it solves:&lt;/p&gt;\n\n&lt;p&gt;GPU Acceleration: This isn&amp;#39;t WebGPU. This is an optimized pipeline for NVIDIA cards using onnxruntime-gpu and I/O Binding. It&amp;#39;s a feature the original model lacks entirely.&lt;/p&gt;\n\n&lt;p&gt;Web UI: No command lines needed after setup. Just open the page, type, and click &amp;quot;Generate&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Supports Long-Text: It has an intelligent chunking system that automatically splits huge texts (like audiobooks), generates audio for each part, and seamlessly stitches it all together. You can paste an entire book, and it will work.&lt;/p&gt;\n\n&lt;p&gt;Hassle-Free GPU Installation: I spent a lot of time making the NVIDIA GPU setup as painless as possible for both Windows and Linux. The process correctly installs PyTorch with its bundled CUDA libraries, so you don&amp;#39;t have to fight with complex system-wide installations.&lt;/p&gt;\n\n&lt;p&gt;APIs for Integration: It includes a flexible /tts endpoint and a OpenAI-compatible /v1/audio/speech endpoint, so you can easily plug it into your existing scripts.&lt;/p&gt;\n\n&lt;p&gt;Docker Support: Comes with pre-configured Docker Compose files for both CPU and NVIDIA GPU deployment.  &lt;/p&gt;\n\n&lt;p&gt;Open source with an MIT license. Hope this helps anyone who wants a more robust way to run the Kitten TTS model:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/devnen/Kitten-TTS-Server\"&gt;https://github.com/devnen/Kitten-TTS-Server&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?auto=webp&amp;s=f99ecfdb84e6cd61a37aa3cc3ad5e38b9bdd2a12",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dfe9cb8adc53050a74727fab520cfbf203143b71",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=406c26ed4b6e7ff10bd00229d41b271f51c52ef9",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=71e6737f7e5b5ff4016c4e74a9b2523080dc984d",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ee4de5385789b513a4aea14f9efdcf20618a72b",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed94bd8bc92c54d8a22e68ab869d288f78d06a63",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e9d2b1395a402972b1315fdf1312be614cb987b6",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "LJfRK1MfvFYt3gMCzjdNPbLVbezfMUo-8CXIbmCf85Q"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mj0fsr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "One_Slip1455",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj0fsr/kitten_tts_server_a_selfhosted_server_with_web_ui/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj0fsr/kitten_tts_server_a_selfhosted_server_with_web_ui/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754474097,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_48ezkeai",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "openai/gpt-oss-120b · Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mieqcb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 468,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 468,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=c53de7eaf90408930eb8ee160a74f6d720f0282c",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754413237,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/openai/gpt-oss-120b",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?auto=webp&amp;s=0871512cd76cbf7bde2f7bd9a5f885c071ce735a",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=292c3d3a2dfa2ce762d4e0ad0113f21057208fb5",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7caae8dd778b09b71d56e893c0307604fe6185aa",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ffd35e2510c33eb737fe6e23874ab1b1e5a5081",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ae7c659a21f868f6dba51b958c810a90c5bfe24",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e415f43cdae65729878a0ca9f4a7a894ca8be09",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3acf6478b097b66560a9a81bdaef6463bf66481c",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mieqcb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ShreckAndDonkey123",
          "discussion_type": null,
          "num_comments": 102,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/openai/gpt-oss-120b",
          "subreddit_subscribers": 512425,
          "created_utc": 1754413237,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I would expect the download size to be proportional to quantization, but Q2\\_K is 11.47GB, while Q8\\_0 is 12.11GB. Even F16 and BF16 are only 13.79GB.\n\nThe only one that's significantly different is F32, which is 41.86GB.\n\nAre only some layers being quantized or something?",
          "author_fullname": "t2_3s1bp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Why are all the unsloth GPT-OSS-20b quants basically the same size?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjf25w",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754510576,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would expect the download size to be proportional to quantization, but Q2_K is 11.47GB, while Q8_0 is 12.11GB. Even F16 and BF16 are only 13.79GB.&lt;/p&gt;\n\n&lt;p&gt;The only one that&amp;#39;s significantly different is F32, which is 41.86GB.&lt;/p&gt;\n\n&lt;p&gt;Are only some layers being quantized or something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjf25w",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "meatmanek",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjf25w/why_are_all_the_unsloth_gptoss20b_quants/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjf25w/why_are_all_the_unsloth_gptoss20b_quants/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754510576,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey y'all, i'm looking for a new model that would fit those requirements:\n\n\\- Great prose with quality writing, not much slop, repetitions etc  \n\\- Very long context (Over 10k minimum to 100k tokens)  \n\\- Fits under 24GB of VRAM for my 3090  \n\\- Uncensored, not necessarily something trained for RP/NSFW stuff, but something that won't constantly complain about \"muh i can't do that because blablabla\". I decide what i want it to do.  \n\\- Not overly obedient to the point where it's not capable of counterargumenting with you and constantly agrees, but still able to follow instructions well enough.  \n\\- Preferably, something trained to be pretty factual. I don't want the AI outright lying to me nonetheless.",
          "author_fullname": "t2_12e33e",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What's the best uncensored (but not necessarily NSFW) model under 24GB to use as a creative writing assistant?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj7c6d",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754493196,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, i&amp;#39;m looking for a new model that would fit those requirements:&lt;/p&gt;\n\n&lt;p&gt;- Great prose with quality writing, not much slop, repetitions etc&lt;br/&gt;\n- Very long context (Over 10k minimum to 100k tokens)&lt;br/&gt;\n- Fits under 24GB of VRAM for my 3090&lt;br/&gt;\n- Uncensored, not necessarily something trained for RP/NSFW stuff, but something that won&amp;#39;t constantly complain about &amp;quot;muh i can&amp;#39;t do that because blablabla&amp;quot;. I decide what i want it to do.&lt;br/&gt;\n- Not overly obedient to the point where it&amp;#39;s not capable of counterargumenting with you and constantly agrees, but still able to follow instructions well enough.&lt;br/&gt;\n- Preferably, something trained to be pretty factual. I don&amp;#39;t want the AI outright lying to me nonetheless.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mj7c6d",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "HRudy94",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj7c6d/whats_the_best_uncensored_but_not_necessarily/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj7c6d/whats_the_best_uncensored_but_not_necessarily/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754493196,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_twl3xhruz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "AMD Radeon AI PRO R9700 Has Already Launched But Will Be Only Available Via System Integrators",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj71cg",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.72,
          "author_flair_background_color": null,
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=cc6436a72dfff74da11e97b61b0f451a9cbe9da4",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754492517,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "wccftech.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://wccftech.com/amd-radeon-ai-pro-r9700-has-already-launched-but-will-be-only-available-via-system-integrators/",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?auto=webp&amp;s=1b1cddd160cfd154f6028f96b8eadb26d54994ab",
                  "width": 1493,
                  "height": 837
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e7da05caae6d75f7cdd0e822908efc42a62fe6e",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=82f7f189fbb4651232aba3b6bfdd435808cf3730",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f63d85f0ef5f4d1d42b85af8946dafa138067eaa",
                    "width": 320,
                    "height": 179
                  },
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=82787d21e7b0821fdce5a034706e0598040c7cc4",
                    "width": 640,
                    "height": 358
                  },
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2b9202a3e04226baa903ee3afe8ddf7a1398cc0",
                    "width": 960,
                    "height": 538
                  },
                  {
                    "url": "https://external-preview.redd.it/q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fc89c53afff247534a45b455b4d1ae5d01d6db7",
                    "width": 1080,
                    "height": 605
                  }
                ],
                "variants": {},
                "id": "q7mve0pWQXapLu3eVRUlgERITl5WzhQmx_iowI8HRh8"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mj71cg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_SYSTEM_ADMIN_MOD_",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj71cg/amd_radeon_ai_pro_r9700_has_already_launched_but/",
          "stickied": false,
          "url": "https://wccftech.com/amd-radeon-ai-pro-r9700-has-already-launched-but-will-be-only-available-via-system-integrators/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754492517,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I want to use a VLM for video description but what is the best VLM at the moment (6 August)? Is there any benchmarks that I can follow for VLMs?",
          "author_fullname": "t2_5jif7uko",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What is the best VLM at the moment?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj8dq7",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.89,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754495518,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use a VLM for video description but what is the best VLM at the moment (6 August)? Is there any benchmarks that I can follow for VLMs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mj8dq7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "muhlisgursoy",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj8dq7/what_is_the_best_vlm_at_the_moment/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj8dq7/what_is_the_best_vlm_at_the_moment/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754495518,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "new dots model from rednote:\n\n  \nWe are excited to introduce **dots.vlm1**, the first vision-language model in the dots model family. Built upon a 1.2 billion-parameter vision encoder and the DeepSeek V3 large language model (LLM), **dots.vlm1** demonstrates strong multimodal understanding and reasoning capabilities.\n\nThrough large-scale pretraining and carefully tuned post-training, **dots.vlm1 achieves near state-of-the-art performance in both visual perception and reasoning**, setting a new performance ceiling for open-source vision-language models—while still maintaining competitive capabilities in pure-text tasks.\n\n# [](https://huggingface.co/rednote-hilab/dots.vlm1.inst#model-summary)\n\n# Model Summary\n\n**This repo contains the instruction-tuned** `dots.vlm1` **model** which has the following features:\n\n* Type: A multimodal vision-language model with 1.2B vision encoder and DeepSeek V3 LLM\n* Training Stages: Vision encoder pretraining, VLM pretraining, and supervised fine-tuning (SFT)\n* Architecture: NaViT vision encoder + MLP adapter + DeepSeek V3 MoE language model\n* Vision Encoder: 1.2B parameters, 42 transformer layers with RMSNorm, SwiGLU, and 2D RoPE\n* Supported Languages: English, Chinese\n* Context Length: 65,536 tokens\n* License: MIT\n\n**Model Highlights**:\n\n* **NaViT Vision Encoder**: Trained entirely from scratch rather than fine-tuning an existing vision backbone. It natively supports dynamic resolution and incorporates pure visual supervision in addition to traditional text supervision, thereby enhancing the upper bound of perceptual capacity. Beyond image captioning datasets, a large amount of structured image data was introduced during pretraining to improve the model's perceptual capabilities—particularly for tasks such as OCR.\n* **Multimodal Training Data**: In addition to conventional approaches, dots.vlm1 leverages a wide range of synthetic data strategies to cover diverse image types (e.g., tables, charts, documents, graphics) and descriptions (e.g., alt text, dense captions, grounding annotations). Furthermore, a strong multimodal model was used to rewrite web page data with interleaved text and images, significantly improving the quality of the training corpus.",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "rednote-hilab/dots.vlm1.inst",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miw41b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": "#bbbdbf",
          "ups": 44,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 44,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=d749051cfe5a2af204b2c11ab5bd2db703aa4a0d",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754457624,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;new dots model from rednote:&lt;/p&gt;\n\n&lt;p&gt;We are excited to introduce &lt;strong&gt;dots.vlm1&lt;/strong&gt;, the first vision-language model in the dots model family. Built upon a 1.2 billion-parameter vision encoder and the DeepSeek V3 large language model (LLM), &lt;strong&gt;dots.vlm1&lt;/strong&gt; demonstrates strong multimodal understanding and reasoning capabilities.&lt;/p&gt;\n\n&lt;p&gt;Through large-scale pretraining and carefully tuned post-training, &lt;strong&gt;dots.vlm1 achieves near state-of-the-art performance in both visual perception and reasoning&lt;/strong&gt;, setting a new performance ceiling for open-source vision-language models—while still maintaining competitive capabilities in pure-text tasks.&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://huggingface.co/rednote-hilab/dots.vlm1.inst#model-summary\"&gt;&lt;/a&gt;&lt;/h1&gt;\n\n&lt;h1&gt;Model Summary&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;This repo contains the instruction-tuned&lt;/strong&gt; &lt;code&gt;dots.vlm1&lt;/code&gt; &lt;strong&gt;model&lt;/strong&gt; which has the following features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Type: A multimodal vision-language model with 1.2B vision encoder and DeepSeek V3 LLM&lt;/li&gt;\n&lt;li&gt;Training Stages: Vision encoder pretraining, VLM pretraining, and supervised fine-tuning (SFT)&lt;/li&gt;\n&lt;li&gt;Architecture: NaViT vision encoder + MLP adapter + DeepSeek V3 MoE language model&lt;/li&gt;\n&lt;li&gt;Vision Encoder: 1.2B parameters, 42 transformer layers with RMSNorm, SwiGLU, and 2D RoPE&lt;/li&gt;\n&lt;li&gt;Supported Languages: English, Chinese&lt;/li&gt;\n&lt;li&gt;Context Length: 65,536 tokens&lt;/li&gt;\n&lt;li&gt;License: MIT&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Model Highlights&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;NaViT Vision Encoder&lt;/strong&gt;: Trained entirely from scratch rather than fine-tuning an existing vision backbone. It natively supports dynamic resolution and incorporates pure visual supervision in addition to traditional text supervision, thereby enhancing the upper bound of perceptual capacity. Beyond image captioning datasets, a large amount of structured image data was introduced during pretraining to improve the model&amp;#39;s perceptual capabilities—particularly for tasks such as OCR.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Multimodal Training Data&lt;/strong&gt;: In addition to conventional approaches, dots.vlm1 leverages a wide range of synthetic data strategies to cover diverse image types (e.g., tables, charts, documents, graphics) and descriptions (e.g., alt text, dense captions, grounding annotations). Furthermore, a strong multimodal model was used to rewrite web page data with interleaved text and images, significantly improving the quality of the training corpus.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/rednote-hilab/dots.vlm1.inst",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?auto=webp&amp;s=7380c934961835b1c9d2cb25a82b3d435642beb9",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fad0b801303232ea78b764a2dd4e4f630548fdb2",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9a02ad3ba5bd448fd95426af8a5aed6e34d0933",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=afcb4b683c3af65bdc22115f38d351011d475ce8",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=37f493347207fe571e78519d5d47caadcba70841",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc6039c93320e711b31ac0eb8069ee787dfec899",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d490fe6d3b2de751e1e907481f4847a7b55910c0",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "JnSIe24tNYiYbzSSIgrts2MUNL0-oMA6VhVjvooEbxw"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1miw41b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1miw41b/rednotehilabdotsvlm1inst/",
          "stickied": false,
          "url": "https://huggingface.co/rednote-hilab/dots.vlm1.inst",
          "subreddit_subscribers": 512425,
          "created_utc": 1754457624,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Which one is better?",
          "author_fullname": "t2_tqt1idp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-20b vs magistral:24b?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj9690",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.73,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754497291,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one is better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mj9690",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "BillyTheMilli",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754497291,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey all! Since GPT-OSS has such an efficient architecture, I was able to get 120B running 100% locally in pure JavaScript: https://codepen.io/Clowerweb/full/wBKeGYe",
          "author_fullname": "t2_1iuzpxw7eg",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 120B locally in JavaScript",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Generation"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mj524g",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.74,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Generation",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754487831,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! Since GPT-OSS has such an efficient architecture, I was able to get 120B running 100% locally in pure JavaScript: &lt;a href=\"https://codepen.io/Clowerweb/full/wBKeGYe\"&gt;https://codepen.io/Clowerweb/full/wBKeGYe&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "23bddba8-ff56-11ed-9688-1a11994b71f7",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#b5a3d0",
          "id": "1mj524g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "CommunityTough1",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj524g/gptoss_120b_locally_in_javascript/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj524g/gptoss_120b_locally_in_javascript/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754487831,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "So I recently built a new PC that has dual purpose for gaming and AI. It's got a 5090 in it that has definitely upped my AI game since I bought it. However now that I am really starting to work with agents, 32gb vram is just not enough to do multiple tasks without it taking forever. I have a very old PC that I have been using as a Plex server for some time. It has an Intel i7-8700 processor and an msi z370 motherboard. It currently has a 1060 in it but I was thinking about replacing it with 2x Tesla p40s. The PSU is 1000w so I THINK I am OK on power. My question is other than the issue where fp16 is a no go for LLMs, does anyone have any red flags that I am not aware of? Still relatively new to the AI game but I think having an extra 48gb of vram to run in parallel to my 5090 could add a lot more capability to any agents that I want to build ",
          "author_fullname": "t2_8cxfir1v",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Old PC conversation viability",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjgv2m",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754514740,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I recently built a new PC that has dual purpose for gaming and AI. It&amp;#39;s got a 5090 in it that has definitely upped my AI game since I bought it. However now that I am really starting to work with agents, 32gb vram is just not enough to do multiple tasks without it taking forever. I have a very old PC that I have been using as a Plex server for some time. It has an Intel i7-8700 processor and an msi z370 motherboard. It currently has a 1060 in it but I was thinking about replacing it with 2x Tesla p40s. The PSU is 1000w so I THINK I am OK on power. My question is other than the issue where fp16 is a no go for LLMs, does anyone have any red flags that I am not aware of? Still relatively new to the AI game but I think having an extra 48gb of vram to run in parallel to my 5090 could add a lot more capability to any agents that I want to build &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mjgv2m",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Rabbitsatemycheese",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjgv2m/old_pc_conversation_viability/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjgv2m/old_pc_conversation_viability/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754514740,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi all,\n\nI wanted to share my recent experience (and save others some hours of troubleshooting!) trying to run the new GPT-OSS-20B F16/MXFP4/MOE GGUF models locally via `llama.cpp` and `llama-cpp-python` — and to confirm that as of August 7, 2025, this is NOT yet supported, regardless of what you try.\n\n# What I did:\n\n1. Built an isolated Python virtual environment Using Windows 11, Python 3.11, latest pip, etc.\n2. Compiled llama-cpp-python from source\n   * Cloned [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python) with `--recursive`\n   * Explicitly updated the `vendor/llama.cpp` submodule:\n      * Switched to upstream origin: `git remote set-url origin` [`https://github.com/ggerganov/llama.cpp.git`](https://github.com/ggerganov/llama.cpp.git)\n      * Checked out latest `master`, did `git pull origin master`\n      * Confirmed commit:yamlCopyEditcommit 5fd160bbd9d70b94b5b11b0001fd7f477005e4a0 (HEAD -&gt; master, tag: b6106, origin/master, origin/HEAD) Date:   Wed Aug 6 15:14:40 2025 -0700 \n   * Compiled with `FORCE_CMAKE=1`, CPU only\n3. Downloaded the official Unsloth GPT-OSS-20B F16 GGUF\n   * 13.4 GB\n   * Downloaded directly from HuggingFace, verified SHA256, file size matches exactly.\n4. Tested file integrity with a custom Python script:\n   * Confirmed GGUF header, no corruption, full SHA256 check.\n5. Tried loading the model with llama\\_cpp.Llama (chat\\_format=\"gpt-oss\")\n   * Also tested with the latest compiled `main.exe` from `llama.cpp` directly.\n   * Tried both with F16 and Q0\\_0 versions.\n\n# The error (every single time):\n\n    pgsqlCopyEditgguf_init_from_file_impl: tensor 'blk.0.ffn_down_exps.weight' has invalid ggml type 39 (NONE)\n    gguf_init_from_file_impl: failed to read tensor info\n    llama_model_load: error loading model: llama_model_loader: failed to load model from xxx.gguf\n    llama_model_load_from_file_impl: failed to load model\n    [ERRO] Failed to load model from file: xxx.gguf\n    \n\n# What this means:\n\n* As of the most recent commit (`b6106`, Aug 6, 2025) on `llama.cpp` and the latest source build of `llama-cpp-python`, there is still NO support for the new MXFP4 tensor type (ggml type 39) required by GPT-OSS F16/MXFP4/MOE models.\n* This is not an issue with your build, Python, environment, or file.\n* The GGUF files themselves are valid and pass header/hash checks.\n* No one can run these models locally via vanilla llama.cpp at this time**.** (I even tried other quantizations; only the latest MXFP4/F16 fail like this.)\n\n# What to do?\n\n* Wait for an official update / PR / patch in llama.cpp that adds MXFP4 and GPT-OSS F16/MOE support.\n* Track issues on [ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp/issues) and the HuggingFace repo for progress.\n* When that happens, just update and recompile — no extra hacks should be needed.\n\n# Conclusion:\n\nIf you’re seeing  \n`gguf_init_from_file_impl: tensor 'blk.0.ffn_down_exps.weight' has invalid ggml type 39 (NONE)`  \ntrying to load GPT-OSS-20B F16/MXFP4, **it’s not you — it’s the code!**\n\nWe’re all waiting for upstream support.",
          "author_fullname": "t2_l2tfh53yn",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS-20B F16/MXFP4 GGUF Models Not Loading on Latest llama.cpp: \"tensor ... has invalid ggml type 39 (NONE)\"",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mjm5vm",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754528046,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share my recent experience (and save others some hours of troubleshooting!) trying to run the new GPT-OSS-20B F16/MXFP4/MOE GGUF models locally via &lt;code&gt;llama.cpp&lt;/code&gt; and &lt;code&gt;llama-cpp-python&lt;/code&gt; — and to confirm that as of August 7, 2025, this is NOT yet supported, regardless of what you try.&lt;/p&gt;\n\n&lt;h1&gt;What I did:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Built an isolated Python virtual environment Using Windows 11, Python 3.11, latest pip, etc.&lt;/li&gt;\n&lt;li&gt;Compiled llama-cpp-python from source\n\n&lt;ul&gt;\n&lt;li&gt;Cloned &lt;a href=\"https://github.com/abetlen/llama-cpp-python\"&gt;abetlen/llama-cpp-python&lt;/a&gt; with &lt;code&gt;--recursive&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Explicitly updated the &lt;code&gt;vendor/llama.cpp&lt;/code&gt; submodule:\n\n&lt;ul&gt;\n&lt;li&gt;Switched to upstream origin: &lt;code&gt;git remote set-url origin&lt;/code&gt; &lt;a href=\"https://github.com/ggerganov/llama.cpp.git\"&gt;&lt;code&gt;https://github.com/ggerganov/llama.cpp.git&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Checked out latest &lt;code&gt;master&lt;/code&gt;, did &lt;code&gt;git pull origin master&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Confirmed commit:yamlCopyEditcommit 5fd160bbd9d70b94b5b11b0001fd7f477005e4a0 (HEAD -&amp;gt; master, tag: b6106, origin/master, origin/HEAD) Date:   Wed Aug 6 15:14:40 2025 -0700 &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Compiled with &lt;code&gt;FORCE_CMAKE=1&lt;/code&gt;, CPU only&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Downloaded the official Unsloth GPT-OSS-20B F16 GGUF\n\n&lt;ul&gt;\n&lt;li&gt;13.4 GB&lt;/li&gt;\n&lt;li&gt;Downloaded directly from HuggingFace, verified SHA256, file size matches exactly.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Tested file integrity with a custom Python script:\n\n&lt;ul&gt;\n&lt;li&gt;Confirmed GGUF header, no corruption, full SHA256 check.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Tried loading the model with llama_cpp.Llama (chat_format=&amp;quot;gpt-oss&amp;quot;)\n\n&lt;ul&gt;\n&lt;li&gt;Also tested with the latest compiled &lt;code&gt;main.exe&lt;/code&gt; from &lt;code&gt;llama.cpp&lt;/code&gt; directly.&lt;/li&gt;\n&lt;li&gt;Tried both with F16 and Q0_0 versions.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;The error (every single time):&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;pgsqlCopyEditgguf_init_from_file_impl: tensor &amp;#39;blk.0.ffn_down_exps.weight&amp;#39; has invalid ggml type 39 (NONE)\ngguf_init_from_file_impl: failed to read tensor info\nllama_model_load: error loading model: llama_model_loader: failed to load model from xxx.gguf\nllama_model_load_from_file_impl: failed to load model\n[ERRO] Failed to load model from file: xxx.gguf\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;What this means:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;As of the most recent commit (&lt;code&gt;b6106&lt;/code&gt;, Aug 6, 2025) on &lt;code&gt;llama.cpp&lt;/code&gt; and the latest source build of &lt;code&gt;llama-cpp-python&lt;/code&gt;, there is still NO support for the new MXFP4 tensor type (ggml type 39) required by GPT-OSS F16/MXFP4/MOE models.&lt;/li&gt;\n&lt;li&gt;This is not an issue with your build, Python, environment, or file.&lt;/li&gt;\n&lt;li&gt;The GGUF files themselves are valid and pass header/hash checks.&lt;/li&gt;\n&lt;li&gt;No one can run these models locally via vanilla llama.cpp at this time&lt;strong&gt;.&lt;/strong&gt; (I even tried other quantizations; only the latest MXFP4/F16 fail like this.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;What to do?&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Wait for an official update / PR / patch in llama.cpp that adds MXFP4 and GPT-OSS F16/MOE support.&lt;/li&gt;\n&lt;li&gt;Track issues on &lt;a href=\"https://github.com/ggerganov/llama.cpp/issues\"&gt;ggerganov/llama.cpp&lt;/a&gt; and the HuggingFace repo for progress.&lt;/li&gt;\n&lt;li&gt;When that happens, just update and recompile — no extra hacks should be needed.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Conclusion:&lt;/h1&gt;\n\n&lt;p&gt;If you’re seeing&lt;br/&gt;\n&lt;code&gt;gguf_init_from_file_impl: tensor &amp;#39;blk.0.ffn_down_exps.weight&amp;#39; has invalid ggml type 39 (NONE)&lt;/code&gt;&lt;br/&gt;\ntrying to load GPT-OSS-20B F16/MXFP4, &lt;strong&gt;it’s not you — it’s the code!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We’re all waiting for upstream support.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?auto=webp&amp;s=15dec2ef279707b2b7293f298adf65c120367689",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f92890af939223e811c78aea793ad74924524124",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7a52293722d602fe6fdebcf196182f6b7c5e573",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0624f431dbc1aca0fda020f274bbe55097bc3029",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cf04d8aa804465078ae5a4e47e5c8fb229efaa46",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a1c420daf96989a2ffdd13a56551243766e0602e",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=014bf6642a86d58418fa1570ec5de73a70a0c2e9",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "tkjhWxNM-Mt33ysEhzUuJ63e8pNrfpVAPEbJGjatflc"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mjm5vm",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "PT_OV",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjm5vm/gptoss20b_f16mxfp4_gguf_models_not_loading_on/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjm5vm/gptoss20b_f16mxfp4_gguf_models_not_loading_on/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754528046,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I have 3x 3090 running oss 120B in LM studio. With flash attention enabled and 32k context window I get 100 token/s prompt eval speed.\n\nThat seems terribly slow...what are you guys getting?\n",
          "author_fullname": "t2_aafjsulg",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Slow prompt eval oss 120b?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mjlvxo",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754527286,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3x 3090 running oss 120B in LM studio. With flash attention enabled and 32k context window I get 100 token/s prompt eval speed.&lt;/p&gt;\n\n&lt;p&gt;That seems terribly slow...what are you guys getting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjlvxo",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Only_Situation_4713",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjlvxo/slow_prompt_eval_oss_120b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjlvxo/slow_prompt_eval_oss_120b/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754527286,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey guys! You can now run OpenAI's gpt-oss-120b &amp; 20b open models locally with our [Unsloth](https://github.com/unslothai/unsloth) GGUFs! 🦥\n\nThe uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI's recent change to their chat template and our new fixes.\n\n* 20b GGUF: [https://huggingface.co/unsloth/gpt-oss-20b-GGUF](https://huggingface.co/unsloth/gpt-oss-20b-GGUF)\n* 120b GGUF: [https://huggingface.co/unsloth/gpt-oss-120b-GGUF](https://huggingface.co/unsloth/gpt-oss-120b-GGUF)\n\nYou can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp; 20b model on 14GB RAM/unified mem. Both will run at &gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.\n\nGuide to run model: [https://docs.unsloth.ai/basics/gpt-oss](https://docs.unsloth.ai/basics/gpt-oss)\n\n**Instructions**: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run\n\n    ./llama.cpp/llama-cli \\\n        -hf unsloth/gpt-oss-20b-GGUF:F16 \\\n        --jinja -ngl 99 --threads -1 --ctx-size 16384 \\\n        --temp 0.6 --top-p 1.0 --top-k 0\n\nOr Ollama:\n\n    ollama run hf.co/unsloth/gpt-oss-20b-GGUF\n\nTo run the **120B model** via llama.cpp:\n\n    ./llama.cpp/llama-cli \\\n        --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \\\n        --threads -1 \\\n        --ctx-size 16384 \\\n        --n-gpu-layers 99 \\\n        -ot \".ffn_.*_exps.=CPU\" \\\n        --temp 0.6 \\\n        --min-p 0.0 \\\n        --top-p 1.0 \\\n        --top-k 0.0 \\\n\nThanks for the support guys and happy running. 🥰\n\nFinetuning support coming soon (likely tomorrow)!",
          "author_fullname": "t2_5wukhd4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Run gpt-oss locally with Unsloth GGUFs + Fixes!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milkqp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 157,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 157,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/zPPlSmg4vBRTUG_cvJInG8onvJy3mjcTiitOisY7Wj8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428406,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! You can now run OpenAI&amp;#39;s gpt-oss-120b &amp;amp; 20b open models locally with our &lt;a href=\"https://github.com/unslothai/unsloth\"&gt;Unsloth&lt;/a&gt; GGUFs! 🦥&lt;/p&gt;\n\n&lt;p&gt;The uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI&amp;#39;s recent change to their chat template and our new fixes.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;20b GGUF: &lt;a href=\"https://huggingface.co/unsloth/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;120b GGUF: &lt;a href=\"https://huggingface.co/unsloth/gpt-oss-120b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-120b-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp;amp; 20b model on 14GB RAM/unified mem. Both will run at &amp;gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.&lt;/p&gt;\n\n&lt;p&gt;Guide to run model: &lt;a href=\"https://docs.unsloth.ai/basics/gpt-oss\"&gt;https://docs.unsloth.ai/basics/gpt-oss&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \\\n    -hf unsloth/gpt-oss-20b-GGUF:F16 \\\n    --jinja -ngl 99 --threads -1 --ctx-size 16384 \\\n    --temp 0.6 --top-p 1.0 --top-k 0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Or Ollama:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ollama run hf.co/unsloth/gpt-oss-20b-GGUF\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To run the &lt;strong&gt;120B model&lt;/strong&gt; via llama.cpp:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \\\n    --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \\\n    --threads -1 \\\n    --ctx-size 16384 \\\n    --n-gpu-layers 99 \\\n    -ot &amp;quot;.ffn_.*_exps.=CPU&amp;quot; \\\n    --temp 0.6 \\\n    --min-p 0.0 \\\n    --top-p 1.0 \\\n    --top-k 0.0 \\\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Thanks for the support guys and happy running. 🥰&lt;/p&gt;\n\n&lt;p&gt;Finetuning support coming soon (likely tomorrow)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/6s62jsx2o9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/6s62jsx2o9hf1.png?auto=webp&amp;s=c412cb62d534fd94a21e971e05062c2ca1d5130d",
                  "width": 2560,
                  "height": 2740
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e815bdf932294f33e187adf930d6da99b4dbd9d",
                    "width": 108,
                    "height": 115
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0936e565586e45c54c1b2808e296e0e5cd0878f2",
                    "width": 216,
                    "height": 231
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=894e81043bd4c71fdad40f23b8c89993b03f261b",
                    "width": 320,
                    "height": 342
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4a03b38836e71df4373dc670859d4fca8398ff1",
                    "width": 640,
                    "height": 685
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=46f698a73faf6edbcbabdc8ef7fe28a834246f0e",
                    "width": 960,
                    "height": 1027
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0efa5f3bdd3ba25dcb36d290a95bbeb1670ca74a",
                    "width": 1080,
                    "height": 1155
                  }
                ],
                "variants": {},
                "id": "cgDifyZFtbjbAPhmEKVZn1UiSMpgWQoUTWOijJXGf1w"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1milkqp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "danielhanchen",
          "discussion_type": null,
          "num_comments": 68,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/",
          "stickied": false,
          "url": "https://i.redd.it/6s62jsx2o9hf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754428406,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Please\n\n",
          "author_fullname": "t2_efuai1rs",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Somebody please make the pilgrim the official avatar of GPT-OSS",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mja01g",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.61,
          "author_flair_background_color": null,
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/q3WiZi1lPSGp8XeUbWbetxDDJId2nlout-YJCpwWr6U.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754499159,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/4dnchresifhf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/4dnchresifhf1.jpeg?auto=webp&amp;s=f5e8759dae09d5bb40145a11c3633a90bd732389",
                  "width": 500,
                  "height": 1124
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/4dnchresifhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=efed9cace505e6e1b8874c7c5a25eedab00278ab",
                    "width": 108,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/4dnchresifhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c512a1ef115c90b2c763afee60b7ccd0662049d",
                    "width": 216,
                    "height": 432
                  },
                  {
                    "url": "https://preview.redd.it/4dnchresifhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fbcdc790b74a6f87b865bfb70a53c3ed97565cde",
                    "width": 320,
                    "height": 640
                  }
                ],
                "variants": {},
                "id": "R729FnA5aPbGHX5Pjph_LqU3i70hyKQQhCgX4mr1Lx4"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mja01g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "TachiSommerfeld1970",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mja01g/somebody_please_make_the_pilgrim_the_official/",
          "stickied": false,
          "url": "https://i.redd.it/4dnchresifhf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754499159,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "A no non-sense, complete byte-pair encoding implementation, in python, completely from scratch.\n\n```py\n\"\"\"\n@file model.py\n@license cc-by-sa-nc-4.0\n@ref https://aclanthology.org/P16-1162/\n@ref https://huggingface.co/blog/catherinearnett/dangers-of-tokenizer-recycling\n\"\"\"\n\nimport argparse\nimport collections\nimport json\nimport math\n\n\nclass Corpus:\n    \"\"\"Load and initialize training data\"\"\"\n\n    @staticmethod\n    def default() -&gt; list[str]:\n        return [\"lo\", \"low\", \"lower\", \"newest\", \"wide\", \"wider\", \"widest\"]\n\n    @staticmethod\n    def read(path: str) -&gt; list[str]:\n        \"\"\"Load a flat list of words from a file, one per whitespace.\"\"\"\n        words = []\n        with open(path, \"r\") as file:\n            for line in file:\n                for word in line.split():\n                    words.append(word)\n        return words\n\n    @staticmethod\n    def words(path: str = None) -&gt; list[str]:\n        if path:\n            print(f\"Using corpus from file: {path}\")\n            return Corpus.read(path)\n        print(\"Using default corpus.\")\n        return Corpus.default()\n\n    @staticmethod\n    def vocab(path: str = None) -&gt; dict[str, int]:\n        \"\"\"Convert list of words into vocab dict: space-joined symbols -&gt; freq.\"\"\"\n        vocab = {}\n        for word in Corpus.words(path):\n            symbols = list(word)\n            vocab[\" \".join(symbols)] = 1\n        print(\"Initialized vocab:\")\n        print(json.dumps(vocab, indent=2))\n        return vocab\n\n\nclass Model:\n    \"\"\"Byte-pair Encoding\"\"\"\n\n    @staticmethod\n    def pairs(vocab: dict[str, int]) -&gt; dict[tuple[str, str], int]:\n        # print(\"Generating pairs:\")\n        pairs = collections.defaultdict(int)  # init freqs to 0\n        for word, freq in vocab.items():  # unpacks (\"l o w &lt;/w&gt;\", 5)\n            symbols = word.split()  # split word by char -&gt; [\"l\", \"o\", \"w\", ...]\n            for i in range(len(symbols) - 1):  # for each step in the set of symbols\n                cur = symbols[i]  # \"l\"\n                nxt = symbols[i + 1]  # \"o\"\n                pairs[cur, nxt] += freq  # p[(\"l\", \"o\")] += 1\n                # print(f\"i={i}, cur='{cur}', nxt='{nxt}', freq={freq}\")\n        return pairs  # {('l', 'o'): 1}\n\n    @staticmethod\n    def bigram(symbols: list[str], pair: tuple[str, str]) -&gt; list[str]:\n        bigram = []\n        i = 0\n        while i &lt; len(symbols):\n            # If this symbol and the next match the pair, merge them\n            if (\n                i &lt; len(symbols) - 1\n                and symbols[i] == pair[0]\n                and symbols[i + 1] == pair[1]\n            ):\n                bigram.append(symbols[i] + symbols[i + 1])\n                i += 2  # Skip the next symbol (it's merged)\n            else:\n                bigram.append(symbols[i])\n                i += 1\n        return bigram\n\n    @staticmethod\n    def merges(vocab: dict[str, int], pair: tuple[str, str]) -&gt; dict[str, int]:\n        # print(\"Updated pairs:\")\n        # print(json.dumps(vocab, indent=2))\n\n        new_vocab = {}  # new empty vocab\n        for word in vocab:  # for each pair in a given map\n            symbols = word.split()  # [\"l\", \"o\", \"w\", \"&lt;/w&gt;\"]\n            bigram = Model.bigram(symbols, pair)  # merge neighbors\n            new_word = \" \".join(bigram)  # new n-gram\n            # print(f\"word={word}, new_word={new_word}\")\n            new_vocab[new_word] = vocab[word]\n        return new_vocab\n\n\nclass Tokenizer:\n    def __init__(self, vocab: dict[str, int]):\n        self.model = {\n            \"type\": \"BPE\",\n            \"version\": \"0.1.0\",\n            \"vocab\": vocab,\n            \"merges\": [],\n        }\n\n    @property\n    def type(self) -&gt; str:\n        return self.model[\"type\"]\n\n    @property\n    def version(self) -&gt; str:\n        return self.model[\"version\"]\n\n    @property\n    def vocab(self) -&gt; dict[str, int]:\n        return self.model[\"vocab\"]\n\n    @vocab.setter\n    def vocab(self, value: dict[str, int]) -&gt; None:\n        self.model[\"vocab\"] = value\n\n    @property\n    def merges(self) -&gt; list[tuple[str, str]]:\n        return self.model[\"merges\"]\n\n    @merges.setter\n    def merges(self, value: list[tuple[str, str]]):\n        self.model[\"merges\"] = value\n\n    def train(self, num_merges: int) -&gt; None:\n        # Train vocab model (vocab is the set of all merges)\n        self.merges = []\n        for i in range(num_merges):\n            # pre-process merge pairs every cycle\n            pairs = Model.pairs(self.vocab)  # create pairs\n            if not pairs:  # bail if pairs is empty\n                print(f\"Exhausted all potential pairs! Halted at step {i}.\")\n                break\n            # use the highest ranked pair for the next merge cycle\n            best = max(pairs, key=pairs.get)  # get max rank\n            self.merges.append(best)\n            self.vocab = Model.merges(self.vocab, best)  # merge ranked pair\n\n    def save(self, path: str) -&gt; None:\n        with open(path, \"w\", encoding=\"utf-8\") as file:\n            json.dump(self.model, file, ensure_ascii=False, indent=2)\n\n    def load(self, path: str) -&gt; None:\n        with open(path, \"r\", encoding=\"utf-8\") as file:\n            self.model = json.load(file)\n\n    @property\n    def tokens(self) -&gt; list[str]:\n        # Collect All Unique Tokens\n        token_set = set()\n        for word in self.vocab:  # must be vocab!\n            for symbol in word.split():\n                token_set.add(symbol)\n        # Assign IDs in sorted order (order matters)\n        return sorted(list(token_set))\n\n    @property\n    def token_to_id(self) -&gt; dict[str, int]:\n        return {token: idx for idx, token in enumerate(self.tokens)}\n\n    @property\n    def id_to_token(self) -&gt; dict[int, str]:\n        return {idx: token for idx, token in enumerate(self.tokens)}\n\n    @property\n    def ranks(self) -&gt; dict[str, int]:\n        # Build the rank table (rank merges)\n        rank_table = {}\n        for i, pair in enumerate(self.merges):  # must be merges!\n            token = \"\".join(pair)\n            rank_table[token] = i\n        return rank_table\n\n    @property\n    def scores(self):\n        # Score the merges\n        scores = {}\n        for token in self.tokens:\n            rank = self.ranks.get(token)\n            scores[token] = -math.log(rank + 1) if rank else -1e6\n        return scores\n\n    def encode(self, token: str) -&gt; int:\n        return self.token_to_id[token]\n\n    def decode(self, id: int) -&gt; str:\n        return self.id_to_token[id]\n\n\ndef parse_args() -&gt; argparse.Namespace:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"-m\",\n        \"--merges\",\n        required=False,\n        type=int,\n        default=10,\n        help=\"number of merges\",\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--corpus\",\n        required=False,\n        type=str,\n        default=None,\n        help=\"input plaintext file\",\n    )\n    return parser.parse_args()\n\n\nif __name__ == \"__main__\":\n    args = parse_args()\n\n    # Get number of merges (training cycles)\n    num_merges = int(args.merges)\n\n    # Get words from corpus (training data)\n    vocab = Corpus.vocab(args.corpus)\n\n    # Train vocab model (vocab is the set of all merges)\n    tokenizer = Tokenizer(vocab)\n    tokenizer.train(args.merges)\n\n    # Print vocab training results (dump merges)\n    print(\"Merge Table:\")\n    print(json.dumps(tokenizer.merges, indent=2))\n\n    print(\"Final Vocab:\")\n    print(json.dumps(tokenizer.vocab, indent=2))\n\n    print(\"Tokenizer:\")\n    print(json.dumps(tokenizer.token_to_id, indent=2))\n\n    # Build the rank table (rank merges)\n    print(\"Rank Table:\")\n    print(json.dumps(tokenizer.ranks, indent=2))\n\n    # Score the merges\n    print(\"Token Scores:\")\n    print(json.dumps(tokenizer.scores, indent=2))\n```\n\n- Used the original NMT paper as a core reference.\n- Zero dependencies.\n- Accepts plain-text input.\n- Stateful memory and disk ops.\n- Single-threaded.\n- Extensible.\n\nIt's dead simple, to the point, and - most importantly - legible. Excellent for learning and comprehension.\n\nI genuinely don't understand why implementations are so convoluted when it's only 250 lines of code.\n\nThe is the models voice box. A model \"learns\" from human created data as its input. It then converges towards the most common patterns during back-propagation.\n\nWithout a solid tokenizer, it's garbage in and garbage out. This is, of course, a single piece of a much bigger puzzle.\n\nI'm very interested in doing this for graphemes. And of course, there's a paper and repository on this as well.\n\n- https://aclanthology.org/2025.coling-main.400\n\nI am not affiliated with any of these authors, papers, orgs, etc. I'm just a dude trying to figure this stuff out. I love tinkering and understanding how things work at a fundamental level.\n\nThe internet is becoming a scary place, so stay safe out there, and keep your personal data close to your vest. Things are just starting heat up.",
          "author_fullname": "t2_slcrtxpr",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Vox Populi",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mjlg5q",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754526096,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A no non-sense, complete byte-pair encoding implementation, in python, completely from scratch.&lt;/p&gt;\n\n&lt;p&gt;```py\n&amp;quot;&amp;quot;&amp;quot;\n@file model.py\n@license cc-by-sa-nc-4.0\n@ref &lt;a href=\"https://aclanthology.org/P16-1162/\"&gt;https://aclanthology.org/P16-1162/&lt;/a&gt;\n@ref &lt;a href=\"https://huggingface.co/blog/catherinearnett/dangers-of-tokenizer-recycling\"&gt;https://huggingface.co/blog/catherinearnett/dangers-of-tokenizer-recycling&lt;/a&gt;\n&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;import argparse\nimport collections\nimport json\nimport math&lt;/p&gt;\n\n&lt;p&gt;class Corpus:\n    &amp;quot;&amp;quot;&amp;quot;Load and initialize training data&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@staticmethod\ndef default() -&amp;gt; list[str]:\n    return [&amp;quot;lo&amp;quot;, &amp;quot;low&amp;quot;, &amp;quot;lower&amp;quot;, &amp;quot;newest&amp;quot;, &amp;quot;wide&amp;quot;, &amp;quot;wider&amp;quot;, &amp;quot;widest&amp;quot;]\n\n@staticmethod\ndef read(path: str) -&amp;gt; list[str]:\n    &amp;quot;&amp;quot;&amp;quot;Load a flat list of words from a file, one per whitespace.&amp;quot;&amp;quot;&amp;quot;\n    words = []\n    with open(path, &amp;quot;r&amp;quot;) as file:\n        for line in file:\n            for word in line.split():\n                words.append(word)\n    return words\n\n@staticmethod\ndef words(path: str = None) -&amp;gt; list[str]:\n    if path:\n        print(f&amp;quot;Using corpus from file: {path}&amp;quot;)\n        return Corpus.read(path)\n    print(&amp;quot;Using default corpus.&amp;quot;)\n    return Corpus.default()\n\n@staticmethod\ndef vocab(path: str = None) -&amp;gt; dict[str, int]:\n    &amp;quot;&amp;quot;&amp;quot;Convert list of words into vocab dict: space-joined symbols -&amp;gt; freq.&amp;quot;&amp;quot;&amp;quot;\n    vocab = {}\n    for word in Corpus.words(path):\n        symbols = list(word)\n        vocab[&amp;quot; &amp;quot;.join(symbols)] = 1\n    print(&amp;quot;Initialized vocab:&amp;quot;)\n    print(json.dumps(vocab, indent=2))\n    return vocab\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;class Model:\n    &amp;quot;&amp;quot;&amp;quot;Byte-pair Encoding&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@staticmethod\ndef pairs(vocab: dict[str, int]) -&amp;gt; dict[tuple[str, str], int]:\n    # print(&amp;quot;Generating pairs:&amp;quot;)\n    pairs = collections.defaultdict(int)  # init freqs to 0\n    for word, freq in vocab.items():  # unpacks (&amp;quot;l o w &amp;lt;/w&amp;gt;&amp;quot;, 5)\n        symbols = word.split()  # split word by char -&amp;gt; [&amp;quot;l&amp;quot;, &amp;quot;o&amp;quot;, &amp;quot;w&amp;quot;, ...]\n        for i in range(len(symbols) - 1):  # for each step in the set of symbols\n            cur = symbols[i]  # &amp;quot;l&amp;quot;\n            nxt = symbols[i + 1]  # &amp;quot;o&amp;quot;\n            pairs[cur, nxt] += freq  # p[(&amp;quot;l&amp;quot;, &amp;quot;o&amp;quot;)] += 1\n            # print(f&amp;quot;i={i}, cur=&amp;#39;{cur}&amp;#39;, nxt=&amp;#39;{nxt}&amp;#39;, freq={freq}&amp;quot;)\n    return pairs  # {(&amp;#39;l&amp;#39;, &amp;#39;o&amp;#39;): 1}\n\n@staticmethod\ndef bigram(symbols: list[str], pair: tuple[str, str]) -&amp;gt; list[str]:\n    bigram = []\n    i = 0\n    while i &amp;lt; len(symbols):\n        # If this symbol and the next match the pair, merge them\n        if (\n            i &amp;lt; len(symbols) - 1\n            and symbols[i] == pair[0]\n            and symbols[i + 1] == pair[1]\n        ):\n            bigram.append(symbols[i] + symbols[i + 1])\n            i += 2  # Skip the next symbol (it&amp;#39;s merged)\n        else:\n            bigram.append(symbols[i])\n            i += 1\n    return bigram\n\n@staticmethod\ndef merges(vocab: dict[str, int], pair: tuple[str, str]) -&amp;gt; dict[str, int]:\n    # print(&amp;quot;Updated pairs:&amp;quot;)\n    # print(json.dumps(vocab, indent=2))\n\n    new_vocab = {}  # new empty vocab\n    for word in vocab:  # for each pair in a given map\n        symbols = word.split()  # [&amp;quot;l&amp;quot;, &amp;quot;o&amp;quot;, &amp;quot;w&amp;quot;, &amp;quot;&amp;lt;/w&amp;gt;&amp;quot;]\n        bigram = Model.bigram(symbols, pair)  # merge neighbors\n        new_word = &amp;quot; &amp;quot;.join(bigram)  # new n-gram\n        # print(f&amp;quot;word={word}, new_word={new_word}&amp;quot;)\n        new_vocab[new_word] = vocab[word]\n    return new_vocab\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;class Tokenizer:\n    def &lt;strong&gt;init&lt;/strong&gt;(self, vocab: dict[str, int]):\n        self.model = {\n            &amp;quot;type&amp;quot;: &amp;quot;BPE&amp;quot;,\n            &amp;quot;version&amp;quot;: &amp;quot;0.1.0&amp;quot;,\n            &amp;quot;vocab&amp;quot;: vocab,\n            &amp;quot;merges&amp;quot;: [],\n        }&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@property\ndef type(self) -&amp;gt; str:\n    return self.model[&amp;quot;type&amp;quot;]\n\n@property\ndef version(self) -&amp;gt; str:\n    return self.model[&amp;quot;version&amp;quot;]\n\n@property\ndef vocab(self) -&amp;gt; dict[str, int]:\n    return self.model[&amp;quot;vocab&amp;quot;]\n\n@vocab.setter\ndef vocab(self, value: dict[str, int]) -&amp;gt; None:\n    self.model[&amp;quot;vocab&amp;quot;] = value\n\n@property\ndef merges(self) -&amp;gt; list[tuple[str, str]]:\n    return self.model[&amp;quot;merges&amp;quot;]\n\n@merges.setter\ndef merges(self, value: list[tuple[str, str]]):\n    self.model[&amp;quot;merges&amp;quot;] = value\n\ndef train(self, num_merges: int) -&amp;gt; None:\n    # Train vocab model (vocab is the set of all merges)\n    self.merges = []\n    for i in range(num_merges):\n        # pre-process merge pairs every cycle\n        pairs = Model.pairs(self.vocab)  # create pairs\n        if not pairs:  # bail if pairs is empty\n            print(f&amp;quot;Exhausted all potential pairs! Halted at step {i}.&amp;quot;)\n            break\n        # use the highest ranked pair for the next merge cycle\n        best = max(pairs, key=pairs.get)  # get max rank\n        self.merges.append(best)\n        self.vocab = Model.merges(self.vocab, best)  # merge ranked pair\n\ndef save(self, path: str) -&amp;gt; None:\n    with open(path, &amp;quot;w&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as file:\n        json.dump(self.model, file, ensure_ascii=False, indent=2)\n\ndef load(self, path: str) -&amp;gt; None:\n    with open(path, &amp;quot;r&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as file:\n        self.model = json.load(file)\n\n@property\ndef tokens(self) -&amp;gt; list[str]:\n    # Collect All Unique Tokens\n    token_set = set()\n    for word in self.vocab:  # must be vocab!\n        for symbol in word.split():\n            token_set.add(symbol)\n    # Assign IDs in sorted order (order matters)\n    return sorted(list(token_set))\n\n@property\ndef token_to_id(self) -&amp;gt; dict[str, int]:\n    return {token: idx for idx, token in enumerate(self.tokens)}\n\n@property\ndef id_to_token(self) -&amp;gt; dict[int, str]:\n    return {idx: token for idx, token in enumerate(self.tokens)}\n\n@property\ndef ranks(self) -&amp;gt; dict[str, int]:\n    # Build the rank table (rank merges)\n    rank_table = {}\n    for i, pair in enumerate(self.merges):  # must be merges!\n        token = &amp;quot;&amp;quot;.join(pair)\n        rank_table[token] = i\n    return rank_table\n\n@property\ndef scores(self):\n    # Score the merges\n    scores = {}\n    for token in self.tokens:\n        rank = self.ranks.get(token)\n        scores[token] = -math.log(rank + 1) if rank else -1e6\n    return scores\n\ndef encode(self, token: str) -&amp;gt; int:\n    return self.token_to_id[token]\n\ndef decode(self, id: int) -&amp;gt; str:\n    return self.id_to_token[id]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;def parse_args() -&amp;gt; argparse.Namespace:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        &amp;quot;-m&amp;quot;,\n        &amp;quot;--merges&amp;quot;,\n        required=False,\n        type=int,\n        default=10,\n        help=&amp;quot;number of merges&amp;quot;,\n    )\n    parser.add_argument(\n        &amp;quot;-c&amp;quot;,\n        &amp;quot;--corpus&amp;quot;,\n        required=False,\n        type=str,\n        default=None,\n        help=&amp;quot;input plaintext file&amp;quot;,\n    )\n    return parser.parse_args()&lt;/p&gt;\n\n&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;quot;&lt;strong&gt;main&lt;/strong&gt;&amp;quot;:\n    args = parse_args()&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;# Get number of merges (training cycles)\nnum_merges = int(args.merges)\n\n# Get words from corpus (training data)\nvocab = Corpus.vocab(args.corpus)\n\n# Train vocab model (vocab is the set of all merges)\ntokenizer = Tokenizer(vocab)\ntokenizer.train(args.merges)\n\n# Print vocab training results (dump merges)\nprint(&amp;quot;Merge Table:&amp;quot;)\nprint(json.dumps(tokenizer.merges, indent=2))\n\nprint(&amp;quot;Final Vocab:&amp;quot;)\nprint(json.dumps(tokenizer.vocab, indent=2))\n\nprint(&amp;quot;Tokenizer:&amp;quot;)\nprint(json.dumps(tokenizer.token_to_id, indent=2))\n\n# Build the rank table (rank merges)\nprint(&amp;quot;Rank Table:&amp;quot;)\nprint(json.dumps(tokenizer.ranks, indent=2))\n\n# Score the merges\nprint(&amp;quot;Token Scores:&amp;quot;)\nprint(json.dumps(tokenizer.scores, indent=2))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Used the original NMT paper as a core reference.&lt;/li&gt;\n&lt;li&gt;Zero dependencies.&lt;/li&gt;\n&lt;li&gt;Accepts plain-text input.&lt;/li&gt;\n&lt;li&gt;Stateful memory and disk ops.&lt;/li&gt;\n&lt;li&gt;Single-threaded.&lt;/li&gt;\n&lt;li&gt;Extensible.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It&amp;#39;s dead simple, to the point, and - most importantly - legible. Excellent for learning and comprehension.&lt;/p&gt;\n\n&lt;p&gt;I genuinely don&amp;#39;t understand why implementations are so convoluted when it&amp;#39;s only 250 lines of code.&lt;/p&gt;\n\n&lt;p&gt;The is the models voice box. A model &amp;quot;learns&amp;quot; from human created data as its input. It then converges towards the most common patterns during back-propagation.&lt;/p&gt;\n\n&lt;p&gt;Without a solid tokenizer, it&amp;#39;s garbage in and garbage out. This is, of course, a single piece of a much bigger puzzle.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very interested in doing this for graphemes. And of course, there&amp;#39;s a paper and repository on this as well.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://aclanthology.org/2025.coling-main.400\"&gt;https://aclanthology.org/2025.coling-main.400&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am not affiliated with any of these authors, papers, orgs, etc. I&amp;#39;m just a dude trying to figure this stuff out. I love tinkering and understanding how things work at a fundamental level.&lt;/p&gt;\n\n&lt;p&gt;The internet is becoming a scary place, so stay safe out there, and keep your personal data close to your vest. Things are just starting heat up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/L81qrCmFWubZLxbfuNvtP_7zU12CPJQyAt_EVX5uFnY.jpeg?auto=webp&amp;s=e6db33843099d99dba5c7ea4c05b57efab76d21a",
                  "width": 600,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/L81qrCmFWubZLxbfuNvtP_7zU12CPJQyAt_EVX5uFnY.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1410c1e7e9cb4ef838128bfdf9421febd66849c6",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/L81qrCmFWubZLxbfuNvtP_7zU12CPJQyAt_EVX5uFnY.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bdad77b771381495eba98ab1fd8af71cd545883b",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://external-preview.redd.it/L81qrCmFWubZLxbfuNvtP_7zU12CPJQyAt_EVX5uFnY.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=99f54072c9e69c278627c03b6fad54b0e37a0d2b",
                    "width": 320,
                    "height": 320
                  }
                ],
                "variants": {},
                "id": "L81qrCmFWubZLxbfuNvtP_7zU12CPJQyAt_EVX5uFnY"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mjlg5q",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "teleprint-me",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjlg5q/vox_populi/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjlg5q/vox_populi/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754526096,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi all,\n\nI've hit my usage limit again for Claude Code, and it's time to switch to OpenCode with the newest Qwen model. I plan to generate many, many millions of tokens - working on an app to gamify the creation of RL environments (think GMod, but you come out of it with a working robot).  \n  \nWhat is the most economical way to do this? From what I hear, the newest Qwen model has hit the threshold of being sufficient at tool usage and code output quality, so that is the model I plan on using but I am open to suggestions.\n\nThanks for reading!",
          "author_fullname": "t2_c0jhbv85",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenRouter vs Lambda: Which is more economical for millions of tokens on the newest Qwen coder model?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjc4kb",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754503923,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve hit my usage limit again for Claude Code, and it&amp;#39;s time to switch to OpenCode with the newest Qwen model. I plan to generate many, many millions of tokens - working on an app to gamify the creation of RL environments (think GMod, but you come out of it with a working robot).  &lt;/p&gt;\n\n&lt;p&gt;What is the most economical way to do this? From what I hear, the newest Qwen model has hit the threshold of being sufficient at tool usage and code output quality, so that is the model I plan on using but I am open to suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjc4kb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ImpressiveSir9769",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754503923,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "**CodeFu** learned competitive programming from execution outcomes - no ground truth solutions were given during training. The results are encouraging:\n\n* 13.7% Pass@1 on USA Computing Olympiad benchmark \n* Outperforms models 4x larger \n* 10x improvement over its base model\n\nBuilt on DeepSeek-R1-Distill-Qwen-7B, CodeFu shows how effective RL training can achieve 10x improvements - jumping from 1% to 13.7%. This required overcoming several training stability challenges, including response length and reward collapse during hard problem training.\n\nThe training pipeline uses Ray-orchestrated distributed training on SageMaker Training Jobs to handle resource-intensive RL rollouts and code compilation/execution.\n\nTraining approach is detailed on the HF [model card](https://huggingface.co/aws-prototyping/codefu-7b-v0.1) page.\n\nhttps://preview.redd.it/6b56c57rqehf1.png?width=1276&amp;format=png&amp;auto=webp&amp;s=bbd6291e8e6e10f2cb23edcf95187459472c97f4\n\n  \n",
          "author_fullname": "t2_7r6ablum",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "CodeFu-7B-v0.1 - a Reinforcement Learning (RL)-trained 7B model for Competitive Programming",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "6b56c57rqehf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 57,
                  "x": 108,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8351a17038999ca8164bddded350c2b142b778b4"
                },
                {
                  "y": 114,
                  "x": 216,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f89273ebab4331cd2cc5f63bf38b84a54bd16c5"
                },
                {
                  "y": 169,
                  "x": 320,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=128aeeb51ae9ad3e5182f45f85428c178ccb15c0"
                },
                {
                  "y": 339,
                  "x": 640,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=497a3dde0f845dc87d6d4bb1ca57e024d8548935"
                },
                {
                  "y": 508,
                  "x": 960,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc8834c7f32057adc3d4a8183a60d065e4795b22"
                },
                {
                  "y": 572,
                  "x": 1080,
                  "u": "https://preview.redd.it/6b56c57rqehf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a979d688e5c0226bae19ed416418f33b0551aaf6"
                }
              ],
              "s": {
                "y": 676,
                "x": 1276,
                "u": "https://preview.redd.it/6b56c57rqehf1.png?width=1276&amp;format=png&amp;auto=webp&amp;s=bbd6291e8e6e10f2cb23edcf95187459472c97f4"
              },
              "id": "6b56c57rqehf1"
            }
          },
          "name": "t3_1mj5xuw",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=c01ca64ac1831d7bb5f52a7511846b47a1e83ab8",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1754489962,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;CodeFu&lt;/strong&gt; learned competitive programming from execution outcomes - no ground truth solutions were given during training. The results are encouraging:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;13.7% Pass@1 on USA Computing Olympiad benchmark &lt;/li&gt;\n&lt;li&gt;Outperforms models 4x larger &lt;/li&gt;\n&lt;li&gt;10x improvement over its base model&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Built on DeepSeek-R1-Distill-Qwen-7B, CodeFu shows how effective RL training can achieve 10x improvements - jumping from 1% to 13.7%. This required overcoming several training stability challenges, including response length and reward collapse during hard problem training.&lt;/p&gt;\n\n&lt;p&gt;The training pipeline uses Ray-orchestrated distributed training on SageMaker Training Jobs to handle resource-intensive RL rollouts and code compilation/execution.&lt;/p&gt;\n\n&lt;p&gt;Training approach is detailed on the HF &lt;a href=\"https://huggingface.co/aws-prototyping/codefu-7b-v0.1\"&gt;model card&lt;/a&gt; page.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6b56c57rqehf1.png?width=1276&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbd6291e8e6e10f2cb23edcf95187459472c97f4\"&gt;https://preview.redd.it/6b56c57rqehf1.png?width=1276&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bbd6291e8e6e10f2cb23edcf95187459472c97f4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?auto=webp&amp;s=a8982db3a47f9f2b857f0c7d51fb24956db2a363",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f52fb4b533f9cd10ae971b52bbd71708b64e883",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=293956d9375e572f75ba6948d8af41d2b6f2452a",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b4aa6119b64cb150fabce0431391c649e953135d",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cb960069c047d2606ddccbce9a7f76f0ad921322",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b431b23d1d40bdbcfda257aac42c14e08c66dee0",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b196c4345b25e1673734d41898564ba232b7ee3",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "zgW6HTBpLc8d_FUSPNpLKbimBYooh1wT1-1dC31nLgY"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mj5xuw",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Live_Area_2746",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mj5xuw/codefu7bv01_a_reinforcement_learning_rltrained_7b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj5xuw/codefu7bv01_a_reinforcement_learning_rltrained_7b/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754489962,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/6ukj8h9fqchf1.png?width=1420&amp;format=png&amp;auto=webp&amp;s=0e9fc50915cf1d72c4d3d01ecd3a5291f9792462\n\nit could have just answered:  \n\"steal\" sea water. wait for it to dry. that's it.",
          "author_fullname": "t2_ik8czvp65",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "openai model is a bit too safe",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 79,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "6ukj8h9fqchf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 61,
                  "x": 108,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=27bd75693b849a4db58794f7391e2673ed45587b"
                },
                {
                  "y": 122,
                  "x": 216,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=54d0895503b1f62c0c3ef115000c17cb7239843a"
                },
                {
                  "y": 181,
                  "x": 320,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=06995b0f064bd48a384ca7473b50985bb01d6675"
                },
                {
                  "y": 363,
                  "x": 640,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e15e3a6dcbeabae1d7e6df07fc068c63f991b25"
                },
                {
                  "y": 545,
                  "x": 960,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4ae25288e91b808d7d1f8c05efb8d4757d1af2f5"
                },
                {
                  "y": 613,
                  "x": 1080,
                  "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=827c9a959e584f15ac43d2ffefdbae783e77b0f4"
                }
              ],
              "s": {
                "y": 807,
                "x": 1420,
                "u": "https://preview.redd.it/6ukj8h9fqchf1.png?width=1420&amp;format=png&amp;auto=webp&amp;s=0e9fc50915cf1d72c4d3d01ecd3a5291f9792462"
              },
              "id": "6ukj8h9fqchf1"
            }
          },
          "name": "t3_1miy8ni",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.7,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 26,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 26,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/Xumbhwt98LxRMgZPwdNXRzRJMqX72yhz_RRCHDCsDv8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754465453,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/6ukj8h9fqchf1.png?width=1420&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e9fc50915cf1d72c4d3d01ecd3a5291f9792462\"&gt;https://preview.redd.it/6ukj8h9fqchf1.png?width=1420&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e9fc50915cf1d72c4d3d01ecd3a5291f9792462&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it could have just answered:&lt;br/&gt;\n&amp;quot;steal&amp;quot; sea water. wait for it to dry. that&amp;#39;s it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miy8ni",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Sicarius_The_First",
          "discussion_type": null,
          "num_comments": 37,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miy8ni/openai_model_is_a_bit_too_safe/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miy8ni/openai_model_is_a_bit_too_safe/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754465453,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "because this is almost merged [https://github.com/ggml-org/llama.cpp/pull/15091](https://github.com/ggml-org/llama.cpp/pull/15091)",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS today?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 71,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1midi67",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": "#bbbdbf",
          "ups": 343,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 343,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/rWsT_DTXjma-FsqHb3ZPqeOxaWp6ibEhmZlicqBnNIw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754410494,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;because this is almost merged &lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091\"&gt;https://github.com/ggml-org/llama.cpp/pull/15091&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/2br9oi8178hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/2br9oi8178hf1.png?auto=webp&amp;s=1e7805788444e59781ff93284c63bb4e01a54742",
                  "width": 1212,
                  "height": 622
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8743b46eb33077e121abc8ff636f8ec7cb342be9",
                    "width": 108,
                    "height": 55
                  },
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c8deb0e0f24a5d37d2c3ee9e93e2390a3514719",
                    "width": 216,
                    "height": 110
                  },
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9c67123a99b696985ee836a91058d25c2a7ac7d",
                    "width": 320,
                    "height": 164
                  },
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=20cd517e2220fa7745b9e909a9f4bfcf589d5f03",
                    "width": 640,
                    "height": 328
                  },
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7ac80346792dfcc859d70bb73e4c7f00f4731387",
                    "width": 960,
                    "height": 492
                  },
                  {
                    "url": "https://preview.redd.it/2br9oi8178hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9428910dbc1d7e12a6d6995d4c304729280530ed",
                    "width": 1080,
                    "height": 554
                  }
                ],
                "variants": {},
                "id": "2bbvgtLr_--LF8ZbLAklwJGWtil3xpMgUZbjdC26W-k"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1midi67",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 78,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1midi67/gptoss_today/",
          "stickied": false,
          "url": "https://i.redd.it/2br9oi8178hf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754410494,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I am not able to get the thinking mode of cogito v2 working in openwebui. I am using llama.cpp server. I tried using the chat template and modify it by changing {%- set enable\\_thinking = false %} to {%- set enable\\_thinking = true %}. But this results in a thinking which is not recognized by openwebui. Thus the thinking is shown as part of the answer. The documentation also mention to prefill the response with &lt;think&gt;, but I have not found out how to do that. Can anybody help?",
          "author_fullname": "t2_6z7m9i7r",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How do I get cogito v2 to work in thinking mode in openwebui?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjf58p",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754510767,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not able to get the thinking mode of cogito v2 working in openwebui. I am using llama.cpp server. I tried using the chat template and modify it by changing {%- set enable_thinking = false %} to {%- set enable_thinking = true %}. But this results in a thinking which is not recognized by openwebui. Thus the thinking is shown as part of the answer. The documentation also mention to prefill the response with &amp;lt;think&amp;gt;, but I have not found out how to do that. Can anybody help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjf58p",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "erazortt",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjf58p/how_do_i_get_cogito_v2_to_work_in_thinking_mode/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjf58p/how_do_i_get_cogito_v2_to_work_in_thinking_mode/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754510767,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1urjd1hc7b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Am i the only one seeing it this way ?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mihfp7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.81,
          "author_flair_background_color": null,
          "ups": 218,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 218,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/103xh0pWdv2S5AIpPLKAM78C_7-7vgNodsPwhHF6n6o.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754419086,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/e8eauyilw8hf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/e8eauyilw8hf1.jpeg?auto=webp&amp;s=584a1afc50c5a895db2139f01571bd52b76aa34c",
                  "width": 500,
                  "height": 531
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/e8eauyilw8hf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=875683a503155088f908eacc076e24c6b6ff4e3d",
                    "width": 108,
                    "height": 114
                  },
                  {
                    "url": "https://preview.redd.it/e8eauyilw8hf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5f5a996adf2301165585afb67072ec62182a783",
                    "width": 216,
                    "height": 229
                  },
                  {
                    "url": "https://preview.redd.it/e8eauyilw8hf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc7e2a6e64c3c38ddae74650deab4d5b10f30cb3",
                    "width": 320,
                    "height": 339
                  }
                ],
                "variants": {},
                "id": "hE2XTZnWQu4kWRqyOYiPDCGLq472RFb6r6S_RFcdsX8"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mihfp7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Severe-Awareness829",
          "discussion_type": null,
          "num_comments": 35,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mihfp7/am_i_the_only_one_seeing_it_this_way/",
          "stickied": false,
          "url": "https://i.redd.it/e8eauyilw8hf1.jpeg",
          "subreddit_subscribers": 512425,
          "created_utc": 1754419086,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Sorry for weird title, I'm using llama 3.1 8b instruct (Q8) for text analysis on some call transcripts, sentiment/topic identification (specific categories).\n\nConsidering llama is old, and a bit lower on reasoning, what alternative would u suggest? \n\nSorry again if it's a really noob question ",
          "author_fullname": "t2_1t2iejzeto",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "*Noob question*- running a single L4, text analysis, llama 3.1 8b-it, looking to upgrade",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjept0",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754509792,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for weird title, I&amp;#39;m using llama 3.1 8b instruct (Q8) for text analysis on some call transcripts, sentiment/topic identification (specific categories).&lt;/p&gt;\n\n&lt;p&gt;Considering llama is old, and a bit lower on reasoning, what alternative would u suggest? &lt;/p&gt;\n\n&lt;p&gt;Sorry again if it&amp;#39;s a really noob question &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjept0",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "llm_pirate",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjept0/noob_question_running_a_single_l4_text_analysis/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjept0/noob_question_running_a_single_l4_text_analysis/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754509792,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "If I want to be able to RAG downloaded files and search the web to kind of maximize simple qa scores as a researcher. What models and ecosystems would support this best?",
          "author_fullname": "t2_gem8t",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What is the best Local Setup for Research?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjeopa",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754509722,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I want to be able to RAG downloaded files and search the web to kind of maximize simple qa scores as a researcher. What models and ecosystems would support this best?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjeopa",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Loighic",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjeopa/what_is_the_best_local_setup_for_research/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjeopa/what_is_the_best_local_setup_for_research/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754509722,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I need to run a local embedding model, I know there's a MTEB to find good open source embedding models, but not sure if there's any advice on specialized models or special configurations in llama.cpp to make them optimal.",
          "author_fullname": "t2_opo23",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Does anyone know if the same rules apply to embedding models with q4 being \"good enough\" in general?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mjk5l5",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754522714,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to run a local embedding model, I know there&amp;#39;s a MTEB to find good open source embedding models, but not sure if there&amp;#39;s any advice on specialized models or special configurations in llama.cpp to make them optimal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjk5l5",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "richardanaya",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjk5l5/does_anyone_know_if_the_same_rules_apply_to/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjk5l5/does_anyone_know_if_the_same_rules_apply_to/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754522714,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Here is a table I put together:\n\n| Benchmark | DeepSeek-R1 | DeepSeek-R1-0528 | GPT-OSS-20B | GPT-OSS-120B |\n|-----------|-------------|------------------|-------------|--------------|\n| **GPQA Diamond** | 71.5 | 81.0 | 71.5 | 80.1 |\n| **Humanity's Last Exam** | 8.5 | 17.7 | 17.3 | 19.0 |\n| **AIME 2024** | 79.8 | 91.4 | 96.0 | 96.6 |\n| **AIME 2025** | 70.0 | 87.5 | 98.7 | 97.9 |\n| **Average** | **57.5** | **69.4** | **70.9** | **73.4** |\n\nbased on\n\nhttps://openai.com/open-models/\n\nhttps://huggingface.co/deepseek-ai/DeepSeek-R1-0528\n\n-----\n\nHere is the table without AIME, as some have pointed out the GPT-OSS benchmarks used tools while the DeepSeek ones did not:\n\n| Benchmark | DeepSeek-R1 | DeepSeek-R1-0528 | GPT-OSS-20B | GPT-OSS-120B |\n|-----------|-------------|------------------|-------------|--------------|\n| **GPQA Diamond** | 71.5 | 81.0 | 71.5 | 80.1 |\n| **Humanity's Last Exam** | 8.5 | 17.7 | 17.3 | 19.0 |\n| **Average** | **40.0** | **49.4** | **44.4** | **49.6** |\n\n----\n\n# EDIT: After testing this model on my private benchmark, I'm confident it's nowhere near the quality of DeepSeek-R1.\n\nhttps://oobabooga.github.io/benchmark.html",
          "author_fullname": "t2_d0cgv68mn",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-120b outperforms DeepSeek-R1-0528 in benchmarks",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mifuqk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.85,
          "author_flair_background_color": "#5a74cc",
          "subreddit_type": "public",
          "ups": 273,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "b1184578-c910-11ed-a9d1-9ac6a8b97878",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 273,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754503362,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "Web UI Developer"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754415656,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is a table I put together:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Benchmark&lt;/th&gt;\n&lt;th&gt;DeepSeek-R1&lt;/th&gt;\n&lt;th&gt;DeepSeek-R1-0528&lt;/th&gt;\n&lt;th&gt;GPT-OSS-20B&lt;/th&gt;\n&lt;th&gt;GPT-OSS-120B&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;GPQA Diamond&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;71.5&lt;/td&gt;\n&lt;td&gt;81.0&lt;/td&gt;\n&lt;td&gt;71.5&lt;/td&gt;\n&lt;td&gt;80.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;Humanity&amp;#39;s Last Exam&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;8.5&lt;/td&gt;\n&lt;td&gt;17.7&lt;/td&gt;\n&lt;td&gt;17.3&lt;/td&gt;\n&lt;td&gt;19.0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;AIME 2024&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;79.8&lt;/td&gt;\n&lt;td&gt;91.4&lt;/td&gt;\n&lt;td&gt;96.0&lt;/td&gt;\n&lt;td&gt;96.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;AIME 2025&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;70.0&lt;/td&gt;\n&lt;td&gt;87.5&lt;/td&gt;\n&lt;td&gt;98.7&lt;/td&gt;\n&lt;td&gt;97.9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;57.5&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;69.4&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;70.9&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;73.4&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;based on&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://openai.com/open-models/\"&gt;https://openai.com/open-models/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528\"&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Here is the table without AIME, as some have pointed out the GPT-OSS benchmarks used tools while the DeepSeek ones did not:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Benchmark&lt;/th&gt;\n&lt;th&gt;DeepSeek-R1&lt;/th&gt;\n&lt;th&gt;DeepSeek-R1-0528&lt;/th&gt;\n&lt;th&gt;GPT-OSS-20B&lt;/th&gt;\n&lt;th&gt;GPT-OSS-120B&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;GPQA Diamond&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;71.5&lt;/td&gt;\n&lt;td&gt;81.0&lt;/td&gt;\n&lt;td&gt;71.5&lt;/td&gt;\n&lt;td&gt;80.1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;Humanity&amp;#39;s Last Exam&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;8.5&lt;/td&gt;\n&lt;td&gt;17.7&lt;/td&gt;\n&lt;td&gt;17.3&lt;/td&gt;\n&lt;td&gt;19.0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;strong&gt;Average&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;40.0&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;49.4&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;44.4&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;49.6&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;hr/&gt;\n\n&lt;h1&gt;EDIT: After testing this model on my private benchmark, I&amp;#39;m confident it&amp;#39;s nowhere near the quality of DeepSeek-R1.&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://oobabooga.github.io/benchmark.html\"&gt;https://oobabooga.github.io/benchmark.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "Web UI Developer",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mifuqk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "oobabooga4",
          "discussion_type": null,
          "num_comments": 89,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mifuqk/gptoss120b_outperforms_deepseekr10528_in/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mifuqk/gptoss120b_outperforms_deepseekr10528_in/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754415656,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "With the release of [gpt-oss](https://ollama.com/library/gpt-oss), is there a way/guide to setup and run copilot, particularly agent mode on macbook pro m4 as if you run it with paid version of o4 mini.",
          "author_fullname": "t2_4okn1kud",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Copilot Agent Mode with any reasonable local LLM that's on par with o4 mini",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mje4dm",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754508406,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the release of &lt;a href=\"https://ollama.com/library/gpt-oss\"&gt;gpt-oss&lt;/a&gt;, is there a way/guide to setup and run copilot, particularly agent mode on macbook pro m4 as if you run it with paid version of o4 mini.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?auto=webp&amp;s=a080c4707584d3aa14134960cda9ba2d339b93a3",
                  "width": 1200,
                  "height": 630
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3dc759de0e8fa36d241c5728d41ee3cf022cab96",
                    "width": 108,
                    "height": 56
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ccf136f5d3091254a0067a3bc5d6c7df9d62d89",
                    "width": 216,
                    "height": 113
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2530aa4ecbcf7899ec0d023e217fe24af15fe0a6",
                    "width": 320,
                    "height": 168
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e51add1cab39c7614eb13e6195f23c5b4eeb417",
                    "width": 640,
                    "height": 336
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=750a6d42fd91c5a6e9a9c069e74247c877644e97",
                    "width": 960,
                    "height": 504
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9eab390b865b031211658564ad5fe5241c9661c5",
                    "width": 1080,
                    "height": 567
                  }
                ],
                "variants": {},
                "id": "krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mje4dm",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "stockninja666",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mje4dm/copilot_agent_mode_with_any_reasonable_local_llm/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mje4dm/copilot_agent_mode_with_any_reasonable_local_llm/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754508406,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "You can get interesting interactions by telling a model that you are giving it a challenge, and that it is going to be hard to keep saying the word, and ask it to say banana 10 times. It will just spit out different tokens after a few times. And you can see it struggle with itself.",
          "author_fullname": "t2_v88pu0v9d",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "You can make models try to repeat a word and set repeat penalty really high.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjdzo4",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754508105,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can get interesting interactions by telling a model that you are giving it a challenge, and that it is going to be hard to keep saying the word, and ask it to say banana 10 times. It will just spit out different tokens after a few times. And you can see it struggle with itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mjdzo4",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Coolengineer7",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjdzo4/you_can_make_models_try_to_repeat_a_word_and_set/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjdzo4/you_can_make_models_try_to_repeat_a_word_and_set/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754508105,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_q924919v",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Llama.cpp: Add GPT-OSS",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mic8kf",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": null,
          "ups": 349,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 349,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=75bd2276c8e972280803ce7207ac5eb6a91cfde6",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754407557,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/ggml-org/llama.cpp/pull/15091",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?auto=webp&amp;s=7a3422c9d3010663aed71cb1e264c5cc3a5c523a",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fc0a9456ea2aba0fff93672ee04a1dff1ae7e21",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c7a8024c90bd19a185cad631b6331181cd8be68d",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f692ce562377209ae555054812a3c52571c89b92",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=95a9e3e605eab496c9ba148173f1d7e68a1d7e9f",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a0c6f0d3a119481fd253e8878d5e92d5c7c3f9c",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91c6ba4637f988cd1ff6db7d629220a3c493d7e0",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mic8kf",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "atgctg",
          "discussion_type": null,
          "num_comments": 63,
          "send_replies": false,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/",
          "stickied": false,
          "url": "https://github.com/ggml-org/llama.cpp/pull/15091",
          "subreddit_subscribers": 512425,
          "created_utc": 1754407557,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I tried the recommended Unsloth settings, as well as the default settings, and after a few questions, the model proceeds to skip its turn indefinitely.  Maybe it’s missing a stop token? ",
          "author_fullname": "t2_vcawomd",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Playing 20 questions with gpt-oss-120b causes the model to spiral",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjdy9g",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.54,
          "author_flair_background_color": null,
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/SB7UUlSDYD3ftVVsrrhum8U3QpnLurB7cAZ8xmHvHjw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754508019,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried the recommended Unsloth settings, as well as the default settings, and after a few questions, the model proceeds to skip its turn indefinitely.  Maybe it’s missing a stop token? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/fzggmq5i8ghf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/fzggmq5i8ghf1.png?auto=webp&amp;s=0e4405e63ab5bf9a7b4a99dec8e646f6f0a5def0",
                  "width": 1057,
                  "height": 1210
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/fzggmq5i8ghf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b707934d1ae707c636da27819dd544b55c546978",
                    "width": 108,
                    "height": 123
                  },
                  {
                    "url": "https://preview.redd.it/fzggmq5i8ghf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8615dd625b61805d7cdc15b50fc12aca20001d09",
                    "width": 216,
                    "height": 247
                  },
                  {
                    "url": "https://preview.redd.it/fzggmq5i8ghf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c198ce10088e28a08d4d592985429361f315944",
                    "width": 320,
                    "height": 366
                  },
                  {
                    "url": "https://preview.redd.it/fzggmq5i8ghf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=08134fa5c63c474d25ddd5a5d44ec880348ec4ba",
                    "width": 640,
                    "height": 732
                  },
                  {
                    "url": "https://preview.redd.it/fzggmq5i8ghf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=32dfc6a2fe17eb5f2e62d0f54f4aa87ff779734d",
                    "width": 960,
                    "height": 1098
                  }
                ],
                "variants": {},
                "id": "ljZjp8JJaa9mATyRKuqr1RPC2Ax-vO-Vh3e8BEHMnfQ"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjdy9g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "onil_gova",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjdy9g/playing_20_questions_with_gptoss120b_causes_the/",
          "stickied": false,
          "url": "https://i.redd.it/fzggmq5i8ghf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754508019,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Because range matters.",
          "author_fullname": "t2_ts2dg",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Let me fix that chart for you",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 129,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miqzgb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.86,
          "author_flair_background_color": null,
          "ups": 58,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 58,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3Ok8ftvPtdWtD-XGVnuGickHrw1QOMKeHe84HGj9Omw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754442110,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Because range matters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/69scmtwzsahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/69scmtwzsahf1.png?auto=webp&amp;s=8f10fc00fb6f46cda975ad8202cc0242fa8ede02",
                  "width": 1272,
                  "height": 1180
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=33a6329665f72ebd056ba1358adce8334fa278b5",
                    "width": 108,
                    "height": 100
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7b88353f16af4b173471115398b3cb67f74750e",
                    "width": 216,
                    "height": 200
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8d420a7b9dc4092b1389e18be4245e21a14824d",
                    "width": 320,
                    "height": 296
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=90ff74d87020e05e7f407a73bbc2874a6ef21143",
                    "width": 640,
                    "height": 593
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b02c3e39a067b03b3575eca3a8844f120beb84a",
                    "width": 960,
                    "height": 890
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9b4d54ac08a5a124832b53e91a43c2d4024df36",
                    "width": 1080,
                    "height": 1001
                  }
                ],
                "variants": {},
                "id": "ZTLEigllWjDcs1VEMHDhGNlq6geK4NSDHKVgPIsBcFY"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1miqzgb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "sstainsby",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqzgb/let_me_fix_that_chart_for_you/",
          "stickied": false,
          "url": "https://i.redd.it/69scmtwzsahf1.png",
          "subreddit_subscribers": 512425,
          "created_utc": 1754442110,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "\nI trained and merged my model. There wasn't problem when I just trained one lora, but I wanted to apply two loras at once so I made a merged model.\n\nBut when I try to run this model on A100 40gb, I got OOM error unlike applying lora to quantized model.\n\nSo I want to quantize this model and tried GPTQModel and failed with 280gb(140×2) vram.\n(I tried tutorial code in github readme file. Is there any optimization option?)\n\nThen, how much vram do I need to quantize this model? Also, I've heard that gptqmodel has problem with gemma 3. Is there any substitute?\n(I want to run model with vllm)",
          "author_fullname": "t2_g6ps751g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How much vram required to quantize gemma 3 27b?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjdqqm",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=be5bf3e009dafaf12cdf780607349750217f5824",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754507545,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I trained and merged my model. There wasn&amp;#39;t problem when I just trained one lora, but I wanted to apply two loras at once so I made a merged model.&lt;/p&gt;\n\n&lt;p&gt;But when I try to run this model on A100 40gb, I got OOM error unlike applying lora to quantized model.&lt;/p&gt;\n\n&lt;p&gt;So I want to quantize this model and tried GPTQModel and failed with 280gb(140×2) vram.\n(I tried tutorial code in github readme file. Is there any optimization option?)&lt;/p&gt;\n\n&lt;p&gt;Then, how much vram do I need to quantize this model? Also, I&amp;#39;ve heard that gptqmodel has problem with gemma 3. Is there any substitute?\n(I want to run model with vllm)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/ij/gemma3-27b-pt-it-RPandNOVEL-merge",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?auto=webp&amp;s=2becd8b8236330869312c214ee1d747db0086de6",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a042edc8af04b9bca30603551265d20c582dfbde",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c094c16596c05029f17a01a12f7dc3674238532f",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=abdba90dcf5f4308e56fc9f1d56d5a8ffb163924",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad5f96af690c862f65bbc1bde119d60670b4c05d",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f160707dbcb9622712544f241a26bea1eb8bd491",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a2525445be4b93d11d52153eb2101aa7a5b2841",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "LX381FNFghjuylp4rXtUtlx_6_F96RpodjPlrUQUGiM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjdqqm",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "1wndrla17",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjdqqm/how_much_vram_required_to_quantize_gemma_3_27b/",
          "stickied": false,
          "url": "https://huggingface.co/ij/gemma3-27b-pt-it-RPandNOVEL-merge",
          "subreddit_subscribers": 512425,
          "created_utc": 1754507545,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b\n\nEvery time answering the question, Gpt-oss will check whether it contains disallowed content(explicit/violent/illegal content),and ”according to policy, we must refuse“.",
          "author_fullname": "t2_u398xzta",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "The openai gpt-oss model is too safe!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 65,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "g4ih1pz7nahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 50,
                  "x": 108,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9a41e96ba97c60bf30ebfb35c5be98e4cd585cc"
                },
                {
                  "y": 101,
                  "x": 216,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=de00c769617f01054d6902e10ed390dc848b849b"
                },
                {
                  "y": 150,
                  "x": 320,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c108ee6407b5bc148c9906c3d9774c13681f315c"
                },
                {
                  "y": 301,
                  "x": 640,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea182f8586233d5ec30c227e64d9346bf0fb1b28"
                },
                {
                  "y": 452,
                  "x": 960,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c06abd8e6412ffea246a11801d589d13f657482"
                },
                {
                  "y": 508,
                  "x": 1080,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4334cd9e97db0e15810d020eec915d3a999ab2ce"
                }
              ],
              "s": {
                "y": 849,
                "x": 1802,
                "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b"
              },
              "id": "g4ih1pz7nahf1"
            }
          },
          "name": "t3_1miqbyk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.85,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 61,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 61,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/9AYqrIhNJjW4c44_58a53bBAstFq2WK6RLkfAreEYV8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754440319,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b\"&gt;https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Every time answering the question, Gpt-oss will check whether it contains disallowed content(explicit/violent/illegal content),and ”according to policy, we must refuse“.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miqbyk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "sunshinecheung",
          "discussion_type": null,
          "num_comments": 40,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754440319,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "What a ride! Been a big 24h. Now that the dust has barely settled, I just wanted some clarification (and I'm sure there are many of us) around which of the major GPT-OSS releases should we be using for best quality-performance? (rather than speed)\n\nThere's llama.cpp native support: [https://github.com/ggml-org/llama.cpp/discussions/15095](https://github.com/ggml-org/llama.cpp/discussions/15095)  \nI presume this means I can just run the native models dropped by OpenAI on hugging face here: [https://huggingface.co/openai/gpt-oss-120b](https://huggingface.co/openai/gpt-oss-120b) \n\nBut then there is GGML: [https://github.com/ggml-org/llama.cpp/pull/15091](https://github.com/ggml-org/llama.cpp/pull/15091)  \nWith the models here: [https://huggingface.co/collections/ggml-org/gpt-oss-68923b60bee37414546c70bf](https://huggingface.co/collections/ggml-org/gpt-oss-68923b60bee37414546c70bf)\n\nAnd there's Unsloth: [https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune](https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune)  \nTheir models are gguf: [https://huggingface.co/unsloth/gpt-oss-20b-GGUF](https://huggingface.co/unsloth/gpt-oss-20b-GGUF)  \nThey mention chat template fixes have have different quants.\n\nIs the right combo the OpenAI quants with the Unsloth chat template fixes? (I'm using LMStudio on a 128 M4 Max for what that's worth).\n\nAlso, shoutout to everyone involved to the organisations involved above, woking your absolute asses off at the moment.",
          "author_fullname": "t2_1gzoposi1r",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Where are we at running the GPT-OSS models locally?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mjjaor",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.56,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754520512,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What a ride! Been a big 24h. Now that the dust has barely settled, I just wanted some clarification (and I&amp;#39;m sure there are many of us) around which of the major GPT-OSS releases should we be using for best quality-performance? (rather than speed)&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s llama.cpp native support: &lt;a href=\"https://github.com/ggml-org/llama.cpp/discussions/15095\"&gt;https://github.com/ggml-org/llama.cpp/discussions/15095&lt;/a&gt;&lt;br/&gt;\nI presume this means I can just run the native models dropped by OpenAI on hugging face here: &lt;a href=\"https://huggingface.co/openai/gpt-oss-120b\"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;But then there is GGML: &lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091\"&gt;https://github.com/ggml-org/llama.cpp/pull/15091&lt;/a&gt;&lt;br/&gt;\nWith the models here: &lt;a href=\"https://huggingface.co/collections/ggml-org/gpt-oss-68923b60bee37414546c70bf\"&gt;https://huggingface.co/collections/ggml-org/gpt-oss-68923b60bee37414546c70bf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And there&amp;#39;s Unsloth: &lt;a href=\"https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune\"&gt;https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune&lt;/a&gt;&lt;br/&gt;\nTheir models are gguf: &lt;a href=\"https://huggingface.co/unsloth/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;br/&gt;\nThey mention chat template fixes have have different quants.&lt;/p&gt;\n\n&lt;p&gt;Is the right combo the OpenAI quants with the Unsloth chat template fixes? (I&amp;#39;m using LMStudio on a 128 M4 Max for what that&amp;#39;s worth).&lt;/p&gt;\n\n&lt;p&gt;Also, shoutout to everyone involved to the organisations involved above, woking your absolute asses off at the moment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?auto=webp&amp;s=021ac90e342e7ce24176d8fc1d8f982df536ec3a",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b2771ee5257111e4de088311cb5195ef52c7b24",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=546ac16b2e0ddee9d735b54e7252ea7704f0aa25",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d3b1de829365122de157087d1354ddc7ce0a097",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ab49a1bcbed40a5d13899b9b4cca4f76dd3f536",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=26c58e1a03de3b0334cae1d33f50e3bfa61973c5",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5c58046231d9a33ac45a28213537010cf1e217fd",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "wBahFztknQ-A1CZRCY7qY4UJKbme9D-9RZUUC_JNONw"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mjjaor",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Suspicious_Young8152",
          "discussion_type": null,
          "num_comments": 12,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mjjaor/where_are_we_at_running_the_gptoss_models_locally/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjjaor/where_are_we_at_running_the_gptoss_models_locally/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754520512,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Kudos to you guys",
          "author_fullname": "t2_q1q7nlxa",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Just wanna say : Kudos to llama cpp our unsung heroes 🫡",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milm9t",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 112,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 112,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754428505,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kudos to you guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1milm9t",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "dreamai87",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/",
          "subreddit_subscribers": 512425,
          "created_utc": 1754428505,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      }
    ],
    "before": null
  }
}