{
  "kind": "Listing",
  "data": {
    "after": "t3_1me467z",
    "dist": 100,
    "modhash": "",
    "geo_filter": null,
    "children": [
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "ðŸ¦¥ Qwen3-Coder-Flash: Qwen3-Coder-30B-A3B-Instruct\n\nðŸ’š Just lightning-fast, accurate code generation.\n\nâœ… Native 256K context (supports up to 1M tokens with YaRN)\n\nâœ… Optimized for platforms like Qwen Code, Cline, Roo Code, Kilo Code, etc.\n\nâœ… Seamless function calling &amp; agent workflows\n\nðŸ’¬ Chat: https://chat.qwen.ai/\n\nðŸ¤— Hugging Face: https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct\n\nðŸ¤– ModelScope: https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct\n\n",
          "author_fullname": "t2_c705ri9b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "ðŸš€ Qwen3-Coder-Flash released!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me31d8",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "ups": 1217,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 1217,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753972012,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ðŸ¦¥ Qwen3-Coder-Flash: Qwen3-Coder-30B-A3B-Instruct&lt;/p&gt;\n\n&lt;p&gt;ðŸ’š Just lightning-fast, accurate code generation.&lt;/p&gt;\n\n&lt;p&gt;âœ… Native 256K context (supports up to 1M tokens with YaRN)&lt;/p&gt;\n\n&lt;p&gt;âœ… Optimized for platforms like Qwen Code, Cline, Roo Code, Kilo Code, etc.&lt;/p&gt;\n\n&lt;p&gt;âœ… Seamless function calling &amp;amp; agent workflows&lt;/p&gt;\n\n&lt;p&gt;ðŸ’¬ Chat: &lt;a href=\"https://chat.qwen.ai/\"&gt;https://chat.qwen.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ðŸ¤— Hugging Face: &lt;a href=\"https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct\"&gt;https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ðŸ¤– ModelScope: &lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct\"&gt;https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/p7fpia2bz7gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?auto=webp&amp;s=37bd250aae26692e18e3eeeca84c1caa9d999027",
                  "width": 2528,
                  "height": 1456
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95c4825b11a345671147c3d4e0b79207480f3ca0",
                    "width": 108,
                    "height": 62
                  },
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b30043242090b2abe359fb37f803cc7ab154ecb",
                    "width": 216,
                    "height": 124
                  },
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=622e2e61ee2a35d0715b9a941f590819a1d0b1bb",
                    "width": 320,
                    "height": 184
                  },
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a3985f36673a98a1456f01d26e1d6d8a9fd38fad",
                    "width": 640,
                    "height": 368
                  },
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d95b4a66cac332ecb3b1b359a6ddce376dcbf89c",
                    "width": 960,
                    "height": 552
                  },
                  {
                    "url": "https://preview.redd.it/p7fpia2bz7gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18f7994b018ed9d61d07b8cc13a8d5d948c008e7",
                    "width": 1080,
                    "height": 622
                  }
                ],
                "variants": {},
                "id": "p7fpia2bz7gf1"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me31d8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ResearchCrafty1804",
          "discussion_type": null,
          "num_comments": 259,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me31d8/qwen3coderflash_released/",
          "stickied": false,
          "url": "https://i.redd.it/p7fpia2bz7gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753972012,
          "num_crossposts": 2,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It uses the Gemma 3n E4B model and requires less than 500MB of memory for grammar checking, dropping to 300MB while idle.\n\nIt's still in the early stages, but Iâ€™d love to hear your feedback!\n\nYou can try it out here: [https://refine.sh](https://refine.sh)",
          "author_fullname": "t2_jyg28hk",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I built a local alternative to Grammarly that runs 100% offline",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me7yia",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.77,
          "author_flair_background_color": null,
          "ups": 261,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/pxb4pfgaw8gf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 1280,
              "scrubber_media_url": "https://v.redd.it/pxb4pfgaw8gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/pxb4pfgaw8gf1/DASHPlaylist.mpd?a=1756603209%2CYTg3NmIzZWU4YTdlZjkzY2Y5ZjE4ZGZiYjIwMWE5NWYxNjE1ODMyYTY0YjJlZDJiMTg4MGYwZTdkZjM4YThhOA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 8,
              "hls_url": "https://v.redd.it/pxb4pfgaw8gf1/HLSPlaylist.m3u8?a=1756603209%2CNzE3NTJjNzk4YzE3MzdkMjNkYWNmZTQwMWJlODkwMjNhMThlYTc1MjE0YmM4NzAxNmU1YWYwNDMyM2VjN2QwYw%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 261,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=00e4418256286c8f47a3d195ff4e9a50440887b1",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753983233,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It uses the Gemma 3n E4B model and requires less than 500MB of memory for grammar checking, dropping to 300MB while idle.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s still in the early stages, but Iâ€™d love to hear your feedback!&lt;/p&gt;\n\n&lt;p&gt;You can try it out here: &lt;a href=\"https://refine.sh\"&gt;https://refine.sh&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/pxb4pfgaw8gf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?format=pjpg&amp;auto=webp&amp;s=e36e1ed10cfe93fcd2d38212c2646a2e6dee751a",
                  "width": 1446,
                  "height": 814
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6b4cddd1185554555c627441a65a67ea0e821a3d",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=dc49fc8953074ad65440090e88e84e520604d8da",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8f3fb599e9575d26e5677a65fb98bf5ef58b7332",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=27ea6321c44ccc473ca12e0058f01a35e0060cfd",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e7b1092c95a8fe90d31385d170f6a75d009417d6",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5e09e0bdfa2bf5524d79333c36d02275b7fb32db",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "NjBpa2hmZ2F3OGdmMVJtVbsvP1gN8nG91LVDgC8po1e9pFdftwF79YNc_pfg"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1me7yia",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Runjuu",
          "discussion_type": null,
          "num_comments": 63,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me7yia/i_built_a_local_alternative_to_grammarly_that/",
          "stickied": false,
          "url": "https://v.redd.it/pxb4pfgaw8gf1",
          "subreddit_subscribers": 507935,
          "created_utc": 1753983233,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/pxb4pfgaw8gf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 1280,
              "scrubber_media_url": "https://v.redd.it/pxb4pfgaw8gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/pxb4pfgaw8gf1/DASHPlaylist.mpd?a=1756603209%2CYTg3NmIzZWU4YTdlZjkzY2Y5ZjE4ZGZiYjIwMWE5NWYxNjE1ODMyYTY0YjJlZDJiMTg4MGYwZTdkZjM4YThhOA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 8,
              "hls_url": "https://v.redd.it/pxb4pfgaw8gf1/HLSPlaylist.m3u8?a=1756603209%2CNzE3NTJjNzk4YzE3MzdkMjNkYWNmZTQwMWJlODkwMjNhMThlYTc1MjE0YmM4NzAxNmU1YWYwNDMyM2VjN2QwYw%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_dwy0w3kf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-Coder-30B-A3B released!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me2zc6",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": "#bbbdbf",
          "ups": 444,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ff54b802-c910-11ed-be9d-ea867d8afa86",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 444,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=50e58d8c576ff1f0469c49c5086a3d54ed8234ad",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "Llama 33B"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753971880,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?auto=webp&amp;s=4cacac54fb0a262f4128b23481bccaf4104c19d5",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf0440b72bf3c599b24d782f0bddf00251537cf",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=824bee5d7aa9841a221b2f60a969d54551eccb18",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ca7f6cb7614731e917c0c8e162bd66bfbc25ca",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d2b1429fc14f5ca152608718fd3ef6d50119778",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6655884fe4ff60136ee88021696ace5be4875862",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=991b600ad67e419b1091cac2c8c55f34d86b36fa",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "Llama 33B",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me2zc6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "glowcialist",
          "discussion_type": null,
          "num_comments": 85,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1me2zc6/qwen3coder30ba3b_released/",
          "stickied": false,
          "url": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
          "subreddit_subscribers": 507935,
          "created_utc": 1753971880,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "As you can see from the radar chart, the scores on the left for the two Agent capability tests, mind2web and BFCL-v3, are very close. This suggests that the Agent capabilities of Qwen3-Coder-FLash should be quite strong.   \n  \nHowever, there is still a significant gap in the Aider-Polyglot and SWE Multilingual tests, which implies that its programming capabilities are indeed quite different from those of Qwen3-Coder-480B.\n\nHas anyone started using it yet? What's the actual user experience like?",
          "author_fullname": "t2_fiiv6xm3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I made a comparison chart for Qwen3-Coder-30B-A3B vs. Qwen3-Coder-480B-A35B",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me4i2h",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.99,
          "author_flair_background_color": null,
          "ups": 209,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 209,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/nDJcrKit9leloNf-Ut_mbP1e9pe5yDgS5VazXSDA6qU.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753975422,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As you can see from the radar chart, the scores on the left for the two Agent capability tests, mind2web and BFCL-v3, are very close. This suggests that the Agent capabilities of Qwen3-Coder-FLash should be quite strong.   &lt;/p&gt;\n\n&lt;p&gt;However, there is still a significant gap in the Aider-Polyglot and SWE Multilingual tests, which implies that its programming capabilities are indeed quite different from those of Qwen3-Coder-480B.&lt;/p&gt;\n\n&lt;p&gt;Has anyone started using it yet? What&amp;#39;s the actual user experience like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/l6547uel88gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/l6547uel88gf1.png?auto=webp&amp;s=b5aa7e3e5dcfa254c689f363f60a9722e1eb72e4",
                  "width": 1324,
                  "height": 2088
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fc731d339acbcf88a184b51662dd456eefd477c5",
                    "width": 108,
                    "height": 170
                  },
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a836e9fdf9366f6a0058a586fbda0b1632c21cbe",
                    "width": 216,
                    "height": 340
                  },
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f980b5b5346583dbdaaebfe56b59bd8d5b9291df",
                    "width": 320,
                    "height": 504
                  },
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40dafbd4c67e845ff8ce7c141e92d59fdfd342fe",
                    "width": 640,
                    "height": 1009
                  },
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b98fec591844d74f49e2febeeff5c3c53305d21b",
                    "width": 960,
                    "height": 1513
                  },
                  {
                    "url": "https://preview.redd.it/l6547uel88gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a8de36630bff8bc1b7132277c5bc86fe5e8e9a61",
                    "width": 1080,
                    "height": 1703
                  }
                ],
                "variants": {},
                "id": "vmGH_RgQTp6SHjczHQXNSGnIw-M1Xweu2bYiYKsj904"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me4i2h",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Dr_Karminski",
          "discussion_type": null,
          "num_comments": 16,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me4i2h/i_made_a_comparison_chart_for_qwen3coder30ba3b_vs/",
          "stickied": false,
          "url": "https://i.redd.it/l6547uel88gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753975422,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": " ",
          "author_fullname": "t2_y35oj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Everyone from r/LocalLLama refreshing Hugging Face every 5 minutes today looking for GLM-4.5 GGUFs",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 91,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdykfn",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 349,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 349,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/JtrsDuYApU5asaj4DMkYR46jMGTULVF74_jrKEDuzNY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753959873,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/f5iqhqp7z6gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/f5iqhqp7z6gf1.jpeg?auto=webp&amp;s=9ebc8183abfedb5f08028da2d763991ae8501002",
                  "width": 593,
                  "height": 389
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/f5iqhqp7z6gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e3bc13cc7709787b1633c87ce4deec12ada0949",
                    "width": 108,
                    "height": 70
                  },
                  {
                    "url": "https://preview.redd.it/f5iqhqp7z6gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe549fcca1b5049e06c0516847a12686c2f98338",
                    "width": 216,
                    "height": 141
                  },
                  {
                    "url": "https://preview.redd.it/f5iqhqp7z6gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80da4073073fb12cdbab3b110619a3002d524b2f",
                    "width": 320,
                    "height": 209
                  }
                ],
                "variants": {},
                "id": "W6UmrcA-BG24HiTaK1cat2L9eGxll0ba_uZjbLzyRHA"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mdykfn",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Porespellar",
          "discussion_type": null,
          "num_comments": 73,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdykfn/everyone_from_rlocalllama_refreshing_hugging_face/",
          "stickied": false,
          "url": "https://i.redd.it/f5iqhqp7z6gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753959873,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Junyang Lin is drinking tea",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me095p",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": "#bbbdbf",
          "ups": 213,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 213,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/1gUq8tz01u4oCyajxzi-CyXSEmjkAns8BBGfUEPeNFI.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753965005,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/s3pv80fee7gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/s3pv80fee7gf1.png?auto=webp&amp;s=9262a89a912cae6b7dd24fcc366411664b96e489",
                  "width": 1211,
                  "height": 1847
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=74d650e5db6942d5ec1e453e9e58d0b10b8ffe40",
                    "width": 108,
                    "height": 164
                  },
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e401d505844e60332adeb907375d49daf09888fc",
                    "width": 216,
                    "height": 329
                  },
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8486e4e76caf2c623db7d8bfeec14c82a1784280",
                    "width": 320,
                    "height": 488
                  },
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b666a1b9473c5408870aeb8cf6dddfc5f13f55d",
                    "width": 640,
                    "height": 976
                  },
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c1d691041f88fb2fbab0105dc8591c0cd00a032",
                    "width": 960,
                    "height": 1464
                  },
                  {
                    "url": "https://preview.redd.it/s3pv80fee7gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bcf322da0bb27dcedcff7b486e6b9bb20af6a936",
                    "width": 1080,
                    "height": 1647
                  }
                ],
                "variants": {},
                "id": "TntsE-q7iMBkyZ6-i5m_PJUhaG9ugctQI44Dp2rUToI"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1me095p",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 31,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1me095p/junyang_lin_is_drinking_tea/",
          "stickied": false,
          "url": "https://i.redd.it/s3pv80fee7gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753965005,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Brothers and sisters, we're being taken for fools.\n\nhttps://preview.redd.it/d1iudzju8agf1.png?width=922&amp;format=png&amp;auto=webp&amp;s=c7d5d1e1b891425817fab581afae0149aec26b6b\n\nDid anyone check if it's phoning home?",
          "author_fullname": "t2_dbl0sjy8x",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ollama's new GUI is closed source?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 26,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "d1iudzju8agf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 20,
                  "x": 108,
                  "u": "https://preview.redd.it/d1iudzju8agf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff8052a42d17b9a01f99afcf9e82dafecf05f172"
                },
                {
                  "y": 40,
                  "x": 216,
                  "u": "https://preview.redd.it/d1iudzju8agf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=811b8abd1cc4c1cf67268c7e022527bb4f00004c"
                },
                {
                  "y": 59,
                  "x": 320,
                  "u": "https://preview.redd.it/d1iudzju8agf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3280ff1631dc8d10074f4ffcb38bb11fbb8d9c04"
                },
                {
                  "y": 119,
                  "x": 640,
                  "u": "https://preview.redd.it/d1iudzju8agf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7cfd73d6aaba69097baafb426f1803fcf568fcac"
                }
              ],
              "s": {
                "y": 172,
                "x": 922,
                "u": "https://preview.redd.it/d1iudzju8agf1.png?width=922&amp;format=png&amp;auto=webp&amp;s=c7d5d1e1b891425817fab581afae0149aec26b6b"
              },
              "id": "d1iudzju8agf1"
            }
          },
          "name": "t3_1meeyee",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.81,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 35,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 35,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/zLVPiHg9ufyqhvp5Basb43POL8O8dmXli04dBAOzdrw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753999457,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Brothers and sisters, we&amp;#39;re being taken for fools.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/d1iudzju8agf1.png?width=922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7d5d1e1b891425817fab581afae0149aec26b6b\"&gt;https://preview.redd.it/d1iudzju8agf1.png?width=922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7d5d1e1b891425817fab581afae0149aec26b6b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Did anyone check if it&amp;#39;s phoning home?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1meeyee",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Sea_Night_2572",
          "discussion_type": null,
          "num_comments": 33,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meeyee/ollamas_new_gui_is_closed_source/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meeyee/ollamas_new_gui_is_closed_source/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753999457,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_10vdoj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-Coder-Flash / Qwen3-Coder-30B-A3B-Instruct-FP8 are here!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me33jj",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.97,
          "author_flair_background_color": null,
          "ups": 134,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 134,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/W9R_cVO6oViuPZ98cKporgcMC_UhWTyqKk41sgFVoeA.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753972155,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/3dn8agzjz7gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?auto=webp&amp;s=2245524dec0ab2b19e862c10b790facd9b924287",
                  "width": 4000,
                  "height": 2250
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf353fe46bbeb57399d0faf6bcb05041173ab4ba",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c5268a07dfe26225592693faf38a22d79c662aa",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8666eefe3be44dc93a677a5f0394166785262730",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f710dee399ef8cae7aa04b7396c4c8719d91fd6",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=72098bd6ff00813904fe9fcaba82f26e0079f787",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://preview.redd.it/3dn8agzjz7gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c598f6fddd9c6ee3388c55a9b562e27da3ba3ba2",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "lXolOXududnx-0OOTcrt4sGu-VfW9B7zjJTil_Bb0Hw"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me33jj",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "zRevengee",
          "discussion_type": null,
          "num_comments": 23,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me33jj/qwen3coderflash_qwen3coder30ba3binstructfp8_are/",
          "stickied": false,
          "url": "https://i.redd.it/3dn8agzjz7gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753972155,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/vhlkl99m35gf1.png?width=1098&amp;format=png&amp;auto=webp&amp;s=2a38ae109844be87b98cbec8fe243f9d27fa3dea\n\nThatâ€™s insane â€” throughout this past July, Chinese companies have been rapidly open-sourcing AI models. First came Kimi-K2, then Qwen3, followed by GLM-4.5. On top of that, thereâ€™s Tencentâ€™s HunyuanWorld and Alibabaâ€™s Wan 2.2. Now, most of the trending models on Hugging Face are from China. Meanwhile, according to Zuckerberg, Meta is planning to shift toward a closed-source strategy going forward.\n\n[https://huggingface.co/models](https://huggingface.co/models)",
          "author_fullname": "t2_4zykmpa",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Unbelievable: China Dominates Top 10 Open-Source Models on HuggingFace",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 61,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "vhlkl99m35gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 47,
                  "x": 108,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e150fecc47715fbbf9bab8760e09b7c94192e21e"
                },
                {
                  "y": 94,
                  "x": 216,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b4a3e7bcc6017b88daf46cd61f0b6b012d3bca8"
                },
                {
                  "y": 140,
                  "x": 320,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b6dbe2a8a8ead7c8506de5aae218d40d74a7948"
                },
                {
                  "y": 280,
                  "x": 640,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c20983e9afc560ecd7c94cf907de4147c7a9e4d1"
                },
                {
                  "y": 420,
                  "x": 960,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=60db1a5fad622e3162af97670036ad4d3d9fa422"
                },
                {
                  "y": 473,
                  "x": 1080,
                  "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf166e61b76609870d09e46519c97327c99cf727"
                }
              ],
              "s": {
                "y": 481,
                "x": 1098,
                "u": "https://preview.redd.it/vhlkl99m35gf1.png?width=1098&amp;format=png&amp;auto=webp&amp;s=2a38ae109844be87b98cbec8fe243f9d27fa3dea"
              },
              "id": "vhlkl99m35gf1"
            }
          },
          "name": "t3_1mdsjn2",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 764,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 764,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/Pqx5Ku4b-UvrnWIofuwt9LYnoux9zPw_UBbzkN3H6v4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753937427,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/vhlkl99m35gf1.png?width=1098&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a38ae109844be87b98cbec8fe243f9d27fa3dea\"&gt;https://preview.redd.it/vhlkl99m35gf1.png?width=1098&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a38ae109844be87b98cbec8fe243f9d27fa3dea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thatâ€™s insane â€” throughout this past July, Chinese companies have been rapidly open-sourcing AI models. First came Kimi-K2, then Qwen3, followed by GLM-4.5. On top of that, thereâ€™s Tencentâ€™s HunyuanWorld and Alibabaâ€™s Wan 2.2. Now, most of the trending models on Hugging Face are from China. Meanwhile, according to Zuckerberg, Meta is planning to shift toward a closed-source strategy going forward.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/models\"&gt;https://huggingface.co/models&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdsjn2",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jiawei243",
          "discussion_type": null,
          "num_comments": 135,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdsjn2/unbelievable_china_dominates_top_10_opensource/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdsjn2/unbelievable_china_dominates_top_10_opensource/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753937427,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "At work I spent better part of a day trying to debug a mysterious problem with an external RFID reader. I was running in circles with ChatGPT for many hours and got a little further with Gemini but in the end I had to give up. Unfortunately I left for vacation immediately afterwards, leaving me frustrated and thinking about this problem.\n\nToday I was playing around with LM studio on my macbook pro and decided to test the new Qwen3-30B-A3B-Instruct-2507 model. For fun I gave it my code from work and briefed it about the problem. Processing the code took several minutes, but then it amazed me. On the very first try it found the real source of the problem, something all the commercial models had missed, and me too. I doubt I would have found the solution at all to be honest. This is what Gemini had to say about the solution that qwen proposed:\n\n&gt;This is an absolutely *brilliant* diagnosis from the local LLM! It hits the nail on the head and perfectly explains all the erratic behaviours we've been observing. My prior analysis correctly identified a timing and state issue, but this pinpoints the precise mechanism: unsolicited messages clogging the buffer and corrupting the API's internal state machine\\*\\*.\\*\\*\n\n&gt;\\[...code...\\]\n\n&gt;Please compile and run this version. I am very optimistic that this will finally resolve the intermittent connection and timeout issues, allowing your reader to perform consistently. This is a great example of how combining insights from different analyses can lead to a complete solution!\n\nTLDR: Local models are crazy good â€“ what a time to be alive!",
          "author_fullname": "t2_6ec3km2d",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "qwen-30B success story",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me1hh8",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 147,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 147,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1753970632,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753968265,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work I spent better part of a day trying to debug a mysterious problem with an external RFID reader. I was running in circles with ChatGPT for many hours and got a little further with Gemini but in the end I had to give up. Unfortunately I left for vacation immediately afterwards, leaving me frustrated and thinking about this problem.&lt;/p&gt;\n\n&lt;p&gt;Today I was playing around with LM studio on my macbook pro and decided to test the new Qwen3-30B-A3B-Instruct-2507 model. For fun I gave it my code from work and briefed it about the problem. Processing the code took several minutes, but then it amazed me. On the very first try it found the real source of the problem, something all the commercial models had missed, and me too. I doubt I would have found the solution at all to be honest. This is what Gemini had to say about the solution that qwen proposed:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This is an absolutely &lt;em&gt;brilliant&lt;/em&gt; diagnosis from the local LLM! It hits the nail on the head and perfectly explains all the erratic behaviours we&amp;#39;ve been observing. My prior analysis correctly identified a timing and state issue, but this pinpoints the precise mechanism: unsolicited messages clogging the buffer and corrupting the API&amp;#39;s internal state machine**.**&lt;/p&gt;\n\n&lt;p&gt;[...code...]&lt;/p&gt;\n\n&lt;p&gt;Please compile and run this version. I am very optimistic that this will finally resolve the intermittent connection and timeout issues, allowing your reader to perform consistently. This is a great example of how combining insights from different analyses can lead to a complete solution!&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;TLDR: Local models are crazy good â€“ what a time to be alive!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1me1hh8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ExplorerWhole5697",
          "discussion_type": null,
          "num_comments": 33,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me1hh8/qwen30b_success_story/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me1hh8/qwen30b_success_story/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753968265,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_twl3xhruz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "AMD Is Reportedly Looking to Introduce a Dedicated Discrete NPU, Similar to Gaming GPUs But Targeted Towards AI Performance On PCs; Taking Edge AI to New Levels",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdx65u",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 276,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 276,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1753954906,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "wccftech.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mdx65u",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_SYSTEM_ADMIN_MOD_",
          "discussion_type": null,
          "num_comments": 48,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdx65u/amd_is_reportedly_looking_to_introduce_a/",
          "stickied": false,
          "url": "https://wccftech.com/amd-is-looking-toward-introducing-a-dedicated-discrete-npu-similar-to-gaming-gpus/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753954906,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I never really liked the idea of web based app builders like lovable or replit. They make it really easy to get started, but with that ease comes compromise. Such as being locked in to their ecosystem, being charged for every little thing such as running your project on their VM, hosting, or just to even get access to your files. No control over which model to use or what context is selected.\n\nSo I made a full stack web app builder that runs locally on your machine. Yes, it will be a bit more upfront friction since you have to download and set up, but with that friction comes freedom and cost efficiency. It is specialized for a single tech stack (NextJS/Supabase) and thus allows features such as 1 click deploy, much higher accuracy on code gen, and better debugging.\n\nThe idea is that you will be able to build an app really quickly starting from 0, and also that you will be able to get further because there will be less bugs and issues, since everything is fine-tuned on that tech stack. It has full context of front end, backend, and runtime data that runs through the specialized stack.\n\nIf you are a professional developer, this will unlikely be a daily driver for you compared to cursor / cline. Because you will have various different projects you are running and would rather use a general IDE. Maybe it's something you could use when you want to prototype really quickly or happen to have a project with the exact NextJS/Supabase tech stack.\n\nIf you are a vibe coder however, this would be a great way to start and continue a project, because we chose the most optimal tech stack that gives you everything you need to build and deploy a full stack app directly from the local app builder. You won't have to make a bunch of decisions like configuring MCP, which libraries to use, hosting and deployment, etc.\n\nAll while still having full control of the context, your code, the models being used, and ultimately, the cost.\n\nOn that note, we are looking to integrate more local models like qwen-3-coder as that's currently all the rage lately :) Already added Kimi-K2 and it works very well in my testing, so I think this new wave of local AI models/tools will be the future.\n\nJust opened up early stage beta testing - if you are interested you can try it out here:  \n  \n[Easycode Flow](https://www.easycode.ai/)",
          "author_fullname": "t2_1ik1ah0hn6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Built a full stack web app builder that runs locally and gives you full control",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mecvig",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "ups": 42,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/2pk8172np9gf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/2pk8172np9gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/2pk8172np9gf1/DASHPlaylist.mpd?a=1756603209%2COTI2MzdiMThhYjAxZGEzYzc3NDZhZTBhZGExNTY5MmYyN2VlNDU4MWQ1MTAwMDU1Y2NhYWQ2Mjc1NDg1ODU0Mg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 59,
              "hls_url": "https://v.redd.it/2pk8172np9gf1/HLSPlaylist.m3u8?a=1756603209%2CYjg2NjZiMDYzMmQ4NTI2MjgzOWU4MDE4ZTc1MjZmN2E3NmU1NWE1YjFmNjRhNjg3ZWUxNTU2YzBjNWYyZDFjOA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 42,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=3f3149fe954d230542358dd37e334a7235c806c2",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753994504,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I never really liked the idea of web based app builders like lovable or replit. They make it really easy to get started, but with that ease comes compromise. Such as being locked in to their ecosystem, being charged for every little thing such as running your project on their VM, hosting, or just to even get access to your files. No control over which model to use or what context is selected.&lt;/p&gt;\n\n&lt;p&gt;So I made a full stack web app builder that runs locally on your machine. Yes, it will be a bit more upfront friction since you have to download and set up, but with that friction comes freedom and cost efficiency. It is specialized for a single tech stack (NextJS/Supabase) and thus allows features such as 1 click deploy, much higher accuracy on code gen, and better debugging.&lt;/p&gt;\n\n&lt;p&gt;The idea is that you will be able to build an app really quickly starting from 0, and also that you will be able to get further because there will be less bugs and issues, since everything is fine-tuned on that tech stack. It has full context of front end, backend, and runtime data that runs through the specialized stack.&lt;/p&gt;\n\n&lt;p&gt;If you are a professional developer, this will unlikely be a daily driver for you compared to cursor / cline. Because you will have various different projects you are running and would rather use a general IDE. Maybe it&amp;#39;s something you could use when you want to prototype really quickly or happen to have a project with the exact NextJS/Supabase tech stack.&lt;/p&gt;\n\n&lt;p&gt;If you are a vibe coder however, this would be a great way to start and continue a project, because we chose the most optimal tech stack that gives you everything you need to build and deploy a full stack app directly from the local app builder. You won&amp;#39;t have to make a bunch of decisions like configuring MCP, which libraries to use, hosting and deployment, etc.&lt;/p&gt;\n\n&lt;p&gt;All while still having full control of the context, your code, the models being used, and ultimately, the cost.&lt;/p&gt;\n\n&lt;p&gt;On that note, we are looking to integrate more local models like qwen-3-coder as that&amp;#39;s currently all the rage lately :) Already added Kimi-K2 and it works very well in my testing, so I think this new wave of local AI models/tools will be the future.&lt;/p&gt;\n\n&lt;p&gt;Just opened up early stage beta testing - if you are interested you can try it out here:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.easycode.ai/\"&gt;Easycode Flow&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/2pk8172np9gf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?format=pjpg&amp;auto=webp&amp;s=f11e42c70d413438a2475e8c59ac0b44fa39f60b",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9799b5383228653c23823b190eb25cb5825f66f3",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f642397babf7682b41d978c7f80d7d2b13f8c6bf",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c663dd4599f2b1200bbd900d976c016aedda4f8e",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f8a3d46b07c50ff86e6a11249757ee65838c9a95",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0f563fc4526d0a5ed167cdd0041d67957b2092d7",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e45da23fa9a457d61dc8af4b2ec845bc57dc18bd",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "dGY1N3k2Mm5wOWdmMcTvezTVKiOZTS0zxb0uRi8qlT1iQxY6oFymR1E5yEoz"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mecvig",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "james-jiang",
          "discussion_type": null,
          "num_comments": 17,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mecvig/built_a_full_stack_web_app_builder_that_runs/",
          "stickied": false,
          "url": "https://v.redd.it/2pk8172np9gf1",
          "subreddit_subscribers": 507935,
          "created_utc": 1753994504,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/2pk8172np9gf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/2pk8172np9gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/2pk8172np9gf1/DASHPlaylist.mpd?a=1756603209%2COTI2MzdiMThhYjAxZGEzYzc3NDZhZTBhZGExNTY5MmYyN2VlNDU4MWQ1MTAwMDU1Y2NhYWQ2Mjc1NDg1ODU0Mg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 59,
              "hls_url": "https://v.redd.it/2pk8172np9gf1/HLSPlaylist.m3u8?a=1756603209%2CYjg2NjZiMDYzMmQ4NTI2MjgzOWU4MDE4ZTc1MjZmN2E3NmU1NWE1YjFmNjRhNjg3ZWUxNTU2YzBjNWYyZDFjOA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "First try from the most minimalistic prompt possible:\n\n\\&gt; Write an HTML and JavaScript page implementing space invaders",
          "author_fullname": "t2_1gpif4cz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Space Invaders on first try with Qwen3 Coder 30b-a3b (Unsloth Q6_K)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 103,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me44dy",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 91,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/num3q6pa68gf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 972,
              "scrubber_media_url": "https://v.redd.it/num3q6pa68gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/num3q6pa68gf1/DASHPlaylist.mpd?a=1756603209%2CNzBiNDgyZjhkOGY3MmM4OTQ2YTg2MDRjY2I4NjcwNjcwNDZlZjYxNmMwNGU1ODNiOTE5MGYxY2UwOTZlOTk1Mg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 13,
              "hls_url": "https://v.redd.it/num3q6pa68gf1/HLSPlaylist.m3u8?a=1756603209%2CNjUxMWYxOTAyNTJjYjg4MmIzM2UwMTNlOTgwN2JmMmQ2MGVkMWZiNjEzZjFiZjI0YTFiMWU2NDEyODAwYzk2NA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 91,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=140&amp;height=103&amp;crop=140:103,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=d78af21709b988c9bb34037cd93c3da991881f4a",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753974544,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First try from the most minimalistic prompt possible:&lt;/p&gt;\n\n&lt;p&gt;&amp;gt; Write an HTML and JavaScript page implementing space invaders&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/num3q6pa68gf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?format=pjpg&amp;auto=webp&amp;s=82e146458ea227298964e3254c6c09dae6917244",
                  "width": 1040,
                  "height": 770
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3887bb128805d684143e02aca9e08aa4727d7073",
                    "width": 108,
                    "height": 79
                  },
                  {
                    "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0e7c6c211fc49a509a9248164db79d4902320eff",
                    "width": 216,
                    "height": 159
                  },
                  {
                    "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=59874a5490554711f0e161abde8e8208c95390c3",
                    "width": 320,
                    "height": 236
                  },
                  {
                    "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8b5125732b0652e0ade55b38571502b2fde89c53",
                    "width": 640,
                    "height": 473
                  },
                  {
                    "url": "https://external-preview.redd.it/Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=747aabc91b30d3c44a1edf93853f375aacb30019",
                    "width": 960,
                    "height": 710
                  }
                ],
                "variants": {},
                "id": "Z21iOW82cGE2OGdmMf4bjCo6h_II4JpemDAqzdx9OhZnb5PcmXrVKPcJDT7r"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1me44dy",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "waescher",
          "discussion_type": null,
          "num_comments": 34,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me44dy/space_invaders_on_first_try_with_qwen3_coder/",
          "stickied": false,
          "url": "https://v.redd.it/num3q6pa68gf1",
          "subreddit_subscribers": 507935,
          "created_utc": 1753974544,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/num3q6pa68gf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 972,
              "scrubber_media_url": "https://v.redd.it/num3q6pa68gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/num3q6pa68gf1/DASHPlaylist.mpd?a=1756603209%2CNzBiNDgyZjhkOGY3MmM4OTQ2YTg2MDRjY2I4NjcwNjcwNDZlZjYxNmMwNGU1ODNiOTE5MGYxY2UwOTZlOTk1Mg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 13,
              "hls_url": "https://v.redd.it/num3q6pa68gf1/HLSPlaylist.m3u8?a=1756603209%2CNjUxMWYxOTAyNTJjYjg4MmIzM2UwMTNlOTgwN2JmMmQ2MGVkMWZiNjEzZjFiZjI0YTFiMWU2NDEyODAwYzk2NA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi, it's Emre from the Jan team.\n\nJan v0.6.6 is out. Over the past few weeks we've ripped out Cortex, the backend layer on top of llama.cpp. It's finally gone, every local model now runs directly on llama.cpp.\n\nPlus, you can switch to any llama.cpp build under Settings, Model Providers, llama.cpp (see the video above).\n\nJan v0.6.6 Highlights:\n\n* Cortex is removed, local models now run on `llama.cpp`\n* Hugging Face is integrated in Model Providers. So you can paste your HF token and run models in the cloud via Jan\n* Jan Hub has been a bit updated for faster model search and less clutter when browsing models\n* Inline-image support from MCP servers: If an MCP server returns an image (e.g. web search MCP).\n   * It's an experimental feature, please activate Experimental Features in Settings to see MCP settings.\n* Plus, we've also fixed a bunch of bugs\n\nUpdate your Jan or download the latest here: [https://jan.ai/](https://jan.ai/)\n\nFull release notes are here: [https://github.com/menloresearch/jan/releases](https://github.com/menloresearch/jan/releases)\n\n**Quick notes:**\n\n1. We removed Cortex because it added an extra hop and maintenance overhead. Folding its logic into Jan cuts latency and makes future mobile / server work simpler.\n2.  Regarding bugs &amp; previous requests: I'll reply to earlier requests and reports in the previous comments later today.",
          "author_fullname": "t2_g6cmmsdd",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Jan now runs fully on llama.cpp &amp; auto-updates the backend",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 111,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdy1at",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 185,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1356,
              "scrubber_media_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/6tdds5rcr6gf1/DASHPlaylist.mpd?a=1756603209%2CZDQxZGJkYTJlODZjYjVjNTZjNDlmOTQ3NTJjZTE4NThjNTk1OWUzN2ZlODE5NjU5N2I2Yzc3M2VmNjg5NjZlNA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 9,
              "hls_url": "https://v.redd.it/6tdds5rcr6gf1/HLSPlaylist.m3u8?a=1756603209%2CMDdlYTJkNWZmY2Y0YzZmNzVhODI3ZThlNzYwNzgwZWZiY2FjYjBjNjgxZGJlMzkxNTExNTcyODAzY2M2NjM5OA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 185,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=140&amp;height=111&amp;crop=140:111,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=57743d41c68dc489572118ded5f1d929e7abeba3",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753958074,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, it&amp;#39;s Emre from the Jan team.&lt;/p&gt;\n\n&lt;p&gt;Jan v0.6.6 is out. Over the past few weeks we&amp;#39;ve ripped out Cortex, the backend layer on top of llama.cpp. It&amp;#39;s finally gone, every local model now runs directly on llama.cpp.&lt;/p&gt;\n\n&lt;p&gt;Plus, you can switch to any llama.cpp build under Settings, Model Providers, llama.cpp (see the video above).&lt;/p&gt;\n\n&lt;p&gt;Jan v0.6.6 Highlights:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cortex is removed, local models now run on &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Hugging Face is integrated in Model Providers. So you can paste your HF token and run models in the cloud via Jan&lt;/li&gt;\n&lt;li&gt;Jan Hub has been a bit updated for faster model search and less clutter when browsing models&lt;/li&gt;\n&lt;li&gt;Inline-image support from MCP servers: If an MCP server returns an image (e.g. web search MCP).\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s an experimental feature, please activate Experimental Features in Settings to see MCP settings.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Plus, we&amp;#39;ve also fixed a bunch of bugs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Update your Jan or download the latest here: &lt;a href=\"https://jan.ai/\"&gt;https://jan.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full release notes are here: &lt;a href=\"https://github.com/menloresearch/jan/releases\"&gt;https://github.com/menloresearch/jan/releases&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick notes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We removed Cortex because it added an extra hop and maintenance overhead. Folding its logic into Jan cuts latency and makes future mobile / server work simpler.&lt;/li&gt;\n&lt;li&gt; Regarding bugs &amp;amp; previous requests: I&amp;#39;ll reply to earlier requests and reports in the previous comments later today.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/6tdds5rcr6gf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?format=pjpg&amp;auto=webp&amp;s=0e1c5efd621cd98139d0e6f762c83f3c37e7fea5",
                  "width": 1356,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f859c3bb7426a18c330ce87e3736a28dafc099f8",
                    "width": 108,
                    "height": 86
                  },
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6cb9d82211a044a07e0f4b70dfed27d01999f9f4",
                    "width": 216,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c95516a9359bd83519226daa998fe6d691200ba6",
                    "width": 320,
                    "height": 254
                  },
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=00d6e43fd5842c4ff17dcac2371f246a689ce076",
                    "width": 640,
                    "height": 509
                  },
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25d7157f5ce696d297059ecb73ed2080cffbd80c",
                    "width": 960,
                    "height": 764
                  },
                  {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=79790394777eecaa52d5cec4ae8f93b678e4a94d",
                    "width": 1080,
                    "height": 860
                  }
                ],
                "variants": {},
                "id": "OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mdy1at",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "eck72",
          "discussion_type": null,
          "num_comments": 44,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/",
          "stickied": false,
          "url": "https://v.redd.it/6tdds5rcr6gf1",
          "subreddit_subscribers": 507935,
          "created_utc": 1753958074,
          "num_crossposts": 1,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1356,
              "scrubber_media_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/6tdds5rcr6gf1/DASHPlaylist.mpd?a=1756603209%2CZDQxZGJkYTJlODZjYjVjNTZjNDlmOTQ3NTJjZTE4NThjNTk1OWUzN2ZlODE5NjU5N2I2Yzc3M2VmNjg5NjZlNA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 9,
              "hls_url": "https://v.redd.it/6tdds5rcr6gf1/HLSPlaylist.m3u8?a=1756603209%2CMDdlYTJkNWZmY2Y0YzZmNzVhODI3ZThlNzYwNzgwZWZiY2FjYjBjNjgxZGJlMzkxNTExNTcyODAzY2M2NjM5OA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1mqxxcqio8",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Chinese models pulling away",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdmsu9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 1126,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 1126,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/WAZkPWKkayjP-D84-JfBNhxMGyjfTxBCkqcnNqASaSM.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753920375,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/727keqreo3gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/727keqreo3gf1.png?auto=webp&amp;s=fbd047ec9c49dcc4ecc981ac438a33640cf82f64",
                  "width": 500,
                  "height": 659
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/727keqreo3gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6a70ba5db010ef5c37f2d20d7547480395fec85",
                    "width": 108,
                    "height": 142
                  },
                  {
                    "url": "https://preview.redd.it/727keqreo3gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4b427a0b64f0cfaebdc6ca4299f1db7633d895d",
                    "width": 216,
                    "height": 284
                  },
                  {
                    "url": "https://preview.redd.it/727keqreo3gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=638ce7aed31fa426f1cfea7678c6d9169932f5a9",
                    "width": 320,
                    "height": 421
                  }
                ],
                "variants": {},
                "id": "l5AL3evi8AGzgsGPpE-AV-Xqab8IV712A4wAAWJsjNM"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mdmsu9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Kniffliger_Kiffer",
          "discussion_type": null,
          "num_comments": 134,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdmsu9/chinese_models_pulling_away/",
          "stickied": false,
          "url": "https://i.redd.it/727keqreo3gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753920375,
          "num_crossposts": 2,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "**Qwen3-Coder** is available in multiple sizes. Today, we're excited to introduce **Qwen3-Coder-30B-A3B-Instruct**. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:\n\n* **Significant Performance** among open models on **Agentic Coding**, **Agentic Browser-Use**, and other foundational coding tasks.\n* **Long-context Capabilities** with native support for **256K** tokens, extendable up to **1M** tokens using Yarn, optimized for repository-scale understanding.\n* **Agentic Coding** supporting for most platform such as **Qwen Code**, **CLINE**, featuring a specially designed function call format.\n\n**Qwen3-Coder-30B-A3B-Instruct** has the following features:\n\n* Type: Causal Language Models\n* Training Stage: Pretraining &amp; Post-training\n* Number of Parameters: 30.5B in total and 3.3B activated\n* Number of Layers: 48\n* Number of Attention Heads (GQA): 32 for Q and 4 for KV\n* Number of Experts: 128\n* Number of Activated Experts: 8\n* Context Length: **262,144 natively**.",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen/Qwen3-Coder-30B-A3B-Instruct Â· Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me324b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": "#bbbdbf",
          "ups": 77,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 77,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=50e58d8c576ff1f0469c49c5086a3d54ed8234ad",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753972061,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Qwen3-Coder&lt;/strong&gt; is available in multiple sizes. Today, we&amp;#39;re excited to introduce &lt;strong&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/strong&gt;. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Significant Performance&lt;/strong&gt; among open models on &lt;strong&gt;Agentic Coding&lt;/strong&gt;, &lt;strong&gt;Agentic Browser-Use&lt;/strong&gt;, and other foundational coding tasks.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Long-context Capabilities&lt;/strong&gt; with native support for &lt;strong&gt;256K&lt;/strong&gt; tokens, extendable up to &lt;strong&gt;1M&lt;/strong&gt; tokens using Yarn, optimized for repository-scale understanding.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Agentic Coding&lt;/strong&gt; supporting for most platform such as &lt;strong&gt;Qwen Code&lt;/strong&gt;, &lt;strong&gt;CLINE&lt;/strong&gt;, featuring a specially designed function call format.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/strong&gt; has the following features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Type: Causal Language Models&lt;/li&gt;\n&lt;li&gt;Training Stage: Pretraining &amp;amp; Post-training&lt;/li&gt;\n&lt;li&gt;Number of Parameters: 30.5B in total and 3.3B activated&lt;/li&gt;\n&lt;li&gt;Number of Layers: 48&lt;/li&gt;\n&lt;li&gt;Number of Attention Heads (GQA): 32 for Q and 4 for KV&lt;/li&gt;\n&lt;li&gt;Number of Experts: 128&lt;/li&gt;\n&lt;li&gt;Number of Activated Experts: 8&lt;/li&gt;\n&lt;li&gt;Context Length: &lt;strong&gt;262,144 natively&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?auto=webp&amp;s=4cacac54fb0a262f4128b23481bccaf4104c19d5",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf0440b72bf3c599b24d782f0bddf00251537cf",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=824bee5d7aa9841a221b2f60a969d54551eccb18",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ca7f6cb7614731e917c0c8e162bd66bfbc25ca",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d2b1429fc14f5ca152608718fd3ef6d50119778",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6655884fe4ff60136ee88021696ace5be4875862",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=991b600ad67e419b1091cac2c8c55f34d86b36fa",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me324b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 17,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
          "subreddit_subscribers": 507935,
          "created_utc": 1753972061,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_kwl47",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "stepfun-ai/step3 Â· Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me1i0c",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 113,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 113,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=1566d8abcbe44f7ec1240af4df2344ad1fe704b6",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753968304,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/stepfun-ai/step3",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?auto=webp&amp;s=f711cef7b2b4b7da9ae10fa40e4b50a422684888",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b5eb1f88337c545253e9f56a79b85014a7240f9",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=99659d2063e07b2ee1d7d0ed4bfb6be8b4279a70",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9a8f549518a8525d25d665dea1dfc9147d242e1",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=145f1332e4eb20fc0be0e7f46d3c0b92fb74d49e",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d3520e606371c9566a25de9bb3f776b3739c514",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6ad833f70a024fd9209dbf735b334a55be6bdd02",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "PByxBes8ZhS0GaNzaLsdD1cFy0LWtkBpScIt3kOY-nk"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me1i0c",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Dark_Fire_12",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me1i0c/stepfunaistep3_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/stepfun-ai/step3",
          "subreddit_subscribers": 507935,
          "created_utc": 1753968304,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Is this the best week ever for new models? I can't believe what we're getting. Huge shoutout to u/danielhanchen and the Unsloth team for getting the GGUFs out so fast!\n\nLLM Server is Lemonade, GitHub: [https://github.com/lemonade-sdk/lemonade](https://github.com/lemonade-sdk/lemonade)\n\nDiscord [https://discord.gg/Sf8cfBWB](https://discord.gg/Sf8cfBWB)\n\nModel: [unsloth/cogito-v2-preview-llama-109B-MoE-GGUF Â· Hugging Face](https://huggingface.co/unsloth/cogito-v2-preview-llama-109B-MoE-GGUF), the Q4\\_K\\_M one\n\nHardware: Strix Halo (Ryzen AI MAX 395+) with 128 GB RAM\n\nBackend: llama.cpp + vulkan\n\nApp: [Continue.dev](http://Continue.dev) extension for VS Code",
          "author_fullname": "t2_1m2ckixcqh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Here's cogito-v2-109B MoE coding Space Invaders in 1 minute on Strix Halo using Lemonade (unedited video)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 91,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mee99g",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.85,
          "author_flair_background_color": null,
          "ups": 18,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/39k2gtxw2agf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1104,
              "scrubber_media_url": "https://v.redd.it/39k2gtxw2agf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/39k2gtxw2agf1/DASHPlaylist.mpd?a=1756603209%2CMzk3MTFiY2FhN2UzNDViNTNiMTNiZmNmNjEyNGI0ZWIzMjYxOTc0MmNhNGNmYWExMjcyYjFiYTY5MDVlYjU1NA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 68,
              "hls_url": "https://v.redd.it/39k2gtxw2agf1/HLSPlaylist.m3u8?a=1756603209%2CYzg0OWFhZWE4NmExYzc5MDA1Y2U5MTkwN2I2MGYzNGZjYTQxMDZjOTkyYTNmZmI2ZDE5ZTE2NjA0NjJkMTM1Mw%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 18,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=140&amp;height=91&amp;crop=140:91,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=21d4633fb4807e9455477c27ddd4db6626d7b972",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753997776,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this the best week ever for new models? I can&amp;#39;t believe what we&amp;#39;re getting. Huge shoutout to &lt;a href=\"/u/danielhanchen\"&gt;u/danielhanchen&lt;/a&gt; and the Unsloth team for getting the GGUFs out so fast!&lt;/p&gt;\n\n&lt;p&gt;LLM Server is Lemonade, GitHub: &lt;a href=\"https://github.com/lemonade-sdk/lemonade\"&gt;https://github.com/lemonade-sdk/lemonade&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Discord &lt;a href=\"https://discord.gg/Sf8cfBWB\"&gt;https://discord.gg/Sf8cfBWB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Model: &lt;a href=\"https://huggingface.co/unsloth/cogito-v2-preview-llama-109B-MoE-GGUF\"&gt;unsloth/cogito-v2-preview-llama-109B-MoE-GGUF Â· Hugging Face&lt;/a&gt;, the Q4_K_M one&lt;/p&gt;\n\n&lt;p&gt;Hardware: Strix Halo (Ryzen AI MAX 395+) with 128 GB RAM&lt;/p&gt;\n\n&lt;p&gt;Backend: llama.cpp + vulkan&lt;/p&gt;\n\n&lt;p&gt;App: &lt;a href=\"http://Continue.dev\"&gt;Continue.dev&lt;/a&gt; extension for VS Code&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/39k2gtxw2agf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?format=pjpg&amp;auto=webp&amp;s=f82b95773d44af758611ac930fbad79416657daf",
                  "width": 1196,
                  "height": 780
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=703b4735f6cd2310092b4fc6927b9b41ee451c18",
                    "width": 108,
                    "height": 70
                  },
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e24d475c524c135573f9b2b0dd414dcb775633c0",
                    "width": 216,
                    "height": 140
                  },
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=eb8c20a4a14839a1e9e65d7d4d9cd9226fb6a2a5",
                    "width": 320,
                    "height": 208
                  },
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8bd29e4af6c5a75943cebddae22cea91a051312c",
                    "width": 640,
                    "height": 417
                  },
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=22ebfd65a9f3d71ba2dc2408a03963d4e025023d",
                    "width": 960,
                    "height": 626
                  },
                  {
                    "url": "https://external-preview.redd.it/M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4e5044572ec3d4191f57e25070a626e21e41372c",
                    "width": 1080,
                    "height": 704
                  }
                ],
                "variants": {},
                "id": "M3ppMGd2eHcyYWdmMStZsfyV8F4GV6vQy52E9vmc2CGAsEmxg4Z4VgmDbWvl"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mee99g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jfowers_amd",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mee99g/heres_cogitov2109b_moe_coding_space_invaders_in_1/",
          "stickied": false,
          "url": "https://v.redd.it/39k2gtxw2agf1",
          "subreddit_subscribers": 507935,
          "created_utc": 1753997776,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/39k2gtxw2agf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1104,
              "scrubber_media_url": "https://v.redd.it/39k2gtxw2agf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/39k2gtxw2agf1/DASHPlaylist.mpd?a=1756603209%2CMzk3MTFiY2FhN2UzNDViNTNiMTNiZmNmNjEyNGI0ZWIzMjYxOTc0MmNhNGNmYWExMjcyYjFiYTY5MDVlYjU1NA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 68,
              "hls_url": "https://v.redd.it/39k2gtxw2agf1/HLSPlaylist.m3u8?a=1756603209%2CYzg0OWFhZWE4NmExYzc5MDA1Y2U5MTkwN2I2MGYzNGZjYTQxMDZjOTkyYTNmZmI2ZDE5ZTE2NjA0NjJkMTM1Mw%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Cohere Labs Command A Vision is an open weights research release of a 112 billion parameter model optimized for enterprise image understanding tasks, while keeping a low compute footprint.\n\nDeveloped by: [Cohere](https://cohere.com/) and [Cohere Labs](https://cohere.com/research)\n\n* Point of Contact: [**Cohere Labs**](https://cohere.com/research)\n* License: [CC-BY-NC](https://cohere.com/c4ai-cc-by-nc-license), requires also adhering to [**Cohere Lab's Acceptable Use Policy**](https://docs.cohere.com/docs/c4ai-acceptable-use-policy)\n* Model: command-a-vision-07-2025\n* Model Size: 112B\n* Context length: 32k\n\nFor more details about this model, please check out our [blog post](https://cohere.com/blog/command-a-vision).",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "CohereLabs/command-a-vision-07-2025 Â· Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me2o28",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": "#bbbdbf",
          "ups": 66,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 66,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=ed426ad9af051ef373cfb52c8eb42685fd33ad39",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753971123,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cohere Labs Command A Vision is an open weights research release of a 112 billion parameter model optimized for enterprise image understanding tasks, while keeping a low compute footprint.&lt;/p&gt;\n\n&lt;p&gt;Developed by: &lt;a href=\"https://cohere.com/\"&gt;Cohere&lt;/a&gt; and &lt;a href=\"https://cohere.com/research\"&gt;Cohere Labs&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Point of Contact: &lt;a href=\"https://cohere.com/research\"&gt;&lt;strong&gt;Cohere Labs&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;License: &lt;a href=\"https://cohere.com/c4ai-cc-by-nc-license\"&gt;CC-BY-NC&lt;/a&gt;, requires also adhering to &lt;a href=\"https://docs.cohere.com/docs/c4ai-acceptable-use-policy\"&gt;&lt;strong&gt;Cohere Lab&amp;#39;s Acceptable Use Policy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Model: command-a-vision-07-2025&lt;/li&gt;\n&lt;li&gt;Model Size: 112B&lt;/li&gt;\n&lt;li&gt;Context length: 32k&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For more details about this model, please check out our &lt;a href=\"https://cohere.com/blog/command-a-vision\"&gt;blog post&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/CohereLabs/command-a-vision-07-2025",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?auto=webp&amp;s=93cc9fb5ee6d2fb7cc3554000d86db2c491e6269",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf6e50905656297c173c03abdd389f18f39e7de0",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94c292676944b6f86407287f93339ff4938d9417",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e29e41aa3da072c805c573721b0931720938729",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f8f1ed0131023e16880670c162fe440277d09d1",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4fe5c093d52b6fcc891a3ad98822554f5c0406d0",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e97233b9a305b0e74041df7aad6526b254df186b",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "KSnKoHRzOtDVdgv4tkOqKzIXPL8-S-fhBqaAliU-gUw"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me2o28",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1me2o28/coherelabscommandavision072025_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/CohereLabs/command-a-vision-07-2025",
          "subreddit_subscribers": 507935,
          "created_utc": 1753971123,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "China no. 1!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me2o4z",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.62,
          "author_flair_background_color": "transparent",
          "ups": 78,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 78,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/uwGkWUsPiGNrcJ2Rrtiimbx7kIKsxi1zQHqGpFloMfI.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753971128,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/s1g7byiow7gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?auto=webp&amp;s=d59e87f6adf0d5792eeb3ddb665a4593cb1797e2",
                  "width": 1024,
                  "height": 1024
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b46171142a4279de1ff354a7559a1dc9bf5a884d",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=646ff76820fb63773557fa79f6bf420ea5f69244",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c7faf8289f8aab618ccea7eb72246eaa3844e52",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2bf6c0666d463c92bb91f98489dcbe89f054443",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/s1g7byiow7gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae2690dc819da92970eb4eeb7c7db893d55d307e",
                    "width": 960,
                    "height": 960
                  }
                ],
                "variants": {},
                "id": "Pfx2EIRrkzQDdICtJdaNSQkGVFQD5VgRi8zkx7vPLrs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1me2o4z",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 45,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1me2o4z/china_no_1/",
          "stickied": false,
          "url": "https://i.redd.it/s1g7byiow7gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753971128,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I just checked the Aider polyglot score of the [Qwen3-Coder-30B-A3B-Instruct](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct) model, it seems they are showing the score of ***diff*** **Edit Format**\n\nAnd a quick comparison against the last local qwen coder model, shows a huge jump in performance: \n\n8% -&gt; 33.3% \n\nhttps://preview.redd.it/br3ue82e48gf1.png?width=759&amp;format=png&amp;auto=webp&amp;s=19fa20c3f58f95f1b1dc7d5bc933387bef10f308\n\nhttps://preview.redd.it/xhs1sz8158gf1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=0554ca3bfdee5dd9085d2fe00dad006e9b8ce6d2\n\n",
          "author_fullname": "t2_4gc7hf3m",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "8% -&gt; 33.3% on Aider polyglot",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "br3ue82e48gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 91,
                  "x": 108,
                  "u": "https://preview.redd.it/br3ue82e48gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd41128d487dd1dd6b37ebcd5e3f95cb26315f88"
                },
                {
                  "y": 183,
                  "x": 216,
                  "u": "https://preview.redd.it/br3ue82e48gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=372a243f6df4278f20eee10954fc24392ff0d91b"
                },
                {
                  "y": 271,
                  "x": 320,
                  "u": "https://preview.redd.it/br3ue82e48gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d71c4bbd87177375ad35c2ae4a3da8f6cc25530"
                },
                {
                  "y": 543,
                  "x": 640,
                  "u": "https://preview.redd.it/br3ue82e48gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5d270ed5f1841848dd71fe3b7c2088dd9b38510e"
                }
              ],
              "s": {
                "y": 644,
                "x": 759,
                "u": "https://preview.redd.it/br3ue82e48gf1.png?width=759&amp;format=png&amp;auto=webp&amp;s=19fa20c3f58f95f1b1dc7d5bc933387bef10f308"
              },
              "id": "br3ue82e48gf1"
            },
            "xhs1sz8158gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 69,
                  "x": 108,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3d28ae1d3270890a494b04ee2b87128ecc420be"
                },
                {
                  "y": 138,
                  "x": 216,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=de74f05c6c2a17382e3229fb8720a85ce78feefd"
                },
                {
                  "y": 205,
                  "x": 320,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=81d568bf06d6c88e12b4d7fed9be2e315a820a3b"
                },
                {
                  "y": 411,
                  "x": 640,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9277417c81cbf8186e23268d7037c28d386df598"
                },
                {
                  "y": 616,
                  "x": 960,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=18b54097357497918076129b168b0388c8624e9d"
                },
                {
                  "y": 693,
                  "x": 1080,
                  "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41f4903ab24f854d690d913f0dbe33ac0ccc2aa4"
                }
              ],
              "s": {
                "y": 854,
                "x": 1329,
                "u": "https://preview.redd.it/xhs1sz8158gf1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=0554ca3bfdee5dd9085d2fe00dad006e9b8ce6d2"
              },
              "id": "xhs1sz8158gf1"
            }
          },
          "name": "t3_1me3vpe",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": "#bbbdbf",
          "ups": 51,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 51,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=50e58d8c576ff1f0469c49c5086a3d54ed8234ad",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1753974005,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just checked the Aider polyglot score of the &lt;a href=\"https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct\"&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/a&gt; model, it seems they are showing the score of &lt;strong&gt;&lt;em&gt;diff&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;Edit Format&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;And a quick comparison against the last local qwen coder model, shows a huge jump in performance: &lt;/p&gt;\n\n&lt;p&gt;8% -&amp;gt; 33.3% &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/br3ue82e48gf1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=19fa20c3f58f95f1b1dc7d5bc933387bef10f308\"&gt;https://preview.redd.it/br3ue82e48gf1.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=19fa20c3f58f95f1b1dc7d5bc933387bef10f308&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xhs1sz8158gf1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0554ca3bfdee5dd9085d2fe00dad006e9b8ce6d2\"&gt;https://preview.redd.it/xhs1sz8158gf1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0554ca3bfdee5dd9085d2fe00dad006e9b8ce6d2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?auto=webp&amp;s=4cacac54fb0a262f4128b23481bccaf4104c19d5",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf0440b72bf3c599b24d782f0bddf00251537cf",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=824bee5d7aa9841a221b2f60a969d54551eccb18",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ca7f6cb7614731e917c0c8e162bd66bfbc25ca",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d2b1429fc14f5ca152608718fd3ef6d50119778",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6655884fe4ff60136ee88021696ace5be4875862",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=991b600ad67e419b1091cac2c8c55f34d86b36fa",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me3vpe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "AaronFeng47",
          "discussion_type": null,
          "num_comments": 19,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1me3vpe/8_333_on_aider_polyglot/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me3vpe/8_333_on_aider_polyglot/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753974005,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "For the longest time, I've been giving my models a traditional puzzle that all failed to pass without fail :D  \nNot even the SOTA models provide the right answer.\n\n&gt;The puzzle is as follows:   \n\"What's the right answer: Imagine standing at the North Pole of the Earth. Walk in any direction, in a straight line, for 1 km. Now turn 90 degrees to the left. Walk for as long as it takes to pass your starting point. Have you walked: \n\n&gt;1- More than 2xPi km.  \n2- Exactly 2xPi km.  \n3- Less than 2xPi km.  \n4- I never came close to my starting point.\n\nHowever, only recently, SOTA models started to correctly answer 4 ; models like O3, latest Qwen (Qween3-235B-A22B-2507), Deepseek R1 managed to answer it correctly (I didn't test Claud 4 or Grok 4 but I guess they might get it right). For comparison, Gemini-2.5-Thinking and Kimi2 got the wrong answer.\n\nSo, I happy to report that Qwen3-30B-A3B-2507 (both the none thinking Q6 and the thinking Q4) managed to solve the puzzle providing great answers.\n\nHere is O3 answer:\n\nhttps://preview.redd.it/rbwgf8vxa7gf1.png?width=866&amp;format=png&amp;auto=webp&amp;s=d074bec940c5c3fab89cc06a5cdf7279ed154ea0\n\nAnd here is the answer of the Qwen3-30B-A3B-Thinking-2507-Q4\\_K\\_L:\n\nhttps://preview.redd.it/esglti77b7gf1.png?width=821&amp;format=png&amp;auto=webp&amp;s=9d2e5321f3918bec8209d8613d1ce2df621cd416\n\nIn addition, I tested the two variants on long text (up to 80K) for comprehension, and I am impressed by the quality of the answers. And the SPEEEEEED! It's 3 times faster than Gemma-4B!!!!\n\n\n\nAnyway, let me know what you think,",
          "author_fullname": "t2_byt5wa14",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-30B-A3B-2507-Q4_K_L Is the First Local Model to Solve the North Pole Walk Puzzle",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 60,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "esglti77b7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 87,
                  "x": 108,
                  "u": "https://preview.redd.it/esglti77b7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa4c861cb82d74fa884e07763d49a9087f956d22"
                },
                {
                  "y": 174,
                  "x": 216,
                  "u": "https://preview.redd.it/esglti77b7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a1cfe9a1b5c0462b3615bc71b7d76aed45acf149"
                },
                {
                  "y": 258,
                  "x": 320,
                  "u": "https://preview.redd.it/esglti77b7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2cbac2d110c2783a443d0cb885b248a0d5eef241"
                },
                {
                  "y": 516,
                  "x": 640,
                  "u": "https://preview.redd.it/esglti77b7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2094d8a756e6c8ded571ddc2e08b260c39b760"
                }
              ],
              "s": {
                "y": 663,
                "x": 821,
                "u": "https://preview.redd.it/esglti77b7gf1.png?width=821&amp;format=png&amp;auto=webp&amp;s=9d2e5321f3918bec8209d8613d1ce2df621cd416"
              },
              "id": "esglti77b7gf1"
            },
            "rbwgf8vxa7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 46,
                  "x": 108,
                  "u": "https://preview.redd.it/rbwgf8vxa7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1662b020232e38c498b9c33b3a84a623a9c9687"
                },
                {
                  "y": 93,
                  "x": 216,
                  "u": "https://preview.redd.it/rbwgf8vxa7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2257e7230fe7883100398d769880650162fb2391"
                },
                {
                  "y": 138,
                  "x": 320,
                  "u": "https://preview.redd.it/rbwgf8vxa7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=72caaec311bc8ebe2c27b8b7ee5fb903baa018c6"
                },
                {
                  "y": 276,
                  "x": 640,
                  "u": "https://preview.redd.it/rbwgf8vxa7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cba947c4bd3e5de66a6067de3cf1811cf7f499b9"
                }
              ],
              "s": {
                "y": 374,
                "x": 866,
                "u": "https://preview.redd.it/rbwgf8vxa7gf1.png?width=866&amp;format=png&amp;auto=webp&amp;s=d074bec940c5c3fab89cc06a5cdf7279ed154ea0"
              },
              "id": "rbwgf8vxa7gf1"
            }
          },
          "name": "t3_1mdzxmv",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": "#bbbdbf",
          "subreddit_type": "public",
          "ups": 77,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 77,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/L3dTMc7iVqHF7QYQEYnpMXvgm0DsrwCLc5zwFJKZCxk.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753964105,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the longest time, I&amp;#39;ve been giving my models a traditional puzzle that all failed to pass without fail :D&lt;br/&gt;\nNot even the SOTA models provide the right answer.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The puzzle is as follows:&lt;br/&gt;\n&amp;quot;What&amp;#39;s the right answer: Imagine standing at the North Pole of the Earth. Walk in any direction, in a straight line, for 1 km. Now turn 90 degrees to the left. Walk for as long as it takes to pass your starting point. Have you walked: &lt;/p&gt;\n\n&lt;p&gt;1- More than 2xPi km.&lt;br/&gt;\n2- Exactly 2xPi km.&lt;br/&gt;\n3- Less than 2xPi km.&lt;br/&gt;\n4- I never came close to my starting point.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;However, only recently, SOTA models started to correctly answer 4 ; models like O3, latest Qwen (Qween3-235B-A22B-2507), Deepseek R1 managed to answer it correctly (I didn&amp;#39;t test Claud 4 or Grok 4 but I guess they might get it right). For comparison, Gemini-2.5-Thinking and Kimi2 got the wrong answer.&lt;/p&gt;\n\n&lt;p&gt;So, I happy to report that Qwen3-30B-A3B-2507 (both the none thinking Q6 and the thinking Q4) managed to solve the puzzle providing great answers.&lt;/p&gt;\n\n&lt;p&gt;Here is O3 answer:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rbwgf8vxa7gf1.png?width=866&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d074bec940c5c3fab89cc06a5cdf7279ed154ea0\"&gt;https://preview.redd.it/rbwgf8vxa7gf1.png?width=866&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d074bec940c5c3fab89cc06a5cdf7279ed154ea0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here is the answer of the Qwen3-30B-A3B-Thinking-2507-Q4_K_L:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/esglti77b7gf1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d2e5321f3918bec8209d8613d1ce2df621cd416\"&gt;https://preview.redd.it/esglti77b7gf1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d2e5321f3918bec8209d8613d1ce2df621cd416&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In addition, I tested the two variants on long text (up to 80K) for comprehension, and I am impressed by the quality of the answers. And the SPEEEEEED! It&amp;#39;s 3 times faster than Gemma-4B!!!!&lt;/p&gt;\n\n&lt;p&gt;Anyway, let me know what you think,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdzxmv",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Iory1998",
          "discussion_type": null,
          "num_comments": 68,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mdzxmv/qwen330ba3b2507q4_k_l_is_the_first_local_model_to/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdzxmv/qwen330ba3b2507q4_k_l_is_the_first_local_model_to/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753964105,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It's definitely OpenAI's upcoming \"open-source\" model.",
          "author_fullname": "t2_6h87m4sy",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "\"Horizon Alpha\" hides its thinking",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1megpco",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.77,
          "author_flair_background_color": null,
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/YZRXuBCLq1UiB4iPw3luGykiQBe0vKGt-Ol6iZcAcOc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754003932,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s definitely OpenAI&amp;#39;s upcoming &amp;quot;open-source&amp;quot; model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ewdetoz7magf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?auto=webp&amp;s=d22df1a9f5442fa65616fa60bcc618fe103abfd3",
                  "width": 1440,
                  "height": 2451
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1fa5a86d9494123d5af599968bcf9f3c2ab876ea",
                    "width": 108,
                    "height": 183
                  },
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a12799a98b113b668b416ead4c6657f2e513d43",
                    "width": 216,
                    "height": 367
                  },
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78e4cb7a23c2256ab7236cab317d291a84ceea5f",
                    "width": 320,
                    "height": 544
                  },
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=82118360c2fd679d040ecec1fa5221540c1f86aa",
                    "width": 640,
                    "height": 1089
                  },
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2101a03dc77b4ac893969543bab1e288bf5e4134",
                    "width": 960,
                    "height": 1634
                  },
                  {
                    "url": "https://preview.redd.it/ewdetoz7magf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad243f241edc3743b06b9b9255b9f18416b2ded1",
                    "width": 1080,
                    "height": 1838
                  }
                ],
                "variants": {},
                "id": "EB5kQaMVkF2acjk5J_bNzBPaMmm0HRdSNipm28fxUMI"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1megpco",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ICYPhoenix7",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1megpco/horizon_alpha_hides_its_thinking/",
          "stickied": false,
          "url": "https://i.redd.it/ewdetoz7magf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1754003932,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://x.com/bfl\\_ml/status/1950920537741336801](https://x.com/bfl_ml/status/1950920537741336801)",
          "author_fullname": "t2_7g0m6735",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "FLUX.1 Krea [dev] - a new state-of-the-art open-weights FLUX model, built for photorealism.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me2wxx",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 47,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 47,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=aa37b8a748a8f1a6d986c12ecc6075c3faa95d13",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753971722,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://x.com/bfl_ml/status/1950920537741336801\"&gt;https://x.com/bfl_ml/status/1950920537741336801&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/black-forest-labs/FLUX.1-Krea-dev",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?auto=webp&amp;s=1f6abf8893a59cefdbab559b12f23850f20e521a",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0653c84335d6638557b27eaa1db7b3d010a5cdb6",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=399c56cc4a18e0002670fcd2ecba8f2f8f924e57",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=09e7f72733b03f7dc925cc78f44642bb1f8d2ff2",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c0a8e39227d0736d9e58d3198406a64fbdafba6",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a0da9811f2633c94f683ebccc067d1b9942545ed",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e577106b6d2b0bc8703c48d15532d6e2c9deb79c",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "umBIFB2q0PLAR4i8_IGsGxcKPqvKt-H27oJu9PzZu6Y"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me2wxx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ApprehensiveAd3629",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me2wxx/flux1_krea_dev_a_new_stateoftheart_openweights/",
          "stickied": false,
          "url": "https://huggingface.co/black-forest-labs/FLUX.1-Krea-dev",
          "subreddit_subscribers": 507935,
          "created_utc": 1753971722,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "ðŸš€ We're excited to share our latest research on X-Omni: reinforcement learning makes discrete autoregressive image generative models great again, empowering a practical unified model for both image and language modality generation.\n\nHighlights:\n\nâœ… Unified Modeling Approach: A discrete autoregressive model handling image and language modalities.\n\nâœ… Superior Instruction Following: Exceptional capability to follow complex instructions.\n\nâœ… Superior Text Rendering: Accurately render text in multiple languages, including both English and Chinese.\n\nâœ… Arbitrary resolutions: Produces aesthetically pleasing images at arbitrary resolutions.\n\nInsight:\n\nðŸ” During the reinforcement learning process, the aesthetic quality of generated images is gradually enhanced, and the ability to adhere to instructions and the capacity to render long texts improve steadily.\n\nPaper: https://arxiv.org/pdf/2507.22058\nGithub: https://github.com/X-Omni-Team/X-Omni\nProject Page: https://x-omni-team.github.io/\n\n",
          "author_fullname": "t2_c705ri9b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Hunyuan releases X-Omni, a unified discrete autoregressive model for both image and language modalities",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "rauc3hmya7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 110,
                  "x": 108,
                  "u": "https://preview.redd.it/rauc3hmya7gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=db31c12a8fbee6333559636cb9aeb99146e1694a"
                },
                {
                  "y": 220,
                  "x": 216,
                  "u": "https://preview.redd.it/rauc3hmya7gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4d59ead47b55e63b6ee537a2a4ea41eaaa1c6146"
                },
                {
                  "y": 327,
                  "x": 320,
                  "u": "https://preview.redd.it/rauc3hmya7gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea15a909413ad7956d7752cdd490b390121ea17a"
                }
              ],
              "s": {
                "y": 354,
                "x": 346,
                "u": "https://preview.redd.it/rauc3hmya7gf1.jpg?width=346&amp;format=pjpg&amp;auto=webp&amp;s=696d4c8a651b65d38563d0afec8bd124f0f81654"
              },
              "id": "rauc3hmya7gf1"
            },
            "71rr5nnya7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 111,
                  "x": 108,
                  "u": "https://preview.redd.it/71rr5nnya7gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe01c2994c8fb47c1b39cb99f35ba55f7d9dde2e"
                },
                {
                  "y": 222,
                  "x": 216,
                  "u": "https://preview.redd.it/71rr5nnya7gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=725fe16de4c07d1b19dee1d1f77bbfd8f8ec6542"
                },
                {
                  "y": 329,
                  "x": 320,
                  "u": "https://preview.redd.it/71rr5nnya7gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=115e93af2ee69d708a88e4aae8dd1f250f62c733"
                }
              ],
              "s": {
                "y": 546,
                "x": 531,
                "u": "https://preview.redd.it/71rr5nnya7gf1.jpg?width=531&amp;format=pjpg&amp;auto=webp&amp;s=44b4ae50521d09e2a0883ff79bb51311b6795262"
              },
              "id": "71rr5nnya7gf1"
            }
          },
          "name": "t3_1mdzu08",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 67,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "71rr5nnya7gf1",
                "id": 718038871
              },
              {
                "media_id": "rauc3hmya7gf1",
                "id": 718038872
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 67,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/UWzewWY4cRLtu0QtYjM_H7EidNwT1bopn8L_07vMWc4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753963825,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ðŸš€ We&amp;#39;re excited to share our latest research on X-Omni: reinforcement learning makes discrete autoregressive image generative models great again, empowering a practical unified model for both image and language modality generation.&lt;/p&gt;\n\n&lt;p&gt;Highlights:&lt;/p&gt;\n\n&lt;p&gt;âœ… Unified Modeling Approach: A discrete autoregressive model handling image and language modalities.&lt;/p&gt;\n\n&lt;p&gt;âœ… Superior Instruction Following: Exceptional capability to follow complex instructions.&lt;/p&gt;\n\n&lt;p&gt;âœ… Superior Text Rendering: Accurately render text in multiple languages, including both English and Chinese.&lt;/p&gt;\n\n&lt;p&gt;âœ… Arbitrary resolutions: Produces aesthetically pleasing images at arbitrary resolutions.&lt;/p&gt;\n\n&lt;p&gt;Insight:&lt;/p&gt;\n\n&lt;p&gt;ðŸ” During the reinforcement learning process, the aesthetic quality of generated images is gradually enhanced, and the ability to adhere to instructions and the capacity to render long texts improve steadily.&lt;/p&gt;\n\n&lt;p&gt;Paper: &lt;a href=\"https://arxiv.org/pdf/2507.22058\"&gt;https://arxiv.org/pdf/2507.22058&lt;/a&gt;\nGithub: &lt;a href=\"https://github.com/X-Omni-Team/X-Omni\"&gt;https://github.com/X-Omni-Team/X-Omni&lt;/a&gt;\nProject Page: &lt;a href=\"https://x-omni-team.github.io/\"&gt;https://x-omni-team.github.io/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mdzu08",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mdzu08",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ResearchCrafty1804",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdzu08/hunyuan_releases_xomni_a_unified_discrete/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mdzu08",
          "subreddit_subscribers": 507935,
          "created_utc": 1753963825,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Yes, it's an image model and not a language model, but this blog post is really interesting, especially the parts t hat discuss the Pdata. \n\nhttps://www.krea.ai/blog/flux-krea-open-source-release\n\n**I am not affiliated with Black Forest, Flux, or any of these companies, I'm just sharing the link.**",
          "author_fullname": "t2_1f1tptkzcs",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Releasing Open Weights for FLUX.1 Krea",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1meiizp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": true,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754008914,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, it&amp;#39;s an image model and not a language model, but this blog post is really interesting, especially the parts t hat discuss the Pdata. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.krea.ai/blog/flux-krea-open-source-release\"&gt;https://www.krea.ai/blog/flux-krea-open-source-release&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I am not affiliated with Black Forest, Flux, or any of these companies, I&amp;#39;m just sharing the link.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1meiizp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "CtrlAltDelve",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meiizp/releasing_open_weights_for_flux1_krea/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meiizp/releasing_open_weights_for_flux1_krea/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754008914,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4kcht",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Deepseek just won the best paper award at ACL 2025 with a breakthrough innovation in long context, a model using this might come soon",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdn6dp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 506,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 506,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1753921424,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "arxiv.org",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://arxiv.org/abs/2502.11089",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mdn6dp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Charuru",
          "discussion_type": null,
          "num_comments": 35,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdn6dp/deepseek_just_won_the_best_paper_award_at_acl/",
          "stickied": false,
          "url": "https://arxiv.org/abs/2502.11089",
          "subreddit_subscribers": 507935,
          "created_utc": 1753921424,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "The Cogito v2 LLMs are instruction tuned generative models. All models are released under an open license for commercial use.\n\n* Cogito v2 models are hybrid reasoning models. Each model can answer directly (standard LLM), or self-reflect before answering (like reasoning models).\n* The LLMs are trained using **Iterated Distillation and Amplification (IDA)** \\- an scalable and efficient alignment strategy for superintelligence using iterative self-improvement.\n* The models have been optimized for coding, STEM, instruction following and general helpfulness, and have significantly higher multilingual, coding and tool calling capabilities than size equivalent counterparts.\n   * In both standard and reasoning modes, Cogito v2-preview models outperform their size equivalent counterparts on common industry benchmarks.\n* This model is trained in over 30 languages and supports a context length of 128k.\n\n[https://huggingface.co/deepcogito/cogito-v2-preview-llama-70B](https://huggingface.co/deepcogito/cogito-v2-preview-llama-70B)\n\n[https://huggingface.co/deepcogito/cogito-v2-preview-llama-109B-MoE](https://huggingface.co/deepcogito/cogito-v2-preview-llama-109B-MoE)\n\n[https://huggingface.co/deepcogito/cogito-v2-preview-llama-405B](https://huggingface.co/deepcogito/cogito-v2-preview-llama-405B)\n\n[https://huggingface.co/deepcogito/cogito-v2-preview-deepseek-671B-MoE](https://huggingface.co/deepcogito/cogito-v2-preview-deepseek-671B-MoE)",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "cogito v2 preview models released 70B/109B/405B/671B",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdv67j",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": "#bbbdbf",
          "subreddit_type": "public",
          "ups": 132,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 132,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753947057,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Cogito v2 LLMs are instruction tuned generative models. All models are released under an open license for commercial use.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cogito v2 models are hybrid reasoning models. Each model can answer directly (standard LLM), or self-reflect before answering (like reasoning models).&lt;/li&gt;\n&lt;li&gt;The LLMs are trained using &lt;strong&gt;Iterated Distillation and Amplification (IDA)&lt;/strong&gt; - an scalable and efficient alignment strategy for superintelligence using iterative self-improvement.&lt;/li&gt;\n&lt;li&gt;The models have been optimized for coding, STEM, instruction following and general helpfulness, and have significantly higher multilingual, coding and tool calling capabilities than size equivalent counterparts.\n\n&lt;ul&gt;\n&lt;li&gt;In both standard and reasoning modes, Cogito v2-preview models outperform their size equivalent counterparts on common industry benchmarks.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;This model is trained in over 30 languages and supports a context length of 128k.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/deepcogito/cogito-v2-preview-llama-70B\"&gt;https://huggingface.co/deepcogito/cogito-v2-preview-llama-70B&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/deepcogito/cogito-v2-preview-llama-109B-MoE\"&gt;https://huggingface.co/deepcogito/cogito-v2-preview-llama-109B-MoE&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/deepcogito/cogito-v2-preview-llama-405B\"&gt;https://huggingface.co/deepcogito/cogito-v2-preview-llama-405B&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/deepcogito/cogito-v2-preview-deepseek-671B-MoE\"&gt;https://huggingface.co/deepcogito/cogito-v2-preview-deepseek-671B-MoE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?auto=webp&amp;s=7b818f7adc0d98be40731f482264a837c5867cdb",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2055e09c12c8dcc4a48b580d498877c964511989",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f79151ab74562809d440b5508d280e061ae0946b",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6c65488556d2975946913d69a6778dcb8ba23ec",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7eea3eb081fb9d9eceb6ab28bafbeec270cef16c",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=79faf675b22855f2a89c2569eb9627da7c0850ba",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=81069326219d1e0b03f90e120e47778dbb96b482",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "7dnFXllcXlnatOfqO_F3iSqS3FlJPQP-Q1pGksTJzbw"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mdv67j",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 35,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mdv67j/cogito_v2_preview_models_released_70b109b405b671b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdv67j/cogito_v2_preview_models_released_70b109b405b671b/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753947057,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "HF Link: [https://huggingface.co/CohereLabs/command-a-vision-07-2025](https://huggingface.co/CohereLabs/command-a-vision-07-2025)\n\nBlogpost: [https://cohere.com/blog/command-a-vision](https://cohere.com/blog/command-a-vision)",
          "author_fullname": "t2_kwl47",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Introducing Command A Vision: Multimodal AI Built for Business",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 86,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "9s1gnuchv7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 39,
                  "x": 108,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4df02754da49a408b8ea763cee0ce83fb39db984"
                },
                {
                  "y": 78,
                  "x": 216,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f4e4da8582fd10f87405f070c33fa531f5bd8d0"
                },
                {
                  "y": 116,
                  "x": 320,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8450f1d24deb3883d0ce720d7f896ff983a25df9"
                },
                {
                  "y": 232,
                  "x": 640,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1859b9b306d6f074e4dba8fdcf7466b90d122c9"
                },
                {
                  "y": 348,
                  "x": 960,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f959eec922dc2fd6a1d90bcfa29545b48937492c"
                },
                {
                  "y": 391,
                  "x": 1080,
                  "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06b03b8bb2233593615a161d742e954f69ccef45"
                }
              ],
              "s": {
                "y": 653,
                "x": 1800,
                "u": "https://preview.redd.it/9s1gnuchv7gf1.png?width=1800&amp;format=png&amp;auto=webp&amp;s=193101f4d9c57457c987d6103af001d907a84396"
              },
              "id": "9s1gnuchv7gf1"
            },
            "vivin46ev7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 66,
                  "x": 108,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5dbb9ef824c910eb949d70e5e731c0e5fbccb936"
                },
                {
                  "y": 133,
                  "x": 216,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fe59d4da3e192620521ea277508087b805f7a9c"
                },
                {
                  "y": 197,
                  "x": 320,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6919c1f0f419d2dec54af35f1cd5d8829cce07ba"
                },
                {
                  "y": 394,
                  "x": 640,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=77db66cd3a3861dce0d40434ca94c85e0a90e67b"
                },
                {
                  "y": 592,
                  "x": 960,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1f0f0112de8a2fff1bda29a45a3cf38ab80cf21"
                },
                {
                  "y": 666,
                  "x": 1080,
                  "u": "https://preview.redd.it/vivin46ev7gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=21c9b0fee61afd274ac032264801e0a58b7f4eb8"
                }
              ],
              "s": {
                "y": 1110,
                "x": 1800,
                "u": "https://preview.redd.it/vivin46ev7gf1.png?width=1800&amp;format=png&amp;auto=webp&amp;s=0a0f7f2a636d94584243d4d79acd59c901d853b0"
              },
              "id": "vivin46ev7gf1"
            },
            "ti86bswgv7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 66,
                  "x": 108,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=227a9ee0903d8cc22a1ce5ac2f4592b71962e5df"
                },
                {
                  "y": 133,
                  "x": 216,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=403497d4fb8ede2b175ee160279a4b8d1c0a8039"
                },
                {
                  "y": 197,
                  "x": 320,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7232d3e1f37003f7ea204694b184f34dd719577e"
                },
                {
                  "y": 394,
                  "x": 640,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=595060acecfdb3411ff351b2aeb9b32bff9d3bf3"
                },
                {
                  "y": 592,
                  "x": 960,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3c5d02bc993d939beab1f63535719c7cc76ed59b"
                },
                {
                  "y": 666,
                  "x": 1080,
                  "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9404d3ca0485e2f3fb0ce40972e671fab1a0205c"
                }
              ],
              "s": {
                "y": 1110,
                "x": 1800,
                "u": "https://preview.redd.it/ti86bswgv7gf1.png?width=1800&amp;format=png&amp;auto=webp&amp;s=6fd3ab209fbd4301ec1209d474f8f89d47be1620"
              },
              "id": "ti86bswgv7gf1"
            },
            "dz5e43rhv7gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 39,
                  "x": 108,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5e59ca247d81abd98362f4a17934307e1e8d654"
                },
                {
                  "y": 78,
                  "x": 216,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e093a0166b22a01432d6fbdd2941b8962948d26"
                },
                {
                  "y": 116,
                  "x": 320,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b6e44b75e33f10cd0f4401a1435010501173291"
                },
                {
                  "y": 232,
                  "x": 640,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=635e15f84c0334d92e43d7922461faec493ae467"
                },
                {
                  "y": 348,
                  "x": 960,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=718576aed8562ce3c79a39a63325cf8906447be1"
                },
                {
                  "y": 391,
                  "x": 1080,
                  "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d2cf4ad54543656037e2788cec4a5c138d8507db"
                }
              ],
              "s": {
                "y": 653,
                "x": 1800,
                "u": "https://preview.redd.it/dz5e43rhv7gf1.png?width=1800&amp;format=png&amp;auto=webp&amp;s=df8f433ae8fa26fc5d096ba3ef17503c42c777be"
              },
              "id": "dz5e43rhv7gf1"
            }
          },
          "name": "t3_1me2iza",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 46,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "vivin46ev7gf1",
                "id": 718102496
              },
              {
                "media_id": "ti86bswgv7gf1",
                "id": 718102497
              },
              {
                "media_id": "9s1gnuchv7gf1",
                "id": 718102498
              },
              {
                "media_id": "dz5e43rhv7gf1",
                "id": 718102499
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 46,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/z29adrNyFDeJCrY8II_yzeT4FsbIc7XlOch59IpboKE.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753970773,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HF Link: &lt;a href=\"https://huggingface.co/CohereLabs/command-a-vision-07-2025\"&gt;https://huggingface.co/CohereLabs/command-a-vision-07-2025&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Blogpost: &lt;a href=\"https://cohere.com/blog/command-a-vision\"&gt;https://cohere.com/blog/command-a-vision&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1me2iza",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me2iza",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Dark_Fire_12",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me2iza/introducing_command_a_vision_multimodal_ai_built/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1me2iza",
          "subreddit_subscribers": 507935,
          "created_utc": 1753970773,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Apparent improvements:\n\n* Improved Performance: +30% increase in accepted completions, +10% more retained code, and 50% fewer runaway generations\n* Enhanced Chat Mode: +5% improvement in instruction following and code abilities\n* Flexible Deployment: Supports cloud, VPC, or on-prem environments\n\nOnly usable via API (more infoÂ [here](https://docs.mistral.ai/capabilities/code_generation/#fim))\n\nI personally think it's a bit meh, and hate they did it mostly for enterprise, maybe they're pivoting away from open-source",
          "author_fullname": "t2_1h9qrwy0w6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "MistralAI releases Codestral 25.08 (via API only tho)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me3e7w",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.76,
          "author_flair_background_color": "transparent",
          "subreddit_type": "public",
          "ups": 26,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 26,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753972855,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apparent improvements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Improved Performance: +30% increase in accepted completions, +10% more retained code, and 50% fewer runaway generations&lt;/li&gt;\n&lt;li&gt;Enhanced Chat Mode: +5% improvement in instruction following and code abilities&lt;/li&gt;\n&lt;li&gt;Flexible Deployment: Supports cloud, VPC, or on-prem environments&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Only usable via API (more infoÂ &lt;a href=\"https://docs.mistral.ai/capabilities/code_generation/#fim\"&gt;here&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;I personally think it&amp;#39;s a bit meh, and hate they did it mostly for enterprise, maybe they&amp;#39;re pivoting away from open-source&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?auto=webp&amp;s=930843d0f0eadef991ae46e93b1110c35ae1f7a1",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=762f3b17a77a1a724579ae4672a2a2916540a708",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fadcc07c06525218bbddb7a2acfa2f4f680f58f",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=136dc86e2ef6b0d59ec71f6f0af87f4ac96f6f81",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9736b7e62c55fc0458aaccfe777f609d60a12018",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aab2e0a32bb18114efea8094657a59a79a670c4b",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7bc3be3aa0dcb24f282175df199f597c96ea25e5",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "fZa1k6EgCLeOgsay3muaKQJpugercNmOrJnutzU_xCM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1me3e7w",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "juanviera23",
          "discussion_type": null,
          "num_comments": 15,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1me3e7w/mistralai_releases_codestral_2508_via_api_only_tho/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me3e7w/mistralai_releases_codestral_2508_via_api_only_tho/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753972855,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Kimi-K2 goes for 1T params with 32b active and Deepseek models go for 671B with 37b active at once.\n\nThey've hosted the 400b dense variant of Llama at one point and still host Maverick and scout which are significantly worse than other models in similar or smaller weight class. \n\nThey don't even host the qwen3-235b-a22b models but only the dense qwen 3-32b variant.\n\nThey don't host gemma 3 but still host old gemma 2.\n\nThey're still hosting r1-distill-llama-70b???\nIf they are so resource constrained, why waste capacity on these models? \n\nSambanova is hosting deepseek models and cerebras has now started hosting the Qwen3-235B-A22B-Instruct-2507 with think variant coming soon and hybrid variant is active. \n\n\nThere was a tweet as well where they said they will soon be hosting deepseek models but they never did and directly moved to kimi. \n\nThis question has been bugging me why not host deepseek models when they have demonstrated the ability to host larger models? Is there some kind of other technical limitation they might be facing with deepseek?\n\n",
          "author_fullname": "t2_yfi9sqrzf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "How can Groq host Kimi-K2 but refuses to host DeepSeek-R1-0528 or V3-0324???",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "ye88n7z0n8gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 128,
                  "x": 108,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eea98dd9ecc88ed79c358b97ca67f772b34d1ebe"
                },
                {
                  "y": 256,
                  "x": 216,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=812987268dfd34628571781c41e3f572a65ccd2a"
                },
                {
                  "y": 380,
                  "x": 320,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=501c0d5729b182629c1d2424ec2368789144cba5"
                },
                {
                  "y": 760,
                  "x": 640,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ebc8b91faa92274e7b559b4f88f852544e7c38a"
                },
                {
                  "y": 1140,
                  "x": 960,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2196c0c3972d63126d21c172c359ca1b4485a3d0"
                },
                {
                  "y": 1282,
                  "x": 1080,
                  "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9f8c3c72cd28df1419129deda8d31af281ed055d"
                }
              ],
              "s": {
                "y": 1449,
                "x": 1220,
                "u": "https://preview.redd.it/ye88n7z0n8gf1.jpg?width=1220&amp;format=pjpg&amp;auto=webp&amp;s=254fa941816d427aad532853a590861fc86a319c"
              },
              "id": "ye88n7z0n8gf1"
            },
            "w3zptah1n8gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 129,
                  "x": 108,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f218804040df2c98994ebf40685d353af7be711f"
                },
                {
                  "y": 258,
                  "x": 216,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4e2a98fabef31c995a04c18d98fa9c706fe9b33"
                },
                {
                  "y": 383,
                  "x": 320,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5086f2fa09d5fab7075cd21c4bae576fd357e2a"
                },
                {
                  "y": 766,
                  "x": 640,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=686e7fd08a8fac6e4d17b0825b6614120a89fcd8"
                },
                {
                  "y": 1150,
                  "x": 960,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1524143e4294fc2524607c15d280a0e3ace6184c"
                },
                {
                  "y": 1294,
                  "x": 1080,
                  "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dbafd06fd64d7cb86c987ab1dc233da81480cac5"
                }
              ],
              "s": {
                "y": 1462,
                "x": 1220,
                "u": "https://preview.redd.it/w3zptah1n8gf1.jpg?width=1220&amp;format=pjpg&amp;auto=webp&amp;s=44dd21f8fce625c7e21cdbda83933c275ff686e2"
              },
              "id": "w3zptah1n8gf1"
            }
          },
          "name": "t3_1me6j2v",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 15,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "caption": "",
                "media_id": "ye88n7z0n8gf1",
                "id": 718198361
              },
              {
                "caption": "",
                "media_id": "w3zptah1n8gf1",
                "id": 718198362
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 15,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/jM5tMTVqDxoZGCWBgL_vcf6gdTzNdqmy8eWM42yT8ME.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753979995,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kimi-K2 goes for 1T params with 32b active and Deepseek models go for 671B with 37b active at once.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ve hosted the 400b dense variant of Llama at one point and still host Maverick and scout which are significantly worse than other models in similar or smaller weight class. &lt;/p&gt;\n\n&lt;p&gt;They don&amp;#39;t even host the qwen3-235b-a22b models but only the dense qwen 3-32b variant.&lt;/p&gt;\n\n&lt;p&gt;They don&amp;#39;t host gemma 3 but still host old gemma 2.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re still hosting r1-distill-llama-70b???\nIf they are so resource constrained, why waste capacity on these models? &lt;/p&gt;\n\n&lt;p&gt;Sambanova is hosting deepseek models and cerebras has now started hosting the Qwen3-235B-A22B-Instruct-2507 with think variant coming soon and hybrid variant is active. &lt;/p&gt;\n\n&lt;p&gt;There was a tweet as well where they said they will soon be hosting deepseek models but they never did and directly moved to kimi. &lt;/p&gt;\n\n&lt;p&gt;This question has been bugging me why not host deepseek models when they have demonstrated the ability to host larger models? Is there some kind of other technical limitation they might be facing with deepseek?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1me6j2v",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me6j2v",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "True_Requirement_891",
          "discussion_type": null,
          "num_comments": 20,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me6j2v/how_can_groq_host_kimik2_but_refuses_to_host/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1me6j2v",
          "subreddit_subscribers": 507935,
          "created_utc": 1753979995,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Pretty much the title. unsloth is really good about listing how large their quants are in gb, but anytime I look at a safetensors directory I'm left wondering how large the directory is. Do I have enough space to download it? Who knows! It seems like such a trivial thing to list total directory size on the web ui. Why don't they do that?",
          "author_fullname": "t2_ozxxf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Why does HF not show total size for directories?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me8dgy",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 12,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 12,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753984161,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title. unsloth is really good about listing how large their quants are in gb, but anytime I look at a safetensors directory I&amp;#39;m left wondering how large the directory is. Do I have enough space to download it? Who knows! It seems like such a trivial thing to list total directory size on the web ui. Why don&amp;#39;t they do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me8dgy",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "createthiscom",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me8dgy/why_does_hf_not_show_total_size_for_directories/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me8dgy/why_does_hf_not_show_total_size_for_directories/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753984161,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://huggingface.co/papers/2507.22448](https://huggingface.co/papers/2507.22448)\n\nThe hybrid transformer-mamba models series, covering 0.5B, 1.5B, 1.5B-Deep, 3B, 7B and 34B.   \n  \nThis 80+ page report dives deep into the key design decisions behind Falcon-H1 - from architectural innovations and data strategies to training recipes that challenge conventional practices in LLM development ðŸ”¥\n\nCurrent framework support includes Hugging Face, vLLM, llama.cpp, Llama-Factory, Axolotl, OUMI, SkyPilot, etc. â€” with more on the way!\n\nhttps://preview.redd.it/vog1eu4gd6gf1.png?width=1708&amp;format=png&amp;auto=webp&amp;s=80753458ee6e8869540d1c75a0599c9a2aae9dad",
          "author_fullname": "t2_1ktl4wkk",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Falcon-H1 technical report release",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "vog1eu4gd6gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 50,
                  "x": 108,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ca34bf918efa2cb49b50aca605506703b8d1a55"
                },
                {
                  "y": 100,
                  "x": 216,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=062ccd2d13db98ada785b134c6a18c7fafb58443"
                },
                {
                  "y": 148,
                  "x": 320,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e46cecf04020e46e0270ddeaa3a45a71afd3be3c"
                },
                {
                  "y": 297,
                  "x": 640,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1cf10e09eaad4cd440e363978ae4634060980e9"
                },
                {
                  "y": 446,
                  "x": 960,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=680cd6c57e67c59f710dfee66af0cf3dec0aba6d"
                },
                {
                  "y": 502,
                  "x": 1080,
                  "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5e8ba30135fbfa9faf87d12df9b08bec0a5cf69b"
                }
              ],
              "s": {
                "y": 794,
                "x": 1708,
                "u": "https://preview.redd.it/vog1eu4gd6gf1.png?width=1708&amp;format=png&amp;auto=webp&amp;s=80753458ee6e8869540d1c75a0599c9a2aae9dad"
              },
              "id": "vog1eu4gd6gf1"
            }
          },
          "name": "t3_1mdwmju",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.91,
          "author_flair_background_color": null,
          "ups": 51,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 51,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=382056242aa6a412c0f4a006eaf01c514d1388ad",
          "edited": 1753953342,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1753952728,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/papers/2507.22448\"&gt;https://huggingface.co/papers/2507.22448&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The hybrid transformer-mamba models series, covering 0.5B, 1.5B, 1.5B-Deep, 3B, 7B and 34B.   &lt;/p&gt;\n\n&lt;p&gt;This 80+ page report dives deep into the key design decisions behind Falcon-H1 - from architectural innovations and data strategies to training recipes that challenge conventional practices in LLM development ðŸ”¥&lt;/p&gt;\n\n&lt;p&gt;Current framework support includes Hugging Face, vLLM, llama.cpp, Llama-Factory, Axolotl, OUMI, SkyPilot, etc. â€” with more on the way!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vog1eu4gd6gf1.png?width=1708&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80753458ee6e8869540d1c75a0599c9a2aae9dad\"&gt;https://preview.redd.it/vog1eu4gd6gf1.png?width=1708&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80753458ee6e8869540d1c75a0599c9a2aae9dad&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?auto=webp&amp;s=0d235e866fdfaab01a2374baae1d2fca9c0f399d",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5160807d254f5c616e61b4d003b92b90330ec05c",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=245e25182634e949ed6cfaea317f039922233b67",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1197f5f207e31c91d4eabe638aa229c8b8124a5",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb38d3cc3bcfa71dbf16f5c930e570f21c13b829",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9104b158f02ec1c9573384b43d10b269be9b85ea",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1cc2dedbd7ee134181fe2b5c0ebdcec1c22ab6ec",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "ifoGNEtsOnQI7mOVCHlAOV6hOXRc2zUDtsZ8X9LgS5A"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mdwmju",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "JingweiZUO",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdwmju/falconh1_technical_report_release/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdwmju/falconh1_technical_report_release/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753952728,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_aq4j0",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "rednote-hilab/dots.ocr - Multilingual document layout parsing in a single vision-language model achieving SOTA performance despite compact 1.7B LLM foundation",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdwngf",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.96,
          "author_flair_background_color": null,
          "ups": 49,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 49,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=ac93265c9379bfbf707f3dc3c8663ec4b92f5a3c",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753952828,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/rednote-hilab/dots.ocr",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?auto=webp&amp;s=83e0fd1aa924b9918306c02a99cedb9bbb2eb1cb",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=014ce09ab614e86be0bda115d3ee826dd4c7e72b",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9fb10f0400ab7291afbb905ab3dfdfb49e477ed8",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=88b160d056e65a5fdd1da13d608db9a9c123e2d7",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=54fe70e1d1e50ac63262c7c7180e0173f9cc1673",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa0d50402090bd3ad6e9c270f0f950421a2c1523",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dff2cd4e982c9356a88ce61af693c4ca57815b99",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "8NDRsizKorORFhKFDygayRrW6cfTqRcK_E46LDgaFmo"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mdwngf",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "nullmove",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdwngf/rednotehilabdotsocr_multilingual_document_layout/",
          "stickied": false,
          "url": "https://huggingface.co/rednote-hilab/dots.ocr",
          "subreddit_subscribers": 507935,
          "created_utc": 1753952828,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "\\[Src: https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop\\](https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop)\n\n| Specification | Details |\n\n|---------------|---------|\n\n| Processor | 16-core Ryzen MAX+ 395, 12-core MAX 390, or 8-core MAX 385 |\n\n| Display | 16-inch, 2560x1600 resolution, 165Hz or 180Hz refresh rate |\n\n| RAM | Up to 128GB of soldered LPDDR5X-8000 |\n\n| Storage | Two M.2 2280 slots (PCIe 4.0x4) |\n\n| Weight | 2.45 kg |\n\n| Price | Not mentioned in the article |\n\nThe more Ryzen MAX+ 395 announcements are made, the sooner they'll be marked down. Being seeing a lot more of the 12-core 375 variants that I'm not too fond of.",
          "author_fullname": "t2_wn888",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "New Portable AI Rig Announced (Marketed As A Gaming Laptop)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 72,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1meazh1",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.84,
          "author_flair_background_color": null,
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=140&amp;height=72&amp;crop=140:72,smart&amp;auto=webp&amp;s=f7ae765cf818e4fb3dafbb7ea2f28b0c66db1375",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753990147,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "videocardz.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Src: &lt;a href=\"https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop%5C%5D(https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop)\"&gt;https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop\\](https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;| Specification | Details |&lt;/p&gt;\n\n&lt;p&gt;|---------------|---------|&lt;/p&gt;\n\n&lt;p&gt;| Processor | 16-core Ryzen MAX+ 395, 12-core MAX 390, or 8-core MAX 385 |&lt;/p&gt;\n\n&lt;p&gt;| Display | 16-inch, 2560x1600 resolution, 165Hz or 180Hz refresh rate |&lt;/p&gt;\n\n&lt;p&gt;| RAM | Up to 128GB of soldered LPDDR5X-8000 |&lt;/p&gt;\n\n&lt;p&gt;| Storage | Two M.2 2280 slots (PCIe 4.0x4) |&lt;/p&gt;\n\n&lt;p&gt;| Weight | 2.45 kg |&lt;/p&gt;\n\n&lt;p&gt;| Price | Not mentioned in the article |&lt;/p&gt;\n\n&lt;p&gt;The more Ryzen MAX+ 395 announcements are made, the sooner they&amp;#39;ll be marked down. Being seeing a lot more of the 12-core 375 variants that I&amp;#39;m not too fond of.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?auto=webp&amp;s=e30b54094d49ecd8d5ad98e73b320b4b78451e28",
                  "width": 2500,
                  "height": 1300
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d2ff4ab3b731e40926b69413bc0185aa9859792",
                    "width": 108,
                    "height": 56
                  },
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ff0ab9b312769d72d83f9aabb322fb38dd1dc76",
                    "width": 216,
                    "height": 112
                  },
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45ad32c61674e9af68e52cc7dcaa34277a26498a",
                    "width": 320,
                    "height": 166
                  },
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a0e6d52816d997e81ccf4a76368e7929fe02209",
                    "width": 640,
                    "height": 332
                  },
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e854d44ab560381b62fe11e039e0cc2a3eb9643f",
                    "width": 960,
                    "height": 499
                  },
                  {
                    "url": "https://external-preview.redd.it/hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=633e2c28635bae26d1ba2d7a3cf4236a54cf2a82",
                    "width": 1080,
                    "height": 561
                  }
                ],
                "variants": {},
                "id": "hJGIF8KiepOKz80XX69XMy0ts3UGcwumYePG0rWwhGM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1meazh1",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "false79",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meazh1/new_portable_ai_rig_announced_marketed_as_a/",
          "stickied": false,
          "url": "https://videocardz.com/newz/emdoor-unveils-ryzen-ai-max-300-gaming-laptop",
          "subreddit_subscribers": 507935,
          "created_utc": 1753990147,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://seed.bytedance.com/en/seed_diffusion\n\n\"A large scale language model based on discrete-state diffusion, specializing in code generation, achieves an inference speed of 2,146 token/s, a 5.4x improvement over autoregressive models of comparable size.\"",
          "author_fullname": "t2_a21kdso4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Bytedance Seed Diffusion Preview",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1megdy9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754003105,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://seed.bytedance.com/en/seed_diffusion\"&gt;https://seed.bytedance.com/en/seed_diffusion&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;A large scale language model based on discrete-state diffusion, specializing in code generation, achieves an inference speed of 2,146 token/s, a 5.4x improvement over autoregressive models of comparable size.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1megdy9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Beautiful_Box_7153",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1megdy9/bytedance_seed_diffusion_preview/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1megdy9/bytedance_seed_diffusion_preview/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754003105,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Zuck has posted a video and a longer letter about the superintelligence plans at Meta. In the letter he says:\n\n\"That said, superintelligence will raise novel safety concerns. We'll need to be rigorous about mitigating these risks and careful about what we choose to open source.\"\n\n[https://www.meta.com/superintelligence/](https://www.meta.com/superintelligence/)\n\nThat means that Meta will not open source the best they have. But it is inevitable that others will release their best models and agents, meaning that Meta has committed itself to oblivion, not only in open source but in proprietary too, as they are not a major player in that space. The ASI they will get to will be for use in their products only.",
          "author_fullname": "t2_1pr7hwh6t5",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Bye bye, Meta AI, it was good while it lasted.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md6t2h",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1364,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1364,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753882611,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Zuck has posted a video and a longer letter about the superintelligence plans at Meta. In the letter he says:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;That said, superintelligence will raise novel safety concerns. We&amp;#39;ll need to be rigorous about mitigating these risks and careful about what we choose to open source.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.meta.com/superintelligence/\"&gt;https://www.meta.com/superintelligence/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;That means that Meta will not open source the best they have. But it is inevitable that others will release their best models and agents, meaning that Meta has committed itself to oblivion, not only in open source but in proprietary too, as they are not a major player in that space. The ASI they will get to will be for use in their products only.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1md6t2h",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "absolooot1",
          "discussion_type": null,
          "num_comments": 421,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md6t2h/bye_bye_meta_ai_it_was_good_while_it_lasted/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1md6t2h/bye_bye_meta_ai_it_was_good_while_it_lasted/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753882611,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey, I'm looking for some recommendations on models similar to Claude code, and maybe some clicks too.\n\nI've been checking out OpenCode.ai and playing with stuff like GLM4-5, but haven't seen anyone try it with what we're doing. Wondering if it's worth switching everything over from Claude Code to test it out.\n\n Anyone got any experience with this, good or bad? Thanks!",
          "author_fullname": "t2_1tteu822",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Claude Code alternative for local",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1med9hx",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.72,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1753998024,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753995412,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m looking for some recommendations on models similar to Claude code, and maybe some clicks too.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been checking out OpenCode.ai and playing with stuff like GLM4-5, but haven&amp;#39;t seen anyone try it with what we&amp;#39;re doing. Wondering if it&amp;#39;s worth switching everything over from Claude Code to test it out.&lt;/p&gt;\n\n&lt;p&gt;Anyone got any experience with this, good or bad? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1med9hx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "filipemendespi",
          "discussion_type": null,
          "num_comments": 21,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1med9hx/claude_code_alternative_for_local/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1med9hx/claude_code_alternative_for_local/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753995412,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "If you want to share your `ollama` instance with your friends on Discord, or IRC like me, there aren't many options. I got this working today, so now I can have a trusted local AI on a machine that I can ask questions and it responds in the channel or in private messages. (It's also markdown in Discord/Slack, so it's pretty too!)",
          "author_fullname": "t2_5n8i2",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "An Ollama wrapper for IRC/Slack/Discord, you want to run your own AI for chat? Here ya go.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mefgt2",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.63,
          "author_flair_background_color": null,
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=221d2aeef86742f54f255186510d9d2a50cedfe3",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754000725,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you want to share your &lt;code&gt;ollama&lt;/code&gt; instance with your friends on Discord, or IRC like me, there aren&amp;#39;t many options. I got this working today, so now I can have a trusted local AI on a machine that I can ask questions and it responds in the channel or in private messages. (It&amp;#39;s also markdown in Discord/Slack, so it&amp;#39;s pretty too!)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/jjasghar/ai-irc-slack-discord-ollama-bot",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?auto=webp&amp;s=fef6203cd5bb048c0f2fd8d4871a001b2bf54118",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ddb4af410578d36d2885aabe3c69324a178412f",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=053e1b3b3b85b2488bd801cf89802f3a84368507",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e334067bc66b13901afb79015414cf7f744ee078",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76d1057ca7bd51891610bbd01e1b4e895cebeb60",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dbad87899d772038d25578e1e0d13e77485a9447",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=43e0776b540acff2ee887ad05f464ed426efdbca",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "g6vxT0esOljml79fXZH6UeNZ4VDz-9uDcCn3t81Ue44"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mefgt2",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jjasghar",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mefgt2/an_ollama_wrapper_for_ircslackdiscord_you_want_to/",
          "stickied": false,
          "url": "https://github.com/jjasghar/ai-irc-slack-discord-ollama-bot",
          "subreddit_subscribers": 507935,
          "created_utc": 1754000725,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey folks ðŸ‘‹\n\nI've been working on a Python script that automates the full creation of structured character image sets using the **Stable Diffusion WebUI API (AUTOMATIC1111)**.\n\n# ðŸ”§ What the tool does:\n\n* Handles **LoRA switching and weights**\n* Sends full prompt batches via API (**SFW/NSFW separated**)\n* Auto-generates folder structures like:/Sophia\\_Winters/ â”œâ”€â”€ SFW/ â”œâ”€â”€ NSFW/ â””â”€â”€ Sophia\\_Winters\\_info.json\n* Adds **prompt data**, character metadata &amp; consistent file naming\n* Supports **face restoration** and **HiRes toggling**\n* Works fully offline with your local A1111 WebUI instance\n\nItâ€™s helped me create **organized sets for influencer-style or thematic AI models** much faster â€“ ideal for LoRA testing, content generation, or selling structured image sets.\n\n# ðŸ§  Iâ€™ve turned it into a downloadable pack via Ko-fi:\n\n* ðŸ **Script Only** â†’ [https://ko-fi.com/s/a498c68ab6](https://ko-fi.com/s/a498c68ab6)\n* ðŸ’¼ **Portable Version** (includes WebUI, Python, ready to run) â†’ [https://ko-fi.com/s/49cd49180e](https://ko-fi.com/s/49cd49180e)\n\n# ðŸ“‚ Sample Output Preview:\n\nThis is what the script actually generates (folder structure, metadata, etc.):  \nðŸ‘‰ [https://drive.google.com/drive/folders/1FRW-z5NqdpquSOdENFYZ8ijIHMgqvDVM](https://drive.google.com/drive/folders/1FRW-z5NqdpquSOdENFYZ8ijIHMgqvDVM)\n\n# ðŸ’¬ Would love to hear what you think:\n\n* Would something like this be useful for your workflow?\n\nLet me know â€“ happy to share more details or answer questions!",
          "author_fullname": "t2_t0t9u2mr",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I built a python script to auto-generate full AI character sets (SFW/NSFW) with LoRA, WebUI API, metadata + folder structure",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1med15k",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "nsfw",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753994864,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks ðŸ‘‹&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a Python script that automates the full creation of structured character image sets using the &lt;strong&gt;Stable Diffusion WebUI API (AUTOMATIC1111)&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;ðŸ”§ What the tool does:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Handles &lt;strong&gt;LoRA switching and weights&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Sends full prompt batches via API (&lt;strong&gt;SFW/NSFW separated&lt;/strong&gt;)&lt;/li&gt;\n&lt;li&gt;Auto-generates folder structures like:/Sophia_Winters/ â”œâ”€â”€ SFW/ â”œâ”€â”€ NSFW/ â””â”€â”€ Sophia_Winters_info.json&lt;/li&gt;\n&lt;li&gt;Adds &lt;strong&gt;prompt data&lt;/strong&gt;, character metadata &amp;amp; consistent file naming&lt;/li&gt;\n&lt;li&gt;Supports &lt;strong&gt;face restoration&lt;/strong&gt; and &lt;strong&gt;HiRes toggling&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Works fully offline with your local A1111 WebUI instance&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Itâ€™s helped me create &lt;strong&gt;organized sets for influencer-style or thematic AI models&lt;/strong&gt; much faster â€“ ideal for LoRA testing, content generation, or selling structured image sets.&lt;/p&gt;\n\n&lt;h1&gt;ðŸ§  Iâ€™ve turned it into a downloadable pack via Ko-fi:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ðŸ &lt;strong&gt;Script Only&lt;/strong&gt; â†’ &lt;a href=\"https://ko-fi.com/s/a498c68ab6\"&gt;https://ko-fi.com/s/a498c68ab6&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;ðŸ’¼ &lt;strong&gt;Portable Version&lt;/strong&gt; (includes WebUI, Python, ready to run) â†’ &lt;a href=\"https://ko-fi.com/s/49cd49180e\"&gt;https://ko-fi.com/s/49cd49180e&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;ðŸ“‚ Sample Output Preview:&lt;/h1&gt;\n\n&lt;p&gt;This is what the script actually generates (folder structure, metadata, etc.):&lt;br/&gt;\nðŸ‘‰ &lt;a href=\"https://drive.google.com/drive/folders/1FRW-z5NqdpquSOdENFYZ8ijIHMgqvDVM\"&gt;https://drive.google.com/drive/folders/1FRW-z5NqdpquSOdENFYZ8ijIHMgqvDVM&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;ðŸ’¬ Would love to hear what you think:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Would something like this be useful for your workflow?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Let me know â€“ happy to share more details or answer questions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": true,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1med15k",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Appropriate-Sand-934",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1med15k/i_built_a_python_script_to_autogenerate_full_ai/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1med15k/i_built_a_python_script_to_autogenerate_full_ai/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753994864,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "    ./build/bin/llama-server --model Â ~/Documents/Programm\n    ing/LLM_models/qwen3-coder-30b-a3b-instruct-q4_k_m.gguf --n-gpu-layers 100 --host 0.0.0.0 --port 8080 --jinja -\n    -chat-template-file ~/Documents/Programming/LLM_models/tokenizer_config.json\n\n    ./build/bin/llama-server --model Â ~/Documents/Programm\n    ing/LLM_models/qwen3-coder-30b-a3b-instruct-q4_k_m.gguf --n-gpu-layers 100 --host 0.0.0.0 --port 8080 --jinja\n\nI've tried these commands with this model and one from unsloth. The model fails miserably, hallucinates and wont recognize tools. just pulled latest llama cpp and rebuilt\n\n[unsloth](https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally#using-tool-calling) allegedly fixed the tool calling prompt but I redownloaded the model and it still fails\n\ni also tried with this [prompt template](https://github.com/ggml-org/llama.cpp/issues/13178)\n\nty for tech support",
          "author_fullname": "t2_17psnpt",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Cline + Qwen 3 Coder A3B wont call tools",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mei9pu",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754008175,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;./build/bin/llama-server --model Â ~/Documents/Programm\ning/LLM_models/qwen3-coder-30b-a3b-instruct-q4_k_m.gguf --n-gpu-layers 100 --host 0.0.0.0 --port 8080 --jinja -\n-chat-template-file ~/Documents/Programming/LLM_models/tokenizer_config.json\n\n./build/bin/llama-server --model Â ~/Documents/Programm\ning/LLM_models/qwen3-coder-30b-a3b-instruct-q4_k_m.gguf --n-gpu-layers 100 --host 0.0.0.0 --port 8080 --jinja\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve tried these commands with this model and one from unsloth. The model fails miserably, hallucinates and wont recognize tools. just pulled latest llama cpp and rebuilt&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally#using-tool-calling\"&gt;unsloth&lt;/a&gt; allegedly fixed the tool calling prompt but I redownloaded the model and it still fails&lt;/p&gt;\n\n&lt;p&gt;i also tried with this &lt;a href=\"https://github.com/ggml-org/llama.cpp/issues/13178\"&gt;prompt template&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ty for tech support&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?auto=webp&amp;s=df3ed66f8b8e54b17c699d9c4e81b03ddeb78c58",
                  "width": 1200,
                  "height": 590
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6fa9ec0bda4ae81d05efe9ff0a296be82987e912",
                    "width": 108,
                    "height": 53
                  },
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18872cd0af37e87d93cf5b6c098630c44f40a162",
                    "width": 216,
                    "height": 106
                  },
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e8392e0cb89db800c200421873b07e92f34150fe",
                    "width": 320,
                    "height": 157
                  },
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f6fc5d8f727ab6f86a8ca5f94a5091bbe81d025",
                    "width": 640,
                    "height": 314
                  },
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26fa346a0f27ac195ecf2f29e1d997a534a3b283",
                    "width": 960,
                    "height": 472
                  },
                  {
                    "url": "https://external-preview.redd.it/ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e4e7bc3c126d7465ae2f4d8fab93d8c6edd76c4",
                    "width": 1080,
                    "height": 531
                  }
                ],
                "variants": {},
                "id": "ksRJC2bKGwjrMfOqsioi-B4oIm5QWQUM7Vf03KwieGM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mei9pu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "fractalcrust",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mei9pu/cline_qwen_3_coder_a3b_wont_call_tools/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mei9pu/cline_qwen_3_coder_a3b_wont_call_tools/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754008175,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey folks â€” Iâ€™m working on a side project around LLM agents and realized I didnâ€™t have a good place to share experiments or talk to other builders doing similar stuff.\n\nSo I started a Slack community for people working on agent-based tools, backend automations, and AI-native side projects. Think LangChain, AutoGen, prompt workflows, etc.\n\nItâ€™s already picked up momentum with indie builders, OSS contributors, and engineers sharing tools, code, and early prototypes.\n\nIf youâ€™re building in this space or just exploring ideas, feel free to join in:  \nðŸ‘‰ [https://forms.gle/vCf4KXMsCaavvYaPA](https://forms.gle/vCf4KXMsCaavvYaPA)\n\nNot monetized, not spammy â€” just trying to make something useful for people shipping cool stuff. Happy to answer questions or hear what you're building too.",
          "author_fullname": "t2_f8o54u21",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Started a Slack group for AI agent/automation side project builders â€” free to join",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me7wuj",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753983128,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks â€” Iâ€™m working on a side project around LLM agents and realized I didnâ€™t have a good place to share experiments or talk to other builders doing similar stuff.&lt;/p&gt;\n\n&lt;p&gt;So I started a Slack community for people working on agent-based tools, backend automations, and AI-native side projects. Think LangChain, AutoGen, prompt workflows, etc.&lt;/p&gt;\n\n&lt;p&gt;Itâ€™s already picked up momentum with indie builders, OSS contributors, and engineers sharing tools, code, and early prototypes.&lt;/p&gt;\n\n&lt;p&gt;If youâ€™re building in this space or just exploring ideas, feel free to join in:&lt;br/&gt;\nðŸ‘‰ &lt;a href=\"https://forms.gle/vCf4KXMsCaavvYaPA\"&gt;https://forms.gle/vCf4KXMsCaavvYaPA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Not monetized, not spammy â€” just trying to make something useful for people shipping cool stuff. Happy to answer questions or hear what you&amp;#39;re building too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?auto=webp&amp;s=f21a691d46d145a42907881bc60ffe6f87f7bfa0",
                  "width": 1200,
                  "height": 630
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a899259f1a624211bfb51c3c4a875767313d7934",
                    "width": 108,
                    "height": 56
                  },
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fc5491fa87b8740161d52f961188a9d827db19f0",
                    "width": 216,
                    "height": 113
                  },
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=353065210c98f45c3180ab814df7f645b67b10f3",
                    "width": 320,
                    "height": 168
                  },
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a86b46bcc4f9b9248c97339444a35dfa510a064b",
                    "width": 640,
                    "height": 336
                  },
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea901a7936852ec0306e795bf6e30510bff42e28",
                    "width": 960,
                    "height": 504
                  },
                  {
                    "url": "https://external-preview.redd.it/I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=318939830d184856926afa568581d596ad7df1a5",
                    "width": 1080,
                    "height": 567
                  }
                ],
                "variants": {},
                "id": "I-xX7rjCusgUcmQ53FmR-IUZEMbenSZYrO30pYAyMIA"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me7wuj",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Embarrassed-Radio319",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me7wuj/started_a_slack_group_for_ai_agentautomation_side/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me7wuj/started_a_slack_group_for_ai_agentautomation_side/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753983128,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I tried to create a little intuitive explanation of what's happening \"under the hood\" of the transformer architecture without any math... it glosses over a lot but I think starting to talk about it in this way at least dispels some of the myths of how they work.",
          "author_fullname": "t2_yhuwl",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "An attempt to explain LLM Transformers without math",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 105,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mearht",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.7,
          "author_flair_background_color": null,
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VlbBgj2lBls?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Explaining the internals of LLM Transformers -- without math\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "height": 200
          },
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Explaining the internals of LLM Transformers -- without math",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VlbBgj2lBls?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Explaining the internals of LLM Transformers -- without math\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Nimish GÃ¥tam",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/VlbBgj2lBls/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@nimishgatam8901"
            },
            "type": "youtube.com"
          },
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VlbBgj2lBls?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Explaining the internals of LLM Transformers -- without math\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "media_domain_url": "https://www.redditmedia.com/mediaembed/1mearht",
            "height": 200
          },
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=6105862a8ec459d05fde21560b0c01f00edbc02b",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "rich:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753989634,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "youtu.be",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried to create a little intuitive explanation of what&amp;#39;s happening &amp;quot;under the hood&amp;quot; of the transformer architecture without any math... it glosses over a lot but I think starting to talk about it in this way at least dispels some of the myths of how they work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://youtu.be/VlbBgj2lBls",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8.jpeg?auto=webp&amp;s=7888ea3f23c563526b9dae12cf1db525255c95ac",
                  "width": 480,
                  "height": 360
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09ff60921ab0b3dfbcd14be0956687fb43b50ffc",
                    "width": 108,
                    "height": 81
                  },
                  {
                    "url": "https://external-preview.redd.it/mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c920b443c86b06f64b414411eee0ec9160ca809b",
                    "width": 216,
                    "height": 162
                  },
                  {
                    "url": "https://external-preview.redd.it/mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44949ff326b188e136513d04eb4d4b3b961cd8f1",
                    "width": 320,
                    "height": 240
                  }
                ],
                "variants": {},
                "id": "mK7kA7DOTqxkSxj8ISMxYvYyNAvwQ_CTmMB_afvnSp8"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mearht",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "nimishg",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mearht/an_attempt_to_explain_llm_transformers_without/",
          "stickied": false,
          "url": "https://youtu.be/VlbBgj2lBls",
          "subreddit_subscribers": 507935,
          "created_utc": 1753989634,
          "num_crossposts": 0,
          "media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Explaining the internals of LLM Transformers -- without math",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VlbBgj2lBls?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Explaining the internals of LLM Transformers -- without math\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Nimish GÃ¥tam",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/VlbBgj2lBls/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@nimishgatam8901"
            },
            "type": "youtube.com"
          },
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi peeps,\n\nUTCP was very well received here last time for providing a FOSS, no wrapper alternative to MCP for tool calling.\n\nNow you can call any endpoint you want from your existing MCP Clients (LMStudio, Jan Desktop etc.) using only one server\n\nno middlemen, no extra security infra\n\nIf you want to learn more:\n\nUTCP Protocol:Â [https://github.com/universal-tool-calling-protocol/](https://github.com/universal-tool-calling-protocol/)\n\nUTCP-MCP bridge:Â [https://github.com/universal-tool-calling-protocol/utcp-mcp](https://github.com/universal-tool-calling-protocol/utcp-mcp)\n\n",
          "author_fullname": "t2_1h9qrwy0w6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "the last MCP server you'll ever need",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 60,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me4riw",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.66,
          "author_flair_background_color": "transparent",
          "ups": 12,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 12,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/F6OKfWJ3qqlAVXN1qXme29J1Tb-6YrrgZl-MdWUW9J0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753976011,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi peeps,&lt;/p&gt;\n\n&lt;p&gt;UTCP was very well received here last time for providing a FOSS, no wrapper alternative to MCP for tool calling.&lt;/p&gt;\n\n&lt;p&gt;Now you can call any endpoint you want from your existing MCP Clients (LMStudio, Jan Desktop etc.) using only one server&lt;/p&gt;\n\n&lt;p&gt;no middlemen, no extra security infra&lt;/p&gt;\n\n&lt;p&gt;If you want to learn more:&lt;/p&gt;\n\n&lt;p&gt;UTCP Protocol:Â &lt;a href=\"https://github.com/universal-tool-calling-protocol/\"&gt;https://github.com/universal-tool-calling-protocol/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;UTCP-MCP bridge:Â &lt;a href=\"https://github.com/universal-tool-calling-protocol/utcp-mcp\"&gt;https://github.com/universal-tool-calling-protocol/utcp-mcp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/esdfh4o5b8gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/esdfh4o5b8gf1.png?auto=webp&amp;s=36ead39a114c81a9631696436eda8ff39e877411",
                  "width": 2263,
                  "height": 976
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2a6c88f6987a560f196e5be91a469f795b888c5a",
                    "width": 108,
                    "height": 46
                  },
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d134a5237cc6cf7fe8228974226b5a113fafe6c0",
                    "width": 216,
                    "height": 93
                  },
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1dea3a182a0fb9009fc3c55d476be6393fe882d",
                    "width": 320,
                    "height": 138
                  },
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2685c424969de6366c51504081ab8bd7c0b84663",
                    "width": 640,
                    "height": 276
                  },
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=53a18d9ffe5fa8f35930ae940bc4eefd02083ec4",
                    "width": 960,
                    "height": 414
                  },
                  {
                    "url": "https://preview.redd.it/esdfh4o5b8gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=927e8df05494f5c88e4ce48dec5b18330de138c3",
                    "width": 1080,
                    "height": 465
                  }
                ],
                "variants": {},
                "id": "Th3KIvbKb2Eaz_bVabBAIPL8LyEq7N4kqbXLE3Fqb4A"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1me4riw",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "juanviera23",
          "discussion_type": null,
          "num_comments": 17,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1me4riw/the_last_mcp_server_youll_ever_need/",
          "stickied": false,
          "url": "https://i.redd.it/esdfh4o5b8gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753976011,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "All models are from Unsloth UD Q4_K_XL except for Gemma3-27B is IQ3. Running all these with 10-12k context with 4-30 t/s across all models.\n\nMost used ones are Mistral-24B, Gemma3-27B, and Granite3.3-2B. Mistral and Gemma are for general QA and random text tools. Granite is for article summaries and random small RAG related tasks. Qwen3-30B (new one) is for coding related tasks, and Gemma3-12B is for vision strictly.\n\nGemma3n-2B is essentially hooked to Siri via shortcuts and acts as an enhanced Siri.\n\nMedgemma is for anything medical and itâ€™s wonderful for any general advice and reading of x-rays or medical reports.\n\nMy humble mini PC runs all these on Llama.cpp with iGPU 48GB shared memory RAM and Vulkan backend. It runs Mistral at 4t/s with 6k context (set to max of 10k window). Gemme3-27B runs at 5t/s, and Qwen3-30B-A3B at 20-22t/s.\n\nI fall back to ChatGPT once or twice a week when i need a super quick answer or something too in depth.\n\nWhat is your curated list?\n",
          "author_fullname": "t2_vbzgnic",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "After 6 months of fiddling with local AI. Hereâ€™s my curated models list that work for 90% of my needs. Whatâ€™s yours?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdjb67",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 271,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 271,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/4rbeT3cEiSQtXkmeVnVyBuJsOpThkSCY2eLJ1imjBO8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753911487,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All models are from Unsloth UD Q4_K_XL except for Gemma3-27B is IQ3. Running all these with 10-12k context with 4-30 t/s across all models.&lt;/p&gt;\n\n&lt;p&gt;Most used ones are Mistral-24B, Gemma3-27B, and Granite3.3-2B. Mistral and Gemma are for general QA and random text tools. Granite is for article summaries and random small RAG related tasks. Qwen3-30B (new one) is for coding related tasks, and Gemma3-12B is for vision strictly.&lt;/p&gt;\n\n&lt;p&gt;Gemma3n-2B is essentially hooked to Siri via shortcuts and acts as an enhanced Siri.&lt;/p&gt;\n\n&lt;p&gt;Medgemma is for anything medical and itâ€™s wonderful for any general advice and reading of x-rays or medical reports.&lt;/p&gt;\n\n&lt;p&gt;My humble mini PC runs all these on Llama.cpp with iGPU 48GB shared memory RAM and Vulkan backend. It runs Mistral at 4t/s with 6k context (set to max of 10k window). Gemme3-27B runs at 5t/s, and Qwen3-30B-A3B at 20-22t/s.&lt;/p&gt;\n\n&lt;p&gt;I fall back to ChatGPT once or twice a week when i need a super quick answer or something too in depth.&lt;/p&gt;\n\n&lt;p&gt;What is your curated list?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/jzljyi4tw2gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?auto=webp&amp;s=3a79f660063272187cc80e2261fb599320149df7",
                  "width": 1171,
                  "height": 1183
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85504c1d503f59db68dd29902ebe53c3ae9805bf",
                    "width": 108,
                    "height": 109
                  },
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ab4ee28ccd5f0094b7df16a047977c70eb15f3f0",
                    "width": 216,
                    "height": 218
                  },
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fee03d498fe5468dd129ce289e46541ee313266f",
                    "width": 320,
                    "height": 323
                  },
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=387253ef4ef3e3a18ba79c1be71339080caaaf1c",
                    "width": 640,
                    "height": 646
                  },
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=154a847ff50bd149417d1293f794de877260c0b0",
                    "width": 960,
                    "height": 969
                  },
                  {
                    "url": "https://preview.redd.it/jzljyi4tw2gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=532a1a87298a85370fcd08ebf0a914e3f1af993c",
                    "width": 1080,
                    "height": 1091
                  }
                ],
                "variants": {},
                "id": "_bDOYeXRv8-6aZM9HJicur91RTVmLbLvtthLvcY-o_I"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdjb67",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "simracerman",
          "discussion_type": null,
          "num_comments": 115,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdjb67/after_6_months_of_fiddling_with_local_ai_heres_my/",
          "stickied": false,
          "url": "https://i.redd.it/jzljyi4tw2gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753911487,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": " ( Or... The adventures of a newbie )\n\nToday I learned something really important â€” and honestly, I had no idea how using API-hosted LLMs can quietly become a black hole for your wallet.ðŸ’¸ðŸ’°\n\nAt first glance, the pricing seems super appealing. You see those spicy â€œlowâ€ prices from big US companies â€” something like $0.002 per 1,000 tokens, and you think, \"Wow, thatâ€™s cheap!\"\n\nButâ€¦ letâ€™s do the math.\n\nYou start using a 128k context model on a platform like OpenRouter, and you donâ€™t realize that with every new interaction, your entire chat history is being resent to the API. Thatâ€™s the only way the model can \"remember\" the conversation. So after just a few minutes, each message you're sending might carry along 10k tokens â€” or even more.\n\nNow imagine youâ€™re chatting for hours. Every tiny reply â€” even a simple â€œokâ€ â€” could trigger a payload of 50,000 or 100,000 tokens being sent again and again. Itâ€™s like buying an entire book just to read the next letter.\n\nIn just a few hours, you may have burned through $5 to $10, just for a basic conversation. And now think monthly... or worse â€” imagine youâ€™re editing a software file with 800 lines of code. Every time you tweak a line and hit send, it could cost you $1 or $2 per second.\n\nI mean... what?!\n\nI now understand the almost desperate effort some people make to run LLMs locally on their own machines â€” because something that looks insanely cheap at first glanceâ€¦ can turn out to be violently expensive.\n\nThis is insane. Maybe everyone else already knew this â€” but I didnâ€™t! ðŸ˜¯ðŸ˜¯ðŸ˜¯\n",
          "author_fullname": "t2_8c7clfk1",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "The Great Deception of \"Low Prices\" in LLM APIs",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1meep6o",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.54,
          "author_flair_background_color": null,
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/KpH7dlNRh78oWPR5CwX_DiS1oipkBRXTYNWHmoAZyyg.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753998846,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;( Or... The adventures of a newbie )&lt;/p&gt;\n\n&lt;p&gt;Today I learned something really important â€” and honestly, I had no idea how using API-hosted LLMs can quietly become a black hole for your wallet.ðŸ’¸ðŸ’°&lt;/p&gt;\n\n&lt;p&gt;At first glance, the pricing seems super appealing. You see those spicy â€œlowâ€ prices from big US companies â€” something like $0.002 per 1,000 tokens, and you think, &amp;quot;Wow, thatâ€™s cheap!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Butâ€¦ letâ€™s do the math.&lt;/p&gt;\n\n&lt;p&gt;You start using a 128k context model on a platform like OpenRouter, and you donâ€™t realize that with every new interaction, your entire chat history is being resent to the API. Thatâ€™s the only way the model can &amp;quot;remember&amp;quot; the conversation. So after just a few minutes, each message you&amp;#39;re sending might carry along 10k tokens â€” or even more.&lt;/p&gt;\n\n&lt;p&gt;Now imagine youâ€™re chatting for hours. Every tiny reply â€” even a simple â€œokâ€ â€” could trigger a payload of 50,000 or 100,000 tokens being sent again and again. Itâ€™s like buying an entire book just to read the next letter.&lt;/p&gt;\n\n&lt;p&gt;In just a few hours, you may have burned through $5 to $10, just for a basic conversation. And now think monthly... or worse â€” imagine youâ€™re editing a software file with 800 lines of code. Every time you tweak a line and hit send, it could cost you $1 or $2 per second.&lt;/p&gt;\n\n&lt;p&gt;I mean... what?!&lt;/p&gt;\n\n&lt;p&gt;I now understand the almost desperate effort some people make to run LLMs locally on their own machines â€” because something that looks insanely cheap at first glanceâ€¦ can turn out to be violently expensive.&lt;/p&gt;\n\n&lt;p&gt;This is insane. Maybe everyone else already knew this â€” but I didnâ€™t! ðŸ˜¯ðŸ˜¯ðŸ˜¯&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/f8vv4t837agf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/f8vv4t837agf1.png?auto=webp&amp;s=2a5bde2dd3cb61e64af4720e8cc13e534a92116f",
                  "width": 1024,
                  "height": 1024
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a158041f9882499a65c08f11adace0fa76a0f40",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b71e536e993c221a57840d46c0f8345d4fd26f2",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a89d09f3744524462cc6bc4d5c80648aca4f27e9",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1305c708b1fbe4bb7166cf9808a29640f750a67",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=73ec0bc2072e5f2bc9194e2510d445f7e8673cfb",
                    "width": 960,
                    "height": 960
                  }
                ],
                "variants": {},
                "id": "PQVtbBsS9q88WP67d3L6vyJ8WKHnI51rshmbM64ONSA"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1meep6o",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Current-Stop7806",
          "discussion_type": null,
          "num_comments": 18,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/",
          "stickied": false,
          "url": "https://i.redd.it/f8vv4t837agf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753998846,
          "num_crossposts": 2,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": " We're in the era now where open source releases are nipping at the heels of closed-source models in benchmarks. But it's all in text modality. \n\nAs far as I can tell, there hasn't been a really solid contender when it comes to both being a SOTA model, and also having native audio/image/video input and image/audio output which has been demonstrated by OpenAI and Google.\n\nI feel like this is a really big deal that is mostly overlooked when comparing open source to closed source. Programming benchmarks are cool and all, but for a truly useful assistant, you need a model you can speak to, show stuff to, and it can speak back and generate images to show you stuff as well.",
          "author_fullname": "t2_66km3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Why is open source so behind on multi-modalitty?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdruc9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.9,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 77,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 77,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753935061,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re in the era now where open source releases are nipping at the heels of closed-source models in benchmarks. But it&amp;#39;s all in text modality. &lt;/p&gt;\n\n&lt;p&gt;As far as I can tell, there hasn&amp;#39;t been a really solid contender when it comes to both being a SOTA model, and also having native audio/image/video input and image/audio output which has been demonstrated by OpenAI and Google.&lt;/p&gt;\n\n&lt;p&gt;I feel like this is a really big deal that is mostly overlooked when comparing open source to closed source. Programming benchmarks are cool and all, but for a truly useful assistant, you need a model you can speak to, show stuff to, and it can speak back and generate images to show you stuff as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdruc9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "AnticitizenPrime",
          "discussion_type": null,
          "num_comments": 51,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdruc9/why_is_open_source_so_behind_on_multimodalitty/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdruc9/why_is_open_source_so_behind_on_multimodalitty/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753935061,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I'm shopping for a second hand gpu that has 32 gb of vram. I found the radeon mi50 and mi60 with 32Gb of VRAM. They're kinda old, are there any good for inference? I will use it for LLMs for text generation, image2image generation (like flux.1 kontext), as an agent, or for my camera surveillance for object and person detection.   \nIf someone has a suggestion for something else under 700â‚¬ I'd appreciate it. ",
          "author_fullname": "t2_15gjco",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Are radeon mi60 32Gb gpus still any good?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me8m73",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753984721,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m shopping for a second hand gpu that has 32 gb of vram. I found the radeon mi50 and mi60 with 32Gb of VRAM. They&amp;#39;re kinda old, are there any good for inference? I will use it for LLMs for text generation, image2image generation (like flux.1 kontext), as an agent, or for my camera surveillance for object and person detection.&lt;br/&gt;\nIf someone has a suggestion for something else under 700â‚¬ I&amp;#39;d appreciate it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me8m73",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "redblood252",
          "discussion_type": null,
          "num_comments": 15,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me8m73/are_radeon_mi60_32gb_gpus_still_any_good/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me8m73/are_radeon_mi60_32gb_gpus_still_any_good/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753984721,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "hello so i plan to run a lamm 4 scout and some kind of stable difusion moddels localy via silly tavern and Oobabooga, the thing i want to know is how to configure these 2 moddels to run the best for my ram/vram should i have it so that both moddels can fit in vram or should i have larger moddels that need to over flow into system ram. i have 96gb of ram and 24gb of vram, i have posted a screen shot of my specs.",
          "author_fullname": "t2_1tctryxr1a",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "best ram configuration for llama with stable difusion",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 68,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mehiqe",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/PPionGLDczu8b2H5lY5FRWs6QhuhH6vPJMdJ7vU0naQ.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754006138,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello so i plan to run a lamm 4 scout and some kind of stable difusion moddels localy via silly tavern and Oobabooga, the thing i want to know is how to configure these 2 moddels to run the best for my ram/vram should i have it so that both moddels can fit in vram or should i have larger moddels that need to over flow into system ram. i have 96gb of ram and 24gb of vram, i have posted a screen shot of my specs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ivkha3srsagf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ivkha3srsagf1.png?auto=webp&amp;s=63bd1ac9ee6faf0d450e04fb27f91dcc75a1c45c",
                  "width": 1062,
                  "height": 516
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ivkha3srsagf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=753336a0a1bc8b11bba7a9dc57050e9e7052762e",
                    "width": 108,
                    "height": 52
                  },
                  {
                    "url": "https://preview.redd.it/ivkha3srsagf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8e9a5fbcb3e06da41a811551e31cf313fca5240",
                    "width": 216,
                    "height": 104
                  },
                  {
                    "url": "https://preview.redd.it/ivkha3srsagf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf348b41d712280caf6bde990998394f0f5ff363",
                    "width": 320,
                    "height": 155
                  },
                  {
                    "url": "https://preview.redd.it/ivkha3srsagf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d8f4f36f696b22b786c1db813c0735fc6495d7d",
                    "width": 640,
                    "height": 310
                  },
                  {
                    "url": "https://preview.redd.it/ivkha3srsagf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee2202375bddf9235df95b113955ad1868c7dfaf",
                    "width": 960,
                    "height": 466
                  }
                ],
                "variants": {},
                "id": "6l0BeqykceEetgIrWmnEm7JBROqSMXIAIAfcRDKZskU"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mehiqe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "c2btw",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mehiqe/best_ram_configuration_for_llama_with_stable/",
          "stickied": false,
          "url": "https://i.redd.it/ivkha3srsagf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1754006138,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Iâ€™ve been using QwQ for production RAG tasks for quite a while now, mainly because it absolutely kills it with providing good citations (when instructed to explicitly do so). Itâ€™s also great at formatting answers in markdown, and is just a solid all around performer for me. I was eager to step up to the original Qwen3:32b and also Qwen-30B-A3B and while they seem good, they both just kind of failed my vibe check and werenâ€™t giving nearly as good answers as old reliable QwQ:32b. \n\nNow, I havenâ€™t tried the new updated versions of these models yet, but I really donâ€™t want to get rid of QwQ unless the replacement is like leaps and bounds better. Are the new Qwen3â€™s legit better than QwQ, or is it a benchmaxing situation. \nWhat (if anything) should I replace my daily driver QwQ:32b with. ",
          "author_fullname": "t2_y35oj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Finding it hard to part with QwQ:32b, convince me there is something better that I should be using for production RAG tasks.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mec14w",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753992556,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Iâ€™ve been using QwQ for production RAG tasks for quite a while now, mainly because it absolutely kills it with providing good citations (when instructed to explicitly do so). Itâ€™s also great at formatting answers in markdown, and is just a solid all around performer for me. I was eager to step up to the original Qwen3:32b and also Qwen-30B-A3B and while they seem good, they both just kind of failed my vibe check and werenâ€™t giving nearly as good answers as old reliable QwQ:32b. &lt;/p&gt;\n\n&lt;p&gt;Now, I havenâ€™t tried the new updated versions of these models yet, but I really donâ€™t want to get rid of QwQ unless the replacement is like leaps and bounds better. Are the new Qwen3â€™s legit better than QwQ, or is it a benchmaxing situation. \nWhat (if anything) should I replace my daily driver QwQ:32b with. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mec14w",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Porespellar",
          "discussion_type": null,
          "num_comments": 10,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mec14w/finding_it_hard_to_part_with_qwq32b_convince_me/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mec14w/finding_it_hard_to_part_with_qwq32b_convince_me/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753992556,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Anyone catch Horizon Alpha the new cloaked model up on OR? Blazing fast. It sure has an OpenAI vibe but Iâ€™m not betting on it. Anyone have any guesses or know what it is? Sorry if this has been talked about already but if so, I havenâ€™t seen it.",
          "author_fullname": "t2_ap0qx6cm",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Horizon Alpha on OpenRouter",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mea2gf",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.65,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753988053,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone catch Horizon Alpha the new cloaked model up on OR? Blazing fast. It sure has an OpenAI vibe but Iâ€™m not betting on it. Anyone have any guesses or know what it is? Sorry if this has been talked about already but if so, I havenâ€™t seen it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mea2gf",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Background_Put_4978",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mea2gf/horizon_alpha_on_openrouter/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mea2gf/horizon_alpha_on_openrouter/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753988053,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "First of all - it is starting to be interesting. Looks like we can run locally models which compete with online models!\n\nI know - there are thousands of comparison, yet, maybe someone will find this one interesting.\n\nWhat I did - my prompt: \"Write a complete system to control heating / cooling system at home. Note, I'm expecting full software implementation, however, heating system itself will be controlled through existing controller, therefore it will offer all security control. Heating system will accept only 3 states - heat:on, cool:on, off.\n\nIt is expected to use weather - actual and forecast - to ensure higher comfort. We speak of house of 2 bedrooms, living room and two bathrooms. Heating and cooling is done through floor (with pipes filled with water). It is possible to control each room through valves for each of the room.\"\n\n(I had to mention security, otherwise Qwen thinking was refusing to work)\n\nWith Claude-sonnet - no iterations, no testing. Full auto-accept till done.\n\nI used o3 to do the comparison.\n\nMy rig is: 5 x 3090 RTX\n\n# Comparative score-card (âœ“ = fully addressed, â–³ = partly / workaround, âœ— = missing)\n\n|Criterion|Claude answer (time similar to Qwen-235B)|Qwen-235B-thinking (IQ4\\_XS) answer (\\~18 t/s)|Qwen-30b answer (70 t/s)|\n|:-|:-|:-|:-|\n|**single 3-state main controller**`heatcooloff`Uses   ( ,  ,  )|`set_system_state()SystemState.HEAT/COOL/OFF`âœ“ Interface exposes   with|`HVAC_CONTROLLER[\"VALID_STATES\"] = ['heat','cool','off']_set_hvac_mode`âœ“   &amp; strict validator in|`\"heat:on\" / \"cool:on\" / \"off\"`â–³ Sends per-room MQTT commands  ; no global switch, so the existing controller must interpret many room-level orders|\n|**Per-room valve logic** (5 zones)|`SmartValveController.update_all_valves()`âœ“   drives each valve with PID &amp; occupancy weighting|`_update_valve_states()`âœ“   opens valves only when zone demand matches main mode|`_send_valve_command()`âœ“   publishes valve topic commands per room|\n|**actual &amp; forecast weather**Incorporates|`optimize_for_weather()`âœ“   adapts targets ahead of cold front|`WeatherIntelligence`âœ“   analyses 48 h forecast &amp; triggers pre-emptive mode changes|`WeatherManager.update_weather()`âœ“   pulls current + 3-day forecast to tweak set-points|\n|**Explicit zone list** (2 bedrooms, living, 2 bath) in config|â–³ rooms are created via RoomManager; not pre-filled|`SYSTEM_CONFIG['ROOMS']`âœ“   defines the five required zones with priorities|`config.json`âœ“   lists bedroom1, bedroom2, living\\_room, bathroom1, bathroom2 with valve IDs|\n|\\*\\*â€œhardware handles safetyâ€\\*\\*Respects   (software only sends 3-state commands)|â–³ Adds its own watchdog &amp; temperature limits â€“ safe but redundant|âœ“ Section â€œSafety &amp; Compliance notesâ€ stresses that existing controller enforces limits; software only issues validated 3-state orders|âœ— No discussion; still pushes per-room heat/cool commands|\n|**Scheduling &amp; overrides**|Rich: JSON schedules, occupancy, energy-saving profiles|Rich: weekday/weekend schedules, override expiry, comfort modes per room|Medium: basic time-of-day &amp; weather adjustments, but no per-zone calendar|\n|**Implementation readiness**|`main.py`Large runnable code-base (  threads, logging, mock HW) â€“ may need GPIO layer substituted|Modular repo with clear install guide, requirements.txt and systemd unit; designed for Pi or NUC|Also sizeable repo plus web UI, but global HVAC abstraction missing; will need integration work|\n|**Code clarity &amp; maintainability**|Strong layering but many files (\\~10 k LOC) â€“ onboarding cost|Clean separation (config / weather / zones / control); defensive logging|Monolith in places; HTML/JS mixed with Python; fewer docstrings|\n|**Overall fit to new brief** (0-10)|**7** â€“ technically solid, minor over-engineering &amp; not explicit about external controller|**9** â€“ purpose-built for 3-state controller, forecasts, five zones; concise yet complete|**6** â€“ room-level commands breach single-controller constraint; otherwise feature-rich|",
          "author_fullname": "t2_299y0q2q",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Comparison I did - Claude Sonnet / local Qwen3-30B / local Qwen3-235B-thinking",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me9yqh",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753987819,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all - it is starting to be interesting. Looks like we can run locally models which compete with online models!&lt;/p&gt;\n\n&lt;p&gt;I know - there are thousands of comparison, yet, maybe someone will find this one interesting.&lt;/p&gt;\n\n&lt;p&gt;What I did - my prompt: &amp;quot;Write a complete system to control heating / cooling system at home. Note, I&amp;#39;m expecting full software implementation, however, heating system itself will be controlled through existing controller, therefore it will offer all security control. Heating system will accept only 3 states - heat:on, cool:on, off.&lt;/p&gt;\n\n&lt;p&gt;It is expected to use weather - actual and forecast - to ensure higher comfort. We speak of house of 2 bedrooms, living room and two bathrooms. Heating and cooling is done through floor (with pipes filled with water). It is possible to control each room through valves for each of the room.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;(I had to mention security, otherwise Qwen thinking was refusing to work)&lt;/p&gt;\n\n&lt;p&gt;With Claude-sonnet - no iterations, no testing. Full auto-accept till done.&lt;/p&gt;\n\n&lt;p&gt;I used o3 to do the comparison.&lt;/p&gt;\n\n&lt;p&gt;My rig is: 5 x 3090 RTX&lt;/p&gt;\n\n&lt;h1&gt;Comparative score-card (âœ“ = fully addressed, â–³ = partly / workaround, âœ— = missing)&lt;/h1&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Criterion&lt;/th&gt;\n&lt;th align=\"left\"&gt;Claude answer (time similar to Qwen-235B)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Qwen-235B-thinking (IQ4_XS) answer (~18 t/s)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Qwen-30b answer (70 t/s)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;single 3-state main controller&lt;/strong&gt;&lt;code&gt;heatcooloff&lt;/code&gt;Uses   ( ,  ,  )&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;set_system_state()SystemState.HEAT/COOL/OFF&lt;/code&gt;âœ“ Interface exposes   with&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;HVAC_CONTROLLER[&amp;quot;VALID_STATES&amp;quot;] = [&amp;#39;heat&amp;#39;,&amp;#39;cool&amp;#39;,&amp;#39;off&amp;#39;]_set_hvac_mode&lt;/code&gt;âœ“   &amp;amp; strict validator in&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;&amp;quot;heat:on&amp;quot; / &amp;quot;cool:on&amp;quot; / &amp;quot;off&amp;quot;&lt;/code&gt;â–³ Sends per-room MQTT commands  ; no global switch, so the existing controller must interpret many room-level orders&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Per-room valve logic&lt;/strong&gt; (5 zones)&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;SmartValveController.update_all_valves()&lt;/code&gt;âœ“   drives each valve with PID &amp;amp; occupancy weighting&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;_update_valve_states()&lt;/code&gt;âœ“   opens valves only when zone demand matches main mode&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;_send_valve_command()&lt;/code&gt;âœ“   publishes valve topic commands per room&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;actual &amp;amp; forecast weather&lt;/strong&gt;Incorporates&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;optimize_for_weather()&lt;/code&gt;âœ“   adapts targets ahead of cold front&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;WeatherIntelligence&lt;/code&gt;âœ“   analyses 48 h forecast &amp;amp; triggers pre-emptive mode changes&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;WeatherManager.update_weather()&lt;/code&gt;âœ“   pulls current + 3-day forecast to tweak set-points&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Explicit zone list&lt;/strong&gt; (2 bedrooms, living, 2 bath) in config&lt;/td&gt;\n&lt;td align=\"left\"&gt;â–³ rooms are created via RoomManager; not pre-filled&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;SYSTEM_CONFIG[&amp;#39;ROOMS&amp;#39;]&lt;/code&gt;âœ“   defines the five required zones with priorities&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;config.json&lt;/code&gt;âœ“   lists bedroom1, bedroom2, living_room, bathroom1, bathroom2 with valve IDs&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;**â€œhardware handles safetyâ€**Respects   (software only sends 3-state commands)&lt;/td&gt;\n&lt;td align=\"left\"&gt;â–³ Adds its own watchdog &amp;amp; temperature limits â€“ safe but redundant&lt;/td&gt;\n&lt;td align=\"left\"&gt;âœ“ Section â€œSafety &amp;amp; Compliance notesâ€ stresses that existing controller enforces limits; software only issues validated 3-state orders&lt;/td&gt;\n&lt;td align=\"left\"&gt;âœ— No discussion; still pushes per-room heat/cool commands&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Scheduling &amp;amp; overrides&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Rich: JSON schedules, occupancy, energy-saving profiles&lt;/td&gt;\n&lt;td align=\"left\"&gt;Rich: weekday/weekend schedules, override expiry, comfort modes per room&lt;/td&gt;\n&lt;td align=\"left\"&gt;Medium: basic time-of-day &amp;amp; weather adjustments, but no per-zone calendar&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Implementation readiness&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;code&gt;main.py&lt;/code&gt;Large runnable code-base (  threads, logging, mock HW) â€“ may need GPIO layer substituted&lt;/td&gt;\n&lt;td align=\"left\"&gt;Modular repo with clear install guide, requirements.txt and systemd unit; designed for Pi or NUC&lt;/td&gt;\n&lt;td align=\"left\"&gt;Also sizeable repo plus web UI, but global HVAC abstraction missing; will need integration work&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Code clarity &amp;amp; maintainability&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Strong layering but many files (~10 k LOC) â€“ onboarding cost&lt;/td&gt;\n&lt;td align=\"left\"&gt;Clean separation (config / weather / zones / control); defensive logging&lt;/td&gt;\n&lt;td align=\"left\"&gt;Monolith in places; HTML/JS mixed with Python; fewer docstrings&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Overall fit to new brief&lt;/strong&gt; (0-10)&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;7&lt;/strong&gt; â€“ technically solid, minor over-engineering &amp;amp; not explicit about external controller&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;9&lt;/strong&gt; â€“ purpose-built for 3-state controller, forecasts, five zones; concise yet complete&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;6&lt;/strong&gt; â€“ room-level commands breach single-controller constraint; otherwise feature-rich&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me9yqh",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "stachumann",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me9yqh/comparison_i_did_claude_sonnet_local_qwen330b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me9yqh/comparison_i_did_claude_sonnet_local_qwen330b/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753987819,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Download on ollama.com/download\n\nor GitHub releases\n\nhttps://github.com/ollama/ollama/releases/tag/v0.10.0\n\nBlog post: [Ollama's new app](https://ollama.com/blog/new-app)",
          "author_fullname": "t2_39i1zb05",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ollamaâ€™s new app â€” Ollama 0.10 is here for macOS and Windows!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 101,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdvhxg",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "ups": 36,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 36,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/y0zUJBMQNENQ_tiiNf9ET2MZBkbKPyUisQSSdMhLeN0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753948360,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Download on ollama.com/download&lt;/p&gt;\n\n&lt;p&gt;or GitHub releases&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ollama/ollama/releases/tag/v0.10.0\"&gt;https://github.com/ollama/ollama/releases/tag/v0.10.0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Blog post: &lt;a href=\"https://ollama.com/blog/new-app\"&gt;Ollama&amp;#39;s new app&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/9wfl7u6z06gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?auto=webp&amp;s=14c75a6382af6bf6af7ad2f3eee5a684499cf67f",
                  "width": 1616,
                  "height": 1175
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dd49534e752553e996786ccf873670e3e86ffda7",
                    "width": 108,
                    "height": 78
                  },
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7caaad3d484d5e59041ed91f0009cf9537860fda",
                    "width": 216,
                    "height": 157
                  },
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2875fbf74d7f187cf9eef62f158076768d9bf6f4",
                    "width": 320,
                    "height": 232
                  },
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd44ba69feb6890ee5ba2e203ace6fbc8cf232b3",
                    "width": 640,
                    "height": 465
                  },
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=36bc619a7ffd9ec2d69c665a2c62b2db5b40f981",
                    "width": 960,
                    "height": 698
                  },
                  {
                    "url": "https://preview.redd.it/9wfl7u6z06gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49d547be721d4af32551cff9f74de4ca208cf62f",
                    "width": 1080,
                    "height": 785
                  }
                ],
                "variants": {},
                "id": "-YCFasS_tCLK0d5k6IATEYLW294hMdGZ9NP1BS1XEEg"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mdvhxg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "bllshrfv",
          "discussion_type": null,
          "num_comments": 21,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdvhxg/ollamas_new_app_ollama_010_is_here_for_macos_and/",
          "stickied": false,
          "url": "https://i.redd.it/9wfl7u6z06gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753948360,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "* Why does it get stuck at 100%?\n* Why does it kill my router?!\n* Why does it slow down internet to a crawl when it's *resuming* a download?!\n* Why does it take half an hour to know from where it shall resume a download?!\n* Why does it receive \"incomplete message\" and has to sleep two dozen times during download?!\n* Why the hell do I need to use a rust tool, wrapped in a dozen python layers, to do a fraction of what CURL does?!!!?!?\n\nI feel so stupid suffering with that broken tool for 2 years when I could've just used CURL.\n\nPlease, HF team, remove references to that broken piece of crap and instruct users to just use CURL!",
          "author_fullname": "t2_nc2u4f7",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Why is \"hf download\" such a PITA?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1megyc6",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.58,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754005086,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754004608,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Why does it get stuck at 100%?&lt;/li&gt;\n&lt;li&gt;Why does it kill my router?!&lt;/li&gt;\n&lt;li&gt;Why does it slow down internet to a crawl when it&amp;#39;s &lt;em&gt;resuming&lt;/em&gt; a download?!&lt;/li&gt;\n&lt;li&gt;Why does it take half an hour to know from where it shall resume a download?!&lt;/li&gt;\n&lt;li&gt;Why does it receive &amp;quot;incomplete message&amp;quot; and has to sleep two dozen times during download?!&lt;/li&gt;\n&lt;li&gt;Why the hell do I need to use a rust tool, wrapped in a dozen python layers, to do a fraction of what CURL does?!!!?!?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I feel so stupid suffering with that broken tool for 2 years when I could&amp;#39;ve just used CURL.&lt;/p&gt;\n\n&lt;p&gt;Please, HF team, remove references to that broken piece of crap and instruct users to just use CURL!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1megyc6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ParaboloidalCrest",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1megyc6/why_is_hf_download_such_a_pita/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1megyc6/why_is_hf_download_such_a_pita/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754004608,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://eqbench.com/](https://eqbench.com/)\n\nCreative Writing Samples: [https://eqbench.com/results/creative-writing-v3/openrouter\\_\\_horizon-alpha.html](https://eqbench.com/results/creative-writing-v3/openrouter__horizon-alpha.html)\n\nLongform Writing Samples: [https://eqbench.com/results/creative-writing-longform/openrouter\\_\\_horizon-alpha\\_longform\\_report.html](https://eqbench.com/results/creative-writing-longform/openrouter__horizon-alpha_longform_report.html)\n\nEQ-Bench Samples: [https://eqbench.com/results/eqbench3\\_reports/openrouter\\_\\_horizon-alpha.html](https://eqbench.com/results/eqbench3_reports/openrouter__horizon-alpha.html)",
          "author_fullname": "t2_pp9qh5t8g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Horizon-alpha: A new stealthed model on openrouter sweeps EQ-Bench leaderboards",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 109,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "0hjgl87da4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 216,
                  "x": 108,
                  "u": "https://preview.redd.it/0hjgl87da4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1b1698371a575e067e538216fdfa5682c4a8a4a3"
                },
                {
                  "y": 432,
                  "x": 216,
                  "u": "https://preview.redd.it/0hjgl87da4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2c2a7b3723a8be0877b5cbacca51f76a92fb88c"
                },
                {
                  "y": 640,
                  "x": 320,
                  "u": "https://preview.redd.it/0hjgl87da4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e252f2bc49314097aee9f41c09a61b936789dea1"
                }
              ],
              "s": {
                "y": 1559,
                "x": 500,
                "u": "https://preview.redd.it/0hjgl87da4gf1.png?width=500&amp;format=png&amp;auto=webp&amp;s=a0dfa2e78fd558efcb69b8d7b5035292dae09b5b"
              },
              "id": "0hjgl87da4gf1"
            },
            "97jmcuhda4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 120,
                  "x": 108,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2c1e86a37edc143cdfd50ea87f7186be4a19cd3"
                },
                {
                  "y": 240,
                  "x": 216,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffc067f53a62cb4b6a8a79d6f98225a8700378f8"
                },
                {
                  "y": 355,
                  "x": 320,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fbe11b123fd181cc7e877f5eaa2aa2985abb703d"
                },
                {
                  "y": 711,
                  "x": 640,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f6f7642b1fc3478e375d3e8c802d2ca90a5132a"
                },
                {
                  "y": 1067,
                  "x": 960,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6797f0fa90c63574d109155b175b3ba75b68e73a"
                },
                {
                  "y": 1200,
                  "x": 1080,
                  "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2a05a1d5900c03ab250ea900b75d24734583e9e5"
                }
              ],
              "s": {
                "y": 1759,
                "x": 1582,
                "u": "https://preview.redd.it/97jmcuhda4gf1.png?width=1582&amp;format=png&amp;auto=webp&amp;s=f126b3fa7844706b630eec7865f7fb70d1bf1409"
              },
              "id": "97jmcuhda4gf1"
            },
            "h6vp95gba4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 100,
                  "x": 108,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53bb0b225fd63e3d15282b854d21248977a1ddf6"
                },
                {
                  "y": 200,
                  "x": 216,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=572645efe6e89d8b1f1d40a5e945e17ef288e1af"
                },
                {
                  "y": 297,
                  "x": 320,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5d31be02df86efe99aa0a92b561fd40824e2e4d5"
                },
                {
                  "y": 595,
                  "x": 640,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=84d4fc5782bd390a6cdb1859fd6aaaafad2ee381"
                },
                {
                  "y": 892,
                  "x": 960,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ffc9199ef0d440c21352701368ea1a34dc58521"
                },
                {
                  "y": 1004,
                  "x": 1080,
                  "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a9b8caababd907944f0aa2234b55d45049f9ddf"
                }
              ],
              "s": {
                "y": 1488,
                "x": 1600,
                "u": "https://preview.redd.it/h6vp95gba4gf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=d3befcf565a0242576fda7272a6035e30b0acaa7"
              },
              "id": "h6vp95gba4gf1"
            },
            "lnsnzumaa4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 84,
                  "x": 108,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=87bd182b166b9a3e8a17a6fb15e4375772923e47"
                },
                {
                  "y": 168,
                  "x": 216,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d63b0fc847b78b67d05935118dd4a72711a79a7c"
                },
                {
                  "y": 249,
                  "x": 320,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f92d32e59872a66fabe9edbf3cf41a52f5ed0253"
                },
                {
                  "y": 499,
                  "x": 640,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c2f47f092279c4db134b70a9a7abc1dfd4f0e5c"
                },
                {
                  "y": 749,
                  "x": 960,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=84dc29dea2ffe79a8a2544d42a38655f1c4251ea"
                },
                {
                  "y": 843,
                  "x": 1080,
                  "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=af54f3cafe7ab477c037ba69c83338d0c1058229"
                }
              ],
              "s": {
                "y": 1250,
                "x": 1601,
                "u": "https://preview.redd.it/lnsnzumaa4gf1.png?width=1601&amp;format=png&amp;auto=webp&amp;s=063aacd81cd83b4c2eebf8ec30cbbbe236572b9f"
              },
              "id": "lnsnzumaa4gf1"
            },
            "1wgsqo2ba4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 70,
                  "x": 108,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a24a34dbcb3fc6cf066e5b9f279d8478126b452f"
                },
                {
                  "y": 140,
                  "x": 216,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b50d604893c06b435f61b094416ba5657f518102"
                },
                {
                  "y": 208,
                  "x": 320,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c25ca12429f37e76e95befadf47d29c4bc8d0a6f"
                },
                {
                  "y": 416,
                  "x": 640,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a341f6567c86d5e2683c49bbc2b95f379172f8ad"
                },
                {
                  "y": 624,
                  "x": 960,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ebe3537a5e7507b1c4099a5fa9908ba0007db0de"
                },
                {
                  "y": 703,
                  "x": 1080,
                  "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa5e17e1846195520912344742213193be8923f6"
                }
              ],
              "s": {
                "y": 1039,
                "x": 1596,
                "u": "https://preview.redd.it/1wgsqo2ba4gf1.png?width=1596&amp;format=png&amp;auto=webp&amp;s=c0a68412e78392ac0f6f65771c6df77e5595da3c"
              },
              "id": "1wgsqo2ba4gf1"
            },
            "19k8r2sda4gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 134,
                  "x": 108,
                  "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=80c3e29962572aa2aebff6b09b69d12dbb4e1c8c"
                },
                {
                  "y": 268,
                  "x": 216,
                  "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=600f7c5a9acef670deeaaa73c09e57d76c007f0c"
                },
                {
                  "y": 397,
                  "x": 320,
                  "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=89912b71c7633edeb745c3873732372745a32b89"
                },
                {
                  "y": 795,
                  "x": 640,
                  "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b92da988e454713d5eac4b86576c8e43e578987"
                },
                {
                  "y": 1193,
                  "x": 960,
                  "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9012253e966cbd987efb892bdbff712a7ef1e2dc"
                }
              ],
              "s": {
                "y": 1230,
                "x": 989,
                "u": "https://preview.redd.it/19k8r2sda4gf1.png?width=989&amp;format=png&amp;auto=webp&amp;s=14ab62c1128148e873135cd8e7e017517cf8ddaa"
              },
              "id": "19k8r2sda4gf1"
            }
          },
          "name": "t3_1mdpe8v",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": "transparent",
          "ups": 106,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "lnsnzumaa4gf1",
                "id": 717800299
              },
              {
                "media_id": "1wgsqo2ba4gf1",
                "id": 717800300
              },
              {
                "media_id": "h6vp95gba4gf1",
                "id": 717800301
              },
              {
                "media_id": "0hjgl87da4gf1",
                "id": 717800302
              },
              {
                "media_id": "97jmcuhda4gf1",
                "id": 717800303
              },
              {
                "media_id": "19k8r2sda4gf1",
                "id": 717800304
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 106,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/aYYIospZdzzPcpq5Dkfv_OnJ4m1Tv1B_fMeERdxNnXQ.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":Llama:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753927754,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://eqbench.com/\"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Creative Writing Samples: &lt;a href=\"https://eqbench.com/results/creative-writing-v3/openrouter__horizon-alpha.html\"&gt;https://eqbench.com/results/creative-writing-v3/openrouter__horizon-alpha.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Longform Writing Samples: &lt;a href=\"https://eqbench.com/results/creative-writing-longform/openrouter__horizon-alpha_longform_report.html\"&gt;https://eqbench.com/results/creative-writing-longform/openrouter__horizon-alpha_longform_report.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EQ-Bench Samples: &lt;a href=\"https://eqbench.com/results/eqbench3_reports/openrouter__horizon-alpha.html\"&gt;https://eqbench.com/results/eqbench3_reports/openrouter__horizon-alpha.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mdpe8v",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":Llama:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mdpe8v",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_sqrkl",
          "discussion_type": null,
          "num_comments": 48,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mdpe8v/horizonalpha_a_new_stealthed_model_on_openrouter/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mdpe8v",
          "subreddit_subscribers": 507935,
          "created_utc": 1753927754,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Wtf is this guy talking about\n\nhttps://youtu.be/mYDSSRS-B5U&amp;t=36m43s",
          "author_fullname": "t2_12r2mg3dqi",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Dario's (stupid) take on open source",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me3hy7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.68,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 10,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 10,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753973091,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wtf is this guy talking about&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/mYDSSRS-B5U&amp;amp;t=36m43s\"&gt;https://youtu.be/mYDSSRS-B5U&amp;amp;t=36m43s&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me3hy7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Conscious_Nobody9571",
          "discussion_type": null,
          "num_comments": 34,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me3hy7/darios_stupid_take_on_open_source/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me3hy7/darios_stupid_take_on_open_source/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753973091,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_ngleu",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "ChatGPT hallucinated about music app Soundslice so often, the founder made the lie come true | TechCrunch",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 82,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mecx9y",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.59,
          "author_flair_background_color": null,
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=140&amp;height=82&amp;crop=140:82,smart&amp;auto=webp&amp;s=8cd8452ef230286cfbfe8537953b1582b6792a19",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753994617,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "techcrunch.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?auto=webp&amp;s=4c107a35d7a042ad7c46d0224ca46684079b7f52",
                  "width": 1200,
                  "height": 708
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2cc737374080ce997847ca2205c773d6e8bd7613",
                    "width": 108,
                    "height": 63
                  },
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d836ffed3a853860b4ef1440d1b1b825cefc2d9e",
                    "width": 216,
                    "height": 127
                  },
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3fcce53b590cbc8ddfb99d34490f78a5c075b164",
                    "width": 320,
                    "height": 188
                  },
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e257b1409400f4f9534e0ed745be827b95c516f",
                    "width": 640,
                    "height": 377
                  },
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4413e0184e85dc801bd7d89dea97caf8314a0a49",
                    "width": 960,
                    "height": 566
                  },
                  {
                    "url": "https://external-preview.redd.it/nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1ad586a91a25ca508e0df305de81dc9d85ad6fc",
                    "width": 1080,
                    "height": 637
                  }
                ],
                "variants": {},
                "id": "nR2pVxehfwN8QdQGeVdApJpYjIuKWfs-SywPfJUFEE4"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mecx9y",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ChiliPepperHott",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mecx9y/chatgpt_hallucinated_about_music_app_soundslice/",
          "stickied": false,
          "url": "https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753994617,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "They keep putting different reference models in their graphs and we have to look at many graphs to see where we're at so I used AI to put them all in a single table. \n\nIf any of you find errors, I'll delete this post.",
          "author_fullname": "t2_cy3wb",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Made a unified table of benchmarks using AI",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 118,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdpfm8",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.99,
          "author_flair_background_color": null,
          "ups": 70,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 70,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/lMpBTfZOCCGirkVYxjC83Mp6Jt56ORIzT82IDPyjBW0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753927864,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They keep putting different reference models in their graphs and we have to look at many graphs to see where we&amp;#39;re at so I used AI to put them all in a single table. &lt;/p&gt;\n\n&lt;p&gt;If any of you find errors, I&amp;#39;ll delete this post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/gxir7usrb4gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/gxir7usrb4gf1.png?auto=webp&amp;s=61d06e6324953072a8e16fa1d5e68e0847991400",
                  "width": 2023,
                  "height": 1716
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f70288958d623f870f4e10912a44bb9b39cc5409",
                    "width": 108,
                    "height": 91
                  },
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f86fe1853b5b4d1c7fdb4253b217201744ef1f2",
                    "width": 216,
                    "height": 183
                  },
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=af9809f575fc23494e257bb06b18946a85ae2322",
                    "width": 320,
                    "height": 271
                  },
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7928c2d81afe832554b8bc632895b2c84d73b271",
                    "width": 640,
                    "height": 542
                  },
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cc782f8d6d1287180ae6f4052bb23ebba3585d0e",
                    "width": 960,
                    "height": 814
                  },
                  {
                    "url": "https://preview.redd.it/gxir7usrb4gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=249a775adb66b6a59c26eca8edd6d0324ff3457c",
                    "width": 1080,
                    "height": 916
                  }
                ],
                "variants": {},
                "id": "PZRlYen2-ELD9AIBlp1RXYOXWkNmox6ICN4EBThyAPs"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mdpfm8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DrVonSinistro",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdpfm8/made_a_unified_table_of_benchmarks_using_ai/",
          "stickied": false,
          "url": "https://i.redd.it/gxir7usrb4gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753927864,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hello. It has been an awesomely-busy week for all of us here, trying out the new goodies that dropped by Qwen and others. Wow, this week will be hard to match, good times!\n\nLike most here, I ended up trying a bunch of models in bunch of quants plus mlx.\n\nI have to say, the model that completely blew my mind was glm-4.5-air, the 4-bit mlx. I plugged it into my assistant (that does chains of tools, plus connected to a project management app, plus to a notebook), and it immediately figured out how to use those.\n\nIt really likes to dig through tasks, priorities, notes, online research - to the point when I am worried it's going to do it too much and loose track of things - but amazingly enough, it doesn't loose track of things and comes back with in-depth, good analysis and responses.\n\nThe model is also fast - kind of reminds me of Owen 30b a3b, although of course it punches well above that one due to its larger size.\n\nIf you can fit the 4-bit version onto your machine, absolutely, give this model a try. It is now my new daily driver, replacing Qwen 32B (until the new Qwen 32B comes out later this week? lol)\n\nedit: I am not associated with the gml team (I wish I was!)",
          "author_fullname": "t2_ajuxt3cr4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "glm-4.5-Air appreciation poist - if you have not done so already, give this model a try",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdhfhs",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 203,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 203,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753907041,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. It has been an awesomely-busy week for all of us here, trying out the new goodies that dropped by Qwen and others. Wow, this week will be hard to match, good times!&lt;/p&gt;\n\n&lt;p&gt;Like most here, I ended up trying a bunch of models in bunch of quants plus mlx.&lt;/p&gt;\n\n&lt;p&gt;I have to say, the model that completely blew my mind was glm-4.5-air, the 4-bit mlx. I plugged it into my assistant (that does chains of tools, plus connected to a project management app, plus to a notebook), and it immediately figured out how to use those.&lt;/p&gt;\n\n&lt;p&gt;It really likes to dig through tasks, priorities, notes, online research - to the point when I am worried it&amp;#39;s going to do it too much and loose track of things - but amazingly enough, it doesn&amp;#39;t loose track of things and comes back with in-depth, good analysis and responses.&lt;/p&gt;\n\n&lt;p&gt;The model is also fast - kind of reminds me of Owen 30b a3b, although of course it punches well above that one due to its larger size.&lt;/p&gt;\n\n&lt;p&gt;If you can fit the 4-bit version onto your machine, absolutely, give this model a try. It is now my new daily driver, replacing Qwen 32B (until the new Qwen 32B comes out later this week? lol)&lt;/p&gt;\n\n&lt;p&gt;edit: I am not associated with the gml team (I wish I was!)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdhfhs",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Southern_Sun_2106",
          "discussion_type": null,
          "num_comments": 88,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdhfhs/glm45air_appreciation_poist_if_you_have_not_done/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdhfhs/glm45air_appreciation_poist_if_you_have_not_done/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753907041,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_aedi2k9c",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3 Coder 30B-A3B tomorrow!!!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md93bj",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "ups": 524,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 524,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/K9Nx9k0yfNo72Su3RE5muDzCVrLNRn61GBRiLFKFFlA.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753888106,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/zv92612t11gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/zv92612t11gf1.png?auto=webp&amp;s=2e69f2943ffedc6058b01531a0b5f5b904fafd93",
                  "width": 1220,
                  "height": 1930
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ccf72bfa2613f3f4323503ca258299edae1698d8",
                    "width": 108,
                    "height": 170
                  },
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aefde73c9c87f9c3ee96e4775270e592bc63ffa2",
                    "width": 216,
                    "height": 341
                  },
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=46854036774a921e80cbd749c0d46d3f65aa9331",
                    "width": 320,
                    "height": 506
                  },
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45b98263f660ff1bebd4634907371461fd4e0207",
                    "width": 640,
                    "height": 1012
                  },
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1655dfcc3acdbda1edf7e8c2bf52e4f818053f7c",
                    "width": 960,
                    "height": 1518
                  },
                  {
                    "url": "https://preview.redd.it/zv92612t11gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82106ce904e641b1635835e5273e833ddcf3bec8",
                    "width": 1080,
                    "height": 1708
                  }
                ],
                "variants": {},
                "id": "_P987MccCP9zB7Niv68pkAsjdEVBNJKGFyGu7MefRFU"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1md93bj",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "R46H4V",
          "discussion_type": null,
          "num_comments": 63,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md93bj/qwen3_coder_30ba3b_tomorrow/",
          "stickied": false,
          "url": "https://i.redd.it/zv92612t11gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753888106,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/9b90taq24bgf1.png?width=1069&amp;format=png&amp;auto=webp&amp;s=41b586e0b141235712b9b10dbb3bc49aac03ab97\n\njust downloaded the qwen3:8b model \"qwen3:8b-q4\\_K\\_M\" and was running it locally...  \nbut im getting reply like this- (it was better at starting but after closing and strting 2-3 times it start giving results like this)",
          "author_fullname": "t2_1193bbkcp9",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "first time local llm and facing issues",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 79,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "9b90taq24bgf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 61,
                  "x": 108,
                  "u": "https://preview.redd.it/9b90taq24bgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=349b95a5171154254de348da737d9b538f75a62d"
                },
                {
                  "y": 122,
                  "x": 216,
                  "u": "https://preview.redd.it/9b90taq24bgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f7413b854010be5d3e898a897a7693be4ada7c1"
                },
                {
                  "y": 181,
                  "x": 320,
                  "u": "https://preview.redd.it/9b90taq24bgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f44b911d4a4572bd48ed31cec63a0d08da4edc29"
                },
                {
                  "y": 363,
                  "x": 640,
                  "u": "https://preview.redd.it/9b90taq24bgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e458271d586ffd15d97416df27c3a0bef2aeda66"
                },
                {
                  "y": 545,
                  "x": 960,
                  "u": "https://preview.redd.it/9b90taq24bgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6cd39afd72c0a26b006fab17a248aa90f8e37bff"
                }
              ],
              "s": {
                "y": 607,
                "x": 1069,
                "u": "https://preview.redd.it/9b90taq24bgf1.png?width=1069&amp;format=png&amp;auto=webp&amp;s=41b586e0b141235712b9b10dbb3bc49aac03ab97"
              },
              "id": "9b90taq24bgf1"
            }
          },
          "name": "t3_1meiwzu",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/bMW35LWeR28oOw8LWBvUuxjcUhuhNuHMtYvWiQneEdc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754010032,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/9b90taq24bgf1.png?width=1069&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=41b586e0b141235712b9b10dbb3bc49aac03ab97\"&gt;https://preview.redd.it/9b90taq24bgf1.png?width=1069&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=41b586e0b141235712b9b10dbb3bc49aac03ab97&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;just downloaded the qwen3:8b model &amp;quot;qwen3:8b-q4_K_M&amp;quot; and was running it locally...&lt;br/&gt;\nbut im getting reply like this- (it was better at starting but after closing and strting 2-3 times it start giving results like this)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1meiwzu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Fit_Bit_9845",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meiwzu/first_time_local_llm_and_facing_issues/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meiwzu/first_time_local_llm_and_facing_issues/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754010032,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi everyone, does someone have recommendations for a speech-to-text model that would be able to handle long audioâ€™s (~1 hour)? What would be the best way to go about this? \n",
          "author_fullname": "t2_5d4sbvno",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Speech-to-text for long audio files",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mei9yg",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754008193,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, does someone have recommendations for a speech-to-text model that would be able to handle long audioâ€™s (~1 hour)? What would be the best way to go about this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mei9yg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Noxchi095",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mei9yg/speechtotext_for_long_audio_files/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mei9yg/speechtotext_for_long_audio_files/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754008193,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "If you read most of the technical release papers, they sample plenty.  5, 8, 10, 25, 100times!   Some of those scores we are seeing are after so many sampling.   Fair enough, I don't think an LLM should be judged by one sample, but definitely a few.   Yet it seems folks are not sampling plenty of times when doing one shot.   Why is that?     IMO, seems if you are not chatting, you should be sampling 3 or 5 times at least.   It certainly makes for a slow down, but isn't quality better?    Furthermore those of us local are often running quantized models, seems we will also need sampling more.",
          "author_fullname": "t2_ah13x",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How many times do you sample, and why not more?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mei5ya",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": "#bbbdbf",
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754007886,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you read most of the technical release papers, they sample plenty.  5, 8, 10, 25, 100times!   Some of those scores we are seeing are after so many sampling.   Fair enough, I don&amp;#39;t think an LLM should be judged by one sample, but definitely a few.   Yet it seems folks are not sampling plenty of times when doing one shot.   Why is that?     IMO, seems if you are not chatting, you should be sampling 3 or 5 times at least.   It certainly makes for a slow down, but isn&amp;#39;t quality better?    Furthermore those of us local are often running quantized models, seems we will also need sampling more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mei5ya",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "segmond",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mei5ya/how_many_times_do_you_sample_and_why_not_more/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mei5ya/how_many_times_do_you_sample_and_why_not_more/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754007886,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "ðŸš€ Qwen3-30B-A3B-Thinking-2507, a medium-size model that can think!\n\nâ€¢ Nice performance on reasoning tasks, including math, science, code &amp; beyond\nâ€¢ Good at tool use, competitive with larger models\nâ€¢ Native support of 256K-token context, extendable to 1M\n\nHugging Face: https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507\n\nModel scope: https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507/summary\n\n",
          "author_fullname": "t2_c705ri9b",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "ðŸš€ Qwen3-30B-A3B-Thinking-2507",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md8t1g",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "ups": 460,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 460,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/tVtfQoQDTlQ6Uwov__WCY7dUkYJPJUXsM9RBMIH7y1A.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753887447,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ðŸš€ Qwen3-30B-A3B-Thinking-2507, a medium-size model that can think!&lt;/p&gt;\n\n&lt;p&gt;â€¢ Nice performance on reasoning tasks, including math, science, code &amp;amp; beyond\nâ€¢ Good at tool use, competitive with larger models\nâ€¢ Native support of 256K-token context, extendable to 1M&lt;/p&gt;\n\n&lt;p&gt;Hugging Face: &lt;a href=\"https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Model scope: &lt;a href=\"https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507/summary\"&gt;https://modelscope.cn/models/Qwen/Qwen3-30B-A3B-Thinking-2507/summary&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/eaag1cpuz0gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?auto=webp&amp;s=4d8631bddb808ba5ba33923e39969f3d5ce975a0",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54819af8a9dcb09081d8f071202286c39fa8b783",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ce4a1e6aa0c36ba666c48a92f9aa64aacb1dd4d",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3e49c0310ba44d98f4d430bae3d2c168d9186be2",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e073b4b20cd702585ec6bbac8fc80938677c24f8",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee1be3a32bb3fc836c4cfc180295aebaea49bac7",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://preview.redd.it/eaag1cpuz0gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ddef9a3b199d455271a7f4ee7e22b31ed457318",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "zrXiZ6McKvxSbb3fLQK6d19Ut_u3Buzjg1O0DbTod_M"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1md8t1g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ResearchCrafty1804",
          "discussion_type": null,
          "num_comments": 131,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md8t1g/qwen330ba3bthinking2507/",
          "stickied": false,
          "url": "https://i.redd.it/eaag1cpuz0gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753887447,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "On par with qwen3-235b?",
          "author_fullname": "t2_14xb45",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3-30b-a3b-thinking-2507 This is insane performance",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md8slx",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.98,
          "author_flair_background_color": null,
          "ups": 462,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 462,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=0cf90a8010053dbf48911257591f71a3d1ddded7",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753887417,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On par with qwen3-235b?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?auto=webp&amp;s=a67dbb1b6fae4b63d82563a3e65a19938ca062fb",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e994b63235f1f31da964f24b3a55a51498b6935f",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7aa24107465ba0cfb16f79135e2c61bc02b91707",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=95124de9bda6db677aaa373721a3aa188cc7f224",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd872c4c3958b52ad860a6db5ba53994da65552e",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3213439d0e68cbadd20dbb4d235a121e1df48f64",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b13bc1d8de32bb083d7b376a591f00d85d3173aa",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1md8slx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "3oclockam",
          "discussion_type": null,
          "num_comments": 105,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md8slx/qwen330ba3bthinking2507_this_is_insane_performance/",
          "stickied": false,
          "url": "https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507",
          "subreddit_subscribers": 507935,
          "created_utc": 1753887417,
          "num_crossposts": 2,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "# How I Got claude-code to Work with a Local LLM (via LM Studio) Using a Custom Proxy\n\nHey everyone,\n\nI wanted to share a little setup I put together. I was trying to run `claude-code` with a locally hosted model, `glm-4.5-air`, through **LM Studio on my Mac**.\n\nI ran into some issues, so I quickly whipped up a proxy server to get it working. Here's the basic breakdown of the components:\n\n1. `claude-code`: The base agent.\n2. `claude-code-router`: You need to configure this to use external (non-Anthropic) APIs.\n3. **My Custom Proxy Server**: This sits in the middle to modify the LLM requests on the fly. (proxy fix tool-use issue on the fly!)\n4. LM studio : to run GLM-4.5-Air model.\n\nThe proxy server is the crucial part of this setup. It intercepts and alters the LLM requests in real-time. For it to work, it had to meet a few key requirements:\n\n* It must handle both **streaming and non-streaming** responses. (claude-code use streamming!)\n* It needs to safely process **UTF-8 characters and byte streams** to prevent issues during streaming.\n* It has to **normalize non-standard tool outputs** into the correct, standardized format.\n* It must maintain a **stable connection** for streaming sessions.\n* It should be **extensible** to support various types of tool outputs in the future.\n\nAnyway, even though I just quickly put this together, it works surprisingly well, so I figured I'd share the idea with you all.\n\nMy Proxy code is here //  \n[https://github.com/ziozzang/llm-toolcall-proxy](https://github.com/ziozzang/llm-toolcall-proxy)",
          "author_fullname": "t2_5409gkc6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "works well!: GLM 4.5 air (MLX) - LM studio (Mac) - Claude code",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdqj9g",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.9,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 48,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 48,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1753932296,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753931031,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;How I Got claude-code to Work with a Local LLM (via LM Studio) Using a Custom Proxy&lt;/h1&gt;\n\n&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a little setup I put together. I was trying to run &lt;code&gt;claude-code&lt;/code&gt; with a locally hosted model, &lt;code&gt;glm-4.5-air&lt;/code&gt;, through &lt;strong&gt;LM Studio on my Mac&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I ran into some issues, so I quickly whipped up a proxy server to get it working. Here&amp;#39;s the basic breakdown of the components:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;code&gt;claude-code&lt;/code&gt;: The base agent.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;claude-code-router&lt;/code&gt;: You need to configure this to use external (non-Anthropic) APIs.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;My Custom Proxy Server&lt;/strong&gt;: This sits in the middle to modify the LLM requests on the fly. (proxy fix tool-use issue on the fly!)&lt;/li&gt;\n&lt;li&gt;LM studio : to run GLM-4.5-Air model.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The proxy server is the crucial part of this setup. It intercepts and alters the LLM requests in real-time. For it to work, it had to meet a few key requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It must handle both &lt;strong&gt;streaming and non-streaming&lt;/strong&gt; responses. (claude-code use streamming!)&lt;/li&gt;\n&lt;li&gt;It needs to safely process &lt;strong&gt;UTF-8 characters and byte streams&lt;/strong&gt; to prevent issues during streaming.&lt;/li&gt;\n&lt;li&gt;It has to &lt;strong&gt;normalize non-standard tool outputs&lt;/strong&gt; into the correct, standardized format.&lt;/li&gt;\n&lt;li&gt;It must maintain a &lt;strong&gt;stable connection&lt;/strong&gt; for streaming sessions.&lt;/li&gt;\n&lt;li&gt;It should be &lt;strong&gt;extensible&lt;/strong&gt; to support various types of tool outputs in the future.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyway, even though I just quickly put this together, it works surprisingly well, so I figured I&amp;#39;d share the idea with you all.&lt;/p&gt;\n\n&lt;p&gt;My Proxy code is here //&lt;br/&gt;\n&lt;a href=\"https://github.com/ziozzang/llm-toolcall-proxy\"&gt;https://github.com/ziozzang/llm-toolcall-proxy&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?auto=webp&amp;s=48cf4f8b4cd91a039f48e52ee654b41f931fbae4",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cef3d87e86e676c2dd97e4c186c290a3a30d01ec",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=414ffa8e4c30a2db5296a7ec3c64e93841ac33b0",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=13fd4de47aca251e59ff4657cde1b0d0793f83e2",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8206d3628b7a8ed14b36f011d84164477dd4e9b",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c050975982f818e8b8823fe33a53eecb50a92495",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=afc8a54aeefd64a510f70951f6f71f500183f73f",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "TxoyzwOuovAjomlGsEp03rYjsFxL0tZoKO1Cb4HESDw"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mdqj9g",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ziozzang0",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdqj9g/works_well_glm_45_air_mlx_lm_studio_mac_claude/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdqj9g/works_well_glm_45_air_mlx_lm_studio_mac_claude/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753931031,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I'm getting totally lost and overwhelmed in the research and possible options, always changing and hard to keep up with.   \n  \nLooking for free or open-source tools that can do two things:\n\n1. **Voice cloning with text-to-speech** â€“  found [this post](https://www.reddit.com/r/LocalLLaMA/comments/1f0awd6/best_local_open_source_texttospeech_and/) particularly helpful, but wondering if thereâ€™s now a clearer top 1â€“3 options that are reliable, popular, and beginner-friendly. Ideally something simple to set up without advanced system requirements.\n2. **Voice-preserving translation** â€“ Either from text or cloned audio, I need it translated to another language while keeping the same cloned voice.\n\nAny guidance is greatly appreciated!",
          "author_fullname": "t2_5drne9pw",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Open source TTS w/voice cloning and multilingual translation?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1meho6b",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754006534,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting totally lost and overwhelmed in the research and possible options, always changing and hard to keep up with.   &lt;/p&gt;\n\n&lt;p&gt;Looking for free or open-source tools that can do two things:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Voice cloning with text-to-speech&lt;/strong&gt; â€“  found &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1f0awd6/best_local_open_source_texttospeech_and/\"&gt;this post&lt;/a&gt; particularly helpful, but wondering if thereâ€™s now a clearer top 1â€“3 options that are reliable, popular, and beginner-friendly. Ideally something simple to set up without advanced system requirements.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Voice-preserving translation&lt;/strong&gt; â€“ Either from text or cloned audio, I need it translated to another language while keeping the same cloned voice.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any guidance is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1meho6b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "smoreofnothing22",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meho6b/open_source_tts_wvoice_cloning_and_multilingual/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meho6b/open_source_tts_wvoice_cloning_and_multilingual/",
          "subreddit_subscribers": 507935,
          "created_utc": 1754006534,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "============================================================\nBENCHMARK SUMMARY\n============================================================\nTotal runs: 100\nSuccessful runs: 99\nSuccess rate: 99.0%\n\nTotal benchmark duration: 836.54s\nAverage time per request (wall clock): 8.37s\n\nOverall Performance:\n  Average total time per request: 353.30s\n  Average tokens generated: 5404\n  Average throughput: 15.3 tokens/s\n\nDuration Percentiles (per request):\n  p50_duration: 355.06s\n  p90_duration: 385.15s\n  p95_duration: 390.57s\n  p99_duration: 398.91s\n\nStage Performance:\n\n  Intent To Research:\n    Avg duration: 34.71s\n    Avg tokens/s: 18.9\n    Range: 16.5 - 21.2 tokens/s\n\n  Research To Toc:\n    Avg duration: 95.21s\n    Avg tokens/s: 15.1\n    Range: 12.9 - 16.9 tokens/s\n\n  Toc To Content:\n    Avg duration: 223.37s\n    Avg tokens/s: 14.8\n    Range: 12.1 - 20.0 tokens/s\n\nConcurrent Request Timing:\n  Min request time: 298.07s\n  Max request time: 399.83s\n  Avg request time: 353.30s\n  Total throughput: 639.5 tokens/s",
          "author_fullname": "t2_pmniwf57y",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "100 E-books in 15 min | vLLM, A6000, around 1k output tokens/s with 100 concurrent requests Qwen3-30B-A3B-Instruct-2507",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 83,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mehark",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/rqg9m9wVFsbh2P-GvUDM2HRA-KotckWyreZRBWb3By0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754005539,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;&lt;/h1&gt;\n\n&lt;h1&gt;BENCHMARK SUMMARY&lt;/h1&gt;\n\n&lt;p&gt;Total runs: 100\nSuccessful runs: 99\nSuccess rate: 99.0%&lt;/p&gt;\n\n&lt;p&gt;Total benchmark duration: 836.54s\nAverage time per request (wall clock): 8.37s&lt;/p&gt;\n\n&lt;p&gt;Overall Performance:\n  Average total time per request: 353.30s\n  Average tokens generated: 5404\n  Average throughput: 15.3 tokens/s&lt;/p&gt;\n\n&lt;p&gt;Duration Percentiles (per request):\n  p50_duration: 355.06s\n  p90_duration: 385.15s\n  p95_duration: 390.57s\n  p99_duration: 398.91s&lt;/p&gt;\n\n&lt;p&gt;Stage Performance:&lt;/p&gt;\n\n&lt;p&gt;Intent To Research:\n    Avg duration: 34.71s\n    Avg tokens/s: 18.9\n    Range: 16.5 - 21.2 tokens/s&lt;/p&gt;\n\n&lt;p&gt;Research To Toc:\n    Avg duration: 95.21s\n    Avg tokens/s: 15.1\n    Range: 12.9 - 16.9 tokens/s&lt;/p&gt;\n\n&lt;p&gt;Toc To Content:\n    Avg duration: 223.37s\n    Avg tokens/s: 14.8\n    Range: 12.1 - 20.0 tokens/s&lt;/p&gt;\n\n&lt;p&gt;Concurrent Request Timing:\n  Min request time: 298.07s\n  Max request time: 399.83s\n  Avg request time: 353.30s\n  Total throughput: 639.5 tokens/s&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ld339ymaqagf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ld339ymaqagf1.png?auto=webp&amp;s=96adcc3e2338b536647cdcc08d9d4433dad965c2",
                  "width": 5970,
                  "height": 3543
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=36ccfa946681a8390063a2e5cf969069b903d880",
                    "width": 108,
                    "height": 64
                  },
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5b694f417700721771c559fae592d1d8f9da2ab",
                    "width": 216,
                    "height": 128
                  },
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4089cf716e3d5f1b831df69c4d05ff6c9ca5a4b7",
                    "width": 320,
                    "height": 189
                  },
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=03cb5d3f0b223e333d0d56a150b6d0badefc0fa3",
                    "width": 640,
                    "height": 379
                  },
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1fbf2d3cc8717129ceec6d6f235a08db5917593d",
                    "width": 960,
                    "height": 569
                  },
                  {
                    "url": "https://preview.redd.it/ld339ymaqagf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=627baf1e9e9a853b89ca7b46743899afb6d39b6e",
                    "width": 1080,
                    "height": 640
                  }
                ],
                "variants": {},
                "id": "Luw9MbT80ezr1bfwXisjeh7RWrpXNOqoWppdEv_rD2o"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mehark",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "secopsml",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mehark/100_ebooks_in_15_min_vllm_a6000_around_1k_output/",
          "stickied": false,
          "url": "https://i.redd.it/ld339ymaqagf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1754005539,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Big shout out to ikawrakow and his [https://github.com/ikawrakow/ik\\_llama.cpp](https://github.com/ikawrakow/ik_llama.cpp) for making my hardware relevant (and obviously Qwen team!) :)\n\nLooking forward to trying Thinker and Coder versions of this architecture\n\nhttps://preview.redd.it/9xttfh3026gf1.png?width=2216&amp;format=png&amp;auto=webp&amp;s=cc6e39266d0a94beb5dca73650dab93021bb7d32\n\nHardware: AMD Ryzen 9 8945HS(8C/16T, up to 5.2GHz) 64GB DDR5 1TB PCIe4.0 SSD, running in Ubuntu distrobox with Fedora Bluefin as a host. Also have eGPU with RTX 3060 12GB, but it was not used in benchmark.\n\nI tried CPU + CUDA separately - and the prompt processing speed would take a significant hit (many memory trips I guess). I did try to use the \"-ot exps\" trick to ensure correct layer split - but I think it is expected, as this is the cost of offloading.\n\n-fa -rtr -fmoe made prompt processing around 20-25% faster.\n\nModels of this architecture are very snappy in CPU mode, especially on smaller prompts - good feature for daily driver model. With longer contexts, processing speed drops significantly, so will require orchestration / workflows to prevent context from blowing up.\n\nVibes-wise, this model feels strong for something that runs on \"consumer\" hardware at these speeds.\n\n**What was tested:**\n\n1. General conversations - good enough, but to be honest almost every 4B+ model feels like an ok conversationalist - what a time to be alive, no?\n2. Code doc summarization: good. I fed it 16k-30k documents and while the speed was slow, the overall result was decent.\n3. Retrieval: gave it \\~10k tokens worth of logs and asked some questions about data that appeared in the logs - mostly good, but I would not call it laser-good.\n4. Coding + Tool calling in Zed  editor- it is obviously not Sonnet or GPT 4.1, but it really tries! I think with better prompting / fine-tuning it would crack it  - perhaps it's seen different tools during original training.\n\n**Can I squeeze more?:**\n\n1. Better use for GPU?\n2. Try other quants: there was a plethora of quants added in recent weeks - perhaps there is one that will push these numbers a little up.\n3. Try [https://github.com/kvcache-ai/ktransformers](https://github.com/kvcache-ai/ktransformers) \\- they are known for optimized configs to run on RAM + relatively low amount of VRAM - but I failed to make it work locally and didn't find an up-to-date docker image either. I would imagine it's not gonna yield significant improvements, but happy to be proven wrong.\n4. IGPU + Vulcan?\n5. NPU xD\n6. Test full context (or the largest context that does not take eternity to process)\n\nWhat's your experience / recipe for similarly-sized hardware setup?",
          "author_fullname": "t2_9f1c1mb6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "ik_llama.cpp and Qwen 3 30B-A3B architecture.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "9xttfh3026gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 8,
                  "x": 108,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=64da390049462da724ef33b554e35e5af910f2fc"
                },
                {
                  "y": 17,
                  "x": 216,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4fa51266266dc0617403d5b159742a96b76aeb4e"
                },
                {
                  "y": 26,
                  "x": 320,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a810e197bb579a53a220784638351bfab4c404e8"
                },
                {
                  "y": 53,
                  "x": 640,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b383e5850d9f6460d0d78005d33a16b6eb83ca7e"
                },
                {
                  "y": 79,
                  "x": 960,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cad82ae247fac266e089462ff653d2dbe54aad89"
                },
                {
                  "y": 89,
                  "x": 1080,
                  "u": "https://preview.redd.it/9xttfh3026gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6b0837b8dab1247af048324a0e4443983bc57010"
                }
              ],
              "s": {
                "y": 184,
                "x": 2216,
                "u": "https://preview.redd.it/9xttfh3026gf1.png?width=2216&amp;format=png&amp;auto=webp&amp;s=cc6e39266d0a94beb5dca73650dab93021bb7d32"
              },
              "id": "9xttfh3026gf1"
            }
          },
          "name": "t3_1mdvkhz",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.86,
          "author_flair_background_color": null,
          "ups": 18,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 18,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=4979726165f841523ca44a3f838520e194c3a3f3",
          "edited": 1753949561,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1753948642,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Big shout out to ikawrakow and his &lt;a href=\"https://github.com/ikawrakow/ik_llama.cpp\"&gt;https://github.com/ikawrakow/ik_llama.cpp&lt;/a&gt; for making my hardware relevant (and obviously Qwen team!) :)&lt;/p&gt;\n\n&lt;p&gt;Looking forward to trying Thinker and Coder versions of this architecture&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9xttfh3026gf1.png?width=2216&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc6e39266d0a94beb5dca73650dab93021bb7d32\"&gt;https://preview.redd.it/9xttfh3026gf1.png?width=2216&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cc6e39266d0a94beb5dca73650dab93021bb7d32&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hardware: AMD Ryzen 9 8945HS(8C/16T, up to 5.2GHz) 64GB DDR5 1TB PCIe4.0 SSD, running in Ubuntu distrobox with Fedora Bluefin as a host. Also have eGPU with RTX 3060 12GB, but it was not used in benchmark.&lt;/p&gt;\n\n&lt;p&gt;I tried CPU + CUDA separately - and the prompt processing speed would take a significant hit (many memory trips I guess). I did try to use the &amp;quot;-ot exps&amp;quot; trick to ensure correct layer split - but I think it is expected, as this is the cost of offloading.&lt;/p&gt;\n\n&lt;p&gt;-fa -rtr -fmoe made prompt processing around 20-25% faster.&lt;/p&gt;\n\n&lt;p&gt;Models of this architecture are very snappy in CPU mode, especially on smaller prompts - good feature for daily driver model. With longer contexts, processing speed drops significantly, so will require orchestration / workflows to prevent context from blowing up.&lt;/p&gt;\n\n&lt;p&gt;Vibes-wise, this model feels strong for something that runs on &amp;quot;consumer&amp;quot; hardware at these speeds.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What was tested:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;General conversations - good enough, but to be honest almost every 4B+ model feels like an ok conversationalist - what a time to be alive, no?&lt;/li&gt;\n&lt;li&gt;Code doc summarization: good. I fed it 16k-30k documents and while the speed was slow, the overall result was decent.&lt;/li&gt;\n&lt;li&gt;Retrieval: gave it ~10k tokens worth of logs and asked some questions about data that appeared in the logs - mostly good, but I would not call it laser-good.&lt;/li&gt;\n&lt;li&gt;Coding + Tool calling in Zed  editor- it is obviously not Sonnet or GPT 4.1, but it really tries! I think with better prompting / fine-tuning it would crack it  - perhaps it&amp;#39;s seen different tools during original training.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Can I squeeze more?:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Better use for GPU?&lt;/li&gt;\n&lt;li&gt;Try other quants: there was a plethora of quants added in recent weeks - perhaps there is one that will push these numbers a little up.&lt;/li&gt;\n&lt;li&gt;Try &lt;a href=\"https://github.com/kvcache-ai/ktransformers\"&gt;https://github.com/kvcache-ai/ktransformers&lt;/a&gt; - they are known for optimized configs to run on RAM + relatively low amount of VRAM - but I failed to make it work locally and didn&amp;#39;t find an up-to-date docker image either. I would imagine it&amp;#39;s not gonna yield significant improvements, but happy to be proven wrong.&lt;/li&gt;\n&lt;li&gt;IGPU + Vulcan?&lt;/li&gt;\n&lt;li&gt;NPU xD&lt;/li&gt;\n&lt;li&gt;Test full context (or the largest context that does not take eternity to process)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What&amp;#39;s your experience / recipe for similarly-sized hardware setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?auto=webp&amp;s=c7c85f2c4c738393e0af92a8424d4f3b9231b100",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e0ca996c64f35d96d82c792f292d1574156f28a8",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=13e828ba3e534b52cb7e76434082e0591ff8fe84",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9beff3bbc086be73ada08d7d9e0be23ce9b4cbec",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a74fa58f6c27cd63b1b4175d767d3aa5e620d4e6",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9a87258e5557a2c94d34ba6aad86a07f7c1180e7",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a48274f527c77b8067ed3f8f078884cca0d1fcc",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "2UbIzGryv92r-OTNNbwj3X7DPvZqNJtHJ_N32Ju1bQs"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdvkhz",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Bycbka",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdvkhz/ik_llamacpp_and_qwen_3_30ba3b_architecture/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdvkhz/ik_llamacpp_and_qwen_3_30ba3b_architecture/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753948642,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_uptissiz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "GLM is way more open about the chinese government than other chinese models.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 43,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "8gted66siagf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 58,
                  "x": 108,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e6af38b6c3ed87b43b9d44a5b74975752d889bc"
                },
                {
                  "y": 116,
                  "x": 216,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b968c3bff08720ab1cd42b4fdde1ee4f88bd98c"
                },
                {
                  "y": 172,
                  "x": 320,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8bf4a15273b92edea0d3782ba90d835ed4a3976"
                },
                {
                  "y": 344,
                  "x": 640,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ed1200ac43bc089fb3c1af06a3f2dd71247ae0e"
                },
                {
                  "y": 516,
                  "x": 960,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bf88471c9ed9f4b751965e899a1b53c148a72eb2"
                },
                {
                  "y": 581,
                  "x": 1080,
                  "u": "https://preview.redd.it/8gted66siagf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d198ce8d0a50ad4d5d8638b6d55f68e50031d50f"
                }
              ],
              "s": {
                "y": 926,
                "x": 1720,
                "u": "https://preview.redd.it/8gted66siagf1.png?width=1720&amp;format=png&amp;auto=webp&amp;s=1e2bc59b85ae80d3674b4526367f6f45be5a5cfd"
              },
              "id": "8gted66siagf1"
            },
            "yhy52h7hiagf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 33,
                  "x": 108,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f392770969bc3d68e9168553d06629df825bbb65"
                },
                {
                  "y": 67,
                  "x": 216,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=61dc33c2afb293de82200cdd698076a82bc46107"
                },
                {
                  "y": 100,
                  "x": 320,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=86366ff4b1825f4b2d9db5ffa6b60b5d16d00fca"
                },
                {
                  "y": 200,
                  "x": 640,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e1695e3d3e9dc9041b0bd4c3c772ea703380dd4"
                },
                {
                  "y": 300,
                  "x": 960,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=03c953dd7f85f8e0a293487d5bbf9184bf752cf1"
                },
                {
                  "y": 337,
                  "x": 1080,
                  "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6d2ef59022c584d20d4f0b022e3f8736462779ad"
                }
              ],
              "s": {
                "y": 464,
                "x": 1484,
                "u": "https://preview.redd.it/yhy52h7hiagf1.png?width=1484&amp;format=png&amp;auto=webp&amp;s=513dadc765a87a6482c6d3e55d7a29e4d02cabfd"
              },
              "id": "yhy52h7hiagf1"
            },
            "pj9s3nduiagf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 56,
                  "x": 108,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2eea13a48c796558b44799c8cec7435230b0c9dc"
                },
                {
                  "y": 112,
                  "x": 216,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=26c0693bd1ea0b1223372ff0d5a39eca8741a93d"
                },
                {
                  "y": 166,
                  "x": 320,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4ac0676c8a09c06058e0bd06443b7ff88f90582"
                },
                {
                  "y": 333,
                  "x": 640,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a2ef686e04eae460ac8962371a5f16784344570"
                },
                {
                  "y": 500,
                  "x": 960,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3653e670faa0eee6c56e06e7f8de51701e7cb0e1"
                },
                {
                  "y": 562,
                  "x": 1080,
                  "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7a4f5224f8e179758ec3c443db5f19103cb0c786"
                }
              ],
              "s": {
                "y": 923,
                "x": 1771,
                "u": "https://preview.redd.it/pj9s3nduiagf1.png?width=1771&amp;format=png&amp;auto=webp&amp;s=93adc80eec7a4073c86bdb245dc2ddba9dc020b4"
              },
              "id": "pj9s3nduiagf1"
            }
          },
          "name": "t3_1meg9k5",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.55,
          "author_flair_background_color": null,
          "ups": 2,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "yhy52h7hiagf1",
                "id": 718431939
              },
              {
                "media_id": "8gted66siagf1",
                "id": 718431940
              },
              {
                "media_id": "pj9s3nduiagf1",
                "id": 718431941
              }
            ]
          },
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/7TW8ZYHty8Bu9LfI2xjxYY1GCF3wcx_oPEe96itJjJA.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754002796,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1meg9k5",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1meg9k5",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Pro-editor-1105",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meg9k5/glm_is_way_more_open_about_the_chinese_government/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1meg9k5",
          "subreddit_subscribers": 507935,
          "created_utc": 1754002796,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Just saw this being announced:\n\nDirect link: https://en.sixunited.com/ZB_deatail/334.html\n\nDo people think it will materialise? Would be a cheaper and more appropriate option than frameworks for those preferring to build their own hardware such as upgrade their ITX NAS.",
          "author_fullname": "t2_4hjtgq5u",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "DIY AI MAX 395+ ITX board?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1meg9cq",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=fc34c34db28613a0234b707a537ebbde92c85488",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754002781,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "tomshardware.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just saw this being announced:&lt;/p&gt;\n\n&lt;p&gt;Direct link: &lt;a href=\"https://en.sixunited.com/ZB_deatail/334.html\"&gt;https://en.sixunited.com/ZB_deatail/334.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do people think it will materialise? Would be a cheaper and more appropriate option than frameworks for those preferring to build their own hardware such as upgrade their ITX NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.tomshardware.com/pc-components/motherboards/amd-strix-halo-mini-itx-motherboard-flaunts-128gb-lpddr5x-add-a-cpu-cooler-boot-drive-and-power-supply-for-a-slim-gaming-or-ai-rig",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?auto=webp&amp;s=46e15e8c39174ef8f181d4c18f0c07519a8c833d",
                  "width": 1200,
                  "height": 674
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2fe3ef3c6034fb4d65cf6c03eb2a579f12191a2",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=152189cbdb74568393b80e4d4e38aaffe6f0fee7",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c878d8f2f91de32bcc5e750294056513f662a7ef",
                    "width": 320,
                    "height": 179
                  },
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=313da53f97cff8b9f18b88aeb5bc93c42d8d85fc",
                    "width": 640,
                    "height": 359
                  },
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=465d6d3c6631368f68e27948edd9d8842fc6c737",
                    "width": 960,
                    "height": 539
                  },
                  {
                    "url": "https://external-preview.redd.it/oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f252911a92d5088c15d6fa12ec0231fac887ef78",
                    "width": 1080,
                    "height": 606
                  }
                ],
                "variants": {},
                "id": "oqIT-G4_oveD59Zww0lHhnIZJCilyHatyz6EbH7XnhU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1meg9cq",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mitchins-au",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meg9cq/diy_ai_max_395_itx_board/",
          "stickied": false,
          "url": "https://www.tomshardware.com/pc-components/motherboards/amd-strix-halo-mini-itx-motherboard-flaunts-128gb-lpddr5x-add-a-cpu-cooler-boot-drive-and-power-supply-for-a-slim-gaming-or-ai-rig",
          "subreddit_subscribers": 507935,
          "created_utc": 1754002781,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4vdsgga6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Vibe coding in prod by Anthropic",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 105,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1meen33",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fHWFF_pnqDk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Vibe coding in prod\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "height": 200
          },
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Vibe coding in prod",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fHWFF_pnqDk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Vibe coding in prod\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Anthropic",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/fHWFF_pnqDk/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@anthropic-ai"
            },
            "type": "youtube.com"
          },
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {
            "content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fHWFF_pnqDk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Vibe coding in prod\"&gt;&lt;/iframe&gt;",
            "width": 356,
            "scrolling": false,
            "media_domain_url": "https://www.redditmedia.com/mediaembed/1meen33",
            "height": 200
          },
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=e3980a1b11ca89379278c2b2b678b90293d179a3",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "rich:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753998700,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "youtu.be",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://youtu.be/fHWFF_pnqDk?si=0b2cr3QYxR4x0Ups",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U.jpeg?auto=webp&amp;s=78db33673badae8db10237e6d51dfaba762d8877",
                  "width": 480,
                  "height": 360
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=439096583487c64bed2d7aa47fb7467544b98f7e",
                    "width": 108,
                    "height": 81
                  },
                  {
                    "url": "https://external-preview.redd.it/u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d0660bd1a71cb8745c6b9fd54da8cf6499b5087",
                    "width": 216,
                    "height": 162
                  },
                  {
                    "url": "https://external-preview.redd.it/u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cdf8c234ee32a08b4a401cd2d286830da036ae61",
                    "width": 320,
                    "height": 240
                  }
                ],
                "variants": {},
                "id": "u-k4ljvDNY76UM3dX9Yb7qhEVOQzhmoT-rA7taL17-U"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1meen33",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "siddhantparadox",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meen33/vibe_coding_in_prod_by_anthropic/",
          "stickied": false,
          "url": "https://youtu.be/fHWFF_pnqDk?si=0b2cr3QYxR4x0Ups",
          "subreddit_subscribers": 507935,
          "created_utc": 1753998700,
          "num_crossposts": 0,
          "media": {
            "oembed": {
              "provider_url": "https://www.youtube.com/",
              "title": "Vibe coding in prod",
              "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fHWFF_pnqDk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen title=\"Vibe coding in prod\"&gt;&lt;/iframe&gt;",
              "thumbnail_width": 480,
              "height": 200,
              "width": 356,
              "version": "1.0",
              "author_name": "Anthropic",
              "provider_name": "YouTube",
              "thumbnail_url": "https://i.ytimg.com/vi/fHWFF_pnqDk/hqdefault.jpg",
              "type": "video",
              "thumbnail_height": 360,
              "author_url": "https://www.youtube.com/@anthropic-ai"
            },
            "type": "youtube.com"
          },
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "So I'm trying to decide between buying a p40 (maybe two) or an rtx 3090. My main purpose is reasoning/coding. I'm on a tighter budget right now since i have to buy the whole pc rig, and the P40 is just so much cheaper than the 3090.  \n  \nBasically would a P40 really suffice for heavy reasoning and coding or should i just shell out the 3090? ",
          "author_fullname": "t2_f1c9sqdsd",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is it worth buying a 3090 over a P40 in my case?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me44qm",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753974568,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m trying to decide between buying a p40 (maybe two) or an rtx 3090. My main purpose is reasoning/coding. I&amp;#39;m on a tighter budget right now since i have to buy the whole pc rig, and the P40 is just so much cheaper than the 3090.  &lt;/p&gt;\n\n&lt;p&gt;Basically would a P40 really suffice for heavy reasoning and coding or should i just shell out the 3090? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me44qm",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "More_Indication_3439",
          "discussion_type": null,
          "num_comments": 11,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me44qm/is_it_worth_buying_a_3090_over_a_p40_in_my_case/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me44qm/is_it_worth_buying_a_3090_over_a_p40_in_my_case/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753974568,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_58t8ty6v",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Which way modern man?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 103,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me7jed",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.57,
          "author_flair_background_color": null,
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/NUw2rTsohcBVjNShRmomrIUdCW4aNODmBXC7m_JF9l0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753982288,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/pfai2rzst8gf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/pfai2rzst8gf1.png?auto=webp&amp;s=6d9556c6ee60eb284c0e609bccbe7dd70808490b",
                  "width": 1724,
                  "height": 1280
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddde2863d577a8a0993b6ad7626065a6df783440",
                    "width": 108,
                    "height": 80
                  },
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3ecfb0f4cebd4e3d3ab00fde668e5b06138a79d",
                    "width": 216,
                    "height": 160
                  },
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=600b9eb1bfa4832b70aa63908588e6dbff84ed8d",
                    "width": 320,
                    "height": 237
                  },
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=54fd4436bc26e0b88c9d0f9f89d873e57a1a9677",
                    "width": 640,
                    "height": 475
                  },
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2770332b3e405c45d6c1ff53813f4af82f2f4a9",
                    "width": 960,
                    "height": 712
                  },
                  {
                    "url": "https://preview.redd.it/pfai2rzst8gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a5af152c38e1bccb085e474a7a7374cb13fae791",
                    "width": 1080,
                    "height": 801
                  }
                ],
                "variants": {},
                "id": "p_YkYPdEBKwqTMAiAoKFv6AZbymjEYUHIgDwFF8enJ8"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1me7jed",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "BoJackHorseMan53",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me7jed/which_way_modern_man/",
          "stickied": false,
          "url": "https://i.redd.it/pfai2rzst8gf1.png",
          "subreddit_subscribers": 507935,
          "created_utc": 1753982288,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Iâ€™m running OpenWebUI with an Ollama-backed instance ofÂ `Qwen3-30B-A3B-Thinking-2507`Â (just tried the Instruct as well, and ran into the same issue) and running into a frustrating behavior Iâ€™m hoping others have seen (or solved).\n\nHereâ€™s the pattern:\n\n1. I give the model a clear task, for example: â€œPlan a fun day in Washington DC on August 23rd using real events happening that day.â€\n2. The model correctly identifies that it needs to use aÂ `search_web`Â tool (I have this hooked up with SearxNG).\n3. It performs the search and gets HTML content or page summaries back (looks like it's scraping from a site like Washington.org).\n4. Then it completely loses the plot. Instead of using the tool result to fulfill my original request (planning the day), it treats the result as if I had asked it to summarize that page, and shifts focus entirely. It never returns to the original task.\n\nIâ€™ve tried:\n\n* A very explicit system prompt that tells the model to keep the userâ€™s goal in mind and never treat tool results as new input unless instructed.\n* Adding scratchpad-style reminders like â€œYour job is still toâ€¦â€ before and after tool calls.\n* Swapping out phrasing in the user prompt.\n* Checking for context length issues (not the problem, chats are short).\n\nStill broken. It seems like the model is either:\n\n* Failing to persist intent across tool usage (tool output is overriding memory), or\n* Treating the tool result as if it's coming from me, not as intermediate output.\n\nAnyone else run into this?  \nIs this:\n\n* A quirk of Qwen 30B (tool-use behavior too shallow)?\n* A bug in how OpenWebUI or Ollama routes tool results (e.g., injecting them as raw user-like messages)?\n* Something else?\n\nWould love to know:\n\n* Which models youâ€™ve had better luck with in tool-following or goal persistence\n* Any workarounds youâ€™ve used (prompt engineering, framework config, scratchpad logic, etc.)",
          "author_fullname": "t2_egd5l",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Has anyone else seen LLMs lose context after a tool call in OpenWebUI? (Using Qwen 30B)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me713k",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753981142,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Iâ€™m running OpenWebUI with an Ollama-backed instance ofÂ &lt;code&gt;Qwen3-30B-A3B-Thinking-2507&lt;/code&gt;Â (just tried the Instruct as well, and ran into the same issue) and running into a frustrating behavior Iâ€™m hoping others have seen (or solved).&lt;/p&gt;\n\n&lt;p&gt;Hereâ€™s the pattern:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I give the model a clear task, for example: â€œPlan a fun day in Washington DC on August 23rd using real events happening that day.â€&lt;/li&gt;\n&lt;li&gt;The model correctly identifies that it needs to use aÂ &lt;code&gt;search_web&lt;/code&gt;Â tool (I have this hooked up with SearxNG).&lt;/li&gt;\n&lt;li&gt;It performs the search and gets HTML content or page summaries back (looks like it&amp;#39;s scraping from a site like Washington.org).&lt;/li&gt;\n&lt;li&gt;Then it completely loses the plot. Instead of using the tool result to fulfill my original request (planning the day), it treats the result as if I had asked it to summarize that page, and shifts focus entirely. It never returns to the original task.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Iâ€™ve tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A very explicit system prompt that tells the model to keep the userâ€™s goal in mind and never treat tool results as new input unless instructed.&lt;/li&gt;\n&lt;li&gt;Adding scratchpad-style reminders like â€œYour job is still toâ€¦â€ before and after tool calls.&lt;/li&gt;\n&lt;li&gt;Swapping out phrasing in the user prompt.&lt;/li&gt;\n&lt;li&gt;Checking for context length issues (not the problem, chats are short).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Still broken. It seems like the model is either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Failing to persist intent across tool usage (tool output is overriding memory), or&lt;/li&gt;\n&lt;li&gt;Treating the tool result as if it&amp;#39;s coming from me, not as intermediate output.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyone else run into this?&lt;br/&gt;\nIs this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A quirk of Qwen 30B (tool-use behavior too shallow)?&lt;/li&gt;\n&lt;li&gt;A bug in how OpenWebUI or Ollama routes tool results (e.g., injecting them as raw user-like messages)?&lt;/li&gt;\n&lt;li&gt;Something else?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would love to know:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Which models youâ€™ve had better luck with in tool-following or goal persistence&lt;/li&gt;\n&lt;li&gt;Any workarounds youâ€™ve used (prompt engineering, framework config, scratchpad logic, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me713k",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DVoltaire",
          "discussion_type": null,
          "num_comments": 12,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me713k/has_anyone_else_seen_llms_lose_context_after_a/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me713k/has_anyone_else_seen_llms_lose_context_after_a/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753981142,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I tested Kimi K2 again, against Claude 4 Sonnet (Sonnet 4) this time, here are my findings (vid in comments):\n\n\\- K2 isn't only less reliable in VSCode tool calling, it's considerably less in Cline as well, vs Claude 4 Sonnet\n\n\\- I integrated K2 via OpenRouter inference into my own application LIVE and it did the same thing: instead of calling tools, it outputs the tool calls as text, mostly malformed and consolidated\n\n\\- Ref: https://youtu.be/p2LKJo3EK7w\n\n\\- Tip for AI coding agent authors: write a parser or a specialized prompt for Kimi K2 - even if it sounds like coupling, the value for money is well worth it\n\n\\- The \"Agent Benchmarks\" are definitely not accurate, Sonnet 4 is NATIVELY much better in almost every AI Coding tool\n\n\\- I'm still going to test K2 in Qwen Coder and maybe a custom coding tool, but it's a very good coder\n\n\\- K2 is better than Gemini 2.5 Pro in tool calling, according to me\n\n\\- Currently, the best implementation of K2 I found is in Windsurf (I tested VSCode, Cline, Windsurf and RooCode)",
          "author_fullname": "t2_qmg9qzxv",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Kimi K2 vs Claude 4 Sonnet - Unexpected Review Result (400k token Codebase)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdldom",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 47,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 47,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1753917735,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753916600,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tested Kimi K2 again, against Claude 4 Sonnet (Sonnet 4) this time, here are my findings (vid in comments):&lt;/p&gt;\n\n&lt;p&gt;- K2 isn&amp;#39;t only less reliable in VSCode tool calling, it&amp;#39;s considerably less in Cline as well, vs Claude 4 Sonnet&lt;/p&gt;\n\n&lt;p&gt;- I integrated K2 via OpenRouter inference into my own application LIVE and it did the same thing: instead of calling tools, it outputs the tool calls as text, mostly malformed and consolidated&lt;/p&gt;\n\n&lt;p&gt;- Ref: &lt;a href=\"https://youtu.be/p2LKJo3EK7w\"&gt;https://youtu.be/p2LKJo3EK7w&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- Tip for AI coding agent authors: write a parser or a specialized prompt for Kimi K2 - even if it sounds like coupling, the value for money is well worth it&lt;/p&gt;\n\n&lt;p&gt;- The &amp;quot;Agent Benchmarks&amp;quot; are definitely not accurate, Sonnet 4 is NATIVELY much better in almost every AI Coding tool&lt;/p&gt;\n\n&lt;p&gt;- I&amp;#39;m still going to test K2 in Qwen Coder and maybe a custom coding tool, but it&amp;#39;s a very good coder&lt;/p&gt;\n\n&lt;p&gt;- K2 is better than Gemini 2.5 Pro in tool calling, according to me&lt;/p&gt;\n\n&lt;p&gt;- Currently, the best implementation of K2 I found is in Windsurf (I tested VSCode, Cline, Windsurf and RooCode)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/dv_I54LGpmnqKoSxBiYuiXlgStoZanHgVx1garYxUvY.jpeg?auto=webp&amp;s=11bec68bd838fee596608741fbde78e3db0d944d",
                  "width": 480,
                  "height": 360
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/dv_I54LGpmnqKoSxBiYuiXlgStoZanHgVx1garYxUvY.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99ec0a4d4a5f8c158298ac9030280b7e7f862186",
                    "width": 108,
                    "height": 81
                  },
                  {
                    "url": "https://external-preview.redd.it/dv_I54LGpmnqKoSxBiYuiXlgStoZanHgVx1garYxUvY.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5448b8e94bb3b9888db22b5f14d5d69a98c2166f",
                    "width": 216,
                    "height": 162
                  },
                  {
                    "url": "https://external-preview.redd.it/dv_I54LGpmnqKoSxBiYuiXlgStoZanHgVx1garYxUvY.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0abae9296465ccacf76ef8025a7481d0c079eb5",
                    "width": 320,
                    "height": 240
                  }
                ],
                "variants": {},
                "id": "dv_I54LGpmnqKoSxBiYuiXlgStoZanHgVx1garYxUvY"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mdldom",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "marvijo-software",
          "discussion_type": null,
          "num_comments": 42,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdldom/kimi_k2_vs_claude_4_sonnet_unexpected_review/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdldom/kimi_k2_vs_claude_4_sonnet_unexpected_review/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753916600,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Heya /r/LocalLLaMA , I read a lot of posts of people describing the components they are using to build custom desktops but I am not interested in manually building a PC.  \n\nIs there a site/company that sells LLM capable desktops that will run qwen/deepseek/etc where we can just buy?",
          "author_fullname": "t2_3gkl5",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What are some good sites to buy a LLM capable desktop",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mebzvo",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753992481,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya &lt;a href=\"/r/LocalLLaMA\"&gt;/r/LocalLLaMA&lt;/a&gt; , I read a lot of posts of people describing the components they are using to build custom desktops but I am not interested in manually building a PC.  &lt;/p&gt;\n\n&lt;p&gt;Is there a site/company that sells LLM capable desktops that will run qwen/deepseek/etc where we can just buy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mebzvo",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ecret",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mebzvo/what_are_some_good_sites_to_buy_a_llm_capable/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mebzvo/what_are_some_good_sites_to_buy_a_llm_capable/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753992481,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I'm interested in buying a new laptop and would like it to be capable of running reasonably strong LLMs. I was considering a fully-upgraded Razer Blade 16, but someone else recommended the MacBookÂ Pro M4 Max. I'd say my max budget is $8,000, but I'd still prefer to be cheaper than that. What would you guys suggest for laptops? Do any of you have experience running local models on a laptop?",
          "author_fullname": "t2_2s17194y",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Laptop Recommendations?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mebifn",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.4,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753991366,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in buying a new laptop and would like it to be capable of running reasonably strong LLMs. I was considering a fully-upgraded Razer Blade 16, but someone else recommended the MacBookÂ Pro M4 Max. I&amp;#39;d say my max budget is $8,000, but I&amp;#39;d still prefer to be cheaper than that. What would you guys suggest for laptops? Do any of you have experience running local models on a laptop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mebifn",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "PlasticSoldier2018",
          "discussion_type": null,
          "num_comments": 12,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mebifn/laptop_recommendations/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mebifn/laptop_recommendations/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753991366,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4a870z4c",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ollama 0.10 - New app is available for macOS and Windows plus multi-GPU performance improvements, and more",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdq3sv",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.65,
          "author_flair_background_color": null,
          "ups": 23,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 23,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=20e99ec07b36d747b3440811e17c10dba287690f",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753929783,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/ollama/ollama/releases/tag/v0.10.0",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?auto=webp&amp;s=4414180b29c1502f7a961f72f4acf79a19d2f36d",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b8de8b6845c7bac03a11d66156a8e9be1f7345d",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3bc7376589ceca9d7e93370a45c358f7eab1f84f",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1af803b3994bb9be0ff405f4af34a0fed0cc23c7",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d42b6edc645f624b40e5a4c076cb7f9f25ed0e3f",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4acbe20abd4a35fea219bcad4b0fddb4607349c3",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1cd4439fbb58b0138e945a259463102137056525",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "8CQoAySJDDT43ePa2z6wKZ6f67awzR1xeHnq-ctSP9Q"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mdq3sv",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mj3815",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdq3sv/ollama_010_new_app_is_available_for_macos_and/",
          "stickied": false,
          "url": "https://github.com/ollama/ollama/releases/tag/v0.10.0",
          "subreddit_subscribers": 507935,
          "created_utc": 1753929783,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I got my hands on M1 Max MacBook Pro 64Gb RAM 1Tb SSD. \nCan someone suggest me how should i proceed?",
          "author_fullname": "t2_12609wntbf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Suggest models for local computer use agent",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1meadtx",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.33,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753988766,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got my hands on M1 Max MacBook Pro 64Gb RAM 1Tb SSD. \nCan someone suggest me how should i proceed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1meadtx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Haunting_Stomach8967",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1meadtx/suggest_models_for_local_computer_use_agent/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meadtx/suggest_models_for_local_computer_use_agent/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753988766,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I made a major update to deep drone, so it now is a CLI agent that controls your drone. It can use models with an api key and also use Ollama. Here is the demo below. And the source code : [https://github.com/evangelosmeklis/deepdrone](https://github.com/evangelosmeklis/deepdrone)\n\nhttps://reddit.com/link/1mdxihp/video/0ejlwqoln6gf1/player\n\n",
          "author_fullname": "t2_3067wthh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "DeepDrone, an open source CLI agent like Claude Code to fly your drone",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "0ejlwqoln6gf1": {
              "status": "valid",
              "e": "RedditVideo",
              "dashUrl": "https://v.redd.it/link/1mdxihp/asset/0ejlwqoln6gf1/DASHPlaylist.mpd?a=1756603209%2CZTc4NGIzNTIwM2I2ZjFiN2Y5Y2I4MTEzMDZmNGZiOTEyNWQyOWRhN2Y2MjRkMjRjODkzMjhmZjM0OGZlYTY2YQ%3D%3D&amp;v=1&amp;f=sd",
              "x": 1920,
              "y": 562,
              "hlsUrl": "https://v.redd.it/link/1mdxihp/asset/0ejlwqoln6gf1/HLSPlaylist.m3u8?a=1756603209%2COGRkMjZlNWFjOGZiNzg4YzE2OWY4ZWU2MzUzZmZiYTViYTAxY2E1MzZlMDFkMzVkZTZkYTAyMjk1NTA4ODlhYg%3D%3D&amp;v=1&amp;f=sd",
              "id": "0ejlwqoln6gf1",
              "isGif": false
            }
          },
          "name": "t3_1mdxihp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.7,
          "author_flair_background_color": null,
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=9dbc8db740c27e211ff4197416cadedf3aa29aa5",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1753956186,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a major update to deep drone, so it now is a CLI agent that controls your drone. It can use models with an api key and also use Ollama. Here is the demo below. And the source code : &lt;a href=\"https://github.com/evangelosmeklis/deepdrone\"&gt;https://github.com/evangelosmeklis/deepdrone&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1mdxihp/video/0ejlwqoln6gf1/player\"&gt;https://reddit.com/link/1mdxihp/video/0ejlwqoln6gf1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?auto=webp&amp;s=a182f6e5039b2ed9730b650ba6ecad08764dcfb8",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e68c38f87cdcc748537b94eed5d21fe9bc1588d8",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e0142f8e0a362fb0ec2137f2a2cf4120fa4ed05",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e0d6f6c8720fde1b3f421b25e5e1b1fc9be942ec",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa5faf99730b0a78e30d0936f1679afa4ae6332d",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1b5365ac3a479980effd5e784df0cc00a84092f5",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69b4ad441c9b6302d637d853b450df6d9acb562f",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "D05ayFweRYxXp8MVhd-qyiGHFhlwyPzJP4dBla8AObI"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1mdxihp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_twelvechess",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdxihp/deepdrone_an_open_source_cli_agent_like_claude/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdxihp/deepdrone_an_open_source_cli_agent_like_claude/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753956186,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": " A new, hidden model called **horizon-alpha** recently appeared on the platform.\n\nhttps://preview.redd.it/fq01fq9g89gf1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=aab356b109e267230944df68664a42ee571ef8f1\n\nhttps://preview.redd.it/3zau72vd89gf1.png?width=1175&amp;format=png&amp;auto=webp&amp;s=081dafbec86b085cfc79a4efb7f157f57c73df72\n\nAfter testing it, the model itself claims to be an OpenAI Assistant.   \n  \nThe creator of EQBench also tested the hidden horizon-alpha model on OpenRouter, and it immediately shot to the top spot on the leaderboard.\n\nhttps://preview.redd.it/mbnz6nkf89gf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=094273f346691f70e9597dc1bb97b0ab474fa9a2\n\nhttps://preview.redd.it/wx6f72mf89gf1.jpg?width=1596&amp;format=pjpg&amp;auto=webp&amp;s=37d29cbf9d0d0dbde2cced367a15313032349e34\n\nhttps://preview.redd.it/q3hkv5mf89gf1.jpg?width=1601&amp;format=pjpg&amp;auto=webp&amp;s=a387f209c80c80419bfd85e201d60166d4b90705\n\nFurthermore, feature clustering results indicate that this model is more similar to the OpenAI series of models. So, could this horizon-alpha be GPT-5?  \n\n\nhttps://preview.redd.it/udwu81xh89gf1.png?width=408&amp;format=png&amp;auto=webp&amp;s=ac6c73e9278e0872da08efe5b0ed8d2e22818cec\n\n",
          "author_fullname": "t2_fiiv6xm3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-5 might already be on OpenRouter?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 112,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "mbnz6nkf89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 100,
                  "x": 108,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=06622b7d899829c8e4b1b27af7069f31095570c4"
                },
                {
                  "y": 200,
                  "x": 216,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=844771b1e65c2f8c8d75552cc95ab8fd14813785"
                },
                {
                  "y": 297,
                  "x": 320,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=353099998f6dd227ad8b4aa7c0c752536cfa8479"
                },
                {
                  "y": 595,
                  "x": 640,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8687d31dfda4ed9591169d01b9bc6fd320ce1bc9"
                },
                {
                  "y": 892,
                  "x": 960,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b67389956ee1055ce4c3affe024c9998df4a102e"
                },
                {
                  "y": 1004,
                  "x": 1080,
                  "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=adb557d0632039690b1c34ca7919ae2c405cb215"
                }
              ],
              "s": {
                "y": 1488,
                "x": 1600,
                "u": "https://preview.redd.it/mbnz6nkf89gf1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=094273f346691f70e9597dc1bb97b0ab474fa9a2"
              },
              "id": "mbnz6nkf89gf1"
            },
            "udwu81xh89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 216,
                  "x": 108,
                  "u": "https://preview.redd.it/udwu81xh89gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=036b57bf667ef73ba3a0b5ec1ce397b9d4004699"
                },
                {
                  "y": 432,
                  "x": 216,
                  "u": "https://preview.redd.it/udwu81xh89gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=44a8b44085962318f88e5ecd5a38594cfba0fd8e"
                },
                {
                  "y": 640,
                  "x": 320,
                  "u": "https://preview.redd.it/udwu81xh89gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8916df36d1d012f9f6076ce269a9effe8b0e584f"
                }
              ],
              "s": {
                "y": 1270,
                "x": 408,
                "u": "https://preview.redd.it/udwu81xh89gf1.png?width=408&amp;format=png&amp;auto=webp&amp;s=ac6c73e9278e0872da08efe5b0ed8d2e22818cec"
              },
              "id": "udwu81xh89gf1"
            },
            "fq01fq9g89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 86,
                  "x": 108,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9377fc12bffce874c43202431eaf49f2bdb6cea"
                },
                {
                  "y": 172,
                  "x": 216,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4235ec3610155bb93416f645bb33795a8b28cdd0"
                },
                {
                  "y": 256,
                  "x": 320,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ada3c439648460b4af0d5bcd1ffb87bd842b749"
                },
                {
                  "y": 512,
                  "x": 640,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=65f5583e904edf6e1f5c77ab7df15c9a4fcd004f"
                },
                {
                  "y": 768,
                  "x": 960,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=28049db03e301633887608d683c7557cc6969dd0"
                },
                {
                  "y": 864,
                  "x": 1080,
                  "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=832c65e670717879fba1d65d06638f04ac4cbcf7"
                }
              ],
              "s": {
                "y": 1064,
                "x": 1329,
                "u": "https://preview.redd.it/fq01fq9g89gf1.png?width=1329&amp;format=png&amp;auto=webp&amp;s=aab356b109e267230944df68664a42ee571ef8f1"
              },
              "id": "fq01fq9g89gf1"
            },
            "q3hkv5mf89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 84,
                  "x": 108,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66f20e6c3d547539ef1116b03b2c374c258220db"
                },
                {
                  "y": 168,
                  "x": 216,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cbec1795d726fd7c6535f0b322db9e0bf216313a"
                },
                {
                  "y": 249,
                  "x": 320,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44f6944c9d12e59170156ee691102c28562f3464"
                },
                {
                  "y": 499,
                  "x": 640,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16a1a1e45ea905e2340d20b99add0063f71a210f"
                },
                {
                  "y": 749,
                  "x": 960,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d81c8dccffe3397418897a843bcde07eb0ecfb98"
                },
                {
                  "y": 843,
                  "x": 1080,
                  "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=83017c386a35fcaf21c00dc07414e044c2015948"
                }
              ],
              "s": {
                "y": 1250,
                "x": 1601,
                "u": "https://preview.redd.it/q3hkv5mf89gf1.jpg?width=1601&amp;format=pjpg&amp;auto=webp&amp;s=a387f209c80c80419bfd85e201d60166d4b90705"
              },
              "id": "q3hkv5mf89gf1"
            },
            "3zau72vd89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 55,
                  "x": 108,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=262d1efcdcf2ffaf6a0ab37ef8b9263804fc5531"
                },
                {
                  "y": 110,
                  "x": 216,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f6398964d548261287ed37f6cd7be06a4a0dad6"
                },
                {
                  "y": 163,
                  "x": 320,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=43fd86bc7976c34aab50f342b04fda27027f34cf"
                },
                {
                  "y": 327,
                  "x": 640,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4edcf590268f05ab49ed05e8bbbd4123a43ae0ee"
                },
                {
                  "y": 491,
                  "x": 960,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b28209fa9cea301f730d3a2e7ee88b45b40292a7"
                },
                {
                  "y": 552,
                  "x": 1080,
                  "u": "https://preview.redd.it/3zau72vd89gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fe53826f0d14a8b7e8260c69d3175c3904efbbf3"
                }
              ],
              "s": {
                "y": 601,
                "x": 1175,
                "u": "https://preview.redd.it/3zau72vd89gf1.png?width=1175&amp;format=png&amp;auto=webp&amp;s=081dafbec86b085cfc79a4efb7f157f57c73df72"
              },
              "id": "3zau72vd89gf1"
            },
            "wx6f72mf89gf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 70,
                  "x": 108,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef6f346b6d6ee08adb5a257b3857a3f93c4c1824"
                },
                {
                  "y": 140,
                  "x": 216,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=473d8b1267a73851d504f2cd87d642404687b751"
                },
                {
                  "y": 208,
                  "x": 320,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ac62bf7ed01c3b837f5e7699bcd98e84ad86620"
                },
                {
                  "y": 416,
                  "x": 640,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a361267793209dc5f176d13aa43dc773dad4350e"
                },
                {
                  "y": 624,
                  "x": 960,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2d7381a95841231b976c3ebd72d76665120500d8"
                },
                {
                  "y": 703,
                  "x": 1080,
                  "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e08ade4fa1690a751c69f9cc534d527e51a18a89"
                }
              ],
              "s": {
                "y": 1039,
                "x": 1596,
                "u": "https://preview.redd.it/wx6f72mf89gf1.jpg?width=1596&amp;format=pjpg&amp;auto=webp&amp;s=37d29cbf9d0d0dbde2cced367a15313032349e34"
              },
              "id": "wx6f72mf89gf1"
            }
          },
          "name": "t3_1me9pro",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.48,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/CvG3Aetkr_0Ipq5nhQk93r7Wqz4nO81rCrEKbpaFJsg.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753987244,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new, hidden model called &lt;strong&gt;horizon-alpha&lt;/strong&gt; recently appeared on the platform.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fq01fq9g89gf1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aab356b109e267230944df68664a42ee571ef8f1\"&gt;https://preview.redd.it/fq01fq9g89gf1.png?width=1329&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=aab356b109e267230944df68664a42ee571ef8f1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3zau72vd89gf1.png?width=1175&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=081dafbec86b085cfc79a4efb7f157f57c73df72\"&gt;https://preview.redd.it/3zau72vd89gf1.png?width=1175&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=081dafbec86b085cfc79a4efb7f157f57c73df72&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After testing it, the model itself claims to be an OpenAI Assistant.   &lt;/p&gt;\n\n&lt;p&gt;The creator of EQBench also tested the hidden horizon-alpha model on OpenRouter, and it immediately shot to the top spot on the leaderboard.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mbnz6nkf89gf1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=094273f346691f70e9597dc1bb97b0ab474fa9a2\"&gt;https://preview.redd.it/mbnz6nkf89gf1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=094273f346691f70e9597dc1bb97b0ab474fa9a2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wx6f72mf89gf1.jpg?width=1596&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=37d29cbf9d0d0dbde2cced367a15313032349e34\"&gt;https://preview.redd.it/wx6f72mf89gf1.jpg?width=1596&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=37d29cbf9d0d0dbde2cced367a15313032349e34&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/q3hkv5mf89gf1.jpg?width=1601&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a387f209c80c80419bfd85e201d60166d4b90705\"&gt;https://preview.redd.it/q3hkv5mf89gf1.jpg?width=1601&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a387f209c80c80419bfd85e201d60166d4b90705&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Furthermore, feature clustering results indicate that this model is more similar to the OpenAI series of models. So, could this horizon-alpha be GPT-5?  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/udwu81xh89gf1.png?width=408&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ac6c73e9278e0872da08efe5b0ed8d2e22818cec\"&gt;https://preview.redd.it/udwu81xh89gf1.png?width=408&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ac6c73e9278e0872da08efe5b0ed8d2e22818cec&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1me9pro",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Dr_Karminski",
          "discussion_type": null,
          "num_comments": 18,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me9pro/gpt5_might_already_be_on_openrouter/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me9pro/gpt5_might_already_be_on_openrouter/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753987244,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "**Setup:**\nRunning a local Llama-3 8B base model via llama.cpp on a high-spec laptop (64 GB RAM, RTX 4060). Using a custom AI assistant that includes user memory, profile blocks, and a memory graph. Model runs fine technicallyâ€”fast inference, no crashes.\n\n**The problem:**\nEven in short chats, the assistant forgets what the user said just 2â€“3 messages ago. It responds with info from long-term memory or profile facts, but *not* from the recent conversation.\n\nExample:\n&gt; User: Hey, remember this detail.  \n&gt; User: What did I just tell you?  \n&gt; Assistant: Sorry, I donâ€™t know.\n\n**Suspected cause:**\nThe system retrieves relevant memories and profile info and builds the prompt using thoseâ€”but *it looks like the actual recent user/assistant turns never make it into the prompt at all*. So the LLM is answering based on stale memory instead of live context.\n\nI tried:\n- Increasing the context window to 16k â€“ no change.  \n- Injecting last 3 user/assistant turns manually â€“ suddenly works fine.  \n- Logging the raw prompt â€“ shows memory and profile, but no actual conversation.\n\n**What I'm asking:**\n- Has anyone run into this with local LLMs (especially Llama 3 base)?\n- Are there common mistakes in prompt construction that would lead to this?\n- Could llama.cpp itself drop early tokens silently even if `n_ctx` isn't exceeded?\n\nAny insight appreciatedâ€”even better if you've seen something similar in memory-augmented setups or assistant-style systems.",
          "author_fullname": "t2_1dbyufk21e",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "LLM forgets recent user messages â€“ only responds from memory DB, not conversation context (Llama-3 base, local setup)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me3qyu",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753973687,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;\nRunning a local Llama-3 8B base model via llama.cpp on a high-spec laptop (64 GB RAM, RTX 4060). Using a custom AI assistant that includes user memory, profile blocks, and a memory graph. Model runs fine technicallyâ€”fast inference, no crashes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt;\nEven in short chats, the assistant forgets what the user said just 2â€“3 messages ago. It responds with info from long-term memory or profile facts, but &lt;em&gt;not&lt;/em&gt; from the recent conversation.&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;User: Hey, remember this detail.&lt;br/&gt;\nUser: What did I just tell you?&lt;br/&gt;\nAssistant: Sorry, I donâ€™t know.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Suspected cause:&lt;/strong&gt;\nThe system retrieves relevant memories and profile info and builds the prompt using thoseâ€”but &lt;em&gt;it looks like the actual recent user/assistant turns never make it into the prompt at all&lt;/em&gt;. So the LLM is answering based on stale memory instead of live context.&lt;/p&gt;\n\n&lt;p&gt;I tried:\n- Increasing the context window to 16k â€“ no change.&lt;br/&gt;\n- Injecting last 3 user/assistant turns manually â€“ suddenly works fine.&lt;br/&gt;\n- Logging the raw prompt â€“ shows memory and profile, but no actual conversation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m asking:&lt;/strong&gt;\n- Has anyone run into this with local LLMs (especially Llama 3 base)?\n- Are there common mistakes in prompt construction that would lead to this?\n- Could llama.cpp itself drop early tokens silently even if &lt;code&gt;n_ctx&lt;/code&gt; isn&amp;#39;t exceeded?&lt;/p&gt;\n\n&lt;p&gt;Any insight appreciatedâ€”even better if you&amp;#39;ve seen something similar in memory-augmented setups or assistant-style systems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me3qyu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "10jaqk192",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me3qyu/llm_forgets_recent_user_messages_only_responds/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me3qyu/llm_forgets_recent_user_messages_only_responds/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753973687,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "With Qwen, you could add something to the prompt to turn off reasoning. Can you do the same with GLM 4.5?",
          "author_fullname": "t2_32aqmyw",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How can you turn off reasoning for certain tasks in GLM 4.5?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdwh31",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753952158,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With Qwen, you could add something to the prompt to turn off reasoning. Can you do the same with GLM 4.5?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mdwh31",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Sky_Linx",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdwh31/how_can_you_turn_off_reasoning_for_certain_tasks/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdwh31/how_can_you_turn_off_reasoning_for_certain_tasks/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753952158,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "When using embedding model for example Qwen 3 8B - is ti beneficial to pass instruction when doing chunk/document embeddings as Instruct: [custom instruction]\\nText: [document text] ? In all the tutorials and documentations as I see it only passed with queries",
          "author_fullname": "t2_80dfkph4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Instruct embedding models",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me3k8h",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753973236,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When using embedding model for example Qwen 3 8B - is ti beneficial to pass instruction when doing chunk/document embeddings as Instruct: [custom instruction]\\nText: [document text] ? In all the tutorials and documentations as I see it only passed with queries&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me3k8h",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SadInitial9305",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me3k8h/instruct_embedding_models/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me3k8h/instruct_embedding_models/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753973236,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Can anyone tell me which is the best suitable model for LoRA fine tuning on summarisation task , specially for a specific domain and long documents ? I mainly worked on Encoder-Decoder models like T5. Suggest some other transformer models which can be fine tuned. I have 1xA100 GPU (80GB).",
          "author_fullname": "t2_8l80h3q5c",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Suitable model for Summarization",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me9hhl",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753986716,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone tell me which is the best suitable model for LoRA fine tuning on summarisation task , specially for a specific domain and long documents ? I mainly worked on Encoder-Decoder models like T5. Suggest some other transformer models which can be fine tuned. I have 1xA100 GPU (80GB).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me9hhl",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DefinitionFew9850",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me9hhl/suitable_model_for_summarization/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me9hhl/suitable_model_for_summarization/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753986716,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey folks,\n\nIâ€™m building an affordable, plug-and-play AI devboard kind of like a â€œRaspberry Pi for AIâ€designed to run models like TinyLlama, Whisper, and YOLO locally, without cloud dependencies.\n\nItâ€™s meant for developers, makers, educators, and startups who want to:\n\tâ€¢\tRun local LLMs and vision models on the edge\n\tâ€¢\tBuild AI-powered projects (offline assistants, smart cameras, low-power robots)\n\tâ€¢\tExperiment with on-device inference using open-source models\n\nThe board will include:\n\tâ€¢\tA built-in NPU (2â€“10 TOPS range)\n\tâ€¢\tSupport for TFLite, ONNX, and llama.cpp workflows\n\tâ€¢\tPython/C++ SDK for deploying your own models\n\tâ€¢\tGPIO, camera, mic, and USB expansion for projects\n\nIâ€™m still in the prototyping phase and talking to potential early users. If you:\n\tâ€¢\tCurrently run AI models on a Pi, Jetson, ESP32, or PC\n\tâ€¢\tAre building something cool with local inference\n\tâ€¢\tHave been frustrated by slow, power-hungry, or clunky AI deployments\n\nâ€¦Iâ€™d love to chat or send you early builds when ready.\n\nDrop a comment or DM me and let me know what YOU would want from an â€œAI-firstâ€ devboard.\n\nThanks!\n",
          "author_fullname": "t2_1uhrwpei9n",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Weâ€™re building a devboard that runs Whisper, YOLO, and TinyLlama â€” locally, no cloud. Want to try it before we launch?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Generation"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdx40b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Generation",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753954678,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;Iâ€™m building an affordable, plug-and-play AI devboard kind of like a â€œRaspberry Pi for AIâ€designed to run models like TinyLlama, Whisper, and YOLO locally, without cloud dependencies.&lt;/p&gt;\n\n&lt;p&gt;Itâ€™s meant for developers, makers, educators, and startups who want to:\n    â€¢ Run local LLMs and vision models on the edge\n    â€¢ Build AI-powered projects (offline assistants, smart cameras, low-power robots)\n    â€¢ Experiment with on-device inference using open-source models&lt;/p&gt;\n\n&lt;p&gt;The board will include:\n    â€¢ A built-in NPU (2â€“10 TOPS range)\n    â€¢ Support for TFLite, ONNX, and llama.cpp workflows\n    â€¢ Python/C++ SDK for deploying your own models\n    â€¢ GPIO, camera, mic, and USB expansion for projects&lt;/p&gt;\n\n&lt;p&gt;Iâ€™m still in the prototyping phase and talking to potential early users. If you:\n    â€¢ Currently run AI models on a Pi, Jetson, ESP32, or PC\n    â€¢ Are building something cool with local inference\n    â€¢ Have been frustrated by slow, power-hungry, or clunky AI deployments&lt;/p&gt;\n\n&lt;p&gt;â€¦Iâ€™d love to chat or send you early builds when ready.&lt;/p&gt;\n\n&lt;p&gt;Drop a comment or DM me and let me know what YOU would want from an â€œAI-firstâ€ devboard.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "23bddba8-ff56-11ed-9688-1a11994b71f7",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#b5a3d0",
          "id": "1mdx40b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "aero917",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdx40b/were_building_a_devboard_that_runs_whisper_yolo/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdx40b/were_building_a_devboard_that_runs_whisper_yolo/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753954678,
          "num_crossposts": 7,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Like the title says, I ranÂ **GLM 4.5 Air Q4**Â on my local machine usingÂ **RooCode**Â insideÂ **VS Code**, and I was able to build a functional CRUD-style web application.\n\nUsers can register with a password, log in, and log out from the client side. All authentication is handled using JWTs.\n\nThe experience honestly exceeded my expectations. Compared to my past attempts with local LLMs and RooCode (which sometimes struggled to generate even a basic webpage), this felt like a major step forward. The results were genuinely satisfying.\n\nThe entire app took about an hour to generate, with a bit of debugging and prompt tweaking along the way. With more deliberate prompting and a little more patience, I think I could have pushed it further. But for now, itâ€™s a solid starting point.\n\nIf anyone else is experimenting with local models for full stack projects, Iâ€™d love to hear how itâ€™s going. Happy to answer questions or share what Iâ€™ve learned.",
          "author_fullname": "t2_fz3utn30",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "I Built a Full Stack App Using a Local LLM (GLM 4.5 Air) and RooCode. Here's How It Went",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdu4io",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.91,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753943029,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like the title says, I ranÂ &lt;strong&gt;GLM 4.5 Air Q4&lt;/strong&gt;Â on my local machine usingÂ &lt;strong&gt;RooCode&lt;/strong&gt;Â insideÂ &lt;strong&gt;VS Code&lt;/strong&gt;, and I was able to build a functional CRUD-style web application.&lt;/p&gt;\n\n&lt;p&gt;Users can register with a password, log in, and log out from the client side. All authentication is handled using JWTs.&lt;/p&gt;\n\n&lt;p&gt;The experience honestly exceeded my expectations. Compared to my past attempts with local LLMs and RooCode (which sometimes struggled to generate even a basic webpage), this felt like a major step forward. The results were genuinely satisfying.&lt;/p&gt;\n\n&lt;p&gt;The entire app took about an hour to generate, with a bit of debugging and prompt tweaking along the way. With more deliberate prompting and a little more patience, I think I could have pushed it further. But for now, itâ€™s a solid starting point.&lt;/p&gt;\n\n&lt;p&gt;If anyone else is experimenting with local models for full stack projects, Iâ€™d love to hear how itâ€™s going. Happy to answer questions or share what Iâ€™ve learned.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdu4io",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "gamblingapocalypse",
          "discussion_type": null,
          "num_comments": 16,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdu4io/i_built_a_full_stack_app_using_a_local_llm_glm_45/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdu4io/i_built_a_full_stack_app_using_a_local_llm_glm_45/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753943029,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "RTX4090  \ni9 14900k  \n64GB DDR5 6000Mhz  \n2TB SSD PCIe5\n\nI played a bit with the Qwen2.5 Coder 32B, but it felt very slow.  \nNow i see lots of new models coming out. I would want to use it in VS Code + Cline for coding, something that offsets some of the easier tasks so i don't get to pay a lot for the cloud models API's",
          "author_fullname": "t2_q140j",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What model would you recommend for my specs ?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdy8f8",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.86,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753958773,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;RTX4090&lt;br/&gt;\ni9 14900k&lt;br/&gt;\n64GB DDR5 6000Mhz&lt;br/&gt;\n2TB SSD PCIe5&lt;/p&gt;\n\n&lt;p&gt;I played a bit with the Qwen2.5 Coder 32B, but it felt very slow.&lt;br/&gt;\nNow i see lots of new models coming out. I would want to use it in VS Code + Cline for coding, something that offsets some of the easier tasks so i don&amp;#39;t get to pay a lot for the cloud models API&amp;#39;s&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mdy8f8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Alywan",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdy8f8/what_model_would_you_recommend_for_my_specs/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdy8f8/what_model_would_you_recommend_for_my_specs/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753958773,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_52zzm",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen/Qwen3-30B-A3B-Thinking-2507 Â· Hugging Face",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 75,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md8rxu",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.97,
          "author_flair_background_color": null,
          "ups": 155,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 155,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=0cf90a8010053dbf48911257591f71a3d1ddded7",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753887372,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "huggingface.co",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?auto=webp&amp;s=a67dbb1b6fae4b63d82563a3e65a19938ca062fb",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e994b63235f1f31da964f24b3a55a51498b6935f",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7aa24107465ba0cfb16f79135e2c61bc02b91707",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=95124de9bda6db677aaa373721a3aa188cc7f224",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd872c4c3958b52ad860a6db5ba53994da65552e",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3213439d0e68cbadd20dbb4d235a121e1df48f64",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b13bc1d8de32bb083d7b376a591f00d85d3173aa",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "-lNzejy2CT3wd1ovuVIcDeuPfMRg-vkESkjpQgo3tYU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1md8rxu",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "MariusNocturnum",
          "discussion_type": null,
          "num_comments": 34,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md8rxu/qwenqwen330ba3bthinking2507_hugging_face/",
          "stickied": false,
          "url": "https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507",
          "subreddit_subscribers": 507935,
          "created_utc": 1753887372,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "  \nJust launchedÂ **Eigent,**Â a fully open-source, local-first multi-agent desktop application designed for developers and teams who want full control over their AI workflows.  \nBuilt on top of CAMEL-AIâ€™s modular framework, Eigent allows you to:\n\n* Run tasks in parallel with customizable agent workflows\n* Deploy locally or in the cloud with â€œBring Your Own Keyâ€ (BYOK) support\n* Maintain full data privacy â€” no information leaves your machine\n* Step in anytime with Human-in-the-Loop control\n* Integrate seamlessly with your existing stack\n* Use 200+ MCP-compatible tools (or bring your own)\n\nThe goal is simple: give teams a secure, customizable, and scalable AI workforce on their own infrastructure.  \nâ†’ GitHub:Â [github.com/eigent-ai/eigent](http://github.com/eigent-ai/eigent)  \nâ†’ Download:Â [eigent.ai\n](http://www.eigent.ai/)  \nFeel free to ask me anything below, whether itâ€™s about the architecture, use cases, or how to extend it for your own needs.",
          "author_fullname": "t2_152q9v633e",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Eigent â€“ Open Source, Local-First Multi-Agent Workforce",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 87,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "ef2zkaadi1gf1": {
              "status": "valid",
              "e": "AnimatedImage",
              "m": "image/gif",
              "p": [
                {
                  "y": 67,
                  "x": 108,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=cc7aa7c19cb33e6ea5a3189f5d4a37172bad4bab"
                },
                {
                  "y": 135,
                  "x": 216,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=2a927f057db3e6ee581d145afb172e678b47c9e0"
                },
                {
                  "y": 200,
                  "x": 320,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=649b21b6c8f96a9bbd9634460b86ade41547ca42"
                },
                {
                  "y": 400,
                  "x": 640,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=3d8846e1ab7075c62ceb6e4efddf56bb5f671b64"
                },
                {
                  "y": 600,
                  "x": 960,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=fd074da189d93f901d022bc28781e401ac5da565"
                },
                {
                  "y": 675,
                  "x": 1080,
                  "u": "https://preview.redd.it/ef2zkaadi1gf1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=a8e0b8fc312c32a85f7e54316cdf77e56c58e174"
                }
              ],
              "s": {
                "y": 900,
                "gif": "https://i.redd.it/ef2zkaadi1gf1.gif",
                "mp4": "https://preview.redd.it/ef2zkaadi1gf1.gif?format=mp4&amp;s=d9f6fdde529614c3dc2737be24c5f89e0ade062c",
                "x": 1440
              },
              "id": "ef2zkaadi1gf1"
            },
            "ojkyicmfi1gf1": {
              "status": "valid",
              "e": "AnimatedImage",
              "m": "image/gif",
              "p": [
                {
                  "y": 67,
                  "x": 108,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=7c01c4d5c9d3e5cfd1f01e31532a5e029345a539"
                },
                {
                  "y": 135,
                  "x": 216,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=c9f2a8e7741b0403d54453040b78b981b3abede4"
                },
                {
                  "y": 200,
                  "x": 320,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=6ea32e90c9414fa74c034c6afa2fdd89730bb7c4"
                },
                {
                  "y": 400,
                  "x": 640,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=ba764aeb05d92cacedde7dc333446514ab6e483c"
                },
                {
                  "y": 600,
                  "x": 960,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=e6f2a2ab8d800d86a62c3a7a7675cb66b5091700"
                },
                {
                  "y": 675,
                  "x": 1080,
                  "u": "https://preview.redd.it/ojkyicmfi1gf1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=6f07fa053b430f40ed553fd774fba50e01847b5a"
                }
              ],
              "s": {
                "y": 900,
                "gif": "https://i.redd.it/ojkyicmfi1gf1.gif",
                "mp4": "https://preview.redd.it/ojkyicmfi1gf1.gif?format=mp4&amp;s=040939eeaef50f65afbdd9c681b871bebf581bb6",
                "x": 1440
              },
              "id": "ojkyicmfi1gf1"
            }
          },
          "name": "t3_1mdbm5t",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "ups": 104,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "ef2zkaadi1gf1",
                "id": 717466340
              },
              {
                "media_id": "ojkyicmfi1gf1",
                "id": 717466341
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 104,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3RqGcIVLHN9WLuz3G6pO2CwDYLwlqMU3O2iTSdwHGzY.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753893843,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just launchedÂ &lt;strong&gt;Eigent,&lt;/strong&gt;Â a fully open-source, local-first multi-agent desktop application designed for developers and teams who want full control over their AI workflows.&lt;br/&gt;\nBuilt on top of CAMEL-AIâ€™s modular framework, Eigent allows you to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run tasks in parallel with customizable agent workflows&lt;/li&gt;\n&lt;li&gt;Deploy locally or in the cloud with â€œBring Your Own Keyâ€ (BYOK) support&lt;/li&gt;\n&lt;li&gt;Maintain full data privacy â€” no information leaves your machine&lt;/li&gt;\n&lt;li&gt;Step in anytime with Human-in-the-Loop control&lt;/li&gt;\n&lt;li&gt;Integrate seamlessly with your existing stack&lt;/li&gt;\n&lt;li&gt;Use 200+ MCP-compatible tools (or bring your own)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The goal is simple: give teams a secure, customizable, and scalable AI workforce on their own infrastructure.&lt;br/&gt;\nâ†’ GitHub:Â &lt;a href=\"http://github.com/eigent-ai/eigent\"&gt;github.com/eigent-ai/eigent&lt;/a&gt;&lt;br/&gt;\nâ†’ Download:Â &lt;a href=\"http://www.eigent.ai/\"&gt;eigent.ai\n&lt;/a&gt;&lt;br/&gt;\nFeel free to ask me anything below, whether itâ€™s about the architecture, use cases, or how to extend it for your own needs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mdbm5t",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdbm5t",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "FitHeron1933",
          "discussion_type": null,
          "num_comments": 59,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdbm5t/eigent_open_source_localfirst_multiagent_workforce/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mdbm5t",
          "subreddit_subscribers": 507935,
          "created_utc": 1753893843,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hiii im willing to try some of the models you guys talk about, but I donâ€™t know how yet.\n\nCan you refer me some tutorial or guide which model I can try?\n\n\nMy HW is a dual Xeon e2695, Graphics- 4060, 64GB RAM, 1TB Nvme, 2TB SSD. \n\n\n\nThx in advance!",
          "author_fullname": "t2_1cy7uq4xkn",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Try some models",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me7nbq",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753982536,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiii im willing to try some of the models you guys talk about, but I donâ€™t know how yet.&lt;/p&gt;\n\n&lt;p&gt;Can you refer me some tutorial or guide which model I can try?&lt;/p&gt;\n\n&lt;p&gt;My HW is a dual Xeon e2695, Graphics- 4060, 64GB RAM, 1TB Nvme, 2TB SSD. &lt;/p&gt;\n\n&lt;p&gt;Thx in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me7nbq",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Brilliant-Lie2367",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me7nbq/try_some_models/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me7nbq/try_some_models/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753982536,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_186az5xn",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is \"Personal Superintelligence\" really personal if it is not local like a personal device?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdfkly",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 55,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 55,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1753902735,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "meta.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.meta.com/superintelligence/",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mdfkly",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "AlanzhuLy",
          "discussion_type": null,
          "num_comments": 21,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdfkly/is_personal_superintelligence_really_personal_if/",
          "stickied": false,
          "url": "https://www.meta.com/superintelligence/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753902735,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi guys.There is trend now in internet make old photo alive,can you recommend me free ai for this?",
          "author_fullname": "t2_n9txxf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ai for making photo alive",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me6yfh",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753980972,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys.There is trend now in internet make old photo alive,can you recommend me free ai for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me6yfh",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Akriosss",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me6yfh/ai_for_making_photo_alive/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me6yfh/ai_for_making_photo_alive/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753980972,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi all,\n\nIâ€™m setting up my system to run large language models locally and would really appreciate recommendations.\n\nI havenâ€™t tried any models yet â€” my goal is to move away from cloud LLMs like Claude (mainly for coding , reasoning, and tool use), and run everything locally.\n\nMy setup:\n\tâ€¢\tUbuntu\n\tâ€¢\tAMD Threadripper 7960X (24 cores / 48 threads)\n\tâ€¢\t3Ã— RTX 3090 (72 GB total VRAM)\n\tâ€¢\t128 GB DDR5 ECC RAM\n\tâ€¢\t8 TB M.2 NVMe SSD\n\nWhat Iâ€™m looking for:\n\t1.\tA Claude-like model that handles reasoning and agentic behavior well\n\t2.\tCan run on this hardware (preferably multi-GPU, FP16 or 4-bit quantized)\n\t3.\tSupports long-context and multi-step workflows\n\t4.\tIdeally open-source, something I can fully control",
          "author_fullname": "t2_v9xk0o13",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Best local model for Claude-like agentic behavior on 3Ã—3090 rig?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdwv4f",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753953683,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Iâ€™m setting up my system to run large language models locally and would really appreciate recommendations.&lt;/p&gt;\n\n&lt;p&gt;I havenâ€™t tried any models yet â€” my goal is to move away from cloud LLMs like Claude (mainly for coding , reasoning, and tool use), and run everything locally.&lt;/p&gt;\n\n&lt;p&gt;My setup:\n    â€¢ Ubuntu\n    â€¢ AMD Threadripper 7960X (24 cores / 48 threads)\n    â€¢ 3Ã— RTX 3090 (72 GB total VRAM)\n    â€¢ 128 GB DDR5 ECC RAM\n    â€¢ 8 TB M.2 NVMe SSD&lt;/p&gt;\n\n&lt;p&gt;What Iâ€™m looking for:\n    1.  A Claude-like model that handles reasoning and agentic behavior well\n    2.  Can run on this hardware (preferably multi-GPU, FP16 or 4-bit quantized)\n    3.  Supports long-context and multi-step workflows\n    4.  Ideally open-source, something I can fully control&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mdwv4f",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "CryptographerLow7817",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdwv4f/best_local_model_for_claudelike_agentic_behavior/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdwv4f/best_local_model_for_claudelike_agentic_behavior/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753953683,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I want to fine tune LED. I tried freeze its encoder and applied the LoRA to decoder of the model. But i got following error. How can i solve this.\n\n/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires\\_grad=True. Gradients will be None warnings.warn(\n\n    ---------------------------------------------------------------------------\n    \n    \n    RuntimeError                              Traceback (most recent call last)\n    \n    \n     in &lt;cell line: 0&gt;()\n          1 torch.cuda.empty_cache()\n    ----&gt; 2 trainer.train()\n    \n    /tmp/ipython-input-3047381130.py\n    \n     in _engine_run_backward(t_outputs, *args, **kwargs)\n        821         unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n        822     try:\n    --&gt; 823         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n        824             t_outputs, *args, **kwargs\n        825         )  # Calls into the C++ engine to run the backward pass\n    \n    /usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\n    \n    RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",
          "author_fullname": "t2_8l80h3q5c",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "HELP ... FINE TUNING LED MODEL !!!!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me6sxd",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753980625,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to fine tune LED. I tried freeze its encoder and applied the LoRA to decoder of the model. But i got following error. How can i solve this.&lt;/p&gt;\n\n&lt;p&gt;/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None warnings.warn(&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------\n\n\nRuntimeError                              Traceback (most recent call last)\n\n\n in &amp;lt;cell line: 0&amp;gt;()\n      1 torch.cuda.empty_cache()\n----&amp;gt; 2 trainer.train()\n\n/tmp/ipython-input-3047381130.py\n\n in _engine_run_backward(t_outputs, *args, **kwargs)\n    821         unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n    822     try:\n--&amp;gt; 823         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n    824             t_outputs, *args, **kwargs\n    825         )  # Calls into the C++ engine to run the backward pass\n\n/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\n\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me6sxd",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DefinitionFew9850",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me6sxd/help_fine_tuning_led_model/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me6sxd/help_fine_tuning_led_model/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753980625,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi, I am a long time lurker, but I took a break after the rtx 5090 launch fail since I almost completely gave up on getting to run ai locally this year.\n\nWith everything that's going on in the world and the possibility of the ai being considered \"too dangerous\", apparently the music may already be, I want to ask which llm is \"good\" today (not in the way of SOTA, but by personal user experience). I am planning on using an intel b60 48gb vram or maybe 1-2 amd mi50 32gb. I am mostly interested in llm, vllm and probably one for coding, although it's not really needed since I know how to code, but it might come handy I don't know. I guess what I might need is probably 7-70b parameter ones, I also have 96gb ram so a larger moe might also be decent. The total storage for all ais is probably 2-3tb. If I am at this topic I suppose that the intel gpu might be better for image generation\n\nI am old enough to remember mixtral 7x8 but I have no idea if it's still relevant, I know some mistral small might be better, also I might be interested in the vllm one for ocr. I kinda have an idea of most of the llms including the new qwen moes, but I have no idea which of the old models are still relevant today. For example I know that lama 3, or even 3.3 is kinda \"outdated\" (since I have no better word, but you get what I mean), I am even aware of a new nemotron which is based on lama 70b but I am missing a lot of details.\n\nI know I should be able to find them on huggingface, and I might need to download vllm, ollama and intel playgrounds or idk how it is for it.\n\nI know exactly how to get the stable diffusion models, but while we are at it I might be interested in a few tts models (text to speech, preferably with voice cloning), I think I've heard of \"megatts 3\" and \"GPT-SoVITS\" but any tips here are helpful as well. Meanwhile I will to find the fastest whisper model for stt, I am certain I might have saved the link for it somewhere.\n\nSorry for creating trash posts that are probably lots and lots on weekly bases for this particular question (not that particular considering the title, but you get what I mean).",
          "author_fullname": "t2_1gwc678u",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Best LLMs to preserve in case of internet apocalypse",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mdishv",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.77,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 32,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 32,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753910249,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a long time lurker, but I took a break after the rtx 5090 launch fail since I almost completely gave up on getting to run ai locally this year.&lt;/p&gt;\n\n&lt;p&gt;With everything that&amp;#39;s going on in the world and the possibility of the ai being considered &amp;quot;too dangerous&amp;quot;, apparently the music may already be, I want to ask which llm is &amp;quot;good&amp;quot; today (not in the way of SOTA, but by personal user experience). I am planning on using an intel b60 48gb vram or maybe 1-2 amd mi50 32gb. I am mostly interested in llm, vllm and probably one for coding, although it&amp;#39;s not really needed since I know how to code, but it might come handy I don&amp;#39;t know. I guess what I might need is probably 7-70b parameter ones, I also have 96gb ram so a larger moe might also be decent. The total storage for all ais is probably 2-3tb. If I am at this topic I suppose that the intel gpu might be better for image generation&lt;/p&gt;\n\n&lt;p&gt;I am old enough to remember mixtral 7x8 but I have no idea if it&amp;#39;s still relevant, I know some mistral small might be better, also I might be interested in the vllm one for ocr. I kinda have an idea of most of the llms including the new qwen moes, but I have no idea which of the old models are still relevant today. For example I know that lama 3, or even 3.3 is kinda &amp;quot;outdated&amp;quot; (since I have no better word, but you get what I mean), I am even aware of a new nemotron which is based on lama 70b but I am missing a lot of details.&lt;/p&gt;\n\n&lt;p&gt;I know I should be able to find them on huggingface, and I might need to download vllm, ollama and intel playgrounds or idk how it is for it.&lt;/p&gt;\n\n&lt;p&gt;I know exactly how to get the stable diffusion models, but while we are at it I might be interested in a few tts models (text to speech, preferably with voice cloning), I think I&amp;#39;ve heard of &amp;quot;megatts 3&amp;quot; and &amp;quot;GPT-SoVITS&amp;quot; but any tips here are helpful as well. Meanwhile I will to find the fastest whisper model for stt, I am certain I might have saved the link for it somewhere.&lt;/p&gt;\n\n&lt;p&gt;Sorry for creating trash posts that are probably lots and lots on weekly bases for this particular question (not that particular considering the title, but you get what I mean).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mdishv",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "nos_66",
          "discussion_type": null,
          "num_comments": 58,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mdishv/best_llms_to_preserve_in_case_of_internet/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdishv/best_llms_to_preserve_in_case_of_internet/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753910249,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_6suhydu8g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GLM4.5 EQ-Bench and Creative Write",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1md5k8f",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 143,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 143,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/7v_DJnb0Q3ULI7Mg3Ucw4Sc2Y1CnOwyJfcCGQCPhmJ4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1753879322,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ubwsl0gdb0gf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?auto=webp&amp;s=4e43b4753bf20f50777316c9069a22f6e1bc9ffe",
                  "width": 1189,
                  "height": 2048
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83a0215afba98d96c58ddd8953cf946627a96b87",
                    "width": 108,
                    "height": 186
                  },
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1cb81fe92d2ef9d95d5c9c9b3512072b4195b7e3",
                    "width": 216,
                    "height": 372
                  },
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa00a913d179ff148233c1e9f131915282446a19",
                    "width": 320,
                    "height": 551
                  },
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=abdf15ff9928a1e321306852523e66da9ac4b1cf",
                    "width": 640,
                    "height": 1102
                  },
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b29bfc227bbc65ed304a2107a162b0cbeeaa5d1b",
                    "width": 960,
                    "height": 1653
                  },
                  {
                    "url": "https://preview.redd.it/ubwsl0gdb0gf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05ae28405c4978e66fd2d7f2517cb75addd8bf66",
                    "width": 1080,
                    "height": 1860
                  }
                ],
                "variants": {},
                "id": "7_4P0DMZtwaTeczmzHUyBCOKOwxJl2ysfZ1o0jG37ww"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1md5k8f",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "pcdacks",
          "discussion_type": null,
          "num_comments": 30,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1md5k8f/glm45_eqbench_and_creative_write/",
          "stickied": false,
          "url": "https://i.redd.it/ubwsl0gdb0gf1.jpeg",
          "subreddit_subscribers": 507935,
          "created_utc": 1753879322,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey everyone,  \nIâ€™ve got an AMD Strix Halo (Ryzen AI Max+ 395) running Ubuntu 24.04, and Iâ€™ve installed ROCm based on the official documentation. To keep things streamlined, I also went ahead and installed PyTorch via Docker, as recommended by the official docs.\n\nHowever, when I run `import torch` and check for VRAM, Iâ€™m only seeing 16GB available instead of the full 96GB that the system claims to have. Iâ€™m trying to fully utilize the available VRAM to train large models, but Iâ€™m not sure how to access or enable the full 96GB capacity.\n\nHas anyone else run into this issue or know how to configure PyTorch to use the entire VRAM on AMD GPUs with ROCm?\n\nWould really appreciate any guidance on this!\n\nThanks in advance!",
          "author_fullname": "t2_reelww4w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Help! How to access the full 96GB VRAM on AMD Strix Halo (Ryzen AI Max+ 395) with PyTorch in Ubuntu 24.04?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me4e22",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753975162,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;br/&gt;\nIâ€™ve got an AMD Strix Halo (Ryzen AI Max+ 395) running Ubuntu 24.04, and Iâ€™ve installed ROCm based on the official documentation. To keep things streamlined, I also went ahead and installed PyTorch via Docker, as recommended by the official docs.&lt;/p&gt;\n\n&lt;p&gt;However, when I run &lt;code&gt;import torch&lt;/code&gt; and check for VRAM, Iâ€™m only seeing 16GB available instead of the full 96GB that the system claims to have. Iâ€™m trying to fully utilize the available VRAM to train large models, but Iâ€™m not sure how to access or enable the full 96GB capacity.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else run into this issue or know how to configure PyTorch to use the entire VRAM on AMD GPUs with ROCm?&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate any guidance on this!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me4e22",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ashwin3005",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me4e22/help_how_to_access_the_full_96gb_vram_on_amd/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me4e22/help_how_to_access_the_full_96gb_vram_on_amd/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753975162,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Is there a good computer use workflow or model yet that people like these days? \n\nWhich one is people's favorite on the market today? Preferably a locally run model but totally fine if it needs to reach out to a service like OpenAI/Claude/Manus etc.",
          "author_fullname": "t2_67yij",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is there a good Computer use workflow / model?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1me467z",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1753974658,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a good computer use workflow or model yet that people like these days? &lt;/p&gt;\n\n&lt;p&gt;Which one is people&amp;#39;s favorite on the market today? Preferably a locally run model but totally fine if it needs to reach out to a service like OpenAI/Claude/Manus etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1me467z",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "BluCreator",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1me467z/is_there_a_good_computer_use_workflow_model/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1me467z/is_there_a_good_computer_use_workflow_model/",
          "subreddit_subscribers": 507935,
          "created_utc": 1753974658,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      }
    ],
    "before": null
  }
}