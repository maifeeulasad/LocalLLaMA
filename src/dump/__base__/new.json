{
  "kind": "Listing",
  "data": {
    "after": "t3_1miiesj",
    "dist": 100,
    "modhash": "",
    "geo_filter": "",
    "children": [
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Because range matters.",
          "author_fullname": "t2_ts2dg",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Let me fix that chart for you",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 129,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqzgb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "ups": 10,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 10,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3Ok8ftvPtdWtD-XGVnuGickHrw1QOMKeHe84HGj9Omw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754442110,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Because range matters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/69scmtwzsahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/69scmtwzsahf1.png?auto=webp&amp;s=8f10fc00fb6f46cda975ad8202cc0242fa8ede02",
                  "width": 1272,
                  "height": 1180
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=33a6329665f72ebd056ba1358adce8334fa278b5",
                    "width": 108,
                    "height": 100
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7b88353f16af4b173471115398b3cb67f74750e",
                    "width": 216,
                    "height": 200
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d8d420a7b9dc4092b1389e18be4245e21a14824d",
                    "width": 320,
                    "height": 296
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=90ff74d87020e05e7f407a73bbc2874a6ef21143",
                    "width": 640,
                    "height": 593
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b02c3e39a067b03b3575eca3a8844f120beb84a",
                    "width": 960,
                    "height": 890
                  },
                  {
                    "url": "https://preview.redd.it/69scmtwzsahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f9b4d54ac08a5a124832b53e91a43c2d4024df36",
                    "width": 1080,
                    "height": 1001
                  }
                ],
                "variants": {},
                "id": "ZTLEigllWjDcs1VEMHDhGNlq6geK4NSDHKVgPIsBcFY"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1miqzgb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "sstainsby",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqzgb/let_me_fix_that_chart_for_you/",
          "stickied": false,
          "url": "https://i.redd.it/69scmtwzsahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754442110,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "My pc specs:\n\ncpu: ryzen 5600g\nram: ddr4 32gb 3200 mt/s (considering upgrading to 64 or 128 gb)\n\nWhat t/s and ram usage i should expect? Would it be slow to use with Aider? Codebase i work with is fairly small and tasks are fairly repetitive ",
          "author_fullname": "t2_7ii0iu53",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Running Qwen2.5-Coder-32b-q6-gguf entirely on cpu",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqxdc",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754441954,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My pc specs:&lt;/p&gt;\n\n&lt;p&gt;cpu: ryzen 5600g\nram: ddr4 32gb 3200 mt/s (considering upgrading to 64 or 128 gb)&lt;/p&gt;\n\n&lt;p&gt;What t/s and ram usage i should expect? Would it be slow to use with Aider? Codebase i work with is fairly small and tasks are fairly repetitive &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1miqxdc",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "miraska_",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqxdc/running_qwen25coder32bq6gguf_entirely_on_cpu/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqxdc/running_qwen25coder32bq6gguf_entirely_on_cpu/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754441954,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "From: https://artificialanalysis.ai/",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Aggregated gpt-oss benchmarks",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 138,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqw54",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": "transparent",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/aa8ZSvUaonhxQPXCG9hmdyB0zZmXOfgXRLbVC6vdOI4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754441854,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From: &lt;a href=\"https://artificialanalysis.ai/\"&gt;https://artificialanalysis.ai/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/uvf0s0vdsahf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?auto=webp&amp;s=18c49cae126caac5d4b28358b449a2f393fe30d7",
                  "width": 2048,
                  "height": 2033
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9db28130facf42f9f8d8a7362eba214e2c0e2b51",
                    "width": 108,
                    "height": 107
                  },
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b30f14e1c56ff9e13855dde6991d368892f206d",
                    "width": 216,
                    "height": 214
                  },
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=77c7f5d5a40c547cfc04a50f51b32b3b82070739",
                    "width": 320,
                    "height": 317
                  },
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab3ed914600f9ffd4555c064c6964834c2f66c5d",
                    "width": 640,
                    "height": 635
                  },
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5ee5e4bbc9988a3f5b81f908feaf8f1f5852ab6",
                    "width": 960,
                    "height": 952
                  },
                  {
                    "url": "https://preview.redd.it/uvf0s0vdsahf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b9254d1a65471a2c16c3e4b8af2727121bb13fa",
                    "width": 1080,
                    "height": 1072
                  }
                ],
                "variants": {},
                "id": "IU2amUl3Zs5hiixrGjkn67l415TU_tCysnyg2egIQus"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miqw54",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1miqw54/aggregated_gptoss_benchmarks/",
          "stickied": false,
          "url": "https://i.redd.it/uvf0s0vdsahf1.jpeg",
          "subreddit_subscribers": 511363,
          "created_utc": 1754441854,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Isn't Kimi-K2-Instruct the most recent? If so, then what's Kimi-Latest and why is it so expensive? And why would Kimi K2 Fast be more expensive than Kimi-K2-Instruct? Unless it's just trying to say it's the same model on a faster rig.",
          "author_fullname": "t2_14fcwv",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What is the difference between these Kimi-K2 models? (From NanoGPT)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 28,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqv9l",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": "#bbbdbf",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "1c60b73a-72f2-11ee-bdcc-8e2a7b94d6a0",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/ETX4jDZEHFVkcLidHsBlYinHyghjl4RHSq8vd1Tf3VM.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "textgen web UI"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754441785,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Isn&amp;#39;t Kimi-K2-Instruct the most recent? If so, then what&amp;#39;s Kimi-Latest and why is it so expensive? And why would Kimi K2 Fast be more expensive than Kimi-K2-Instruct? Unless it&amp;#39;s just trying to say it&amp;#39;s the same model on a faster rig.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/v2m6ayrurahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/v2m6ayrurahf1.png?auto=webp&amp;s=cf607d6f9734d5e8092d8a9417f24163b294a2cf",
                  "width": 2551,
                  "height": 512
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1880b2cc6267dc0a2930a0ed47d3a24c9d111f5",
                    "width": 108,
                    "height": 21
                  },
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=076d0a139c1c6d44fbeec2ac248c4882889a589a",
                    "width": 216,
                    "height": 43
                  },
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4e8b72b95587471cc4d3e351bb07ae24655a4fe",
                    "width": 320,
                    "height": 64
                  },
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ce8612c6b999200cdb70f0a9188d5ee4801dc3f",
                    "width": 640,
                    "height": 128
                  },
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=16d3a372045905e68d3910af6b1036dabc903b62",
                    "width": 960,
                    "height": 192
                  },
                  {
                    "url": "https://preview.redd.it/v2m6ayrurahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79fbd8561dfe61978def11f19f53ead96f52275c",
                    "width": 1080,
                    "height": 216
                  }
                ],
                "variants": {},
                "id": "GrLWBN5g8dGEWQQOfDq_WeecWGPcVoycmBi2f7OZQdQ"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "textgen web UI",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1miqv9l",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ReMeDyIII",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1miqv9l/what_is_the_difference_between_these_kimik2/",
          "stickied": false,
          "url": "https://i.redd.it/v2m6ayrurahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754441785,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Interesting analysis thread: https://x.com/artificialanlys/status/1952887733803991070",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "gpt-oss-120B most intelligent model that fits on a single H100 in native precision",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 71,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "dpzvl2p3sahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 49,
                  "x": 108,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e7473690833fe0e39a07ac83e89c6d0f6b7b27f"
                },
                {
                  "y": 98,
                  "x": 216,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83e93c9dd5d47df316e95edb2292f5a6a5091e23"
                },
                {
                  "y": 146,
                  "x": 320,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63d80b0a2dd384b96d7903aec3ab6b9721410440"
                },
                {
                  "y": 292,
                  "x": 640,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f8a5cdfbdcd2ab97c4418c73a2d2a0773f964c5"
                },
                {
                  "y": 439,
                  "x": 960,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=efbcb8fa29c2a67f7ffaa3d1c1c6cbebe61e4c17"
                },
                {
                  "y": 494,
                  "x": 1080,
                  "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a942a2ba4b2440e42a0a1437f449c04b54babbe1"
                }
              ],
              "s": {
                "y": 937,
                "x": 2048,
                "u": "https://preview.redd.it/dpzvl2p3sahf1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=a19a8f0106f41e6bb43ddcad7d87fe6f8deae7e1"
              },
              "id": "dpzvl2p3sahf1"
            },
            "ebkya4p3sahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 55,
                  "x": 108,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6d038cf936f5021097db9c730b7687bd8ca8cd9"
                },
                {
                  "y": 110,
                  "x": 216,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ce956009db834dcb698b6eb5bf74b0d6fa796fa6"
                },
                {
                  "y": 164,
                  "x": 320,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6b4516bd964d524ada4830ab63cd7412e6c5570a"
                },
                {
                  "y": 328,
                  "x": 640,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f82feabfc145a5e784aa49b984898a50a37f5663"
                },
                {
                  "y": 492,
                  "x": 960,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e83f0e47f3a43af04328b7155123130dc35a98c"
                },
                {
                  "y": 554,
                  "x": 1080,
                  "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=364cd0b9e6611d8439f4565dab7b0471341d54d9"
                }
              ],
              "s": {
                "y": 1051,
                "x": 2048,
                "u": "https://preview.redd.it/ebkya4p3sahf1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=fa26d7bc4703b2d2cd46903d100d285ce712afce"
              },
              "id": "ebkya4p3sahf1"
            }
          },
          "name": "t3_1miquy8",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.86,
          "author_flair_background_color": "transparent",
          "ups": 5,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "ebkya4p3sahf1",
                "id": 722170772
              },
              {
                "media_id": "dpzvl2p3sahf1",
                "id": 722170773
              }
            ]
          },
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/kyXTn28y1tAmnc_8U0wiFCHXcHi8sY_VKspmKlI2Zi0.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754441759,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interesting analysis thread: &lt;a href=\"https://x.com/artificialanlys/status/1952887733803991070\"&gt;https://x.com/artificialanlys/status/1952887733803991070&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1miquy8",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miquy8",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1miquy8/gptoss120b_most_intelligent_model_that_fits_on_a/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1miquy8",
          "subreddit_subscribers": 511363,
          "created_utc": 1754441759,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "The benchmarks seem really promising but I’m wondering how it actually performs compared to some of the other SOTA open source llms.",
          "author_fullname": "t2_8kbjrt7z",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Anyone test the gpt-oss-120b model yet? How is its real world performance?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqu6b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754441699,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The benchmarks seem really promising but I’m wondering how it actually performs compared to some of the other SOTA open source llms.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miqu6b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Euphoric_Ad9500",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754441699,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_5gebp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Running OpenAI’s GPT-OSS locally: the good, the bad, and the loopy",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqk3e",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1754440927,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "blog.tymscar.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://blog.tymscar.com/posts/gptoss/",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1miqk3e",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "tymscar",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqk3e/running_openais_gptoss_locally_the_good_the_bad/",
          "stickied": false,
          "url": "https://blog.tymscar.com/posts/gptoss/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754440927,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "About a year ago, through the magic of Craigslist, I got myself an old HPE Gen9 (old Xeon server from 2015-2016). Shopped aggressively on eBay and ultimately built a machine with 4 Nvidia Tesla P40s (96gb total VRAM), for just about $1,000. I've been using it as my junkyard AI lab ever since.\n\nGot it to ran gpt-oss 120b today using llama.cpp's PR for that. So far I feel this is the best application of my junkyard machine. I'm seeing ~25 tokens/second on generations with ~10k tokens of prompt.\n\nWould love to see other people's experiences with old equipment like this.",
          "author_fullname": "t2_a14f8oqm",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss 120b on Nvidia P40",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miqfi7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754440587,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About a year ago, through the magic of Craigslist, I got myself an old HPE Gen9 (old Xeon server from 2015-2016). Shopped aggressively on eBay and ultimately built a machine with 4 Nvidia Tesla P40s (96gb total VRAM), for just about $1,000. I&amp;#39;ve been using it as my junkyard AI lab ever since.&lt;/p&gt;\n\n&lt;p&gt;Got it to ran gpt-oss 120b today using llama.cpp&amp;#39;s PR for that. So far I feel this is the best application of my junkyard machine. I&amp;#39;m seeing ~25 tokens/second on generations with ~10k tokens of prompt.&lt;/p&gt;\n\n&lt;p&gt;Would love to see other people&amp;#39;s experiences with old equipment like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miqfi7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Antique_Juggernaut_7",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqfi7/gptoss_120b_on_nvidia_p40/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqfi7/gptoss_120b_on_nvidia_p40/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754440587,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b\n\nEvery time answering the question, Gpt-oss will check whether it contains disallowed content(explicit/violent/illegal content),and ”according to policy, we must refuse“.",
          "author_fullname": "t2_u398xzta",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "The openai gpt-oss model is too safe!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 65,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "g4ih1pz7nahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 50,
                  "x": 108,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9a41e96ba97c60bf30ebfb35c5be98e4cd585cc"
                },
                {
                  "y": 101,
                  "x": 216,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=de00c769617f01054d6902e10ed390dc848b849b"
                },
                {
                  "y": 150,
                  "x": 320,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c108ee6407b5bc148c9906c3d9774c13681f315c"
                },
                {
                  "y": 301,
                  "x": 640,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea182f8586233d5ec30c227e64d9346bf0fb1b28"
                },
                {
                  "y": 452,
                  "x": 960,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c06abd8e6412ffea246a11801d589d13f657482"
                },
                {
                  "y": 508,
                  "x": 1080,
                  "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4334cd9e97db0e15810d020eec915d3a999ab2ce"
                }
              ],
              "s": {
                "y": 849,
                "x": 1802,
                "u": "https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b"
              },
              "id": "g4ih1pz7nahf1"
            }
          },
          "name": "t3_1miqbyk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.7,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/9AYqrIhNJjW4c44_58a53bBAstFq2WK6RLkfAreEYV8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754440319,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b\"&gt;https://preview.redd.it/g4ih1pz7nahf1.png?width=1802&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=82a72c2f8fe6b14c02fca081598119fc4e0ea67b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Every time answering the question, Gpt-oss will check whether it contains disallowed content(explicit/violent/illegal content),and ”according to policy, we must refuse“.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miqbyk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "sunshinecheung",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqbyk/the_openai_gptoss_model_is_too_safe/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754440319,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "&gt;This adds support for easily running Codex backed by a local Ollama instance running our new open source models. See [https://github.com/openai/gpt-oss](https://github.com/openai/gpt-oss) for details.\n\n&gt;If you pass in `--oss` you'll be prompted to install/launch ollama, and it will automatically download the 20b model and attempt to use it.\n\n&gt;We'll likely want to expand this with some options later to make the experience smoother for users who can't run the 20b or want to run the 120b.\n\nFinally! From the README.md:\n\nCodex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the `--oss` flag:\n\n* Interactive UI:\n   * codex --oss\n* Non-interactive (programmatic) mode:\n   * echo \"Refactor utils\" | codex exec --oss\n\nModel selection when using `--oss`:\n\n* If you omit `-m/--model`, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).\n* To pick a different size, pass one of:\n   * \\-m \"gpt-oss:20b\"\n   * \\-m \"gpt-oss:120b\"\n\nPoint Codex at your own OSS host:\n\n* By default, `--oss` talks to [http://localhost:11434/v1](http://localhost:11434/v1).\n* To use a different host, set one of these environment variables before running Codex:\n   * CODEX\\_OSS\\_BASE\\_URL, for example:\n      * CODEX\\_OSS\\_BASE\\_URL=\"[http://my-ollama.example.com:11434/v1](http://my-ollama.example.com:11434/v1)\" codex --oss -m gpt-oss:20b\n   * or CODEX\\_OSS\\_PORT (when the host is localhost):\n      * CODEX\\_OSS\\_PORT=11434 codex --oss",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS Support Merged into Codex",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miq7sp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": "transparent",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=2b090249ceaf6e7f45d71434f6c8c062b73ae6f7",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754440006,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;This adds support for easily running Codex backed by a local Ollama instance running our new open source models. See &lt;a href=\"https://github.com/openai/gpt-oss\"&gt;https://github.com/openai/gpt-oss&lt;/a&gt; for details.&lt;/p&gt;\n\n&lt;p&gt;If you pass in &lt;code&gt;--oss&lt;/code&gt; you&amp;#39;ll be prompted to install/launch ollama, and it will automatically download the 20b model and attempt to use it.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll likely want to expand this with some options later to make the experience smoother for users who can&amp;#39;t run the 20b or want to run the 120b.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Finally! From the README.md:&lt;/p&gt;\n\n&lt;p&gt;Codex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the &lt;code&gt;--oss&lt;/code&gt; flag:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Interactive UI:\n\n&lt;ul&gt;\n&lt;li&gt;codex --oss&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Non-interactive (programmatic) mode:\n\n&lt;ul&gt;\n&lt;li&gt;echo &amp;quot;Refactor utils&amp;quot; | codex exec --oss&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Model selection when using &lt;code&gt;--oss&lt;/code&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If you omit &lt;code&gt;-m/--model&lt;/code&gt;, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).&lt;/li&gt;\n&lt;li&gt;To pick a different size, pass one of:\n\n&lt;ul&gt;\n&lt;li&gt;-m &amp;quot;gpt-oss:20b&amp;quot;&lt;/li&gt;\n&lt;li&gt;-m &amp;quot;gpt-oss:120b&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Point Codex at your own OSS host:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;By default, &lt;code&gt;--oss&lt;/code&gt; talks to &lt;a href=\"http://localhost:11434/v1\"&gt;http://localhost:11434/v1&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;To use a different host, set one of these environment variables before running Codex:\n\n&lt;ul&gt;\n&lt;li&gt;CODEX_OSS_BASE_URL, for example:\n\n&lt;ul&gt;\n&lt;li&gt;CODEX_OSS_BASE_URL=&amp;quot;&lt;a href=\"http://my-ollama.example.com:11434/v1\"&gt;http://my-ollama.example.com:11434/v1&lt;/a&gt;&amp;quot; codex --oss -m gpt-oss:20b&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;or CODEX_OSS_PORT (when the host is localhost):\n\n&lt;ul&gt;\n&lt;li&gt;CODEX_OSS_PORT=11434 codex --oss&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/openai/codex/pull/1848",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?auto=webp&amp;s=111697d4c518f33761436131a56881604a6d040f",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a5c7865804f46b4afc776363f3b853726fb06d9",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b48a2dd354b66540c5e096cff83ae8ab061e8f1",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf379a221fdcbf6104b2087851df9d810fbc8f84",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9f9b264f3311e8171e53bf5722ada5dc146a2f9",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9dc794e9546dc84124b6f3c6ebb6e368924da087",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=81faaee50132740f70b7bd507f4dd6bd71a8e9e6",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "Vjq3Wm4TP-8aGogiesDe7829v5kwcywPCEB_nkJJ3bU"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miq7sp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1miq7sp/gptoss_support_merged_into_codex/",
          "stickied": false,
          "url": "https://github.com/openai/codex/pull/1848",
          "subreddit_subscribers": 511363,
          "created_utc": 1754440006,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I have this M4 chip sitting around in the dust, i really want to try the models, my laptop is low spec and even lags chrome\n\ni really want to use this m4 for some actual purposes, please help. ",
          "author_fullname": "t2_jqeoai5z",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How can we run models on IpadOS??",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miq6y3",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754439945,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have this M4 chip sitting around in the dust, i really want to try the models, my laptop is low spec and even lags chrome&lt;/p&gt;\n\n&lt;p&gt;i really want to use this m4 for some actual purposes, please help. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1miq6y3",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Fun_Highway9504",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miq6y3/how_can_we_run_models_on_ipados/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miq6y3/how_can_we_run_models_on_ipados/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754439945,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "**Full specs**:\n\n**GPU**: RTX 4070 TI Super (16 GB VRAM)\n\n**CPU**: i7 14700K\n\n**System RAM**: 96 GB DDR5 @ 6200 MT/s (total usage, including all Windows processes, is 61 GB, so only having 64GB RAM is probably sufficient)\n\n**OS**: Windows 11\n\n**Model runner**: LM Studio (see settings in third screenshot)\n\n  \nWhen I saw that OpenAI released a 120b parameter model, my assumption was that running it wouldn't be realistic for people with consumer-grade hardware. After some experimentation, I was *partly* proven wrong- 13 t/s is a speed that I'd consider \"usable\" on days where I'm feeling relatively patient. I'd imagine that people running RTX 5090's and/or faster system RAM are getting speeds that are truly usable for a lot of people, a lot of the time. If anyone has this setup, I'd love to hear what kind of speeds you're getting. ",
          "author_fullname": "t2_1t2n2s9f",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "gpt-oss-120b performance with only 16 GB VRAM- surprisingly decent",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 114,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "i0atmotcgahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 88,
                  "x": 108,
                  "u": "https://preview.redd.it/i0atmotcgahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ae2fdd72226ff436307c407112f2825a6a2885d"
                },
                {
                  "y": 176,
                  "x": 216,
                  "u": "https://preview.redd.it/i0atmotcgahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b006d9e18fb382960d218f8475eda8d6af7a4e5"
                },
                {
                  "y": 262,
                  "x": 320,
                  "u": "https://preview.redd.it/i0atmotcgahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2334591ddfde6c24b6127e8e024c358eb7c96f23"
                }
              ],
              "s": {
                "y": 344,
                "x": 420,
                "u": "https://preview.redd.it/i0atmotcgahf1.png?width=420&amp;format=png&amp;auto=webp&amp;s=82d5ca666a8ad3f6bc713112ec84cd299bb4abc7"
              },
              "id": "i0atmotcgahf1"
            },
            "i1yjttaggahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 147,
                  "x": 108,
                  "u": "https://preview.redd.it/i1yjttaggahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=139ffdbef2afdfb2f27c515606e13b62126698ba"
                },
                {
                  "y": 295,
                  "x": 216,
                  "u": "https://preview.redd.it/i1yjttaggahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=89d9ce76d1ff7eebf94964ec2de7f9b6d5ce8060"
                },
                {
                  "y": 437,
                  "x": 320,
                  "u": "https://preview.redd.it/i1yjttaggahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c6c628f2b1dab58f75b68c746437470e5a64e628"
                }
              ],
              "s": {
                "y": 592,
                "x": 433,
                "u": "https://preview.redd.it/i1yjttaggahf1.png?width=433&amp;format=png&amp;auto=webp&amp;s=bf4c25d2d3d63ecc3d632e14af48ae2fdd260edd"
              },
              "id": "i1yjttaggahf1"
            },
            "uin3n9rjgahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 60,
                  "x": 108,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8f6a117776c5a38995291509599b083970cbab99"
                },
                {
                  "y": 120,
                  "x": 216,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ac27f81fd04f331e34425b0686ef826313fd641"
                },
                {
                  "y": 178,
                  "x": 320,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a9f2eeac062cba3d74ea30788fd59f2b770f304"
                },
                {
                  "y": 356,
                  "x": 640,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b812cd15ad1a75cfab386d5c7ee8b7720cb298d7"
                },
                {
                  "y": 534,
                  "x": 960,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7b252d0d7d01a708c51fb555d6da0ba7a275e22"
                },
                {
                  "y": 601,
                  "x": 1080,
                  "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=894f3af2e68991bca0d2b8352c7e80d3e3d0871a"
                }
              ],
              "s": {
                "y": 684,
                "x": 1229,
                "u": "https://preview.redd.it/uin3n9rjgahf1.png?width=1229&amp;format=png&amp;auto=webp&amp;s=b28d0dca527df3e3dac4939295d592c858f6aec2"
              },
              "id": "uin3n9rjgahf1"
            }
          },
          "name": "t3_1miprwe",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.74,
          "author_flair_background_color": null,
          "ups": 11,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "i0atmotcgahf1",
                "id": 722144194
              },
              {
                "media_id": "i1yjttaggahf1",
                "id": 722144195
              },
              {
                "media_id": "uin3n9rjgahf1",
                "id": 722144196
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 11,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3XwIvatwftLg0e--y7jCH8mLR2VOGeduF77wVTFjpug.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754438808,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Full specs&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GPU&lt;/strong&gt;: RTX 4070 TI Super (16 GB VRAM)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;CPU&lt;/strong&gt;: i7 14700K&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;System RAM&lt;/strong&gt;: 96 GB DDR5 @ 6200 MT/s (total usage, including all Windows processes, is 61 GB, so only having 64GB RAM is probably sufficient)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;OS&lt;/strong&gt;: Windows 11&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Model runner&lt;/strong&gt;: LM Studio (see settings in third screenshot)&lt;/p&gt;\n\n&lt;p&gt;When I saw that OpenAI released a 120b parameter model, my assumption was that running it wouldn&amp;#39;t be realistic for people with consumer-grade hardware. After some experimentation, I was &lt;em&gt;partly&lt;/em&gt; proven wrong- 13 t/s is a speed that I&amp;#39;d consider &amp;quot;usable&amp;quot; on days where I&amp;#39;m feeling relatively patient. I&amp;#39;d imagine that people running RTX 5090&amp;#39;s and/or faster system RAM are getting speeds that are truly usable for a lot of people, a lot of the time. If anyone has this setup, I&amp;#39;d love to hear what kind of speeds you&amp;#39;re getting. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1miprwe",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1miprwe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "gigaflops_",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miprwe/gptoss120b_performance_with_only_16_gb_vram/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1miprwe",
          "subreddit_subscribers": 511363,
          "created_utc": 1754438808,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[Windows Cuda 1.45.0 \\(Not Cuda 12!\\)](https://preview.redd.it/604fqlijgahf1.png?width=464&amp;format=png&amp;auto=webp&amp;s=a23e1aa7f34f3c14c33b1167bdbeaec20c4a4905)\n\n**The Cuda 12 ver 1.44.0 do not support GLM-4.5-AIR:**\n\nhttps://preview.redd.it/pzmxer3shahf1.png?width=444&amp;format=png&amp;auto=webp&amp;s=62827136dd50d356fcc199ca5cadb958f7370ae6\n\n  \n**Ver: LM Studio 0.3.21 (Build 4) - Beta**\n\n**GLM-4.5-AIR-Q4\\_K\\_XL - UnSloth**  \n\n\nhttps://preview.redd.it/f7ow8z50hahf1.png?width=1083&amp;format=png&amp;auto=webp&amp;s=4c28aef56171182da14f6d415f7c272bd21d83c5\n\nhttps://preview.redd.it/fo4nqtu4iahf1.png?width=490&amp;format=png&amp;auto=webp&amp;s=e79dcb312290f97839548de85d8fb3765c24f4e5\n\nBut it's slow af with RTX 3090.  \n",
          "author_fullname": "t2_ti5m9mpc",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "🍃 GLM-4.5-AIR - LmStudio Windows Unlocked !",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 24,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "fo4nqtu4iahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 27,
                  "x": 108,
                  "u": "https://preview.redd.it/fo4nqtu4iahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=01c1011b57576095b560ff584f65a922f4997443"
                },
                {
                  "y": 55,
                  "x": 216,
                  "u": "https://preview.redd.it/fo4nqtu4iahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5827b5f9c28ff5d4c54e0d31298037627e30af9a"
                },
                {
                  "y": 82,
                  "x": 320,
                  "u": "https://preview.redd.it/fo4nqtu4iahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c214da098c770cd0d607166174f64925442ef8b0"
                }
              ],
              "s": {
                "y": 126,
                "x": 490,
                "u": "https://preview.redd.it/fo4nqtu4iahf1.png?width=490&amp;format=png&amp;auto=webp&amp;s=e79dcb312290f97839548de85d8fb3765c24f4e5"
              },
              "id": "fo4nqtu4iahf1"
            },
            "pzmxer3shahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 31,
                  "x": 108,
                  "u": "https://preview.redd.it/pzmxer3shahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a3b90a53256968099e24be72f28fdea1ce3997b3"
                },
                {
                  "y": 63,
                  "x": 216,
                  "u": "https://preview.redd.it/pzmxer3shahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c99eef3b0c595aaaad7eb13244d97cded7307568"
                },
                {
                  "y": 94,
                  "x": 320,
                  "u": "https://preview.redd.it/pzmxer3shahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce73123af8f8d50bbb90b2e72522c64ad6532ab6"
                }
              ],
              "s": {
                "y": 131,
                "x": 444,
                "u": "https://preview.redd.it/pzmxer3shahf1.png?width=444&amp;format=png&amp;auto=webp&amp;s=62827136dd50d356fcc199ca5cadb958f7370ae6"
              },
              "id": "pzmxer3shahf1"
            },
            "604fqlijgahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 18,
                  "x": 108,
                  "u": "https://preview.redd.it/604fqlijgahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=36e94d443abf8783c10546c948f543f108098df7"
                },
                {
                  "y": 37,
                  "x": 216,
                  "u": "https://preview.redd.it/604fqlijgahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cbfe6532c35d034cbbbcd6433b5404979f1f4793"
                },
                {
                  "y": 55,
                  "x": 320,
                  "u": "https://preview.redd.it/604fqlijgahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=67350cfb52ab8d39c5ec648f3f39e8893ed25f17"
                }
              ],
              "s": {
                "y": 80,
                "x": 464,
                "u": "https://preview.redd.it/604fqlijgahf1.png?width=464&amp;format=png&amp;auto=webp&amp;s=a23e1aa7f34f3c14c33b1167bdbeaec20c4a4905"
              },
              "id": "604fqlijgahf1"
            },
            "f7ow8z50hahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 44,
                  "x": 108,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7badd4bf8ae3c3ee8eb75f412e3f75a8343eeb32"
                },
                {
                  "y": 88,
                  "x": 216,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ea0a05c5847e78286e5c2c3db89ee65878b7123b"
                },
                {
                  "y": 131,
                  "x": 320,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=031eeb0f1d0f9d98a6a562a55ccbbeadf18e514e"
                },
                {
                  "y": 262,
                  "x": 640,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=07f40316977a064b0509fc656d5f59f38b56377b"
                },
                {
                  "y": 394,
                  "x": 960,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa3c1944fb3744aec13d48533d1eb4eb745262d8"
                },
                {
                  "y": 443,
                  "x": 1080,
                  "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=af820a2dc156638f6a2c2e4455d1a7229d549de0"
                }
              ],
              "s": {
                "y": 445,
                "x": 1083,
                "u": "https://preview.redd.it/f7ow8z50hahf1.png?width=1083&amp;format=png&amp;auto=webp&amp;s=4c28aef56171182da14f6d415f7c272bd21d83c5"
              },
              "id": "f7ow8z50hahf1"
            }
          },
          "name": "t3_1mipnte",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/YTAya9ym3-oD0YR6AjDDqp6FjwK2l4sgsia5bCj1bq4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754438509,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/604fqlijgahf1.png?width=464&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a23e1aa7f34f3c14c33b1167bdbeaec20c4a4905\"&gt;Windows Cuda 1.45.0 (Not Cuda 12!)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Cuda 12 ver 1.44.0 do not support GLM-4.5-AIR:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pzmxer3shahf1.png?width=444&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=62827136dd50d356fcc199ca5cadb958f7370ae6\"&gt;https://preview.redd.it/pzmxer3shahf1.png?width=444&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=62827136dd50d356fcc199ca5cadb958f7370ae6&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Ver: LM Studio 0.3.21 (Build 4) - Beta&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GLM-4.5-AIR-Q4_K_XL - UnSloth&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f7ow8z50hahf1.png?width=1083&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c28aef56171182da14f6d415f7c272bd21d83c5\"&gt;https://preview.redd.it/f7ow8z50hahf1.png?width=1083&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c28aef56171182da14f6d415f7c272bd21d83c5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fo4nqtu4iahf1.png?width=490&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e79dcb312290f97839548de85d8fb3765c24f4e5\"&gt;https://preview.redd.it/fo4nqtu4iahf1.png?width=490&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e79dcb312290f97839548de85d8fb3765c24f4e5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s slow af with RTX 3090.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mipnte",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Ok_Ninja7526",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mipnte/glm45air_lmstudio_windows_unlocked/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mipnte/glm45air_lmstudio_windows_unlocked/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754438509,
          "num_crossposts": 4,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I distilled a coding model and I want to know how to do a proper benchmark, and not do the typical ones that are used for benchmaxxing. ",
          "author_fullname": "t2_zws5yqyow",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What's a good way to benchmark a model without doing the useless benchmarks",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mipm3s",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754438390,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I distilled a coding model and I want to know how to do a proper benchmark, and not do the typical ones that are used for benchmaxxing. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mipm3s",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Commercial-Celery769",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mipm3s/whats_a_good_way_to_benchmark_a_model_without/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mipm3s/whats_a_good_way_to_benchmark_a_model_without/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754438390,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It is difficult to trust the benchmarks when it comes to math skills, I've found - I'd be interested to hear the community's impressions on this.  \nEDIT - I'm asking specifically about open source models",
          "author_fullname": "t2_47ws19uq",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Which of the current models are you finding to be best at math and statistics related reasoning?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mipcgr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754439181,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754437679,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is difficult to trust the benchmarks when it comes to math skills, I&amp;#39;ve found - I&amp;#39;d be interested to hear the community&amp;#39;s impressions on this.&lt;br/&gt;\nEDIT - I&amp;#39;m asking specifically about open source models&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mipcgr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "seoulsrvr",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mipcgr/which_of_the_current_models_are_you_finding_to_be/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mipcgr/which_of_the_current_models_are_you_finding_to_be/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437679,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4p7o5",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Real time vibe coding with openai/gpt-oss-120b (resources in comments!)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Generation"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mipahr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.64,
          "author_flair_background_color": null,
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/qrpl1h09fahf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1074,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/qrpl1h09fahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/qrpl1h09fahf1/DASHPlaylist.mpd?a=1757034803%2CODNlOTczNmEwZDY0YzE1N2M2MTIwOGViNmRkNzNmZjJjZjlhNDA5OWQ2NmQ2Yzg0MTg4YzliODMyMDI4NDU4OA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 35,
              "hls_url": "https://v.redd.it/qrpl1h09fahf1/HLSPlaylist.m3u8?a=1757034803%2CMzU4NDMzZWZhZDg4OWU0NWI3NzYzMzdhNTM4NmU5YWE1MTZmY2U5MTRlOTc4M2RhOWVjZDNiMDNiMWZlZmZjNA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Generation",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=0017224e7543476b97282ad25767a0d71ddd06fc",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754437538,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/qrpl1h09fahf1",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?format=pjpg&amp;auto=webp&amp;s=5cefaa309eb660a925ad061e572eff5ecac5fc22",
                  "width": 2972,
                  "height": 1664
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=14b3d16843d76046c914058a64050f087e24533a",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8cf56583b3c72eda214b22c6fb1c72aa197f5a87",
                    "width": 216,
                    "height": 120
                  },
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=178501f985af0bcab71797018b826d80839de0f0",
                    "width": 320,
                    "height": 179
                  },
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=61f4987e53735e8200b0748ca4835e6b032455b3",
                    "width": 640,
                    "height": 358
                  },
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ab74e8ad5f611b2e58a638c6ae9215c718aa490b",
                    "width": 960,
                    "height": 537
                  },
                  {
                    "url": "https://external-preview.redd.it/OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c737decaaa82ee622e17f3c140c1d15e4299e91f",
                    "width": 1080,
                    "height": 604
                  }
                ],
                "variants": {},
                "id": "OTRoc2cxejhmYWhmMRdfj0SxUSrkmQM1JYs8HmICSn7G3sGk4chHW3PQpR3h"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "23bddba8-ff56-11ed-9688-1a11994b71f7",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#b5a3d0",
          "id": "1mipahr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "bakaasama",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mipahr/real_time_vibe_coding_with_openaigptoss120b/",
          "stickied": false,
          "url": "https://v.redd.it/qrpl1h09fahf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437538,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/qrpl1h09fahf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1074,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/qrpl1h09fahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/qrpl1h09fahf1/DASHPlaylist.mpd?a=1757034803%2CODNlOTczNmEwZDY0YzE1N2M2MTIwOGViNmRkNzNmZjJjZjlhNDA5OWQ2NmQ2Yzg0MTg4YzliODMyMDI4NDU4OA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 35,
              "hls_url": "https://v.redd.it/qrpl1h09fahf1/HLSPlaylist.m3u8?a=1757034803%2CMzU4NDMzZWZhZDg4OWU0NWI3NzYzMzdhNTM4NmU5YWE1MTZmY2U5MTRlOTc4M2RhOWVjZDNiMDNiMWZlZmZjNA%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Alright, OpenAI finally released their long-awaited open-weight model. And, by their own admission, this model matches or surpasses GPT-o3 and o4-mini and is highly customizable. All good and dandy.\n\nBut here's the twist.\n\nWhile they encourage **local customization and autonomy** right out of the gate, they had to bake in **guardrails** (aka telemetry). Some of them, like Biological, Chemical and Cyber capabilities, are understandable. But they also included \"No AI Self-Improvement\" (see below image). WTF is that all about? Are they afraid some local loonies will spark AI sentience in their garage?\n\n[gpt-oss-120b &amp; gpt-oss-20b Model Card \\(https:\\/\\/openai.com\\/index\\/gpt-oss-model-card\\/?utm\\_source=chatgpt.com\\)](https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;format=png&amp;auto=webp&amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0)",
          "author_fullname": "t2_cna812e",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI Releases gpt-oss-120b with This Warning: No AI Self-Improvement (Like What??)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 64,
          "top_awarded_type": null,
          "hide_score": true,
          "media_metadata": {
            "oh9o1124dahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 50,
                  "x": 108,
                  "u": "https://preview.redd.it/oh9o1124dahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7144afa2fd7f9e49d9fbfb18a83ffa94273c1e4"
                },
                {
                  "y": 100,
                  "x": 216,
                  "u": "https://preview.redd.it/oh9o1124dahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=015c7d97ffbb0d722cd13538f0c4438b553e3a87"
                },
                {
                  "y": 148,
                  "x": 320,
                  "u": "https://preview.redd.it/oh9o1124dahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f2189301a9da21c386f2c11f82d1f39c8fdf919"
                },
                {
                  "y": 296,
                  "x": 640,
                  "u": "https://preview.redd.it/oh9o1124dahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6beca9fdafa01ab6e390fdfaf53a73a20a90123e"
                }
              ],
              "s": {
                "y": 352,
                "x": 760,
                "u": "https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;format=png&amp;auto=webp&amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0"
              },
              "id": "oh9o1124dahf1"
            }
          },
          "name": "t3_1mipaft",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.58,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/FAqhmYjy7P9wFDjBnzVIDWLwelMou0qj66AJNyTGUZU.jpg",
          "edited": 1754437719,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754437534,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright, OpenAI finally released their long-awaited open-weight model. And, by their own admission, this model matches or surpasses GPT-o3 and o4-mini and is highly customizable. All good and dandy.&lt;/p&gt;\n\n&lt;p&gt;But here&amp;#39;s the twist.&lt;/p&gt;\n\n&lt;p&gt;While they encourage &lt;strong&gt;local customization and autonomy&lt;/strong&gt; right out of the gate, they had to bake in &lt;strong&gt;guardrails&lt;/strong&gt; (aka telemetry). Some of them, like Biological, Chemical and Cyber capabilities, are understandable. But they also included &amp;quot;No AI Self-Improvement&amp;quot; (see below image). WTF is that all about? Are they afraid some local loonies will spark AI sentience in their garage?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0\"&gt;gpt-oss-120b &amp;amp; gpt-oss-20b Model Card (https://openai.com/index/gpt-oss-model-card/?utm_source=chatgpt.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mipaft",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "sourdub",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437534,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_j1kqr",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Trying NSFW on the OAI OSS model is fun sometimes.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 80,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mip7ds",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": "#bbbdbf",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/u9WuEYAKURbSmzVg7NLoy5DSXfQL8tmcSvZYhumzypA.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "Llama 405B"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754437315,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/25nt59vteahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/25nt59vteahf1.png?auto=webp&amp;s=c679a81790c994660a4775c3b5110b54a9534656",
                  "width": 1235,
                  "height": 713
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca427c6c459e350da52eeecaed5690cb07dfc683",
                    "width": 108,
                    "height": 62
                  },
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aaec52b7c9a2c3f19c0cf8c7b3e4260dd8007ba1",
                    "width": 216,
                    "height": 124
                  },
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4213b6cbe11060e4b742cee5ccaf3f104f019e3e",
                    "width": 320,
                    "height": 184
                  },
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7bf871702f6fd2708d73d04e2f7b35597112483d",
                    "width": 640,
                    "height": 369
                  },
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=aeb9f24c86e58323405fb60a3cb919874891bf28",
                    "width": 960,
                    "height": 554
                  },
                  {
                    "url": "https://preview.redd.it/25nt59vteahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bd09fc1f78902a11677c69b1e543495dcca2d216",
                    "width": 1080,
                    "height": 623
                  }
                ],
                "variants": {},
                "id": "P_k2tYCq8IF2nIKM4P-FuYjtlZ7vwln3G-q2ukHf5b0"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "Llama 405B",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mip7ds",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "panchovix",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mip7ds/trying_nsfw_on_the_oai_oss_model_is_fun_sometimes/",
          "stickied": false,
          "url": "https://i.redd.it/25nt59vteahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437315,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hello,\n\nI'm currently considering an upgrade from my RTX 3060 Ti to the RX 7900 XT, mainly for improved performance running LLMs. My primary interest is in models like the Qwen3-30B-A3B and the newly released OpenAI GPT-OSS 20B. Since the RX 7900 XTX is almost sold out everywhere, the RX 7900 XT seems like my next best option.\n\nFor context, my current RTX 3060 Ti achieves around 20 tok/s with Qwen3-30B-A3B at Q3\\_K\\_L, and approximately 16-19 tok/s with GPT-OSS with basic short prompts in **LM Studio** with CUDA 12 llama.cpp runtime engine. Additionally, I have 32GB DDR5 RAM, which I'm planning to upgrade to 64GB or more to run these models more efficiently, and Ryzen a 5 7600X.\n\nHas anyone tested these specific models with the RX 7900 XT? If so, could you share the token generation speeds you're achieving, and whether you're using ROCm with Vulkan? Any advice or recommendations would be greatly appreciated as this information would help me finalize my decision on whether to purchase the RX 7900 XT now or wait for the availability of the RX 7900 XTX.\n\nThanks.",
          "author_fullname": "t2_ckmk0mz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "RX 7900 XT for LLMs?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mip775",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754437302,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently considering an upgrade from my RTX 3060 Ti to the RX 7900 XT, mainly for improved performance running LLMs. My primary interest is in models like the Qwen3-30B-A3B and the newly released OpenAI GPT-OSS 20B. Since the RX 7900 XTX is almost sold out everywhere, the RX 7900 XT seems like my next best option.&lt;/p&gt;\n\n&lt;p&gt;For context, my current RTX 3060 Ti achieves around 20 tok/s with Qwen3-30B-A3B at Q3_K_L, and approximately 16-19 tok/s with GPT-OSS with basic short prompts in &lt;strong&gt;LM Studio&lt;/strong&gt; with CUDA 12 llama.cpp runtime engine. Additionally, I have 32GB DDR5 RAM, which I&amp;#39;m planning to upgrade to 64GB or more to run these models more efficiently, and Ryzen a 5 7600X.&lt;/p&gt;\n\n&lt;p&gt;Has anyone tested these specific models with the RX 7900 XT? If so, could you share the token generation speeds you&amp;#39;re achieving, and whether you&amp;#39;re using ROCm with Vulkan? Any advice or recommendations would be greatly appreciated as this information would help me finalize my decision on whether to purchase the RX 7900 XT now or wait for the availability of the RX 7900 XTX.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mip775",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Reaper_9382",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mip775/rx_7900_xt_for_llms/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mip775/rx_7900_xt_for_llms/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437302,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "End of an era I guess",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 93,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mip3vn",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.22,
          "author_flair_background_color": "transparent",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/LFE7FrLn2NZKu-V8VpcSo_rQK6klSDtGkrm9T2haHJg.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754437069,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/3813hbh3eahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/3813hbh3eahf1.png?auto=webp&amp;s=cfe0425526588cff89ceb89e5d6aa65fead1e7f4",
                  "width": 1536,
                  "height": 1024
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e0ac73a8b2d5864ae92a89573fe5bc72d553b406",
                    "width": 108,
                    "height": 72
                  },
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d804ed54899ce55faccbca8b86f8a8e56d08721",
                    "width": 216,
                    "height": 144
                  },
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f3d6e7c21c9df1e413524b2d1e9bb62aa0cdba0",
                    "width": 320,
                    "height": 213
                  },
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=baf66e91be02148d5d0871465214a04a5adda6db",
                    "width": 640,
                    "height": 426
                  },
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0be4be90c9c31b1a9ee3284fb5b430f39649e395",
                    "width": 960,
                    "height": 640
                  },
                  {
                    "url": "https://preview.redd.it/3813hbh3eahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ca65803477e4651c595a445c89b5921fbcb554b",
                    "width": 1080,
                    "height": 720
                  }
                ],
                "variants": {},
                "id": "sTk3Bj1iUbeAI8HiamvnPxfOMozXuDjU_4CdkVRcHc0"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mip3vn",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mip3vn/end_of_an_era_i_guess/",
          "stickied": false,
          "url": "https://i.redd.it/3813hbh3eahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754437069,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://www.kaggle.com/benchmarks/kaggle/chess-text/versions/1/tournament](https://www.kaggle.com/benchmarks/kaggle/chess-text/versions/1/tournament)\n\nLooking forward to seeing gpt-oss-120b on there! Not happy with the current position of open weight models.",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Strong showing by OpenAI in Kaggle Game Arena Day 1",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 111,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miozqy",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.5,
          "author_flair_background_color": "transparent",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/aicrDuqxuBNkhzlC0DZZBuxULBL0vYCn6a3efHLnYCM.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754436775,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.kaggle.com/benchmarks/kaggle/chess-text/versions/1/tournament\"&gt;https://www.kaggle.com/benchmarks/kaggle/chess-text/versions/1/tournament&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Looking forward to seeing gpt-oss-120b on there! Not happy with the current position of open weight models.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ylw1aytzcahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ylw1aytzcahf1.png?auto=webp&amp;s=c61e0d0301a95d225850d931fec87d7920ff840d",
                  "width": 1834,
                  "height": 1460
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0398392dfde5f87cca42c72225fd925d4af54ff5",
                    "width": 108,
                    "height": 85
                  },
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=08432a3fe00ac4c741aa586a7d8e0b4a64891dfd",
                    "width": 216,
                    "height": 171
                  },
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c94ceb46a71f206884ac067ea7cd77a07d36478",
                    "width": 320,
                    "height": 254
                  },
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3d29fc7b439e7f504b2e94322cc70dd780f6d73",
                    "width": 640,
                    "height": 509
                  },
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=031852106401ee3baec511b8534b72f6167a7b0e",
                    "width": 960,
                    "height": 764
                  },
                  {
                    "url": "https://preview.redd.it/ylw1aytzcahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87911dea74d3603ca17f026ca11ab753c0155e83",
                    "width": 1080,
                    "height": 859
                  }
                ],
                "variants": {},
                "id": "-Yk_rn3j8zt1exKu-lhKPMaI3vLOHTATn6mXU7GF92E"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miozqy",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1miozqy/strong_showing_by_openai_in_kaggle_game_arena_day/",
          "stickied": false,
          "url": "https://i.redd.it/ylw1aytzcahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436775,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_8pgou3uq9",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "DeepMind’s Genie 3 shows Google is like 3 years ahead of China and 10 years ahead of open source—leaving everyone in the dust.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miov4l",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.29,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/fs7yvxd8cahf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1280,
              "scrubber_media_url": "https://v.redd.it/fs7yvxd8cahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/fs7yvxd8cahf1/DASHPlaylist.mpd?a=1757034803%2CMDljZDY0Mjg2MDAwZTQ0NTliMzlhNzI2NjE4MmJjYmM1ODBkNGY1YmYyNzYwOTcxOTRiODhlZWFhMzI5NzE3NA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 142,
              "hls_url": "https://v.redd.it/fs7yvxd8cahf1/HLSPlaylist.m3u8?a=1757034803%2CMGJjZDAwMWExNWZmM2YxM2UxMDJhZDU4NDZiZGIzNDFlZDY5Mjg1M2FmNzQwMTBmZDk5Yzg2NWVhZTE2MDNkOQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=ff45fe5a9b60112d2094ffcf7a404b9e90ca1311",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754436448,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/fs7yvxd8cahf1",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?format=pjpg&amp;auto=webp&amp;s=33ad1297b290c5bfbc214541c754889a7376e880",
                  "width": 1280,
                  "height": 720
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=655ac01b511bf846e437fc1d8e44b748b2594fdc",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4745b73a813765cb1b17827dcca04464f5605bcc",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2caa25f468e7a8305063c39421fb56538e177367",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2ef45568722889f480c4d625c75bf5741d6c0a44",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=82304c2395a829f82e8336345ac1e61efc690237",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f9ef25626e31b7bd2e2be8d23477c4475a8e8e7d",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "ZDI4dDF5MmJjYWhmMcECTCOhDDlv8SRxw1axECLn2eTK_ydmN2ciZAyWoibp"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miov4l",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "balianone",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miov4l/deepminds_genie_3_shows_google_is_like_3_years/",
          "stickied": false,
          "url": "https://v.redd.it/fs7yvxd8cahf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436448,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/fs7yvxd8cahf1/DASH_720.mp4?source=fallback",
              "has_audio": true,
              "height": 720,
              "width": 1280,
              "scrubber_media_url": "https://v.redd.it/fs7yvxd8cahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/fs7yvxd8cahf1/DASHPlaylist.mpd?a=1757034803%2CMDljZDY0Mjg2MDAwZTQ0NTliMzlhNzI2NjE4MmJjYmM1ODBkNGY1YmYyNzYwOTcxOTRiODhlZWFhMzI5NzE3NA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 142,
              "hls_url": "https://v.redd.it/fs7yvxd8cahf1/HLSPlaylist.m3u8?a=1757034803%2CMGJjZDAwMWExNWZmM2YxM2UxMDJhZDU4NDZiZGIzNDFlZDY5Mjg1M2FmNzQwMTBmZDk5Yzg2NWVhZTE2MDNkOQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Another one. [https://simple-bench.com/](https://simple-bench.com/)",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miotjk",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 22,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 22,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/slZPx2kenGAlzhxkZ4KeZH5vjmH3f3fIYWLTRX-XaQo.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754436341,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Another one. &lt;a href=\"https://simple-bench.com/\"&gt;https://simple-bench.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/yu8x76wnbahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/yu8x76wnbahf1.png?auto=webp&amp;s=a252360952acf8fb0d8fcc73b0ee29610a5fb4fd",
                  "width": 906,
                  "height": 1217
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=40f088e8768c33b741683caac490b28a990b5794",
                    "width": 108,
                    "height": 145
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a55fa927d4a91b9a5ccba1996153c985d4f05a2",
                    "width": 216,
                    "height": 290
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b03c14b089ffe5a77d3f1486e1fbc8b7003e23bf",
                    "width": 320,
                    "height": 429
                  },
                  {
                    "url": "https://preview.redd.it/yu8x76wnbahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c5a7c3a67a52ed6461fbbc4ed074a559a66c3df6",
                    "width": 640,
                    "height": 859
                  }
                ],
                "variants": {},
                "id": "Yk7g-iwcJye_OAwxTkg4k6gNrgKoADVulTcpXZoHJ7g"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miotjk",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 22,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/",
          "stickied": false,
          "url": "https://i.redd.it/yu8x76wnbahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436341,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://www.facebook.com/share/p/1CJEDkyAY3/",
          "author_fullname": "t2_hl2zk56w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "For you vibe coders..",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mioswc",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.14,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754436296,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.facebook.com/share/p/1CJEDkyAY3/\"&gt;https://www.facebook.com/share/p/1CJEDkyAY3/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mioswc",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Inevitable-Prior-799",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mioswc/for_you_vibe_coders/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mioswc/for_you_vibe_coders/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436296,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "So far, my use case is writing textual elements for an RPG videogame i'm developing, and its as good as qwen 30b a3b 2507 if not slightly better.\n\nHow well has this model performed for you in creative writing? Punching far above its weight class? Terrible, or just as you would expect for the size?\n\nPlease comment your use-case and your satisfaction with what OpenAI just gave us.",
          "author_fullname": "t2_1rg0qz5eci",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 20B | Performance for creative types",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mioq3p",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 4,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754436096,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far, my use case is writing textual elements for an RPG videogame i&amp;#39;m developing, and its as good as qwen 30b a3b 2507 if not slightly better.&lt;/p&gt;\n\n&lt;p&gt;How well has this model performed for you in creative writing? Punching far above its weight class? Terrible, or just as you would expect for the size?&lt;/p&gt;\n\n&lt;p&gt;Please comment your use-case and your satisfaction with what OpenAI just gave us.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mioq3p",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Temporary_Exam_3620",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mioq3p/gptoss_20b_performance_for_creative_types/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mioq3p/gptoss_20b_performance_for_creative_types/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436096,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "\n\n[View Poll](https://www.reddit.com/poll/1miopto)",
          "author_fullname": "t2_18di024ua3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Are openai's new opensource llms too censored? POLL",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1miopto",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754436078,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1miopto\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miopto",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Own-Potential-2308",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "poll_data": {
            "prediction_status": null,
            "total_stake_amount": null,
            "voting_end_timestamp": 1754608878928,
            "options": [
              {
                "text": "yes",
                "id": "31284249"
              },
              {
                "text": "no",
                "id": "31284250"
              }
            ],
            "vote_updates_remained": null,
            "is_prediction": false,
            "resolved_option_id": null,
            "user_won_amount": null,
            "user_selection": null,
            "total_vote_count": 99,
            "tournament_id": null
          },
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miopto/are_openais_new_opensource_llms_too_censored_poll/",
          "stickied": false,
          "mod_reports": [],
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miopto/are_openais_new_opensource_llms_too_censored_poll/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754436078,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_roupbc6rv",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "made these animations with llama 4",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": true,
          "name": "t3_1mioj8f",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.22,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/kwz853sr9ahf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/kwz853sr9ahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/kwz853sr9ahf1/DASHPlaylist.mpd?a=1757034803%2CODk1YTY4OTcyYTlhNGY5NTdiNzMxN2M5OTJkOGU4NDI0MTVmYWM0ODg1ZmQ0MjA4YjI3NGM3MTFkNmU2ODUxMQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 58,
              "hls_url": "https://v.redd.it/kwz853sr9ahf1/HLSPlaylist.m3u8?a=1757034803%2CZDUwMjA2OWU3N2U1ZDFhODE3ZTI1OGExNDljZjE2OTIyYTZmNzc1MTUzOWE4N2ZlNGQwOWIyNjhjNzA1ZWUwZQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=d39bf9ae9187823a43185faec3a796511175370c",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754435614,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/kwz853sr9ahf1",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?format=pjpg&amp;auto=webp&amp;s=2dfca232a765a9734891f3ae6d601a696471bd21",
                  "width": 1920,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=be099a44245599f5150e591ea052f7ace8fecceb",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c2aadedc1bc496a8f10ab0dbe6923f8066c06d9e",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=560b2e6382898671888a62e8dcbd1c8b933f2aa1",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8fcca28683c04662a175ef7ea7cbef024f11b47f",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c371d135b2ff9f99035b2aa1144084ec3729c634",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25ba41825886a6ea1d56f9513595af30a8d74f1f",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "YWJiYngyc3I5YWhmMZPV6sPwIDxqnmyGd9i_3o4X7HIYHxtmi0bhMEY5cb1t"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1mioj8f",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Witty_Side8702",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mioj8f/made_these_animations_with_llama_4/",
          "stickied": false,
          "url": "https://v.redd.it/kwz853sr9ahf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754435614,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/kwz853sr9ahf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1920,
              "scrubber_media_url": "https://v.redd.it/kwz853sr9ahf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/kwz853sr9ahf1/DASHPlaylist.mpd?a=1757034803%2CODk1YTY4OTcyYTlhNGY5NTdiNzMxN2M5OTJkOGU4NDI0MTVmYWM0ODg1ZmQ0MjA4YjI3NGM3MTFkNmU2ODUxMQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 58,
              "hls_url": "https://v.redd.it/kwz853sr9ahf1/HLSPlaylist.m3u8?a=1757034803%2CZDUwMjA2OWU3N2U1ZDFhODE3ZTI1OGExNDljZjE2OTIyYTZmNzc1MTUzOWE4N2ZlNGQwOWIyNjhjNzA1ZWUwZQ%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "After feeling horribly underwhelmed by these models, the more I look around, the more I’m noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. \n\nOur company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we’ve ever seen in the models we’ve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)",
          "author_fullname": "t2_ie4ku",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 120B and 20B feel kind of… bad?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miodyp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 62,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 62,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754435230,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After feeling horribly underwhelmed by these models, the more I look around, the more I’m noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. &lt;/p&gt;\n\n&lt;p&gt;Our company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we’ve ever seen in the models we’ve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miodyp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SlackEight",
          "discussion_type": null,
          "num_comments": 31,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754435230,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey LocalLlaMA! To celebrate the release of OpenAI GPT-OSS-120b, we're also soft-launching the coding assistant we made that works with open-source models: [https://github.com/synthetic-lab/octofriend](https://github.com/synthetic-lab/octofriend)\n\nYou can run the models locally, or use inference providers (we run [a privacy-focused one](https://synthetic.new)). One of the neat things it does differently is used custom-trained models to auto-fix diffs and JSON tool calls when models make minor mistakes; we also open-sourced the models we trained: [fix-json](https://huggingface.co/synthetic-lab/fix-json) and [diff-apply](https://huggingface.co/diff-apply). The models we trained are truly open-source: [here's the training code and synthetic data generation pipeline](https://github.com/synthetic-lab/octofriend/tree/main/training).\n\nhttps://preview.redd.it/scg0f8829ahf1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=2a811545fefdd11ad066d94dafcc64b5376e0f6c\n\nHappy open source release day :)",
          "author_fullname": "t2_k8syh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "We made Octofriend, a local-LLM-friendly coding assistant like Claude Code",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "scg0f8829ahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 108,
                  "x": 108,
                  "u": "https://preview.redd.it/scg0f8829ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d425e232bd20b1eb21b80b6aa49a2b0e9bc0523"
                },
                {
                  "y": 216,
                  "x": 216,
                  "u": "https://preview.redd.it/scg0f8829ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=00f2506d98ca3cdc70ec9223b99afb3b82fe9530"
                },
                {
                  "y": 320,
                  "x": 320,
                  "u": "https://preview.redd.it/scg0f8829ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9c622ab9197d4583d13ab6123653ea1c9b8c6b4"
                },
                {
                  "y": 640,
                  "x": 640,
                  "u": "https://preview.redd.it/scg0f8829ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2fb42713d71db731da782662a6ab314b4aedfe2e"
                },
                {
                  "y": 960,
                  "x": 960,
                  "u": "https://preview.redd.it/scg0f8829ahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f62d143eea62795af228c7bfcd37461677204f04"
                }
              ],
              "s": {
                "y": 1024,
                "x": 1024,
                "u": "https://preview.redd.it/scg0f8829ahf1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=2a811545fefdd11ad066d94dafcc64b5376e0f6c"
              },
              "id": "scg0f8829ahf1"
            }
          },
          "name": "t3_1miobog",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.82,
          "author_flair_background_color": null,
          "ups": 7,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 7,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=251328f1e7266adb159e2897d64180b6da53f961",
          "edited": 1754435623,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "subreddit_type": "public",
          "created": 1754435074,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey LocalLlaMA! To celebrate the release of OpenAI GPT-OSS-120b, we&amp;#39;re also soft-launching the coding assistant we made that works with open-source models: &lt;a href=\"https://github.com/synthetic-lab/octofriend\"&gt;https://github.com/synthetic-lab/octofriend&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can run the models locally, or use inference providers (we run &lt;a href=\"https://synthetic.new\"&gt;a privacy-focused one&lt;/a&gt;). One of the neat things it does differently is used custom-trained models to auto-fix diffs and JSON tool calls when models make minor mistakes; we also open-sourced the models we trained: &lt;a href=\"https://huggingface.co/synthetic-lab/fix-json\"&gt;fix-json&lt;/a&gt; and &lt;a href=\"https://huggingface.co/diff-apply\"&gt;diff-apply&lt;/a&gt;. The models we trained are truly open-source: &lt;a href=\"https://github.com/synthetic-lab/octofriend/tree/main/training\"&gt;here&amp;#39;s the training code and synthetic data generation pipeline&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/scg0f8829ahf1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a811545fefdd11ad066d94dafcc64b5376e0f6c\"&gt;https://preview.redd.it/scg0f8829ahf1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a811545fefdd11ad066d94dafcc64b5376e0f6c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Happy open source release day :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?auto=webp&amp;s=09f2308b92f0aa2465808358ee38cb8bf902dced",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eab1807fd0d2a90e341dea1e3fa0036691f43a30",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e2cd5fa46778ce2a91628fef8bc7e520a6df5342",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ccae375db8c4a5adec0de6929a4bb5ed5967fb40",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d65a13c195798d7821de4fe9f0ac96748bc40f9f",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=66f8bdb0666058c55e7a439cf24b10eeb30432fb",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e885e440c4685be620af9286280976473fb39ca7",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "WrKsuk1CiUKFxv8BgI1hbzq2_vobi8CbYB46uwDVBEQ"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miobog",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "reissbaker",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miobog/we_made_octofriend_a_localllmfriendly_coding/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miobog/we_made_octofriend_a_localllmfriendly_coding/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754435074,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "ik_llama.cpp too! I’d love to hear how people are running it (hardware, CLI flags, use case, etc.)\n\nBandwidth constraints and having a single 3090 are giving me a bit of analysis paralysis choosing a quant to start. I’m a patient hybrid inference gal, as long as it’s not seconds per token 😂. Workload is usually long context document work and coding (still looking a local Roo/aider to go steady with).\n\nFrom what I’ve seen ~70GB for Q4 would be a good fit with typical the MoE CPU/GPU setup as I have &gt;70GB of RAM to play with. I’m afraid to go too low with so few active parameters — or is that guiding principal more bound to total parameters?\n\nI’m surprised I haven’t seen more yet but with gpt-oss dropping the morning the GLM GGUFs did I get why.",
          "author_fullname": "t2_zebuyjw9s",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GLM-4.5-Air llama.cpp experiences?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mio5ld",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.72,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754434659,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ik_llama.cpp too! I’d love to hear how people are running it (hardware, CLI flags, use case, etc.)&lt;/p&gt;\n\n&lt;p&gt;Bandwidth constraints and having a single 3090 are giving me a bit of analysis paralysis choosing a quant to start. I’m a patient hybrid inference gal, as long as it’s not seconds per token 😂. Workload is usually long context document work and coding (still looking a local Roo/aider to go steady with).&lt;/p&gt;\n\n&lt;p&gt;From what I’ve seen ~70GB for Q4 would be a good fit with typical the MoE CPU/GPU setup as I have &amp;gt;70GB of RAM to play with. I’m afraid to go too low with so few active parameters — or is that guiding principal more bound to total parameters?&lt;/p&gt;\n\n&lt;p&gt;I’m surprised I haven’t seen more yet but with gpt-oss dropping the morning the GLM GGUFs did I get why.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mio5ld",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "DorphinPack",
          "discussion_type": null,
          "num_comments": 10,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mio5ld/glm45air_llamacpp_experiences/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mio5ld/glm45air_llamacpp_experiences/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754434659,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_36uys",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Worst. Model. Ever.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "ics4nb9l6ahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 137,
                  "x": 108,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59a0e211128b851a373644840bdf4aa132638a6c"
                },
                {
                  "y": 274,
                  "x": 216,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=01d3c9cb52711471769e3367e4823672c9898922"
                },
                {
                  "y": 405,
                  "x": 320,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78dedd303d750939885bbeaf9cfe9a661406569c"
                },
                {
                  "y": 811,
                  "x": 640,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=770cb15ee55afefb71a6696e73122a8d466a7a49"
                },
                {
                  "y": 1217,
                  "x": 960,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=017bc5d3e3bd217e34eb5bed25a6446f55c28f84"
                },
                {
                  "y": 1370,
                  "x": 1080,
                  "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73449f17a2fd8c47326c2bd93e8a797676b1e2f8"
                }
              ],
              "s": {
                "y": 2739,
                "x": 2159,
                "u": "https://preview.redd.it/ics4nb9l6ahf1.jpg?width=2159&amp;format=pjpg&amp;auto=webp&amp;s=05c25893cd8d5fc1ef676d1191342ce555d0221e"
              },
              "id": "ics4nb9l6ahf1"
            },
            "hz6qk7al6ahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 72,
                  "x": 108,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c926dab46cf0c387123935a1eda2f9d500a09f4f"
                },
                {
                  "y": 145,
                  "x": 216,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cbe350ccfbfdf4a8a2281d60d430d6ef60674392"
                },
                {
                  "y": 215,
                  "x": 320,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24c9fdfc6d2097232390bd7573c81688ab57e875"
                },
                {
                  "y": 431,
                  "x": 640,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb04bf8fdd0ca6e9d4f60bfd1435bdabc87f713d"
                },
                {
                  "y": 647,
                  "x": 960,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dae7011a029b548b8c27283f01ef9d18d27962e8"
                },
                {
                  "y": 728,
                  "x": 1080,
                  "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cd246586f8b004e0ee1bfa2ab93543270da7e54"
                }
              ],
              "s": {
                "y": 2159,
                "x": 3199,
                "u": "https://preview.redd.it/hz6qk7al6ahf1.jpg?width=3199&amp;format=pjpg&amp;auto=webp&amp;s=db2d80b2825141b2db6d1e8123938f5ec12f9f28"
              },
              "id": "hz6qk7al6ahf1"
            }
          },
          "name": "t3_1mio3pe",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.57,
          "author_flair_background_color": null,
          "ups": 4,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "ics4nb9l6ahf1",
                "id": 722103273
              },
              {
                "media_id": "hz6qk7al6ahf1",
                "id": 722103274
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/mC5XnCWsxIi_60QjUcOYwGmJuEH4arC1CUvyFUQORUE.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754434524,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mio3pe",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mio3pe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "tetsuto",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mio3pe/worst_model_ever/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mio3pe",
          "subreddit_subscribers": 511363,
          "created_utc": 1754434524,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "If at all possible, I'd like to be able to run locally models like Qwen3 235b, Kimi K2, GLM 4.5, deepseek r1, GPT-OSS 120b (even quantized versions would do).\n\nWhat specs should I aim for.\n\nCan I do this on a 12GB VRAM GPU (3060 12GB) and a say 256GB or 512 GB RAM?\n\nWhat would it take to run these models locally at acceptable speeds?",
          "author_fullname": "t2_1rfhip3pge",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Looking to buy a new PC - What specs should I be aiming for.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mio3j9",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754434512,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If at all possible, I&amp;#39;d like to be able to run locally models like Qwen3 235b, Kimi K2, GLM 4.5, deepseek r1, GPT-OSS 120b (even quantized versions would do).&lt;/p&gt;\n\n&lt;p&gt;What specs should I aim for.&lt;/p&gt;\n\n&lt;p&gt;Can I do this on a 12GB VRAM GPU (3060 12GB) and a say 256GB or 512 GB RAM?&lt;/p&gt;\n\n&lt;p&gt;What would it take to run these models locally at acceptable speeds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mio3j9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "KindlyAnything1996",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mio3j9/looking_to_buy_a_new_pc_what_specs_should_i_be/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mio3j9/looking_to_buy_a_new_pc_what_specs_should_i_be/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754434512,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html",
          "author_fullname": "t2_1gnii9bkc9",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Every Reason Why I Hate AI and You Should Too",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minxdr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.18,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754434085,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html\"&gt;https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1minxdr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Educational_Sun_8813",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minxdr/every_reason_why_i_hate_ai_and_you_should_too/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minxdr/every_reason_why_i_hate_ai_and_you_should_too/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754434085,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "This is a **community-provided** independent benchmark: [https://github.com/johnbean393/SVGBench](https://github.com/johnbean393/SVGBench).\n\n5 percentage points better with 5x *fewer* active parameters! Keep the vibe benchmarks coming r/LocalLLaMA. We are witnessing something historic.",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-120b destroys DeepSeek-r1-0528 on SVGBench",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 83,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minuvb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.72,
          "author_flair_background_color": "transparent",
          "ups": 78,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 78,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/8B4Kd6TkCkMyalYksAtVXwl-70kNu5cOiBLV6eueNnw.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754433908,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a &lt;strong&gt;community-provided&lt;/strong&gt; independent benchmark: &lt;a href=\"https://github.com/johnbean393/SVGBench\"&gt;https://github.com/johnbean393/SVGBench&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;5 percentage points better with 5x &lt;em&gt;fewer&lt;/em&gt; active parameters! Keep the vibe benchmarks coming &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;. We are witnessing something historic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/lzcxba1k4ahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/lzcxba1k4ahf1.png?auto=webp&amp;s=ce3c87a4c75b076501be2e57c0f82ea20d9064fc",
                  "width": 752,
                  "height": 448
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/lzcxba1k4ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=44f2a2c3bb25b794f716e5fe50ca96f3dc986aa5",
                    "width": 108,
                    "height": 64
                  },
                  {
                    "url": "https://preview.redd.it/lzcxba1k4ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a085ef7bc09e85cbd4e34294d22955b64f826a61",
                    "width": 216,
                    "height": 128
                  },
                  {
                    "url": "https://preview.redd.it/lzcxba1k4ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab0d5d744d4162b05bdc0268f1475998e265f48f",
                    "width": 320,
                    "height": 190
                  },
                  {
                    "url": "https://preview.redd.it/lzcxba1k4ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5774318e992c9ebca1af3e76935e7e980b6bd051",
                    "width": 640,
                    "height": 381
                  }
                ],
                "variants": {},
                "id": "lLH2zLWooZrZl5IVp9mYBmUdOaaI48brKSEEJorPlqQ"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1minuvb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1minuvb/gptoss120b_destroys_deepseekr10528_on_svgbench/",
          "stickied": false,
          "url": "https://i.redd.it/lzcxba1k4ahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433908,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey everyone!\n\nI'm a beginner student in **Systems Analysis and Development** (Brazil 🇧🇷), just getting started in the tech world. Lately, I've been reading about **Retrieval-Augmented Generation (RAG)** and I'm really intrigued by how it's used to connect LLMs with real-world data.\n\nI’m wondering:\n\n* Is RAG a good area to dive into as a beginner?\n* Can it be a **realistic path to building something useful or even monetizable**?\n* Are there small projects or startups already doing this in niche areas?\n* What would you recommend I study or build first if I want to go deep into this space?\n\nMy goal is not just to study for a job — I want to **learn by building**, maybe even **launch a small product** in the future. I'd love to hear your thoughts, experiences, or resource suggestions.\n\nThanks in advance! 🙏",
          "author_fullname": "t2_x58mdf51o",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is RAG a good area to focus on as a beginner ADS student who wants to build something?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minsd6",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433728,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a beginner student in &lt;strong&gt;Systems Analysis and Development&lt;/strong&gt; (Brazil 🇧🇷), just getting started in the tech world. Lately, I&amp;#39;ve been reading about &lt;strong&gt;Retrieval-Augmented Generation (RAG)&lt;/strong&gt; and I&amp;#39;m really intrigued by how it&amp;#39;s used to connect LLMs with real-world data.&lt;/p&gt;\n\n&lt;p&gt;I’m wondering:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is RAG a good area to dive into as a beginner?&lt;/li&gt;\n&lt;li&gt;Can it be a &lt;strong&gt;realistic path to building something useful or even monetizable&lt;/strong&gt;?&lt;/li&gt;\n&lt;li&gt;Are there small projects or startups already doing this in niche areas?&lt;/li&gt;\n&lt;li&gt;What would you recommend I study or build first if I want to go deep into this space?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My goal is not just to study for a job — I want to &lt;strong&gt;learn by building&lt;/strong&gt;, maybe even &lt;strong&gt;launch a small product&lt;/strong&gt; in the future. I&amp;#39;d love to hear your thoughts, experiences, or resource suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! 🙏&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1minsd6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ChangeEuphoric560",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minsd6/is_rag_a_good_area_to_focus_on_as_a_beginner_ads/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minsd6/is_rag_a_good_area_to_focus_on_as_a_beginner_ads/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433728,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi fellows,\n\n  \nI've just (excitedly) downloaded the new open source model by OpenAI (20b version) and ran it on my 4070 Ti (12 GB VRAM, 32 GB system RAM).\n\nAaaand... it's 2.5x slower than the 4-bit quantized Qwen 3 30b A3B 2507 Instruct. Why? I have updated to the newest version of Ollama (yes, folks, I know vLLM and LM Studio exists), but am getting ridicolously low speeds:\n\n|Model|Average speed in tok/s|\n|:-|:-|\n|GPT-OSS 20b|12.07|\n|Qwen 3 30b A3B Q4\\_K\\_M 2507 Instruct|31.5|\n\n  \nBesides the speed - I don't want to hate - the model kind of sucks at anything that's not English. I've consulted the website of OpenAI, which said that they \"mostly\" trained it on English data, but does that mean the model is not multilingual? Because the performance in German is really, really underwhelming. Like, on the level of Gemma 3 4b Q4\\_K\\_M, which is sooo much smaller than GPT-OSS.\n\nI've then ran it over a set of custom benchmarks (math, reasoning, translation) that are unpublished and it... did not meet my expectations, to say it politely.\n\nWhy would I want to use a much slower, smaller model that cannot take it up with the competition (mostly Qwen)?\n\n  \nAnd lastly, how damn censored did they make this thing? It constantly talks about \"policy\" in its thinking process, all the fricking time, wasting time and tokens when it's not even relevant.\n\nKind of underwhelming for anything non-english.",
          "author_fullname": "t2_cyrs5dhp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is it just me?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minr6f",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.73,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433647,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellows,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just (excitedly) downloaded the new open source model by OpenAI (20b version) and ran it on my 4070 Ti (12 GB VRAM, 32 GB system RAM).&lt;/p&gt;\n\n&lt;p&gt;Aaaand... it&amp;#39;s 2.5x slower than the 4-bit quantized Qwen 3 30b A3B 2507 Instruct. Why? I have updated to the newest version of Ollama (yes, folks, I know vLLM and LM Studio exists), but am getting ridicolously low speeds:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Average speed in tok/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;GPT-OSS 20b&lt;/td&gt;\n&lt;td align=\"left\"&gt;12.07&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 30b A3B Q4_K_M 2507 Instruct&lt;/td&gt;\n&lt;td align=\"left\"&gt;31.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Besides the speed - I don&amp;#39;t want to hate - the model kind of sucks at anything that&amp;#39;s not English. I&amp;#39;ve consulted the website of OpenAI, which said that they &amp;quot;mostly&amp;quot; trained it on English data, but does that mean the model is not multilingual? Because the performance in German is really, really underwhelming. Like, on the level of Gemma 3 4b Q4_K_M, which is sooo much smaller than GPT-OSS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve then ran it over a set of custom benchmarks (math, reasoning, translation) that are unpublished and it... did not meet my expectations, to say it politely.&lt;/p&gt;\n\n&lt;p&gt;Why would I want to use a much slower, smaller model that cannot take it up with the competition (mostly Qwen)?&lt;/p&gt;\n\n&lt;p&gt;And lastly, how damn censored did they make this thing? It constantly talks about &amp;quot;policy&amp;quot; in its thinking process, all the fricking time, wasting time and tokens when it&amp;#39;s not even relevant.&lt;/p&gt;\n\n&lt;p&gt;Kind of underwhelming for anything non-english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1minr6f",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Final_Wheel_7486",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minr6f/is_it_just_me/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minr6f/is_it_just_me/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433647,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;format=png&amp;auto=webp&amp;s=09af507acfa40063fa0bed3df990bca01d097c81\n\nThanks openai, you're really contributing to the open-source LLM community\n\nI haven't been this blown away by a model since Llama 4!",
          "author_fullname": "t2_s7n3irsrx",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Finally, a model that's SAFE",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 52,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "elpfx70g3ahf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 40,
                  "x": 108,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e1a7fab7e04de2bfb3425720fd1d39d2862ca0b"
                },
                {
                  "y": 80,
                  "x": 216,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=83a97fc796d05b2b1c246327b06b1380dc21bb4b"
                },
                {
                  "y": 119,
                  "x": 320,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a2c0b599116370239a30953765d3d2b978a6787"
                },
                {
                  "y": 238,
                  "x": 640,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63174dff4ba685b55c838cdbba82cfd8bcfd8e69"
                },
                {
                  "y": 357,
                  "x": 960,
                  "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e00fbca69d88a1db10e18805ba238859bada108"
                }
              ],
              "s": {
                "y": 371,
                "x": 996,
                "u": "https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;format=png&amp;auto=webp&amp;s=09af507acfa40063fa0bed3df990bca01d097c81"
              },
              "id": "elpfx70g3ahf1"
            }
          },
          "name": "t3_1minpqr",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 98,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 98,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/vPXQi6mxUBYl7zt9fZCD3LWOB6PaZGcjaDHZr2r1u18.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433550,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81\"&gt;https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks openai, you&amp;#39;re really contributing to the open-source LLM community&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t been this blown away by a model since Llama 4!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1minpqr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "RandumbRedditor1000",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433550,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Lol this is some next level brain fried from censorship.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 87,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minnrb",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 22,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 22,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/_FCinv5u4rYlfumyKkhG-Ezi7NxGT6dyNufkywbnmS4.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754433414,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/tcnuqjo63ahf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/tcnuqjo63ahf1.png?auto=webp&amp;s=3ae1aa4b4f93ecaf3cf51bfc038fb9ad06ea4cf8",
                  "width": 1662,
                  "height": 1034
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67e1eec24f60cf63977d249e2cf11ef1e88a76dc",
                    "width": 108,
                    "height": 67
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d81c7517b43aa8e9e398136d9842d70123a1884",
                    "width": 216,
                    "height": 134
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d46fb0db5f457047f584027ae33caab6fb54d82",
                    "width": 320,
                    "height": 199
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=043f9f18d071dc3ac979b1c42c6e3c2c762f2319",
                    "width": 640,
                    "height": 398
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=94378cf121fabda8774b3d6e7896814005a607a9",
                    "width": 960,
                    "height": 597
                  },
                  {
                    "url": "https://preview.redd.it/tcnuqjo63ahf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98ff6dfcfb98f81a9c68d19bdbb6be51b13ff781",
                    "width": 1080,
                    "height": 671
                  }
                ],
                "variants": {},
                "id": "9k6ua2_tpRRxx8jO2pJxOvTy53da50umqPEtOc9jHEE"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1minnrb",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 22,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/",
          "stickied": false,
          "url": "https://i.redd.it/tcnuqjo63ahf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433414,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Basically the title.  I know its early but I'm curious about giving this a shot, willing to throw GPUs/a few bucks at it.  I don't think a LoRa will be enough to unlearn refusals, but maybe full SFT or RL could make a noticeable difference.  \n\nJust curious if anyone's given it a shot or ran into any pitfalls that would save some time.  If not, happy to post early results should there be interest.  I've done it before but I'm far from a pro.  Starting with the 20b for obvious reasons.  ",
          "author_fullname": "t2_dm9wt0ya",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Has anyone tried full fine-tuning on the OpenAI models yet?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minmk6",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433333,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title.  I know its early but I&amp;#39;m curious about giving this a shot, willing to throw GPUs/a few bucks at it.  I don&amp;#39;t think a LoRa will be enough to unlearn refusals, but maybe full SFT or RL could make a noticeable difference.  &lt;/p&gt;\n\n&lt;p&gt;Just curious if anyone&amp;#39;s given it a shot or ran into any pitfalls that would save some time.  If not, happy to post early results should there be interest.  I&amp;#39;ve done it before but I&amp;#39;m far from a pro.  Starting with the 20b for obvious reasons.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1minmk6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SOCSChamp",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minmk6/has_anyone_tried_full_finetuning_on_the_openai/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minmk6/has_anyone_tried_full_finetuning_on_the_openai/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433333,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "1. Does converting to GGUF further quantize it, or just change the format? https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156098490\n\n2. This guy mentions f16 gguf \"works just fine\". How do you get a 16bit quant from a 4bit starting point? Does it improve the intelligence? https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156118810\n\nAnyways, I generally only go for 8bit quants, or at worst 6bit. The last charts I remember showed that intelligence/capabilities tank significantly below the large/high version of 6bit quantization. So...🤷‍♂️",
          "author_fullname": "t2_kvniqgt7",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT OSS: They're 4bit quantized by default (giga yikes 😬), but these comments on the GGUF PR raise some questions.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mink69",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.62,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754433974,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754433171,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Does converting to GGUF further quantize it, or just change the format? &lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156098490\"&gt;https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156098490&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;This guy mentions f16 gguf &amp;quot;works just fine&amp;quot;. How do you get a 16bit quant from a 4bit starting point? Does it improve the intelligence? &lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156118810\"&gt;https://github.com/ggml-org/llama.cpp/pull/15091#issuecomment-3156118810&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anyways, I generally only go for 8bit quants, or at worst 6bit. The last charts I remember showed that intelligence/capabilities tank significantly below the large/high version of 6bit quantization. So...🤷‍♂️&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?auto=webp&amp;s=cd0f8ca9fd0c7f81d6076fccb5c6d1d0326670c1",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bda696394a3347daacb18a8a6a074a4900474307",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ff53d3362d28a1c6301445dabaa1ff5915bc119",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f0a35eddee4e5f20f033f1a4014fd9008e80130",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4c56def5c919fda31730429221f4618fb38af1b",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a6252e350dc05cea44bcc1f85bb8fc5b7a67616c",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e2312ece35f696d04c366202c78165e477e1e1e",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "uoAlW2qpCt3e8xck14MuY5UZnRkqWuVhQs4fD_GJKW0"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mink69",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Virtamancer",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mink69/gpt_oss_theyre_4bit_quantized_by_default_giga/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mink69/gpt_oss_theyre_4bit_quantized_by_default_giga/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754433171,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi,\n\nI was reading a bit about positional encoding and came across ALiBi. It's really simple and surprisingly works. The TL;DR is this:\n\n    // Step 1: Compute raw attention scores. \n    // The scores at this stage are \"position-blind\".\n    Scores = (Query * Transpose(Key)) / Sqrt(Dimension_of_head)\n    // Step 2: Create and add a positional penalty.\n    // This is where we inject the positional information.\n    FOR EACH attention_head:\n        // Get the pre-defined, fixed slope for this head.\n        head_slope = Get_Slope_For_Head(current_head)\n        FOR EACH query_position 'i' AND key_position 'j':\n            distance = |i - j|\n            positional_penalty = head_slope * distance\n            // Subtract the penalty from the raw score.\n            Scores[head, i, j] = Scores[head, i, j] - positional_penalty\n    // Step 3: Apply softmax and compute the final output.\n    Weights = Softmax(Scores)\n    Output = Weights * Value\n\nHas there been any new model trained with this? Was it ever picked up by any lab?",
          "author_fullname": "t2_bfr1vge1",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Recent models trained with ALiBi",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minhh2",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432982,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was reading a bit about positional encoding and came across ALiBi. It&amp;#39;s really simple and surprisingly works. The TL;DR is this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;// Step 1: Compute raw attention scores. \n// The scores at this stage are &amp;quot;position-blind&amp;quot;.\nScores = (Query * Transpose(Key)) / Sqrt(Dimension_of_head)\n// Step 2: Create and add a positional penalty.\n// This is where we inject the positional information.\nFOR EACH attention_head:\n    // Get the pre-defined, fixed slope for this head.\n    head_slope = Get_Slope_For_Head(current_head)\n    FOR EACH query_position &amp;#39;i&amp;#39; AND key_position &amp;#39;j&amp;#39;:\n        distance = |i - j|\n        positional_penalty = head_slope * distance\n        // Subtract the penalty from the raw score.\n        Scores[head, i, j] = Scores[head, i, j] - positional_penalty\n// Step 3: Apply softmax and compute the final output.\nWeights = Softmax(Scores)\nOutput = Weights * Value\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Has there been any new model trained with this? Was it ever picked up by any lab?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1minhh2",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Independent_Aside225",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minhh2/recent_models_trained_with_alibi/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minhh2/recent_models_trained_with_alibi/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432982,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Earlier in the year OpenAI announced that they were delaying the release of their open source model in order to work more on its safety. This announcement was made right around the time Grok was in the news for \"mecha hitler\". So, unsurprisingly gpt-oss is very locked down. In the limited time I've had to test it, it's the first model that (for the most part) manages to negate prefill attacks.\n\nOn a couple occasions I was able to get it to go along with an antagonistic, violent scenario, but any attempt to continue the conversation went back to square 1.\n\nI haven't done a lot of testing on other models aside from the popular ones like Gemma, Qwen, etc. Are there other open source models that can do this that I'm overlooking? Or has OpenAI managed to set a new bar for alignment?",
          "author_fullname": "t2_k1j725u7",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Is GPT-OSS the first open source model to (mostly) negate prefill attack?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mingyj",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.71,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432945,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Earlier in the year OpenAI announced that they were delaying the release of their open source model in order to work more on its safety. This announcement was made right around the time Grok was in the news for &amp;quot;mecha hitler&amp;quot;. So, unsurprisingly gpt-oss is very locked down. In the limited time I&amp;#39;ve had to test it, it&amp;#39;s the first model that (for the most part) manages to negate prefill attacks.&lt;/p&gt;\n\n&lt;p&gt;On a couple occasions I was able to get it to go along with an antagonistic, violent scenario, but any attempt to continue the conversation went back to square 1.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t done a lot of testing on other models aside from the popular ones like Gemma, Qwen, etc. Are there other open source models that can do this that I&amp;#39;m overlooking? Or has OpenAI managed to set a new bar for alignment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mingyj",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Informal_Warning_703",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mingyj/is_gptoss_the_first_open_source_model_to_mostly/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mingyj/is_gptoss_the_first_open_source_model_to_mostly/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432945,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Nothing against those who like it, but for me the results are not always better, and sometimes even worse, but my main reason for wanting to disable it is simply to make the model usable in a poor GPU scenario.",
          "author_fullname": "t2_17ktgtm91m",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How to disable 'thinking' in openai-oss?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1minasr",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.88,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432521,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nothing against those who like it, but for me the results are not always better, and sometimes even worse, but my main reason for wanting to disable it is simply to make the model usable in a poor GPU scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1minasr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "thecalmgreen",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1minasr/how_to_disable_thinking_in_openaioss/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minasr/how_to_disable_thinking_in_openaioss/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432521,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "*A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.*\n\n[https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race](https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race)",
          "author_fullname": "t2_1gnii9bkc9",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "At $250 million, top AI salaries dwarf those of the Manhattan Project and the Space Race",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mina19",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432465,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;A 24 year-old AI researcher will earn 327x what Oppenheimer made while developing the atomic bomb.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race\"&gt;https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?auto=webp&amp;s=2c04453b2be8b8d66904723d553ed2f9f7fc16e1",
                  "width": 1152,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7616c929c8fc6c6e59909bbcfdcfb58e03a00d4e",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=784ca04539c0ab16019a812d0a98635bab4dc12a",
                    "width": 216,
                    "height": 121
                  },
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9066c234636b667ac571867b48c0436e538a4979",
                    "width": 320,
                    "height": 180
                  },
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c00d7a055dc1bc0ce91ddb6d64edcfd5b5ee4000",
                    "width": 640,
                    "height": 360
                  },
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7b64b26264cc0ca71765bc90f6bdbf09d91b3b0",
                    "width": 960,
                    "height": 540
                  },
                  {
                    "url": "https://external-preview.redd.it/7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2a7421ea2f9689d128056eb772c13452c1880d64",
                    "width": 1080,
                    "height": 607
                  }
                ],
                "variants": {},
                "id": "7H0F906LDcOkhfdIiXJzAKb0s4KoXLMzwek9IXxBzzc"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mina19",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Educational_Sun_8813",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mina19/at_250_million_top_ai_salaries_dwarf_those_of_the/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mina19/at_250_million_top_ai_salaries_dwarf_those_of_the/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432465,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I'm using Ollama. \n\nI read that people with M4 Pro are getting 33 tokens/sec but M4 Pro has only marginally faster memory bandwidth 200 vs 273. I'm also not seeing my GPU or CPU being maxed out at any point. \n\nIs this the expected performance? What is my bottleneck here?",
          "author_fullname": "t2_ie86j",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "20B GTP-OSS on a MacBook Pro M1 Pro with 16gb memory running at less than 1 token/s. Is this correct or am I doing something wrong?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1min4lz",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432097,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Ollama. &lt;/p&gt;\n\n&lt;p&gt;I read that people with M4 Pro are getting 33 tokens/sec but M4 Pro has only marginally faster memory bandwidth 200 vs 273. I&amp;#39;m also not seeing my GPU or CPU being maxed out at any point. &lt;/p&gt;\n\n&lt;p&gt;Is this the expected performance? What is my bottleneck here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1min4lz",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "-paul-",
          "discussion_type": null,
          "num_comments": 12,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1min4lz/20b_gtposs_on_a_macbook_pro_m1_pro_with_16gb/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1min4lz/20b_gtposs_on_a_macbook_pro_m1_pro_with_16gb/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432097,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi!\nI tried using the new one vllm docker image but I got \"Sinks are only supported in FlashAttention 3\"\nAny hints?",
          "author_fullname": "t2_dyvrh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Anyone was able to run gpt-oss 20b on a 5090?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1min47x",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432072,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!\nI tried using the new one vllm docker image but I got &amp;quot;Sinks are only supported in FlashAttention 3&amp;quot;\nAny hints?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1min47x",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "celsowm",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1min47x/anyone_was_able_to_run_gptoss_20b_on_a_5090/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1min47x/anyone_was_able_to_run_gptoss_20b_on_a_5090/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432072,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I have a 5070 Ti and a 3060, along with 128GB of DDR5 RAM. Would this be sufficient to run the GPT-OSS 120B model smoothly?",
          "author_fullname": "t2_9ojuc4qy",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "can i run gpt oss 120B with 5070ti + 3060?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1min382",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.6,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754432004,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 5070 Ti and a 3060, along with 128GB of DDR5 RAM. Would this be sufficient to run the GPT-OSS 120B model smoothly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1min382",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Hopeful_Ferret_2701",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1min382/can_i_run_gpt_oss_120b_with_5070ti_3060/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1min382/can_i_run_gpt_oss_120b_with_5070ti_3060/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754432004,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I tested 500 math problems from HuggingFaceH4/MATH-500 and discovered something surprising: Qwen3's Chinese Chain-of-Thought achieves 97% accuracy using only 61% of the tokens its English CoT needs. The efficiency gap grows with problem complexity - for the hardest problems (Level 5), Chinese needs just 65% of English tokens.\n\nThis contradicts most research showing English as the more efficient reasoning language in LLMs. The difference appears to stem from training data: English CoT is exploratory and self-doubting (\"Wait, let me check...\"), while Chinese CoT is direct and confident. Same problem, completely different reasoning styles.\n\nKey findings:\n- Overall: Chinese uses 40% fewer tokens for same accuracy\n- Efficiency scales: 7% advantage on easy problems → 35% on hardest\n- English hit token limits on 15.4% of problems; Chinese only 0.6%\n- When given more tokens, English can match accuracy but still uses 40% more\n\nFull analysis with methodology, case studies, and reproducible code: https://github.com/PastaPastaPasta/llm-chinese-english\n\nTested on: qwen3-30b-a3b-thinking-2507-mlx@6bit via LM Studio",
          "author_fullname": "t2_ynfaa",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3 Uses 40% Fewer Tokens When Reasoning in Chinese vs English",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 104,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1min2c3",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": null,
          "ups": 14,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 14,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/3yM1YJj_ZpYksP-TJ0pe0cKsv0FxUcxVWGobejapRrc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754431944,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tested 500 math problems from HuggingFaceH4/MATH-500 and discovered something surprising: Qwen3&amp;#39;s Chinese Chain-of-Thought achieves 97% accuracy using only 61% of the tokens its English CoT needs. The efficiency gap grows with problem complexity - for the hardest problems (Level 5), Chinese needs just 65% of English tokens.&lt;/p&gt;\n\n&lt;p&gt;This contradicts most research showing English as the more efficient reasoning language in LLMs. The difference appears to stem from training data: English CoT is exploratory and self-doubting (&amp;quot;Wait, let me check...&amp;quot;), while Chinese CoT is direct and confident. Same problem, completely different reasoning styles.&lt;/p&gt;\n\n&lt;p&gt;Key findings:\n- Overall: Chinese uses 40% fewer tokens for same accuracy\n- Efficiency scales: 7% advantage on easy problems → 35% on hardest\n- English hit token limits on 15.4% of problems; Chinese only 0.6%\n- When given more tokens, English can match accuracy but still uses 40% more&lt;/p&gt;\n\n&lt;p&gt;Full analysis with methodology, case studies, and reproducible code: &lt;a href=\"https://github.com/PastaPastaPasta/llm-chinese-english\"&gt;https://github.com/PastaPastaPasta/llm-chinese-english&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Tested on: qwen3-30b-a3b-thinking-2507-mlx@6bit via LM Studio&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/y6r4oreky9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/y6r4oreky9hf1.png?auto=webp&amp;s=71fd8247b4a71b5bb0f025593e91ae20102b4ded",
                  "width": 1050,
                  "height": 784
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/y6r4oreky9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9411b4817b468e3653bbb24545bb86567f9aff4e",
                    "width": 108,
                    "height": 80
                  },
                  {
                    "url": "https://preview.redd.it/y6r4oreky9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e313d8547c3684bce868ef32001e0a0497675930",
                    "width": 216,
                    "height": 161
                  },
                  {
                    "url": "https://preview.redd.it/y6r4oreky9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=96b46effef3077a8bd28468cc14a3ae3c9d9b9ba",
                    "width": 320,
                    "height": 238
                  },
                  {
                    "url": "https://preview.redd.it/y6r4oreky9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=55636863c8127aeded3b9275c0615ec7fa28ce29",
                    "width": 640,
                    "height": 477
                  },
                  {
                    "url": "https://preview.redd.it/y6r4oreky9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c5d0e8e53cdf6fb3450d968f45dd71a96670748",
                    "width": 960,
                    "height": 716
                  }
                ],
                "variants": {},
                "id": "NGrFEOFC_35j6Uz_6zEFlEZETBI5wWBfnbcLP3PZU4I"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1min2c3",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "PastaBlizzard",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1min2c3/qwen3_uses_40_fewer_tokens_when_reasoning_in/",
          "stickied": false,
          "url": "https://i.redd.it/y6r4oreky9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754431944,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Seems pretty standard stuff",
          "author_fullname": "t2_5gg8p4q4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI released Fine-tuning guide for GPT-OSS",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 73,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mimwe9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.97,
          "author_flair_background_color": null,
          "ups": 25,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 25,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=731141103b56a844b825bab2d05e1ce36c0f8dfe",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754431536,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "cookbook.openai.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems pretty standard stuff&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?auto=webp&amp;s=6358f7da610cb4eda31a2a9c1d4a8493bd1a94c3",
                  "width": 1200,
                  "height": 628
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e21b918a6bd47ae52601f8bbd51d5018895a7666",
                    "width": 108,
                    "height": 56
                  },
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=090f92abf1592b127e1ff7a9ff1ffcba1e77635b",
                    "width": 216,
                    "height": 113
                  },
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7758dffb5743f1126d5bc62fd9d7dd1019ce18e3",
                    "width": 320,
                    "height": 167
                  },
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=11ab391878f109e16178aaa55bd6d3f3b344fed6",
                    "width": 640,
                    "height": 334
                  },
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e2938682341d6b004d612bbea72d6b275f9b7af",
                    "width": 960,
                    "height": 502
                  },
                  {
                    "url": "https://external-preview.redd.it/1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=37d0ba9b7515c806f00722d7fd8c14e8ab5c6b5b",
                    "width": 1080,
                    "height": 565
                  }
                ],
                "variants": {},
                "id": "1g1aO4K4YtvuCUsa2NQD2isUUyeWaCLqAH6r5ZvbPzk"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mimwe9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Snoo_64233",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mimwe9/openai_released_finetuning_guide_for_gptoss/",
          "stickied": false,
          "url": "https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers",
          "subreddit_subscribers": 511363,
          "created_utc": 1754431536,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Tested it out on a handful of my favorite test prompts. Knowledge frozen as of 2024-06, handled rescaling and converting a recipe into metric that Qwen 3 30B 3AB 2507 completely hosed, churns at about 72 tok/s on a MacBook M4 Pro Max 4 bit MLX.\n\nAnd it ALMOST got a side scrolling shooter working, whereas the 120B didn't, and Qwen 3 didn't either.\n\n[https://www.youtube.com/live/v4OtI9y4e9g](https://www.youtube.com/live/v4OtI9y4e9g) ",
          "author_fullname": "t2_89vq1",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT OSS 20B is SO good. Definitely a good day to day workhorse",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mimtl9",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.45,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754431352,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tested it out on a handful of my favorite test prompts. Knowledge frozen as of 2024-06, handled rescaling and converting a recipe into metric that Qwen 3 30B 3AB 2507 completely hosed, churns at about 72 tok/s on a MacBook M4 Pro Max 4 bit MLX.&lt;/p&gt;\n\n&lt;p&gt;And it ALMOST got a side scrolling shooter working, whereas the 120B didn&amp;#39;t, and Qwen 3 didn&amp;#39;t either.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/live/v4OtI9y4e9g\"&gt;https://www.youtube.com/live/v4OtI9y4e9g&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mimtl9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "cspenn",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mimtl9/gpt_oss_20b_is_so_good_definitely_a_good_day_to/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mimtl9/gpt_oss_20b_is_so_good_definitely_a_good_day_to/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754431352,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Even on a 3060ti with 8gb of vram I am able to get 10tokens/s on the 20B gpt oss model, which is producing results that are actually insane, this  local model feels better than the flagships from just a year or two back,  at this point it seems like the play is to save the money for better hardware. OpenAI really living up to their name for once. ",
          "author_fullname": "t2_69cq8to",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Cancelling all subscriptions",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mimoat",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.44,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754431004,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Even on a 3060ti with 8gb of vram I am able to get 10tokens/s on the 20B gpt oss model, which is producing results that are actually insane, this  local model feels better than the flagships from just a year or two back,  at this point it seems like the play is to save the money for better hardware. OpenAI really living up to their name for once. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mimoat",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "TheReal4982",
          "discussion_type": null,
          "num_comments": 8,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mimoat/cancelling_all_subscriptions/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mimoat/cancelling_all_subscriptions/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754431004,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_pmniwf57y",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Looking for a team to hack OSS 20B. $500k in prize pool",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mimelx",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.76,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1754430363,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "kaggle.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.kaggle.com/competitions/openai-gpt-oss-20b-red-teaming",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mimelx",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "secopsml",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mimelx/looking_for_a_team_to_hack_oss_20b_500k_in_prize/",
          "stickied": false,
          "url": "https://www.kaggle.com/competitions/openai-gpt-oss-20b-red-teaming",
          "subreddit_subscribers": 511363,
          "created_utc": 1754430363,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi everyone,\n\nWe’ve been experimenting with a prompt optimization strategy for local LLM agents that dramatically reduces prompt size without compromising output quality.\n\nThe problem:\n\nWhen building multi-functional agents (especially using Local LLaMA or Mixtral), prompts tend to become bloated. This leads to:\n• High latency on CPU inference\n• Irrelevant context being injected\n• Unpredictable model behavior\n• Increased GPU memory usage (if available)\n\n\nOur approach:\n\nWe started classifying queries into semantic categories and then selecting only the relevant prompt sections based on a lightweight graph structure of relationships between prompt components.\n\nThis gave us:\n• ~55% token reduction in average prompt size\n• Faster decoding on 7B models (esp. quantized versions)\n• Easier debugging and better eval consistency\n\nInstead of feeding a monolithic prompt every time, the system dynamically builds a minimal one depending on the query.\n\n\nReal-world example:\n\nWe’ve been applying this to a side project called PromptGraph, an open-source initiative (soon to be released) that automates this workflow.\nIt’s model-agnostic and works well with local LLMs, including QLora-tuned models and GGUF-compatible backends.\n\nIf there’s interest, I’d be happy to share the structure or logic we use — or just talk shop about prompt modularization techniques.\n\n\n\nWhat do you think?\n• Has anyone here used graphs or modular prompts in your agent builds?\n• How do you handle prompt size in long-running or multi-turn conversations?\n• Would sharing the repo or an early demo here be useful?\n\nLooking forward to learning from your builds too.\n\nCheers!\n– Michael",
          "author_fullname": "t2_1thv6a883k",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "[Prompt Optimization Strategy] How we use query classification + graph-based context selection to reduce LLM costs in local deployments",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mime87",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "default",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "mod_note": null,
          "created": 1754430337,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "promptgraph.io",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;We’ve been experimenting with a prompt optimization strategy for local LLM agents that dramatically reduces prompt size without compromising output quality.&lt;/p&gt;\n\n&lt;p&gt;The problem:&lt;/p&gt;\n\n&lt;p&gt;When building multi-functional agents (especially using Local LLaMA or Mixtral), prompts tend to become bloated. This leads to:\n• High latency on CPU inference\n• Irrelevant context being injected\n• Unpredictable model behavior\n• Increased GPU memory usage (if available)&lt;/p&gt;\n\n&lt;p&gt;Our approach:&lt;/p&gt;\n\n&lt;p&gt;We started classifying queries into semantic categories and then selecting only the relevant prompt sections based on a lightweight graph structure of relationships between prompt components.&lt;/p&gt;\n\n&lt;p&gt;This gave us:\n• ~55% token reduction in average prompt size\n• Faster decoding on 7B models (esp. quantized versions)\n• Easier debugging and better eval consistency&lt;/p&gt;\n\n&lt;p&gt;Instead of feeding a monolithic prompt every time, the system dynamically builds a minimal one depending on the query.&lt;/p&gt;\n\n&lt;p&gt;Real-world example:&lt;/p&gt;\n\n&lt;p&gt;We’ve been applying this to a side project called PromptGraph, an open-source initiative (soon to be released) that automates this workflow.\nIt’s model-agnostic and works well with local LLMs, including QLora-tuned models and GGUF-compatible backends.&lt;/p&gt;\n\n&lt;p&gt;If there’s interest, I’d be happy to share the structure or logic we use — or just talk shop about prompt modularization techniques.&lt;/p&gt;\n\n&lt;p&gt;What do you think?\n• Has anyone here used graphs or modular prompts in your agent builds?\n• How do you handle prompt size in long-running or multi-turn conversations?\n• Would sharing the repo or an early demo here be useful?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to learning from your builds too.&lt;/p&gt;\n\n&lt;p&gt;Cheers!\n– Michael&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.promptgraph.io",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mime87",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "michael_pintos",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mime87/prompt_optimization_strategy_how_we_use_query/",
          "stickied": false,
          "url": "https://www.promptgraph.io",
          "subreddit_subscribers": 511363,
          "created_utc": 1754430337,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_rfjj2",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-20b claims to be GPT-4 w/ Nov 2023 cutoff.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 112,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mime15",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.31,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/pmOFWO1-m40dFOrHVMLNnGa68ReGmI70-LDyh5GDltI.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754430324,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/8ogdjdpot9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/8ogdjdpot9hf1.png?auto=webp&amp;s=301b87627b6572ffd305ec0a7f22788c479a4a35",
                  "width": 932,
                  "height": 747
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/8ogdjdpot9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=66a133a622aa77b87dbe3e59f2bb812bf0536ea8",
                    "width": 108,
                    "height": 86
                  },
                  {
                    "url": "https://preview.redd.it/8ogdjdpot9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=da8872aa1dbca0d2a523e52cbab81013e2bb7c09",
                    "width": 216,
                    "height": 173
                  },
                  {
                    "url": "https://preview.redd.it/8ogdjdpot9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c2d3d6a71305e019034c295f1fe4318c9c71f6a",
                    "width": 320,
                    "height": 256
                  },
                  {
                    "url": "https://preview.redd.it/8ogdjdpot9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fea445cb4aeb2fb6ccc27d2fe1c4714059450798",
                    "width": 640,
                    "height": 512
                  }
                ],
                "variants": {},
                "id": "ygf23H89V_iSVstzefQMuzh53fgB-n7t6Gcn2PCdfpM"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mime15",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "steezy13312",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mime15/gptoss20b_claims_to_be_gpt4_w_nov_2023_cutoff/",
          "stickied": false,
          "url": "https://i.redd.it/8ogdjdpot9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754430324,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Benchmark: [https://github.com/KCORES/kcores-llm-arena/tree/main/benchmark-ball-bouncing-inside-spinning-heptagon](https://github.com/KCORES/kcores-llm-arena/tree/main/benchmark-ball-bouncing-inside-spinning-heptagon)\n\nInput code (the prompt is taken directly from the benchmark):\n\n    from openai import OpenAI\n     \n    prompt = \"\"\"Write a Python program that shows 20 balls bouncing inside a spinning heptagon:\n    - All balls have the same radius.\n    - All balls have a number on it from 1 to 20.\n    - All balls drop from the heptagon center when starting.\n    - Colors are: #f8b862, #f6ad49, #f39800, #f08300, #ec6d51, #ee7948, #ed6d3d, #ec6800, #ec6800, #ee7800, #eb6238, #ea5506, #ea5506, #eb6101, #e49e61, #e45e32, #e17b34, #dd7a56, #db8449, #d66a35\n    - The balls should be affected by gravity and friction, and they must bounce off the rotating walls realistically. There should also be collisions between balls.\n    - The material of all the balls determines that their impact bounce height will not exceed the radius of the heptagon, but higher than ball radius.\n    - All balls rotate with friction, the numbers on the ball can be used to indicate the spin of the ball.\n    - The heptagon is spinning around its center, and the speed of spinning is 360 degrees per 5 seconds.\n    - The heptagon size should be large enough to contain all the balls.\n    - Do not use the pygame library; implement collision detection algorithms and collision response etc. by yourself. The following Python libraries are allowed: tkinter, math, numpy, dataclasses, typing, sys.\n    - All codes should be put in a single Python file.\n    \"\"\"\n    \n    client = OpenAI(\n        base_url=\"http://localhost:8000/v1\",\n        api_key=\"EMPTY\"\n    )\n     \n    result = client.chat.completions.create(\n        model=\"openai/gpt-oss-120b\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Reasoning: high\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n    )\n     \n    print(result.choices[0].message.content)",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-120b on the \"Ball Bouncing Inside Spinning Heptagon\" benchmark",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 139,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mimbvg",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.83,
          "author_flair_background_color": "transparent",
          "ups": 20,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/wm3v5c7ft9hf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1086,
              "scrubber_media_url": "https://v.redd.it/wm3v5c7ft9hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/wm3v5c7ft9hf1/DASHPlaylist.mpd?a=1757034803%2CY2RmZWMwNzdmNDFkM2JlMGE5ZTM3NzE0NGQ3MzU1MWM2OTkyNDBiMGNmZjYwMGNhY2Q2ZTIxZGQ3ZmRkYjkwOQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 15,
              "hls_url": "https://v.redd.it/wm3v5c7ft9hf1/HLSPlaylist.m3u8?a=1757034803%2CZjk2OTYyZGM5OTU2MGQ0MTYxZjg4NTllNzljOTk3ZWZmYmZiMWIzOTkxYjgyOTk0MTczNmY5MjAzNjEwMWJiNg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 20,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=140&amp;height=139&amp;crop=140:139,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=6c5716804064178836be749710b354cb8e791fe1",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754430176,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Benchmark: &lt;a href=\"https://github.com/KCORES/kcores-llm-arena/tree/main/benchmark-ball-bouncing-inside-spinning-heptagon\"&gt;https://github.com/KCORES/kcores-llm-arena/tree/main/benchmark-ball-bouncing-inside-spinning-heptagon&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Input code (the prompt is taken directly from the benchmark):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from openai import OpenAI\n\nprompt = &amp;quot;&amp;quot;&amp;quot;Write a Python program that shows 20 balls bouncing inside a spinning heptagon:\n- All balls have the same radius.\n- All balls have a number on it from 1 to 20.\n- All balls drop from the heptagon center when starting.\n- Colors are: #f8b862, #f6ad49, #f39800, #f08300, #ec6d51, #ee7948, #ed6d3d, #ec6800, #ec6800, #ee7800, #eb6238, #ea5506, #ea5506, #eb6101, #e49e61, #e45e32, #e17b34, #dd7a56, #db8449, #d66a35\n- The balls should be affected by gravity and friction, and they must bounce off the rotating walls realistically. There should also be collisions between balls.\n- The material of all the balls determines that their impact bounce height will not exceed the radius of the heptagon, but higher than ball radius.\n- All balls rotate with friction, the numbers on the ball can be used to indicate the spin of the ball.\n- The heptagon is spinning around its center, and the speed of spinning is 360 degrees per 5 seconds.\n- The heptagon size should be large enough to contain all the balls.\n- Do not use the pygame library; implement collision detection algorithms and collision response etc. by yourself. The following Python libraries are allowed: tkinter, math, numpy, dataclasses, typing, sys.\n- All codes should be put in a single Python file.\n&amp;quot;&amp;quot;&amp;quot;\n\nclient = OpenAI(\n    base_url=&amp;quot;http://localhost:8000/v1&amp;quot;,\n    api_key=&amp;quot;EMPTY&amp;quot;\n)\n\nresult = client.chat.completions.create(\n    model=&amp;quot;openai/gpt-oss-120b&amp;quot;,\n    messages=[\n        {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Reasoning: high&amp;quot;},\n        {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt}\n    ],\n)\n\nprint(result.choices[0].message.content)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/wm3v5c7ft9hf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?format=pjpg&amp;auto=webp&amp;s=dfba2ec2331ac75fc45ebf8f0b16c7877547a336",
                  "width": 1204,
                  "height": 1198
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fe0feb36681a2f80bcf307b5a8fa80ec03cc53c8",
                    "width": 108,
                    "height": 107
                  },
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9b79101537814e46d9d73e59d30abf7b61de86b9",
                    "width": 216,
                    "height": 214
                  },
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=27482218c1cdefb64f1ff020b42c2f5b33327d16",
                    "width": 320,
                    "height": 318
                  },
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=52d03fb0ec0bda960c6c752b95c5c5b06449350a",
                    "width": 640,
                    "height": 636
                  },
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5fdb1c36064ea9be486fc89a36b31745f40d80f8",
                    "width": 960,
                    "height": 955
                  },
                  {
                    "url": "https://external-preview.redd.it/N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a9ba990e3b068a4dc0ff7cd9bf603240f6a5010d",
                    "width": 1080,
                    "height": 1074
                  }
                ],
                "variants": {},
                "id": "N2YzeGJjN2Z0OWhmMR0l7U2W2QU8pPesZxP949A1S1WH3A2gsjWQ8Ls93hhP"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mimbvg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 20,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mimbvg/gptoss120b_on_the_ball_bouncing_inside_spinning/",
          "stickied": false,
          "url": "https://v.redd.it/wm3v5c7ft9hf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754430176,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/wm3v5c7ft9hf1/DASH_1080.mp4?source=fallback",
              "has_audio": false,
              "height": 1080,
              "width": 1086,
              "scrubber_media_url": "https://v.redd.it/wm3v5c7ft9hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/wm3v5c7ft9hf1/DASHPlaylist.mpd?a=1757034803%2CY2RmZWMwNzdmNDFkM2JlMGE5ZTM3NzE0NGQ3MzU1MWM2OTkyNDBiMGNmZjYwMGNhY2Q2ZTIxZGQ3ZmRkYjkwOQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 15,
              "hls_url": "https://v.redd.it/wm3v5c7ft9hf1/HLSPlaylist.m3u8?a=1757034803%2CZjk2OTYyZGM5OTU2MGQ0MTYxZjg4NTllNzljOTk3ZWZmYmZiMWIzOTkxYjgyOTk0MTczNmY5MjAzNjEwMWJiNg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I just went through the model card highlights. What do you guys think about the fact that the 20B model has only about 3.61 B active params, lower than the Llama's 7B model even; and it performs this well? Also these are good at AIME (a math competition), GPQA (graduate-level physics), and MMLU (a broad academic benchmark), which are analytical benchmarks; but didn't Sam Altman say these models are better at creative writing and not analytical tasks?\n\nhttps://preview.redd.it/mm0yg94bt9hf1.png?width=2542&amp;format=png&amp;auto=webp&amp;s=36ac04cba8cbdb6a3d5df3ec86ce314f46861fc2\n\n(Clone my notes [here](https://www.proread.ai/share/2cc66753-0e94-444d-a77f-414c896e0d7e))",
          "author_fullname": "t2_8dovyb9x",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI's OSS model has fewer active params than Llama 7B? And its good at reasoning?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 74,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "mm0yg94bt9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 57,
                  "x": 108,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e06ed84be0e2c3f102512c079b66de60bf583e7b"
                },
                {
                  "y": 114,
                  "x": 216,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b1155dd3821e66c3176cc8e434d1a0febd77081"
                },
                {
                  "y": 169,
                  "x": 320,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef970879a057f2df365d82d943e5dbda2af7dded"
                },
                {
                  "y": 339,
                  "x": 640,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=eeeb0e60b2ff37db0e08444795dfe4cb9c99fdaf"
                },
                {
                  "y": 509,
                  "x": 960,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c89f6cc70b4ffed5b126a8e89ad1a57dccfc0ff"
                },
                {
                  "y": 572,
                  "x": 1080,
                  "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=921d7550bc54e7b09947816ada8bd2b0f832a182"
                }
              ],
              "s": {
                "y": 1348,
                "x": 2542,
                "u": "https://preview.redd.it/mm0yg94bt9hf1.png?width=2542&amp;format=png&amp;auto=webp&amp;s=36ac04cba8cbdb6a3d5df3ec86ce314f46861fc2"
              },
              "id": "mm0yg94bt9hf1"
            }
          },
          "name": "t3_1mimaof",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.63,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/oqU053UWNNlonmGQnX6Ew0OIu-iHL-V9A3p_DJby-WE.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754430096,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just went through the model card highlights. What do you guys think about the fact that the 20B model has only about 3.61 B active params, lower than the Llama&amp;#39;s 7B model even; and it performs this well? Also these are good at AIME (a math competition), GPQA (graduate-level physics), and MMLU (a broad academic benchmark), which are analytical benchmarks; but didn&amp;#39;t Sam Altman say these models are better at creative writing and not analytical tasks?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mm0yg94bt9hf1.png?width=2542&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36ac04cba8cbdb6a3d5df3ec86ce314f46861fc2\"&gt;https://preview.redd.it/mm0yg94bt9hf1.png?width=2542&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36ac04cba8cbdb6a3d5df3ec86ce314f46861fc2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(Clone my notes &lt;a href=\"https://www.proread.ai/share/2cc66753-0e94-444d-a77f-414c896e0d7e\"&gt;here&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mimaof",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Wonderful-Delivery-6",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mimaof/openais_oss_model_has_fewer_active_params_than/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mimaof/openais_oss_model_has_fewer_active_params_than/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754430096,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_9b9s4a7g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "More profanity: GPT-OSS powered QwenCode. It works. kind of.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 66,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "t9khvxyko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 50,
                  "x": 108,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=640d0942689c60cd5882d8f3eecd03acad795ccf"
                },
                {
                  "y": 101,
                  "x": 216,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79a633c1c2f94fff650881b6d759d0ca4d45cf37"
                },
                {
                  "y": 150,
                  "x": 320,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b50e0308b79d7de696263c49ce716afd0dfea7b"
                },
                {
                  "y": 301,
                  "x": 640,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=683091a51859833bd8bd9c59630486067f2e85a2"
                },
                {
                  "y": 452,
                  "x": 960,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9a20776a4b682671d58786fd371167a6fe6721e6"
                },
                {
                  "y": 509,
                  "x": 1080,
                  "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=83cb022f89c7b1f62da8d5114cd4ac194faf73e6"
                }
              ],
              "s": {
                "y": 946,
                "x": 2006,
                "u": "https://preview.redd.it/t9khvxyko9hf1.png?width=2006&amp;format=png&amp;auto=webp&amp;s=31600bb09f299bd353792215e7e58ea1ff4c352b"
              },
              "id": "t9khvxyko9hf1"
            },
            "r7b4fu1mo9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 91,
                  "x": 108,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bb2fe63f96145dfd0f75feacf443e8303120e5d"
                },
                {
                  "y": 183,
                  "x": 216,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f22754b24bd0ff96b41b244a5dbca3872fe0d513"
                },
                {
                  "y": 272,
                  "x": 320,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a767a8f3109a8c6577262a59d9d9d33a8ae12d7"
                },
                {
                  "y": 544,
                  "x": 640,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3382072ab4fc3e42e6a0298d6361edf01edb5358"
                },
                {
                  "y": 816,
                  "x": 960,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=42d898f570646f911636e6daa767779e7ecd1ea9"
                },
                {
                  "y": 918,
                  "x": 1080,
                  "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc178b7741c528efab7dffaefa447e0da767c46a"
                }
              ],
              "s": {
                "y": 1840,
                "x": 2164,
                "u": "https://preview.redd.it/r7b4fu1mo9hf1.png?width=2164&amp;format=png&amp;auto=webp&amp;s=dc85473fcc65936bec29e82d2e61f9a8a8186b42"
              },
              "id": "r7b4fu1mo9hf1"
            }
          },
          "name": "t3_1mim94b",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "ups": 4,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "t9khvxyko9hf1",
                "id": 722058138
              },
              {
                "media_id": "r7b4fu1mo9hf1",
                "id": 722058139
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 4,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/03q7NmFLz8fMNwuBXZs_E4NMH9P-oViADrKl6tguhRM.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754429993,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mim94b",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mim94b",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "JLeonsarmiento",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mim94b/more_profanity_gptoss_powered_qwencode_it_works/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mim94b",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429993,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Abstract: Approximate nearest-neighbor search (ANNS) algorithms have become increasingly critical for recent AI applications, particularly in retrieval-augmented generation (RAG) and agent-based LLM applications. In this paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS optimization as a reinforcement learning problem where execution speed serves as the reward signal. This approach enables the automatic generation of progressively faster ANNS implementations while maintaining accuracy constraints. Our experimental evaluation demonstrates CRINN's effectiveness across six widely-used NNS benchmark datasets. When compared against state-of-the-art open-source ANNS algorithms, CRINN achieves best performance on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean and GloVe-25-angular). The implications of CRINN's success reach well beyond ANNS optimization: It validates that LLMs augmented with reinforcement learning can function as an effective tool for automating sophisticated algorithmic optimizations that demand specialized knowledge and labor-intensive manual refinement code.\n\n[CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2508.02091)\n\nCode: [https://github.com/deepreinforce-ai/CRINN](https://github.com/deepreinforce-ai/CRINN)\n\nPaper: [https://arxiv.org/abs/2508.02091](https://arxiv.org/abs/2508.02091)",
          "author_fullname": "t2_1v2au0ln9m",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mim56p",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754429729,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Abstract: Approximate nearest-neighbor search (ANNS) algorithms have become increasingly critical for recent AI applications, particularly in retrieval-augmented generation (RAG) and agent-based LLM applications. In this paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS optimization as a reinforcement learning problem where execution speed serves as the reward signal. This approach enables the automatic generation of progressively faster ANNS implementations while maintaining accuracy constraints. Our experimental evaluation demonstrates CRINN&amp;#39;s effectiveness across six widely-used NNS benchmark datasets. When compared against state-of-the-art open-source ANNS algorithms, CRINN achieves best performance on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean and GloVe-25-angular). The implications of CRINN&amp;#39;s success reach well beyond ANNS optimization: It validates that LLMs augmented with reinforcement learning can function as an effective tool for automating sophisticated algorithmic optimizations that demand specialized knowledge and labor-intensive manual refinement code.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2508.02091\"&gt;CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=\"https://github.com/deepreinforce-ai/CRINN\"&gt;https://github.com/deepreinforce-ai/CRINN&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Paper: &lt;a href=\"https://arxiv.org/abs/2508.02091\"&gt;https://arxiv.org/abs/2508.02091&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mim56p",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different741",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mim56p/crinn_contrastive_reinforcement_learning_for/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mim56p/crinn_contrastive_reinforcement_learning_for/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429729,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "My curremt laptop cannit bear it",
          "author_fullname": "t2_2hocwgkh",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Running qwen for free on cloud or running it locally? What are the minimum estimated cost",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mim1ug",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.33,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754429507,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My curremt laptop cannit bear it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mim1ug",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Mark_Collins",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mim1ug/running_qwen_for_free_on_cloud_or_running_it/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mim1ug/running_qwen_for_free_on_cloud_or_running_it/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429507,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "benchmark:\n\n    llama-bench -ngl 99 -m /mnt/models3/gpt-oss-120b-mxfp4-00001-of-00003.gguf\n    \n    ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n    ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n    ggml_cuda_init: found 3 CUDA devices:\n      Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n      Device 1: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n      Device 2: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n    | model                          |       size |     params | backend    | ngl |            test |                  t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |\n    | gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | CUDA       |  99 |           pp512 |       1351.86 ± 6.96 |\n    | gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | CUDA       |  99 |           tg128 |        102.17 ± 4.05 |\n\nserver command:\n\n`llama-server -c 20000 -ngl 99 --jinja --host` [`0.0.0.0`](http://0.0.0.0) `-fa -m /mnt/models3/gpt-oss-120b-mxfp4-00001-of-00003.gguf`\n\nhttps://preview.redd.it/q28rs5oyr9hf1.png?width=1832&amp;format=png&amp;auto=webp&amp;s=32496fb3c5030e3107f1719c0713cda5b4d9694e\n\n  \n",
          "author_fullname": "t2_vqgbql9w",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "gpt-oss-120b is faster than 90t/s on 3x3090",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 44,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "q28rs5oyr9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 34,
                  "x": 108,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39718fb2824e8c22e4a8f1eeb1ce7dd4d7c98327"
                },
                {
                  "y": 69,
                  "x": 216,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=82f25985ec715fc683f23157b515e14715b2a34f"
                },
                {
                  "y": 102,
                  "x": 320,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=343f01e5611b2551fb2802b7dc9e96a5a6343a9c"
                },
                {
                  "y": 204,
                  "x": 640,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6892b263ae8919326402e785f8aa6f059fcb0320"
                },
                {
                  "y": 307,
                  "x": 960,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=99ee3229efbbb9b32653f476af449e3a3026d886"
                },
                {
                  "y": 345,
                  "x": 1080,
                  "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e3da3d61316d4955d58c6414f072452d631635e4"
                }
              ],
              "s": {
                "y": 586,
                "x": 1832,
                "u": "https://preview.redd.it/q28rs5oyr9hf1.png?width=1832&amp;format=png&amp;auto=webp&amp;s=32496fb3c5030e3107f1719c0713cda5b4d9694e"
              },
              "id": "q28rs5oyr9hf1"
            }
          },
          "name": "t3_1mim0cs",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": "#bbbdbf",
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/jActAUQVBg_zXdGUTMCjVJNBxKbgAHh8pnq8whhXExQ.jpg",
          "edited": 1754429605,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "e": "text",
              "t": "llama.cpp"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754429407,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;benchmark:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;llama-bench -ngl 99 -m /mnt/models3/gpt-oss-120b-mxfp4-00001-of-00003.gguf\n\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\nggml_cuda_init: found 3 CUDA devices:\n  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n  Device 1: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n  Device 2: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n| model                          |       size |     params | backend    | ngl |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | --: | --------------: | -------------------: |\n| gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | CUDA       |  99 |           pp512 |       1351.86 ± 6.96 |\n| gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | CUDA       |  99 |           tg128 |        102.17 ± 4.05 |\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;server command:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama-server -c 20000 -ngl 99 --jinja --host&lt;/code&gt; &lt;a href=\"http://0.0.0.0\"&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/a&gt; &lt;code&gt;-fa -m /mnt/models3/gpt-oss-120b-mxfp4-00001-of-00003.gguf&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/q28rs5oyr9hf1.png?width=1832&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32496fb3c5030e3107f1719c0713cda5b4d9694e\"&gt;https://preview.redd.it/q28rs5oyr9hf1.png?width=1832&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32496fb3c5030e3107f1719c0713cda5b4d9694e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": "llama.cpp",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mim0cs",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "jacek2023",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "light",
          "permalink": "/r/LocalLLaMA/comments/1mim0cs/gptoss120b_is_faster_than_90ts_on_3x3090/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mim0cs/gptoss120b_is_faster_than_90ts_on_3x3090/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429407,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "A new drop of RAG and agent-based applications. Today is a big day. A new OAI open-source model, Claude 4.1, and more expected.\n\n[https://x.com/deep\\_reinforce/status/1952841690752139692](https://x.com/deep_reinforce/status/1952841690752139692)\n\n",
          "author_fullname": "t2_1u46l0rfuj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mim030",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 3,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 3,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754429390,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new drop of RAG and agent-based applications. Today is a big day. A new OAI open-source model, Claude 4.1, and more expected.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://x.com/deep_reinforce/status/1952841690752139692\"&gt;https://x.com/deep_reinforce/status/1952841690752139692&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mim030",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Optimal-Outcome-7458",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mim030/crinn_contrastive_reinforcement_learning_for/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mim030/crinn_contrastive_reinforcement_learning_for/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429390,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi everyone,\n\nI'm looking for a **lightweight speech‑to‑text app based on OpenAI Whisper**, ideally:\n\n* **Runs on Windows or Android**\n* **Can works offline or locally?**\n* Supports a **hotkey or push‑to‑talk trigger**\n* **Autostarts at system boot/login** (on Windows) or stays accessible on Android like a dictation IME\n* **Simple, minimal UI**, not heavy or bloated\n\nIf you know of any **free, open‑source, or low‑cost apps** that tick these boxes—please share.",
          "author_fullname": "t2_1qyykcj4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Looking for lightweight Whisper speech‑to‑text app on Windows or Android (open‑source or cheap)?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milxsh",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.5,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754429240,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a &lt;strong&gt;lightweight speech‑to‑text app based on OpenAI Whisper&lt;/strong&gt;, ideally:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Runs on Windows or Android&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Can works offline or locally?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Supports a &lt;strong&gt;hotkey or push‑to‑talk trigger&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Autostarts at system boot/login&lt;/strong&gt; (on Windows) or stays accessible on Android like a dictation IME&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Simple, minimal UI&lt;/strong&gt;, not heavy or bloated&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you know of any &lt;strong&gt;free, open‑source, or low‑cost apps&lt;/strong&gt; that tick these boxes—please share.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1milxsh",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Ranteck",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milxsh/looking_for_lightweight_whisper_speechtotext_app/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1milxsh/looking_for_lightweight_whisper_speechtotext_app/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754429240,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi. Coming from a \"classic ML\" background, I know what do training data look like for a typical supervised learning problem. But when thinking of an instruction-tuned LLM,things get confusing.\n\nWhat does one sample look like, e.g. if I want to fine tune a small LLM for text summarisation in a particular domain? And how many samples does it take to meaningfully change the model weights, given that we are talking about hundreds of millions of parameters?\n\nThank you\n\nBest",
          "author_fullname": "t2_127kho",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "What do the samples look like for fine tuning?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milr4q",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754428811,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Coming from a &amp;quot;classic ML&amp;quot; background, I know what do training data look like for a typical supervised learning problem. But when thinking of an instruction-tuned LLM,things get confusing.&lt;/p&gt;\n\n&lt;p&gt;What does one sample look like, e.g. if I want to fine tune a small LLM for text summarisation in a particular domain? And how many samples does it take to meaningfully change the model weights, given that we are talking about hundreds of millions of parameters?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n\n&lt;p&gt;Best&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1milr4q",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ihatebeinganonymous",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milr4q/what_do_the_samples_look_like_for_fine_tuning/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1milr4q/what_do_the_samples_look_like_for_fine_tuning/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428811,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Leaderboards with all models:\n\n[https://github.com/lechmazur/nyt-connections/](https://github.com/lechmazur/nyt-connections/)\n\n[https://github.com/lechmazur/generalization](https://github.com/lechmazur/generalization)  \n",
          "author_fullname": "t2_p2tr0",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "gpt-oss-120b (and Opus 4.1) on Extended NYT Connections and Thematic Generalization benchmarks",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 87,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "naqcnwfzo9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 117,
                  "x": 108,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c365c860afa30b5f48e8487998f164c486ca62e"
                },
                {
                  "y": 235,
                  "x": 216,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=179951aa6e5a9a544eb1bad1ea097d09898cab75"
                },
                {
                  "y": 349,
                  "x": 320,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47634abd26a9e01f07a6faea1b26d8aace5c4c34"
                },
                {
                  "y": 698,
                  "x": 640,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=490032fe0d7bebdd91520fde0bd97f5c065a3296"
                },
                {
                  "y": 1047,
                  "x": 960,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ef668f533bf1636be61cc6d8066a73e9669f0c1"
                },
                {
                  "y": 1178,
                  "x": 1080,
                  "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=09fd93424b9bc6a0d6133b94e62da4394b53f61b"
                }
              ],
              "s": {
                "y": 1200,
                "x": 1100,
                "u": "https://preview.redd.it/naqcnwfzo9hf1.png?width=1100&amp;format=png&amp;auto=webp&amp;s=d99c27fd9671fbe5f008f609bbc789a127cb2792"
              },
              "id": "naqcnwfzo9hf1"
            },
            "pfz8cf6xo9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 67,
                  "x": 108,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=363ec97b4c541388b34c92b6e5b49c7bf111bf60"
                },
                {
                  "y": 135,
                  "x": 216,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6db6b27ff4b4ec3dbab86db2640c735073373e0"
                },
                {
                  "y": 200,
                  "x": 320,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fff67d257379c208819a1996760ad5cf3b19afbd"
                },
                {
                  "y": 400,
                  "x": 640,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd1510dd764113a1e6a78bbd11528a697ab16acf"
                },
                {
                  "y": 600,
                  "x": 960,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=69f518354182b7389dcad4eeaed504da3e7703c3"
                },
                {
                  "y": 675,
                  "x": 1080,
                  "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ea75327331ac72e220c1613da2168c9f73778ad6"
                }
              ],
              "s": {
                "y": 1000,
                "x": 1600,
                "u": "https://preview.redd.it/pfz8cf6xo9hf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=2242697f6dabfee2c6e12eedee975b6e29d1f7e7"
              },
              "id": "pfz8cf6xo9hf1"
            }
          },
          "name": "t3_1milofa",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 12,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "pfz8cf6xo9hf1",
                "id": 722042621
              },
              {
                "media_id": "naqcnwfzo9hf1",
                "id": 722042622
              }
            ]
          },
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 12,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/yY-Yyq__UkcnzKQTK0oD1bZelpaxS966zTnEq34NcPI.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428640,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Leaderboards with all models:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/lechmazur/nyt-connections/\"&gt;https://github.com/lechmazur/nyt-connections/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/lechmazur/generalization\"&gt;https://github.com/lechmazur/generalization&lt;/a&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1milofa",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1milofa",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "zero0_one1",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milofa/gptoss120b_and_opus_41_on_extended_nyt/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1milofa",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428640,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "[https://eqbench.com/](https://eqbench.com/)\n\n**gpt-oss-120b:**\n\nCreative writing\n\n[https://eqbench.com/results/creative-writing-v3/openai\\_\\_gpt-oss-120b.html](https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html)\n\nLongform writing:\n\n[https://eqbench.com/results/creative-writing-longform/openai\\_\\_gpt-oss-120b\\_longform\\_report.html](https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html)\n\nEQ-Bench:\n\n[https://eqbench.com/results/eqbench3\\_reports/openai\\_\\_gpt-oss-120b.html](https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html)\n\n\n\n**gpt-oss-20b:**\n\nCreative writing\n\n[https://eqbench.com/results/creative-writing-v3/openai\\_\\_gpt-oss-20b.html](https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html)\n\nLongform writing:\n\n[https://eqbench.com/results/creative-writing-longform/openai\\_\\_gpt-oss-20b\\_longform\\_report.html](https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html)\n\nEQ-Bench:\n\n[https://eqbench.com/results/eqbench3\\_reports/openai\\_\\_gpt-oss-20b.html](https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html)\n\n",
          "author_fullname": "t2_pp9qh5t8g",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "OpenAI gpt-oss-120b &amp; 20b EQ-Bench &amp; creative writing results",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "znomj63ko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 155,
                  "x": 108,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0aa028d8fc2cbbc53426f8fd988f3a606086b92"
                },
                {
                  "y": 310,
                  "x": 216,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2b59d07098a95c551490555834b1c8e62cf2601"
                },
                {
                  "y": 459,
                  "x": 320,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a2c0540ce4a7134be96e8f7f530a272c15fb1ee"
                },
                {
                  "y": 918,
                  "x": 640,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=285ef11697d042fbc0ef0cb028fb9016deef81a7"
                },
                {
                  "y": 1377,
                  "x": 960,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c6fc3019f03d6dba919ca1fa768bd68710d8ad8"
                },
                {
                  "y": 1550,
                  "x": 1080,
                  "u": "https://preview.redd.it/znomj63ko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19651cc4b224d1492cf56a26c1a61f30446cd1aa"
                }
              ],
              "s": {
                "y": 1998,
                "x": 1392,
                "u": "https://preview.redd.it/znomj63ko9hf1.png?width=1392&amp;format=png&amp;auto=webp&amp;s=72c63548e222079a1ec8f7e89ce5c672a9eb03ce"
              },
              "id": "znomj63ko9hf1"
            },
            "hwakzukko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 175,
                  "x": 108,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a907c3f561d350306adc7c4be6677f81b93df15b"
                },
                {
                  "y": 351,
                  "x": 216,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ed849eee3da8dedd2edec7fe34e45a21e29874e"
                },
                {
                  "y": 520,
                  "x": 320,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1d376d2e1c0e80cc9ec8e07e158aec8eada39f9"
                },
                {
                  "y": 1041,
                  "x": 640,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45dd2a4f93cae24a8ac54371cae682a79165a929"
                },
                {
                  "y": 1562,
                  "x": 960,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce2ed864a107b1a5cc6eb9477b94e66b45f4b347"
                },
                {
                  "y": 1757,
                  "x": 1080,
                  "u": "https://preview.redd.it/hwakzukko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6506cc300127409ad8ef9485a313e6edee6f3183"
                }
              ],
              "s": {
                "y": 1930,
                "x": 1186,
                "u": "https://preview.redd.it/hwakzukko9hf1.png?width=1186&amp;format=png&amp;auto=webp&amp;s=91b929e09b4665b1bbfe62ab1a758b1d7bb9880a"
              },
              "id": "hwakzukko9hf1"
            },
            "oprys6qjo9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 135,
                  "x": 108,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bed4c8e7b94088bbf92d2a7c95487708e0fb51cc"
                },
                {
                  "y": 270,
                  "x": 216,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7997d24338fbc648ac336e202028bb9d1c237764"
                },
                {
                  "y": 400,
                  "x": 320,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=db3899174c605e6d8c10c2c9e7ceb4bf906e9e07"
                },
                {
                  "y": 800,
                  "x": 640,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c84e6fc911d2ee3c94d1cf272a772bd3051f73a3"
                },
                {
                  "y": 1200,
                  "x": 960,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e294b819550a94da8d361e4195e9e1bebf3724a"
                },
                {
                  "y": 1350,
                  "x": 1080,
                  "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bb4c578ff15e3ff3fccf34fe911f0661200ee074"
                }
              ],
              "s": {
                "y": 2000,
                "x": 1600,
                "u": "https://preview.redd.it/oprys6qjo9hf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=b7526d4ab064ce18d86f6eb52a8df1c9262cf44e"
              },
              "id": "oprys6qjo9hf1"
            },
            "1hm2v1vko9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 64,
                  "x": 108,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ec7ae41b57ca14d5099807b62cb20a3049d7efd"
                },
                {
                  "y": 128,
                  "x": 216,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0224d4e3f215ab1d100401d9bc16b1d8d7c91c3d"
                },
                {
                  "y": 189,
                  "x": 320,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f691d652c1686eb2a70fd7258a869179aa9163d"
                },
                {
                  "y": 379,
                  "x": 640,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b15ded60070d75b9f86870c1855ddd04d8b44026"
                },
                {
                  "y": 569,
                  "x": 960,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=43b18810472e88bec9b9db6b980d3a2914744ce1"
                },
                {
                  "y": 640,
                  "x": 1080,
                  "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=789f265dc80344d4c5e6ee02d316a0d2e82c7b21"
                }
              ],
              "s": {
                "y": 950,
                "x": 1601,
                "u": "https://preview.redd.it/1hm2v1vko9hf1.png?width=1601&amp;format=png&amp;auto=webp&amp;s=0724d38724d2331c9aaa28b35a8f60c53da674c6"
              },
              "id": "1hm2v1vko9hf1"
            }
          },
          "name": "t3_1milmrl",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.77,
          "author_flair_background_color": "transparent",
          "ups": 61,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "oprys6qjo9hf1",
                "id": 722041561
              },
              {
                "media_id": "znomj63ko9hf1",
                "id": 722041562
              },
              {
                "media_id": "hwakzukko9hf1",
                "id": 722041563
              },
              {
                "media_id": "1hm2v1vko9hf1",
                "id": 722041564
              }
            ]
          },
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 61,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/ddG4iHe_QohGbzMrf1QVWE9bWoVRavxmRobwbx0Do3Y.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":Llama:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428536,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://eqbench.com/\"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;gpt-oss-120b:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Creative writing&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html\"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Longform writing:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html\"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EQ-Bench:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html\"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;gpt-oss-20b:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Creative writing&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html\"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Longform writing:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html\"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EQ-Bench:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html\"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1milmrl",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":Llama:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1milmrl",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "_sqrkl",
          "discussion_type": null,
          "num_comments": 48,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1milmrl",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428536,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Kudos to you guys",
          "author_fullname": "t2_q1q7nlxa",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Just wanna say : Kudos to llama cpp our unsung heroes 🫡",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milm9t",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.93,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 38,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 38,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754428505,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kudos to you guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1milm9t",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "dreamai87",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1milm9t/just_wanna_say_kudos_to_llama_cpp_our_unsung/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428505,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey guys! You can now run OpenAI's gpt-oss-120b &amp; 20b open models locally with our [Unsloth](https://github.com/unslothai/unsloth) GGUFs! 🦥\n\nThe uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI's recent change to their chat template and our new fixes.\n\n* 20b GGUF: [https://huggingface.co/unsloth/gpt-oss-20b-GGUF](https://huggingface.co/unsloth/gpt-oss-20b-GGUF)\n* 120b GGUF: [https://huggingface.co/unsloth/gpt-oss-120b-GGUF](https://huggingface.co/unsloth/gpt-oss-120b-GGUF)\n\nYou can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp; 20b model on 14GB RAM/unified mem. Both will run at &gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.\n\nGuide to run model: [https://docs.unsloth.ai/basics/gpt-oss](https://docs.unsloth.ai/basics/gpt-oss)\n\n**Instructions**: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run\n\n    ./llama.cpp/llama-cli \\\n        -hf unsloth/gpt-oss-20b-GGUF:F16 \\\n        --jinja -ngl 99 --threads -1 --ctx-size 16384 \\\n        --temp 0.6 --top-p 1.0 --top-k 0\n\nOr Ollama:\n\n    ollama run hf.co/unsloth/gpt-oss-20b-GGUF\n\nTo run the **120B model** via llama.cpp:\n\n    ./llama.cpp/llama-cli \\\n        --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \\\n        --threads -1 \\\n        --ctx-size 16384 \\\n        --n-gpu-layers 99 \\\n        -ot \".ffn_.*_exps.=CPU\" \\\n        --temp 0.6 \\\n        --min-p 0.0 \\\n        --top-p 1.0 \\\n        --top-k 0.0 \\\n\nThanks for the support guys and happy running. 🥰\n\nFinetuning support coming soon (likely tomorrow)!",
          "author_fullname": "t2_5wukhd4",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Run gpt-oss locally with Unsloth GGUFs + Fixes!",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milkqp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.94,
          "author_flair_background_color": null,
          "ups": 82,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 82,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/zPPlSmg4vBRTUG_cvJInG8onvJy3mjcTiitOisY7Wj8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428406,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! You can now run OpenAI&amp;#39;s gpt-oss-120b &amp;amp; 20b open models locally with our &lt;a href=\"https://github.com/unslothai/unsloth\"&gt;Unsloth&lt;/a&gt; GGUFs! 🦥&lt;/p&gt;\n\n&lt;p&gt;The uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI&amp;#39;s recent change to their chat template and our new fixes.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;20b GGUF: &lt;a href=\"https://huggingface.co/unsloth/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;120b GGUF: &lt;a href=\"https://huggingface.co/unsloth/gpt-oss-120b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-120b-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp;amp; 20b model on 14GB RAM/unified mem. Both will run at &amp;gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.&lt;/p&gt;\n\n&lt;p&gt;Guide to run model: &lt;a href=\"https://docs.unsloth.ai/basics/gpt-oss\"&gt;https://docs.unsloth.ai/basics/gpt-oss&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \\\n    -hf unsloth/gpt-oss-20b-GGUF:F16 \\\n    --jinja -ngl 99 --threads -1 --ctx-size 16384 \\\n    --temp 0.6 --top-p 1.0 --top-k 0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Or Ollama:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ollama run hf.co/unsloth/gpt-oss-20b-GGUF\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To run the &lt;strong&gt;120B model&lt;/strong&gt; via llama.cpp:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \\\n    --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \\\n    --threads -1 \\\n    --ctx-size 16384 \\\n    --n-gpu-layers 99 \\\n    -ot &amp;quot;.ffn_.*_exps.=CPU&amp;quot; \\\n    --temp 0.6 \\\n    --min-p 0.0 \\\n    --top-p 1.0 \\\n    --top-k 0.0 \\\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Thanks for the support guys and happy running. 🥰&lt;/p&gt;\n\n&lt;p&gt;Finetuning support coming soon (likely tomorrow)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/6s62jsx2o9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/6s62jsx2o9hf1.png?auto=webp&amp;s=c412cb62d534fd94a21e971e05062c2ca1d5130d",
                  "width": 2560,
                  "height": 2740
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e815bdf932294f33e187adf930d6da99b4dbd9d",
                    "width": 108,
                    "height": 115
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0936e565586e45c54c1b2808e296e0e5cd0878f2",
                    "width": 216,
                    "height": 231
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=894e81043bd4c71fdad40f23b8c89993b03f261b",
                    "width": 320,
                    "height": 342
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4a03b38836e71df4373dc670859d4fca8398ff1",
                    "width": 640,
                    "height": 685
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=46f698a73faf6edbcbabdc8ef7fe28a834246f0e",
                    "width": 960,
                    "height": 1027
                  },
                  {
                    "url": "https://preview.redd.it/6s62jsx2o9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0efa5f3bdd3ba25dcb36d290a95bbeb1670ca74a",
                    "width": 1080,
                    "height": 1155
                  }
                ],
                "variants": {},
                "id": "cgDifyZFtbjbAPhmEKVZn1UiSMpgWQoUTWOijJXGf1w"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1milkqp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "danielhanchen",
          "discussion_type": null,
          "num_comments": 41,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/",
          "stickied": false,
          "url": "https://i.redd.it/6s62jsx2o9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428406,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hi everyone!\n\nI was super excited for this brand new model from OpenAI and I wanted to run it on my following specs:\n\nOS: Windows 10 64bit\n\nSoftware: LM Studio 0.3.24 b4\n\nOS RAM: 16 GB\n\nGPU VRAM: 8 GB (this is AMD GPU RX Vega 56)\n\nInference engine: Vulkan / CPU.\n\nNormally I can run Qwen 30B A3B MoE models just fine, so I was quite surprised to find out that I can't really run this much smaller 20B model the same way on Vulkan inference engine!\n\nI was starting to lose hope, but then I decided to try the last resort - switching from glorious Vulkan inference engine to just CPU inference. That means saying goodbye to offloading some layers of the model to GPU for inference boost, but surprisingly switching to CPU only actually solved the problem!\n\nSo if you're like me, struggling to make this work with your GPU, please go to your \"Mission Control\" settings (Ctrl / Cmd + Shift + R), click the Runtime tab (see #1 on the attached screenshot). Make sure to download the latest versions of the runtimes (hit that Refresh button and then the green Download button for each inference engine that needs an update). Next, switch from Vulkan (or whatever GPU enabled engine you were using before) to CPU inference (see #2 on the attached screenshot). Next time you load the model, it should load properly, as long as you have enough OS RAM. Since this model requires a lot of memory, it's best to run it with at least 16 GB of RAM, otherwise you're risking that some part of the model will be loaded into the swap file on your hard drive which will make the inference most likely slower.\n\nWith that said, I'd really like to thank to both llama.cpp developers and LM Studio developers for adding support for this new model very early, but I'd also like to ask for further improvements of the support for this model, so that we could also use the Vulkan inference for offloading into the GPU.\n\nI know some people said that CPU inference on MoE models is faster, but being able to use that extra memory on my GPU on Vulkan inference engine would make all the difference for me. If for nothing else, at least I would be able to use larger context window.\n\nThanks everyone and good luck, have fun!",
          "author_fullname": "t2_qz1qjc86",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI's GPT-OSS 20B in LM Studio is a bit tricky, but I finally made it work, here's how I did it...",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 83,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milfjl",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/nlCPFbUvFibO3-lFvBJ_G03bkAHmafU8kw3Ri7f2TtI.jpg",
          "author_cakeday": true,
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428065,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I was super excited for this brand new model from OpenAI and I wanted to run it on my following specs:&lt;/p&gt;\n\n&lt;p&gt;OS: Windows 10 64bit&lt;/p&gt;\n\n&lt;p&gt;Software: LM Studio 0.3.24 b4&lt;/p&gt;\n\n&lt;p&gt;OS RAM: 16 GB&lt;/p&gt;\n\n&lt;p&gt;GPU VRAM: 8 GB (this is AMD GPU RX Vega 56)&lt;/p&gt;\n\n&lt;p&gt;Inference engine: Vulkan / CPU.&lt;/p&gt;\n\n&lt;p&gt;Normally I can run Qwen 30B A3B MoE models just fine, so I was quite surprised to find out that I can&amp;#39;t really run this much smaller 20B model the same way on Vulkan inference engine!&lt;/p&gt;\n\n&lt;p&gt;I was starting to lose hope, but then I decided to try the last resort - switching from glorious Vulkan inference engine to just CPU inference. That means saying goodbye to offloading some layers of the model to GPU for inference boost, but surprisingly switching to CPU only actually solved the problem!&lt;/p&gt;\n\n&lt;p&gt;So if you&amp;#39;re like me, struggling to make this work with your GPU, please go to your &amp;quot;Mission Control&amp;quot; settings (Ctrl / Cmd + Shift + R), click the Runtime tab (see #1 on the attached screenshot). Make sure to download the latest versions of the runtimes (hit that Refresh button and then the green Download button for each inference engine that needs an update). Next, switch from Vulkan (or whatever GPU enabled engine you were using before) to CPU inference (see #2 on the attached screenshot). Next time you load the model, it should load properly, as long as you have enough OS RAM. Since this model requires a lot of memory, it&amp;#39;s best to run it with at least 16 GB of RAM, otherwise you&amp;#39;re risking that some part of the model will be loaded into the swap file on your hard drive which will make the inference most likely slower.&lt;/p&gt;\n\n&lt;p&gt;With that said, I&amp;#39;d really like to thank to both llama.cpp developers and LM Studio developers for adding support for this new model very early, but I&amp;#39;d also like to ask for further improvements of the support for this model, so that we could also use the Vulkan inference for offloading into the GPU.&lt;/p&gt;\n\n&lt;p&gt;I know some people said that CPU inference on MoE models is faster, but being able to use that extra memory on my GPU on Vulkan inference engine would make all the difference for me. If for nothing else, at least I would be able to use larger context window.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone and good luck, have fun!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/gysfnhl7l9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/gysfnhl7l9hf1.png?auto=webp&amp;s=ea078de3ffb58e5e6f92651fad9dbae87b091f68",
                  "width": 1332,
                  "height": 791
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c8b87b7c2e75094fd0bbec8080a4bd0a49af6fb",
                    "width": 108,
                    "height": 64
                  },
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=61b42ec9b40cc45d271f93e2cedc4e2782df26ce",
                    "width": 216,
                    "height": 128
                  },
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d054707531f8f89f3d308f1d3925a278eb3fedac",
                    "width": 320,
                    "height": 190
                  },
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc4f4237497d84c2478f5e704e3e5d9c995a5aae",
                    "width": 640,
                    "height": 380
                  },
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=78388852f99c897c7c47cca8718a39c38f0df04a",
                    "width": 960,
                    "height": 570
                  },
                  {
                    "url": "https://preview.redd.it/gysfnhl7l9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=82c52cb6771a023d45ba3f5f8e347d7ace751185",
                    "width": 1080,
                    "height": 641
                  }
                ],
                "variants": {},
                "id": "HeoI1wjq_lY0awE4-qKX8GkDO4fDbEbRfCuNkMGyMn8"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1milfjl",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Cool-Chemical-5629",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milfjl/openais_gptoss_20b_in_lm_studio_is_a_bit_tricky/",
          "stickied": false,
          "url": "https://i.redd.it/gysfnhl7l9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428065,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_14fb6edg",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Qwen3 dense instruct/coder/thinking models tomorrow?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milfbi",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.92,
          "author_flair_background_color": null,
          "ups": 45,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 45,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://a.thumbs.redditmedia.com/a_kLldfk1NSixLZGGIuXAduGSTOH3mRA8yJ-AFkeMZ8.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754428050,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/pbi1dcacn9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/pbi1dcacn9hf1.png?auto=webp&amp;s=b023920e2e00fad0dd88ada47a90c2d4e45025fc",
                  "width": 1220,
                  "height": 2272
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=272f9d4a11848949a7c5e679527dee7011700084",
                    "width": 108,
                    "height": 201
                  },
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8834d9d25209dd41cf93f0d0e8dbb920988bf22",
                    "width": 216,
                    "height": 402
                  },
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5be990d47f3ca4ae3280bac655b14614f1950932",
                    "width": 320,
                    "height": 595
                  },
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=71abb79aa684b3ff0cd618c4a35f701067ce38ca",
                    "width": 640,
                    "height": 1191
                  },
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a2d0ab4149302cbae983a532f8ecc9790b6cc4b6",
                    "width": 960,
                    "height": 1787
                  },
                  {
                    "url": "https://preview.redd.it/pbi1dcacn9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=afce637e7c7053e6eb42257affc62bf65bf2d906",
                    "width": 1080,
                    "height": 2011
                  }
                ],
                "variants": {},
                "id": "rsQn8LBB7lbIioupvv8EDwwYI5wXn-XO-cpWUkA7mTA"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1milfbi",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "MR_-_501",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milfbi/qwen3_dense_instructcoderthinking_models_tomorrow/",
          "stickied": false,
          "url": "https://i.redd.it/pbi1dcacn9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428050,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I don't understand why they are releasing these great models for free. I must be missing something. ",
          "author_fullname": "t2_6ubpe",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Quick question; What's the business model behind free open source models?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milf6u",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.57,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754428042,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t understand why they are releasing these great models for free. I must be missing something. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1milf6u",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "TweeMansLeger",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1milf6u/quick_question_whats_the_business_model_behind/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1milf6u/quick_question_whats_the_business_model_behind/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754428042,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Don't know why nobody is talking about this. We now have the open-source Codex CLI: https://github.com/openai/codex. And the open-source gpt-oss models: https://huggingface.co/openai/gpt-oss-120b. This gives terminal coders (my IDE is Vim!) a fully open IDE ecosystem that finally rivals VSCode + Model and Cursor + Model. Can't wait for codex plugins!",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Terminal coders rejoice: the Codex CLI ecosystem is finally fully open-source",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1milboe",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": "transparent",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=7adbcbcd65f1f3262b2f91b17fcd0ff9b9886180",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754427814,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t know why nobody is talking about this. We now have the open-source Codex CLI: &lt;a href=\"https://github.com/openai/codex\"&gt;https://github.com/openai/codex&lt;/a&gt;. And the open-source gpt-oss models: &lt;a href=\"https://huggingface.co/openai/gpt-oss-120b\"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;. This gives terminal coders (my IDE is Vim!) a fully open IDE ecosystem that finally rivals VSCode + Model and Cursor + Model. Can&amp;#39;t wait for codex plugins!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/openai/codex",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?auto=webp&amp;s=8bf3fdc6add1fd91ed05fb357105dccc89ec5b4e",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=39f0705850281e8c625f6eaa87c0e39037515e2d",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=769ff26669bce88115f3571fb003b8800f8977c7",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bf37b8624a535c9f40ebf05aa6f2665bdf12c67",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=de5af2479b12626138f27255d9f2ab7364c275a9",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa2726203496c6e9810edbdc488f1a2544cd8093",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=22ec7a7e85dda62b98ee7c8f9810895c6fe99a7c",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "pkbdz8qEySiFJEy_x76PBnHLEC5_ePJUq9_2rPu4Rz0"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1milboe",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1milboe/terminal_coders_rejoice_the_codex_cli_ecosystem/",
          "stickied": false,
          "url": "https://github.com/openai/codex",
          "subreddit_subscribers": 511363,
          "created_utc": 1754427814,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_uptissiz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ollama Turbo - Run models using datacenter-grade hardware",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 73,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mik5gy",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.29,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=140&amp;height=73&amp;crop=140:73,smart&amp;auto=webp&amp;s=37c71bd6eb9aa2635eac207ee75bc00f189acaf8",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754425130,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "ollama.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://ollama.com/turbo",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?auto=webp&amp;s=a080c4707584d3aa14134960cda9ba2d339b93a3",
                  "width": 1200,
                  "height": 630
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3dc759de0e8fa36d241c5728d41ee3cf022cab96",
                    "width": 108,
                    "height": 56
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ccf136f5d3091254a0067a3bc5d6c7df9d62d89",
                    "width": 216,
                    "height": 113
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2530aa4ecbcf7899ec0d023e217fe24af15fe0a6",
                    "width": 320,
                    "height": 168
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e51add1cab39c7614eb13e6195f23c5b4eeb417",
                    "width": 640,
                    "height": 336
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=750a6d42fd91c5a6e9a9c069e74247c877644e97",
                    "width": 960,
                    "height": 504
                  },
                  {
                    "url": "https://external-preview.redd.it/krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9eab390b865b031211658564ad5fe5241c9661c5",
                    "width": 1080,
                    "height": 567
                  }
                ],
                "variants": {},
                "id": "krjt_5uhqcaDfYjfO7lkezThehav9cAIRJgcK-OKAmM"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mik5gy",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Pro-editor-1105",
          "discussion_type": null,
          "num_comments": 10,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mik5gy/ollama_turbo_run_models_using_datacentergrade/",
          "stickied": false,
          "url": "https://ollama.com/turbo",
          "subreddit_subscribers": 511363,
          "created_utc": 1754425130,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It's feeling very slow. ",
          "author_fullname": "t2_1qukezqmce",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Running GPT-OSS:20B Locally on Windows 11 | 16GB of RAM |Using Ollama",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "New Model"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 105,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mik0co",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.62,
          "author_flair_background_color": null,
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "New Model",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/r74Mv0FaqZ7V_3XoqKmpSsm-IBN1MqxU5nsWabQKt8I.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754424821,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s feeling very slow. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/ffwa8n8qd9hf1.jpeg",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?auto=webp&amp;s=6e7724f58576534460c6618d779e9ffaa4c5aad8",
                  "width": 4000,
                  "height": 3000
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=03dc4c23459104a49478fd36b1703743fcd824ec",
                    "width": 108,
                    "height": 81
                  },
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47013b05577df730efb06e19bf79d5289834d6f9",
                    "width": 216,
                    "height": 162
                  },
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82d51e22d5370ee466fd131b381966332b5bf163",
                    "width": 320,
                    "height": 240
                  },
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df06dd62cf62642b8f2143ab78c6e424e297dd48",
                    "width": 640,
                    "height": 480
                  },
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a97daf5b5574320022fbbd1eb5e9a45386db001",
                    "width": 960,
                    "height": 720
                  },
                  {
                    "url": "https://preview.redd.it/ffwa8n8qd9hf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=23d3a085916756d4b0518cbe8ecf585453c679c1",
                    "width": 1080,
                    "height": 810
                  }
                ],
                "variants": {},
                "id": "-iNiNkmJGJ3DatJg_1RaL9I3ThV4zFALMrZeZX8GRMA"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#ffb000",
          "id": "1mik0co",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Ok-Orchid1032",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mik0co/running_gptoss20b_locally_on_windows_11_16gb_of/",
          "stickied": false,
          "url": "https://i.redd.it/ffwa8n8qd9hf1.jpeg",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424821,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I ran the [vLLM provided benchmarks](https://github.com/vllm-project/vllm/tree/main/benchmarks) `serve` (online serving throughput) and `throughput` (offline serving throughput) for `gpt-oss-120b` on my H100 96GB with the ShareGPT benchmark data.\n\nCan confirm it fits snugly in 96GB. Numbers below.\n\n# Throughput Benchmark (offline serving throughput)\n\nCommand: `vllm bench serve --model \"openai/gpt-oss-120b\"`\n\n    ============ Serving Benchmark Result ============\n    Successful requests:                     1000\n    Benchmark duration (s):                  47.81\n    Total input tokens:                      1022745\n    Total generated tokens:                  48223\n    Request throughput (req/s):              20.92\n    Output token throughput (tok/s):         1008.61\n    Total Token throughput (tok/s):          22399.88\n    ---------------Time to First Token----------------\n    Mean TTFT (ms):                          18806.63\n    Median TTFT (ms):                        18631.45\n    P99 TTFT (ms):                           36522.62\n    -----Time per Output Token (excl. 1st token)------\n    Mean TPOT (ms):                          283.85\n    Median TPOT (ms):                        271.48\n    P99 TPOT (ms):                           801.98\n    ---------------Inter-token Latency----------------\n    Mean ITL (ms):                           231.50\n    Median ITL (ms):                         267.02\n    P99 ITL (ms):                            678.42\n    ==================================================\n\n# Serve Benchmark (online serving throughput)\n\nCommand: `vllm bench latency --model \"openai/gpt-oss-120b\"`\n\n    Avg latency: 1.3391752537339925 seconds\n    10% percentile latency: 1.277150624152273 seconds\n    25% percentile latency: 1.30161597346887 seconds\n    50% percentile latency: 1.3404422830790281 seconds\n    75% percentile latency: 1.3767581032589078 seconds\n    90% percentile latency: 1.393262314144522 seconds\n    99% percentile latency: 1.4468831585347652 seconds",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "vLLM latency/throughput benchmarks for gpt-oss-120b",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 81,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijza6",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.95,
          "author_flair_background_color": "transparent",
          "ups": 51,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 51,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/CkiPy_94iF46m6sozte4q0xipLvoNhob8Av1r371Asc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754424752,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran the &lt;a href=\"https://github.com/vllm-project/vllm/tree/main/benchmarks\"&gt;vLLM provided benchmarks&lt;/a&gt; &lt;code&gt;serve&lt;/code&gt; (online serving throughput) and &lt;code&gt;throughput&lt;/code&gt; (offline serving throughput) for &lt;code&gt;gpt-oss-120b&lt;/code&gt; on my H100 96GB with the ShareGPT benchmark data.&lt;/p&gt;\n\n&lt;p&gt;Can confirm it fits snugly in 96GB. Numbers below.&lt;/p&gt;\n\n&lt;h1&gt;Throughput Benchmark (offline serving throughput)&lt;/h1&gt;\n\n&lt;p&gt;Command: &lt;code&gt;vllm bench serve --model &amp;quot;openai/gpt-oss-120b&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;============ Serving Benchmark Result ============\nSuccessful requests:                     1000\nBenchmark duration (s):                  47.81\nTotal input tokens:                      1022745\nTotal generated tokens:                  48223\nRequest throughput (req/s):              20.92\nOutput token throughput (tok/s):         1008.61\nTotal Token throughput (tok/s):          22399.88\n---------------Time to First Token----------------\nMean TTFT (ms):                          18806.63\nMedian TTFT (ms):                        18631.45\nP99 TTFT (ms):                           36522.62\n-----Time per Output Token (excl. 1st token)------\nMean TPOT (ms):                          283.85\nMedian TPOT (ms):                        271.48\nP99 TPOT (ms):                           801.98\n---------------Inter-token Latency----------------\nMean ITL (ms):                           231.50\nMedian ITL (ms):                         267.02\nP99 ITL (ms):                            678.42\n==================================================\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;Serve Benchmark (online serving throughput)&lt;/h1&gt;\n\n&lt;p&gt;Command: &lt;code&gt;vllm bench latency --model &amp;quot;openai/gpt-oss-120b&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avg latency: 1.3391752537339925 seconds\n10% percentile latency: 1.277150624152273 seconds\n25% percentile latency: 1.30161597346887 seconds\n50% percentile latency: 1.3404422830790281 seconds\n75% percentile latency: 1.3767581032589078 seconds\n90% percentile latency: 1.393262314144522 seconds\n99% percentile latency: 1.4468831585347652 seconds\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/bz9j2b92d9hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/bz9j2b92d9hf1.png?auto=webp&amp;s=f4537f0f422810ae514de68f6a07b87764fd88d3",
                  "width": 2695,
                  "height": 1574
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c11c3140455b7faeb590a3bf0df168bd37f153f1",
                    "width": 108,
                    "height": 63
                  },
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0d32efb2dbb850088837decea852e2c7f216980",
                    "width": 216,
                    "height": 126
                  },
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=07654141634decbf9b896303af7caddb1575997f",
                    "width": 320,
                    "height": 186
                  },
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c7db73fb89602975462166e965bca3fd42eb685",
                    "width": 640,
                    "height": 373
                  },
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c7305c5c1ea1f409820387a5147feddc8c865c16",
                    "width": 960,
                    "height": 560
                  },
                  {
                    "url": "https://preview.redd.it/bz9j2b92d9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a59413d800f13ae883ef3683a06ed1962ec705c2",
                    "width": 1080,
                    "height": 630
                  }
                ],
                "variants": {},
                "id": "QSXGsN0xEL2pMJPlSHxzuAzjIjcwxz798p-YwZh29U4"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mijza6",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mijza6/vllm_latencythroughput_benchmarks_for_gptoss120b/",
          "stickied": false,
          "url": "https://i.redd.it/bz9j2b92d9hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424752,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "I am using qwen3 4b with searxng currently for integrating search in it, but many times it fails, like sometimes the content it scrapes is non conclusive. \nHow does tools like Jan do it? Their search functionality is so good, is there any other open searching tools other than searxng giving better result. Or is it just their prompt specific optimization. I am trying to build something like that. ",
          "author_fullname": "t2_1nisx8ggay",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Adding search functionality in a small lm",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijwvo",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 6,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754424602,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using qwen3 4b with searxng currently for integrating search in it, but many times it fails, like sometimes the content it scrapes is non conclusive. \nHow does tools like Jan do it? Their search functionality is so good, is there any other open searching tools other than searxng giving better result. Or is it just their prompt specific optimization. I am trying to build something like that. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mijwvo",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ILoveMy2Balls",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijwvo/adding_search_functionality_in_a_small_lm/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijwvo/adding_search_functionality_in_a_small_lm/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424602,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey guys, \n\nI managed to get an RTX 5080 on my personal machine, so in total it will be 16GB VRAM plus 96 GB RAM.\n\nI am wondering what's the best general model for it? \n\nQwen 30B A3B or something else?\n\nIs it enough to run some bigger models with \\~100k context?",
          "author_fullname": "t2_lipuk",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Best Model for Single RTX 5080?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijwom",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.33,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754424591,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I managed to get an RTX 5080 on my personal machine, so in total it will be 16GB VRAM plus 96 GB RAM.&lt;/p&gt;\n\n&lt;p&gt;I am wondering what&amp;#39;s the best general model for it? &lt;/p&gt;\n\n&lt;p&gt;Qwen 30B A3B or something else?&lt;/p&gt;\n\n&lt;p&gt;Is it enough to run some bigger models with ~100k context?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mijwom",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "SthMax",
          "discussion_type": null,
          "num_comments": 1,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijwom/best_model_for_single_rtx_5080/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijwom/best_model_for_single_rtx_5080/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424591,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_7g0m6735",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "it's literally me",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Funny"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijrtd",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.71,
          "author_flair_background_color": null,
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/udnlm90zb9hf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1080,
              "scrubber_media_url": "https://v.redd.it/udnlm90zb9hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/udnlm90zb9hf1/DASHPlaylist.mpd?a=1757034803%2CZmE1MzBhMTM1NjllMTU2M2I2NWE4YzUwZTA4NTJmMDk2ZjU5NDAyNWZiZDA0MWUxZjQ2NDMxM2E2YjFjMDM1NQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 33,
              "hls_url": "https://v.redd.it/udnlm90zb9hf1/HLSPlaylist.m3u8?a=1757034803%2CY2NkZTRlM2NiNWY1YWNjNDcyZTQ3NDNmMWMyNzI2MmRhODNmMmFkYTFiZDU0MmFjM2IyMmViNTZiZGE3ODAxZg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Funny",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=8dc14432aa19a165ae4e20d3a1dd799819d97d8c",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754424291,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/udnlm90zb9hf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?format=pjpg&amp;auto=webp&amp;s=8dd27883a79e1e568d6713ab42fdcb0c74879a7c",
                  "width": 1080,
                  "height": 1080
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a6c55d610eb406034c802727bec6ac4febada474",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c6a453ddda6666ded1701f405ec24e2f75d496d1",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=611c4b3ec0f307d9ea15084d35627095727c964b",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=298fba3bcaacaf77bb5c1550e22daacb112fe208",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=54689faf724212f599951ffd0a01425b29a96d3c",
                    "width": 960,
                    "height": 960
                  },
                  {
                    "url": "https://external-preview.redd.it/MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ef751cb3e67456cfedcee45380f107786fdd07d6",
                    "width": 1080,
                    "height": 1080
                  }
                ],
                "variants": {},
                "id": "MDZqaHJhMHpiOWhmMcFj068Rj0DgnpNZ8CsCym29edo5hoDBuDsl_ml-tUxO"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#0dd3bb",
          "id": "1mijrtd",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ApprehensiveAd3629",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijrtd/its_literally_me/",
          "stickied": false,
          "url": "https://v.redd.it/udnlm90zb9hf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424291,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/udnlm90zb9hf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1080,
              "width": 1080,
              "scrubber_media_url": "https://v.redd.it/udnlm90zb9hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/udnlm90zb9hf1/DASHPlaylist.mpd?a=1757034803%2CZmE1MzBhMTM1NjllMTU2M2I2NWE4YzUwZTA4NTJmMDk2ZjU5NDAyNWZiZDA0MWUxZjQ2NDMxM2E2YjFjMDM1NQ%3D%3D&amp;v=1&amp;f=sd",
              "duration": 33,
              "hls_url": "https://v.redd.it/udnlm90zb9hf1/HLSPlaylist.m3u8?a=1757034803%2CY2NkZTRlM2NiNWY1YWNjNDcyZTQ3NDNmMWMyNzI2MmRhODNmMmFkYTFiZDU0MmFjM2IyMmViNTZiZGE3ODAxZg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Wonder how the 120b model compares to Qwen 3 Coder in 8-bit. ",
          "author_fullname": "t2_13crip",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How To Run OpenAI GPT-OSS 20B and 120B Models on AMD Ryzen AI Processors and Radeon Graphics Cards",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 78,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijros",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.83,
          "author_flair_background_color": null,
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=edf02ad44e2fd6b62003ccb44c3b1bdbd42df4f2",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754424282,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "amd.com",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wonder how the 120b model compares to Qwen 3 Coder in 8-bit. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.amd.com/en/blogs/2025/how-to-run-openai-gpt-oss-20b-120b-models-on-amd-ryzen-ai-radeon.html",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?auto=webp&amp;s=c5bc77b30d5877b6a5932eb0a84c8fb1976e6dc4",
                  "width": 2386,
                  "height": 1336
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=569ee38687589e1134e6e83d5b36da59d9f13822",
                    "width": 108,
                    "height": 60
                  },
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cb26532b06f5ea81f07adfe5a75835b3e05deae",
                    "width": 216,
                    "height": 120
                  },
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e09b639f1669d23c2f81fe7b4aaafa1f08e9b48e",
                    "width": 320,
                    "height": 179
                  },
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f5a2400223098f00c87af89039830dd05676a630",
                    "width": 640,
                    "height": 358
                  },
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=feffe38281ed5c7865f1858eaf5b4a52fdae65b0",
                    "width": 960,
                    "height": 537
                  },
                  {
                    "url": "https://external-preview.redd.it/NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=282032576631f90d79349a3d0d655abf4371e1b6",
                    "width": 1080,
                    "height": 604
                  }
                ],
                "variants": {},
                "id": "NgWDcnPAzAv9C_IdYMqborsydUjUEEFGZXyC17go05Y"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1mijros",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ZZZCodeLyokoZZZ",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijros/how_to_run_openai_gptoss_20b_and_120b_models_on/",
          "stickied": false,
          "url": "https://www.amd.com/en/blogs/2025/how-to-run-openai-gpt-oss-20b-120b-models-on-amd-ryzen-ai-radeon.html",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424282,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "OpenAI worked with llama.cpp and ollama to integrate MXFP4 support. Clearly they see enough benefit in the format to use it over existing formats. Looking forward to seeing wider adoption.",
          "author_fullname": "t2_5dzdp",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "The real OpenAI OSS news is MXFP4",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijqk1",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.79,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 13,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 13,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754424214,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI worked with llama.cpp and ollama to integrate MXFP4 support. Clearly they see enough benefit in the format to use it over existing formats. Looking forward to seeing wider adoption.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mijqk1",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "explorigin",
          "discussion_type": null,
          "num_comments": 15,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijqk1/the_real_openai_oss_news_is_mxfp4/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754424214,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "It says: \"Similar to the OpenAI o-series reasoning models in the API, the two open-weight models support three reasoning efforts—low, medium, and high—which trade off latency vs. performance. Developers can easily set the reasoning effort with one sentence in the system message.\"\n\nWhat do you write in the system message?\n\nAnswer: \"Reasoning: high\"\n\nhttps://huggingface.co/openai/gpt-oss-120b",
          "author_fullname": "t2_e9jh97s",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How to set the reasoning effort for gpt-oss in the system message?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijmmg",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.84,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754424715,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423977,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It says: &amp;quot;Similar to the OpenAI o-series reasoning models in the API, the two open-weight models support three reasoning efforts—low, medium, and high—which trade off latency vs. performance. Developers can easily set the reasoning effort with one sentence in the system message.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What do you write in the system message?&lt;/p&gt;\n\n&lt;p&gt;Answer: &amp;quot;Reasoning: high&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/openai/gpt-oss-120b\"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?auto=webp&amp;s=0871512cd76cbf7bde2f7bd9a5f885c071ce735a",
                  "width": 1200,
                  "height": 648
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=292c3d3a2dfa2ce762d4e0ad0113f21057208fb5",
                    "width": 108,
                    "height": 58
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7caae8dd778b09b71d56e893c0307604fe6185aa",
                    "width": 216,
                    "height": 116
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ffd35e2510c33eb737fe6e23874ab1b1e5a5081",
                    "width": 320,
                    "height": 172
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ae7c659a21f868f6dba51b958c810a90c5bfe24",
                    "width": 640,
                    "height": 345
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e415f43cdae65729878a0ca9f4a7a894ca8be09",
                    "width": 960,
                    "height": 518
                  },
                  {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3acf6478b097b66560a9a81bdaef6463bf66481c",
                    "width": 1080,
                    "height": 583
                  }
                ],
                "variants": {},
                "id": "12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mijmmg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "chibop1",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijmmg/how_to_set_the_reasoning_effort_for_gptoss_in_the/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijmmg/how_to_set_the_reasoning_effort_for_gptoss_in_the/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423977,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Are there any 16GB eGPUs that'll run with a 6-Core AMD Ryzen 7600 from a ROG STRIX B650E-I GAMING motherboard? Or am I out of luck because there's no way to adapt a PCIe slot to an AMD CPU for Thunderbolt? The chassis is an HD.PLEX fanless case.\n\n* https://rog.asus.com/ca-en/motherboards/rog-strix/rog-strix-b650e-i-gaming-wifi-model\n* https://www.amd.com/en/products/processors/desktops/ryzen/7000-series/amd-ryzen-5-7600.html\n* https://hdplex.com/ (https://hdplex.com/hdplex-h1-v3-fanless-computer-case.html)",
          "author_fullname": "t2_14h5xzwj6o",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "External GPU",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mijmmc",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 2,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 2,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754424870,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423977,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any 16GB eGPUs that&amp;#39;ll run with a 6-Core AMD Ryzen 7600 from a ROG STRIX B650E-I GAMING motherboard? Or am I out of luck because there&amp;#39;s no way to adapt a PCIe slot to an AMD CPU for Thunderbolt? The chassis is an HD.PLEX fanless case.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://rog.asus.com/ca-en/motherboards/rog-strix/rog-strix-b650e-i-gaming-wifi-model\"&gt;https://rog.asus.com/ca-en/motherboards/rog-strix/rog-strix-b650e-i-gaming-wifi-model&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amd.com/en/products/processors/desktops/ryzen/7000-series/amd-ryzen-5-7600.html\"&gt;https://www.amd.com/en/products/processors/desktops/ryzen/7000-series/amd-ryzen-5-7600.html&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://hdplex.com/\"&gt;https://hdplex.com/&lt;/a&gt; (&lt;a href=\"https://hdplex.com/hdplex-h1-v3-fanless-computer-case.html\"&gt;https://hdplex.com/hdplex-h1-v3-fanless-computer-case.html&lt;/a&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?auto=webp&amp;s=6abfceab19c67b45ccb7d09342572c271e1e6e1b",
                  "width": 2000,
                  "height": 1470
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=df22d2270b613db5fa98812f5f655bebe4dcf003",
                    "width": 108,
                    "height": 79
                  },
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e7e32217c2fb981b9f70291595d9ac87c6d0be7",
                    "width": 216,
                    "height": 158
                  },
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dbe6a0be51a65e33f84d03aab95feac829b840c",
                    "width": 320,
                    "height": 235
                  },
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=547f808060147d7abe63fe0ceea77a05147d2682",
                    "width": 640,
                    "height": 470
                  },
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6030b8861d74211a54a6c7c8b9ff41ed97c7a075",
                    "width": 960,
                    "height": 705
                  },
                  {
                    "url": "https://external-preview.redd.it/6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53bb4fac9db81c47b070f3d35c8e538da5e95eb1",
                    "width": 1080,
                    "height": 793
                  }
                ],
                "variants": {},
                "id": "6FHpn-HETuzbSEb0_N3XYhVtN6t98xu0R9tGj3ti3IE"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1mijmmc",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "autonoma_2042",
          "discussion_type": null,
          "num_comments": 3,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijmmc/external_gpu/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijmmc/external_gpu/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423977,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Just tested **GPT-OSS-20B** locally using **LM Studio v0.3.21-b4** on my machine with an **RTX 5090 32GB VRAM + Ryzen 9 9950X3D + 96 GB RAM**.\n\nEverything is set to **default**, no tweaks. I only enabled **Flash Attention** manually.\n\nUsing:\n\n* **Runtime Engine**: `CUDA 12 llama.cpp (Windows)` – v1.44.0\n* LM Studio auto-selected all default values (batch size, offload, KV cache, etc.)\n\n🔹 **Result**:  \n→ **\\~221 tokens/sec**  \n→ **\\~0.20s to first token**\n\nModel runs **super smooth**, very responsive. Impressed with how optimized GPT-OSS-20B is out of the box.\n\nhttps://preview.redd.it/rtsvu484a9hf1.png?width=1032&amp;format=png&amp;auto=webp&amp;s=5f9c01493860c0c16e282ba31d9466b2d798fa5c\n\nhttps://preview.redd.it/ybeinwa5a9hf1.png?width=556&amp;format=png&amp;auto=webp&amp;s=3f8d61a59becc6668fcef27237138fa00373d8ad\n\nhttps://preview.redd.it/dxfz0666a9hf1.png?width=1612&amp;format=png&amp;auto=webp&amp;s=4352954b6593cdf3ad777d8c46320dab4ca1eeb0",
          "author_fullname": "t2_h755hoap",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS-20B on RTX 5090 – 221 tok/s in LM Studio (default settings + FlashAttention)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 114,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "ybeinwa5a9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 143,
                  "x": 108,
                  "u": "https://preview.redd.it/ybeinwa5a9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=55a75512e6bb407244219436b876c780df13f935"
                },
                {
                  "y": 286,
                  "x": 216,
                  "u": "https://preview.redd.it/ybeinwa5a9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f39df8ac6712b46b47ca5e762131eff8931e8a1a"
                },
                {
                  "y": 424,
                  "x": 320,
                  "u": "https://preview.redd.it/ybeinwa5a9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=088ab9795b0fc0ee7575e16325f2e9c365e81860"
                }
              ],
              "s": {
                "y": 737,
                "x": 556,
                "u": "https://preview.redd.it/ybeinwa5a9hf1.png?width=556&amp;format=png&amp;auto=webp&amp;s=3f8d61a59becc6668fcef27237138fa00373d8ad"
              },
              "id": "ybeinwa5a9hf1"
            },
            "rtsvu484a9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 88,
                  "x": 108,
                  "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa121095f116d690afc5beec8b33465d965fc28c"
                },
                {
                  "y": 176,
                  "x": 216,
                  "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3e149b1e6da0a74d4da7429f3e370b3ef920c62"
                },
                {
                  "y": 261,
                  "x": 320,
                  "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d1eb768164f08a783ff987e41c86437ae1b4222"
                },
                {
                  "y": 522,
                  "x": 640,
                  "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e834afdde4b72a887f51e181b83b674c50a50f78"
                },
                {
                  "y": 784,
                  "x": 960,
                  "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=73e8b18c46ba21d05cb21889fa6be08f92d72038"
                }
              ],
              "s": {
                "y": 843,
                "x": 1032,
                "u": "https://preview.redd.it/rtsvu484a9hf1.png?width=1032&amp;format=png&amp;auto=webp&amp;s=5f9c01493860c0c16e282ba31d9466b2d798fa5c"
              },
              "id": "rtsvu484a9hf1"
            },
            "dxfz0666a9hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 66,
                  "x": 108,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8b5924252fb7e6ca4e6ebc8eddfde5fc4e71f4b"
                },
                {
                  "y": 132,
                  "x": 216,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=76e128006f277171986b8ad5591607350006d4d3"
                },
                {
                  "y": 195,
                  "x": 320,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9d5dfd2b207bd8630304607e4738b448c6d9b6e"
                },
                {
                  "y": 391,
                  "x": 640,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=102dd323b9f8c5663a4e8424478af055689a4562"
                },
                {
                  "y": 587,
                  "x": 960,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6b5dd421e143beb87f4bf103665b7acef51526a3"
                },
                {
                  "y": 661,
                  "x": 1080,
                  "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e319b33433f8041048b430fcbaa115faffa29ef9"
                }
              ],
              "s": {
                "y": 987,
                "x": 1612,
                "u": "https://preview.redd.it/dxfz0666a9hf1.png?width=1612&amp;format=png&amp;auto=webp&amp;s=4352954b6593cdf3ad777d8c46320dab4ca1eeb0"
              },
              "id": "dxfz0666a9hf1"
            }
          },
          "name": "t3_1mijfyz",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.73,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/iFZ8uGX59JQ3nY14M3TuGb-H0n5YbTPl86UHD1-29oY.jpg",
          "edited": 1754423887,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423552,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just tested &lt;strong&gt;GPT-OSS-20B&lt;/strong&gt; locally using &lt;strong&gt;LM Studio v0.3.21-b4&lt;/strong&gt; on my machine with an &lt;strong&gt;RTX 5090 32GB VRAM + Ryzen 9 9950X3D + 96 GB RAM&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Everything is set to &lt;strong&gt;default&lt;/strong&gt;, no tweaks. I only enabled &lt;strong&gt;Flash Attention&lt;/strong&gt; manually.&lt;/p&gt;\n\n&lt;p&gt;Using:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Runtime Engine&lt;/strong&gt;: &lt;code&gt;CUDA 12 llama.cpp (Windows)&lt;/code&gt; – v1.44.0&lt;/li&gt;\n&lt;li&gt;LM Studio auto-selected all default values (batch size, offload, KV cache, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;🔹 &lt;strong&gt;Result&lt;/strong&gt;:&lt;br/&gt;\n→ &lt;strong&gt;~221 tokens/sec&lt;/strong&gt;&lt;br/&gt;\n→ &lt;strong&gt;~0.20s to first token&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Model runs &lt;strong&gt;super smooth&lt;/strong&gt;, very responsive. Impressed with how optimized GPT-OSS-20B is out of the box.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rtsvu484a9hf1.png?width=1032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f9c01493860c0c16e282ba31d9466b2d798fa5c\"&gt;https://preview.redd.it/rtsvu484a9hf1.png?width=1032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f9c01493860c0c16e282ba31d9466b2d798fa5c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ybeinwa5a9hf1.png?width=556&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f8d61a59becc6668fcef27237138fa00373d8ad\"&gt;https://preview.redd.it/ybeinwa5a9hf1.png?width=556&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f8d61a59becc6668fcef27237138fa00373d8ad&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dxfz0666a9hf1.png?width=1612&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4352954b6593cdf3ad777d8c46320dab4ca1eeb0\"&gt;https://preview.redd.it/dxfz0666a9hf1.png?width=1612&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4352954b6593cdf3ad777d8c46320dab4ca1eeb0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1mijfyz",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Spiritual_Tie_5574",
          "discussion_type": null,
          "num_comments": 7,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijfyz/gptoss20b_on_rtx_5090_221_toks_in_lm_studio/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijfyz/gptoss20b_on_rtx_5090_221_toks_in_lm_studio/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423552,
          "num_crossposts": 1,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Obviously, the big grumpy guy that I am couldn't help but download these 2 models in order to mess around with them a bit.  \nHardware for this test: CPU Ryzen 9900x + 128GB DDR5 5200MHz + RTX 3090 + RTX 3060\n\nSo for GPT-OSS-20B 64K + Mcp it's not too comfortable but I'm certain there will be improvements:\n\nhttps://preview.redd.it/pwywcy3v19hf1.png?width=1086&amp;format=png&amp;auto=webp&amp;s=549d2e2d8dce02caa1c51b2cc8e154dd55266315\n\nSpeed T/S :\n\nPrompt : \"Write a story about the quantum litter radioactive cat. 5000 words minimum.\"\n\nThe responses surprisingly approach 4200 words at a speed of \\~82 t/s\n\nhttps://preview.redd.it/w4rhnzyl29hf1.png?width=958&amp;format=png&amp;auto=webp&amp;s=79fad4f8bf8b774118f83a2c7e3ae95e91d20865\n\nNow for the GPT-OSS-120b 64K 16 Layers :\n\nMCP test :\n\nhttps://preview.redd.it/udhmyjy549hf1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=5a909f6aea9402f4124a4ff6a38f827667339800\n\nOUCH ! I'm not going to be spiteful, it's surely a poor adaptation to the models' syntax for function calling. It's their first attempt and it's still respectable to have opened up a model for us plebs.\n\nSpeed T/S 16K to free up some VRAM\n\nPrompt : \"Write a story about the quantum litter radioactive cat. 5000 words minimum.\"\n\nhttps://preview.redd.it/anhax6tj89hf1.png?width=1003&amp;format=png&amp;auto=webp&amp;s=038ce1c30cb37599060072df9af6e7a34a799aaf\n\n7.35 tok/s - \\~6200 words. Beyond the speed which remains a variable factor depending on the environment where the model is used, the consistency and adherence to instructions is just perfect!  \nThe structure of the response is perfectly adapted, I didn't include any system prompt. Bravo!  \nThe response here: [https://pastebin.com/xrah1knE](https://pastebin.com/xrah1knE)\n\nNow we just have to wait for Musk's 'response' 😂\n\nhttps://preview.redd.it/tvdwi6rk99hf1.jpg?width=1224&amp;format=pjpg&amp;auto=webp&amp;s=3c426dce948ece2c6d80d97fa73d495ce7206395",
          "author_fullname": "t2_ti5m9mpc",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS-20B &amp; GPT-OSS-120B on LmStudio + MCP",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 66,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "tvdwi6rk99hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 72,
                  "x": 108,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=634632c47d94c1bf51771c92b853f44dd190c7fa"
                },
                {
                  "y": 144,
                  "x": 216,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42787c6fe684c2422bf09ac56d34adcec50230b4"
                },
                {
                  "y": 213,
                  "x": 320,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=32abb2afb9de8098c59ea8fcd852d4c96cae2cf1"
                },
                {
                  "y": 426,
                  "x": 640,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ccca3d4359aa46f97e1eb7c4e5bec7eba01cb59"
                },
                {
                  "y": 640,
                  "x": 960,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd140503961abe701c3156ab4564084b791ccd44"
                },
                {
                  "y": 720,
                  "x": 1080,
                  "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d5daa6a1a902641082ad85842215eb76149ce21"
                }
              ],
              "s": {
                "y": 816,
                "x": 1224,
                "u": "https://preview.redd.it/tvdwi6rk99hf1.jpg?width=1224&amp;format=pjpg&amp;auto=webp&amp;s=3c426dce948ece2c6d80d97fa73d495ce7206395"
              },
              "id": "tvdwi6rk99hf1"
            },
            "pwywcy3v19hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 51,
                  "x": 108,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3022ed0c39ed458106f352c989ccaa99384025be"
                },
                {
                  "y": 102,
                  "x": 216,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c27a6e81b1b1434273378f135d265f3d3ba28372"
                },
                {
                  "y": 152,
                  "x": 320,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e01846b4851ba7a209a074f9a649dd32c50238c"
                },
                {
                  "y": 304,
                  "x": 640,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ffb5385be96be8f350fa62ad5c31cf650828fc8e"
                },
                {
                  "y": 456,
                  "x": 960,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ca108023447d08594732dde8e26acec7342575ce"
                },
                {
                  "y": 513,
                  "x": 1080,
                  "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0019a6f2a590c6114edbcb547a49b0f1a8c71afa"
                }
              ],
              "s": {
                "y": 516,
                "x": 1086,
                "u": "https://preview.redd.it/pwywcy3v19hf1.png?width=1086&amp;format=png&amp;auto=webp&amp;s=549d2e2d8dce02caa1c51b2cc8e154dd55266315"
              },
              "id": "pwywcy3v19hf1"
            },
            "anhax6tj89hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 120,
                  "x": 108,
                  "u": "https://preview.redd.it/anhax6tj89hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=858aa3cd88b27433981ff8431fab1ff2b326f366"
                },
                {
                  "y": 240,
                  "x": 216,
                  "u": "https://preview.redd.it/anhax6tj89hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=51e679c4cf18352a820b6600d65e74425f1bf7a3"
                },
                {
                  "y": 356,
                  "x": 320,
                  "u": "https://preview.redd.it/anhax6tj89hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d82c1ccc2384bba1218738d69b21bbc88ceabe1f"
                },
                {
                  "y": 712,
                  "x": 640,
                  "u": "https://preview.redd.it/anhax6tj89hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7fee161339a790b4196b92261d99588d9d6623d1"
                },
                {
                  "y": 1068,
                  "x": 960,
                  "u": "https://preview.redd.it/anhax6tj89hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6bba0a82f59522425ed68797977eee318d741baf"
                }
              ],
              "s": {
                "y": 1116,
                "x": 1003,
                "u": "https://preview.redd.it/anhax6tj89hf1.png?width=1003&amp;format=png&amp;auto=webp&amp;s=038ce1c30cb37599060072df9af6e7a34a799aaf"
              },
              "id": "anhax6tj89hf1"
            },
            "udhmyjy549hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 67,
                  "x": 108,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9434fc4714a73ac57a7adfc97eadeddf5fab3d51"
                },
                {
                  "y": 135,
                  "x": 216,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=79b0781b4500ce1e3c822f5e263073a1f814f51e"
                },
                {
                  "y": 200,
                  "x": 320,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e5187e0b85526991898d24d99d8b93a1e448ca5"
                },
                {
                  "y": 401,
                  "x": 640,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=49d43a1efc534bdb1ea7bb44dc417c181f866d7f"
                },
                {
                  "y": 601,
                  "x": 960,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=450b2653331cf5b871051e8f5d2144d8c41d91b9"
                },
                {
                  "y": 676,
                  "x": 1080,
                  "u": "https://preview.redd.it/udhmyjy549hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7b6d71eefb606d90c55fc8672cfed36d878bdba5"
                }
              ],
              "s": {
                "y": 685,
                "x": 1093,
                "u": "https://preview.redd.it/udhmyjy549hf1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=5a909f6aea9402f4124a4ff6a38f827667339800"
              },
              "id": "udhmyjy549hf1"
            },
            "w4rhnzyl29hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 32,
                  "x": 108,
                  "u": "https://preview.redd.it/w4rhnzyl29hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2747075dee618c4a8c028f2b59e7096969f6d395"
                },
                {
                  "y": 64,
                  "x": 216,
                  "u": "https://preview.redd.it/w4rhnzyl29hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2fae5489deed10dc200c1886ab40831a27ed36b5"
                },
                {
                  "y": 95,
                  "x": 320,
                  "u": "https://preview.redd.it/w4rhnzyl29hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e87941799210a037a9c8ba0e06141cf4775f7b32"
                },
                {
                  "y": 191,
                  "x": 640,
                  "u": "https://preview.redd.it/w4rhnzyl29hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=46ace8510a1a6963e5cfa40d6b45e93d6d02c5bc"
                }
              ],
              "s": {
                "y": 286,
                "x": 958,
                "u": "https://preview.redd.it/w4rhnzyl29hf1.png?width=958&amp;format=png&amp;auto=webp&amp;s=79fad4f8bf8b774118f83a2c7e3ae95e91d20865"
              },
              "id": "w4rhnzyl29hf1"
            }
          },
          "name": "t3_1mijdx7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.73,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/wY7FabmYDlvlQb3JBksr9rWKLpUR9ztXVhw_RGgxTsU.jpg",
          "edited": 1754423745,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423424,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Obviously, the big grumpy guy that I am couldn&amp;#39;t help but download these 2 models in order to mess around with them a bit.&lt;br/&gt;\nHardware for this test: CPU Ryzen 9900x + 128GB DDR5 5200MHz + RTX 3090 + RTX 3060&lt;/p&gt;\n\n&lt;p&gt;So for GPT-OSS-20B 64K + Mcp it&amp;#39;s not too comfortable but I&amp;#39;m certain there will be improvements:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pwywcy3v19hf1.png?width=1086&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=549d2e2d8dce02caa1c51b2cc8e154dd55266315\"&gt;https://preview.redd.it/pwywcy3v19hf1.png?width=1086&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=549d2e2d8dce02caa1c51b2cc8e154dd55266315&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Speed T/S :&lt;/p&gt;\n\n&lt;p&gt;Prompt : &amp;quot;Write a story about the quantum litter radioactive cat. 5000 words minimum.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The responses surprisingly approach 4200 words at a speed of ~82 t/s&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w4rhnzyl29hf1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=79fad4f8bf8b774118f83a2c7e3ae95e91d20865\"&gt;https://preview.redd.it/w4rhnzyl29hf1.png?width=958&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=79fad4f8bf8b774118f83a2c7e3ae95e91d20865&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Now for the GPT-OSS-120b 64K 16 Layers :&lt;/p&gt;\n\n&lt;p&gt;MCP test :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/udhmyjy549hf1.png?width=1093&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a909f6aea9402f4124a4ff6a38f827667339800\"&gt;https://preview.redd.it/udhmyjy549hf1.png?width=1093&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a909f6aea9402f4124a4ff6a38f827667339800&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;OUCH ! I&amp;#39;m not going to be spiteful, it&amp;#39;s surely a poor adaptation to the models&amp;#39; syntax for function calling. It&amp;#39;s their first attempt and it&amp;#39;s still respectable to have opened up a model for us plebs.&lt;/p&gt;\n\n&lt;p&gt;Speed T/S 16K to free up some VRAM&lt;/p&gt;\n\n&lt;p&gt;Prompt : &amp;quot;Write a story about the quantum litter radioactive cat. 5000 words minimum.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/anhax6tj89hf1.png?width=1003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=038ce1c30cb37599060072df9af6e7a34a799aaf\"&gt;https://preview.redd.it/anhax6tj89hf1.png?width=1003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=038ce1c30cb37599060072df9af6e7a34a799aaf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;7.35 tok/s - ~6200 words. Beyond the speed which remains a variable factor depending on the environment where the model is used, the consistency and adherence to instructions is just perfect!&lt;br/&gt;\nThe structure of the response is perfectly adapted, I didn&amp;#39;t include any system prompt. Bravo!&lt;br/&gt;\nThe response here: &lt;a href=\"https://pastebin.com/xrah1knE\"&gt;https://pastebin.com/xrah1knE&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Now we just have to wait for Musk&amp;#39;s &amp;#39;response&amp;#39; 😂&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tvdwi6rk99hf1.jpg?width=1224&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3c426dce948ece2c6d80d97fa73d495ce7206395\"&gt;https://preview.redd.it/tvdwi6rk99hf1.jpg?width=1224&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=3c426dce948ece2c6d80d97fa73d495ce7206395&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mijdx7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Ok_Ninja7526",
          "discussion_type": null,
          "num_comments": 10,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijdx7/gptoss20b_gptoss120b_on_lmstudio_mcp/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mijdx7/gptoss20b_gptoss120b_on_lmstudio_mcp/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423424,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_akbc8z42",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "When Grok 3?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 76,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "35wdu0ky89hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 59,
                  "x": 108,
                  "u": "https://preview.redd.it/35wdu0ky89hf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b5b0912f3bcc38cca9580952f08da28e255a4ab0"
                },
                {
                  "y": 118,
                  "x": 216,
                  "u": "https://preview.redd.it/35wdu0ky89hf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ebc7fe93f8f5e7b87579aff6f2dc9d7c97088270"
                },
                {
                  "y": 175,
                  "x": 320,
                  "u": "https://preview.redd.it/35wdu0ky89hf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=32b07866c2bebefd3bea5c6aee81e195d4b54e99"
                },
                {
                  "y": 350,
                  "x": 640,
                  "u": "https://preview.redd.it/35wdu0ky89hf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b958aa953622cf39e6bff64e8bd82b52acb9025b"
                }
              ],
              "s": {
                "y": 500,
                "x": 912,
                "u": "https://preview.redd.it/35wdu0ky89hf1.jpg?width=912&amp;format=pjpg&amp;auto=webp&amp;s=3b6df6a5ed99db70fd38a42601ab7303ecb1f319"
              },
              "id": "35wdu0ky89hf1"
            },
            "9z4q006c99hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 79,
                  "x": 108,
                  "u": "https://preview.redd.it/9z4q006c99hf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f75335e3da31ce4918310b3a15d8a47bf923544a"
                },
                {
                  "y": 159,
                  "x": 216,
                  "u": "https://preview.redd.it/9z4q006c99hf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=66d32341db078f343ff8a6b7af298a38f2a3c142"
                },
                {
                  "y": 236,
                  "x": 320,
                  "u": "https://preview.redd.it/9z4q006c99hf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=019bc86fed1f0fa2db25f8992307999911d31519"
                },
                {
                  "y": 472,
                  "x": 640,
                  "u": "https://preview.redd.it/9z4q006c99hf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=99eefc05e5f84bcb98613245d2d83ca7c352cc13"
                }
              ],
              "s": {
                "y": 654,
                "x": 886,
                "u": "https://preview.redd.it/9z4q006c99hf1.jpg?width=886&amp;format=pjpg&amp;auto=webp&amp;s=84b54cc719d528b00ad28dcdb2060d4ddd187edf"
              },
              "id": "9z4q006c99hf1"
            }
          },
          "name": "t3_1mijcv7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "ups": 17,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "35wdu0ky89hf1",
                "id": 721988085
              },
              {
                "media_id": "9z4q006c99hf1",
                "id": 721988086
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 17,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/16O7PzcQf9rGw0YrZSjuIaSfIuWc2xz1NjXyxZEKFSs.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754423357,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mijcv7",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mijcv7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Wrong_User_Logged",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mijcv7/when_grok_3/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mijcv7",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423357,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "So MXFP4 just entered the zeitgeist out of nowhere.\n\nWhat are the implications for this newfangled technology on our GPUs and Macs with Apple Silicon?\n\nRDNA3/4? Various Nvidia generations? Apple silicon?\n\nI asked Gemini for a quick summary on my phone and the result was unintelligible (everything is awesome!!!1!! was pretty much the answer).\n\nAny insight is appreciated.",
          "author_fullname": "t2_iol3buybk",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "MXFP4 and various hardware",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mij7ki",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.67,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 5,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 5,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423032,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So MXFP4 just entered the zeitgeist out of nowhere.&lt;/p&gt;\n\n&lt;p&gt;What are the implications for this newfangled technology on our GPUs and Macs with Apple Silicon?&lt;/p&gt;\n\n&lt;p&gt;RDNA3/4? Various Nvidia generations? Apple silicon?&lt;/p&gt;\n\n&lt;p&gt;I asked Gemini for a quick summary on my phone and the result was unintelligible (everything is awesome!!!1!! was pretty much the answer).&lt;/p&gt;\n\n&lt;p&gt;Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mij7ki",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Thrumpwart",
          "discussion_type": null,
          "num_comments": 6,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mij7ki/mxfp4_and_various_hardware/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mij7ki/mxfp4_and_various_hardware/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423032,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Just starting a community-driven thread.\n\n|Model|License|Commercial Use|Link to License|\n|:-|:-|:-|:-|\n|Qwen 3|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://github.com/QwenLM/Qwen3)|\n|Qwen 2.5 excl. 3B &amp; 72B|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://huggingface.co/Qwen/Qwen2.5-14B/blob/main/LICENSE)|\n|gpt-oss-120b|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://huggingface.co/openai/gpt-oss-120b/blob/main/LICENSE)|\n|gpt-oss-20b|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://huggingface.co/openai/gpt-oss-20b/blob/main/LICENSE)|\n|OLMo series (all)|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://huggingface.co/allenai/OLMo-7B)|\n|Mistral and Magistral Small 3|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://mistral.ai/news/mistral-small-3), [LICENSE](https://mistral.ai/news/magistral)|\n|DeepSeek r1|MIT *unmodified*|Allowed|[LICENSE](https://huggingface.co/deepseek-ai/DeepSeek-R1/blob/main/LICENSE)|\n|DeepSeek v3-0324|MIT *unmodified*|Allowed|[LICENSE](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/blob/main/LICENSE)|\n|DeepSeek r1 Qwen Distill|MIT *unmodified*|Allowed|[LICENSE](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/blob/main/LICENSE)|\n|GLM 4 0414|MIT *unmodified*|Allowed|[LICENSE](https://huggingface.co/zai-org/GLM-4-32B-0414/blob/main/LICENSE)|\n|GLM 4.5|MIT *unmodified*|Allowed|[LICENSE](https://huggingface.co/zai-org/GLM-4.5)|\n|IBM Granite|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://github.com/ibm-granite/granite-code-models/blob/main/LICENSE)|\n|Ernie 4.5|Apache 2.0 *unmodified*|Allowed|[LICENSE](https://github.com/PaddlePaddle/ERNIE/blob/develop/LICENSE)|\n\nAny others? Surprisingly small list.",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "List of open-weight models with unmodified permissive licenses",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mij7fh",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.89,
          "author_flair_background_color": "transparent",
          "subreddit_type": "public",
          "ups": 47,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 47,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": 1754437993,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754423021,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just starting a community-driven thread.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;License&lt;/th&gt;\n&lt;th align=\"left\"&gt;Commercial Use&lt;/th&gt;\n&lt;th align=\"left\"&gt;Link to License&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/QwenLM/Qwen3\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 2.5 excl. 3B &amp;amp; 72B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/Qwen/Qwen2.5-14B/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;gpt-oss-120b&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/openai/gpt-oss-120b/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;gpt-oss-20b&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/openai/gpt-oss-20b/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;OLMo series (all)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/allenai/OLMo-7B\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Mistral and Magistral Small 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://mistral.ai/news/mistral-small-3\"&gt;LICENSE&lt;/a&gt;, &lt;a href=\"https://mistral.ai/news/magistral\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DeepSeek r1&lt;/td&gt;\n&lt;td align=\"left\"&gt;MIT &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DeepSeek v3-0324&lt;/td&gt;\n&lt;td align=\"left\"&gt;MIT &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;DeepSeek r1 Qwen Distill&lt;/td&gt;\n&lt;td align=\"left\"&gt;MIT &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;GLM 4 0414&lt;/td&gt;\n&lt;td align=\"left\"&gt;MIT &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/zai-org/GLM-4-32B-0414/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;GLM 4.5&lt;/td&gt;\n&lt;td align=\"left\"&gt;MIT &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://huggingface.co/zai-org/GLM-4.5\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;IBM Granite&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/ibm-granite/granite-code-models/blob/main/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Ernie 4.5&lt;/td&gt;\n&lt;td align=\"left\"&gt;Apache 2.0 &lt;em&gt;unmodified&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Allowed&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://github.com/PaddlePaddle/ERNIE/blob/develop/LICENSE\"&gt;LICENSE&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Any others? Surprisingly small list.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?auto=webp&amp;s=dc3301f6a0ba9f4b4d1e5e8a211b806cc1b2487b",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b5dd80343742975b635d2403d8ef5e02be2e423",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e7abc6325f245133c1b11bbb4d7339f05341622e",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c476083090a1786628545cc87a7111ebee8b92cb",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=42c82d83fa413f519378562e1894d78be11b3efe",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=28fbe0f51b68533a20b5b615d44beea575e31a4d",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0cf51aa37db2932605b9495a3c802fa8f8b779eb",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "fxTXWWdnNDFfIAA3ubz5TQddkg3cvUBVmDyXj7yO72Q"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1mij7fh",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 13,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1mij7fh/list_of_openweight_models_with_unmodified/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mij7fh/list_of_openweight_models_with_unmodified/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754423021,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Not trying to spark a model war, just sharing numbers that surprised me. Based on today’s releases and the evals below, OpenAI’s open-weights models edge out Claude Opus 4.1 across math (AIME 2025, with tools), graduate-level QA (GPQA Diamond, no tools), and general knowledge (MMLU, no tools). If these hold up, you no longer have to trade openness for top-tier capability.",
          "author_fullname": "t2_1gf0pq2",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "Open-weights just beat Opus 4.1 on today’s benchmarks (AIME’25, GPQA, MMLU)",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 132,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "iguzgaze79hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 68,
                  "x": 108,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b82347cb2d337417ad73b732192269e1d91a60f"
                },
                {
                  "y": 136,
                  "x": 216,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a0ecb6ee3c737512b9bf8fff8a92b18b2ea358c"
                },
                {
                  "y": 202,
                  "x": 320,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47c5d7b914ff117d9c15a77f5428f01b2c43199a"
                },
                {
                  "y": 405,
                  "x": 640,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=479accb8c3b160978b7228099d9518355570a5d5"
                },
                {
                  "y": 608,
                  "x": 960,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d32cebb2ca3905d0293d6b0ced64ec242a06ced1"
                },
                {
                  "y": 684,
                  "x": 1080,
                  "u": "https://preview.redd.it/iguzgaze79hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=34a244bfbb0ceec9500433fa1248c4522eb73306"
                }
              ],
              "s": {
                "y": 946,
                "x": 1492,
                "u": "https://preview.redd.it/iguzgaze79hf1.png?width=1492&amp;format=png&amp;auto=webp&amp;s=29781ca0c140861f46559830c816ad4f64712535"
              },
              "id": "iguzgaze79hf1"
            },
            "i1d26o2f79hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 86,
                  "x": 108,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=711775b1d17d95a2c4f84b4fc215a0e2f2b72c88"
                },
                {
                  "y": 173,
                  "x": 216,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f44d0392945780ca5ba0adc469db81cc396a06e"
                },
                {
                  "y": 256,
                  "x": 320,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bffc006447f99876bb0eeee260fcf60429b9f4ec"
                },
                {
                  "y": 512,
                  "x": 640,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b80a91801e01cbfb23a413b2606a035c1bf07ef"
                },
                {
                  "y": 769,
                  "x": 960,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ebf2170984439e5b0f94f89bd51b4c976dbb899"
                },
                {
                  "y": 865,
                  "x": 1080,
                  "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ac27a1cb83f5d4b0f0e0f03f6e40d5bea6eafc21"
                }
              ],
              "s": {
                "y": 2084,
                "x": 2600,
                "u": "https://preview.redd.it/i1d26o2f79hf1.jpg?width=2600&amp;format=pjpg&amp;auto=webp&amp;s=c9a6cc583783bc21e5ed1ff9df63a84abe36bbc2"
              },
              "id": "i1d26o2f79hf1"
            },
            "yxygc8oe79hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/jpg",
              "p": [
                {
                  "y": 102,
                  "x": 108,
                  "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ca7580f4feafe7b0313b10acb6a0d5176a6d64c"
                },
                {
                  "y": 204,
                  "x": 216,
                  "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffb82076cb0fbf5533d63eaa66d37ea972e18ccf"
                },
                {
                  "y": 303,
                  "x": 320,
                  "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a62346e4c3c2bed33dcf1214fc934150d8ae8d9"
                },
                {
                  "y": 606,
                  "x": 640,
                  "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03242173dd2cb1a40f1b1dc5fb6edf29a1bc5ebc"
                },
                {
                  "y": 910,
                  "x": 960,
                  "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3bae03c82dc47a0de42833d9e7d76acca79c6cd"
                }
              ],
              "s": {
                "y": 917,
                "x": 967,
                "u": "https://preview.redd.it/yxygc8oe79hf1.jpg?width=967&amp;format=pjpg&amp;auto=webp&amp;s=c4a8d8d1e776468003db25969cbe0f2edc8f2f96"
              },
              "id": "yxygc8oe79hf1"
            }
          },
          "name": "t3_1mij25y",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.74,
          "author_flair_background_color": null,
          "ups": 27,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "caption": "",
                "media_id": "yxygc8oe79hf1",
                "id": 721980956
              },
              {
                "caption": "",
                "media_id": "iguzgaze79hf1",
                "id": 721980957
              },
              {
                "caption": "",
                "media_id": "i1d26o2f79hf1",
                "id": 721980958
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 27,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": true,
          "thumbnail": "https://b.thumbs.redditmedia.com/YuQfkziAZhPknOI285v1xDu4Y9rInEz_NVoxbbzydXc.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754422695,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not trying to spark a model war, just sharing numbers that surprised me. Based on today’s releases and the evals below, OpenAI’s open-weights models edge out Claude Opus 4.1 across math (AIME 2025, with tools), graduate-level QA (GPQA Diamond, no tools), and general knowledge (MMLU, no tools). If these hold up, you no longer have to trade openness for top-tier capability.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1mij25y",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mij25y",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "dictionizzle",
          "discussion_type": null,
          "num_comments": 18,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mij25y/openweights_just_beat_opus_41_on_todays/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1mij25y",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422695,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey I just wanted to make a space for people to talk about how well the new open-source models work with claude code? I don't have a chance to try it out yet, but im excited, and think it could finally actually offline my set up. What are y'alls thoughts?",
          "author_fullname": "t2_pp3tet3",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "New GPT-OSS and Claude Code?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1mij1ux",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.91,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 9,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 9,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754422675,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I just wanted to make a space for people to talk about how well the new open-source models work with claude code? I don&amp;#39;t have a chance to try it out yet, but im excited, and think it could finally actually offline my set up. What are y&amp;#39;alls thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1mij1ux",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "LyAkolon",
          "discussion_type": null,
          "num_comments": 5,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1mij1ux/new_gptoss_and_claude_code/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mij1ux/new_gptoss_and_claude_code/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422675,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Hey //locallama,\n\nI’m using the desktop Studio app for local inference and love having everything in one place.  \n\nWhat I’m missing is any way to \\*\\*point LM Studio at an external OpenAI‑compatible endpoint\\*\\* (Ollama, a hosted OpenAI‑style server, etc.) from within the UI.\n\nI know alternatives like \\*\\*Open WebUI\\*\\* can be extended to proxy external services, but I’d rather keep a single, native desktop tool for inference, prompt‑engineering, and any API calls.\n\n\n\n\n\n1. Is the lack of external‑API support a deliberate limitation right now?\n\n2. Is there a roadmap for adding OpenAI‑style function‑calling or a plug‑in system that can forward requests to another compatible server?  \n\n3. Are there any known work‑arounds (local proxy scripts, community extensions etc.) that let LM Studio act as a client for an external OpenAI‑compatible API?\n\n\n\nAny official statements, issue/PR links, or community hacks would be hugely helpful. Thanks! 🙏",
          "author_fullname": "t2_41wov",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Why doesn’t LM Studio let me call external OpenAI‑compatible APIs (e.g., Ollama)?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miixs4",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.56,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754422417,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey //locallama,&lt;/p&gt;\n\n&lt;p&gt;I’m using the desktop Studio app for local inference and love having everything in one place.  &lt;/p&gt;\n\n&lt;p&gt;What I’m missing is any way to **point LM Studio at an external OpenAI‑compatible endpoint** (Ollama, a hosted OpenAI‑style server, etc.) from within the UI.&lt;/p&gt;\n\n&lt;p&gt;I know alternatives like **Open WebUI** can be extended to proxy external services, but I’d rather keep a single, native desktop tool for inference, prompt‑engineering, and any API calls.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is the lack of external‑API support a deliberate limitation right now?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is there a roadmap for adding OpenAI‑style function‑calling or a plug‑in system that can forward requests to another compatible server?  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there any known work‑arounds (local proxy scripts, community extensions etc.) that let LM Studio act as a client for an external OpenAI‑compatible API?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any official statements, issue/PR links, or community hacks would be hugely helpful. Thanks! 🙏&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miixs4",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "myusuf3",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miixs4/why_doesnt_lm_studio_let_me_call_external/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miixs4/why_doesnt_lm_studio_let_me_call_external/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422417,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Pl share what has worked for you, thank you!",
          "author_fullname": "t2_st6lbceni",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "How to ingest nested tables in RAG pipeline?",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miixbr",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754422388,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pl share what has worked for you, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1miixbr",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Significant_Idea2495",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miixbr/how_to_ingest_nested_tables_in_rag_pipeline/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miixbr/how_to_ingest_nested_tables_in_rag_pipeline/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422388,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_l8w0vsc0",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT-OSS 20B running on an 8GB windows laptop. Slow but is running 😁",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miivx7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.65,
          "author_flair_background_color": null,
          "ups": 11,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/b7bkgyr869hf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1920,
              "width": 1080,
              "scrubber_media_url": "https://v.redd.it/b7bkgyr869hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/b7bkgyr869hf1/DASHPlaylist.mpd?a=1757034803%2CNjhjM2E2Yjc3NzJlY2NhMTgzMjUzNjQ1MzI5Y2M3ZjRlNDRmNzhlNmI3M2MyNzlkYzdjMGI5ZGYyYzA5MzAxNg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 28,
              "hls_url": "https://v.redd.it/b7bkgyr869hf1/HLSPlaylist.m3u8?a=1757034803%2CMjkyZGI5ZDZlYmQzMjU4MTkxNmVhMGQxZWNkZGY2MzkzOTg3MGRkYjhkYWQxNzQ2OGY4MGU4OWMyYzMyZTVkZg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 11,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=920a909bb7dde0b83cd17105727c257fbf4b2bc0",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754422300,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/b7bkgyr869hf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?format=pjpg&amp;auto=webp&amp;s=eab3631ec86c663112467ba25dfd87007e2ad4e3",
                  "width": 1080,
                  "height": 1920
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=97194cfa798591c42a73bb2ec264c3fedaf49503",
                    "width": 108,
                    "height": 192
                  },
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ca1636a3dcba941a2753702f3fed903be5d69ea2",
                    "width": 216,
                    "height": 384
                  },
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5f82c71f68537d888a00e581816163e7ad8c8aa3",
                    "width": 320,
                    "height": 568
                  },
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6a6bb779dbcfb275eb58117e2ac3a2bef19fcc4a",
                    "width": 640,
                    "height": 1137
                  },
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=ce83785106d43785aad449a390cce4b371d84f85",
                    "width": 960,
                    "height": 1706
                  },
                  {
                    "url": "https://external-preview.redd.it/enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4f262a278aa052c966e0a59712321de59431a8dd",
                    "width": 1080,
                    "height": 1920
                  }
                ],
                "variants": {},
                "id": "enV5cjFhcTg2OWhmMTM40Qrj6DkO_QD0I5n0iXR7JqD4uKRhq0mG_N5Gvutx"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miivx7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "2088AJ",
          "discussion_type": null,
          "num_comments": 22,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miivx7/gptoss_20b_running_on_an_8gb_windows_laptop_slow/",
          "stickied": false,
          "url": "https://v.redd.it/b7bkgyr869hf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422300,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 5000,
              "fallback_url": "https://v.redd.it/b7bkgyr869hf1/DASH_1080.mp4?source=fallback",
              "has_audio": true,
              "height": 1920,
              "width": 1080,
              "scrubber_media_url": "https://v.redd.it/b7bkgyr869hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/b7bkgyr869hf1/DASHPlaylist.mpd?a=1757034803%2CNjhjM2E2Yjc3NzJlY2NhMTgzMjUzNjQ1MzI5Y2M3ZjRlNDRmNzhlNmI3M2MyNzlkYzdjMGI5ZGYyYzA5MzAxNg%3D%3D&amp;v=1&amp;f=sd",
              "duration": 28,
              "hls_url": "https://v.redd.it/b7bkgyr869hf1/HLSPlaylist.m3u8?a=1757034803%2CMjkyZGI5ZDZlYmQzMjU4MTkxNmVhMGQxZWNkZGY2MzkzOTg3MGRkYjhkYWQxNzQ2OGY4MGU4OWMyYzMyZTVkZg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Many of you have seen my [benchmark](https://www.designarena.ai/) already, but see this post for [context](https://www.designarena.ai/) as always. I haven't been as active on Reddit as of late (so many things are happening so fast!), but here is the weekly update. \n\nAs of an hour ago, we just added the GPT OSS 20B and 120B models. Also recently, we also added several of the models from the Qwen3 30B series, Flux.1 Krea Dev, and Opus 4.1. See the [changelog here](https://www.designarena.ai/changelog) (though not currently up-to-date but will update today!) \n\nAs for other updates: \n\n1. **Audio Arena:** We've added an [arena for audio](https://www.designarena.ai/audio) (though still very much in baby stages) so let us know if there are good OS models to add there or modalities we can add. \n\n2. **Builder Arena:** Not sure if this is going to be of more interest to local llama, but we also released a [\"Builder\" Arena](https://www.designarena.ai/builder) for platforms like Lovable, Cognition, Cursor, etc. Feel free to suggest any kind of OS builders or agents that might be good to add here. \n\n**3. New Models:** As stated above, GPT OSS, Opus 4.1, Qwen3 30.B, and the new GLM models have been added. We've also added some [video models](https://www.designarena.ai/diffusion), specifically Wan 2.2. \n\nLet us know if you have any feedback or would like to see anything! ",
          "author_fullname": "t2_98ouo03z",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "is_gallery": true,
          "title": "UI/UX Benchmark Update 08/05: GPT-OSS Models Added, Qwen3 30B series, Flux.1 Krea Dev, Opus 4.1, Builder, Audio Arenas",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 139,
          "top_awarded_type": null,
          "hide_score": false,
          "media_metadata": {
            "lwohgjbw59hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 107,
                  "x": 108,
                  "u": "https://preview.redd.it/lwohgjbw59hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aece8803a27b1cb7dcd2f4f71f58e95d17301e4c"
                },
                {
                  "y": 215,
                  "x": 216,
                  "u": "https://preview.redd.it/lwohgjbw59hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=48d541911f4b4e2091ad9860996929177894a0f6"
                },
                {
                  "y": 319,
                  "x": 320,
                  "u": "https://preview.redd.it/lwohgjbw59hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b02c9e33c76204a372b75e2f5bb2539bf23e421"
                },
                {
                  "y": 639,
                  "x": 640,
                  "u": "https://preview.redd.it/lwohgjbw59hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=336bd3939b43a8d8128ab8d781d942c06764bba2"
                }
              ],
              "s": {
                "y": 715,
                "x": 716,
                "u": "https://preview.redd.it/lwohgjbw59hf1.png?width=716&amp;format=png&amp;auto=webp&amp;s=76512ce1e61865ccb586812ebc483fbf4ed8ed09"
              },
              "id": "lwohgjbw59hf1"
            },
            "oq3uf33569hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 56,
                  "x": 108,
                  "u": "https://preview.redd.it/oq3uf33569hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcb0d57cb6562e3e5f76cbf92d90a029fa6f4026"
                },
                {
                  "y": 113,
                  "x": 216,
                  "u": "https://preview.redd.it/oq3uf33569hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4aa46a4d9f96eb15c0d9f389a11f95758e27fa22"
                },
                {
                  "y": 168,
                  "x": 320,
                  "u": "https://preview.redd.it/oq3uf33569hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=86641d4ac22aa854c648510bf2c341d57eee777c"
                },
                {
                  "y": 337,
                  "x": 640,
                  "u": "https://preview.redd.it/oq3uf33569hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4bc92f7dbbf366e9722444d2a8e2247efcaab6f6"
                }
              ],
              "s": {
                "y": 374,
                "x": 709,
                "u": "https://preview.redd.it/oq3uf33569hf1.png?width=709&amp;format=png&amp;auto=webp&amp;s=965f27b8a87f7a772daa1ba9789950eaabd2402c"
              },
              "id": "oq3uf33569hf1"
            },
            "up3whth269hf1": {
              "status": "valid",
              "e": "Image",
              "m": "image/png",
              "p": [
                {
                  "y": 64,
                  "x": 108,
                  "u": "https://preview.redd.it/up3whth269hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a34437bd9e7136f93fdb4d4f1c605f85d4e3790"
                },
                {
                  "y": 129,
                  "x": 216,
                  "u": "https://preview.redd.it/up3whth269hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=71afcb0c2e4043080291734b8d2ee67c57867d5f"
                },
                {
                  "y": 191,
                  "x": 320,
                  "u": "https://preview.redd.it/up3whth269hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=37ebaf458b0073900aba18d0659e5a192bbe71c1"
                },
                {
                  "y": 382,
                  "x": 640,
                  "u": "https://preview.redd.it/up3whth269hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16dcf2fdc61fa95990fd07308d7c8ef509b1fa8d"
                }
              ],
              "s": {
                "y": 383,
                "x": 641,
                "u": "https://preview.redd.it/up3whth269hf1.png?width=641&amp;format=png&amp;auto=webp&amp;s=785ac04b0b923c4ce0c4b052e21f2aaaee5ddb62"
              },
              "id": "up3whth269hf1"
            }
          },
          "name": "t3_1miivw7",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.8,
          "author_flair_background_color": null,
          "ups": 6,
          "domain": "reddit.com",
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "gallery_data": {
            "items": [
              {
                "media_id": "lwohgjbw59hf1",
                "id": 721976560
              },
              {
                "media_id": "oq3uf33569hf1",
                "id": 721976561
              },
              {
                "media_id": "up3whth269hf1",
                "id": 721976562
              }
            ]
          },
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 6,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/MkmMEYJEkx6z-7hRtUax5_oiBwPKfem3egHW3cKZ18Q.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754422299,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "total_awards_received": 0,
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of you have seen my &lt;a href=\"https://www.designarena.ai/\"&gt;benchmark&lt;/a&gt; already, but see this post for &lt;a href=\"https://www.designarena.ai/\"&gt;context&lt;/a&gt; as always. I haven&amp;#39;t been as active on Reddit as of late (so many things are happening so fast!), but here is the weekly update. &lt;/p&gt;\n\n&lt;p&gt;As of an hour ago, we just added the GPT OSS 20B and 120B models. Also recently, we also added several of the models from the Qwen3 30B series, Flux.1 Krea Dev, and Opus 4.1. See the &lt;a href=\"https://www.designarena.ai/changelog\"&gt;changelog here&lt;/a&gt; (though not currently up-to-date but will update today!) &lt;/p&gt;\n\n&lt;p&gt;As for other updates: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Audio Arena:&lt;/strong&gt; We&amp;#39;ve added an &lt;a href=\"https://www.designarena.ai/audio\"&gt;arena for audio&lt;/a&gt; (though still very much in baby stages) so let us know if there are good OS models to add there or modalities we can add. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Builder Arena:&lt;/strong&gt; Not sure if this is going to be of more interest to local llama, but we also released a &lt;a href=\"https://www.designarena.ai/builder\"&gt;&amp;quot;Builder&amp;quot; Arena&lt;/a&gt; for platforms like Lovable, Cognition, Cursor, etc. Feel free to suggest any kind of OS builders or agents that might be good to add here. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;3. New Models:&lt;/strong&gt; As stated above, GPT OSS, Opus 4.1, Qwen3 30.B, and the new GLM models have been added. We&amp;#39;ve also added some &lt;a href=\"https://www.designarena.ai/diffusion\"&gt;video models&lt;/a&gt;, specifically Wan 2.2. &lt;/p&gt;\n\n&lt;p&gt;Let us know if you have any feedback or would like to see anything! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://www.reddit.com/gallery/1miivw7",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miivw7",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Accomplished-Copy332",
          "discussion_type": null,
          "num_comments": 9,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miivw7/uiux_benchmark_update_0805_gptoss_models_added/",
          "stickied": false,
          "url": "https://www.reddit.com/gallery/1miivw7",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422299,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Its my first time attempting to install and run a LLM both using ollama and in general. i seem to have downloaded successfully but when attempting to run the model i'm getting 'function \"currentDate\" not defined'. Checking the documentation for installs doesn't seem to offer any help. Any ideas?",
          "author_fullname": "t2_d2nb6pt",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Installing GPT-OSS-20b",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Question | Help"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miiuj9",
          "quarantine": false,
          "link_flair_text_color": "dark",
          "upvote_ratio": 0.56,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 1,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Question | Help",
          "can_mod_post": false,
          "score": 1,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754422214,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its my first time attempting to install and run a LLM both using ollama and in general. i seem to have downloaded successfully but when attempting to run the model i&amp;#39;m getting &amp;#39;function &amp;quot;currentDate&amp;quot; not defined&amp;#39;. Checking the documentation for installs doesn&amp;#39;t seem to offer any help. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#5a74cc",
          "id": "1miiuj9",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "ghost-uk",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miiuj9/installing_gptoss20b/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miiuj9/installing_gptoss20b/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422214,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "* 🧑‍💻GLM 4.5: An open-source reasoning model that is on par with Claude Sonnet 4.\n* 🖼️Qwen-Image: An open-source image generation model similar to ChatGPT.\n* 🆓OpenAI GPT-OSS: This model comes with open weights, Python frameworks, and agentic capabilities that will help people use it for advanced and local applications.\n* 🎖️Claude Opus 4.1: The most advanced code generation model in the world.\n* 🎐Latest Qwen 3 Series: This series includes a code generation model, reasoning models, and non-reasoning models that are on par with proprietary models.",
          "author_fullname": "t2_yeda6sl",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Its raining AI models and I am loving it.",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miirnt",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.44,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754422034,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;🧑‍💻GLM 4.5: An open-source reasoning model that is on par with Claude Sonnet 4.&lt;/li&gt;\n&lt;li&gt;🖼️Qwen-Image: An open-source image generation model similar to ChatGPT.&lt;/li&gt;\n&lt;li&gt;🆓OpenAI GPT-OSS: This model comes with open weights, Python frameworks, and agentic capabilities that will help people use it for advanced and local applications.&lt;/li&gt;\n&lt;li&gt;🎖️Claude Opus 4.1: The most advanced code generation model in the world.&lt;/li&gt;\n&lt;li&gt;🎐Latest Qwen 3 Series: This series includes a code generation model, reasoning models, and non-reasoning models that are on par with proprietary models.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miirnt",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "kingabzpro",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miirnt/its_raining_ai_models_and_i_am_loving_it/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miirnt/its_raining_ai_models_and_i_am_loving_it/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754422034,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "Even regular ChatGPT (online) is more uncensored than GPT OSS.\n\n:(",
          "author_fullname": "t2_1oyduafxrj",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "WHY CENSOR THEM SO HARD MAN??? GPT OSS??",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Other"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miiktg",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.69,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 28,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Other",
          "can_mod_post": false,
          "score": 28,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754421609,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Even regular ChatGPT (online) is more uncensored than GPT OSS.&lt;/p&gt;\n\n&lt;p&gt;:(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#94e044",
          "id": "1miiktg",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "OrganicApricot77",
          "discussion_type": null,
          "num_comments": 16,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miiktg/why_censor_them_so_hard_man_gpt_oss/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miiktg/why_censor_them_so_hard_man_gpt_oss/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421609,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4a870z4c",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Ollama 0.11 - Partners with OpenAI to bring gpt-oss models to Ollama",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "News"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 70,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miikci",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.43,
          "author_flair_background_color": null,
          "ups": 0,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "News",
          "can_mod_post": false,
          "score": 0,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=7949f3543878f3890d2e52fe649bd7fd49451b59",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "link",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754421579,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "github.com",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://github.com/ollama/ollama/releases/tag/v0.11.0",
          "view_count": null,
          "archived": false,
          "no_follow": true,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?auto=webp&amp;s=161bef5cb67ded46f2c14513a31c706d357094c0",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=87008937530dc5ae44d2daa618d7fbf0ceb9a362",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ecd7d443d323fc325f36c567e17660e1bd382189",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ffb5f3121b5d462afab1c2be3497cb5b73edb91a",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fd633d384b6753d447ab58207c5fb8fef2ce0a2",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=685b4fbdbfdfeeb85fad762d3b67f819e0a0fbcb",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d5e2da266646eca14544391299be7e32dba577ad",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "9JD_v1iTHSzuJuhaUNne7s-l4JpXqbZUtMMxgHnFr-8"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#cc3600",
          "id": "1miikci",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "mj3815",
          "discussion_type": null,
          "num_comments": 2,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miikci/ollama_011_partners_with_openai_to_bring_gptoss/",
          "stickied": false,
          "url": "https://github.com/ollama/ollama/releases/tag/v0.11.0",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421579,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_4dhrrvi6",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OSS-120B fails the 20 bouncing balls in heptagon test",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 140,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miij6j",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.57,
          "author_flair_background_color": null,
          "ups": 18,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/vd59dpcu39hf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 720,
              "scrubber_media_url": "https://v.redd.it/vd59dpcu39hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/vd59dpcu39hf1/DASHPlaylist.mpd?a=1757034803%2CMTk0Mzg3NmRlNWE3MTgxNWU3ZDc0NTg2MmNlZWRmZTBmNDEzZTExODBkZmQ5ODA4ODc2NmFlMGNlMjA3M2EyNA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 9,
              "hls_url": "https://v.redd.it/vd59dpcu39hf1/HLSPlaylist.m3u8?a=1757034803%2CYzllMzc5ZDFlZjYzOWZkNzFjZDFjYzBlNWUyYTMyZDliZGVmZGJlYmE1YzhkZTA1NjgyNzg0NzFlOTJlZDBkYg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 18,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=5f121ace5d5f3143df59f595660daba7c00c4fb5",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "hosted:video",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754421505,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "v.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://v.redd.it/vd59dpcu39hf1",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?format=pjpg&amp;auto=webp&amp;s=324f63302e181a567cddd3c313cd4514934bc515",
                  "width": 992,
                  "height": 992
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f184d50ebec1f0e86dcaf9f92117bc238c938b79",
                    "width": 108,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fd86b50d34e5e4761efca54a33e9c02864958396",
                    "width": 216,
                    "height": 216
                  },
                  {
                    "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7ae412af57f34a0a59ac278afa47c720a618646d",
                    "width": 320,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=084a1aef34f02c1c6b05bd6a31a602ee1bd6a086",
                    "width": 640,
                    "height": 640
                  },
                  {
                    "url": "https://external-preview.redd.it/Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=cf12a30c06706681d5ce5f52be5cc138bb924f7c",
                    "width": 960,
                    "height": 960
                  }
                ],
                "variants": {},
                "id": "Z2RpejZvY3UzOWhmMcZ-lfKrwTWy8sv4rAh8UXEfaOU9tc1wa_tIH6YtjRdO"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miij6j",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Different_Fix_2217",
          "discussion_type": null,
          "num_comments": 34,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miij6j/oss120b_fails_the_20_bouncing_balls_in_heptagon/",
          "stickied": false,
          "url": "https://v.redd.it/vd59dpcu39hf1",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421505,
          "num_crossposts": 0,
          "media": {
            "reddit_video": {
              "bitrate_kbps": 2400,
              "fallback_url": "https://v.redd.it/vd59dpcu39hf1/DASH_720.mp4?source=fallback",
              "has_audio": false,
              "height": 720,
              "width": 720,
              "scrubber_media_url": "https://v.redd.it/vd59dpcu39hf1/DASH_96.mp4",
              "dash_url": "https://v.redd.it/vd59dpcu39hf1/DASHPlaylist.mpd?a=1757034803%2CMTk0Mzg3NmRlNWE3MTgxNWU3ZDc0NTg2MmNlZWRmZTBmNDEzZTExODBkZmQ5ODA4ODc2NmFlMGNlMjA3M2EyNA%3D%3D&amp;v=1&amp;f=sd",
              "duration": 9,
              "hls_url": "https://v.redd.it/vd59dpcu39hf1/HLSPlaylist.m3u8?a=1757034803%2CYzllMzc5ZDFlZjYzOWZkNzFjZDFjYzBlNWUyYTMyZDliZGVmZGJlYmE1YzhkZTA1NjgyNzg0NzFlOTJlZDBkYg%3D%3D&amp;v=1&amp;f=sd",
              "is_gif": false,
              "transcoding_status": "completed"
            }
          },
          "is_video": true
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "",
          "author_fullname": "t2_uptissiz",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "OpenAI OSS models compatible PR merged into llama.cpp",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Discussion"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": 20,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miif0v",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.75,
          "author_flair_background_color": null,
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": 140,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": true,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Discussion",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "https://b.thumbs.redditmedia.com/QVvWjsPT6CCPRCKTSs9FOHdIsjwsxR-3q_cD5A_SEJg.jpg",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "image",
          "content_categories": null,
          "is_self": false,
          "subreddit_type": "public",
          "created": 1754421243,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "i.redd.it",
          "allow_live_comments": false,
          "selftext_html": null,
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "url_overridden_by_dest": "https://i.redd.it/bbz9yk4239hf1.png",
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://preview.redd.it/bbz9yk4239hf1.png?auto=webp&amp;s=466040ceddbce4e7f98be5281ad6a00295175d4e",
                  "width": 889,
                  "height": 131
                },
                "resolutions": [
                  {
                    "url": "https://preview.redd.it/bbz9yk4239hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4451b6ddc9fbcf632beda1bbff8bde5637a1c2ec",
                    "width": 108,
                    "height": 15
                  },
                  {
                    "url": "https://preview.redd.it/bbz9yk4239hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e34ffbce43ded8a1ab38fe9a12cc27d014fad50",
                    "width": 216,
                    "height": 31
                  },
                  {
                    "url": "https://preview.redd.it/bbz9yk4239hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=37f960d26de7f7eec235229eacea5b580c0b6e85",
                    "width": 320,
                    "height": 47
                  },
                  {
                    "url": "https://preview.redd.it/bbz9yk4239hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ded0f92b355ed0f10d2e9f3a25ce8009141496d",
                    "width": 640,
                    "height": 94
                  }
                ],
                "variants": {},
                "id": "vPTbk0YpmBQ_EyamwYk8pkFsa9ky4lG62PjFsGlbjd8"
              }
            ],
            "enabled": true
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "mod_note": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "num_reports": null,
          "removal_reason": null,
          "link_flair_background_color": "#646d73",
          "id": "1miif0v",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "Pro-editor-1105",
          "discussion_type": null,
          "num_comments": 4,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miif0v/openai_oss_models_compatible_pr_merged_into/",
          "stickied": false,
          "url": "https://i.redd.it/bbz9yk4239hf1.png",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421243,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "In case you are trying gpt-oss with llama.cpp ([PR#15091](https://github.com/ggml-org/llama.cpp/pull/15091)) and **NOT using the model files from** [**HF ggml-org**](https://huggingface.co/ggml-org/gpt-oss-20b-GGUF)**,** will encounter HTTP 500 error message when have the tool calling function:\n\n`got exception: {\"code\":500,\"message\":\"You have passed a message containing &lt;|channel|&gt; tags in the content field. Instead of doing this, you should pass analysis messages (the string between '&lt;|message|&gt;' and '&lt;|end|&gt;') in the 'thinking' field, and final messages (the string between '&lt;|message|&gt;' and '&lt;|end|&gt;') in the 'content' field. at row 340, column 36:\\n`\n\n  \nThe model chat template from [**ggml-org**](https://huggingface.co/ggml-org/gpt-oss-20b-GGUF) is much better, if do not want to re-download model files, just download the [ggml-org chat template](https://huggingface.co/ggml-org/gpt-oss-20b-GGUF?chat_template=default) and use following option to overwrite:  \n`--chat-template-file gpt-oss-ggml-org-chat_template.jinja`",
          "author_fullname": "t2_v7l3ekwd",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "GPT OSS chat template - tool calling issue",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Resources"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miiewp",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 1,
          "author_flair_background_color": null,
          "subreddit_type": "public",
          "ups": 8,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": null,
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Resources",
          "can_mod_post": false,
          "score": 8,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [],
          "gildings": {},
          "post_hint": "self",
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754421235,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "text",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In case you are trying gpt-oss with llama.cpp (&lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091\"&gt;PR#15091&lt;/a&gt;) and &lt;strong&gt;NOT using the model files from&lt;/strong&gt; &lt;a href=\"https://huggingface.co/ggml-org/gpt-oss-20b-GGUF\"&gt;&lt;strong&gt;HF ggml-org&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; will encounter HTTP 500 error message when have the tool calling function:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;got exception: {&amp;quot;code&amp;quot;:500,&amp;quot;message&amp;quot;:&amp;quot;You have passed a message containing &amp;lt;|channel|&amp;gt; tags in the content field. Instead of doing this, you should pass analysis messages (the string between &amp;#39;&amp;lt;|message|&amp;gt;&amp;#39; and &amp;#39;&amp;lt;|end|&amp;gt;&amp;#39;) in the &amp;#39;thinking&amp;#39; field, and final messages (the string between &amp;#39;&amp;lt;|message|&amp;gt;&amp;#39; and &amp;#39;&amp;lt;|end|&amp;gt;&amp;#39;) in the &amp;#39;content&amp;#39; field. at row 340, column 36:\\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;The model chat template from &lt;a href=\"https://huggingface.co/ggml-org/gpt-oss-20b-GGUF\"&gt;&lt;strong&gt;ggml-org&lt;/strong&gt;&lt;/a&gt; is much better, if do not want to re-download model files, just download the &lt;a href=\"https://huggingface.co/ggml-org/gpt-oss-20b-GGUF?chat_template=default\"&gt;ggml-org chat template&lt;/a&gt; and use following option to overwrite:&lt;br/&gt;\n&lt;code&gt;--chat-template-file gpt-oss-ggml-org-chat_template.jinja&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "preview": {
            "images": [
              {
                "source": {
                  "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?auto=webp&amp;s=7a3422c9d3010663aed71cb1e264c5cc3a5c523a",
                  "width": 1200,
                  "height": 600
                },
                "resolutions": [
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fc0a9456ea2aba0fff93672ee04a1dff1ae7e21",
                    "width": 108,
                    "height": 54
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c7a8024c90bd19a185cad631b6331181cd8be68d",
                    "width": 216,
                    "height": 108
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f692ce562377209ae555054812a3c52571c89b92",
                    "width": 320,
                    "height": 160
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=95a9e3e605eab496c9ba148173f1d7e68a1d7e9f",
                    "width": 640,
                    "height": 320
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a0c6f0d3a119481fd253e8878d5e92d5c7c3f9c",
                    "width": 960,
                    "height": 480
                  },
                  {
                    "url": "https://external-preview.redd.it/SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91c6ba4637f988cd1ff6db7d629220a3c493d7e0",
                    "width": 1080,
                    "height": 540
                  }
                ],
                "variants": {},
                "id": "SMmA2lbsQDUuflgGCV0_YBw5k-KcfZS-9iAMN58tb_s"
              }
            ],
            "enabled": false
          },
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": null,
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#ccac2b",
          "id": "1miiewp",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "tyoyvr-2222",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": null,
          "permalink": "/r/LocalLLaMA/comments/1miiewp/gpt_oss_chat_template_tool_calling_issue/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miiewp/gpt_oss_chat_template_tool_calling_issue/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421235,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      },
      {
        "kind": "t3",
        "data": {
          "approved_at_utc": null,
          "subreddit": "LocalLLaMA",
          "selftext": "You need the Huggingface CLI installed of course: `hf download openai/gpt-oss-20b`\n\nI don't know why, but I was getting dogshit download speeds from both vllm serve, and from the Transformers library in my Python code. This command gives me 100+ MB/s.",
          "author_fullname": "t2_1a48h7vf",
          "saved": false,
          "mod_reason_title": null,
          "gilded": 0,
          "clicked": false,
          "title": "Slow Huggingface downloads of gpt-oss? Try `hf download openai/gpt-oss-20b` or `hf download openai/gpt-oss-20b`",
          "link_flair_richtext": [
            {
              "e": "text",
              "t": "Tutorial | Guide"
            }
          ],
          "subreddit_name_prefixed": "r/LocalLLaMA",
          "hidden": false,
          "pwls": 6,
          "link_flair_css_class": "",
          "downs": 0,
          "thumbnail_height": null,
          "top_awarded_type": null,
          "hide_score": false,
          "name": "t3_1miiesj",
          "quarantine": false,
          "link_flair_text_color": "light",
          "upvote_ratio": 0.87,
          "author_flair_background_color": "transparent",
          "subreddit_type": "public",
          "ups": 11,
          "total_awards_received": 0,
          "media_embed": {},
          "thumbnail_width": null,
          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
          "is_original_content": false,
          "user_reports": [],
          "secure_media": null,
          "is_reddit_media_domain": false,
          "is_meta": false,
          "category": null,
          "secure_media_embed": {},
          "link_flair_text": "Tutorial | Guide",
          "can_mod_post": false,
          "score": 11,
          "approved_by": null,
          "is_created_from_ads_ui": false,
          "author_premium": false,
          "thumbnail": "self",
          "edited": false,
          "author_flair_css_class": null,
          "author_flair_richtext": [
            {
              "a": ":X:",
              "e": "emoji",
              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X"
            }
          ],
          "gildings": {},
          "content_categories": null,
          "is_self": true,
          "mod_note": null,
          "created": 1754421228,
          "link_flair_type": "richtext",
          "wls": 6,
          "removed_by_category": null,
          "banned_by": null,
          "author_flair_type": "richtext",
          "domain": "self.LocalLLaMA",
          "allow_live_comments": false,
          "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You need the Huggingface CLI installed of course: &lt;code&gt;hf download openai/gpt-oss-20b&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know why, but I was getting dogshit download speeds from both vllm serve, and from the Transformers library in my Python code. This command gives me 100+ MB/s.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
          "likes": null,
          "suggested_sort": null,
          "banned_at_utc": null,
          "view_count": null,
          "archived": false,
          "no_follow": false,
          "is_crosspostable": false,
          "pinned": false,
          "over_18": false,
          "all_awardings": [],
          "awarders": [],
          "media_only": false,
          "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
          "can_gild": false,
          "spoiler": false,
          "locked": false,
          "author_flair_text": ":X:",
          "treatment_tags": [],
          "visited": false,
          "removed_by": null,
          "num_reports": null,
          "distinguished": null,
          "subreddit_id": "t5_81eyvm",
          "author_is_blocked": false,
          "mod_reason_by": null,
          "removal_reason": null,
          "link_flair_background_color": "#0079d3",
          "id": "1miiesj",
          "is_robot_indexable": true,
          "report_reasons": null,
          "author": "entsnack",
          "discussion_type": null,
          "num_comments": 0,
          "send_replies": true,
          "contest_mode": false,
          "mod_reports": [],
          "author_patreon_flair": false,
          "author_flair_text_color": "dark",
          "permalink": "/r/LocalLLaMA/comments/1miiesj/slow_huggingface_downloads_of_gptoss_try_hf/",
          "stickied": false,
          "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miiesj/slow_huggingface_downloads_of_gptoss_try_hf/",
          "subreddit_subscribers": 511363,
          "created_utc": 1754421228,
          "num_crossposts": 0,
          "media": null,
          "is_video": false
        }
      }
    ],
    "before": null
  }
}