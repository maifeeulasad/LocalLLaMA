[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I have a scanned form containing a large table with surrounding text. My goal is to extract specific information from certain cells in this table.  \n\nCurrent Approach &amp; Challenges  \n1. OCR Tools (e.g., Tesseract):  \n   - Used to identify the table and extract text.  \n   - Issue: OCR accuracy is inconsistent—sometimes the table isn’t recognized or is parsed incorrectly.  \n\n2. Post-OCR Correction (e.g., Mistral):  \n   - A language model refines the extracted text.  \n   - Issue: Poor results due to upstream OCR errors.  \n\nDespite spending hours on this workflow, I haven’t achieved reliable extraction.  \n\nAlternative Solution (Online Tools Work, but Local Execution is Required)  \n- Observation: Uploading the form to ChatGPT or DeepSeek (online) yields excellent results.  \n- Constraint: The solution must run entirely locally (no internet connection).  \n\nAttempted new Workflow (DINOv2 + Multimodal LLM)  \n1. Step 1: Image Embedding with DINOv2  \n   - Tried converting the image into a vector representation using DINOv2 (Vision Transformer).  \n   - Issue: Did not produce usable results—possibly due to incorrect implementation or model limitations. Is this approach even correct?\n\n2. Step 2: Multimodal LLM Processing  \n   - Planned to feed the vector to a local multimodal LLM (e.g., Mistral) for structured output.  \n   - Blocker: Step 2 failed, didn’t got usable output \n\nQuestion  \nIs there a local, offline-compatible method to replicate the quality of online extraction tools? For example:  \n- Are there better vision models than DINOv2 for this task?  \n- Could a different pipeline (e.g., layout detection + OCR + LLM correction) work?  \n- Any tips for debugging DINOv2 missteps?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Help Needed: Accurate Offline Table Extraction from Scanned Forms",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m8n557",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_ahnt19ga",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753409440,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a scanned form containing a large table with surrounding text. My goal is to extract specific information from certain cells in this table.  &lt;/p&gt;\n\n&lt;p&gt;Current Approach &amp;amp; Challenges&lt;br/&gt;\n1. OCR Tools (e.g., Tesseract):&lt;br/&gt;\n   - Used to identify the table and extract text.&lt;br/&gt;\n   - Issue: OCR accuracy is inconsistent—sometimes the table isn’t recognized or is parsed incorrectly.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Post-OCR Correction (e.g., Mistral):&lt;br/&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A language model refines the extracted text.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Issue: Poor results due to upstream OCR errors.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Despite spending hours on this workflow, I haven’t achieved reliable extraction.  &lt;/p&gt;\n\n&lt;p&gt;Alternative Solution (Online Tools Work, but Local Execution is Required)&lt;br/&gt;\n- Observation: Uploading the form to ChatGPT or DeepSeek (online) yields excellent results.&lt;br/&gt;\n- Constraint: The solution must run entirely locally (no internet connection).  &lt;/p&gt;\n\n&lt;p&gt;Attempted new Workflow (DINOv2 + Multimodal LLM)&lt;br/&gt;\n1. Step 1: Image Embedding with DINOv2&lt;br/&gt;\n   - Tried converting the image into a vector representation using DINOv2 (Vision Transformer).&lt;br/&gt;\n   - Issue: Did not produce usable results—possibly due to incorrect implementation or model limitations. Is this approach even correct?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Step 2: Multimodal LLM Processing&lt;br/&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Planned to feed the vector to a local multimodal LLM (e.g., Mistral) for structured output.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Blocker: Step 2 failed, didn’t got usable output &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Question&lt;br/&gt;\nIs there a local, offline-compatible method to replicate the quality of online extraction tools? For example:&lt;br/&gt;\n- Are there better vision models than DINOv2 for this task?&lt;br/&gt;\n- Could a different pipeline (e.g., layout detection + OCR + LLM correction) work?&lt;br/&gt;\n- Any tips for debugging DINOv2 missteps?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m8n557",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Antelito83",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/",
            "subreddit_subscribers": 504254,
            "created_utc": 1753409440,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n50rjxq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Azuriteh",
                      "can_mod_post": false,
                      "created_utc": 1753412484,
                      "send_replies": true,
                      "parent_id": "t1_n50pt3z",
                      "score": 3,
                      "author_fullname": "t2_wmv41",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is the answer, you're overengineering for a task that's now way easier thanks to big labs focusing on multimodality.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n50rjxq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the answer, you&amp;#39;re overengineering for a task that&amp;#39;s now way easier thanks to big labs focusing on multimodality.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8n557",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/n50rjxq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753412484,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n51dxbi",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "themungbeans",
                      "can_mod_post": false,
                      "created_utc": 1753422367,
                      "send_replies": true,
                      "parent_id": "t1_n50pt3z",
                      "score": 1,
                      "author_fullname": "t2_3vo0xl71",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah I think try a vision model. the three listed abive gave me mixed results.  I think mistral was slow but accurate.  Quant seemed to matter quite a bit in my very limited experience. qwen2.5vl 7B Q4KM had a reasonable amount lower accuracy and ability to answer questions than what qwen2.5vl 7B Q8\\_0.  The larger models 24-32B did quite well,1080p screenshots took 8mins to process as it primarily used CPU resources to complete the task.  mistral-small3.2:24b-instruct-2506-q4\\_K\\_M I landed on for my more complex vision and task around the interpreted image. qwen2.5vl:7b-q8\\_0 for fast but not so critical.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n51dxbi",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah I think try a vision model. the three listed abive gave me mixed results.  I think mistral was slow but accurate.  Quant seemed to matter quite a bit in my very limited experience. qwen2.5vl 7B Q4KM had a reasonable amount lower accuracy and ability to answer questions than what qwen2.5vl 7B Q8_0.  The larger models 24-32B did quite well,1080p screenshots took 8mins to process as it primarily used CPU resources to complete the task.  mistral-small3.2:24b-instruct-2506-q4_K_M I landed on for my more complex vision and task around the interpreted image. qwen2.5vl:7b-q8_0 for fast but not so critical.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8n557",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/n51dxbi/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753422367,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n50pt3z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "HistorianPotential48",
            "can_mod_post": false,
            "created_utc": 1753411808,
            "send_replies": true,
            "parent_id": "t3_1m8n557",
            "score": 3,
            "author_fullname": "t2_4dzthia7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "why not feed LLM the image directly? qwen2.5vl, mistral-small, gemma3, all supports image input",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n50pt3z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;why not feed LLM the image directly? qwen2.5vl, mistral-small, gemma3, all supports image input&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/n50pt3z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753411808,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8n557",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n50q0xo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "eloquentemu",
            "can_mod_post": false,
            "created_utc": 1753411892,
            "send_replies": true,
            "parent_id": "t3_1m8n557",
            "score": 2,
            "author_fullname": "t2_lpdsy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have you tried just using gemma3-27b directly?  I don't need OCR often, but it's been my go-to for one-offs and seems fairly solid, though seems to hallucinate on large text documents.  Tables, notes and otherwise floating text it seems quite good at.  Basically give it a \"Extract the tables in the image as markdown\" or such prompt and the image and it goes to work.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n50q0xo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried just using gemma3-27b directly?  I don&amp;#39;t need OCR often, but it&amp;#39;s been my go-to for one-offs and seems fairly solid, though seems to hallucinate on large text documents.  Tables, notes and otherwise floating text it seems quite good at.  Basically give it a &amp;quot;Extract the tables in the image as markdown&amp;quot; or such prompt and the image and it goes to work.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/n50q0xo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753411892,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8n557",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n513diw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "CantaloupeDismal1195",
            "can_mod_post": false,
            "created_utc": 1753417388,
            "send_replies": true,
            "parent_id": "t3_1m8n557",
            "score": 1,
            "author_fullname": "t2_1ld1b995hk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "qwen2.5vl-72B works really well",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n513diw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;qwen2.5vl-72B works really well&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8n557/help_needed_accurate_offline_table_extraction/n513diw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753417388,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8n557",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]