[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Found this paper recently and thought the idea was worth sharing.\n\nIt is a language model trained specifically for debugging rather than general-purpose code generation. It’s built to understand large codebases over time, using something called Adaptive Graph-Guided Retrieval to pull in relevant files, logs, and commit history when tracing bugs.\n\nThe model is trained on millions of real debugging examples like stack traces, test failures, and CI logs. Instead of just predicting code, it runs through a full debugging loop: retrieve context, propose fix, test, refine, and update memory.\n\nA few standout points:\n\n* Claims 65% success on real-world debugging tasks, compared to \\~10% for GPT-4 or Claude\n* Retrieval seems to prioritize structural relationships between code, not just token similarity\n* Focus is on producing fixes, tests, and docs, not just autocomplete\n\nHonestly surprised we haven’t seen more models focus purely on debugging like this. Most tools still treat it like another code generation task. Would be interested to hear thoughts on how this compares to retrieval-augmented agents or if anyone’s explored similar approaches.\n\nPaper: [https://arxiv.org/abs/2507.12482](https://arxiv.org/abs/2507.12482)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "An LLM Focused Just on Debugging",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mazi8m",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.72,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_dcd7znsr",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753655276,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found this paper recently and thought the idea was worth sharing.&lt;/p&gt;\n\n&lt;p&gt;It is a language model trained specifically for debugging rather than general-purpose code generation. It’s built to understand large codebases over time, using something called Adaptive Graph-Guided Retrieval to pull in relevant files, logs, and commit history when tracing bugs.&lt;/p&gt;\n\n&lt;p&gt;The model is trained on millions of real debugging examples like stack traces, test failures, and CI logs. Instead of just predicting code, it runs through a full debugging loop: retrieve context, propose fix, test, refine, and update memory.&lt;/p&gt;\n\n&lt;p&gt;A few standout points:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Claims 65% success on real-world debugging tasks, compared to ~10% for GPT-4 or Claude&lt;/li&gt;\n&lt;li&gt;Retrieval seems to prioritize structural relationships between code, not just token similarity&lt;/li&gt;\n&lt;li&gt;Focus is on producing fixes, tests, and docs, not just autocomplete&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Honestly surprised we haven’t seen more models focus purely on debugging like this. Most tools still treat it like another code generation task. Would be interested to hear thoughts on how this compares to retrieval-augmented agents or if anyone’s explored similar approaches.&lt;/p&gt;\n\n&lt;p&gt;Paper: &lt;a href=\"https://arxiv.org/abs/2507.12482\"&gt;https://arxiv.org/abs/2507.12482&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mazi8m",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Sharp-Arachnid-8760",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mazi8m/an_llm_focused_just_on_debugging/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mazi8m/an_llm_focused_just_on_debugging/",
            "subreddit_subscribers": 505617,
            "created_utc": 1753655276,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5igycl",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ObnoxiouslyVivid",
            "can_mod_post": false,
            "created_utc": 1753656041,
            "send_replies": true,
            "parent_id": "t3_1mazi8m",
            "score": 2,
            "author_fullname": "t2_n80ogax",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They compare it to GPT-4 and Claude-3+VectorDB? What is this, 2024?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5igycl",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They compare it to GPT-4 and Claude-3+VectorDB? What is this, 2024?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mazi8m/an_llm_focused_just_on_debugging/n5igycl/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753656041,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mazi8m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]