[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hello, \n\nI have as described a LLM programmed in Llama-cpp-python with CUDA GPU support in Windows 10. I have 4 GPUs on an 'old' (2022) mining motherboard. I also host an Apache2 server for web and Java-based James email server. The system is not very stable and honestly it's made for that kind of use. I am looking to move everything to Linux, but I am puzzled on which PC to buy for that to support the 4 GPUs (and potentially more), and the distro, also concerned on the time I'll need to invest in this. \n\nAny recommandations on hardware, software, and which Linux distro considering I have past experience with UNIX and need something that won't be too much of a hassle? For example I wish there was a distro with pre-installed Apache and Mail servers. \n\nBest,   \nC",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Self hosted LLM with GPU support, Apache server, Email server on a Windows 10 PC - need to upgrade PC and OS",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ltdh0n",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.66,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_erkzsfpv",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751839569,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have as described a LLM programmed in Llama-cpp-python with CUDA GPU support in Windows 10. I have 4 GPUs on an &amp;#39;old&amp;#39; (2022) mining motherboard. I also host an Apache2 server for web and Java-based James email server. The system is not very stable and honestly it&amp;#39;s made for that kind of use. I am looking to move everything to Linux, but I am puzzled on which PC to buy for that to support the 4 GPUs (and potentially more), and the distro, also concerned on the time I&amp;#39;ll need to invest in this. &lt;/p&gt;\n\n&lt;p&gt;Any recommandations on hardware, software, and which Linux distro considering I have past experience with UNIX and need something that won&amp;#39;t be too much of a hassle? For example I wish there was a distro with pre-installed Apache and Mail servers. &lt;/p&gt;\n\n&lt;p&gt;Best,&lt;br/&gt;\nC&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ltdh0n",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "calypset",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ltdh0n/self_hosted_llm_with_gpu_support_apache_server/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ltdh0n/self_hosted_llm_with_gpu_support_apache_server/",
            "subreddit_subscribers": 495395,
            "created_utc": 1751839569,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1rievi",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Conscious_Cut_6144",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1rcgqo",
                                "score": 1,
                                "author_fullname": "t2_9hl4ymvj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ya you could just get a disk,  \nThat way you can experiment with Linux and quickly switch back to windows if needed.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1rievi",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ya you could just get a disk,&lt;br/&gt;\nThat way you can experiment with Linux and quickly switch back to windows if needed.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1ltdh0n",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1ltdh0n/self_hosted_llm_with_gpu_support_apache_server/n1rievi/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751868447,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751868447,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1rcgqo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "calypset",
                      "can_mod_post": false,
                      "created_utc": 1751865299,
                      "send_replies": true,
                      "parent_id": "t1_n1r7hwn",
                      "score": 1,
                      "author_fullname": "t2_erkzsfpv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah that makes sense. I guess I didn't want to have downtime and concerned on the boot sequence with a partitioned drive. But I could setup Linux on an external drive and setup the web and mail server while hooked up on another computer. But the CUDA setup and LLM AI will take some work to port once the servers are up. The GPUs are NVIDIA,,, 3 dedicated mining, I can't quite recall which, I think they are RTX 3080s, and one RTX 3090 proper.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1rcgqo",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah that makes sense. I guess I didn&amp;#39;t want to have downtime and concerned on the boot sequence with a partitioned drive. But I could setup Linux on an external drive and setup the web and mail server while hooked up on another computer. But the CUDA setup and LLM AI will take some work to port once the servers are up. The GPUs are NVIDIA,,, 3 dedicated mining, I can&amp;#39;t quite recall which, I think they are RTX 3080s, and one RTX 3090 proper.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ltdh0n",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ltdh0n/self_hosted_llm_with_gpu_support_apache_server/n1rcgqo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751865299,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1r7hwn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Conscious_Cut_6144",
            "can_mod_post": false,
            "created_utc": 1751862869,
            "send_replies": true,
            "parent_id": "t3_1ltdh0n",
            "score": 1,
            "author_fullname": "t2_9hl4ymvj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'd install linux on the existing mining motherboard.  \nYou might find the stability issues were just windows.\n\nAny linux you want should be fine but lots use Ubuntu.\n\nWhat GPU's?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1r7hwn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d install linux on the existing mining motherboard.&lt;br/&gt;\nYou might find the stability issues were just windows.&lt;/p&gt;\n\n&lt;p&gt;Any linux you want should be fine but lots use Ubuntu.&lt;/p&gt;\n\n&lt;p&gt;What GPU&amp;#39;s?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ltdh0n/self_hosted_llm_with_gpu_support_apache_server/n1r7hwn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751862869,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ltdh0n",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]