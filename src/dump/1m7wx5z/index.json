[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Right now, open source models aren’t that far off in terms of capabilities compared to proprietary models and models like DeepSeek, Kimi, and Qwen are beating out Claude, Gemini, GPT, etc. in many domains and categories when you look at various benchmarks.\n\nThat said, do you think open source models will continue to remain competitive across their proprietary counterparts? If not, what do you think the turning point will be when proprietary models just completely dominate open source?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Do you think open source models continue to keep pace with proprietary models or will the gap widen?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m7wx5z",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.6,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1gpe2ygava",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753338395,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now, open source models aren’t that far off in terms of capabilities compared to proprietary models and models like DeepSeek, Kimi, and Qwen are beating out Claude, Gemini, GPT, etc. in many domains and categories when you look at various benchmarks.&lt;/p&gt;\n\n&lt;p&gt;That said, do you think open source models will continue to remain competitive across their proprietary counterparts? If not, what do you think the turning point will be when proprietary models just completely dominate open source?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m7wx5z",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Smart-Confection1435",
            "discussion_type": null,
            "num_comments": 33,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/",
            "subreddit_subscribers": 504024,
            "created_utc": 1753338395,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v0afi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "NNN_Throwaway2",
            "can_mod_post": false,
            "created_utc": 1753342637,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 11,
            "author_fullname": "t2_8rrihts9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It'll only widen if closed source makes a breakthrough in tech. Right now everyone is milking the same cow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v0afi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;ll only widen if closed source makes a breakthrough in tech. Right now everyone is milking the same cow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v0afi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753342637,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v6l9n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "zoupishness7",
            "can_mod_post": false,
            "created_utc": 1753346240,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 6,
            "author_fullname": "t2_disot",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the gap will remain relatively stable, for several years, but maybe not many. It was said at DeepMind, a couple years ago, \"We have no moat, and neither does OpenAI\".  This holds in lot of ways, but not in all. SOTA models are being offered as a service, but that access allows open and closed source interests to distill them. The distillations may not be more powerful, but the successful ones, the ones that tend to be widely adopted, are more efficient, in terms of hardware and energy cost.\n\nAt the same time, there isn't yet a distributed method of training a model, from scratch, that is more cost effective than cramming a bunch of brand new expensive hardware, into a relatively compact location, with top of the line energy and cooling infrastructure.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v6l9n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the gap will remain relatively stable, for several years, but maybe not many. It was said at DeepMind, a couple years ago, &amp;quot;We have no moat, and neither does OpenAI&amp;quot;.  This holds in lot of ways, but not in all. SOTA models are being offered as a service, but that access allows open and closed source interests to distill them. The distillations may not be more powerful, but the successful ones, the ones that tend to be widely adopted, are more efficient, in terms of hardware and energy cost.&lt;/p&gt;\n\n&lt;p&gt;At the same time, there isn&amp;#39;t yet a distributed method of training a model, from scratch, that is more cost effective than cramming a bunch of brand new expensive hardware, into a relatively compact location, with top of the line energy and cooling infrastructure.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v6l9n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753346240,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v9tqu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "dark-light92",
            "can_mod_post": false,
            "created_utc": 1753348080,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 6,
            "author_fullname": "t2_3lvoq8zw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "There are very few open source models. What we have is open weight. Similar to freeware. \n\nEven if a lab publishes all their data and training recipes, training a SOTA model requires ungodly amount of compute.  \n\nSo, the question you should be asking is till when companies like deepseek, qwen and mistral will continue to release the weights of the models under open licenses because the moment they stop, the gap will widen. There is no truly open source player in SOTA race.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v9tqu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are very few open source models. What we have is open weight. Similar to freeware. &lt;/p&gt;\n\n&lt;p&gt;Even if a lab publishes all their data and training recipes, training a SOTA model requires ungodly amount of compute.  &lt;/p&gt;\n\n&lt;p&gt;So, the question you should be asking is till when companies like deepseek, qwen and mistral will continue to release the weights of the models under open licenses because the moment they stop, the gap will widen. There is no truly open source player in SOTA race.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v9tqu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753348080,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4vh6h8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Due-Competition4564",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4vdo9g",
                                "score": 5,
                                "author_fullname": "t2_p168o2pu",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Man it is getting so easy to detect AI slop these days.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4vh6h8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Man it is getting so easy to detect AI slop these days.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vh6h8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753352121,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753352121,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4vmnk1",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Stetto",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4vdo9g",
                                "score": 3,
                                "author_fullname": "t2_cqodq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "And what prevents proprietary models to learn from open-source models as well and include those learnings into their architecture?\n\nSure, everyone loves transparency. But there is not much benefit to being transparent yourself besides idealism.\n\nLLMs aren't linux. LLMs don't need cooperation from more developers.\n\nMaybe try to formulate your own thoughts instead of just making an LLM think for you?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4vmnk1",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And what prevents proprietary models to learn from open-source models as well and include those learnings into their architecture?&lt;/p&gt;\n\n&lt;p&gt;Sure, everyone loves transparency. But there is not much benefit to being transparent yourself besides idealism.&lt;/p&gt;\n\n&lt;p&gt;LLMs aren&amp;#39;t linux. LLMs don&amp;#39;t need cooperation from more developers.&lt;/p&gt;\n\n&lt;p&gt;Maybe try to formulate your own thoughts instead of just making an LLM think for you?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vmnk1/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753354788,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753354788,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4vdo9g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "skyblue_Mr",
                      "can_mod_post": false,
                      "created_utc": 1753350263,
                      "send_replies": true,
                      "parent_id": "t1_n4uzrmc",
                      "score": -6,
                      "author_fullname": "t2_8ohz4gw6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yo, let's cut through the BS: Yeah, data quality matters for training, but if your model's core architecture is trash? You're burning cash on insane compute costs while getting garbage outputs.  \n\nHere’s the kicker—closed-source models keep their architectures locked down like Fort Knox (seriously, WTF is under the hood?). Meanwhile, DeepSeek and Qwen are out here open-sourcing their whole playbook: model designs, training tricks, the works.  \n\nThat transparency is game-changing. Projects like Kimi K2 are already baking their innovations into new models. That's how you accelerate the open-source ecosystem. Data's fuel, but architecture's the damn engine.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4vdo9g",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yo, let&amp;#39;s cut through the BS: Yeah, data quality matters for training, but if your model&amp;#39;s core architecture is trash? You&amp;#39;re burning cash on insane compute costs while getting garbage outputs.  &lt;/p&gt;\n\n&lt;p&gt;Here’s the kicker—closed-source models keep their architectures locked down like Fort Knox (seriously, WTF is under the hood?). Meanwhile, DeepSeek and Qwen are out here open-sourcing their whole playbook: model designs, training tricks, the works.  &lt;/p&gt;\n\n&lt;p&gt;That transparency is game-changing. Projects like Kimi K2 are already baking their innovations into new models. That&amp;#39;s how you accelerate the open-source ecosystem. Data&amp;#39;s fuel, but architecture&amp;#39;s the damn engine.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vdo9g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753350263,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uzrmc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Stetto",
            "can_mod_post": false,
            "created_utc": 1753342337,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 7,
            "author_fullname": "t2_cqodq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think it's a reasonable assumption, that Qwen and Deepseek are using output from proprietary models for training. \n\nThis fallback will always be possible and allow open-source models to keep pace.\n\nBut open-source doesn't have any innate advantage over proprietary models. In the contrary, for training infrastructure, you just need a huge boatload of money that you can burn for long time.\n\nAny company like Alibaba or Deepseek can decide at any moment, that this cost should be better hidden behind a paywall.\n\nSo, I'd say, we won't know. I see good reasons for both.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uzrmc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s a reasonable assumption, that Qwen and Deepseek are using output from proprietary models for training. &lt;/p&gt;\n\n&lt;p&gt;This fallback will always be possible and allow open-source models to keep pace.&lt;/p&gt;\n\n&lt;p&gt;But open-source doesn&amp;#39;t have any innate advantage over proprietary models. In the contrary, for training infrastructure, you just need a huge boatload of money that you can burn for long time.&lt;/p&gt;\n\n&lt;p&gt;Any company like Alibaba or Deepseek can decide at any moment, that this cost should be better hidden behind a paywall.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;d say, we won&amp;#39;t know. I see good reasons for both.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uzrmc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753342337,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4yij0f",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "custodiam99",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4ygbzi",
                                                    "score": 1,
                                                    "author_fullname": "t2_nqnhgqqf5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Probably it is a completely new technology and architecture (for us at least, but I suspect the big players know much more).",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4yij0f",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Probably it is a completely new technology and architecture (for us at least, but I suspect the big players know much more).&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m7wx5z",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4yij0f/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753386105,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753386105,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4ygbzi",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "No_Efficiency_1144",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4uyhfw",
                                          "score": 1,
                                          "author_fullname": "t2_1nkj9l14b0",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Common sense priors are very ambitious yes. I was thinking along the lines of a small 0.6B causal encoder or something because we don’t even have that yet for the most part.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4ygbzi",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Common sense priors are very ambitious yes. I was thinking along the lines of a small 0.6B causal encoder or something because we don’t even have that yet for the most part.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m7wx5z",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4ygbzi/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753385481,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753385481,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4uyhfw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "custodiam99",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4uxn0x",
                                "score": 1,
                                "author_fullname": "t2_nqnhgqqf5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It depends on how they will solve the \"common sense\" problem. Even Yann LeCun said it is a surprisingly hard problem.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4uyhfw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It depends on how they will solve the &amp;quot;common sense&amp;quot; problem. Even Yann LeCun said it is a surprisingly hard problem.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uyhfw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753341607,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753341607,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4uxn0x",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "No_Efficiency_1144",
                      "can_mod_post": false,
                      "created_utc": 1753341142,
                      "send_replies": true,
                      "parent_id": "t1_n4uty60",
                      "score": 3,
                      "author_fullname": "t2_1nkj9l14b0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Causal encoding is way more efficient so we might be lucky",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4uxn0x",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Causal encoding is way more efficient so we might be lucky&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uxn0x/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753341142,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uty60",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "custodiam99",
            "can_mod_post": false,
            "created_utc": 1753339147,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_nqnhgqqf5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It will widen only if spatial-temporal and causal world models won't run on local PCs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uty60",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It will widen only if spatial-temporal and causal world models won&amp;#39;t run on local PCs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uty60/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339147,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4uvcqj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Psionikus",
            "can_mod_post": false,
            "created_utc": 1753339904,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_8vhsch4i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The equilibrium depends on a lot of factors.  A very telling question is if there are advantages to having open IP.  This usually occurs around standards and integration points.\n\nDownstream programs will want to integrate with MCP and A2A etc.  Local models are the only thing that can be trusted to gate interactions with remote models long term.  That's a lot of financial interest that does not care what happens to OpenAI and the rest.\n\nIn general, diversity breaks down walled gardens because it increases the value delivered by integration.  As long as there are a lot of players, you can expect that the demand to integrate downstream will pump a lot of economy into thicker open IP foundations with thinner closed IP products built on top and plugging into the foundatin.\n\nIMO we're just waiting on architecture compression to leave us in a situation with massively overbuilt compute and most of the models any human can ever want will be local.  Supercomputers will run more traditional simulations while taking input from models to walk strange gradients that can't be done with explicitly programmed numerical methods.  Basically CFD + AI and molecular modeling + AI etc will eat up the spare compute capacity.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uvcqj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The equilibrium depends on a lot of factors.  A very telling question is if there are advantages to having open IP.  This usually occurs around standards and integration points.&lt;/p&gt;\n\n&lt;p&gt;Downstream programs will want to integrate with MCP and A2A etc.  Local models are the only thing that can be trusted to gate interactions with remote models long term.  That&amp;#39;s a lot of financial interest that does not care what happens to OpenAI and the rest.&lt;/p&gt;\n\n&lt;p&gt;In general, diversity breaks down walled gardens because it increases the value delivered by integration.  As long as there are a lot of players, you can expect that the demand to integrate downstream will pump a lot of economy into thicker open IP foundations with thinner closed IP products built on top and plugging into the foundatin.&lt;/p&gt;\n\n&lt;p&gt;IMO we&amp;#39;re just waiting on architecture compression to leave us in a situation with massively overbuilt compute and most of the models any human can ever want will be local.  Supercomputers will run more traditional simulations while taking input from models to walk strange gradients that can&amp;#39;t be done with explicitly programmed numerical methods.  Basically CFD + AI and molecular modeling + AI etc will eat up the spare compute capacity.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uvcqj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339904,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v30gy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ethertype",
            "can_mod_post": false,
            "created_utc": 1753344172,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 3,
            "author_fullname": "t2_3nfev4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Proprietary models will end up having to throw in more hardware to stay ahead of *other* proprietary models, making them unsuitable for local use. And such is the modern business anyway, sell whatever as a service for that sweet, sweet recurring revenue. A lot of VC money is burned every day to come into position, and it is way too early to predict winners. \n\nSo maybe the question should be: can open and *local* models and affordable hardware remain *or* become *good enough* to matter vs whatever remains standing among proprietary models when VC-money finally dries out?\n\nI am convinced the answer to that is 'yes'. \n\nThis is just another iteration of the process described in Clayton M. Christensen's \"The Innovator's Dilemma\". \n\n\n*However:*\nThere are certain aspects of \"access to technology\" which can shape the development a bit. As of 2025, there are:\n- memory manufacturers (Samsung, Hynix and Micron). \n- compute hardware (IP, tech, competence), which is a slightly more crowded field: (Nvidia, Intel, AMD, ARM and quite a few more.)\n- semiconductor *manufacturing* side, which in the top end is rather limited (TSMC, SMIC, Global Foundries, Samsung)\n- semiconductor manufacturing *machinery* (of which ASML is of major importance)\n\nYou need the whole stack, and the number of players at each rung of the ladder is so limited that it approaches a vulnerability.\n\nReplacing or even competing with any one of these companies is approaching a nation state level effort, requiring wast amounts of talent, cash, energy and water. And time. Lots of time.\n\nUnless, of course, someone comes up with a really bright idea *again*. Innovation never stops. :-)",
            "edited": 1753344931,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v30gy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Proprietary models will end up having to throw in more hardware to stay ahead of &lt;em&gt;other&lt;/em&gt; proprietary models, making them unsuitable for local use. And such is the modern business anyway, sell whatever as a service for that sweet, sweet recurring revenue. A lot of VC money is burned every day to come into position, and it is way too early to predict winners. &lt;/p&gt;\n\n&lt;p&gt;So maybe the question should be: can open and &lt;em&gt;local&lt;/em&gt; models and affordable hardware remain &lt;em&gt;or&lt;/em&gt; become &lt;em&gt;good enough&lt;/em&gt; to matter vs whatever remains standing among proprietary models when VC-money finally dries out?&lt;/p&gt;\n\n&lt;p&gt;I am convinced the answer to that is &amp;#39;yes&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;This is just another iteration of the process described in Clayton M. Christensen&amp;#39;s &amp;quot;The Innovator&amp;#39;s Dilemma&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;However:&lt;/em&gt;\nThere are certain aspects of &amp;quot;access to technology&amp;quot; which can shape the development a bit. As of 2025, there are:\n- memory manufacturers (Samsung, Hynix and Micron). \n- compute hardware (IP, tech, competence), which is a slightly more crowded field: (Nvidia, Intel, AMD, ARM and quite a few more.)\n- semiconductor &lt;em&gt;manufacturing&lt;/em&gt; side, which in the top end is rather limited (TSMC, SMIC, Global Foundries, Samsung)\n- semiconductor manufacturing &lt;em&gt;machinery&lt;/em&gt; (of which ASML is of major importance)&lt;/p&gt;\n\n&lt;p&gt;You need the whole stack, and the number of players at each rung of the ladder is so limited that it approaches a vulnerability.&lt;/p&gt;\n\n&lt;p&gt;Replacing or even competing with any one of these companies is approaching a nation state level effort, requiring wast amounts of talent, cash, energy and water. And time. Lots of time.&lt;/p&gt;\n\n&lt;p&gt;Unless, of course, someone comes up with a really bright idea &lt;em&gt;again&lt;/em&gt;. Innovation never stops. :-)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v30gy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753344172,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yb7m3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Smart-Confection1435",
                      "can_mod_post": false,
                      "created_utc": 1753384026,
                      "send_replies": true,
                      "parent_id": "t1_n4wzbdf",
                      "score": 1,
                      "author_fullname": "t2_1gpe2ygava",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Mistral’s best models aren’t open source anymore.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yb7m3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mistral’s best models aren’t open source anymore.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4yb7m3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753384026,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4wzbdf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Conversation9561",
            "can_mod_post": false,
            "created_utc": 1753370860,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_jqxb4pte",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think we’re in the golden times of open source competitiveness in AI.\nAll these companies (Deepseek, Baidu, Alibaba, Mistral etc.) must have an end goal for spending huge amounts of time and money on “free” models.\nEvery goal in the corporate world has a timeline to be met.",
            "edited": 1753371198,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4wzbdf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think we’re in the golden times of open source competitiveness in AI.\nAll these companies (Deepseek, Baidu, Alibaba, Mistral etc.) must have an end goal for spending huge amounts of time and money on “free” models.\nEvery goal in the corporate world has a timeline to be met.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4wzbdf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753370860,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4zfn40",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Stetto",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4yyudb",
                                                              "score": 1,
                                                              "author_fullname": "t2_cqodq",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Again, LLMs don't need more developers. That's not the bottleneck. And LLMs like Deepseek, Qwen, Gemma or LLama aren't even real open-source. Deepseek &amp; Co. are all just \"open-weights\".\n\nBy making an LLM open-weight companies don't gain \"more developers working on it for free\". They just make their LLM publicly accessible for free.\n\nThat's nice, but doesn't help the company beyond publicity and growing the user base.",
                                                              "edited": 1753396255,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4zfn40",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Again, LLMs don&amp;#39;t need more developers. That&amp;#39;s not the bottleneck. And LLMs like Deepseek, Qwen, Gemma or LLama aren&amp;#39;t even real open-source. Deepseek &amp;amp; Co. are all just &amp;quot;open-weights&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;By making an LLM open-weight companies don&amp;#39;t gain &amp;quot;more developers working on it for free&amp;quot;. They just make their LLM publicly accessible for free.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s nice, but doesn&amp;#39;t help the company beyond publicity and growing the user base.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m7wx5z",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4zfn40/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753395718,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753395718,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4yyudb",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "GPTshop_ai",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4yet0d",
                                                    "score": 1,
                                                    "author_fullname": "t2_rkmud0isr",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "why did google open source chrom(e)ium and android? a lot of people working on it for free! ultimately it is a platform war.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4yyudb",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;why did google open source chrom(e)ium and android? a lot of people working on it for free! ultimately it is a platform war.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m7wx5z",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4yyudb/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753390654,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753390654,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4yet0d",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Stetto",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xremb",
                                          "score": 1,
                                          "author_fullname": "t2_cqodq",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I agree! Open-weights models and all of the possible fine-tuning and distilling and merging and so on is great! I love it.\n\nWell, my take is very simple:\n\nWhat is the benefit for Deepseek and what will motivate them to keep the weights open?\n\nI'm not aware of any besides \"good publicity\" and \"easy way to grow user base to cash in later\".",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4yet0d",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree! Open-weights models and all of the possible fine-tuning and distilling and merging and so on is great! I love it.&lt;/p&gt;\n\n&lt;p&gt;Well, my take is very simple:&lt;/p&gt;\n\n&lt;p&gt;What is the benefit for Deepseek and what will motivate them to keep the weights open?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not aware of any besides &amp;quot;good publicity&amp;quot; and &amp;quot;easy way to grow user base to cash in later&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m7wx5z",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4yet0d/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753385043,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753385043,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xremb",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "GPTshop_ai",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4v05tx",
                                "score": 1,
                                "author_fullname": "t2_rkmud0isr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Deepseek already became the new linux. IMHO, your take is ...",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xremb",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Deepseek already became the new linux. IMHO, your take is ...&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4xremb/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753378480,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753378480,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4y2psx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ttkciar",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4v05tx",
                                "score": 1,
                                "author_fullname": "t2_cpegz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; Linux being open-source has the advantage of more developers being able to contributes.\n\nYep.  It also has the advantage that developers are deciding what improvements to prioritize, whereas at Microsoft improvements to Windows are prioritized by managers.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4y2psx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Linux being open-source has the advantage of more developers being able to contributes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yep.  It also has the advantage that developers are deciding what improvements to prioritize, whereas at Microsoft improvements to Windows are prioritized by managers.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4y2psx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753381584,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1753381584,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4v05tx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Stetto",
                      "can_mod_post": false,
                      "created_utc": 1753342565,
                      "send_replies": true,
                      "parent_id": "t1_n4uv74o",
                      "score": 6,
                      "author_fullname": "t2_cqodq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Linux being open-source has the advantage of more developers being able to contributes.\n\nLLMs being open-source has only the down-side, that they can be used unlicensed. Meanwhile, whoever develops the model still has to get hold on an unreasonable amount of data and pay incredible infrastructure costs.\n\nWhile I'm a big fan of open-source software, I don't see how the benefits translate to LLMs.\n\nBehind every successful open-source ~~money~~ model, there's still a large company pouring money into it and I doubt all of those companies will keep their models open-source out of the goodness of their hearts.",
                      "edited": 1753385336,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4v05tx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Linux being open-source has the advantage of more developers being able to contributes.&lt;/p&gt;\n\n&lt;p&gt;LLMs being open-source has only the down-side, that they can be used unlicensed. Meanwhile, whoever develops the model still has to get hold on an unreasonable amount of data and pay incredible infrastructure costs.&lt;/p&gt;\n\n&lt;p&gt;While I&amp;#39;m a big fan of open-source software, I don&amp;#39;t see how the benefits translate to LLMs.&lt;/p&gt;\n\n&lt;p&gt;Behind every successful open-source &lt;del&gt;money&lt;/del&gt; model, there&amp;#39;s still a large company pouring money into it and I doubt all of those companies will keep their models open-source out of the goodness of their hearts.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v05tx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753342565,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uv74o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTshop_ai",
            "can_mod_post": false,
            "created_utc": 1753339821,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_rkmud0isr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My guess is, that open source may soon even close the gap. But we might end up with the same situation as with Windows vs Linux. Linux is far far far better. But people still use windows. It is absolutly ridiculous.",
            "edited": 1753340059,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uv74o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My guess is, that open source may soon even close the gap. But we might end up with the same situation as with Windows vs Linux. Linux is far far far better. But people still use windows. It is absolutly ridiculous.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uv74o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339821,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vwero",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Budget_Map_3333",
            "can_mod_post": false,
            "created_utc": 1753358841,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_19mrnrt357",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In terms of model performance of similar types, I think proprietary might have a leg up because of heavier investment.\n\nHowever, innovation and breakthroughs ***usually*** happen on the open-source front because of an engaged community, a wider pool of knowledge and sometimes constrained resources can actually be **a good thing**.\n\nJust look at OpenAI is blowing through a fortune and are barely keeping up. Then a few guys with a couple million of investment go ahead and build DeepSeek R1 with a fraction of compute. More infrastructure and money ≠ innovation.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vwero",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In terms of model performance of similar types, I think proprietary might have a leg up because of heavier investment.&lt;/p&gt;\n\n&lt;p&gt;However, innovation and breakthroughs &lt;strong&gt;&lt;em&gt;usually&lt;/em&gt;&lt;/strong&gt; happen on the open-source front because of an engaged community, a wider pool of knowledge and sometimes constrained resources can actually be &lt;strong&gt;a good thing&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Just look at OpenAI is blowing through a fortune and are barely keeping up. Then a few guys with a couple million of investment go ahead and build DeepSeek R1 with a fraction of compute. More infrastructure and money ≠ innovation.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vwero/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753358841,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4wgbwb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ulterior-Motive_",
            "can_mod_post": false,
            "created_utc": 1753365476,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_127atw4awd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "There is no moat. As long as everyone's using the same basic tech, applying the same basic principles, there's no reason the gap can't close.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4wgbwb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is no moat. As long as everyone&amp;#39;s using the same basic tech, applying the same basic principles, there&amp;#39;s no reason the gap can&amp;#39;t close.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4wgbwb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753365476,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4wlaex",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "-dysangel-",
            "can_mod_post": false,
            "created_utc": 1753366933,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_12ggykute6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So far history shows that open source always does well in the long term (just look at Android or SteamOS). It sometimes just takes a while to get there. With AI so far, open source is kicking ass and there's not that much reason to believe that this will change that I can see.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4wlaex",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So far history shows that open source always does well in the long term (just look at Android or SteamOS). It sometimes just takes a while to get there. With AI so far, open source is kicking ass and there&amp;#39;s not that much reason to believe that this will change that I can see.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4wlaex/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753366933,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4x9ox8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jimmc414",
            "can_mod_post": false,
            "created_utc": 1753373700,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_1u7kis1i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Open source will likely always stay close behind proprietary models due to the practice of model distillation.  It's much easier to stay in the race when your training data has been carefully curated by a superior model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4x9ox8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Open source will likely always stay close behind proprietary models due to the practice of model distillation.  It&amp;#39;s much easier to stay in the race when your training data has been carefully curated by a superior model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4x9ox8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373700,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xz8an",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fungnoth",
            "can_mod_post": false,
            "created_utc": 1753380609,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_13v3uw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The real issue is the consumer vs commercial hardware gap. Without that, open source is hardly open source. We're getting things at some rich lab's mercy. They could easily do an open ai or stability ai move anytime\n\nAnd no one is actually making money. Not even open ai (minus the investments from big corps).\n\nSo it's essentially still a bubble. Not because it's not useful, but even running it is so expensive, why can we expect people spending millions training them and release it for free.\n\nEven if all members here has the knowledge on par with top ai institutes. It's still not realistic to have a true open source community\n\nLet alone data",
            "edited": 1753380932,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xz8an",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The real issue is the consumer vs commercial hardware gap. Without that, open source is hardly open source. We&amp;#39;re getting things at some rich lab&amp;#39;s mercy. They could easily do an open ai or stability ai move anytime&lt;/p&gt;\n\n&lt;p&gt;And no one is actually making money. Not even open ai (minus the investments from big corps).&lt;/p&gt;\n\n&lt;p&gt;So it&amp;#39;s essentially still a bubble. Not because it&amp;#39;s not useful, but even running it is so expensive, why can we expect people spending millions training them and release it for free.&lt;/p&gt;\n\n&lt;p&gt;Even if all members here has the knowledge on par with top ai institutes. It&amp;#39;s still not realistic to have a true open source community&lt;/p&gt;\n\n&lt;p&gt;Let alone data&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4xz8an/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753380609,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y3ysf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1753381940,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the commercial LLM trainers are starting to hit the point of diminishing returns on parameter scaling and training data quality, and are slow to adopt more advanced training techniques.  They do have the advantage of having the compute resources to extract/train smaller models from *vast* large models, though.\n\nThe open source community has the advantages of more quickly adopting inference-time augmentations and new training techniques as researchers publish them, and also more creative use of synthetic datasets and reward models for RLAIF and dataset curation.\n\nIf these trends continue, open source should narrow the gap, even if it never entirely closes.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y3ysf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the commercial LLM trainers are starting to hit the point of diminishing returns on parameter scaling and training data quality, and are slow to adopt more advanced training techniques.  They do have the advantage of having the compute resources to extract/train smaller models from &lt;em&gt;vast&lt;/em&gt; large models, though.&lt;/p&gt;\n\n&lt;p&gt;The open source community has the advantages of more quickly adopting inference-time augmentations and new training techniques as researchers publish them, and also more creative use of synthetic datasets and reward models for RLAIF and dataset curation.&lt;/p&gt;\n\n&lt;p&gt;If these trends continue, open source should narrow the gap, even if it never entirely closes.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4y3ysf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753381940,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xs1g3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "krakoi90",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4v8or5",
                                "score": 1,
                                "author_fullname": "t2_uzz9kqlq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If the scaling truly continues, then obviously yes.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xs1g3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If the scaling truly continues, then obviously yes.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4xs1g3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753378648,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753378648,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4v8or5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ethertype",
                      "can_mod_post": false,
                      "created_utc": 1753347427,
                      "send_replies": true,
                      "parent_id": "t1_n4uy8mv",
                      "score": 2,
                      "author_fullname": "t2_3nfev4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "And what would it take to turn that question on its head: \n\nWill Western labs have access to enough compute/memory/talent/time/money/energy/manufacturing-tech to keep up?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4v8or5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And what would it take to turn that question on its head: &lt;/p&gt;\n\n&lt;p&gt;Will Western labs have access to enough compute/memory/talent/time/money/energy/manufacturing-tech to keep up?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v8or5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753347427,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uy8mv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "krakoi90",
            "can_mod_post": false,
            "created_utc": 1753341472,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_uzz9kqlq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Open models = Chinese models. So, in other words, your question is: did closed-model (western) AI labs find a way around the data problem, and can they continue to scale up by building larger and larger server farms? Will Chinese labs have access to enough compute to keep up?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uy8mv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Open models = Chinese models. So, in other words, your question is: did closed-model (western) AI labs find a way around the data problem, and can they continue to scale up by building larger and larger server farms? Will Chinese labs have access to enough compute to keep up?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uy8mv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753341472,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vo2dx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "davewolfs",
            "can_mod_post": false,
            "created_utc": 1753355420,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 0,
            "author_fullname": "t2_pms20",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It has widened and will continue to do so.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vo2dx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It has widened and will continue to do so.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vo2dx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753355420,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]