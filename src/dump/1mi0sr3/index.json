[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I know about the rule of researching beforehand, but I didn't find any satisfactory answers. Right now, after setting up koboldcpp and sillytavern I use dolphin 2.6 mistral 7b which was recommended to me by deepseek, I installed everything with it's help and because of that I didn't at first had a thought about searching for other models, but when looking it up I noticed it's at least 2 years old.\n\nSo, TLDR: What is the best free model that I can run locally with my hardware constraints for good(-ish?) roleplay?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What is the best current model for roleplay if I have 8gb vram 6600xt 16gb ram and 3600 ryzen?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mi0sr3",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_emzorlxl8",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754371884,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know about the rule of researching beforehand, but I didn&amp;#39;t find any satisfactory answers. Right now, after setting up koboldcpp and sillytavern I use dolphin 2.6 mistral 7b which was recommended to me by deepseek, I installed everything with it&amp;#39;s help and because of that I didn&amp;#39;t at first had a thought about searching for other models, but when looking it up I noticed it&amp;#39;s at least 2 years old.&lt;/p&gt;\n\n&lt;p&gt;So, TLDR: What is the best free model that I can run locally with my hardware constraints for good(-ish?) roleplay?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mi0sr3",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Mental_Budget_5085",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/",
            "subreddit_subscribers": 510540,
            "created_utc": 1754371884,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n70vm0b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "CharmingRogue851",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n70t3cd",
                                "score": 1,
                                "author_fullname": "t2_ex12r",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ah you're right, woops. I'll edit it. And yeah, I mean, you can't expect too much from low end models to be honest. It also depend heavily on the system prompt. You can't give too many details or make it too big. Small models don't have the capacity to keep all the rules in mind and they will overload; meaning they will overcorrect and just end up repeating themselves a lot.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n70vm0b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah you&amp;#39;re right, woops. I&amp;#39;ll edit it. And yeah, I mean, you can&amp;#39;t expect too much from low end models to be honest. It also depend heavily on the system prompt. You can&amp;#39;t give too many details or make it too big. Small models don&amp;#39;t have the capacity to keep all the rules in mind and they will overload; meaning they will overcorrect and just end up repeating themselves a lot.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi0sr3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70vm0b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754386232,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754386232,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n70t3cd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1754384754,
                      "send_replies": true,
                      "parent_id": "t1_n70i0ra",
                      "score": 2,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "1. There is no Qwen 3 7B.\n\n2. Last time I tried it for creative writing (not RP I know) it was shit. Very, very high slop.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n70t3cd",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;There is no Qwen 3 7B.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Last time I tried it for creative writing (not RP I know) it was shit. Very, very high slop.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi0sr3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70t3cd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754384754,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n70w5jb",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "CharmingRogue851",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n70oc18",
                                                    "score": 1,
                                                    "author_fullname": "t2_ex12r",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "470 tokens for responses is totally fine for most roleplay, but you can safely bump it up a bit if you want longer replies. Between 350–600 tokens works well, but for more narrative or multi-character scenes you can also go up to 700–800 without issues.\n\nTry 550–600 as a default for long replies, and drop it lower (300–400) if you want shorter back-and-forth.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n70w5jb",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;470 tokens for responses is totally fine for most roleplay, but you can safely bump it up a bit if you want longer replies. Between 350–600 tokens works well, but for more narrative or multi-character scenes you can also go up to 700–800 without issues.&lt;/p&gt;\n\n&lt;p&gt;Try 550–600 as a default for long replies, and drop it lower (300–400) if you want shorter back-and-forth.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi0sr3",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70w5jb/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754386546,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754386546,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n70oc18",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Mental_Budget_5085",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n70ks3z",
                                          "score": 2,
                                          "author_fullname": "t2_emzorlxl8",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "How much tokens should I allocate to responses? Right now i use 470",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n70oc18",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How much tokens should I allocate to responses? Right now i use 470&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi0sr3",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70oc18/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754381978,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754381978,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n70ks3z",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "CharmingRogue851",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n70jjii",
                                "score": 1,
                                "author_fullname": "t2_ex12r",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "For the 7B/13B models using a context length of 2048–3072 tokens is standard and very stable. Context 3072 is a good cap. So Deepseek suggesting 3072 makes sense. Most 7B/13B models are fine up to that point, and you won’t see big gains going higher unless you’re doing really long, complex stuff. If you try to push it much more, you’ll either crash or slow things down a lot. For 32B models, stick to 2048. \n\nAnd TTS and STT are barely demanding compared to the LLM. Whisper tiny/base for STT uses almost no resources, just CPU, and is fast. For TTS, Piper or Coqui can run on almost anything in real time. Bark is heavy and slow, only worth it if you want experimental voices. And if you're willing to pay: ElevenLabs doesn’t run locally, so it doesn’t matter for performance, but it’s paid and blocks NSFW.\n\nRunning both TTS and STT at once should be no problem. The LLM is always the real resource hog, not these. If you’re not maxing out VRAM already, you’ll barely notice a difference.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n70ks3z",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For the 7B/13B models using a context length of 2048–3072 tokens is standard and very stable. Context 3072 is a good cap. So Deepseek suggesting 3072 makes sense. Most 7B/13B models are fine up to that point, and you won’t see big gains going higher unless you’re doing really long, complex stuff. If you try to push it much more, you’ll either crash or slow things down a lot. For 32B models, stick to 2048. &lt;/p&gt;\n\n&lt;p&gt;And TTS and STT are barely demanding compared to the LLM. Whisper tiny/base for STT uses almost no resources, just CPU, and is fast. For TTS, Piper or Coqui can run on almost anything in real time. Bark is heavy and slow, only worth it if you want experimental voices. And if you&amp;#39;re willing to pay: ElevenLabs doesn’t run locally, so it doesn’t matter for performance, but it’s paid and blocks NSFW.&lt;/p&gt;\n\n&lt;p&gt;Running both TTS and STT at once should be no problem. The LLM is always the real resource hog, not these. If you’re not maxing out VRAM already, you’ll barely notice a difference.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi0sr3",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70ks3z/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754379935,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754379935,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n70jjii",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Mental_Budget_5085",
                      "can_mod_post": false,
                      "created_utc": 1754379217,
                      "send_replies": true,
                      "parent_id": "t1_n70i0ra",
                      "score": 2,
                      "author_fullname": "t2_emzorlxl8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for this detailed response, how much context should i use, deepseek told me to use 3072 to not crash, but I don't know if it's too little. Also, if you use them, how demanding are text to speech/speech to text and how demanding when both of them are running?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n70jjii",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for this detailed response, how much context should i use, deepseek told me to use 3072 to not crash, but I don&amp;#39;t know if it&amp;#39;s too little. Also, if you use them, how demanding are text to speech/speech to text and how demanding when both of them are running?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi0sr3",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70jjii/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754379217,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n70i0ra",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "CharmingRogue851",
            "can_mod_post": false,
            "created_utc": 1754378352,
            "send_replies": true,
            "parent_id": "t3_1mi0sr3",
            "score": 0,
            "author_fullname": "t2_ex12r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Here's a list of good roleplay models (including NSFW).\n\nFor all these models use the Q4\\_K\\_M or Q5 version for best results, else the generation time will increase too much.\n\nSmall models (few seconds generation time):\n\n* Qwen3 8B: Excellent at character RP, emotionally nuanced dialog, and long scenes.\n* Mythmalion-13B: Best for: Uncensored, creative, lively NSFW/ERP roleplay. Sits at the top for blending stability, emotion, and raw fun.\n* MythoMax 13B / Toppy-M 13B: Pure NSFW/ERP/dirty talk, less realism, but fastest if you want instant spicy content.\n* MythoMax L2 7B:  Specifically tuned for NSFW, creative storytelling, and ERP. If you're doing NSFW girlfriend, dominant/submissive RP, or fantasy roleplay, this one is perfect.\n* Toppy-M 7B / Gryphe-M 7B: Based on MythoMax but more NSFW-heavy, edgier, more willing to push boundaries. Less clean, more “naughty”—great for NSFW, taboo, and spicy AI girlfriend content. Slightly less stable than MythoMax.\n* Pygmalion 7B/13B: Older, but tuned entirely for NSFW roleplay, often used in SillyTavern.\n\nHeavier models (can take 1-3 minutes to generate with your specs):\n\n* Qwen3-32B: The best for immersive, realistic, long-form NSFW roleplay, period, if you don’t mind waiting.\n* Nous Hermes 2 Pro 34B - S-tier for spicy RP if you can find an uncensored checkpoint. *That being said, I couldn't find an uncensored model myself on the popular websites (github, huggingface, etc)*\n* Mixtral 8x7B: MoE, very strong at creative/group/complex NSFW, can handle long scenes. Great for narrative, less emotional than dense models.\n\nBonus: You can also check out Pygmalion-2 7b/13b specifically designed for RP and NSFW (with SillyTavern settings):\n\n[https://blog.pygmalion.chat/posts/introducing\\_pygmalion\\_2/](https://blog.pygmalion.chat/posts/introducing_pygmalion_2/)\n\n&gt;*While we trained our Pygmalion-2 models, we wondered if model merging could help the Pygmalion-2 models out in terms of being able to maintain coherency and enhance creativity. To that end, we reached out to Gryphe, creator of the popular MythoMax-L2-13B model (which itself is a blend of many different Llama-2 models) to help us merge our model with theirs. The result is a model named Mythmalion-13B, a versatile and powerful roleplay model combining MythoMax’s stability and intelligence with Pygmalion-2’s raw creative power.*\n\n&gt;*According to our testers, this model surpasses the original Mythomax-L2-13B in terms of response quality.*",
            "edited": 1754386101,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70i0ra",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s a list of good roleplay models (including NSFW).&lt;/p&gt;\n\n&lt;p&gt;For all these models use the Q4_K_M or Q5 version for best results, else the generation time will increase too much.&lt;/p&gt;\n\n&lt;p&gt;Small models (few seconds generation time):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Qwen3 8B: Excellent at character RP, emotionally nuanced dialog, and long scenes.&lt;/li&gt;\n&lt;li&gt;Mythmalion-13B: Best for: Uncensored, creative, lively NSFW/ERP roleplay. Sits at the top for blending stability, emotion, and raw fun.&lt;/li&gt;\n&lt;li&gt;MythoMax 13B / Toppy-M 13B: Pure NSFW/ERP/dirty talk, less realism, but fastest if you want instant spicy content.&lt;/li&gt;\n&lt;li&gt;MythoMax L2 7B:  Specifically tuned for NSFW, creative storytelling, and ERP. If you&amp;#39;re doing NSFW girlfriend, dominant/submissive RP, or fantasy roleplay, this one is perfect.&lt;/li&gt;\n&lt;li&gt;Toppy-M 7B / Gryphe-M 7B: Based on MythoMax but more NSFW-heavy, edgier, more willing to push boundaries. Less clean, more “naughty”—great for NSFW, taboo, and spicy AI girlfriend content. Slightly less stable than MythoMax.&lt;/li&gt;\n&lt;li&gt;Pygmalion 7B/13B: Older, but tuned entirely for NSFW roleplay, often used in SillyTavern.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Heavier models (can take 1-3 minutes to generate with your specs):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Qwen3-32B: The best for immersive, realistic, long-form NSFW roleplay, period, if you don’t mind waiting.&lt;/li&gt;\n&lt;li&gt;Nous Hermes 2 Pro 34B - S-tier for spicy RP if you can find an uncensored checkpoint. &lt;em&gt;That being said, I couldn&amp;#39;t find an uncensored model myself on the popular websites (github, huggingface, etc)&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;Mixtral 8x7B: MoE, very strong at creative/group/complex NSFW, can handle long scenes. Great for narrative, less emotional than dense models.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Bonus: You can also check out Pygmalion-2 7b/13b specifically designed for RP and NSFW (with SillyTavern settings):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.pygmalion.chat/posts/introducing_pygmalion_2/\"&gt;https://blog.pygmalion.chat/posts/introducing_pygmalion_2/&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;While we trained our Pygmalion-2 models, we wondered if model merging could help the Pygmalion-2 models out in terms of being able to maintain coherency and enhance creativity. To that end, we reached out to Gryphe, creator of the popular MythoMax-L2-13B model (which itself is a blend of many different Llama-2 models) to help us merge our model with theirs. The result is a model named Mythmalion-13B, a versatile and powerful roleplay model combining MythoMax’s stability and intelligence with Pygmalion-2’s raw creative power.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;According to our testers, this model surpasses the original Mythomax-L2-13B in terms of response quality.&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70i0ra/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754378352,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi0sr3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70t8vg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754384844,
            "send_replies": true,
            "parent_id": "t3_1mi0sr3",
            "score": 1,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Simply use Mistral Nemo or its finetunes.\n\n&gt; which was recommended to me by deepseek,\n\nNever trust LLMs for factual information, esp. a niche topics.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70t8vg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Simply use Mistral Nemo or its finetunes.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;which was recommended to me by deepseek,&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Never trust LLMs for factual information, esp. a niche topics.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi0sr3/what_is_the_best_current_model_for_roleplay_if_i/n70t8vg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754384844,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi0sr3",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]