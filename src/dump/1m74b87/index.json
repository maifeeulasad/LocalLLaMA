[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "https://preview.redd.it/hx255agsalef1.png?width=932&amp;format=png&amp;auto=webp&amp;s=9e314e0904871f71278151b307047e3b464b3abe\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen3-Coder is VERY expensive maybe one day You can run it locally.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 111,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "hx255agsalef1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 85,
                    "x": 108,
                    "u": "https://preview.redd.it/hx255agsalef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=063f39b86117f95e8228b4552fd603c5bbd7e1bd"
                  },
                  {
                    "y": 171,
                    "x": 216,
                    "u": "https://preview.redd.it/hx255agsalef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5889077fccc99ad0896d2b18ddd7ae26302b033f"
                  },
                  {
                    "y": 253,
                    "x": 320,
                    "u": "https://preview.redd.it/hx255agsalef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ab42e8d5e41cae2912da8cdc8580ad23107c4ee1"
                  },
                  {
                    "y": 507,
                    "x": 640,
                    "u": "https://preview.redd.it/hx255agsalef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a59c57fd28596a519375805b27c122c7fb354ec"
                  }
                ],
                "s": {
                  "y": 739,
                  "x": 932,
                  "u": "https://preview.redd.it/hx255agsalef1.png?width=932&amp;format=png&amp;auto=webp&amp;s=9e314e0904871f71278151b307047e3b464b3abe"
                },
                "id": "hx255agsalef1"
              }
            },
            "name": "t3_1m74b87",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.38,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_4dx55sw2",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/ofD_PGhYFdSfHB4tfxLg9C_lgOPt3cFUilmSEBETViA.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753261576,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/hx255agsalef1.png?width=932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e314e0904871f71278151b307047e3b464b3abe\"&gt;https://preview.redd.it/hx255agsalef1.png?width=932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e314e0904871f71278151b307047e3b464b3abe&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m74b87",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "PositiveEnergyMatter",
            "discussion_type": null,
            "num_comments": 16,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/",
            "subreddit_subscribers": 503257,
            "created_utc": 1753261576,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4okc6p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Dark_Fire_12",
                      "can_mod_post": false,
                      "created_utc": 1753262239,
                      "send_replies": true,
                      "parent_id": "t1_n4ojlkk",
                      "score": 5,
                      "author_fullname": "t2_kwl47",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Also more providers are going to come online, the model only came out a few hours ago. \n\nThey are a bit right about the GPU poor not being able to run it, but Qwen will release smaller models.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4okc6p",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also more providers are going to come online, the model only came out a few hours ago. &lt;/p&gt;\n\n&lt;p&gt;They are a bit right about the GPU poor not being able to run it, but Qwen will release smaller models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m74b87",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4okc6p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753262239,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4orjy0",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "-dysangel-",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4opogk",
                                          "score": 2,
                                          "author_fullname": "t2_12ggykute6",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "or buy a Mac with 256GB or 512GB of unified memory. I'm currently running an 80GB unsloth quant of qwen3-235b-a22b-instruct-2507, and downloading a 175GB unsloth quant of the new coder. I'm not sure what smaller sizes they're releasing, but I'd guess 32B will be the real game changer of this generation of releases. Qwen3 32B is already feeling at GPT4 level, so Qwen3 Coder could be at maybe Claude 3.5-3.7 level? If 32B or 70B can hit Claude 4.0 level then we're done - high quality local coding will be available on your average MBP in a couple of years",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4orjy0",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;or buy a Mac with 256GB or 512GB of unified memory. I&amp;#39;m currently running an 80GB unsloth quant of qwen3-235b-a22b-instruct-2507, and downloading a 175GB unsloth quant of the new coder. I&amp;#39;m not sure what smaller sizes they&amp;#39;re releasing, but I&amp;#39;d guess 32B will be the real game changer of this generation of releases. Qwen3 32B is already feeling at GPT4 level, so Qwen3 Coder could be at maybe Claude 3.5-3.7 level? If 32B or 70B can hit Claude 4.0 level then we&amp;#39;re done - high quality local coding will be available on your average MBP in a couple of years&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m74b87",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4orjy0/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753266191,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1753266191,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4oqlqu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "GPTshop_ai",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4opogk",
                                          "score": -3,
                                          "author_fullname": "t2_rkmud0isr",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "People who buy consumer cards or Mi50 and expect peakperformacne do not know that the most important thing is the connetion speed between the GPUs. Only one GPU is best. If multiple are needed, the connection speed is the most important bottleneck. consumer cards are connected by slow PCIe vs. high-speed NV-link. consumer cards are child's play. Real men run stuff...\n\nPS: Just stateting the prices for GPUs does not cut it. You need all the rest too. Then you end up at sums already quite close to something real.",
                                          "edited": 1753265904,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4oqlqu",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People who buy consumer cards or Mi50 and expect peakperformacne do not know that the most important thing is the connetion speed between the GPUs. Only one GPU is best. If multiple are needed, the connection speed is the most important bottleneck. consumer cards are connected by slow PCIe vs. high-speed NV-link. consumer cards are child&amp;#39;s play. Real men run stuff...&lt;/p&gt;\n\n&lt;p&gt;PS: Just stateting the prices for GPUs does not cut it. You need all the rest too. Then you end up at sums already quite close to something real.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m74b87",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4oqlqu/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753265693,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753265693,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4opogk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Toooooool",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4oo9v6",
                                "score": 0,
                                "author_fullname": "t2_8llornh4",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "first link doesn't work and the second link.. bruh.. $38k for a GH200? just buy a 4029GP for $2k and fill it with MI50's for $150 a pop. that's 320GB VRAM for $3500",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4opogk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;first link doesn&amp;#39;t work and the second link.. bruh.. $38k for a GH200? just buy a 4029GP for $2k and fill it with MI50&amp;#39;s for $150 a pop. that&amp;#39;s 320GB VRAM for $3500&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m74b87",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4opogk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753265199,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753265199,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4oo9v6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "GPTshop_ai",
                      "can_mod_post": false,
                      "created_utc": 1753264446,
                      "send_replies": true,
                      "parent_id": "t1_n4ojlkk",
                      "score": -2,
                      "author_fullname": "t2_rkmud0isr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You can run it now. Just buy some crazy hardware here: [GPTshop.ai](http://GTshop.ai) and [GPTrack.ai](http://GPTrack.ai)",
                      "edited": 1753265415,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4oo9v6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can run it now. Just buy some crazy hardware here: &lt;a href=\"http://GTshop.ai\"&gt;GPTshop.ai&lt;/a&gt; and &lt;a href=\"http://GPTrack.ai\"&gt;GPTrack.ai&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m74b87",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4oo9v6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753264446,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4ojlkk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "logseventyseven",
            "can_mod_post": false,
            "created_utc": 1753261812,
            "send_replies": true,
            "parent_id": "t3_1m74b87",
            "score": 23,
            "author_fullname": "t2_x4ih8rkff",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm not sure what the title is supposed to mean. Can't you run it locally right now?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ojlkk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure what the title is supposed to mean. Can&amp;#39;t you run it locally right now?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4ojlkk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753261812,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m74b87",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 23
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4onbmd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "SourceCodeplz",
                      "can_mod_post": false,
                      "created_utc": 1753263930,
                      "send_replies": true,
                      "parent_id": "t1_n4ol9zx",
                      "score": 1,
                      "author_fullname": "t2_608qiyuv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yep, same here. Qwen3-30B-A3B is already amazing for me, the coding specific one should be even better",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4onbmd",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yep, same here. Qwen3-30B-A3B is already amazing for me, the coding specific one should be even better&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m74b87",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4onbmd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753263930,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4ol9zx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mysterious_Finish543",
            "can_mod_post": false,
            "created_utc": 1753262783,
            "send_replies": true,
            "parent_id": "t3_1m74b87",
            "score": 10,
            "author_fullname": "t2_gbx2bcdvl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs.\n\nThe [Qwen3 Coder](https://qwenlm.github.io/blog/qwen3-coder/) blog post says that more, smaller variants are coming, likely distilled from this expensive frontier level model.\n\nThose should be much cheaper, and might be able to run locally. I'm really looking forward to a potential Qwen3-Coder-30B-A3B-Instruct.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ol9zx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The &lt;a href=\"https://qwenlm.github.io/blog/qwen3-coder/\"&gt;Qwen3 Coder&lt;/a&gt; blog post says that more, smaller variants are coming, likely distilled from this expensive frontier level model.&lt;/p&gt;\n\n&lt;p&gt;Those should be much cheaper, and might be able to run locally. I&amp;#39;m really looking forward to a potential Qwen3-Coder-30B-A3B-Instruct.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4ol9zx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753262783,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m74b87",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4op2vd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AXYZE8",
                      "can_mod_post": false,
                      "created_utc": 1753264878,
                      "send_replies": true,
                      "parent_id": "t1_n4om2y1",
                      "score": 3,
                      "author_fullname": "t2_10dacl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Qwen scales ties so high, because they dont want you to use it as theyre not confident about performance, but still want to market that as 1M context window model.\n\n\nAt 256K-1M output tokens are 4x as expensive as Gemini 2.5 Pro. Nobody would consider using that over Gemini and thats the whole point of these prices. \n\n\nOn paper as good as Gemini in \"specs\", real people dont complain about performance above 256K+ because they dont use it, they can market very low \"starting from\" point. \nIts marketing strategy to maximize good PR.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4op2vd",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen scales ties so high, because they dont want you to use it as theyre not confident about performance, but still want to market that as 1M context window model.&lt;/p&gt;\n\n&lt;p&gt;At 256K-1M output tokens are 4x as expensive as Gemini 2.5 Pro. Nobody would consider using that over Gemini and thats the whole point of these prices. &lt;/p&gt;\n\n&lt;p&gt;On paper as good as Gemini in &amp;quot;specs&amp;quot;, real people dont complain about performance above 256K+ because they dont use it, they can market very low &amp;quot;starting from&amp;quot; point. \nIts marketing strategy to maximize good PR.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m74b87",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4op2vd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753264878,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4om2y1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MaxKruse96",
            "can_mod_post": false,
            "created_utc": 1753263240,
            "send_replies": true,
            "parent_id": "t3_1m74b87",
            "score": 3,
            "author_fullname": "t2_pfi81",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "if it uses the context size better than claude 4 opus, then its definitly beating it (and claude 4 opus is 15/75 per 1mil...) This progressive tiering also means that small tasks are cheap, and it only scales to actual cost for big tasks where the model needs to also use all its capability. Good hybrid approach imo.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4om2y1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if it uses the context size better than claude 4 opus, then its definitly beating it (and claude 4 opus is 15/75 per 1mil...) This progressive tiering also means that small tasks are cheap, and it only scales to actual cost for big tasks where the model needs to also use all its capability. Good hybrid approach imo.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4om2y1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753263240,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m74b87",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4p3j1a",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "-dysangel-",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4p2291",
                                          "score": 1,
                                          "author_fullname": "t2_12ggykute6",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I agree. My point is that in a couple of years, I think your average software engineer or gaming laptop will be able to run Claude 4.0 level agents. And I think by the end of this year a 256GB Mac Studio/AMD EPYC setup will be running Claude 3.7-4.0 level agents (if we're not there already - I'm still waiting for Qwen 3 Coder to finish downloading).",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4p3j1a",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree. My point is that in a couple of years, I think your average software engineer or gaming laptop will be able to run Claude 4.0 level agents. And I think by the end of this year a 256GB Mac Studio/AMD EPYC setup will be running Claude 3.7-4.0 level agents (if we&amp;#39;re not there already - I&amp;#39;m still waiting for Qwen 3 Coder to finish downloading).&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m74b87",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4p3j1a/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753271576,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1753271576,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4p2291",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Low-Opening25",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4os62n",
                                "score": 1,
                                "author_fullname": "t2_ebfjvj5t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "how many tokens can you buy for the price of Mac Studio 256/512 $5k/$10k? 512GB build is equivalent of 4 years of unlimited Claude Code with Opus without any upfront investment.\n\nI would love to run these models locally, but the economy is not there.\n\nI would rather buy 36GB MacBook Pro M4 for my IDE workhorse and use the difference for token subscription instead of bothering with running local models.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4p2291",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;how many tokens can you buy for the price of Mac Studio 256/512 $5k/$10k? 512GB build is equivalent of 4 years of unlimited Claude Code with Opus without any upfront investment.&lt;/p&gt;\n\n&lt;p&gt;I would love to run these models locally, but the economy is not there.&lt;/p&gt;\n\n&lt;p&gt;I would rather buy 36GB MacBook Pro M4 for my IDE workhorse and use the difference for token subscription instead of bothering with running local models.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m74b87",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4p2291/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753270985,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753270985,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4os62n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "-dysangel-",
                      "can_mod_post": false,
                      "created_utc": 1753266509,
                      "send_replies": true,
                      "parent_id": "t1_n4onras",
                      "score": 2,
                      "author_fullname": "t2_12ggykute6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Remember you can run this on a Mac Studio 256GB or 512GB and it will use around 300W iirc. AMD EPYC, nVidia DIGITS etc - it's rapidly going to become more and more feasible for the average person to have high quality local inference without breaking the bank. Though a Claude Code Max subscription is already really good value if you want to pay as you go rather than shell out for your own hardware",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4os62n",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Remember you can run this on a Mac Studio 256GB or 512GB and it will use around 300W iirc. AMD EPYC, nVidia DIGITS etc - it&amp;#39;s rapidly going to become more and more feasible for the average person to have high quality local inference without breaking the bank. Though a Claude Code Max subscription is already really good value if you want to pay as you go rather than shell out for your own hardware&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m74b87",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4os62n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753266509,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4onras",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "dheetoo",
            "can_mod_post": false,
            "created_utc": 1753264168,
            "send_replies": true,
            "parent_id": "t3_1m74b87",
            "score": 1,
            "author_fullname": "t2_c5n1x183x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "for model this big, locally run will not save you much either, this kind of model mean multi gpu setup, that will cost you a good amount of money, and it need to be maintained a lot. also electricity bill.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4onras",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for model this big, locally run will not save you much either, this kind of model mean multi gpu setup, that will cost you a good amount of money, and it need to be maintained a lot. also electricity bill.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4onras/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753264168,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m74b87",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4oqmee",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "complead",
            "can_mod_post": false,
            "created_utc": 1753265702,
            "send_replies": true,
            "parent_id": "t3_1m74b87",
            "score": 1,
            "author_fullname": "t2_uzn88fhh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen3-Coder's local use isn't a cost-saver unless you've got the right multi-GPU setup. Running smaller versions when they release might lower expenses. Balancing GPU costs with cloud or hosted solutions could offer a better approach depending on your workload needs. Power and maintenance are key factors too.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4oqmee",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-Coder&amp;#39;s local use isn&amp;#39;t a cost-saver unless you&amp;#39;ve got the right multi-GPU setup. Running smaller versions when they release might lower expenses. Balancing GPU costs with cloud or hosted solutions could offer a better approach depending on your workload needs. Power and maintenance are key factors too.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m74b87/qwen3coder_is_very_expensive_maybe_one_day_you/n4oqmee/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753265702,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m74b87",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]