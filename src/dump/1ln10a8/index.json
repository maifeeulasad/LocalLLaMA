[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Feel free to downvote me into the gutter, but these are some of the latest Stupid FPHAM Crap (S-FPHAM\\_C) python scripts that I came up:\n\nmerge\\_lora\\_CPU\n\n[https://github.com/FartyPants/merge\\_lora\\_CPU](https://github.com/FartyPants/merge_lora_CPU)\n\nLoRA merging with a base model, primarily designed for CPU\n\nThis script allows you to merge a PEFT (Parameter-Efficient Fine-Tuning) LoRA adapter with a base Hugging Face model. It can also be used to simply resave a base model, potentially changing its format (e.g., to SafeTensors) or data type.  \nOy, and it goes around the Tied Weights in safetensors which was introduced after the \"recent Transformers happy update.\"\n\n# chonker\n\n[https://github.com/FartyPants/chonker](https://github.com/FartyPants/chonker)\n\n# Smart Text Chunker\n\nA \"sophisticated\" Python command-line tool for splitting large text files into smaller, more manageable chunks of, shall we say, semantic relevance.  It's designed for preparing text datasets for training and fine-tuning Large Language Models (LLMs).\n\n# mass_rewriter\n\nExtension for oobabooga WebUI\n\n[https://github.com/FartyPants/mass\\_rewriter](https://github.com/FartyPants/mass_rewriter)\n\nVersion 2.0, now with better logic is here!  \nThis tool helps you automate the process of modifying text in bulk using an AI model. You can load plain text files or JSON datasets, apply various transformations, and then save the rewritten content.\n\n# Axolotl_Loss_Graph\n\n[https://github.com/FartyPants/Axolotl\\_Loss\\_Graph](https://github.com/FartyPants/Axolotl_Loss_Graph)\n\nA handy, dinky-doo graph of your Axolotl training progress.  \nIt takes the data copied from the terminal output and makes a nice little  \nloss graph in a PNG format that you can easily send to your friends  \nshowing them how training your Axolotl is going so well!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "A bunch of LLM FPHAM Python scripts I've added to my GitHub in recent days",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ln10a8",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.85,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 14,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_7f6bw7v0",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 14,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1751155624,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751155063,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feel free to downvote me into the gutter, but these are some of the latest Stupid FPHAM Crap (S-FPHAM_C) python scripts that I came up:&lt;/p&gt;\n\n&lt;p&gt;merge_lora_CPU&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FartyPants/merge_lora_CPU\"&gt;https://github.com/FartyPants/merge_lora_CPU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;LoRA merging with a base model, primarily designed for CPU&lt;/p&gt;\n\n&lt;p&gt;This script allows you to merge a PEFT (Parameter-Efficient Fine-Tuning) LoRA adapter with a base Hugging Face model. It can also be used to simply resave a base model, potentially changing its format (e.g., to SafeTensors) or data type.&lt;br/&gt;\nOy, and it goes around the Tied Weights in safetensors which was introduced after the &amp;quot;recent Transformers happy update.&amp;quot;&lt;/p&gt;\n\n&lt;h1&gt;chonker&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FartyPants/chonker\"&gt;https://github.com/FartyPants/chonker&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Smart Text Chunker&lt;/h1&gt;\n\n&lt;p&gt;A &amp;quot;sophisticated&amp;quot; Python command-line tool for splitting large text files into smaller, more manageable chunks of, shall we say, semantic relevance.  It&amp;#39;s designed for preparing text datasets for training and fine-tuning Large Language Models (LLMs).&lt;/p&gt;\n\n&lt;h1&gt;mass_rewriter&lt;/h1&gt;\n\n&lt;p&gt;Extension for oobabooga WebUI&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FartyPants/mass_rewriter\"&gt;https://github.com/FartyPants/mass_rewriter&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Version 2.0, now with better logic is here!&lt;br/&gt;\nThis tool helps you automate the process of modifying text in bulk using an AI model. You can load plain text files or JSON datasets, apply various transformations, and then save the rewritten content.&lt;/p&gt;\n\n&lt;h1&gt;Axolotl_Loss_Graph&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FartyPants/Axolotl_Loss_Graph\"&gt;https://github.com/FartyPants/Axolotl_Loss_Graph&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A handy, dinky-doo graph of your Axolotl training progress.&lt;br/&gt;\nIt takes the data copied from the terminal output and makes a nice little&lt;br/&gt;\nloss graph in a PNG format that you can easily send to your friends&lt;br/&gt;\nshowing them how training your Axolotl is going so well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?auto=webp&amp;s=44b13da1c1be7b14c8ee5aba53b6181d4b1c5413",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e42fe5f655ba1b49d55fb695a20f1efcc8f6f56b",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9a25601a87e45eaa97a41a5fac3607654793cc84",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad0a80f8f5cbc534074efeb90c4db28221871f4d",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=02463b34b13a19746db6332f2c9f2dff325426ac",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=254f77e8658dd4e8d740eb44317ca87d1cf6e9b1",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4ec4e1a4bb4e5a25d58c83cab13172622ec3656d",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "BT3M3iYf4yEFnx0Vz4O_MB7B4QL1AC2GX3cXr2sAK7A"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1ln10a8",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "FPham",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ln10a8/a_bunch_of_llm_fpham_python_scripts_ive_added_to/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ln10a8/a_bunch_of_llm_fpham_python_scripts_ive_added_to/",
            "subreddit_subscribers": 492625,
            "created_utc": 1751155063,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n0d84ro",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FPham",
                      "can_mod_post": false,
                      "created_utc": 1751177799,
                      "send_replies": true,
                      "parent_id": "t1_n0cwy3z",
                      "score": 1,
                      "author_fullname": "t2_7f6bw7v0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "this one is a bit \"funkee\" as it allows you to attenuate alpha of the lora, something I use often.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n0d84ro",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;this one is a bit &amp;quot;funkee&amp;quot; as it allows you to attenuate alpha of the lora, something I use often.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ln10a8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ln10a8/a_bunch_of_llm_fpham_python_scripts_ive_added_to/n0d84ro/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751177799,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n0cwy3z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "random-tomato",
            "can_mod_post": false,
            "created_utc": 1751172069,
            "send_replies": true,
            "parent_id": "t3_1ln10a8",
            "score": 2,
            "author_fullname": "t2_fmd6oq5v6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You **also** made a script to merge LoRA with the base model!?!? I thought I was the only one haha",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0cwy3z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You &lt;strong&gt;also&lt;/strong&gt; made a script to merge LoRA with the base model!?!? I thought I was the only one haha&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ln10a8/a_bunch_of_llm_fpham_python_scripts_ive_added_to/n0cwy3z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751172069,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1ln10a8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n0dh69r",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ok_Appearance3584",
            "can_mod_post": false,
            "created_utc": 1751183030,
            "send_replies": true,
            "parent_id": "t3_1ln10a8",
            "score": 1,
            "author_fullname": "t2_oyxj85n1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is that LoRA merge as in you just glue the additional weights to the base model and thus increase its size by whatever the adapter size is, or do you somehow ... calculate what the original base model weights should be to yield similar results?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0dh69r",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is that LoRA merge as in you just glue the additional weights to the base model and thus increase its size by whatever the adapter size is, or do you somehow ... calculate what the original base model weights should be to yield similar results?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ln10a8/a_bunch_of_llm_fpham_python_scripts_ive_added_to/n0dh69r/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751183030,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ln10a8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]