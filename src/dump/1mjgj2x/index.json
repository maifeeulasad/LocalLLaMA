[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Today we've released support for ROCm7 beta as a llama.cpp backend in Lemonade Server.\n\nThis is supported on both Ubuntu and Windows on certain Radeon devices, see the [github README](https://github.com/lemonade-sdk/lemonade#supported-configurations) for details:\n\n* Strix Halo\n* Radeon 7000-series\n* Radeon 9000-series (Windows-only until we fix a bug)\n\n**Trying ROCm7+Lemonade**\n\nSince ROCm7 itself is still a beta, we've only enabled this feature when installing from PyPI or source for now.\n\nIn a Python 3.10-3.12 environment, on your supported Radeon PC:\n\n`pip install lemonade-sdk`\n\n`lemonade-server-dev serve --llamacpp rocm`\n\n**Implementation**\n\nTo enable this, we created a new repo specifically for automatically building llama.cpp binaries against ROCm7 beta: [https://github.com/lemonade-sdk/llamacpp-rocm](https://github.com/lemonade-sdk/llamacpp-rocm)\n\nThe llamacpp-rocm repo takes nightlies from TheRock, builds against the latest llama.cpp from ggml, and releases llama.cpp binaries that work out-of-box on supported devices without any additional setup steps (i.e., you don't need to install ROCm or build anything).\n\nReleases from llamacpp-rocm are usable standalone, but the easiest way to get started is with the Lemonade instructions above, which downloads everything for you and provides a convenient model management interface.\n\n**Notes**\n\nDemo in the video recorded on a Radeon 9070 XT with the ROCm backend.\n\nNext steps for this work are to update to the stable ROCm 7 release when it becomes available, then make ROCm available via the Lemonade GUI installer.\n\nShoutout to u/randomfoo2 for the help and encouragement along the way!\n\n**Links**\n\nGitHub: https://github.com/lemonade-sdk/lemonade/\nDiscord: https://discord.gg/Sf8cfBWB",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "llamacpp+ROCm7 beta is now supported on Lemonade",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjgj2x",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.87,
            "author_flair_background_color": null,
            "ups": 60,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1m2ckixcqh",
            "secure_media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/r5grj7kxkghf1/DASH_1080.mp4?source=fallback",
                "has_audio": true,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/r5grj7kxkghf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/r5grj7kxkghf1/DASHPlaylist.mpd?a=1757162021%2COTExODM0NzFjNGU3MDE4ZDJhYmU0OGQ3MmM0NjAzOTlhNDAzZmVlMDU5ZTY5NWU4ZTMzY2I3Y2JjMTUxYmZlNQ%3D%3D&amp;v=1&amp;f=sd",
                "duration": 10,
                "hls_url": "https://v.redd.it/r5grj7kxkghf1/HLSPlaylist.m3u8?a=1757162021%2CNDU1YmE0ODNlZGFlZjM3YTYyOWRhOTA2OTU4NGQ4MTc2MDU5YjFmZTQ2ZGMyOTZkYTcwOGFkZmYyNzhiYWJjZA%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 60,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=bdfa4ec69cd2e7cca60e87eb1645a920bd3c62c4",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "hosted:video",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754513968,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "v.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today we&amp;#39;ve released support for ROCm7 beta as a llama.cpp backend in Lemonade Server.&lt;/p&gt;\n\n&lt;p&gt;This is supported on both Ubuntu and Windows on certain Radeon devices, see the &lt;a href=\"https://github.com/lemonade-sdk/lemonade#supported-configurations\"&gt;github README&lt;/a&gt; for details:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Strix Halo&lt;/li&gt;\n&lt;li&gt;Radeon 7000-series&lt;/li&gt;\n&lt;li&gt;Radeon 9000-series (Windows-only until we fix a bug)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Trying ROCm7+Lemonade&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Since ROCm7 itself is still a beta, we&amp;#39;ve only enabled this feature when installing from PyPI or source for now.&lt;/p&gt;\n\n&lt;p&gt;In a Python 3.10-3.12 environment, on your supported Radeon PC:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;pip install lemonade-sdk&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;lemonade-server-dev serve --llamacpp rocm&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;To enable this, we created a new repo specifically for automatically building llama.cpp binaries against ROCm7 beta: &lt;a href=\"https://github.com/lemonade-sdk/llamacpp-rocm\"&gt;https://github.com/lemonade-sdk/llamacpp-rocm&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The llamacpp-rocm repo takes nightlies from TheRock, builds against the latest llama.cpp from ggml, and releases llama.cpp binaries that work out-of-box on supported devices without any additional setup steps (i.e., you don&amp;#39;t need to install ROCm or build anything).&lt;/p&gt;\n\n&lt;p&gt;Releases from llamacpp-rocm are usable standalone, but the easiest way to get started is with the Lemonade instructions above, which downloads everything for you and provides a convenient model management interface.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Demo in the video recorded on a Radeon 9070 XT with the ROCm backend.&lt;/p&gt;\n\n&lt;p&gt;Next steps for this work are to update to the stable ROCm 7 release when it becomes available, then make ROCm available via the Lemonade GUI installer.&lt;/p&gt;\n\n&lt;p&gt;Shoutout to &lt;a href=\"/u/randomfoo2\"&gt;u/randomfoo2&lt;/a&gt; for the help and encouragement along the way!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub: &lt;a href=\"https://github.com/lemonade-sdk/lemonade/\"&gt;https://github.com/lemonade-sdk/lemonade/&lt;/a&gt;\nDiscord: &lt;a href=\"https://discord.gg/Sf8cfBWB\"&gt;https://discord.gg/Sf8cfBWB&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://v.redd.it/r5grj7kxkghf1",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?format=pjpg&amp;auto=webp&amp;s=d67497215999197eba90b1ac2fe861231cf6dc3f",
                    "width": 1920,
                    "height": 1080
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e4428efe96729a5809c13b1c0f5dc203b5a226e0",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=485127e4f28f73ebeef8df57711c21e2d93328b9",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=978f4be2e41a3bf4262a2363c19d8bf0a694dbfe",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2866bc6cc265971c58fda129b44aaf194945df54",
                      "width": 640,
                      "height": 360
                    },
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4b54850b3a6128413894bb07b8fe46ee3e6fb4c2",
                      "width": 960,
                      "height": 540
                    },
                    {
                      "url": "https://external-preview.redd.it/c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3b88e524d40575ef556e25d57607aa1fce02dab1",
                      "width": 1080,
                      "height": 607
                    }
                  ],
                  "variants": {},
                  "id": "c3prY2pha3hrZ2hmMdl39J6dzlST6kaTI5eOYBacsgH9YzvxyDtJB5DpM2pE"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mjgj2x",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "jfowers_amd",
            "discussion_type": null,
            "num_comments": 18,
            "send_replies": true,
            "media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/r5grj7kxkghf1/DASH_1080.mp4?source=fallback",
                "has_audio": true,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/r5grj7kxkghf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/r5grj7kxkghf1/DASHPlaylist.mpd?a=1757162021%2COTExODM0NzFjNGU3MDE4ZDJhYmU0OGQ3MmM0NjAzOTlhNDAzZmVlMDU5ZTY5NWU4ZTMzY2I3Y2JjMTUxYmZlNQ%3D%3D&amp;v=1&amp;f=sd",
                "duration": 10,
                "hls_url": "https://v.redd.it/r5grj7kxkghf1/HLSPlaylist.m3u8?a=1757162021%2CNDU1YmE0ODNlZGFlZjM3YTYyOWRhOTA2OTU4NGQ4MTc2MDU5YjFmZTQ2ZGMyOTZkYTcwOGFkZmYyNzhiYWJjZA%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/",
            "stickied": false,
            "url": "https://v.redd.it/r5grj7kxkghf1",
            "subreddit_subscribers": 512875,
            "created_utc": 1754513968,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": true
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7b7d46",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ai-christianson",
            "can_mod_post": false,
            "created_utc": 1754517499,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": 11,
            "author_fullname": "t2_1er159f32z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice to have options other than NVIDIA 👍",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7b7d46",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice to have options other than NVIDIA 👍&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7b7d46/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754517499,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7bd72e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "TSG-AYAN",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7bcq0r",
                                "score": 3,
                                "author_fullname": "t2_5ml0rsi7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "so its just untested, i see. ty",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7bd72e",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;so its just untested, i see. ty&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjgj2x",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bd72e/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754519341,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754519341,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7bcq0r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jfowers_amd",
                      "can_mod_post": false,
                      "created_utc": 1754519186,
                      "send_replies": true,
                      "parent_id": "t1_n7b9r46",
                      "score": 3,
                      "author_fullname": "t2_1m2ckixcqh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Not that I’m aware of. The only reason some GPU families are not in our support table is because we only have a few GPUs to test on right now.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7bcq0r",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not that I’m aware of. The only reason some GPU families are not in our support table is because we only have a few GPUs to test on right now.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bcq0r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754519186,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7b9r46",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "TSG-AYAN",
            "can_mod_post": false,
            "created_utc": 1754518242,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": 4,
            "author_fullname": "t2_5ml0rsi7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "is rocm 7 dropping support for navi2?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7b9r46",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;is rocm 7 dropping support for navi2?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7b9r46/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754518242,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7clpbr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "shifty21",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7cjr9n",
                                "score": 3,
                                "author_fullname": "t2_4andn",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks for the fast reply!\n\nI moved the compressed file to a Ubuntu host to extract and upload to VirusTotal for more info\n\n\\[EDIT\\]\n\n[https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70](https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70) \n\nCame out clean.  Not sure why MS Defender on my box freaked out.",
                                "edited": 1754534943,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7clpbr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the fast reply!&lt;/p&gt;\n\n&lt;p&gt;I moved the compressed file to a Ubuntu host to extract and upload to VirusTotal for more info&lt;/p&gt;\n\n&lt;p&gt;[EDIT]&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70\"&gt;https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Came out clean.  Not sure why MS Defender on my box freaked out.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjgj2x",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7clpbr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754534604,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754534604,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7cjr9n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jfowers_amd",
                      "can_mod_post": false,
                      "created_utc": 1754533883,
                      "send_replies": true,
                      "parent_id": "t1_n7ciiyx",
                      "score": 2,
                      "author_fullname": "t2_1m2ckixcqh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for reporting, and sorry about that. We’ve seen it occasionally in testing but we thought we squashed it.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7cjr9n",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for reporting, and sorry about that. We’ve seen it occasionally in testing but we thought we squashed it.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7cjr9n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754533883,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7ciiyx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "shifty21",
            "can_mod_post": false,
            "created_utc": 1754533435,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": 3,
            "author_fullname": "t2_4andn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Strange... I got a Virus warning from MS Defender on Windows 11 for \"llama-batched-bench.exe\"\n\nClaims it is a Trojan:Win32/Wacatac.C!ml\n\nI'm fairly sure this is a false-positive.\n\nI don't think that executable is really necessary for me, however.  Just making some awareness.\n\n  \n**\\[EDIT\\]** [https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70](https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70)\n\nVT claims the binary is clean, so if you're MS Defender is trippin' out, I don't think it is a big deal unless you absolutely need that binary.",
            "edited": 1754535024,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7ciiyx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Strange... I got a Virus warning from MS Defender on Windows 11 for &amp;quot;llama-batched-bench.exe&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Claims it is a Trojan:Win32/Wacatac.C!ml&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly sure this is a false-positive.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think that executable is really necessary for me, however.  Just making some awareness.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;[EDIT]&lt;/strong&gt; &lt;a href=\"https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70\"&gt;https://www.virustotal.com/gui/file/59924ce8d80b489446164f5e6647f39a07217c9c2d507306f9c789a19b225c70&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;VT claims the binary is clean, so if you&amp;#39;re MS Defender is trippin&amp;#39; out, I don&amp;#39;t think it is a big deal unless you absolutely need that binary.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7ciiyx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754533435,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7ay6ha",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "jfowers_amd",
                      "can_mod_post": false,
                      "created_utc": 1754514727,
                      "send_replies": true,
                      "parent_id": "t1_n7axxjs",
                      "score": 7,
                      "author_fullname": "t2_1m2ckixcqh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "u/randomfoo2 has shared a lot of benchmarks, can check their post history. TLDR is that ROCm7 is still in beta, and perf improvements are a work in progress. This Lemonade update means that we can always be up-to-date with the best of ROCm.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7ay6ha",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/u/randomfoo2\"&gt;u/randomfoo2&lt;/a&gt; has shared a lot of benchmarks, can check their post history. TLDR is that ROCm7 is still in beta, and perf improvements are a work in progress. This Lemonade update means that we can always be up-to-date with the best of ROCm.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7ay6ha/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754514727,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7bjjen",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "fallingdowndizzyvr",
                      "can_mod_post": false,
                      "created_utc": 1754521460,
                      "send_replies": true,
                      "parent_id": "t1_n7axxjs",
                      "score": 4,
                      "author_fullname": "t2_o65i6kx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Noice. Did Strix Halo performance gain any improvements as a result?\n\nYes, if you consider that it runs in Linux now under ROCm 7. Before it didn't. It was missing a library for gfx1151(Strix Halo). Now it has it. It still has problems. There are somethings that run on my 7900xtx that still won't on Strix Halo. I think they need to focus on functionality first before worrying about performance.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7bjjen",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Noice. Did Strix Halo performance gain any improvements as a result?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes, if you consider that it runs in Linux now under ROCm 7. Before it didn&amp;#39;t. It was missing a library for gfx1151(Strix Halo). Now it has it. It still has problems. There are somethings that run on my 7900xtx that still won&amp;#39;t on Strix Halo. I think they need to focus on functionality first before worrying about performance.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bjjen/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754521460,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7c1mx7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "fallingdowndizzyvr",
                      "can_mod_post": false,
                      "created_utc": 1754527529,
                      "send_replies": true,
                      "parent_id": "t1_n7axxjs",
                      "score": 2,
                      "author_fullname": "t2_o65i6kx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Here. I just did a couple of runs. One in Vulkan and one with ROCm 7. This is my own build of llama.cpp I made yesterday. Vulkan is still faster than ROCm.\n\n    ggml_vulkan: 0 = AMD Radeon Graphics (RADV GFX1151) (radv) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat\n    | model                          |       size |     params | backend    | ngl | fa | mmap |            test |                  t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | --: | -: | ---: | --------------: | -------------------: |\n    | glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | Vulkan,RPC | 9999 |  1 |    0 |           pp512 |        111.21 ± 0.65 |\n    | glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | Vulkan,RPC | 9999 |  1 |    0 |           tg128 |         20.30 ± 0.01 |\n    \n      Device 0: AMD Radeon Graphics, gfx1151 (0x1151), VMM: no, Wave Size: 32\n    | model                          |       size |     params | backend    | ngl | fa | mmap |            test |                  t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | --: | -: | ---: | --------------: | -------------------: |\n    | glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | ROCm,RPC   | 9999 |  1 |    0 |           pp512 |        101.84 ± 0.12 |\n    | glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | ROCm,RPC   | 9999 |  1 |    0 |           tg128 |         18.09 ± 0.01 |",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7c1mx7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here. I just did a couple of runs. One in Vulkan and one with ROCm 7. This is my own build of llama.cpp I made yesterday. Vulkan is still faster than ROCm.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ggml_vulkan: 0 = AMD Radeon Graphics (RADV GFX1151) (radv) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat\n| model                          |       size |     params | backend    | ngl | fa | mmap |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | --: | -: | ---: | --------------: | -------------------: |\n| glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | Vulkan,RPC | 9999 |  1 |    0 |           pp512 |        111.21 ± 0.65 |\n| glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | Vulkan,RPC | 9999 |  1 |    0 |           tg128 |         20.30 ± 0.01 |\n\n  Device 0: AMD Radeon Graphics, gfx1151 (0x1151), VMM: no, Wave Size: 32\n| model                          |       size |     params | backend    | ngl | fa | mmap |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | --: | -: | ---: | --------------: | -------------------: |\n| glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | ROCm,RPC   | 9999 |  1 |    0 |           pp512 |        101.84 ± 0.12 |\n| glm4moe 106B.A12B Q5_K - Medium |  77.75 GiB |   110.47 B | ROCm,RPC   | 9999 |  1 |    0 |           tg128 |         18.09 ± 0.01 |\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7c1mx7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754527529,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7axxjs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "gusbags",
            "can_mod_post": false,
            "created_utc": 1754514653,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": 3,
            "author_fullname": "t2_5zebabtc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Noice. Did Strix Halo performance gain any improvements as a result?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7axxjs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Noice. Did Strix Halo performance gain any improvements as a result?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7axxjs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754514653,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dwwuv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Wrong-Historian",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7bqbwq",
                                "score": 0,
                                "author_fullname": "t2_69r67vj3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "But I still don't understand. Are you making code changes to some special branch of llama-cpp?  Then why are you not contributing to upstream?\n\nOr (more likely) you are just *taking* upstream dev branch and compiling that.\n\nLook, the problem is that you make it sound like you are doing some special work, while in fact its the people of llama-cpp doing all the ROCm work.\n\nIs there anything lemonade can do (regarding rocm) that I cant do by just checking out the relevant dev branch from llama cpp git and compiling that myself?\n\nDONT take their thunder. Lemonade is just a wrapper, correct?\n\nSame shit as ollama does. They always make it appear 'we added support for this and that' while in fact it's llama-cpp that added support for this and that and they just leach on it. Which is fine, for open-source projects, but just give credit where credit due and provide a clear description of what your project actually does and what extra value it provides (which STILL is not clear to me for lemonade, even when spending some time trying to understand it).",
                                "edited": 1754558340,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dwwuv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But I still don&amp;#39;t understand. Are you making code changes to some special branch of llama-cpp?  Then why are you not contributing to upstream?&lt;/p&gt;\n\n&lt;p&gt;Or (more likely) you are just &lt;em&gt;taking&lt;/em&gt; upstream dev branch and compiling that.&lt;/p&gt;\n\n&lt;p&gt;Look, the problem is that you make it sound like you are doing some special work, while in fact its the people of llama-cpp doing all the ROCm work.&lt;/p&gt;\n\n&lt;p&gt;Is there anything lemonade can do (regarding rocm) that I cant do by just checking out the relevant dev branch from llama cpp git and compiling that myself?&lt;/p&gt;\n\n&lt;p&gt;DONT take their thunder. Lemonade is just a wrapper, correct?&lt;/p&gt;\n\n&lt;p&gt;Same shit as ollama does. They always make it appear &amp;#39;we added support for this and that&amp;#39; while in fact it&amp;#39;s llama-cpp that added support for this and that and they just leach on it. Which is fine, for open-source projects, but just give credit where credit due and provide a clear description of what your project actually does and what extra value it provides (which STILL is not clear to me for lemonade, even when spending some time trying to understand it).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjgj2x",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7dwwuv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754558041,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754558041,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7bqbwq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "jfowers_amd",
                      "can_mod_post": false,
                      "created_utc": 1754523679,
                      "send_replies": true,
                      "parent_id": "t1_n7bkccc",
                      "score": 5,
                      "author_fullname": "t2_1m2ckixcqh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The upstream llamacpp project has some support for ROCm, but requires extra steps from the user to get it working. The llamacpp-rocm in this post is much more convenient. If you want to use llamacpp+rocm, without any wrapper software, I would recommend it.\n\nlemonade-server is convenience wrapper around not only llama-server (now with ROCm) but also ONNX Runtime GenAI, and is one of the only ways of using a Ryzen AI NPU for LLMs. lemonade-server also offers some convenience features llama-server doesn't have, like a GUI installer, tray app, model management GUI, etc. \n\nThose are just the facts. Something I like about localllama is that there's so many cool projects that people can pick what works best for them.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7bqbwq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The upstream llamacpp project has some support for ROCm, but requires extra steps from the user to get it working. The llamacpp-rocm in this post is much more convenient. If you want to use llamacpp+rocm, without any wrapper software, I would recommend it.&lt;/p&gt;\n\n&lt;p&gt;lemonade-server is convenience wrapper around not only llama-server (now with ROCm) but also ONNX Runtime GenAI, and is one of the only ways of using a Ryzen AI NPU for LLMs. lemonade-server also offers some convenience features llama-server doesn&amp;#39;t have, like a GUI installer, tray app, model management GUI, etc. &lt;/p&gt;\n\n&lt;p&gt;Those are just the facts. Something I like about localllama is that there&amp;#39;s so many cool projects that people can pick what works best for them.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bqbwq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754523679,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7bkccc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Wrong-Historian",
            "can_mod_post": false,
            "created_utc": 1754521729,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": 1,
            "author_fullname": "t2_69r67vj3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Im reading for 10 minutes now and I still dont understand what this lemonade-server is. A wrapper around llama-cpp? Why would I use this instead of just llama-cpp-server directly? Doesn't that support ROCm? So llama-cpp added ROCm7 as a beta and now that also works in your wrapper?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7bkccc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Im reading for 10 minutes now and I still dont understand what this lemonade-server is. A wrapper around llama-cpp? Why would I use this instead of just llama-cpp-server directly? Doesn&amp;#39;t that support ROCm? So llama-cpp added ROCm7 as a beta and now that also works in your wrapper?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bkccc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754521729,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7b83v3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ravage382",
                      "can_mod_post": false,
                      "created_utc": 1754517726,
                      "send_replies": true,
                      "parent_id": "t1_n7b50wg",
                      "score": 1,
                      "author_fullname": "t2_9sf41",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"Windows and Ubuntu operating systems\" Is dual booting a possibility?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7b83v3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Windows and Ubuntu operating systems&amp;quot; Is dual booting a possibility?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7b83v3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754517726,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7bcvsd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jfowers_amd",
                      "can_mod_post": false,
                      "created_utc": 1754519238,
                      "send_replies": true,
                      "parent_id": "t1_n7b50wg",
                      "score": 1,
                      "author_fullname": "t2_1m2ckixcqh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "ROCm requires an AMD GPU and windows or Linux OS. Might be technically possible on one of the old Intel Macs?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7bcvsd",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ROCm requires an AMD GPU and windows or Linux OS. Might be technically possible on one of the old Intel Macs?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjgj2x",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7bcvsd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754519238,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7b50wg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "matt8p",
            "can_mod_post": false,
            "created_utc": 1754516790,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": -1,
            "author_fullname": "t2_1t7ktq69",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm on a Mac. Is this relevant / even possible to use?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7b50wg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m on a Mac. Is this relevant / even possible to use?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7b50wg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754516790,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7avzmu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "sudochmod",
            "can_mod_post": false,
            "created_utc": 1754514078,
            "send_replies": true,
            "parent_id": "t3_1mjgj2x",
            "score": -6,
            "author_fullname": "t2_atde2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "First!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7avzmu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;First!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjgj2x/llamacpprocm7_beta_is_now_supported_on_lemonade/n7avzmu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754514078,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjgj2x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -6
          }
        }
      ],
      "before": null
    }
  }
]