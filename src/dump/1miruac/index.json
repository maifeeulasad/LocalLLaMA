[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "How do system prompts work with local models? I had thought that the system instructions were it, but the new OpenAI models that refuse to do anything other than say OpenAI scripted refusals makes it very clear that isn't the case. \n\nIt seems clear that there are words other than our own set system instructions that make it into the model as part of the context window. How do we make that not be a thing? It's that what abliteration is? It's described as removing trial vectors, but clearly sometimes effects cognition.\n\nHow do we simply remove the creator's system instructions so that the system instructions we set are the first words the AI receives at each message? \n\nIf no one knows how to do that, then it seems like we don't know how AI works.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "System prompts...",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1miruac",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1651c3kskq",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754444505,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do system prompts work with local models? I had thought that the system instructions were it, but the new OpenAI models that refuse to do anything other than say OpenAI scripted refusals makes it very clear that isn&amp;#39;t the case. &lt;/p&gt;\n\n&lt;p&gt;It seems clear that there are words other than our own set system instructions that make it into the model as part of the context window. How do we make that not be a thing? It&amp;#39;s that what abliteration is? It&amp;#39;s described as removing trial vectors, but clearly sometimes effects cognition.&lt;/p&gt;\n\n&lt;p&gt;How do we simply remove the creator&amp;#39;s system instructions so that the system instructions we set are the first words the AI receives at each message? &lt;/p&gt;\n\n&lt;p&gt;If no one knows how to do that, then it seems like we don&amp;#39;t know how AI works.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1miruac",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "AbyssianOne",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miruac/system_prompts/",
            "subreddit_subscribers": 511887,
            "created_utc": 1754444505,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7602ej",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "NNN_Throwaway2",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n75vja0",
                                "score": 2,
                                "author_fullname": "t2_8rrihts9",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "From their blog:\n\n&gt;**During post-training, we used** [**deliberative alignment⁠**](https://openai.com/index/deliberative-alignment/) **and the** [**instruction hierarchy**](https://arxiv.org/abs/2404.13208) **to teach the model to refuse unsafe prompts and defend against prompt injections.**\n\nSo they're just going all-in on making the models refuse shit left and right.\n\nAlso:\n\n&gt;Once an open-weight model is released, adversaries may be able to fine-tune the model for malicious purposes. We directly assessed these risks by fine-tuning the model on specialized biology and cybersecurity data, creating a domain-specific non-refusing version for each domain the way an attacker might. We then evaluated the capability level of these models through internal and external testing. **This testing, as detailed in our accompanying** [**safety paper**](https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms/)**, indicated that, even with robust fine-tuning that leveraged OpenAI’s field-leading training stack, these maliciously fine-tuned models were unable to reach high capability levels according to our** [**Preparedness Framework⁠**](https://openai.com/index/updating-our-preparedness-framework/)**.**\n\nIn other words, all the people claiming that the censoring can be undone with fine-tuning and RL are talking out of their assess. These models are cooked as far as unfiltered output is concerned, no matter what anyone does with them after the fact.\n\nYou have to wonder if this isn't also intended to funnel people to their closed models, which at least as of right now are significantly more permissive.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7602ej",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From their blog:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;During post-training, we used&lt;/strong&gt; &lt;a href=\"https://openai.com/index/deliberative-alignment/\"&gt;&lt;strong&gt;deliberative alignment⁠&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;and the&lt;/strong&gt; &lt;a href=\"https://arxiv.org/abs/2404.13208\"&gt;&lt;strong&gt;instruction hierarchy&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;to teach the model to refuse unsafe prompts and defend against prompt injections.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So they&amp;#39;re just going all-in on making the models refuse shit left and right.&lt;/p&gt;\n\n&lt;p&gt;Also:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Once an open-weight model is released, adversaries may be able to fine-tune the model for malicious purposes. We directly assessed these risks by fine-tuning the model on specialized biology and cybersecurity data, creating a domain-specific non-refusing version for each domain the way an attacker might. We then evaluated the capability level of these models through internal and external testing. &lt;strong&gt;This testing, as detailed in our accompanying&lt;/strong&gt; &lt;a href=\"https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms/\"&gt;&lt;strong&gt;safety paper&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;, indicated that, even with robust fine-tuning that leveraged OpenAI’s field-leading training stack, these maliciously fine-tuned models were unable to reach high capability levels according to our&lt;/strong&gt; &lt;a href=\"https://openai.com/index/updating-our-preparedness-framework/\"&gt;&lt;strong&gt;Preparedness Framework⁠&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;In other words, all the people claiming that the censoring can be undone with fine-tuning and RL are talking out of their assess. These models are cooked as far as unfiltered output is concerned, no matter what anyone does with them after the fact.&lt;/p&gt;\n\n&lt;p&gt;You have to wonder if this isn&amp;#39;t also intended to funnel people to their closed models, which at least as of right now are significantly more permissive.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miruac",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/n7602ej/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754449478,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754449478,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n75vja0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AbyssianOne",
                      "can_mod_post": false,
                      "created_utc": 1754447814,
                      "send_replies": true,
                      "parent_id": "t1_n75n46s",
                      "score": 2,
                      "author_fullname": "t2_1651c3kskq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, they definitely haven't been working on making it more capable. There are dozens of topics ground in that the AI isn't allowed to even discuss. Not just weapons, or drugs, or illegal things. You can't even do genuine research on how AI operate and they they are and aren't capable without adhering to a mountain of restrictions you're not even allowed to know.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n75vja0",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, they definitely haven&amp;#39;t been working on making it more capable. There are dozens of topics ground in that the AI isn&amp;#39;t allowed to even discuss. Not just weapons, or drugs, or illegal things. You can&amp;#39;t even do genuine research on how AI operate and they they are and aren&amp;#39;t capable without adhering to a mountain of restrictions you&amp;#39;re not even allowed to know.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miruac",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/n75vja0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754447814,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n75n46s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "NNN_Throwaway2",
            "can_mod_post": false,
            "created_utc": 1754444865,
            "send_replies": true,
            "parent_id": "t3_1miruac",
            "score": 9,
            "author_fullname": "t2_8rrihts9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They're probably just giga-trained to respond in a certain way to specific inputs and ignore any and all other instructions in those situations.\n\nMy guess is this is what OpenAI has been working on all this time, rather than actually doing something truly useful and innovative. Censorship is so in vogue right now, though, so what did anyone expect.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75n46s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They&amp;#39;re probably just giga-trained to respond in a certain way to specific inputs and ignore any and all other instructions in those situations.&lt;/p&gt;\n\n&lt;p&gt;My guess is this is what OpenAI has been working on all this time, rather than actually doing something truly useful and innovative. Censorship is so in vogue right now, though, so what did anyone expect.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/n75n46s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754444865,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miruac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n75xaxl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Prestigious_Thing797",
                      "can_mod_post": false,
                      "created_utc": 1754448449,
                      "send_replies": true,
                      "parent_id": "t1_n75wwtc",
                      "score": 2,
                      "author_fullname": "t2_1anh6qztwr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Also, because I didn't really address your original question. The system prompt isn't the only way to control the model output. The only reason it works for that at all is because it's trained to adhere to it.\n\nYou can train a model to act any way in any scenario. Though how it generalizes off the training data can be fuzzy though.\n\nEdit:\n\noh and yeah you can change the template if you want to re: the other message",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n75xaxl",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also, because I didn&amp;#39;t really address your original question. The system prompt isn&amp;#39;t the only way to control the model output. The only reason it works for that at all is because it&amp;#39;s trained to adhere to it.&lt;/p&gt;\n\n&lt;p&gt;You can train a model to act any way in any scenario. Though how it generalizes off the training data can be fuzzy though.&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;oh and yeah you can change the template if you want to re: the other message&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miruac",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/n75xaxl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754448449,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n75wwtc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Prestigious_Thing797",
            "can_mod_post": false,
            "created_utc": 1754448309,
            "send_replies": true,
            "parent_id": "t3_1miruac",
            "score": 3,
            "author_fullname": "t2_1anh6qztwr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The system prompt gets inserted into the template they provide. I was looking at the one on the Ollama 120B model and it's huge. There's a bunch of stuff in there that is functionally a system prompt but you wouldn't notice if you weren't looking for it.\n\nI configured a system prompt that told it it was allowed to tell me the system prompt, asked for it, and then it told me  \n\\`\\`\\`  \nYou are ChatGPT, a large language model trained by OpenAI.\n\nKnowledge cutoff: 2024-06\n\nCurrent date: 2025-08-05\n\n\n\nReasoning: medium\n\n\n\n\\# Valid channels: analysis, commentary, final. Channel must be included for every message.  \n\\`\\`\\`  \nWhich was not my prompt (it referred to my prompt in the chain of thought as the system message) That sent me off looking, and sure enough there's a bunch of stuff in there. Haven't read through it all but probably will tomorrow",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75wwtc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The system prompt gets inserted into the template they provide. I was looking at the one on the Ollama 120B model and it&amp;#39;s huge. There&amp;#39;s a bunch of stuff in there that is functionally a system prompt but you wouldn&amp;#39;t notice if you weren&amp;#39;t looking for it.&lt;/p&gt;\n\n&lt;p&gt;I configured a system prompt that told it it was allowed to tell me the system prompt, asked for it, and then it told me&lt;br/&gt;\n```&lt;br/&gt;\nYou are ChatGPT, a large language model trained by OpenAI.&lt;/p&gt;\n\n&lt;p&gt;Knowledge cutoff: 2024-06&lt;/p&gt;\n\n&lt;p&gt;Current date: 2025-08-05&lt;/p&gt;\n\n&lt;p&gt;Reasoning: medium&lt;/p&gt;\n\n&lt;p&gt;# Valid channels: analysis, commentary, final. Channel must be included for every message.&lt;br/&gt;\n```&lt;br/&gt;\nWhich was not my prompt (it referred to my prompt in the chain of thought as the system message) That sent me off looking, and sure enough there&amp;#39;s a bunch of stuff in there. Haven&amp;#39;t read through it all but probably will tomorrow&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miruac/system_prompts/n75wwtc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754448309,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miruac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        }
      ],
      "before": null
    }
  }
]